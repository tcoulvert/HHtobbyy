{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmslpcgpu3.fnal.gov      Fri Jan 31 17:38:33 2025  555.42.06\n",
      "[0] Tesla P100-PCIE-12GB | 42Â°C,   1 % |     0 / 12288 MB |\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib widget\n",
    "# Stdlib packages\n",
    "import copy\n",
    "import datetime\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "# Common Py packages\n",
    "import awkward as ak\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from prettytable import PrettyTable\n",
    "from scipy.special import logit as inverse_sigmoid\n",
    "\n",
    "# HEP packages\n",
    "import gpustat\n",
    "import h5py\n",
    "import hist\n",
    "import mplhep as hep\n",
    "import xgboost as xgb\n",
    "from cycler import cycler\n",
    "\n",
    "# ML packages\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, fbeta_score\n",
    "from scipy.integrate import trapezoid\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Integer\n",
    "from skopt.utils import use_named_args\n",
    "\n",
    "# Module packages\n",
    "from data_processing_BDT_v2 import process_data\n",
    "\n",
    "gpustat.print_gpustat()\n",
    "\n",
    "plt.style.use(hep.style.CMS)\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "cmap_petroff10 = [\"#3f90da\", \"#ffa90e\", \"#bd1f01\", \"#94a4a2\", \"#832db6\", \"#a96b59\", \"#e76300\", \"#b9ac70\", \"#717581\", \"#92dadd\"]\n",
    "plt.rcParams.update({\"axes.prop_cycle\": cycler(\"color\", cmap_petroff10)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Locations and Model Naming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lpc_fileprefix = \"/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v2/Run3_2022_merged_v1/sim\"\n",
    "\n",
    "FILEPATHS_DICT = {\n",
    "    'ggF HH': [\n",
    "        # lpc_fileprefix+f\"/preEE/GluGluToHH/nominal/*\", \n",
    "        lpc_fileprefix+f\"/postEE/GluGluToHH/nominal/*merged.parquet\"\n",
    "    ],\n",
    "    # 'VBF HH': [\n",
    "    #     lpc_fileprefix+f\"/Run3_2022preEE_merged_v4/VBFHHto2B2G_CV_1_C2V_1_C3_1/nominal/*\", \n",
    "    #     lpc_fileprefix+f\"/Run3_2022postEE_merged_v4/VBFHHto2B2G_CV_1_C2V_1_C3_1/nominal/*\"\n",
    "    # ],\n",
    "    'ttH': [\n",
    "        lpc_fileprefix+f\"/preEE/ttHtoGG_M_125/nominal/*merged.parquet\", \n",
    "        lpc_fileprefix+f\"/postEE/ttHToGG/nominal/*merged.parquet\"\n",
    "    ],\n",
    "    'VH': [\n",
    "        # VH\n",
    "        lpc_fileprefix+f\"/preEE/VHtoGG_M_125/nominal/*merged.parquet\", \n",
    "        lpc_fileprefix+f\"/postEE/VHToGG/nominal/*merged.parquet\",\n",
    "    ],\n",
    "    # 'bbH': [\n",
    "    #     lpc_fileprefix+f\"/preEE/BBHto2G_M_125/nominal/*\", \n",
    "    #     lpc_fileprefix+f\"/postEE/BBHto2G_M_125/nominal/*\"\n",
    "    # ],\n",
    "    'non-res + ggFH + VBFH': [\n",
    "        # GG + 3Jets\n",
    "        lpc_fileprefix+f\"/preEE/GGJets/nominal/*merged.parquet\", \n",
    "        lpc_fileprefix+f\"/postEE/GGJets/nominal/*merged.parquet\",\n",
    "        # GJet pT 20-40\n",
    "        lpc_fileprefix+f\"/preEE/GJetPt20To40/nominal/*merged.parquet\", \n",
    "        lpc_fileprefix+f\"/postEE/GJetPt20To40/nominal/*merged.parquet\",\n",
    "        # GJet pT 40-inf\n",
    "        lpc_fileprefix+f\"/preEE/GJetPt40/nominal/*merged.parquet\", \n",
    "        lpc_fileprefix+f\"/postEE/GJetPt40/nominal/*merged.parquet\",\n",
    "        # ggF H\n",
    "        lpc_fileprefix+f\"/preEE/GluGluHToGG_M_125/nominal/*merged.parquet\", \n",
    "        lpc_fileprefix+f\"/postEE/GluGluHToGG/nominal/*merged.parquet\",\n",
    "        # VBF H\n",
    "        lpc_fileprefix+f\"/preEE/VBFHToGG_M_125/nominal/*merged.parquet\", \n",
    "        lpc_fileprefix+f\"/postEE/VBFHToGG/nominal/*merged.parquet\",\n",
    "    ],\n",
    "    # 'single-H': [\n",
    "    #     # ggF H\n",
    "    #     lpc_fileprefix+f\"/preEE/GluGluHToGG/nominal/*\", \n",
    "    #     lpc_fileprefix+f\"/postEE/GluGluHToGG/nominal/*\",\n",
    "    #     # VBF H\n",
    "    #     lpc_fileprefix+f\"/preEE/VBFHToGG/nominal/*\", \n",
    "    #     lpc_fileprefix+f\"/postEE/VBFHToGG/nominal/*\",\n",
    "    #     # VH\n",
    "    #     lpc_fileprefix+f\"/preEE/VHToGG/nominal/*\", \n",
    "    #     lpc_fileprefix+f\"/postEE/VHToGG/nominal/*\",\n",
    "    # ],\n",
    "    # 'non-res': [\n",
    "    #     # GG + 3Jets\n",
    "    #     lpc_fileprefix+f\"/preEE/GGJets/nominal/*\", \n",
    "    #     lpc_fileprefix+f\"/postEE/GGJets/nominal/*\",\n",
    "    #     # GJet pT 20-40\n",
    "    #     lpc_fileprefix+f\"/preEE/GJetPt20To40/nominal/*\", \n",
    "    #     lpc_fileprefix+f\"/postEE/GJetPt20To40/nominal/*\",\n",
    "    #     # GJet pT 40-inf\n",
    "    #     lpc_fileprefix+f\"/preEE/GJetPt40/nominal/*\", \n",
    "    #     lpc_fileprefix+f\"/postEE/GJetPt40/nominal/*\",\n",
    "    # ],\n",
    "}\n",
    "\n",
    "CURRENT_DIRPATH = str(Path().absolute())\n",
    "VERSION = 'v8'\n",
    "MOD_VALS = (5, 5)\n",
    "# VARS = 'nonres_and_ttH_and_DNN_vars_no_diphoMass'\n",
    "# CURRENT_TIME = '2025-01-23_09-59-35'\n",
    "VARS = 'nonres_and_ttH_and_DNN_vars_no_badVars_no_badMyyVars'\n",
    "# CURRENT_TIME = '2025-01-24_23-18-02'\n",
    "if 'CURRENT_TIME' in globals():\n",
    "    OUTPUT_DIRPATH = os.path.join(CURRENT_DIRPATH, f\"MultiClassBDT_model_outputs/{VERSION}/{VARS}\", CURRENT_TIME)\n",
    "else:\n",
    "    OUTPUT_DIRPATH = os.path.join(CURRENT_DIRPATH, f\"MultiClassBDT_model_outputs/{VERSION}/{VARS}\")\n",
    "\n",
    "if not os.path.exists(OUTPUT_DIRPATH):\n",
    "    os.makedirs(OUTPUT_DIRPATH)\n",
    "\n",
    "OTHER_BKG_RESCALE = 50\n",
    "OPTIMIZE_SPACE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_weights(event_weights, labels, order=None, weighttype='rescaled_and_shifted', sig_rescale_factor=None):\n",
    "    if weighttype == 'abs':\n",
    "        return np.abs(event_weights)\n",
    "    \n",
    "    if order is not None:\n",
    "        sig_idx, big_bkg_idx = -1, -1\n",
    "        for i, sample_name in enumerate(order):\n",
    "            if re.search('ggF HH', sample_name) is not None:\n",
    "                sig_idx = i\n",
    "                continue\n",
    "            if re.search('non-res', sample_name) is not None:\n",
    "                big_bkg_idx = i\n",
    "                continue\n",
    "    else:\n",
    "        sig_idx, big_bkg_idx = 0, len(order)-1\n",
    "    \n",
    "    if sig_rescale_factor is None:\n",
    "        sig_sum = np.sum(event_weights[labels[:, sig_idx] == 1])\n",
    "        bkg_sum = np.sum(event_weights[labels[:, sig_idx] == 0])\n",
    "        \n",
    "        sig_rescale_factor = bkg_sum / sig_sum\n",
    "\n",
    "    scaled_weights = np.where(\n",
    "        labels[:, sig_idx] == 0, \n",
    "        np.where(\n",
    "            np.argmax(labels, axis=1) != big_bkg_idx,  \n",
    "            event_weights * OTHER_BKG_RESCALE,  # if not big bkg, rescale\n",
    "            event_weights  # otherwise do nothing\n",
    "        ),\n",
    "        event_weights * sig_rescale_factor  # if sig, rescale to equal sum of all bkgs\n",
    "    )\n",
    "\n",
    "    abs_weights = np.abs(scaled_weights)\n",
    "\n",
    "    if weighttype == 'rescaled':\n",
    "        return abs_weights\n",
    "    elif weighttype == 'rescaled_and_shifted':\n",
    "        mean_weights = np.mean(scaled_weights)\n",
    "        rescaled_weights = abs_weights / mean_weights\n",
    "        return rescaled_weights\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"The only options for weighttype are 'abs', 'rescaled', and 'rescaled_and_shifted'. You provided {weighttype}\"\n",
    "        )\n",
    "\n",
    "# def training_weights(event_weights, labels, order=None, sig_rescale_factor=None):\n",
    "#     if order is None:\n",
    "#         order = [i for v in range(np.shape(labels)[0])]\n",
    "#     sum_dict, max_sum, max_i = {}, 0, 0\n",
    "#     for i, sample_name in enumerate(order):\n",
    "#         sum_dict[i] = np.sum(event_weights[labels[:, i] == 1])\n",
    "#         if np.sum(event_weights[labels[:, i] == 1]) > max_sum:\n",
    "#             max_sum, max_i = np.sum(event_weights[labels[:, i] == 1]), i\n",
    "\n",
    "#     label_i = np.sum(\n",
    "#         np.tile([i for i in range(np.shape(labels)[1])], (np.shape(labels)[0], 1)) * labels,\n",
    "#         axis=1\n",
    "#     )\n",
    "\n",
    "#     weight_factors = []\n",
    "#     for i in range(len(label_i)):\n",
    "#         weight_factors.append(\n",
    "#             max_sum / sum_dict[label_i[i]] if label_i[i] != max_i else 1\n",
    "#         )\n",
    "#     weights = event_weights * np.array(weight_factors)\n",
    "\n",
    "#     mean_weight = np.mean(weights)\n",
    "#     abs_weights = np.abs(weights)\n",
    "#     scaled_weights = abs_weights / mean_weight\n",
    "\n",
    "#     return scaled_weights\n",
    "\n",
    "\n",
    "def xgb_labels(labels):\n",
    "    label_i = np.sum(\n",
    "        np.tile([i for i in range(np.shape(labels)[1])], (np.shape(labels)[0], 1)) * labels,\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    return label_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading and Input Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# order = ['ggF HH', 'ttH', 'single-H', 'non-res']\n",
    "order = ['ggF HH', 'ttH', 'VH', 'non-res + ggFH + VBFH']\n",
    "\n",
    "(\n",
    "    sig_rescale_factor,\n",
    "    data_df_dict, data_test_df_dict, \n",
    "    data_hlf_dict, label_dict,\n",
    "    data_hlf_test_dict, label_test_dict, \n",
    "    hlf_vars_columns_dict,\n",
    "    data_aux_dict, data_test_aux_dict\n",
    ") = process_data(\n",
    "    FILEPATHS_DICT, OUTPUT_DIRPATH, order=order, mod_vals=MOD_VALS,\n",
    "    save=False if 'CURRENT_TIME' in globals() else True,\n",
    "    std_json_dirpath=OUTPUT_DIRPATH if 'CURRENT_TIME' in globals() else None,\n",
    "    other_bkg_rescale=OTHER_BKG_RESCALE\n",
    ")\n",
    "\n",
    "# Make xgb-like labels (NOT one-hot encoded, but integer encoded for each class)\n",
    "xgb_label_dict = {\n",
    "    f\"fold_{fold_idx}\": copy.deepcopy(xgb_labels(label_dict[f\"fold_{fold_idx}\"])) for fold_idx in range(len(data_test_aux_dict))\n",
    "}\n",
    "xgb_label_test_dict = {\n",
    "    f\"fold_{fold_idx}\": copy.deepcopy(xgb_labels(label_test_dict[f\"fold_{fold_idx}\"])) for fold_idx in range(len(data_test_aux_dict))\n",
    "}\n",
    "\n",
    "# Make weight dicts:\n",
    "#   - the top two are with the training rescale (i.e. rescale sig eventWeight to match bkg and then shift for gradients)\n",
    "#   - the bottom two are the standard eventWeights (i.e. xs * lumi * genWeight) for proper plotting\n",
    "weight_train_dict = {\n",
    "    f\"fold_{fold_idx}\": copy.deepcopy(training_weights(data_aux_dict[f'fold_{fold_idx}'].loc[:, \"eventWeight\"].to_numpy(), label_dict[f'fold_{fold_idx}'], order=order, sig_rescale_factor=sig_rescale_factor)) for fold_idx in range(len(data_aux_dict))\n",
    "}\n",
    "weight_test_dict = {\n",
    "    f'fold_{fold_idx}': copy.deepcopy(training_weights(data_test_aux_dict[f'fold_{fold_idx}'].loc[:, \"eventWeight\"].to_numpy(), label_test_dict[f'fold_{fold_idx}'], order=order, sig_rescale_factor=sig_rescale_factor)) for fold_idx in range(len(data_test_aux_dict))\n",
    "}\n",
    "weights_plot_train_dict = {\n",
    "    f\"fold_{fold_idx}\": copy.deepcopy(data_aux_dict[f'fold_{fold_idx}'].loc[:, \"eventWeight\"].to_numpy()) for fold_idx in range(len(data_aux_dict))\n",
    "}\n",
    "weights_plot_test = {\n",
    "    f'fold_{fold_idx}': copy.deepcopy(data_test_aux_dict[f'fold_{fold_idx}'].loc[:, \"eventWeight\"].to_numpy()) for fold_idx in range(len(data_test_aux_dict))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "Num train: 1250553 -> 109202 sig & 221813 ttH bkg & 107711 single-H bkg & 811827 non-res bkg\n",
      "Num val: 312639 -> 27328 sig & 55392 ttH bkg & 26930 single-H bkg & 202989 non-res bkg\n",
      "Num test: 391785 -> 34224 sig & 69297 ttH bkg & 33713 single-H bkg & & 254551 non-res bkg\n",
      "============================================================\n",
      "fold 1\n",
      "Num train: 1251336 -> 109538 sig & 221692 ttH bkg & 107855 single-H bkg & 812251 non-res bkg\n",
      "Num val: 312835 -> 26928 sig & 55760 ttH bkg & 26850 single-H bkg & 203297 non-res bkg\n",
      "Num test: 390806 -> 34288 sig & 69050 ttH bkg & 33649 single-H bkg & & 253819 non-res bkg\n",
      "============================================================\n",
      "fold 2\n",
      "Num train: 1250948 -> 109282 sig & 221260 ttH bkg & 108006 single-H bkg & 812400 non-res bkg\n",
      "Num val: 312737 -> 27356 sig & 55367 ttH bkg & 26813 single-H bkg & 203201 non-res bkg\n",
      "Num test: 391292 -> 34116 sig & 69875 ttH bkg & 33535 single-H bkg & & 253766 non-res bkg\n",
      "============================================================\n",
      "fold 3\n",
      "Num train: 1251535 -> 109354 sig & 221822 ttH bkg & 107689 single-H bkg & 812670 non-res bkg\n",
      "Num val: 312884 -> 27317 sig & 55232 ttH bkg & 26926 single-H bkg & 203409 non-res bkg\n",
      "Num test: 390558 -> 34083 sig & 69448 ttH bkg & 33739 single-H bkg & & 253288 non-res bkg\n",
      "============================================================\n",
      "fold 4\n",
      "Num train: 1251552 -> 109336 sig & 221879 ttH bkg & 107866 single-H bkg & 812471 non-res bkg\n",
      "Num val: 312889 -> 27375 sig & 55791 ttH bkg & 26770 single-H bkg & 202953 non-res bkg\n",
      "Num test: 390536 -> 34043 sig & 68832 ttH bkg & 33718 single-H bkg & & 253943 non-res bkg\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "bdt_train_dict, bdt_val_dict, bdt_test_dict = {}, {}, {}\n",
    "\n",
    "train_data_dict, val_data_dict = {}, {}\n",
    "xgb_label_train_dict, xgb_label_val_dict = {}, {}\n",
    "weights_plot_train, weights_plot_val= {}, {}\n",
    "train_idxs_dict, val_idxs_dict = {}, {}\n",
    "for fold_idx in range(len(data_df_dict)):\n",
    "    if re.search('no_std', VARS) is not None:\n",
    "        print('no standardization')\n",
    "        train_val_data_dict = {key: value.to_numpy() for key, value in data_df_dict.items()}\n",
    "        test_data_dict = {key: value.to_numpy() for key, value in data_test_df_dict.items()}\n",
    "    else:\n",
    "        train_val_data_dict = data_hlf_dict\n",
    "        test_data_dict = data_hlf_test_dict\n",
    "    (\n",
    "        X_train, X_val, \n",
    "        y_train, y_val, \n",
    "        weight_train, weight_val, \n",
    "        weight_plot_train, weight_plot_val,\n",
    "        train_idxs, val_idxs\n",
    "    ) = train_test_split(\n",
    "        train_val_data_dict[f\"fold_{fold_idx}\"], xgb_label_dict[f\"fold_{fold_idx}\"], \n",
    "        weight_train_dict[f\"fold_{fold_idx}\"], weights_plot_train_dict[f\"fold_{fold_idx}\"],\n",
    "        range(len(train_val_data_dict[f\"fold_{fold_idx}\"])),\n",
    "        test_size=0.2, random_state=21\n",
    "    )\n",
    "\n",
    "    train_data_dict[f\"fold_{fold_idx}\"] = copy.deepcopy(X_train)\n",
    "    val_data_dict[f\"fold_{fold_idx}\"] = copy.deepcopy(X_val)\n",
    "\n",
    "    xgb_label_train_dict[f\"fold_{fold_idx}\"] = copy.deepcopy(y_train)\n",
    "    xgb_label_val_dict[f\"fold_{fold_idx}\"] = copy.deepcopy(y_val)\n",
    "\n",
    "    weights_plot_train[f\"fold_{fold_idx}\"] = copy.deepcopy(weight_plot_train)\n",
    "    weights_plot_val[f\"fold_{fold_idx}\"] = copy.deepcopy(weight_plot_val)\n",
    "\n",
    "    train_idxs_dict[f\"fold_{fold_idx}\"] = copy.deepcopy(train_idxs)\n",
    "    val_idxs_dict[f\"fold_{fold_idx}\"] = copy.deepcopy(val_idxs)\n",
    "\n",
    "    bdt_train_dict[f\"fold_{fold_idx}\"] = xgb.DMatrix(\n",
    "        data=X_train, label=y_train, \n",
    "        weight=weight_train,\n",
    "        missing=-999.0, feature_names=list(hlf_vars_columns_dict[f\"fold_{fold_idx}\"])\n",
    "    )\n",
    "    bdt_val_dict[f\"fold_{fold_idx}\"] = xgb.DMatrix(\n",
    "        data=X_val, label=y_val, \n",
    "        weight=weight_val,\n",
    "        missing=-999.0, feature_names=list(hlf_vars_columns_dict[f\"fold_{fold_idx}\"])\n",
    "    )\n",
    "    \n",
    "    bdt_test_dict[f\"fold_{fold_idx}\"] = xgb.DMatrix(\n",
    "        data=test_data_dict[f\"fold_{fold_idx}\"], label=xgb_label_test_dict[f\"fold_{fold_idx}\"], \n",
    "        weight=np.abs(weight_test_dict[f\"fold_{fold_idx}\"]),\n",
    "        missing=-999.0, feature_names=list(hlf_vars_columns_dict[f\"fold_{fold_idx}\"])\n",
    "    )\n",
    "\n",
    "    print(f\"fold {fold_idx}\")\n",
    "    print(f\"Num train: {len(y_train)} -> {sum(y_train == 0)} sig & {sum(y_train == 1)} ttH bkg & {sum(y_train == 2)} single-H bkg & {sum(y_train == 3)} non-res bkg\")\n",
    "    print(f\"Num val: {len(y_val)} -> {sum(y_val == 0)} sig & {sum(y_val == 1)} ttH bkg & {sum(y_val == 2)} single-H bkg & {sum(y_val == 3)} non-res bkg\")\n",
    "    print(f\"Num test: {len(label_test_dict[f'fold_{fold_idx}'])} -> {sum(label_test_dict[f'fold_{fold_idx}'] == np.array([1, 0, 0, 0]))[0]} sig & {sum(label_test_dict[f'fold_{fold_idx}'] == np.array([0, 1, 0, 0]))[1]} ttH bkg & {sum(label_test_dict[f'fold_{fold_idx}'] == np.array([0, 0, 1, 0]))[2]} single-H bkg & & {sum(label_test_dict[f'fold_{fold_idx}'] == np.array([0, 0, 0, 1]))[3]} non-res bkg\")\n",
    "    print('='*60)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Parameterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/57986259/multiclass-classification-with-xgboost-classifier\n",
    "# https://forecastegy.com/posts/xgboost-multiclass-classification-python/\n",
    "# https://indico.cern.ch/event/915265/contributions/3848138/attachments/2048174/3432202/kunlinRan_bbyy_20200531.pdf\n",
    "\n",
    "# https://xgboost.readthedocs.io/en/stable/tutorials/intercept.html - for looking at logits level BDT output\n",
    "# https://indico.cern.ch/event/915265/contributions/3848138/attachments/2048174/3432202/kunlinRan_bbyy_20200531.pdf - ATLAS HHbbgg BDT\n",
    "\n",
    "\n",
    "param = {}\n",
    "\n",
    "# Booster parameters\n",
    "param['eta']              = 0.05 # learning rate\n",
    "num_trees = round(25 / param['eta'])  # number of trees to make\n",
    "# param['max_depth']        = 8  # maximum depth of a tree\n",
    "# param['subsample']        = 1 # fraction of events to train tree on\n",
    "# param['colsample_bytree'] = 0.33 # fraction of features to train tree on\n",
    "param['max_depth']        = 10  # maximum depth of a tree\n",
    "param['subsample']        = 0.6 # fraction of events to train tree on\n",
    "param['colsample_bytree'] = 0.6 # fraction of features to train tree on\n",
    "param['num_class']        = len(order) # num classes for multi-class training\n",
    "\n",
    "# Learning task parameters\n",
    "param['objective']   = 'multi:softprob'   # objective function\n",
    "param['eval_metric'] = 'merror'           # evaluation metric for cross validation\n",
    "param = list(param.items()) + [('eval_metric', 'mlogloss')]\n",
    "# param[\"disable_default_eval_metric\"] = True\n",
    "# param = list(param.items())\n",
    "\n",
    "\n",
    "def thresholded_weighted_merror(predt: np.ndarray, dtrain: xgb.DMatrix, threshold=0.95):\n",
    "    \"\"\"Used when there's no custom objective.\"\"\"\n",
    "    # No need to do transform, XGBoost handles it internally.\n",
    "    weights = dtrain.get_weight()\n",
    "    thresh_weight_merror = np.where(\n",
    "        np.logical_and(\n",
    "            np.max(predt, axis=1) >= threshold,\n",
    "            np.argmax(predt, axis=1) == dtrain.get_label()\n",
    "        ),\n",
    "        0,\n",
    "        weights\n",
    "    )\n",
    "    return f'WeightedMError@{threshold:.2f}', np.sum(thresh_weight_merror)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_hyperparams(\n",
    "    dtrain_dict: dict, dval_dict: dict, dtest_dict: dict, param, verbose: bool=False, verbose_eval=False\n",
    "):  \n",
    "    rng = np.random.default_rng()\n",
    "\n",
    "    space  = [\n",
    "        Real(1e-3, 0.1, \"log-uniform\", name='eta'),\n",
    "        Integer(1, 20, \"uniform\", name='max_depth'),\n",
    "        Real(1e-3, 1., \"log-uniform\", name='subsample'),\n",
    "        Real(0.1, 1., \"uniform\", name='colsample_bytree'),\n",
    "        # Real(1e-4, 1., \"log-uniform\", name='alpha'),\n",
    "        # Real(1e-4, 1., \"log-uniform\", name='lambda'),\n",
    "    ]\n",
    "\n",
    "    score_arrs = []\n",
    "\n",
    "    @use_named_args(space)\n",
    "    def objective(**X):\n",
    "        if verbose:\n",
    "            print(\"New configuration: {}\".format(X))\n",
    "\n",
    "        for key, val in X.items():\n",
    "            param[key] = val\n",
    "        num_trees = round(25 / X['eta'])\n",
    "\n",
    "        # randomly sample a fold to evaluate\n",
    "        fold_idx = rng.integers(0, 4)\n",
    "\n",
    "        evallist = [(dtrain_dict[f\"fold_{fold_idx}\"], 'train'), (dtest_dict[f\"fold_{fold_idx}\"], 'test'), (dval_dict[f\"fold_{fold_idx}\"], 'val')]\n",
    "        booster = xgb.train(\n",
    "            param, dtrain_dict[f\"fold_{fold_idx}\"], num_boost_round=num_trees, \n",
    "            evals=evallist, early_stopping_rounds=10, verbose_eval=verbose_eval,\n",
    "        )\n",
    "\n",
    "        eval_str = booster.eval(dval_dict[f\"fold_{fold_idx}\"], name='val', iteration=booster.best_iteration)\n",
    "\n",
    "        best_mlogloss = float(eval_str[eval_str.find('val-mlogloss:')+len('val-mlogloss:'):])\n",
    "        score_arrs.append(best_mlogloss)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Best val. mlogloss on fold{fold_idx} = {best_mlogloss}\")\n",
    "\n",
    "        return -best_mlogloss\n",
    "    \n",
    "    res_gp = gp_minimize(objective, space)\n",
    "    print(\"Best parameters: {}\".format(res_gp.x))\n",
    "\n",
    "    param['eta'] = float(res_gp.x[0])\n",
    "    param['max_depth'] = int(res_gp.x[1])\n",
    "    param['subsample'] = float(res_gp.x[2])\n",
    "    param['colsample_bytree'] = float(res_gp.x[3])\n",
    "    # param['alpha'] = float(res_gp.x[4])\n",
    "    # param['lambda'] = float(res_gp.x[5])\n",
    "    return param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.11608\ttrain-mlogloss:1.31215\ttest-merror:0.12912\ttest-mlogloss:1.31323\tval-merror:0.13353\tval-mlogloss:1.31363\n",
      "[25]\ttrain-merror:0.05354\ttrain-mlogloss:0.46024\ttest-merror:0.06626\ttest-mlogloss:0.47893\tval-merror:0.06916\tval-mlogloss:0.48321\n",
      "[50]\ttrain-merror:0.04843\ttrain-mlogloss:0.24507\ttest-merror:0.06268\ttest-mlogloss:0.27330\tval-merror:0.06548\tval-mlogloss:0.27874\n",
      "[75]\ttrain-merror:0.04534\ttrain-mlogloss:0.17714\ttest-merror:0.06171\ttest-mlogloss:0.21403\tval-merror:0.06469\tval-mlogloss:0.22021\n",
      "[100]\ttrain-merror:0.04253\ttrain-mlogloss:0.14952\ttest-merror:0.06114\ttest-mlogloss:0.19457\tval-merror:0.06400\tval-mlogloss:0.20118\n",
      "[125]\ttrain-merror:0.03966\ttrain-mlogloss:0.13479\ttest-merror:0.06117\ttest-mlogloss:0.18715\tval-merror:0.06364\tval-mlogloss:0.19401\n",
      "[150]\ttrain-merror:0.03711\ttrain-mlogloss:0.12519\ttest-merror:0.06102\ttest-mlogloss:0.18395\tval-merror:0.06369\tval-mlogloss:0.19097\n",
      "[175]\ttrain-merror:0.03451\ttrain-mlogloss:0.11747\ttest-merror:0.06108\ttest-mlogloss:0.18250\tval-merror:0.06367\tval-mlogloss:0.18967\n",
      "[200]\ttrain-merror:0.03224\ttrain-mlogloss:0.11163\ttest-merror:0.06073\ttest-mlogloss:0.18199\tval-merror:0.06337\tval-mlogloss:0.18918\n",
      "[225]\ttrain-merror:0.03017\ttrain-mlogloss:0.10655\ttest-merror:0.06056\ttest-mlogloss:0.18176\tval-merror:0.06374\tval-mlogloss:0.18907\n",
      "[236]\ttrain-merror:0.02918\ttrain-mlogloss:0.10456\ttest-merror:0.06065\ttest-mlogloss:0.18181\tval-merror:0.06373\tval-mlogloss:0.18911\n",
      "[226]\ttest-merror:0.060652\ttest-mlogloss:0.181807\n",
      "====================================================================================================\n",
      "fold 1\n",
      "[0]\ttrain-merror:0.07099\ttrain-mlogloss:1.30687\ttest-merror:0.08295\ttest-mlogloss:1.30773\tval-merror:0.08144\tval-mlogloss:1.30781\n",
      "[25]\ttrain-merror:0.05192\ttrain-mlogloss:0.44966\ttest-merror:0.06624\ttest-mlogloss:0.47065\tval-merror:0.06487\tval-mlogloss:0.46925\n",
      "[50]\ttrain-merror:0.04839\ttrain-mlogloss:0.24565\ttest-merror:0.06482\ttest-mlogloss:0.27769\tval-merror:0.06335\tval-mlogloss:0.27595\n",
      "[75]\ttrain-merror:0.04517\ttrain-mlogloss:0.17736\ttest-merror:0.06324\ttest-mlogloss:0.21859\tval-merror:0.06219\tval-mlogloss:0.21662\n",
      "[100]\ttrain-merror:0.04233\ttrain-mlogloss:0.14915\ttest-merror:0.06218\ttest-mlogloss:0.19872\tval-merror:0.06123\tval-mlogloss:0.19658\n",
      "[125]\ttrain-merror:0.03938\ttrain-mlogloss:0.13454\ttest-merror:0.06200\ttest-mlogloss:0.19146\tval-merror:0.06098\tval-mlogloss:0.18924\n",
      "[150]\ttrain-merror:0.03666\ttrain-mlogloss:0.12490\ttest-merror:0.06183\ttest-mlogloss:0.18827\tval-merror:0.06101\tval-mlogloss:0.18624\n",
      "[175]\ttrain-merror:0.03425\ttrain-mlogloss:0.11749\ttest-merror:0.06154\ttest-mlogloss:0.18679\tval-merror:0.06124\tval-mlogloss:0.18479\n",
      "[200]\ttrain-merror:0.03215\ttrain-mlogloss:0.11190\ttest-merror:0.06139\ttest-mlogloss:0.18617\tval-merror:0.06136\tval-mlogloss:0.18412\n",
      "[225]\ttrain-merror:0.03009\ttrain-mlogloss:0.10679\ttest-merror:0.06194\ttest-mlogloss:0.18597\tval-merror:0.06117\tval-mlogloss:0.18390\n",
      "[239]\ttrain-merror:0.02899\ttrain-mlogloss:0.10424\ttest-merror:0.06207\ttest-mlogloss:0.18602\tval-merror:0.06123\tval-mlogloss:0.18385\n",
      "[230]\ttest-merror:0.062076\ttest-mlogloss:0.186009\n",
      "====================================================================================================\n",
      "fold 2\n",
      "[0]\ttrain-merror:0.06882\ttrain-mlogloss:1.30673\ttest-merror:0.08110\ttest-mlogloss:1.30799\tval-merror:0.07957\tval-mlogloss:1.30776\n",
      "[25]\ttrain-merror:0.05186\ttrain-mlogloss:0.44598\ttest-merror:0.06575\ttest-mlogloss:0.46792\tval-merror:0.06463\tval-mlogloss:0.46687\n",
      "[50]\ttrain-merror:0.04842\ttrain-mlogloss:0.24130\ttest-merror:0.06424\ttest-mlogloss:0.27472\tval-merror:0.06287\tval-mlogloss:0.27297\n",
      "[75]\ttrain-merror:0.04501\ttrain-mlogloss:0.17450\ttest-merror:0.06336\ttest-mlogloss:0.21801\tval-merror:0.06199\tval-mlogloss:0.21600\n",
      "[100]\ttrain-merror:0.04225\ttrain-mlogloss:0.14755\ttest-merror:0.06271\ttest-mlogloss:0.19954\tval-merror:0.06148\tval-mlogloss:0.19760\n",
      "[125]\ttrain-merror:0.03931\ttrain-mlogloss:0.13303\ttest-merror:0.06218\ttest-mlogloss:0.19272\tval-merror:0.06120\tval-mlogloss:0.19078\n",
      "[150]\ttrain-merror:0.03648\ttrain-mlogloss:0.12343\ttest-merror:0.06232\ttest-mlogloss:0.18985\tval-merror:0.06121\tval-mlogloss:0.18792\n",
      "[175]\ttrain-merror:0.03399\ttrain-mlogloss:0.11608\ttest-merror:0.06227\ttest-mlogloss:0.18858\tval-merror:0.06161\tval-mlogloss:0.18660\n",
      "[200]\ttrain-merror:0.03183\ttrain-mlogloss:0.11040\ttest-merror:0.06249\ttest-mlogloss:0.18808\tval-merror:0.06155\tval-mlogloss:0.18613\n",
      "[225]\ttrain-merror:0.02967\ttrain-mlogloss:0.10553\ttest-merror:0.06305\ttest-mlogloss:0.18789\tval-merror:0.06180\tval-mlogloss:0.18573\n",
      "[235]\ttrain-merror:0.02892\ttrain-mlogloss:0.10377\ttest-merror:0.06311\ttest-mlogloss:0.18805\tval-merror:0.06185\tval-mlogloss:0.18576\n",
      "[225]\ttest-merror:0.063110\ttest-mlogloss:0.188054\n",
      "====================================================================================================\n",
      "fold 3\n",
      "[0]\ttrain-merror:0.07243\ttrain-mlogloss:1.30802\ttest-merror:0.08520\ttest-mlogloss:1.30923\tval-merror:0.08450\tval-mlogloss:1.30913\n",
      "[25]\ttrain-merror:0.05330\ttrain-mlogloss:0.45449\ttest-merror:0.06571\ttest-mlogloss:0.47366\tval-merror:0.06494\tval-mlogloss:0.47306\n",
      "[50]\ttrain-merror:0.04865\ttrain-mlogloss:0.24147\ttest-merror:0.06326\ttest-mlogloss:0.27101\tval-merror:0.06166\tval-mlogloss:0.26973\n",
      "[75]\ttrain-merror:0.04562\ttrain-mlogloss:0.17520\ttest-merror:0.06244\ttest-mlogloss:0.21427\tval-merror:0.06048\tval-mlogloss:0.21255\n",
      "[100]\ttrain-merror:0.04255\ttrain-mlogloss:0.14853\ttest-merror:0.06225\ttest-mlogloss:0.19609\tval-merror:0.05996\tval-mlogloss:0.19398\n",
      "[125]\ttrain-merror:0.03972\ttrain-mlogloss:0.13434\ttest-merror:0.06164\ttest-mlogloss:0.18935\tval-merror:0.05949\tval-mlogloss:0.18699\n",
      "[150]\ttrain-merror:0.03700\ttrain-mlogloss:0.12465\ttest-merror:0.06168\ttest-mlogloss:0.18648\tval-merror:0.05992\tval-mlogloss:0.18405\n",
      "[175]\ttrain-merror:0.03457\ttrain-mlogloss:0.11764\ttest-merror:0.06175\ttest-mlogloss:0.18511\tval-merror:0.05979\tval-mlogloss:0.18257\n",
      "[200]\ttrain-merror:0.03238\ttrain-mlogloss:0.11217\ttest-merror:0.06172\ttest-mlogloss:0.18447\tval-merror:0.05996\tval-mlogloss:0.18195\n",
      "[225]\ttrain-merror:0.03021\ttrain-mlogloss:0.10711\ttest-merror:0.06161\ttest-mlogloss:0.18426\tval-merror:0.06007\tval-mlogloss:0.18173\n",
      "[244]\ttrain-merror:0.02862\ttrain-mlogloss:0.10363\ttest-merror:0.06166\ttest-mlogloss:0.18430\tval-merror:0.06012\tval-mlogloss:0.18177\n",
      "[234]\ttest-merror:0.061657\ttest-mlogloss:0.184299\n",
      "====================================================================================================\n",
      "fold 4\n",
      "[0]\ttrain-merror:0.11156\ttrain-mlogloss:1.31144\ttest-merror:0.12750\ttest-mlogloss:1.31267\tval-merror:0.12735\tval-mlogloss:1.31287\n",
      "[25]\ttrain-merror:0.05703\ttrain-mlogloss:0.46733\ttest-merror:0.07211\ttest-mlogloss:0.48807\tval-merror:0.07153\tval-mlogloss:0.48799\n",
      "[50]\ttrain-merror:0.04965\ttrain-mlogloss:0.25277\ttest-merror:0.06551\ttest-mlogloss:0.28345\tval-merror:0.06536\tval-mlogloss:0.28344\n",
      "[75]\ttrain-merror:0.04525\ttrain-mlogloss:0.18041\ttest-merror:0.06291\ttest-mlogloss:0.21973\tval-merror:0.06278\tval-mlogloss:0.21954\n",
      "[100]\ttrain-merror:0.04218\ttrain-mlogloss:0.15082\ttest-merror:0.06181\ttest-mlogloss:0.19827\tval-merror:0.06212\tval-mlogloss:0.19802\n",
      "[125]\ttrain-merror:0.03957\ttrain-mlogloss:0.13572\ttest-merror:0.06191\ttest-mlogloss:0.19054\tval-merror:0.06190\tval-mlogloss:0.19036\n",
      "[150]\ttrain-merror:0.03687\ttrain-mlogloss:0.12584\ttest-merror:0.06172\ttest-mlogloss:0.18734\tval-merror:0.06178\tval-mlogloss:0.18713\n",
      "[175]\ttrain-merror:0.03461\ttrain-mlogloss:0.11860\ttest-merror:0.06148\ttest-mlogloss:0.18596\tval-merror:0.06148\tval-mlogloss:0.18580\n",
      "[200]\ttrain-merror:0.03255\ttrain-mlogloss:0.11286\ttest-merror:0.06157\ttest-mlogloss:0.18545\tval-merror:0.06157\tval-mlogloss:0.18521\n",
      "[225]\ttrain-merror:0.03043\ttrain-mlogloss:0.10759\ttest-merror:0.06174\ttest-mlogloss:0.18512\tval-merror:0.06159\tval-mlogloss:0.18485\n",
      "[250]\ttrain-merror:0.02847\ttrain-mlogloss:0.10302\ttest-merror:0.06200\ttest-mlogloss:0.18508\tval-merror:0.06153\tval-mlogloss:0.18465\n",
      "[260]\ttrain-merror:0.02774\ttrain-mlogloss:0.10127\ttest-merror:0.06199\ttest-mlogloss:0.18516\tval-merror:0.06169\tval-mlogloss:0.18475\n",
      "[250]\ttest-merror:0.061994\ttest-mlogloss:0.185165\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "if 'CURRENT_TIME' in globals():\n",
    "    OUTPUT_DIRPATH, OLD_TIME = os.path.split(OUTPUT_DIRPATH)\n",
    "CURRENT_TIME = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "OUTPUT_DIRPATH = os.path.join(OUTPUT_DIRPATH, CURRENT_TIME)\n",
    "if not os.path.exists(OUTPUT_DIRPATH):\n",
    "    os.makedirs(OUTPUT_DIRPATH)\n",
    "\n",
    "if OPTIMIZE_SPACE:\n",
    "\n",
    "    print('OPTIMIZING SPACE')\n",
    "\n",
    "    param_dict = {}\n",
    "    for name, value in param:\n",
    "        if value == 'merror':\n",
    "            continue\n",
    "        param_dict[name] = value\n",
    "        \n",
    "    param = optimize_hyperparams(bdt_train_dict, bdt_val_dict, bdt_test_dict, param_dict, verbose=True, verbose_eval=50)\n",
    "\n",
    "    with open(os.path.join(OUTPUT_DIRPATH, f'{CURRENT_TIME}_best_params.json'), 'w') as f:\n",
    "        json.dump(param, f)\n",
    "        print(param)\n",
    "\n",
    "    param['eval_metric'] = 'merror'\n",
    "    param = list(param.items()) + [('eval_metric', 'mlogloss')]\n",
    "\n",
    "evals_result_dict = {f\"fold_{fold_idx}\": dict() for fold_idx in range(len(bdt_train_dict))}\n",
    "for fold_idx in range(len(bdt_train_dict)):\n",
    "    print(f\"fold {fold_idx}\")\n",
    "    # Train bdt\n",
    "    evallist = [(bdt_train_dict[f\"fold_{fold_idx}\"], 'train'), (bdt_test_dict[f\"fold_{fold_idx}\"], 'test'), (bdt_val_dict[f\"fold_{fold_idx}\"], 'val')]\n",
    "    booster = xgb.train(\n",
    "        param, bdt_train_dict[f\"fold_{fold_idx}\"], num_boost_round=num_trees, \n",
    "        evals=evallist, early_stopping_rounds=10, verbose_eval=25, evals_result=evals_result_dict[f\"fold_{fold_idx}\"],\n",
    "        # custom_metric=thresholded_weighted_merror\n",
    "    )\n",
    "\n",
    "    booster.save_model(os.path.join(OUTPUT_DIRPATH, f'{CURRENT_TIME}_BDT_fold{fold_idx}.model'))\n",
    "    \n",
    "    # Print perf on test dataset\n",
    "    print(booster.eval(bdt_test_dict[f\"fold_{fold_idx}\"], name='test', iteration=booster.best_iteration))\n",
    "    print('='*100)\n",
    "\n",
    "with open(os.path.join(OUTPUT_DIRPATH, f'{CURRENT_TIME}_BDT_eval_result.json'), 'w') as f:\n",
    "    json.dump(evals_result_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance (ROC) Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_tpr = np.linspace(0, 1, 5000)  # copied from IN evaluate.py file\n",
    "roc_baseline = np.zeros(\n",
    "    (len(bdt_train_dict), len(base_tpr), len(order)), \n",
    "    dtype=float\n",
    ")\n",
    "area_baseline = np.zeros(\n",
    "    (len(bdt_train_dict), len(order)), \n",
    "    dtype=float\n",
    ")\n",
    "\n",
    "BDT_perf = {\n",
    "    sample_name: copy.deepcopy({\n",
    "        'base_tpr': base_tpr,\n",
    "        'class_order': copy.deepcopy(order),\n",
    "        # test data #\n",
    "        'preds': [],\n",
    "        'fprs_density': copy.deepcopy(roc_baseline), 'thresholds_density': copy.deepcopy(roc_baseline), 'areas_density': copy.deepcopy(area_baseline),\n",
    "        'fprs_weighted': copy.deepcopy(roc_baseline), 'thresholds_weighted': copy.deepcopy(roc_baseline), 'areas_weighted': copy.deepcopy(area_baseline),\n",
    "        'fprs_sum_density': copy.deepcopy(roc_baseline[0, ...]), 'thresholds_sum_density': copy.deepcopy(roc_baseline[0, ...]), 'areas_sum_density': copy.deepcopy(area_baseline[0, ...]),\n",
    "        'fprs_sum_weighted': copy.deepcopy(roc_baseline[0, ...]), 'thresholds_sum_weighted': copy.deepcopy(roc_baseline[0, ...]), 'areas_sum_weighted': copy.deepcopy(area_baseline[0, ...]),\n",
    "        # train data #\n",
    "        'train_preds': [], \n",
    "        'train_fprs_density': copy.deepcopy(roc_baseline), 'train_thresholds_density': copy.deepcopy(roc_baseline), 'train_areas_density': copy.deepcopy(area_baseline),\n",
    "        'train_fprs_weighted': copy.deepcopy(roc_baseline), 'train_thresholds_weighted': copy.deepcopy(roc_baseline), 'train_areas_weighted': copy.deepcopy(area_baseline),\n",
    "        'train_fprs_sum_density': copy.deepcopy(roc_baseline[0, ...]), 'train_thresholds_sum_density': copy.deepcopy(roc_baseline[0, ...]), 'train_areas_sum_density': copy.deepcopy(area_baseline[0, ...]),\n",
    "        'train_fprs_sum_weighted': copy.deepcopy(roc_baseline[0, ...]), 'train_thresholds_sum_weighted': copy.deepcopy(roc_baseline[0, ...]), 'train_areas_sum_weighted': copy.deepcopy(area_baseline[0, ...]),\n",
    "        # val data #\n",
    "        'val_preds': [],\n",
    "        'val_fprs_density': copy.deepcopy(roc_baseline), 'val_thresholds_density': copy.deepcopy(roc_baseline), 'val_areas_density': copy.deepcopy(area_baseline),\n",
    "        'val_fprs_weighted': copy.deepcopy(roc_baseline), 'val_thresholds_weighted': copy.deepcopy(roc_baseline), 'val_areas_weighted': copy.deepcopy(area_baseline),\n",
    "        'val_fprs_sum_density': copy.deepcopy(roc_baseline[0, ...]), 'val_thresholds_sum_density': copy.deepcopy(roc_baseline[0, ...]), 'val_areas_sum_density': copy.deepcopy(area_baseline[0, ...]),\n",
    "        'val_fprs_sum_weighted': copy.deepcopy(roc_baseline[0, ...]), 'val_thresholds_sum_weighted': copy.deepcopy(roc_baseline[0, ...]), 'val_areas_sum_weighted': copy.deepcopy(area_baseline[0, ...]),\n",
    "    }) for sample_name in order\n",
    "}\n",
    "\n",
    "for j, sample_name in enumerate(order):\n",
    "\n",
    "    for fold_idx in range(len(bdt_train_dict)):\n",
    "        booster = xgb.Booster(param)\n",
    "\n",
    "        try:\n",
    "            booster.load_model(os.path.join(OUTPUT_DIRPATH, f'{CURRENT_TIME}_BDT_fold{fold_idx}.model'))\n",
    "        except:\n",
    "            raise FileNotFoundError(f\"No model file at fold {fold_idx}.\")\n",
    "    \n",
    "        for pred_type, dataset in [\n",
    "            ('train_', bdt_train_dict[f\"fold_{fold_idx}\"]),\n",
    "            ('val_', bdt_val_dict[f\"fold_{fold_idx}\"]),\n",
    "            ('', bdt_test_dict[f\"fold_{fold_idx}\"])\n",
    "        ]:\n",
    "            \n",
    "            BDT_perf[sample_name][pred_type + 'preds'].append(\n",
    "                booster.predict(\n",
    "                    dataset, \n",
    "                    iteration_range=(0, booster.best_iteration+1)\n",
    "                ).tolist()\n",
    "            )\n",
    "\n",
    "            for i, sample_name_ in enumerate(order):\n",
    "                \n",
    "                if sample_name_ == sample_name:\n",
    "                    event_mask = dataset.get_label() > -1\n",
    "                    pred_rescale = np.ones_like(event_mask)\n",
    "                else:\n",
    "                    event_mask = np.logical_or(dataset.get_label() == j, dataset.get_label() == i)\n",
    "                    pred_rescale = np.array(BDT_perf[sample_name][pred_type + 'preds'][-1])[:, j][event_mask] + np.array(BDT_perf[sample_name][pred_type + 'preds'][-1])[:, i][event_mask]\n",
    "                class_preds = np.array(BDT_perf[sample_name][pred_type + 'preds'][-1])[:, j][event_mask] / pred_rescale\n",
    "                class_truths = np.where(dataset.get_label() == j, 1, 0)[event_mask]\n",
    "                \n",
    "                for roc_type in ['density', 'weighted']:\n",
    "\n",
    "                    if roc_type == 'weighted':\n",
    "                        if re.search('train', pred_type) is not None:\n",
    "                            roc_weights = weights_plot_train[f\"fold_{fold_idx}\"][event_mask]\n",
    "                        elif re.search('val', pred_type) is not None:\n",
    "                            roc_weights = weights_plot_val[f\"fold_{fold_idx}\"][event_mask]\n",
    "                        else:\n",
    "                            roc_weights = weights_plot_test[f\"fold_{fold_idx}\"][event_mask]\n",
    "                    else:\n",
    "                        roc_weights = None\n",
    "\n",
    "                    fpr_bdt, tpr_bdt, threshold_bdt = roc_curve(class_truths, class_preds, sample_weight=roc_weights)\n",
    "                    fpr_bdt = np.interp(base_tpr, tpr_bdt, fpr_bdt)\n",
    "                    threshold_bdt = np.interp(base_tpr, tpr_bdt, threshold_bdt)\n",
    "\n",
    "                    BDT_perf[sample_name][pred_type + 'fprs_' + roc_type][fold_idx][:, i] = fpr_bdt\n",
    "                    BDT_perf[sample_name][pred_type + 'thresholds_' + roc_type][fold_idx][:, i] = threshold_bdt\n",
    "                    BDT_perf[sample_name][pred_type + 'areas_' + roc_type][fold_idx][i] = float(trapezoid(base_tpr, fpr_bdt))\n",
    "    \n",
    "    for pred_type, dataset_dict in [\n",
    "        ('train_', bdt_train_dict),\n",
    "        ('val_', bdt_val_dict),\n",
    "        ('', bdt_test_dict)\n",
    "    ]:\n",
    "\n",
    "        flat_preds = np.concatenate(BDT_perf[sample_name][f'{pred_type}preds'], axis=0)\n",
    "        flat_truths = np.concatenate([dataset_dict[f\"fold_{fold_idx}\"].get_label() for fold_idx in range(len(dataset_dict))], axis=0)\n",
    "\n",
    "        for i, sample_name_ in enumerate(order):\n",
    "            \n",
    "            if sample_name_ == sample_name:\n",
    "                event_mask = flat_truths > -1\n",
    "                pred_rescale = np.ones_like(event_mask)\n",
    "            else:\n",
    "                event_mask = np.logical_or(flat_truths == j, flat_truths == i)\n",
    "                pred_rescale = flat_preds[:, j][event_mask] + flat_preds[:, i][event_mask]\n",
    "            class_preds = flat_preds[:, j][event_mask] / pred_rescale\n",
    "            class_truths = np.where(flat_truths == j, 1, 0)[event_mask]\n",
    "            \n",
    "            for roc_type in ['density', 'weighted']:\n",
    "\n",
    "                if roc_type == 'weighted':\n",
    "                    if re.search('train', pred_type) is not None:\n",
    "                        roc_weights = np.concatenate([weights_plot_train[f\"fold_{fold_idx}\"] for fold_idx in range(len(weights_plot_train))], axis=0)[event_mask]\n",
    "                    elif re.search('val', pred_type) is not None:\n",
    "                        roc_weights = np.concatenate([weights_plot_val[f\"fold_{fold_idx}\"] for fold_idx in range(len(weights_plot_val))], axis=0)[event_mask]\n",
    "                    else:\n",
    "                        roc_weights = np.concatenate([weights_plot_test[f\"fold_{fold_idx}\"] for fold_idx in range(len(weights_plot_test))], axis=0)[event_mask]\n",
    "                else:\n",
    "                    roc_weights = None\n",
    "\n",
    "                fpr_bdt, tpr_bdt, threshold_bdt = roc_curve(class_truths, class_preds, sample_weight=roc_weights)\n",
    "                fpr_bdt = np.interp(base_tpr, tpr_bdt, fpr_bdt)\n",
    "                threshold_bdt = np.interp(base_tpr, tpr_bdt, threshold_bdt)\n",
    "\n",
    "                BDT_perf[sample_name][pred_type + 'fprs_sum_' + roc_type][:, i] = fpr_bdt\n",
    "                BDT_perf[sample_name][pred_type + 'thresholds_sum_' + roc_type][:, i] = threshold_bdt\n",
    "                BDT_perf[sample_name][pred_type + 'areas_sum_' + roc_type][i] = float(trapezoid(base_tpr, fpr_bdt))\n",
    "    \n",
    "    for key in BDT_perf[sample_name].keys():\n",
    "        if type(BDT_perf[sample_name][key]) is list:\n",
    "            continue\n",
    "        BDT_perf[sample_name][key] = BDT_perf[sample_name][key].tolist()\n",
    "\n",
    "\n",
    "with open(os.path.join(OUTPUT_DIRPATH, CURRENT_TIME+f\"_BDT_perf.json\"), 'w') as f:\n",
    "    json.dump(BDT_perf, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_list(list_of_lists):\n",
    "    max_length = np.max([len(list_i) for list_i in list_of_lists])\n",
    "    for list_i in list_of_lists:\n",
    "        while len(list_i) < max_length:\n",
    "            list_i.append(list_i[-1])\n",
    "\n",
    "    return list_of_lists\n",
    "\n",
    "def plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix, format='png'):\n",
    "    plot_prefix = plot_prefix + ('_' if plot_prefix != '' else '')\n",
    "    plot_postfix = plot_postfix + ('_' if plot_postfix != '' else '')\n",
    "    plot_name = plot_prefix + plot_name + plot_postfix + f'.{format}'\n",
    "\n",
    "    plot_filepath = os.path.join(plot_dirpath, plot_name)\n",
    "    return plot_filepath\n",
    "\n",
    "def plot_train_val_losses(\n",
    "    losses_arrs, labels, plot_name, plot_dirpath, \n",
    "    plot_prefix='', plot_postfix='', linestyles=None,\n",
    "    losses_std_arrs=None\n",
    "):\n",
    "    plt.figure(figsize=(9,7))\n",
    "    \n",
    "    if type(losses_arrs[0]) is float:\n",
    "        losses_arrs = [losses_arrs]\n",
    "    if linestyles is None:\n",
    "        linestyles = ['solid'] * len(losses_arrs)\n",
    "    if labels is None:\n",
    "        labels = [i for i in range(len(losses_arrs))]\n",
    "\n",
    "    if losses_std_arrs is not None:\n",
    "        for i in range(len(losses_std_arrs)):\n",
    "            plt.fill_between(\n",
    "                range(len(losses_std_arrs[i])), \n",
    "                losses_arrs[i]+losses_std_arrs[i], losses_arrs[i]-losses_std_arrs[i],\n",
    "                alpha=0.7\n",
    "            )\n",
    "\n",
    "    for i in range(len(losses_arrs)):\n",
    "        plt.plot(\n",
    "            range(len(losses_arrs[i])), \n",
    "            losses_arrs[i], \n",
    "            label=f\"{labels[i]} losses\", linestyle=linestyles[i],\n",
    "            alpha=0.7\n",
    "        )\n",
    "        \n",
    "    plt.legend(bbox_to_anchor=(1, 1))\n",
    "    plt.xlabel('EPOCH')\n",
    "    plt.ylabel('Data Loss')\n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix, format='pdf'), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.close()\n",
    "\n",
    "def plot_rocs(\n",
    "    fprs, tprs, labels, plot_name, plot_dirpath,\n",
    "    plot_prefix='', plot_postfix='', close=True, log=None\n",
    "):\n",
    "    plt.figure(figsize=(9,7))\n",
    "    \n",
    "    for fpr, tpr, label in zip(fprs, tprs, labels):\n",
    "        linestyle = 'solid' if re.search('IN', label) is not None else ('dashed' if re.search('BDT', label) is not None else 'dotted')\n",
    "        plt.plot(fpr, tpr, label=label, linestyle=linestyle)\n",
    "\n",
    "    plt.legend(bbox_to_anchor=(1, 1))\n",
    "    plt.xlabel('Background contamination')\n",
    "    plt.ylabel('Signal efficiency')\n",
    "    if log is not None and re.search('x', log) is not None:\n",
    "        plt.xscale('log')\n",
    "    elif log is not None and re.search('y', log) is not None:\n",
    "        plt.yscale('log')\n",
    "    \n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix, format='pdf'), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    if close:\n",
    "        plt.close()\n",
    "\n",
    "def plot_output_scores(\n",
    "    sigs_and_bkgs, order, plot_name, plot_dirpath,\n",
    "    plot_prefix='', plot_postfix='', bins=1000, weights=None, log=False, arctanh=False\n",
    "):\n",
    "    plt.figure(figsize=(9,7))\n",
    "\n",
    "    if arctanh:\n",
    "        end_point = 6.\n",
    "    else:\n",
    "        end_point = 1.\n",
    "    hist_axis = hist.axis.Regular(bins, 0., end_point, name='var', growth=False, underflow=False, overflow=False)\n",
    "    hists, labels = [], []\n",
    "    for sample_name in order:\n",
    "        if sample_name not in sigs_and_bkgs:\n",
    "            continue\n",
    "        hists.append(\n",
    "            hist.Hist(hist_axis, storage='weight').fill(\n",
    "                var=sigs_and_bkgs[sample_name], \n",
    "                weight=weights[sample_name] if weights is not None else np.ones_like(sigs_and_bkgs[sample_name])\n",
    "            )\n",
    "        )\n",
    "        labels.append(sample_name)\n",
    "    hep.histplot(\n",
    "        hists,\n",
    "        yerr=(True if weights is not None else False),\n",
    "        alpha=0.2, density=(False if weights is not None else True), histtype='step',\n",
    "        label=labels\n",
    "    )\n",
    "\n",
    "    plt.legend(bbox_to_anchor=(1, 1))\n",
    "    plt.xlabel('Output score')\n",
    "    if log:\n",
    "        plt.yscale('log')\n",
    "    \n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix, format='pdf'), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.close()\n",
    "\n",
    "def plot_s_over_root_b(\n",
    "    sig, bkg, label, plot_name, plot_dirpath,\n",
    "    plot_prefix='', plot_postfix='', bins=1000, weights={'sig': None, 'bkg': None},\n",
    "    lines=None, lines_labels=None, line_colors=None, arctanh=False\n",
    "):\n",
    "    plt.figure(figsize=(9,7))\n",
    "\n",
    "    if arctanh:\n",
    "        end_point = 6.\n",
    "        hist_axis = hist.axis.Regular(bins, 0., end_point, name='var', growth=False, underflow=False, overflow=False)\n",
    "    else:\n",
    "        end_point = 1.\n",
    "        hist_axis = hist.axis.Regular(bins, 0., end_point, name='var', growth=False, underflow=False, overflow=False)\n",
    "    sig_hist = hist.Hist(hist_axis, storage='weight').fill(var=sig, weight=weights['sig'] if weights['sig'] is not None else np.ones_like(sig))\n",
    "    bkg_hist = hist.Hist(hist_axis, storage='weight').fill(var=bkg, weight=weights['bkg'] if weights['bkg'] is not None else np.ones_like(bkg))\n",
    "    s_over_root_b_points = sig_hist.values().flatten() / np.sqrt(bkg_hist.values().flatten())\n",
    "    plt.plot(\n",
    "        np.arange(0., end_point, end_point*(1/bins)), s_over_root_b_points, \n",
    "        label=f'{label} - s/âb', alpha=0.8\n",
    "    )\n",
    "\n",
    "    if lines is not None:\n",
    "        for i in range(len(lines)):\n",
    "            plt.vlines(\n",
    "                lines[i], 0, np.max(s_over_root_b_points), \n",
    "                label='s/âb'+(' - '+lines_labels[i] if lines_labels is not None else ''), \n",
    "                alpha=0.5, colors=line_colors[i]\n",
    "            )\n",
    "    \n",
    "    plt.legend(bbox_to_anchor=(1, 1))\n",
    "    plt.xlabel('Output score')\n",
    "    plt.ylabel('s/âb')\n",
    "    \n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix, format='pdf'), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.close()\n",
    "\n",
    "def plot_confusion_matrix(\n",
    "    conf_matrix, class_labels, plot_name, plot_dirpath, \n",
    "    plot_prefix='', plot_postfix=''\n",
    "):\n",
    "    plt.figure(figsize=(9,7))\n",
    "\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=class_labels)\n",
    "    disp.plot(im_kw={'norm': 'log'})\n",
    "    \n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix, format='pdf'), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.close()\n",
    "\n",
    "def plot_feature_importance(\n",
    "    feature_scores, feature_labels, plot_name, plot_dirpath, \n",
    "    plot_prefix='', plot_postfix='', fscore_method='total_gain', log=True\n",
    "):\n",
    "    plt.figure(figsize=(18,14))\n",
    "\n",
    "    plt.barh(\n",
    "        np.arange(len(feature_scores)), feature_scores, align='center'\n",
    "    )\n",
    "    plt.yticks(np.arange(len(feature_scores)), feature_labels, fontsize=8)\n",
    "    plt.ylabel('Features')\n",
    "    plt.xlabel(f'F score ({fscore_method})')\n",
    "    if log:\n",
    "        plt.xscale('log')\n",
    "    \n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix, format='pdf'), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_cut_boundaries(sigs, bkgs, weights, bins=10000, arctanh=False):\n",
    "    hist_list_fold = []\n",
    "    cut_boundaries_fold = []\n",
    "    cut_s_over_root_bs_fold = []\n",
    "    sig_weights_fold = []\n",
    "    bkg_weights_fold = []\n",
    "    if len(np.shape(sigs)) == 1:\n",
    "        sigs, bkgs = [sigs], [bkgs] \n",
    "    if arctanh:\n",
    "        end_point = 6.\n",
    "    else:\n",
    "        end_point = 1.\n",
    "    for sig, bkg in zip(sigs, bkgs):\n",
    "        hist_axis = hist.axis.Regular(bins, 0., end_point, name='var', growth=False, underflow=False, overflow=False)\n",
    "        sig_hist = hist.Hist(hist_axis, storage='weight').fill(var=sig, weight=weights['sig'])\n",
    "        bkg_hist = hist.Hist(hist_axis, storage='weight').fill(var=bkg, weight=weights['bkg'])\n",
    "        hist_list_fold.append({'sig': copy.deepcopy(sig_hist), 'bkg': copy.deepcopy(bkg_hist)})\n",
    "\n",
    "        fold_idx_cuts_bins_inclusive = []\n",
    "        fold_idx_sig_weights = []\n",
    "        fold_idx_bkg_weights = []\n",
    "        fold_idx_prev_s_over_root_b = []\n",
    "        prev_s_over_root_b = 0\n",
    "        for i in range(bins):\n",
    "            s = np.sum(sig_hist.values().flatten()[\n",
    "                (bins-1) - i : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "            ])\n",
    "            sqrt_b = np.sqrt(np.sum(bkg_hist.values().flatten()[\n",
    "                (bins-1) - i : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "            ]))\n",
    "            if prev_s_over_root_b < (s / sqrt_b) or s < 0.25:\n",
    "                prev_s_over_root_b = s / sqrt_b\n",
    "                continue\n",
    "            else:\n",
    "                fold_idx_sig_weights.append(\n",
    "                    {\n",
    "                        'value': np.sum(sig_hist.values().flatten()[\n",
    "                            (bins) - i : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                        ]),\n",
    "                        'w2': np.sqrt(np.sum(sig_hist.variances().flatten()[\n",
    "                            (bins) - i : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                        ])),\n",
    "                    }\n",
    "                )\n",
    "                fold_idx_bkg_weights.append(\n",
    "                    {\n",
    "                        'value': np.sum(bkg_hist.values().flatten()[\n",
    "                            (bins) - i : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                        ]),\n",
    "                        'w2': np.sqrt(np.sum(bkg_hist.variances().flatten()[\n",
    "                            (bins) - i : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                        ])),\n",
    "                    }\n",
    "                )\n",
    "                fold_idx_cuts_bins_inclusive.append(bins - i)\n",
    "                fold_idx_prev_s_over_root_b.append(prev_s_over_root_b)\n",
    "                prev_s_over_root_b = 0\n",
    "        fold_idx_sig_weights.append(\n",
    "            {\n",
    "                'value': np.sum(sig_hist.values().flatten()[\n",
    "                    0 : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                ]),\n",
    "                'w2': np.sqrt(np.sum(sig_hist.variances().flatten()[\n",
    "                    0 : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                ])),\n",
    "            }\n",
    "        )\n",
    "        fold_idx_bkg_weights.append(\n",
    "            {\n",
    "                'value': np.sum(bkg_hist.values().flatten()[\n",
    "                    0 : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                ]),\n",
    "                'w2': np.sqrt(np.sum(bkg_hist.variances().flatten()[\n",
    "                    0 : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                ])),\n",
    "            }\n",
    "        )\n",
    "        fold_idx_cuts_bins_inclusive.append(0)\n",
    "        fold_idx_prev_s_over_root_b.append(prev_s_over_root_b)\n",
    "        fold_idx_score_cuts = [end_point * (bin_i / bins) for bin_i in fold_idx_cuts_bins_inclusive]\n",
    "        cut_boundaries_fold.append(fold_idx_score_cuts)\n",
    "        cut_s_over_root_bs_fold.append(fold_idx_prev_s_over_root_b)\n",
    "        sig_weights_fold.append(fold_idx_sig_weights)\n",
    "        bkg_weights_fold.append(fold_idx_bkg_weights)\n",
    "    return cut_boundaries_fold, cut_s_over_root_bs_fold, sig_weights_fold, bkg_weights_fold\n",
    "\n",
    "def p_to_xyz(p, split=True):  # makes a tetrahedron with height 1 and vertices {(0, 0, 0),  (â3/2, 0, â3/2),  (0, â3/2, â3/2),  (â3/2, â3/2, 0)}\n",
    "    rt3o2 = np.sqrt(3) / 2\n",
    "\n",
    "    x = rt3o2 * (0*p[:, 0] + p[:, 1] + p[:, 2] + 0*p[:, 3])\n",
    "    y = rt3o2 * (0*p[:, 0] + 0*p[:, 1] + p[:, 2] + p[:, 3])\n",
    "    z = rt3o2 * (0*p[:, 0] + p[:, 1] + 0*p[:, 2] + p[:, 3])\n",
    "\n",
    "    if split:\n",
    "        return x, y, z\n",
    "    else:\n",
    "        return np.column_stack((x, y, z))\n",
    "\n",
    "def optimize_cuts(\n",
    "    preds: np.ndarray, binary_labels: np.ndarray, weights: np.ndarray,\n",
    "    init_guess=[1e-9, 2e-3, 1e-2], param_names=['r1', 'r2', 'r3'], param_range=[(1e-11, 1e-4), (1e-3, 5e-2), (0., 1.)], \n",
    "    n_steps=int(5e2), verbose: bool=False, min_sig: float=0.2, prefactor: float=1e3, rng_seed: int=21\n",
    "):\n",
    "    xyz_preds = p_to_xyz(preds, split=False)\n",
    "\n",
    "    space  = [Real(float(param_range[i][0]), float(param_range[i][1]), (\"log-uniform\" if param_name == 'r4' else \"uniform\"), name=param_name) for i, param_name in enumerate(param_names)]\n",
    "\n",
    "    def space_transform(X):\n",
    "        triangle_vertices = X['r1']**(1/3) * np.array([\n",
    "            [np.sqrt(3)/2,         0,            np.sqrt(3)/2], \n",
    "            [0,                np.sqrt(3)/2,     np.sqrt(3)/2], \n",
    "            [np.sqrt(3)/2,     np.sqrt(3)/2,                0]\n",
    "        ])\n",
    "\n",
    "        sampled_point = (\n",
    "            (1 - np.sqrt((1 - X['r2']))) * triangle_vertices[0, :]\n",
    "        ) + (\n",
    "            np.sqrt((1 - X['r2']))*(1 - X['r3']) * triangle_vertices[1, :]\n",
    "        ) + (\n",
    "            np.sqrt((1 - X['r2']))*X['r3'] * triangle_vertices[2, :]\n",
    "        )\n",
    "\n",
    "        if verbose:\n",
    "            print(sampled_point)\n",
    "\n",
    "        return sampled_point\n",
    "\n",
    "    @use_named_args(space)\n",
    "    def objective(**X):\n",
    "        if verbose:\n",
    "            print(\"New configuration: {}\".format(X))\n",
    "\n",
    "        thresholds = space_transform(X)\n",
    "        sample_mask = np.all(xyz_preds < thresholds, axis=1)\n",
    "\n",
    "        # print(f\"total sig = {np.sum(weights[binary_labels == 1])}\")\n",
    "        # print(f\"total bkg = {np.sum(weights[binary_labels == 0])}\")\n",
    "\n",
    "        num_sig = np.abs(\n",
    "            np.sum(\n",
    "                weights[\n",
    "                    np.logical_and(\n",
    "                        binary_labels == 1,\n",
    "                        sample_mask\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "\n",
    "        num_bkg = np.abs(\n",
    "            np.sum(\n",
    "                weights[\n",
    "                    np.logical_and(\n",
    "                        binary_labels == 0,\n",
    "                        sample_mask\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "\n",
    "        s_over_root_b = num_sig / np.sqrt(num_bkg)\n",
    "\n",
    "        if num_sig == 0 and num_bkg == 0:\n",
    "            both_0 = prefactor*1e1\n",
    "            if verbose:\n",
    "                print(f\"both sig and bkg 0 at this hyperplane => {both_0}\")\n",
    "            return both_0\n",
    "        elif num_sig < min_sig:\n",
    "            small_sig = prefactor*0\n",
    "            if verbose:\n",
    "                print(f\"too little sig ({num_sig}) at this hyperplane => {small_sig}\")\n",
    "            return small_sig\n",
    "        elif num_bkg == 0:\n",
    "            zero_bkg = -prefactor*num_sig\n",
    "            if verbose:\n",
    "                print(f\"zero bkg at this hyperplane (likely due to finite data rather than real bkg-free zone) => {zero_bkg}\")\n",
    "            return zero_bkg\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"s/âb = {s_over_root_b}, s = {num_sig}, b = {num_bkg}\")\n",
    "\n",
    "        return -prefactor*s_over_root_b\n",
    "    \n",
    "    res_gp = gp_minimize(\n",
    "        objective, space, random_state=rng_seed, \n",
    "        n_calls=(n_steps + (1 if len(np.shape(init_guess)) == 1 else np.shape(init_guess)[0])), \n",
    "        n_initial_points=n_steps, x0=init_guess\n",
    "    )\n",
    "\n",
    "    opt_params = [float(res_gp.x[i]) for i in range(len(space))]\n",
    "    opt_cuts = [float(opt_cut) for opt_cut in space_transform({param_names[i]: res_gp.x[i] for i in range(len(param_names))})]\n",
    "    if verbose:\n",
    "        print(\"Best parameters: {}\".format(opt_cuts))\n",
    "        print(f\"Best s/âb = {-res_gp.fun / prefactor}\")\n",
    "\n",
    "    return opt_cuts, opt_params\n",
    "\n",
    "\n",
    "def multi_optimize_cut_boundaries(preds: list, binary_labels: np.ndarray, weights: np.ndarray, num_categories: int=3, min_sig: float=0.2):\n",
    "    init_param_range = [(1e-8, 1e-7), (1e-6, 1e-5), (1e-2, 1e-1)]\n",
    "    init_guess = [5e-8, 5e-6, 5e-2]\n",
    "    clf_dict = {}\n",
    "    param_clf_dict = {}\n",
    "    for cat in range(num_categories):\n",
    "\n",
    "        clf_dict[cat] = []\n",
    "        param_clf_dict[cat] = []\n",
    "\n",
    "        if cat == 0:\n",
    "            sliced_preds = np.array(preds)\n",
    "            sliced_labels = binary_labels\n",
    "            sliced_weights = weights\n",
    "            param_range = init_param_range\n",
    "            guess = init_guess\n",
    "\n",
    "        else:\n",
    "            slice_array = np.ones_like(binary_labels, dtype=bool)\n",
    "            for prev_cat in range(cat):\n",
    "                slice_array = np.logical_and(\n",
    "                    slice_array,\n",
    "                    np.logical_not(\n",
    "                        np.all(\n",
    "                            p_to_xyz(np.array(preds), split=False) < clf_dict[prev_cat], \n",
    "                            axis=1\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            sliced_preds = np.array(preds)[slice_array]\n",
    "            sliced_labels = binary_labels[slice_array]\n",
    "            sliced_weights = weights[slice_array]\n",
    "            # param_range = [(param_clf_dict[cat-1][0], init_param_range[0][1]), (param_clf_dict[cat-1][1], init_param_range[1][1]), init_param_range[2]]\n",
    "            # guess = [param_clf_dict[cat-1][0] + 1e-11, param_clf_dict[cat-1][1] + 1e-11, 0.5 * init_param_range[2][1]]\n",
    "            param_range = init_param_range\n",
    "            guess = init_guess\n",
    "            \n",
    "        opt_cuts, opt_params = optimize_cuts(\n",
    "            sliced_preds, sliced_labels, sliced_weights, verbose=False,\n",
    "            param_range=param_range, init_guess=guess, n_steps=200, min_sig=min_sig, rng_seed=None\n",
    "        )\n",
    "\n",
    "        clf_dict[cat] = opt_cuts\n",
    "        param_clf_dict[cat] = opt_params\n",
    "\n",
    "    return clf_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "MC_NAMES_PRETTY = {\n",
    "    \"GGJets\": r\"$\\gamma\\gamma+3j$\",\n",
    "    \"GJetPt20To40\": r\"$\\gamma+j$, 20<$p_T$<40GeV\",\n",
    "    \"GJetPt40\": r\"$\\gamma+j$, 40GeV<$p_T$\",\n",
    "    \"GluGluHToGG\": r\"ggF $H\\rightarrow \\gamma\\gamma$\",\n",
    "    \"VBFHToGG\": r\"VBF $H\\rightarrow \\gamma\\gamma$\",\n",
    "    \"VHToGG\": r\"V$H\\rightarrow\\gamma\\gamma$\",\n",
    "    \"ttHToGG\": r\"$t\\bar{t}H\\rightarrow\\gamma\\gamma$\",\n",
    "    \"GluGluToHH\": r\"ggF $HH\\rightarrow bb\\gamma\\gamma$\",\n",
    "    # \"VBFHHto2B2G_CV_1_C2V_1_C3_1\": r\"VBF $HH\\rightarrow bb\\gamma\\gamma$\",\n",
    "    \"signal\": r\"ggF $HH\\rightarrow bb\\gamma\\gamma$ + VBF $HH\\rightarrow bb\\gamma\\gamma$\",\n",
    "    # Names for order #\n",
    "    \"ggF HH\": r\"ggF $H\\rightarrow \\gamma\\gamma$\",\n",
    "    \"ttH\": r\"$t\\bar{t}H\\rightarrow\\gamma\\gamma$\",\n",
    "    \"single-H\": r\"ggF $H\\rightarrow \\gamma\\gamma$ + VBF $H\\rightarrow \\gamma\\gamma$ + V$H\\rightarrow\\gamma\\gamma$\",\n",
    "    \"non-res\": r\"$\\gamma\\gamma+3j$ + $\\gamma+j$, 20GeV<$p_T$\",\n",
    "    \"VH\": r\"V$H\\rightarrow\\gamma\\gamma$\",\n",
    "    \"non-res + ggFH + VBFH\": r\"$\\gamma\\gamma+3j$ + $\\gamma+j$, 20GeV<$p_T$ + ggF $H\\rightarrow \\gamma\\gamma$ + VBF $H\\rightarrow \\gamma\\gamma$\"\n",
    "    # Need to fill in pretty print for BSM samples #\n",
    "}\n",
    "LUMINOSITIES = {\n",
    "    '2022preEE': 7.9804, \n",
    "    '2022postEE': 26.6717,\n",
    "    # Need to fill in lumis for other eras #\n",
    "}\n",
    "LUMINOSITIES['total_lumi'] = sum(LUMINOSITIES.values())\n",
    "\n",
    "# Dictionary of variables\n",
    "VARIABLES = {\n",
    "    # key: hist.axis axes for plotting #\n",
    "    # MET variables\n",
    "    'puppiMET_sumEt': hist.axis.Regular(40, 150., 2000, name='var', label=r'puppiMET $\\Sigma E_T$ [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'puppiMET_pt': hist.axis.Regular(40, 20., 250, name='var', label=r'puppiMET $p_T$ [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'puppiMET_phi': hist.axis.Regular(20,-3.2, 3.2, name='var', label=r'puppiMET $\\phi$', growth=False, underflow=False, overflow=False), \n",
    "    # jet-MET variables\n",
    "    'DeltaPhi_j1MET': hist.axis.Regular(20,-3.2, 3.2, name='var', label=r'$\\Delta\\phi (j_1,E_T^{miss})$', growth=False, underflow=False, overflow=False), \n",
    "    'DeltaPhi_j2MET': hist.axis.Regular(20, -3.2, 3.2, name='var', label=r'$\\Delta\\phi (j_2,E_T^{miss})$', growth=False, underflow=False, overflow=False), \n",
    "    # jet-photon variables\n",
    "    'DeltaR_jg_min': hist.axis.Regular(30, 0, 5, name='var', label=r'min$(\\Delta R(jet, \\gamma))$', growth=False, underflow=False, overflow=False), \n",
    "    # jet variables\n",
    "    # 'jet1_pt': hist.axis.Regular(40, 20., 250, name='var', label=r'lead jet $p_T$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    # 'jet2_pt': hist.axis.Regular(40, 20., 250, name='var', label=r'sublead jet $p_T$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    'lead_bjet_pt': hist.axis.Regular(40, 20., 250, name='var', label=r'lead bjet $p_T$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    'lead_bjet_eta': hist.axis.Regular(20, -5., 5., name='var', label=r'lead bjet $\\eta$', growth=False, underflow=False, overflow=False),\n",
    "    'lead_bjet_phi': hist.axis.Regular(20, -3.2, 3.2, name='var', label=r'lead bjet $\\phi$', growth=False, underflow=False, overflow=False),\n",
    "    'sublead_bjet_pt': hist.axis.Regular(40, 20., 250, name='var', label=r'lead bjet $p_T$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    'sublead_bjet_eta': hist.axis.Regular(20, -5., 5., name='var', label=r'lead bjet $\\eta$', growth=False, underflow=False, overflow=False),\n",
    "    'sublead_bjet_phi': hist.axis.Regular(20, -3.2, 3.2, name='var', label=r'lead bjet $\\phi$', growth=False, underflow=False, overflow=False),\n",
    "    'n_jets': hist.axis.Integer(0, 10, name='var', label=r'$n_{jets}$', growth=False, underflow=False, overflow=False), \n",
    "    'chi_t0': hist.axis.Regular(40, 0., 150, name='var', label=r'$\\chi_{t0}^2$', growth=False, underflow=False, overflow=False), \n",
    "    'chi_t1': hist.axis.Regular(30, 0., 500, name='var', label=r'$\\chi_{t1}^2$', growth=False, underflow=False, overflow=False), \n",
    "    # lepton variables\n",
    "    'n_leptons': hist.axis.Integer(0, 10, name='var', label=r'$n_{leptons}$', growth=False, underflow=False, overflow=False),\n",
    "    'lepton1_pt': hist.axis.Regular(40, 0., 200., name='var', label=r'lead lepton $p_T$ [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'lepton2_pt': hist.axis.Regular(40, 0., 200., name='var', label=r'sublead lepton $p_T$ [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'lepton1_eta': hist.axis.Regular(30, -5., 5., name='var', label=r'lead lepton $\\eta$', growth=False, underflow=False, overflow=False), \n",
    "    'lepton2_eta': hist.axis.Regular(30, -5., 5., name='var', label=r'sublead lepton $\\eta$', growth=False, underflow=False, overflow=False),\n",
    "    'lepton1_phi': hist.axis.Regular(20, -3.2, 3.2, name='var', label=r'lead lepton $\\phi$', growth=False, underflow=False, overflow=False), \n",
    "    'lepton2_phi': hist.axis.Regular(20, -3.2, 3.2, name='var', label=r'sublead lepton $\\phi$', growth=False, underflow=False, overflow=False),\n",
    "    # diphoton variables\n",
    "    'pt': hist.axis.Regular(40, 20., 2000, name='var', label=r' $\\gamma\\gamma p_{T}$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    'eta': hist.axis.Regular(20, -5., 5., name='var', label=r'$\\gamma\\gamma \\eta$', growth=False, underflow=False, overflow=False), \n",
    "    'phi': hist.axis.Regular(20, -3.2, 3.2, name='var', label=r'$\\gamma \\gamma \\phi$', growth=False, underflow=False, overflow=False),\n",
    "    # angular (cos) variables\n",
    "    'abs_CosThetaStar_CS': hist.axis.Regular(20, 0, 1, name='var', label=r'|cos$(\\theta_{CS})$|', growth=False, underflow=False, overflow=False), \n",
    "    'abs_CosThetaStar_jj': hist.axis.Regular(20, 0, 1, name='var', label=r'|cos$(\\theta_{jj})$|', growth=False, underflow=False, overflow=False),\n",
    "    'CosThetaStar_CS': hist.axis.Regular(20, -1, 1, name='var', label=r'cos$(\\theta_{CS})$', growth=False, underflow=False, overflow=False), \n",
    "    'CosThetaStar_jj': hist.axis.Regular(20, -1, 1, name='var', label=r'cos$(\\theta_{jj})$', growth=False, underflow=False, overflow=False), \n",
    "    # jet-lepton variables\n",
    "    'leadBjet_leadLepton': hist.axis.Regular(30, 0, 5, name='var', label=r'$\\Delta R(bjet_{lead}, l_{lead})$', growth=False, underflow=False, overflow=False), \n",
    "    'leadBjet_subleadLepton': hist.axis.Regular(30, 0, 5, name='var', label=r'$\\Delta R(bjet_{lead}, l_{sublead})$', growth=False, underflow=False, overflow=False), \n",
    "    'subleadBjet_leadLepton': hist.axis.Regular(30, 0, 5, name='var', label=r'$\\Delta R(bjet_{sublead}, l_{lead})$', growth=False, underflow=False, overflow=False), \n",
    "    'subleadBjet_subleadLepton': hist.axis.Regular(30, 0, 5, name='var', label=r'$\\Delta R(bjet_{sublead}, l_{sublead})$', growth=False, underflow=False, overflow=False),\n",
    "    # dijet variables (must be blinded on data)\n",
    "    'dijet_mass': hist.axis.Regular(25, 25., 180., name='var', label=r'$M_{jj}$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    # diphoton variables (must be blinded on data)\n",
    "    'mass': hist.axis.Regular(25, 25., 180., name='var', label=r'$M_{\\gamma\\gamma}$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    # Yibo's BDT variables\n",
    "    'lead_mvaID': hist.axis.Regular(50, -1., 1., name='var', label=r'$\\gamma_{lead}$ MVA ID', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_mvaID': hist.axis.Regular(50, -1., 1., name='var', label=r'$\\gamma_{sublead}$ MVA ID', growth=False, underflow=False, overflow=False),\n",
    "    'CosThetaStar_gg': hist.axis.Regular(50, -1., 1., name='var', label=r'cos$(\\theta_{gg})$', growth=False, underflow=False, overflow=False),\n",
    "    'lead_pt_over_Mgg': hist.axis.Regular(50, 0., 1., name='var', label=r'$p_{T,\\gamma_1} / M_{\\gamma\\gamma}$', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_pt_over_Mgg': hist.axis.Regular(50, 0., 1., name='var', label=r'$p_{T,\\gamma_2} / M_{\\gamma\\gamma}$', growth=False, underflow=False, overflow=False),\n",
    "    'lead_sigmaE_over_E': hist.axis.Regular(50, 0., 1., name='var', label=r'$\\sigma {E,\\gamma_1} / E_{\\gamma\\gamma}$', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_sigmaE_over_E': hist.axis.Regular(50, 0., 1., name='var', label=r'$\\sigma {E,\\gamma_2} / E_{\\gamma\\gamma}$', growth=False, underflow=False, overflow=False),\n",
    "    'lead_bjet_pt_over_Mjj': hist.axis.Regular(50, 0., 1., name='var', label=r'$p_{T,j1} / M_{jj}$', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_bjet_pt_over_Mjj': hist.axis.Regular(50, 0., 1., name='var', label=r'$p_{T,j2} / M_{jj}$', growth=False, underflow=False, overflow=False),\n",
    "    'lead_bjet_btagPNetB': hist.axis.Regular(50, -1., 1., name='var', label=r'$j_{lead}$ PNet btag score', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_bjet_btagPNetB': hist.axis.Regular(50, -1., 1., name='var', label=r'$j_{sublead}$ PNet btag score', growth=False, underflow=False, overflow=False),\n",
    "    'lead_bjet_sigmapT_over_pT': hist.axis.Regular(50, 0., 1., name='var', label=r'$\\sigma p_{T,j1} / p_{T,jj}$', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_bjet_sigmapT_over_pT': hist.axis.Regular(50, 0., 1., name='var', label=r'$\\sigma p_{T,j2} / p_{T,jj}$', growth=False, underflow=False, overflow=False),\n",
    "    'dipho_mass_over_Mggjj': hist.axis.Regular(50, 0., 1., name='var', label=r'$M_{\\gamma\\gamma} / M_{\\gamma\\gamma jj}$', growth=False, underflow=False, overflow=False), \n",
    "    'dijet_mass_over_Mggjj': hist.axis.Regular(50, 0., 1., name='var', label=r'$M_{jj} / M_{\\gamma\\gamma jj}$', growth=False, underflow=False, overflow=False),\n",
    "    # My variables for non-reso reduction #\n",
    "    'lead_pfRelIso03_all_quadratic': hist.axis.Regular(50, -1., 1., name='var', label=r'$\\gamma_{lead}$ PF RelIso03 all quad.', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_pfRelIso03_all_quadratic': hist.axis.Regular(50, -1., 1., name='var', label=r'$\\gamma_{sublead}$ PF RelIso03 all quad.', growth=False, underflow=False, overflow=False),\n",
    "    # Michael's DNN variables #\n",
    "    'DeltaR_j1g1': hist.axis.Regular(50, 0., 5., name='var', label=r'$\\Delta R(bjet_{lead}, \\gamma_{lead})$', growth=False, underflow=False, overflow=False), \n",
    "    'DeltaR_j1g2': hist.axis.Regular(50, 0., 5., name='var', label=r'$\\Delta R(bjet_{lead}, \\gamma_{sublead})$', growth=False, underflow=False, overflow=False), \n",
    "    'DeltaR_j2g1': hist.axis.Regular(50, 0., 5., name='var', label=r'$\\Delta R(bjet_{sublead}, \\gamma_{lead})$', growth=False, underflow=False, overflow=False), \n",
    "    'DeltaR_j2g2': hist.axis.Regular(50, 0., 5., name='var', label=r'$\\Delta R(bjet_{sublead}, \\gamma_{sublead})$', growth=False, underflow=False, overflow=False),\n",
    "    'HHbbggCandidate_pt': hist.axis.Regular(100, 0., 700., name='var', label=r'HH $p_T$ [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'HHbbggCandidate_eta': hist.axis.Regular(50, -5., 5., name='var', label=r'HH $\\eta$', growth=False, underflow=False, overflow=False), \n",
    "    'HHbbggCandidate_phi': hist.axis.Regular(50, -3.2, 3.2, name='var', label=r'HH $\\phi$', growth=False, underflow=False, overflow=False),\n",
    "    'HHbbggCandidate_mass': hist.axis.Regular(25, 0., 700., name='var', label=r'$M_{HH}$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    # ATLAS variables #\n",
    "    'pt_balance': hist.axis.Regular(100, 0., 2., name='var', label=r'$p_{T,HH} / (p_{T,\\gamma1} + p_{T,\\gamma2} + p_{T,j1} + p_{T,j2})$', growth=False, underflow=False, overflow=False), \n",
    "    # VH variables #\n",
    "    'DeltaPhi_jj': hist.axis.Regular(20, -3.2, 3.2, name='var', label=r'$\\Delta\\phi (j_1,j_2)$', growth=False, underflow=False, overflow=False),\n",
    "    'DeltaEta_jj': hist.axis.Regular(20, 0., 10., name='var', label=r'$\\Delta\\eta (j_1,j_2)$', growth=False, underflow=False, overflow=False),\n",
    "    'isr_jet_pt': hist.axis.Regular(100, 0., 200., name='var', label=r'ISR jet $p_T$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    'DeltaPhi_isr_jet_z': hist.axis.Regular(20, -3.2, 3.2, name='var', label=r'$\\Delta\\phi (j_{ISR},jj)$', growth=False, underflow=False, overflow=False),\n",
    "    'dijet_pt': hist.axis.Regular(100, 0., 500., name='var', label=r'jj $p_T$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "}\n",
    "# Dictionary of variables to do MC/Data comparison\n",
    "VARIABLES_STD = {\n",
    "    # key: hist.axis axes for plotting #\n",
    "    # MET variables\n",
    "    'puppiMET_sumEt': hist.axis.Regular(40, -4., 4., name='var', label=r'puppiMET ln($\\Sigma E_T$) [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'puppiMET_pt': hist.axis.Regular(40, -4., 4., name='var', label=r'puppiMET ln($p_T$) [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'puppiMET_phi': hist.axis.Regular(40, -4., 4., name='var', label=r'puppiMET $\\phi$', growth=False, underflow=False, overflow=False), \n",
    "    # jet-MET variables\n",
    "    'DeltaPhi_j1MET': hist.axis.Regular(40, -4., 4., name='var', label=r'$\\Delta\\phi (j_1,E_T^{miss})$', growth=False, underflow=False, overflow=False), \n",
    "    'DeltaPhi_j2MET': hist.axis.Regular(40, -4., 4., name='var', label=r'$\\Delta\\phi (j_2,E_T^{miss})$', growth=False, underflow=False, overflow=False), \n",
    "    # jet-photon variables\n",
    "    'DeltaR_jg_min': hist.axis.Regular(40, -4., 4., name='var', label=r'min$(\\Delta R(jet, \\gamma))$', growth=False, underflow=False, overflow=False), \n",
    "    # jet variables\n",
    "    'lead_bjet_pt': hist.axis.Regular(40, -4., 4., name='var', label=r'lead bjet ln($p_T$) [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_bjet_pt': hist.axis.Regular(40, -4., 4., name='var', label=r'sublead bjet ln($p_T$) [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'lead_bjet_eta': hist.axis.Regular(40, -4., 4., name='var', label=r'lead bjet $\\eta$', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_bjet_eta': hist.axis.Regular(40, -4., 4., name='var', label=r'sublead bjet $\\eta$', growth=False, underflow=False, overflow=False),\n",
    "    'lead_bjet_phi': hist.axis.Regular(40, -4., 4., name='var', label=r'lead bjet $\\phi$', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_bjet_phi': hist.axis.Regular(40, -4., 4., name='var', label=r'sublead bjet $\\phi$', growth=False, underflow=False, overflow=False),\n",
    "    'n_jets': hist.axis.Regular(12, -4., 4., name='var', label=r'$n_{jets}$', growth=False, underflow=False, overflow=False), \n",
    "    'chi_t0': hist.axis.Regular(40, -4., 10., name='var', label=r'ln($\\chi_{t0}^2$)', growth=False, underflow=False, overflow=False), \n",
    "    'chi_t1': hist.axis.Regular(40, -4., 10., name='var', label=r'ln($\\chi_{t1}^2$)', growth=False, underflow=False, overflow=False), \n",
    "    # lepton variables\n",
    "    'n_leptons': hist.axis.Regular(12, -4., 4., name='var', label=r'$n_{leptons}$', growth=False, underflow=False, overflow=False),\n",
    "    'lepton1_pt': hist.axis.Regular(40, -4., 4., name='var', label=r'lead lepton ln($p_T$) [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'lepton2_pt': hist.axis.Regular(40, -4., 4., name='var', label=r'sublead lepton ln($p_T$) [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'lepton1_eta': hist.axis.Regular(40, -4., 4., name='var', label=r'lead lepton $\\eta$', growth=False, underflow=False, overflow=False), \n",
    "    'lepton2_eta': hist.axis.Regular(40, -4., 4., name='var', label=r'sublead lepton $\\eta$', growth=False, underflow=False, overflow=False),\n",
    "    'lepton1_phi': hist.axis.Regular(40, -4., 4., name='var', label=r'lead lepton $\\phi$', growth=False, underflow=False, overflow=False), \n",
    "    'lepton2_phi': hist.axis.Regular(40, -4., 4., name='var', label=r'sublead lepton $\\phi$', growth=False, underflow=False, overflow=False),\n",
    "    # diphoton variables\n",
    "    'pt': hist.axis.Regular(40, -4., 4., name='var', label=r' $\\gamma\\gamma$ ln($p_{T}$) [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    'eta': hist.axis.Regular(40, -4., 4., name='var', label=r'$\\gamma\\gamma \\eta$', growth=False, underflow=False, overflow=False), \n",
    "    'phi': hist.axis.Regular(40, -4., 4., name='var', label=r'$\\gamma \\gamma \\phi$', growth=False, underflow=False, overflow=False),\n",
    "    # angular (cos) variables\n",
    "    'abs_CosThetaStar_CS': hist.axis.Regular(40, -4., 4., name='var', label=r'|cos$(\\theta_{CS})$|', growth=False, underflow=False, overflow=False), \n",
    "    'abs_CosThetaStar_jj': hist.axis.Regular(40, -4., 4., name='var', label=r'|cos$(\\theta_{jj})$|', growth=False, underflow=False, overflow=False), \n",
    "    'CosThetaStar_CS': hist.axis.Regular(40, -1., 1., name='var', label=r'cos$(\\theta_{CS})$', growth=False, underflow=False, overflow=False), \n",
    "    'CosThetaStar_jj': hist.axis.Regular(40, -1., 1., name='var', label=r'cos$(\\theta_{jj})$', growth=False, underflow=False, overflow=False), \n",
    "    # jet-lepton variables\n",
    "    'leadBjet_leadLepton': hist.axis.Regular(40, -4., 4., name='var', label=r'$\\Delta R(bjet_{lead}, l_{lead})$', growth=False, underflow=False, overflow=False), \n",
    "    'leadBjet_subleadLepton': hist.axis.Regular(40, -4., 4., name='var', label=r'$\\Delta R(bjet_{lead}, l_{sublead})$', growth=False, underflow=False, overflow=False), \n",
    "    'subleadBjet_leadLepton': hist.axis.Regular(40, -4., 4., name='var', label=r'$\\Delta R(bjet_{sublead}, l_{lead})$', growth=False, underflow=False, overflow=False), \n",
    "    'subleadBjet_subleadLepton': hist.axis.Regular(40, -4., 4., name='var', label=r'$\\Delta R(bjet_{sublead}, l_{sublead})$', growth=False, underflow=False, overflow=False),\n",
    "    # dijet variables (must be blinded on data)\n",
    "    'dijet_mass': hist.axis.Regular(40, -4., 4., name='var', label=r'ln($M_{jj}$) [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    # diphoton variables (must be blinded on data)\n",
    "    'mass': hist.axis.Regular(40, -4., 4., name='var', label=r'$M_{\\gamma\\gamma}$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    # Yibo's BDT variables\n",
    "    'lead_mvaID': hist.axis.Regular(50, -4., 4., name='var', label=r'$\\gamma_{lead}$ MVA ID', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_mvaID': hist.axis.Regular(50, -4., 4., name='var', label=r'$\\gamma_{sublead}$ MVA ID', growth=False, underflow=False, overflow=False),\n",
    "    'CosThetaStar_gg': hist.axis.Regular(50, -1., 1., name='var', label=r'cos$(\\theta_{gg})$', growth=False, underflow=False, overflow=False),\n",
    "    'lead_pt_over_Mgg': hist.axis.Regular(50, -4., 4., name='var', label=r'$p_{T,\\gamma_1} / M_{\\gamma\\gamma}$', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_pt_over_Mgg': hist.axis.Regular(50, -4., 4., name='var', label=r'$p_{T,\\gamma_2} / M_{\\gamma\\gamma}$', growth=False, underflow=False, overflow=False),\n",
    "    'lead_sigmaE_over_E': hist.axis.Regular(50, -4., 4., name='var', label=r'$\\sigma {E,\\gamma_1} / E_{\\gamma\\gamma}$', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_sigmaE_over_E': hist.axis.Regular(50, -4., 4., name='var', label=r'$\\sigma {E,\\gamma_2} / E_{\\gamma\\gamma}$', growth=False, underflow=False, overflow=False),\n",
    "    'lead_bjet_pt_over_Mjj': hist.axis.Regular(50, -4., 4., name='var', label=r'$p_{T,j1} / M_{jj}$', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_bjet_pt_over_Mjj': hist.axis.Regular(50, -4., 4., name='var', label=r'$p_{T,j2} / M_{jj}$', growth=False, underflow=False, overflow=False),\n",
    "    'lead_bjet_btagPNetB': hist.axis.Regular(50, -4., 4., name='var', label=r'$j_{lead}$ PNet btag score', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_bjet_btagPNetB': hist.axis.Regular(50, -4., 4., name='var', label=r'$j_{sublead}$ PNet btag score', growth=False, underflow=False, overflow=False),\n",
    "    'lead_bjet_sigmapT_over_pT': hist.axis.Regular(50, -4., 4., name='var', label=r'$\\sigma p_{T,j1} / p_{T,jj}$', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_bjet_sigmapT_over_pT': hist.axis.Regular(50, -4., 4., name='var', label=r'$\\sigma p_{T,j2} / p_{T,jj}$', growth=False, underflow=False, overflow=False),\n",
    "    'dipho_mass_over_Mggjj': hist.axis.Regular(50, -4., 4., name='var', label=r'$M_{\\gamma\\gamma} / M_{\\gamma\\gamma jj}$', growth=False, underflow=False, overflow=False), \n",
    "    'dijet_mass_over_Mggjj': hist.axis.Regular(50, -4., 4., name='var', label=r'$M_{jj} / M_{\\gamma\\gamma jj}$', growth=False, underflow=False, overflow=False),\n",
    "    # My variables for non-reso reduction #\n",
    "    'lead_pfRelIso03_all_quadratic': hist.axis.Regular(50, -4., 4., name='var', label=r'$\\gamma_{lead}$ PF RelIso03 all quad.', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_pfRelIso03_all_quadratic': hist.axis.Regular(50, -4., 4., name='var', label=r'$\\gamma_{sublead}$ PF RelIso03 all quad.', growth=False, underflow=False, overflow=False),\n",
    "    # Michael's DNN variables #\n",
    "    'DeltaR_j1g1': hist.axis.Regular(50, -4., 4., name='var', label=r'$\\Delta R(bjet_{lead}, \\gamma_{lead})$', growth=False, underflow=False, overflow=False), \n",
    "    'DeltaR_j1g2': hist.axis.Regular(50, -4., 4., name='var', label=r'$\\Delta R(bjet_{lead}, \\gamma_{sublead})$', growth=False, underflow=False, overflow=False), \n",
    "    'DeltaR_j2g1': hist.axis.Regular(50, -4., 4., name='var', label=r'$\\Delta R(bjet_{sublead}, \\gamma_{lead})$', growth=False, underflow=False, overflow=False), \n",
    "    'DeltaR_j2g2': hist.axis.Regular(50, -4., 4., name='var', label=r'$\\Delta R(bjet_{sublead}, \\gamma_{sublead})$', growth=False, underflow=False, overflow=False),\n",
    "    'HHbbggCandidate_pt': hist.axis.Regular(100, -4., 4., name='var', label=r'HH ln($p_T$) [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'HHbbggCandidate_eta': hist.axis.Regular(50, -4., 4., name='var', label=r'HH $\\eta$', growth=False, underflow=False, overflow=False), \n",
    "    'HHbbggCandidate_phi': hist.axis.Regular(50, -4., 4., name='var', label=r'HH $\\phi$', growth=False, underflow=False, overflow=False),\n",
    "    'HHbbggCandidate_mass': hist.axis.Regular(50, -4., 4., name='var', label=r'ln($M_{HH}$) [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    # ATLAS variables #\n",
    "    'pt_balance': hist.axis.Regular(100, -4., 4., name='var', label=r'ln($p_{T,HH} / (p_{T,\\gamma1} + p_{T,\\gamma2} + p_{T,j1} + p_{T,j2})$)', growth=False, underflow=False, overflow=False), \n",
    "    # VH variables #\n",
    "    'DeltaPhi_jj': hist.axis.Regular(20, -4., 4., name='var', label=r'$\\Delta\\phi (j_1,j_2)$', growth=False, underflow=False, overflow=False),\n",
    "    'DeltaEta_jj': hist.axis.Regular(20, -4., 4., name='var', label=r'$\\Delta\\eta (j_1,j_2)$', growth=False, underflow=False, overflow=False),\n",
    "    'isr_jet_pt': hist.axis.Regular(100, -4., 4., name='var', label=r'ISR jet ln($p_T$) [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    'DeltaPhi_isr_jet_z': hist.axis.Regular(20, -4., 4., name='var', label=r'$\\Delta\\phi (j_{ISR},jj)$', growth=False, underflow=False, overflow=False),\n",
    "    'dijet_pt': hist.axis.Regular(100, -4., 4., name='var', label=r'jj ln($p_T$) [GeV]', growth=False, underflow=False, overflow=False),\n",
    "}\n",
    "\n",
    "\n",
    "def make_input_plot(\n",
    "    output_dir, var_name, hist_list, fold_idx=None, labels=None, density=True, \n",
    "    plot_prefix='', plot_postfix='', alpha=0.8, linestyle=True\n",
    "):\n",
    "    fig, ax = plt.subplots()\n",
    "    if linestyle:\n",
    "        if fold_idx is not None:\n",
    "            linestyles = [\"solid\", \"dashed\", \"dotted\", \"solid\", \"dashed\", \"dotted\"]\n",
    "        else:\n",
    "            linestyles = [\"solid\", \"dotted\", \"solid\", \"dotted\"]\n",
    "        linestyles = linestyles * ((len(hist_list) // len(linestyles)) + 1)\n",
    "        linestyles = linestyles[:len(hist_list)]\n",
    "    else:\n",
    "        linestyles = None\n",
    "    hep.histplot(\n",
    "        hist_list, ax=ax, linewidth=3, histtype=\"step\", yerr=True, density=density,\n",
    "        linestyle=linestyles, label=labels, alpha=alpha\n",
    "    )\n",
    "    # Plotting niceties #\n",
    "    hep.cms.lumitext(f\"{LUMINOSITIES['total_lumi']:.2f}\" + r\"fb$^{-1}$ (13.6 TeV)\", ax=ax)\n",
    "    hep.cms.text(\"Work in Progress\", ax=ax)\n",
    "    # Plot legend properly\n",
    "    ax.legend(bbox_to_anchor=(1, 0.5))\n",
    "    # Make angular and chi^2 plots linear, otherwise log\n",
    "    if re.match('chi_t', var_name) is None and re.match('DeltaPhi', var_name) is None and re.match('mass', var_name) is None:\n",
    "        ax.set_yscale('log')\n",
    "    else:\n",
    "        ax.set_yscale('linear')\n",
    "    ax.set_yscale('linear')\n",
    "    # Save out the plot\n",
    "    if fold_idx is not None:\n",
    "        plt.savefig(f'{output_dir}/{plot_prefix}1dhist_{var_name}{plot_postfix}_fold{fold_idx}.pdf', bbox_inches='tight')\n",
    "        plt.savefig(f'{output_dir}/{plot_prefix}1dhist_{var_name}{plot_postfix}_fold{fold_idx}.png', bbox_inches='tight')\n",
    "    else:\n",
    "        plt.savefig(f'{output_dir}/{plot_prefix}1dhist_{var_name}{plot_postfix}.pdf', bbox_inches='tight')\n",
    "        plt.savefig(f'{output_dir}/{plot_prefix}1dhist_{var_name}{plot_postfix}.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss per Epoch Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"losses\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "if 'BDT_perf' not in globals():\n",
    "    with open(os.path.join(OUTPUT_DIRPATH, CURRENT_TIME+\"_BDT_perf.json\"), 'r') as f:\n",
    "        BDT_perf = json.load(f)\n",
    "\n",
    "if 'evals_result_dict' not in globals():\n",
    "    with open(os.path.join(OUTPUT_DIRPATH, CURRENT_TIME+\"_BDT_eval_result.json\"), 'r') as f:\n",
    "        evals_result_dict = json.load(f)\n",
    "\n",
    "# plot train/val/test losses\n",
    "all_train, all_val, all_test = [], [], []\n",
    "for fold_idx in range(len(evals_result_dict)):\n",
    "    all_train.append(evals_result_dict[f\"fold_{fold_idx}\"]['train']['mlogloss'])\n",
    "    all_val.append(evals_result_dict[f\"fold_{fold_idx}\"]['val']['mlogloss'])\n",
    "    all_test.append(evals_result_dict[f\"fold_{fold_idx}\"]['test']['mlogloss'])\n",
    "\n",
    "plot_train_val_losses(\n",
    "    all_train + all_val, [f'train fold {i}' for i in range(len(all_train))]+[f'val fold {i}' for i in range(len(all_val))],\n",
    "    'train_val_losses_vs_epoch', plot_dirpath, \n",
    "    linestyles=['solid']*len(all_train) + ['dashed']*len(all_val),\n",
    ")\n",
    "plot_train_val_losses(\n",
    "    all_train + all_test, [f'train fold {i}' for i in range(len(all_train))]+[f'test fold {i}' for i in range(len(all_test))],\n",
    "    'train_test_losses_vs_epoch', plot_dirpath,\n",
    "    linestyles=['solid']*len(all_train) + ['dotted']*len(all_test),\n",
    ")\n",
    "avg_train, avg_val, avg_test = np.mean(pad_list(all_train), axis=0), np.mean(pad_list(all_val), axis=0), np.mean(pad_list(all_test), axis=0)\n",
    "std_train, std_val, std_test = np.std(pad_list(all_train), axis=0), np.std(pad_list(all_val), axis=0), np.std(pad_list(all_test), axis=0)\n",
    "plot_train_val_losses(\n",
    "    [avg_train, avg_val, avg_test], ['train avg', 'val avg', 'test avg'],\n",
    "    'train_val_test_avg_vs_epoch', plot_dirpath,\n",
    "    losses_std_arrs=[std_train, std_val, std_test],\n",
    "    linestyles=['solid', 'dashed', 'dotted'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"ROCs\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "if 'BDT_perf' not in globals():\n",
    "    with open(os.path.join(OUTPUT_DIRPATH, CURRENT_TIME+\"_BDT_perf.json\"), 'r') as f:\n",
    "        BDT_perf = json.load(f)\n",
    "\n",
    "base_tpr = np.array(BDT_perf['ggF HH']['base_tpr'])\n",
    "\n",
    "# plot ROCs\n",
    "for j, sample_name in enumerate(order):\n",
    "\n",
    "    for fold_idx in range(len(bdt_train_dict)):\n",
    "\n",
    "        for roc_type in ['density', 'weighted']:\n",
    "\n",
    "            fprs = [np.array(BDT_perf[sample_name][f'fprs_{roc_type}'][fold_idx])[:, i] for i in range(len(order))]\n",
    "            tprs = [base_tpr for _ in range(len(order))]\n",
    "            labels = [\n",
    "                f\"{sample_name} vs. {'all' if i == j else sample_name_}, AUC = {BDT_perf[sample_name][f'areas_{roc_type}'][fold_idx][i]:.4f}\" \n",
    "                for i, sample_name_ in enumerate(order)\n",
    "            ]\n",
    "\n",
    "            plot_rocs(fprs, tprs, labels, f\"BDT_roc_{sample_name}_{roc_type}_testData_fold{fold_idx}\", plot_dirpath)\n",
    "\n",
    "    for roc_type in ['sum_density', 'sum_weighted']:\n",
    "\n",
    "        fprs = [np.array(BDT_perf[sample_name][f'fprs_{roc_type}'])[:, i] for i in range(len(order))]\n",
    "        tprs = [base_tpr for _ in range(len(order))]\n",
    "        labels = [\n",
    "            f\"{sample_name} vs. {'all' if i == j else sample_name_}, AUC = {BDT_perf[sample_name][f'areas_{roc_type}'][i]:.4f}\" \n",
    "            for i, sample_name_ in enumerate(order)\n",
    "        ]\n",
    "\n",
    "        plot_rocs(fprs, tprs, labels, f\"BDT_roc_{sample_name}_{roc_type}_testData_sum\", plot_dirpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Score Dist Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"output_scores\")\n",
    "# plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"output_scores_arctanh\")\n",
    "# plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"output_scores_resample\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "if 'BDT_perf' not in globals():\n",
    "    with open(os.path.join(OUTPUT_DIRPATH, CURRENT_TIME+\"_BDT_perf.json\"), 'r') as f:\n",
    "        BDT_perf = json.load(f)\n",
    "\n",
    "# plot Output scores\n",
    "for j, sample_name in enumerate(order):\n",
    "\n",
    "    for i, sample_name_ in enumerate(order):\n",
    "\n",
    "        for fold_idx in range(len(bdt_train_dict)):\n",
    "            \n",
    "            sigs_and_bkgs = {\n",
    "                sample_name__: np.array(BDT_perf[sample_name]['preds'][fold_idx])[:, j][bdt_test_dict[f\"fold_{fold_idx}\"].get_label() == k]\n",
    "                for k, sample_name__ in enumerate(order)\n",
    "            }\n",
    "            score_weights = {\n",
    "                sample_name__: weights_plot_test[f\"fold_{fold_idx}\"][bdt_test_dict[f\"fold_{fold_idx}\"].get_label() == k]\n",
    "                for k, sample_name__ in enumerate(order)\n",
    "            }\n",
    "\n",
    "            if sample_name_ != sample_name:\n",
    "                event_j_mask = bdt_test_dict[f\"fold_{fold_idx}\"].get_label() == j\n",
    "                pred_j_rescale = np.array(BDT_perf[sample_name]['preds'][fold_idx])[:, j][event_j_mask] + np.array(BDT_perf[sample_name]['preds'][fold_idx])[:, i][event_j_mask]\n",
    "                event_i_mask = bdt_test_dict[f\"fold_{fold_idx}\"].get_label() == i\n",
    "                pred_i_rescale = np.array(BDT_perf[sample_name]['preds'][fold_idx])[:, j][event_i_mask] + np.array(BDT_perf[sample_name]['preds'][fold_idx])[:, i][event_i_mask]\n",
    "\n",
    "                for sample_name__ in order:\n",
    "                    if sample_name__ == sample_name:\n",
    "                        sigs_and_bkgs[sample_name__] = sigs_and_bkgs[sample_name__] / pred_j_rescale\n",
    "                    elif sample_name__ == sample_name_:\n",
    "                        sigs_and_bkgs[sample_name__] = sigs_and_bkgs[sample_name__] / pred_i_rescale\n",
    "                    else:\n",
    "                        del sigs_and_bkgs[sample_name__]\n",
    "                        del score_weights[sample_name__]\n",
    "\n",
    "            if re.search('arctanh', plot_dirpath) is not None:\n",
    "                for key, value in sigs_and_bkgs.items():\n",
    "                    sigs_and_bkgs[key] = np.arctanh(value)\n",
    "\n",
    "            plot_output_scores(\n",
    "                sigs_and_bkgs, order, \n",
    "                f\"BDT_{sample_name}_vs_{sample_name_ if sample_name_ != sample_name else 'all'}_outputScoreWeighted_testData_fold{fold_idx}\", \n",
    "                plot_dirpath, weights=score_weights, log=True,\n",
    "                arctanh=True if re.search('arctanh', plot_dirpath) is not None else False\n",
    "            )\n",
    "            plot_output_scores(\n",
    "                sigs_and_bkgs, order, \n",
    "                f\"BDT_{sample_name}_vs_{sample_name_ if sample_name_ != sample_name else 'all'}_outputScoreDensity_testData_fold{fold_idx}\", \n",
    "                plot_dirpath,\n",
    "                arctanh=True if re.search('arctanh', plot_dirpath) is not None else False\n",
    "            )\n",
    "\n",
    "        flat_preds = np.concatenate([BDT_perf[sample_name]['preds'][fold_idx] for fold_idx in range(len(bdt_test_dict))], axis=0)\n",
    "        if re.search('arctanh', plot_dirpath) is not None:\n",
    "            flat_preds = np.arctanh(flat_preds)\n",
    "        flat_truths = np.concatenate([bdt_test_dict[f\"fold_{fold_idx}\"].get_label() for fold_idx in range(len(bdt_test_dict))], axis=0)\n",
    "        flat_weights = np.concatenate([weights_plot_test[f\"fold_{fold_idx}\"] for fold_idx in range(len(bdt_test_dict))], axis=0)\n",
    "\n",
    "        sigs_and_bkgs = {\n",
    "            sample_name__: flat_preds[:, j][flat_truths == k]\n",
    "            for k, sample_name__ in enumerate(order)\n",
    "        }\n",
    "        score_weights = {\n",
    "            sample_name__: flat_weights[flat_truths == k]\n",
    "            for k, sample_name__ in enumerate(order)\n",
    "        }\n",
    "        \n",
    "        if sample_name_ != sample_name:\n",
    "            event_j_mask = flat_truths == j\n",
    "            pred_j_rescale = (flat_preds[:, j] + flat_preds[:, i])[event_j_mask]\n",
    "            event_i_mask = flat_truths == i\n",
    "            pred_i_rescale = (flat_preds[:, j] + flat_preds[:, i])[event_i_mask]\n",
    "\n",
    "            for sample_name__ in order:\n",
    "                if sample_name__ == sample_name:\n",
    "                    sigs_and_bkgs[sample_name__] = sigs_and_bkgs[sample_name__] / pred_j_rescale\n",
    "                elif sample_name__ == sample_name_:\n",
    "                    sigs_and_bkgs[sample_name__] = sigs_and_bkgs[sample_name__] / pred_i_rescale\n",
    "                else:\n",
    "                    del sigs_and_bkgs[sample_name__]\n",
    "                    del score_weights[sample_name__]\n",
    "        \n",
    "        plot_output_scores(\n",
    "            sigs_and_bkgs, order, \n",
    "            f\"BDT_{sample_name}_vs_{sample_name_ if sample_name_ != sample_name else 'all'}_outputScoreWeighted_testData_sum\", \n",
    "            plot_dirpath, weights=score_weights, log=True,\n",
    "            arctanh=True if re.search('arctanh', plot_dirpath) is not None else False\n",
    "        )\n",
    "        plot_output_scores(\n",
    "            sigs_and_bkgs, order, \n",
    "            f\"BDT_{sample_name}_vs_{sample_name_ if sample_name_ != sample_name else 'all'}_outputScoreDensity_testData_sum\", \n",
    "            plot_dirpath,\n",
    "            arctanh=True if re.search('arctanh', plot_dirpath) is not None else False\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### s/âb Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "============================================================\n",
      "Cat1: 0.9981 < ggF HH score â¤ 1.0000 AND 120 GeV < m_HH < 130 GeV\n",
      "------------------------------------------------------------\n",
      "Cat1: Num ggF HH = 0.2543\n",
      "------------------------------------------------------------\n",
      "Cat1: Num ttH = 0.0144\n",
      "------------------------------------------------------------\n",
      "Cat1: Num VH = 0.0216\n",
      "------------------------------------------------------------\n",
      "Cat1: Num non-res + ggFH + VBFH = 0.8248\n",
      "------------------------------------------------------------\n",
      "Cat1: Num GluGluHToGG = 0.09462991176480666\n",
      "------------------------------------------------------------\n",
      "Cat1: Num VBFHToGG = 0.008416797922045714\n",
      "------------------------------------------------------------\n",
      "Cat1: Num GGJets = 0.7217241259553565\n",
      "------------------------------------------------------------\n",
      "Cat1: Num GJetPt20To40 = 0.0\n",
      "------------------------------------------------------------\n",
      "Cat1: Num GJetPt40 = 0.0\n",
      "------------------------------------------------------------\n",
      "Cat1: S = 0.2543, B = 0.8608, S/âB = 0.2741\n",
      "============================================================\n",
      "============================================================\n",
      "Cat2: 0.9933 < ggF HH score â¤ 0.9981 AND 120 GeV < m_HH < 130 GeV\n",
      "------------------------------------------------------------\n",
      "Cat2: Num ggF HH = 0.2365\n",
      "------------------------------------------------------------\n",
      "Cat2: Num ttH = 0.1369\n",
      "------------------------------------------------------------\n",
      "Cat2: Num VH = 0.1083\n",
      "------------------------------------------------------------\n",
      "Cat2: Num non-res + ggFH + VBFH = 4.8520\n",
      "------------------------------------------------------------\n",
      "Cat2: Num GluGluHToGG = 0.46386418809394697\n",
      "------------------------------------------------------------\n",
      "Cat2: Num VBFHToGG = 0.049986357588345603\n",
      "------------------------------------------------------------\n",
      "Cat2: Num GGJets = 3.103949782073729\n",
      "------------------------------------------------------------\n",
      "Cat2: Num GJetPt20To40 = 0.0\n",
      "------------------------------------------------------------\n",
      "Cat2: Num GJetPt40 = 1.2341594322756537\n",
      "------------------------------------------------------------\n",
      "Cat2: S = 0.2365, B = 5.0972, S/âB = 0.1048\n",
      "============================================================\n",
      "============================================================\n",
      "Cat3: 0.9673 < ggF HH score â¤ 0.9933 AND 120 GeV < m_HH < 130 GeV\n",
      "------------------------------------------------------------\n",
      "Cat3: Num ggF HH = 0.2372\n",
      "------------------------------------------------------------\n",
      "Cat3: Num ttH = 0.7686\n",
      "------------------------------------------------------------\n",
      "Cat3: Num VH = 0.2726\n",
      "------------------------------------------------------------\n",
      "Cat3: Num non-res + ggFH + VBFH = 30.6843\n",
      "------------------------------------------------------------\n",
      "Cat3: Num GluGluHToGG = 1.5054103220557582\n",
      "------------------------------------------------------------\n",
      "Cat3: Num VBFHToGG = 0.10436583037204883\n",
      "------------------------------------------------------------\n",
      "Cat3: Num GGJets = 27.840353234491417\n",
      "------------------------------------------------------------\n",
      "Cat3: Num GJetPt20To40 = 0.0\n",
      "------------------------------------------------------------\n",
      "Cat3: Num GJetPt40 = 1.2341594322756537\n",
      "------------------------------------------------------------\n",
      "Cat3: S = 0.2372, B = 31.7255, S/âB = 0.0421\n"
     ]
    }
   ],
   "source": [
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"s_over_rootb\")\n",
    "# plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"s_over_rootb_arctanh\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "if 'BDT_perf' not in globals():\n",
    "    with open(os.path.join(OUTPUT_DIRPATH, CURRENT_TIME+\"_BDT_perf.json\"), 'r') as f:\n",
    "        BDT_perf = json.load(f)\n",
    "\n",
    "# plot s/âb curves\n",
    "for j, sample_name in enumerate(order):\n",
    "\n",
    "    for i, sample_name_ in enumerate(order):\n",
    "\n",
    "        for fold_idx in range(len(BDT_perf['ggF HH']['preds'])):\n",
    "\n",
    "            if sample_name_ == sample_name:\n",
    "                sig_mask = bdt_test_dict[f\"fold_{fold_idx}\"].get_label() == j\n",
    "                bkg_mask = bdt_test_dict[f\"fold_{fold_idx}\"].get_label() != j\n",
    "\n",
    "                sig_rescale = np.ones_like(sig_mask)\n",
    "                bkg_rescale = np.ones_like(bkg_mask)\n",
    "            else:\n",
    "                sig_mask = bdt_test_dict[f\"fold_{fold_idx}\"].get_label() == j\n",
    "                bkg_mask = bdt_test_dict[f\"fold_{fold_idx}\"].get_label() == i\n",
    "\n",
    "                sig_rescale = (\n",
    "                    np.array(BDT_perf[sample_name]['preds'][fold_idx])[:, j] \n",
    "                    + np.array(BDT_perf[sample_name]['preds'][fold_idx])[:, i]\n",
    "                )\n",
    "                bkg_rescale = (\n",
    "                    np.array(BDT_perf[sample_name]['preds'][fold_idx])[:, j] \n",
    "                    + np.array(BDT_perf[sample_name]['preds'][fold_idx])[:, i]\n",
    "                )\n",
    "\n",
    "            sigs_and_bkgs = {\n",
    "                'sig': (np.array(BDT_perf[sample_name]['preds'][fold_idx])[:, j] / sig_rescale)[sig_mask],\n",
    "                'bkg': (np.array(BDT_perf[sample_name]['preds'][fold_idx])[:, j] / bkg_rescale)[bkg_mask]\n",
    "            }\n",
    "            if re.search('arctanh', plot_dirpath) is not None:\n",
    "                sigs_and_bkgs['sig'] = np.arctanh(sigs_and_bkgs['sig'])\n",
    "                sigs_and_bkgs['bkg'] = np.arctanh(sigs_and_bkgs['bkg'])\n",
    "            score_weights = {\n",
    "                'sig': weights_plot_test[f\"fold_{fold_idx}\"][sig_mask],\n",
    "                'bkg': weights_plot_test[f\"fold_{fold_idx}\"][bkg_mask]\n",
    "            }\n",
    "\n",
    "\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\")\n",
    "                plot_s_over_root_b(\n",
    "                    sigs_and_bkgs['sig'], sigs_and_bkgs['bkg'], f\"{sample_name} vs. {sample_name_ if sample_name_ != sample_name else 'all'}\", \n",
    "                    f\"BDT_{sample_name}_vs_{sample_name_ if sample_name_ != sample_name else 'all'}_sOverRootb_testData_fold{fold_idx}\", \n",
    "                    plot_dirpath, weights=score_weights,\n",
    "                    arctanh=True if re.search('arctanh', plot_dirpath) is not None else False  \n",
    "                )\n",
    "\n",
    "                (\n",
    "                    cut_boundaries_fold, cut_s_over_root_bs_fold, sig_weights_fold, bkg_weights_fold\n",
    "                ) = optimize_cut_boundaries(\n",
    "                    sigs_and_bkgs['sig'], sigs_and_bkgs['bkg'], score_weights,\n",
    "                    arctanh=True if re.search('arctanh', plot_dirpath) is not None else False\n",
    "                )\n",
    "\n",
    "                BDT_cut_labels = [\n",
    "                    f\"cut={cut_boundaries_fold[0][cut_idx]:.4f}: s/âb={cut_s_over_root_bs_fold[0][cut_idx]:.5f}, s={sig_weights_fold[0][cut_idx]['value']:.5f}Â±{sig_weights_fold[0][cut_idx]['w2']:.5f}, b={bkg_weights_fold[0][cut_idx]['value']:.5f}Â±{bkg_weights_fold[0][cut_idx]['w2']:.5f}\" for cut_idx in range(len(cut_s_over_root_bs_fold[0]))\n",
    "                ]\n",
    "                line_labels = BDT_cut_labels[:10]\n",
    "                lines = cut_boundaries_fold[0][:10]\n",
    "                line_colors = cmap_petroff10\n",
    "\n",
    "                plot_s_over_root_b(\n",
    "                    sigs_and_bkgs['sig'], sigs_and_bkgs['bkg'], f\"{sample_name} vs. {sample_name_ if sample_name_ != sample_name else 'all'}\", \n",
    "                    f\"BDT_{sample_name}_vs_{sample_name_ if sample_name_ != sample_name else 'all'}_sOverRootb_withCuts_testData_fold{fold_idx}_{sample_name}\", plot_dirpath, \n",
    "                    weights=score_weights,\n",
    "                    lines=lines, lines_labels=line_labels, line_colors=line_colors,\n",
    "                    arctanh=True if re.search('arctanh', plot_dirpath) is not None else False\n",
    "                )\n",
    "            \n",
    "        flat_preds = np.concatenate([BDT_perf[sample_name]['preds'][fold_idx] for fold_idx in range(len(BDT_perf['ggF HH']['preds']))], axis=0)\n",
    "        if re.search('arctanh', plot_dirpath) is not None:\n",
    "            flat_preds = np.arctanh(flat_preds)\n",
    "        flat_truths = np.concatenate([bdt_test_dict[f\"fold_{fold_idx}\"].get_label() for fold_idx in range(len(BDT_perf['ggF HH']['preds']))], axis=0)\n",
    "        flat_weights = np.concatenate([weights_plot_test[f\"fold_{fold_idx}\"] for fold_idx in range(len(BDT_perf['ggF HH']['preds']))], axis=0)\n",
    "        flat_sample_names = np.concatenate([data_test_aux_dict[f\"fold_{fold_idx}\"]['sample_name'] for fold_idx in range(len(BDT_perf['ggF HH']['preds']))], axis=0)\n",
    "\n",
    "        if sample_name_ == sample_name:\n",
    "            sig_mask = flat_truths == j\n",
    "            bkg_mask = flat_truths != j\n",
    "\n",
    "            sig_rescale = np.ones_like(sig_mask)\n",
    "            bkg_rescale = np.ones_like(bkg_mask)\n",
    "        else:\n",
    "            sig_mask = flat_truths == j\n",
    "            bkg_mask = flat_truths == i\n",
    "\n",
    "            sig_rescale = flat_preds[:, j] + flat_preds[:, i]\n",
    "            bkg_rescale = flat_preds[:, j] + flat_preds[:, i]\n",
    "\n",
    "        sigs_and_bkgs = {\n",
    "            'sig': (flat_preds[:, j] / sig_rescale)[sig_mask],\n",
    "            'bkg': (flat_preds[:, j] / bkg_rescale)[bkg_mask]\n",
    "        }\n",
    "        score_weights = {\n",
    "            'sig': flat_weights[sig_mask],\n",
    "            'bkg': flat_weights[bkg_mask]\n",
    "        }\n",
    "\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            plot_s_over_root_b(\n",
    "                sigs_and_bkgs['sig'], sigs_and_bkgs['bkg'], f\"{sample_name} vs. {sample_name_ if sample_name_ != sample_name else 'all'}\", \n",
    "                f\"BDT_{sample_name}_vs_{sample_name_ if sample_name_ != sample_name else 'all'}_sOverRootb_testData_sum\", \n",
    "                plot_dirpath, weights=score_weights,\n",
    "                arctanh=True if re.search('arctanh', plot_dirpath) is not None else False\n",
    "            )\n",
    "\n",
    "            (\n",
    "                cut_boundaries_fold, cut_s_over_root_bs_fold, sig_weights_fold, bkg_weights_fold\n",
    "            ) = optimize_cut_boundaries(\n",
    "                sigs_and_bkgs['sig'], sigs_and_bkgs['bkg'], score_weights,\n",
    "                arctanh=True if re.search('arctanh', plot_dirpath) is not None else False\n",
    "            )\n",
    "\n",
    "            BDT_cut_labels = [\n",
    "                f\"cut={cut_boundaries_fold[0][cut_idx]:.4f}: s/âb={cut_s_over_root_bs_fold[0][cut_idx]:.5f}, s={sig_weights_fold[0][cut_idx]['value']:.5f}Â±{sig_weights_fold[0][cut_idx]['w2']:.5f}, b={bkg_weights_fold[0][cut_idx]['value']:.5f}Â±{bkg_weights_fold[0][cut_idx]['w2']:.5f}\" for cut_idx in range(len(cut_s_over_root_bs_fold[0]))\n",
    "            ]\n",
    "            line_labels = BDT_cut_labels[:10]\n",
    "            lines = cut_boundaries_fold[0][:10]\n",
    "            line_colors = cmap_petroff10\n",
    "\n",
    "            plot_s_over_root_b(\n",
    "                sigs_and_bkgs['sig'], sigs_and_bkgs['bkg'], f\"{sample_name} vs. {sample_name_ if sample_name_ != sample_name else 'all'}\", \n",
    "                f\"BDT_{sample_name}_vs_{sample_name_ if sample_name_ != sample_name else 'all'}_sOverRootb_withCuts_testData_sum\", plot_dirpath, \n",
    "                weights=score_weights,\n",
    "                lines=lines, lines_labels=line_labels, line_colors=line_colors,\n",
    "                arctanh=True if re.search('arctanh', plot_dirpath) is not None else False\n",
    "            )\n",
    "\n",
    "        if j == 0 and i == 0:\n",
    "            flat_mass = np.concatenate([data_test_aux_dict[f\"fold_{fold_idx}\"]['mass'] for fold_idx in range(len(BDT_perf['ggF HH']['preds']))], axis=0)\n",
    "            if re.search('arctanh', plot_dirpath) is not None:\n",
    "                cat_lines = [6.0] + lines[:3]\n",
    "            else:\n",
    "                cat_lines = [1.0] + lines[:3]\n",
    "            cat_num_samples = {}\n",
    "            for k, cat in enumerate(['Cat1', 'Cat2', 'Cat3']):\n",
    "                cat_num_samples[cat] = {}\n",
    "                print('='*60)\n",
    "                print('='*60)\n",
    "                print(f\"{cat}: {cat_lines[k+1]:.4f} < ggF HH score â¤ {cat_lines[k]:.4f} AND 120 GeV < m_HH < 130 GeV\")\n",
    "                print('-'*60)\n",
    "                for m, sample_name in enumerate(order):\n",
    "                    sample_bool = np.logical_and(  # event passes conditions and is the right type (i.e. sample)\n",
    "                        np.logical_and(  # event passes category and mass conditions\n",
    "                            np.logical_and(  # prediction is within category bounds\n",
    "                                flat_preds[:, 0] <= cat_lines[k],\n",
    "                                flat_preds[:, 0] > cat_lines[k+1]\n",
    "                            ),\n",
    "                            np.logical_and(  # diphoton mass is within 120-130 window\n",
    "                                flat_mass < 130,\n",
    "                                flat_mass > 120\n",
    "                            ),\n",
    "                        ),\n",
    "                        flat_truths == m\n",
    "                    )\n",
    "                    cat_num_samples[cat][sample_name] = np.sum(\n",
    "                        flat_weights[sample_bool]\n",
    "                    )\n",
    "                    print(f\"{cat}: Num {sample_name} = {cat_num_samples[cat][sample_name]:.4f}\")\n",
    "                    print('-'*60)\n",
    "                    if sample_name == order[-1]:\n",
    "                        for smpl in ['GluGluHToGG', 'VBFHToGG', 'GGJets', 'GJetPt20To40', 'GJetPt40']:\n",
    "                            smpl_num = np.sum(\n",
    "                                flat_weights[\n",
    "                                    np.logical_and(\n",
    "                                        sample_bool,\n",
    "                                        flat_sample_names == smpl\n",
    "                                    )\n",
    "                                ]\n",
    "                            )\n",
    "                            print(f\"{cat}: Num {smpl} = {smpl_num}\")\n",
    "                            print('-'*60)\n",
    "\n",
    "                print(f\"{cat}: S = {cat_num_samples[cat][order[0]]:.4f}, B = {np.sum([cat_num_samples[cat][order[v]] for v in range(1, len(order))]):.4f}, S/âB = {(cat_num_samples[cat][order[0]] / np.sqrt(np.sum([cat_num_samples[cat][order[v]] for v in range(1, len(order))]))):.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "============================================================\n",
      "Category 0 3D outputs < [0.00014055027654462777, 0.0019279517132367056, 0.0017874033775492724] AND 120 GeV < m_HH < 130 GeV\n",
      "------------------------------------------------------------\n",
      "0: Num ggF HH = 0.4181\n",
      "------------------------------------------------------------\n",
      "0: Num ttH = 0.1792\n",
      "------------------------------------------------------------\n",
      "0: Num VH = 0.1668\n",
      "------------------------------------------------------------\n",
      "0: Num non-res + ggFH + VBFH = 3.0598\n",
      "------------------------------------------------------------\n",
      "0: S = 0.4181, B = 3.4058, S/âB = 0.2265\n",
      "============================================================\n",
      "============================================================\n",
      "Category 1 3D outputs NOT< [0.00014055027654462777, 0.0019279517132367056, 0.0017874033775492724] AND 3D outputs < [0.00015953082067176068, 0.0031904568899924963, 0.0030309420216650075] AND 120 GeV < m_HH < 130 GeV\n",
      "------------------------------------------------------------\n",
      "1: Num ggF HH = 0.0754\n",
      "------------------------------------------------------------\n",
      "1: Num ttH = 0.0950\n",
      "------------------------------------------------------------\n",
      "1: Num VH = 0.0466\n",
      "------------------------------------------------------------\n",
      "1: Num non-res + ggFH + VBFH = 1.8324\n",
      "------------------------------------------------------------\n",
      "1: S = 0.0754, B = 1.9740, S/âB = 0.0537\n",
      "============================================================\n",
      "============================================================\n",
      "Category 2 3D outputs NOT< [0.00015953082067176068, 0.0031904568899924963, 0.0030309420216650075] AND 3D outputs < [0.00012428479978053485, 0.0036933592767097153, 0.003569109152819045] AND 120 GeV < m_HH < 130 GeV\n",
      "------------------------------------------------------------\n",
      "2: Num ggF HH = 0.0135\n",
      "------------------------------------------------------------\n",
      "2: Num ttH = 0.0069\n",
      "------------------------------------------------------------\n",
      "2: Num VH = 0.0089\n",
      "------------------------------------------------------------\n",
      "2: Num non-res + ggFH + VBFH = 0.2208\n",
      "------------------------------------------------------------\n",
      "2: S = 0.0135, B = 0.2365, S/âB = 0.0277\n"
     ]
    }
   ],
   "source": [
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"s_over_rootb_multiOptim\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "if 'BDT_perf' not in globals():\n",
    "    with open(os.path.join(OUTPUT_DIRPATH, CURRENT_TIME+\"_BDT_perf.json\"), 'r') as f:\n",
    "        BDT_perf = json.load(f)\n",
    "\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(projection='3d')\n",
    "# # x_preds, y_preds, z_preds = p_to_xyz(np.concatenate([BDT_perf['ggF HH']['preds'][fold_idx] for fold_idx in range(len(bdt_test_dict))], axis=0))\n",
    "# for i, sample_name in enumerate(order):\n",
    "#     if i == 0:\n",
    "#         downsample = 100\n",
    "#     elif i == 1:\n",
    "#         downsample = 200\n",
    "#     elif i == 2:\n",
    "#         downsample = 400\n",
    "#     elif i == 3:\n",
    "#         downsample = 500\n",
    "\n",
    "#     x_preds, y_preds, z_preds = p_to_xyz(np.array(BDT_perf['ggF HH']['preds'][0])[bdt_test_dict[f\"fold_0\"].get_label() == i][::downsample])\n",
    "#     ax.scatter(x_preds, y_preds, z_preds, marker='.', label=sample_name)\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# # plot s/âb curves\n",
    "# for fold_idx in range(len(bdt_train_dict)):\n",
    "\n",
    "#     with warnings.catch_warnings():\n",
    "#         warnings.simplefilter(\"ignore\")\n",
    "#         clf_dict = multi_optimize_cut_boundaries(\n",
    "#             BDT_perf['ggF HH']['preds'][fold_idx], \n",
    "#             bdt_test_dict[f\"fold_{fold_idx}\"].get_label() == 0, \n",
    "#             weights_plot_test[f\"fold_{fold_idx}\"],\n",
    "#             min_sig=0.07\n",
    "#         )\n",
    "\n",
    "#     cat_dict = {}\n",
    "#     for cat in range(len(clf_dict)):\n",
    "#         prev_cat_slice = np.ones_like(weights_plot_test[f\"fold_{fold_idx}\"], dtype=bool)\n",
    "#         if cat > 0:\n",
    "#             for prev_cat in range(cat):\n",
    "#                 prev_cat_slice = np.logical_and(\n",
    "#                     prev_cat_slice,\n",
    "#                     np.logical_not(\n",
    "#                         np.all(\n",
    "#                             p_to_xyz(np.array(BDT_perf['ggF HH']['preds'][fold_idx]), split=False) < clf_dict[prev_cat], \n",
    "#                             axis=1\n",
    "#                         )\n",
    "#                     )\n",
    "#                 )\n",
    "#         cat_dict[cat] = np.logical_and(\n",
    "#             prev_cat_slice,\n",
    "#             np.all(\n",
    "#                 p_to_xyz(np.array(BDT_perf['ggF HH']['preds'][fold_idx]), split=False) < clf_dict[cat],\n",
    "#                 axis=1\n",
    "#             )\n",
    "#         )\n",
    "\n",
    "#     masses = data_test_aux_dict[f\"fold_{fold_idx}\"]['mass']\n",
    "#     cat_num_samples = {}\n",
    "#     for cat in range(len(clf_dict)):\n",
    "#         cat_num_samples[cat] = {}\n",
    "#         print('='*60)\n",
    "#         print('='*60)\n",
    "#         print(f\"Fold {fold_idx}: Category {cat} (SVM) AND 120 GeV < m_HH < 130 GeV\")\n",
    "#         print('-'*60)\n",
    "#         for m, sample_name in enumerate(order):\n",
    "#             cat_num_samples[cat][sample_name] = np.sum(\n",
    "#                 weights_plot_test[f\"fold_{fold_idx}\"][\n",
    "#                     np.logical_and(  # event passes conditions and is the right type (i.e. sample)\n",
    "#                         np.logical_and(  # event passes category and mass conditions\n",
    "#                             cat_dict[cat],  # event passes category selections\n",
    "#                             np.logical_and(  # diphoton mass is within 120-130 window\n",
    "#                                 masses < 130,\n",
    "#                                 masses > 120\n",
    "#                             ),\n",
    "#                         ),\n",
    "#                         bdt_test_dict[f\"fold_{fold_idx}\"].get_label() == m\n",
    "#                     )\n",
    "#                 ]\n",
    "#             )\n",
    "#             print(f\"{cat}: Num {sample_name} = {cat_num_samples[cat][sample_name]:.4f}\")\n",
    "#             print('-'*60)\n",
    "#         print(f\"{cat}: S = {cat_num_samples[cat][order[0]]:.4f}, B = {np.sum([cat_num_samples[cat][order[v]] for v in range(1, len(order))]):.4f}, S/âB = {(cat_num_samples[cat][order[0]] / np.sqrt(np.sum([cat_num_samples[cat][order[v]] for v in range(1, len(order))]))):.4f}\")\n",
    "\n",
    "# print('='*60)\n",
    "# print('='*60)\n",
    "# print('='*60)\n",
    "# print('='*60)\n",
    "\n",
    "flat_preds = np.concatenate([BDT_perf['ggF HH']['preds'][fold_idx] for fold_idx in range(len(bdt_test_dict))], axis=0)\n",
    "flat_truths = np.concatenate([bdt_test_dict[f\"fold_{fold_idx}\"].get_label() for fold_idx in range(len(bdt_test_dict))], axis=0)\n",
    "flat_weights = np.concatenate([weights_plot_test[f\"fold_{fold_idx}\"] for fold_idx in range(len(bdt_test_dict))], axis=0)\n",
    "# flat_weights = np.concatenate([weight_test_dict[f\"fold_{fold_idx}\"] for fold_idx in range(len(bdt_test_dict))], axis=0)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    clf_dict = multi_optimize_cut_boundaries(\n",
    "        flat_preds, flat_truths == 0, flat_weights\n",
    "    )\n",
    "\n",
    "    # plot_s_over_root_b(\n",
    "    #     sigs_and_bkgs['sig'], sigs_and_bkgs['bkg'], f\"{sample_name} vs. {sample_name_ if sample_name_ != sample_name else 'all'}\", \n",
    "    #     f\"BDT_{sample_name}_vs_{sample_name_ if sample_name_ != sample_name else 'all'}_sOverRootb_withCuts_testData_sum\", plot_dirpath, \n",
    "    #     weights=score_weights,\n",
    "    #     lines=lines, lines_labels=line_labels, line_colors=line_colors\n",
    "    # )\n",
    "\n",
    "flat_mass = np.concatenate([data_test_aux_dict[f\"fold_{fold_idx}\"]['mass'] for fold_idx in range(len(data_test_aux_dict))], axis=0)\n",
    "cat_dict = {}\n",
    "for cat in range(len(clf_dict)):\n",
    "    prev_cat_slice = np.ones_like(flat_weights, dtype=bool)\n",
    "    if cat > 0:\n",
    "        for prev_cat in range(cat):\n",
    "            prev_cat_slice = np.logical_and(\n",
    "                prev_cat_slice,\n",
    "                np.logical_not(\n",
    "                    np.all(\n",
    "                        p_to_xyz(flat_preds, split=False) < clf_dict[prev_cat], \n",
    "                        axis=1\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "    cat_dict[cat] = np.logical_and(\n",
    "        prev_cat_slice,\n",
    "        np.all(\n",
    "            p_to_xyz(flat_preds, split=False) < clf_dict[cat],\n",
    "            axis=1\n",
    "        )\n",
    "    )\n",
    "\n",
    "cat_num_samples = {}\n",
    "for cat in range(len(clf_dict)):\n",
    "    cat_num_samples[cat] = {}\n",
    "    print('='*60)\n",
    "    print('='*60)\n",
    "    print(f\"Category {cat} {f'3D outputs NOT< {clf_dict[cat-1]} AND ' if cat > 0 else ''}3D outputs < {clf_dict[cat]} AND 120 GeV < m_HH < 130 GeV\")\n",
    "    print('-'*60)\n",
    "    for m, sample_name in enumerate(order):\n",
    "        cat_num_samples[cat][sample_name] = np.sum(\n",
    "            flat_weights[\n",
    "                np.logical_and(  # event passes conditions and is the right type (i.e. sample)\n",
    "                    np.logical_and(  # event passes category and mass conditions\n",
    "                        cat_dict[cat],  # event passes category selections\n",
    "                        np.logical_and(  # diphoton mass is within 120-130 window\n",
    "                            flat_mass < 130,\n",
    "                            flat_mass > 120\n",
    "                        ),\n",
    "                    ),\n",
    "                    flat_truths == m\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "        print(f\"{cat}: Num {sample_name} = {cat_num_samples[cat][sample_name]:.4f}\")\n",
    "        print('-'*60)\n",
    "    print(f\"{cat}: S = {cat_num_samples[cat][order[0]]:.4f}, B = {np.sum([cat_num_samples[cat][order[v]] for v in range(1, len(order))]):.4f}, S/âB = {(cat_num_samples[cat][order[0]] / np.sqrt(np.sum([cat_num_samples[cat][order[v]] for v in range(1, len(order))]))):.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0: FÎ² (Î²=1) score = \n",
      "[3.92960986e-04 1.01874084e-01 5.90661366e-02 9.79408323e-01]\n",
      "fold 1: FÎ² (Î²=1) score = \n",
      "[3.69152187e-04 8.86786270e-02 4.68464860e-02 9.77694577e-01]\n",
      "fold 2: FÎ² (Î²=1) score = \n",
      "[3.58511629e-04 7.72140103e-02 4.91374774e-02 9.77605929e-01]\n",
      "fold 3: FÎ² (Î²=1) score = \n",
      "[3.70750046e-04 8.06271197e-02 4.11353837e-02 9.77874159e-01]\n",
      "fold 4: FÎ² (Î²=1) score = \n",
      "[3.87484035e-04 9.66763183e-02 4.94075289e-02 9.79008103e-01]\n",
      "Sum over folds: FÎ² (Î²=1) score = \n",
      "[3.75337993e-04 8.80499245e-02 4.85413652e-02 9.78316009e-01]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 900x700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 900x700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 900x700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 900x700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 900x700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 900x700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"confusion_matrix\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "if 'BDT_perf' not in globals():\n",
    "    with open(os.path.join(OUTPUT_DIRPATH, CURRENT_TIME+\"_BDT_perf.json\"), 'r') as f:\n",
    "        BDT_perf = json.load(f)\n",
    "\n",
    "beta = 1\n",
    "normalize = 'true'  # 'true' for normalize over rows, None for absoulte yields\n",
    "\n",
    "for fold_idx in range(len(BDT_perf['ggF HH']['preds'])):\n",
    "\n",
    "    pred_classes = np.argmax(BDT_perf['ggF HH']['preds'][fold_idx], axis=1)\n",
    "\n",
    "    conf_matrix = confusion_matrix(\n",
    "        bdt_test_dict[f\"fold_{fold_idx}\"].get_label(), \n",
    "        pred_classes,\n",
    "        sample_weight=weights_plot_test[f\"fold_{fold_idx}\"],\n",
    "        normalize=normalize\n",
    "    )\n",
    "\n",
    "    plot_confusion_matrix(\n",
    "        conf_matrix, order, f\"confusion_matrix_fold{fold_idx}{'_norm_'+normalize if normalize is not None else ''}\", plot_dirpath\n",
    "    )\n",
    "\n",
    "    f1_scores = fbeta_score(\n",
    "        bdt_test_dict[f\"fold_{fold_idx}\"].get_label(), \n",
    "        pred_classes,\n",
    "        beta=beta,\n",
    "        sample_weight=weights_plot_test[f\"fold_{fold_idx}\"], average=None\n",
    "    )\n",
    "    print(f\"fold {fold_idx}: FÎ² (Î²={beta}) score = \\n{f1_scores}\")\n",
    "\n",
    "full_pred_classes = np.argmax(\n",
    "    np.concatenate(\n",
    "        [\n",
    "            BDT_perf['ggF HH']['preds'][fold_idx] for fold_idx in range(len(BDT_perf['ggF HH']['preds']))\n",
    "        ]\n",
    "    ), axis=1\n",
    ")\n",
    "full_labels = np.concatenate(\n",
    "    [\n",
    "        bdt_test_dict[f\"fold_{fold_idx}\"].get_label() for fold_idx in range(len(BDT_perf['ggF HH']['preds']))\n",
    "    ]\n",
    ")\n",
    "full_weights = np.concatenate(\n",
    "    [\n",
    "        weights_plot_test[f\"fold_{fold_idx}\"] for fold_idx in range(len(BDT_perf['ggF HH']['preds']))\n",
    "    ]\n",
    ")\n",
    "\n",
    "conf_matrix = confusion_matrix(\n",
    "    full_labels, \n",
    "    full_pred_classes,\n",
    "    sample_weight=full_weights,\n",
    "    normalize=normalize\n",
    ")\n",
    "\n",
    "plot_confusion_matrix(\n",
    "    conf_matrix, order, f\"confusion_matrix_sum{'_norm_'+normalize if normalize is not None else ''}\", plot_dirpath\n",
    ")\n",
    "\n",
    "f1_scores = fbeta_score(\n",
    "    full_labels, \n",
    "    full_pred_classes,\n",
    "    beta=beta,\n",
    "    sample_weight=full_weights, average=None\n",
    ")\n",
    "print(f\"Sum over folds: FÎ² (Î²={beta}) score = \\n{f1_scores}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"variable_importance\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "for fold_idx in range(len(bdt_train_dict)):\n",
    "    booster = xgb.Booster(param, model_file=os.path.join(OUTPUT_DIRPATH, f'{CURRENT_TIME}_BDT_fold{fold_idx}.model'))\n",
    "\n",
    "    labels = copy.deepcopy([key for key in hlf_vars_columns_dict[f'fold_{fold_idx}'].keys()])\n",
    "    labels.sort()\n",
    "    \n",
    "    booster.feature_names = labels\n",
    "    score_dict = booster.get_score(importance_type='total_gain')\n",
    "\n",
    "    sorted_scores, sorted_labels = [], []\n",
    "    for label, score in score_dict.items():\n",
    "        sorted_scores.append(score)\n",
    "        sorted_labels.append(label)\n",
    "\n",
    "    sorted_labels = np.array(sorted_labels)[np.argsort(sorted_scores)]\n",
    "    sorted_scores = np.sort(sorted_scores)\n",
    "\n",
    "    plot_feature_importance(\n",
    "        sorted_scores, sorted_labels, f'xgb_importance_fold{fold_idx}', plot_dirpath\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Variable Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "------------------------------------------------------------\n",
      "mass                            1.000000\n",
      "HHbbggCandidate_mass            0.375709\n",
      "CosThetaStar_CS                 0.004460\n",
      "CosThetaStar_gg                 0.001330\n",
      "CosThetaStar_jj                 0.001529\n",
      "DeltaEta_jj                    -0.017657\n",
      "DeltaPhi_isr_jet_z              0.012729\n",
      "DeltaPhi_j1MET                 -0.000128\n",
      "DeltaPhi_j2MET                  0.000717\n",
      "DeltaPhi_jj                     0.001864\n",
      "DeltaR_jg_min                  -0.059714\n",
      "HHbbggCandidate_eta             0.004782\n",
      "HHbbggCandidate_pt              0.043332\n",
      "chi_t0                          0.006656\n",
      "chi_t1                          0.001299\n",
      "dijet_mass                      0.021438\n",
      "dijet_mass_over_Mggjj          -0.304632\n",
      "dijet_pt                        0.049606\n",
      "eta                             0.006297\n",
      "isr_jet_pt                      0.015894\n",
      "leadBjet_leadLepton            -0.055153\n",
      "lead_bjet_btagPNetB            -0.079635\n",
      "lead_bjet_eta                   0.001464\n",
      "lead_bjet_pt                    0.052944\n",
      "lead_bjet_pt_over_Mjj           0.044314\n",
      "lead_bjet_sigmapT_over_pT      -0.024856\n",
      "lead_mvaID                      0.025086\n",
      "lead_sigmaE_over_E             -0.060878\n",
      "lepton1_eta                    -0.055157\n",
      "lepton1_pt                     -0.054411\n",
      "n_jets                         -0.014539\n",
      "n_leptons                      -0.053621\n",
      "pt                              0.084853\n",
      "pt_balance                     -0.089345\n",
      "puppiMET_pt                    -0.031629\n",
      "puppiMET_sumEt                  0.192666\n",
      "subleadBjet_leadLepton         -0.055152\n",
      "sublead_bjet_btagPNetB         -0.064706\n",
      "sublead_bjet_eta               -0.000348\n",
      "sublead_bjet_pt                -0.008921\n",
      "sublead_bjet_pt_over_Mjj       -0.017221\n",
      "sublead_bjet_sigmapT_over_pT    0.012028\n",
      "sublead_mvaID                   0.033735\n",
      "sublead_sigmaE_over_E          -0.085996\n",
      "Name: mass, dtype: float64\n",
      "============================================================\n",
      "============================================================\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2205033/3023114728.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfold_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_aux_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmerged_pd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_df_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf\"fold_{fold_idx}\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mass'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'HHbbggCandidate_mass'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mmerged_pd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_aux_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf\"fold_{fold_idx}\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mdata_corr_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf\"fold_{fold_idx}\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerged_pd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"fold {fold_idx}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, method, min_periods, numeric_only)\u001b[0m\n\u001b[1;32m  11048\u001b[0m         \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11049\u001b[0m         \u001b[0mmat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11050\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11051\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"pearson\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 11052\u001b[0;31m             \u001b[0mcorrel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibalgos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnancorr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_periods\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  11053\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"spearman\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11054\u001b[0m             \u001b[0mcorrel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibalgos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnancorr_spearman\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_periods\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11055\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"kendall\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_corr_dict = {}\n",
    "for fold_idx in range(len(data_aux_dict)):\n",
    "    merged_pd = copy.deepcopy(data_df_dict[f\"fold_{fold_idx}\"])\n",
    "    for i, var_name in enumerate(['mass', 'HHbbggCandidate_mass']):\n",
    "        merged_pd.insert(i, var_name, data_aux_dict[f\"fold_{fold_idx}\"].loc[:, var_name])\n",
    "    data_corr_dict[f\"fold_{fold_idx}\"] = merged_pd.corr()\n",
    "\n",
    "    print(f\"fold {fold_idx}\")\n",
    "    print('-'*60)\n",
    "    print(data_corr_dict[f\"fold_{fold_idx}\"].iloc[0, :])\n",
    "    print(f\"{'='*60}\\n{'='*60}\\n{'='*60}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mass Sculpting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 38\u001b[0m\n\u001b[1;32m     32\u001b[0m train_hists[sample_name], val_hists[sample_name], test_hists[sample_name] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(), \u001b[38;5;28mlist\u001b[39m(), \u001b[38;5;28mlist\u001b[39m()\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m score_cut \u001b[38;5;129;01min\u001b[39;00m score_cuts:\n\u001b[1;32m     35\u001b[0m     train_mask \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     36\u001b[0m         xgb_label_train_dict[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfold_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m i\n\u001b[1;32m     37\u001b[0m     ) \u001b[38;5;241m&\u001b[39m (\n\u001b[0;32m---> 38\u001b[0m         \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBDT_perf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mggF HH\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain_preds\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfold_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[:, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m score_cut\n\u001b[1;32m     39\u001b[0m     )\n\u001b[1;32m     40\u001b[0m     val_mask \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     41\u001b[0m         xgb_label_val_dict[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfold_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m i\n\u001b[1;32m     42\u001b[0m     ) \u001b[38;5;241m&\u001b[39m (\n\u001b[1;32m     43\u001b[0m         np\u001b[38;5;241m.\u001b[39marray(BDT_perf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mggF HH\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_preds\u001b[39m\u001b[38;5;124m'\u001b[39m][fold_idx])[:, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m score_cut\n\u001b[1;32m     44\u001b[0m     )\n\u001b[1;32m     45\u001b[0m     test_mask \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     46\u001b[0m         xgb_label_test_dict[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfold_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m i\n\u001b[1;32m     47\u001b[0m     ) \u001b[38;5;241m&\u001b[39m (\n\u001b[1;32m     48\u001b[0m         np\u001b[38;5;241m.\u001b[39marray(BDT_perf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mggF HH\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreds\u001b[39m\u001b[38;5;124m'\u001b[39m][fold_idx])[:, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m score_cut\n\u001b[1;32m     49\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"mass_sculpting\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "if 'BDT_perf' not in globals():\n",
    "    with open(os.path.join(OUTPUT_DIRPATH, CURRENT_TIME+f\"_BDT_perf.json\"), 'r') as f:\n",
    "        BDT_perf = json.load(f)\n",
    "\n",
    "score_cuts = [0.0, 0.7, 0.99]\n",
    "label_arr = {\n",
    "    MC_NAMES_PRETTY[sample_name]: [f'score above {score_cut}' for score_cut in score_cuts] for sample_name in order\n",
    "}\n",
    "\n",
    "# Loop over and plot the per-fold variables\n",
    "for fold_idx in range(len(hlf_vars_columns_dict)):\n",
    "\n",
    "    for var_idx, var_name in enumerate(['mass', 'dijet_mass']):\n",
    "\n",
    "        plot_dirpath_ = os.path.join(plot_dirpath, var_name)\n",
    "        if not os.path.exists(plot_dirpath_):\n",
    "            os.makedirs(plot_dirpath_)\n",
    "\n",
    "        train_hists, val_hists, test_hists = {}, {}, {}\n",
    "        for i, sample_name in enumerate(order):\n",
    "\n",
    "            train_hists[sample_name], val_hists[sample_name], test_hists[sample_name] = list(), list(), list()\n",
    "            for score_cut in score_cuts:\n",
    "\n",
    "                train_mask = (\n",
    "                    xgb_label_train_dict[f'fold_{fold_idx}'] == i\n",
    "                ) & (\n",
    "                    np.array(BDT_perf['ggF HH']['train_preds'][fold_idx])[:, 0] > score_cut\n",
    "                )\n",
    "                val_mask = (\n",
    "                    xgb_label_val_dict[f'fold_{fold_idx}'] == i\n",
    "                ) & (\n",
    "                    np.array(BDT_perf['ggF HH']['val_preds'][fold_idx])[:, 0] > score_cut\n",
    "                )\n",
    "                test_mask = (\n",
    "                    xgb_label_test_dict[f'fold_{fold_idx}'] == i\n",
    "                ) & (\n",
    "                    np.array(BDT_perf['ggF HH']['preds'][fold_idx])[:, 0] > score_cut\n",
    "                )\n",
    "            \n",
    "                train_np = (\n",
    "                    data_aux_dict[f'fold_{fold_idx}'].iloc[train_idxs_dict[f'fold_{fold_idx}']]\n",
    "                ).loc[train_mask, var_name].to_numpy()\n",
    "                val_np = (\n",
    "                    data_aux_dict[f'fold_{fold_idx}'].iloc[val_idxs_dict[f'fold_{fold_idx}']]\n",
    "                ).loc[val_mask, var_name].to_numpy()\n",
    "                test_np = data_test_aux_dict[f'fold_{fold_idx}'].loc[test_mask, var_name].to_numpy()\n",
    "            \n",
    "                train_hists[sample_name].append(hist.Hist(VARIABLES[var_name]).fill(var=train_np))\n",
    "                val_hists[sample_name].append(hist.Hist(VARIABLES[var_name]).fill(var=val_np))\n",
    "                test_hists[sample_name].append(hist.Hist(VARIABLES[var_name]).fill(var=test_np))\n",
    "    \n",
    "            for j, (plot_type, histdict) in enumerate([('train_', train_hists), ('val_', val_hists), ('test_', test_hists)]):\n",
    "                make_input_plot(\n",
    "                    plot_dirpath_, var_name,\n",
    "                    histdict[sample_name], \n",
    "                    fold_idx=fold_idx, labels=label_arr[MC_NAMES_PRETTY[sample_name]], \n",
    "                    plot_prefix=plot_type+f'{sample_name}_scoreCut_'\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling for Mass Sculpting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_from_var(sample_var, sample_weight, n_events, n_samples_per_event=1, bins=100, seed=None):\n",
    "    resample_rng = np.random.default_rng(seed=seed)\n",
    "\n",
    "    np_hist, bin_edges = np.histogram(sample_var, bins=bins, weights=sample_weight, density=True)\n",
    "    np_hist /= np.sum(np_hist)\n",
    "\n",
    "    bin_choices = resample_rng.choice(np.arange(len(np_hist)), size=n_events*n_samples_per_event, p=np_hist)\n",
    "\n",
    "    value_choices = (bin_edges[bin_choices+1] - bin_edges[bin_choices]) * resample_rng.random(size=n_events*n_samples_per_event) + bin_edges[bin_choices]\n",
    "\n",
    "    return value_choices\n",
    "\n",
    "def resample_grow_np(var, bool_arr, n_duplicates_per_event):\n",
    "    new_rows_shape = tuple([n_duplicates_per_event]+[1 for _ in range(1, len(np.shape(var)))])\n",
    "    new_rows = np.tile(\n",
    "        var[bool_arr],\n",
    "        new_rows_shape\n",
    "    )\n",
    "    return np.concatenate([var, new_rows])\n",
    "def resample_grow_pd(var, bool_arr, n_duplicates_per_event):\n",
    "    new_rows = pd.DataFrame(\n",
    "        np.tile(\n",
    "            ( var.loc[bool_arr] ).to_numpy(),\n",
    "            (n_duplicates_per_event, 1)\n",
    "        ),\n",
    "        columns=var.columns\n",
    "    )\n",
    "    return pd.concat([var, new_rows], ignore_index=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAAM1CAYAAACVFavbAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABfSklEQVR4nO3de5RX5X0v/vdwB0EBiaMyVrxVxSLVRoitbdDES1RiTZOoCcdjUry0E5GYlYs263hLJef8TmIwTk8NtdLkaDSJv/6M+gsxseHXmKh41ByDWESIWoc4gFwFwyDs3x+emTLOxZk9l+8wvF5rzcJ+n+fZ+9nTZ5Hvm8/ez64qiqIIAAAAXTKo0hMAAADYEwlTAAAAJQhTAAAAJQhTAAAAJQhTAAAAJQhTAAAAJQhTAAAAJQhTAAAAJQyp9AT6g3322Se/+93vMnjw4BxwwAGVng4AAFAha9asyc6dOzNixIhs3bq1w75VRVEUfTSvfmvw4MHZtWtXpacBAAD0E4MGDcrOnTs77KMylf8IU4MGDcpBBx1U6emkKIqsXr06Bx98cKqqqio9nTQ0NKS6urrS00hiLm3pb+sl6T+/m8Rc2mLNdMxcWrNmOmYurfW3NdNffi9N+tN8+stc+tOa+e1vf5tdu3Zl8ODB79pXZSpJTU1N6uvrM3HixLz66quVnk42b96c/fbbL5s2bcq+++5b6elk8uTJWbZsWaWnkcRc2tLf1kvSf343ibm0xZrpmLm0Zs10zFxa629rpr/8Xpr0p/n0l7n0pzXTlWxgAwoAAIASSoepRx55JOeee24OO+yw7Lfffpk+fXq+/OUvZ9u2bW32X758eS666KIceOCBGTVqVKZOnZpvfvOb6agwtmTJksycOTMTJkzI6NGjM3369Nx1110dzmvRokU57bTTMnbs2IwdOzannnpqFi1aVPYyAQAA2lQqTP3X//pfc/rpp+ehhx7K6tWrM3z48CxZsiR/+7d/mylTpuT1119v0f+pp57KSSedlHvuuSdr1qzJsGHD8uyzz2bOnDmZNWtWm+d46KGHcsopp+TBBx/Mpk2bUlVVlSVLlmTWrFm59tpr2xxz++235+yzz87PfvazbN++Pdu3b8/ixYtz9tln5/bbby9zqQAAAG3qcph6+eWX81/+y3/JkCFD8vd///d54403smbNmqxYsSInnXRSVq1alc9//vPN/Xft2pVPfvKT2bJlSy6++OK89tprWb9+fX76059mzJgxufvuu1tVmzZv3pyLL744O3bsyJe+9KWsW7cu69evzz333JMhQ4Zk3rx5efTRR1uMWbVqVebMmZOiKHLrrbfm9ddfz+uvv55vfOMbKYoic+bMyapVq0r+mgAAAFrqcpiqq6tLY2Nj/tN/+k+5/PLLM3To0CTJkUceme9+97sZPHhw7rrrrrz11ltJkvvvvz/Lly/P8ccfnwULFuSAAw7IoEGD8oEPfKC5WvS1r32txTnuuOOOrF+/PmeddVZuvvnm7Lfffhk6dGguuOCC3HjjjUmSr3/96y3GzJ8/P42Njbn88stz5ZVXZtSoURk1alSuuuqqXHbZZWlsbMxtt93W9d8QAABAG7ocppYvX54k+chHPtKq7Ygjjshhhx2WxsbG5irQAw88kCT5xCc+kWHDhrXo/9GPfjSjR4/OM88802KnjKYxl1xySautES+55JIkyY9//OM0Nja2GvOpT32q1byaPmvqQ9fU1tZWegrNzGXP0J9+N+ayZ+hPvxtz2TP0p9+NufR//e330p/m05/msifq8tboJ598cpYuXZpf/OIXOf7441u1T506Nc8++2yefPLJvPe9782xxx6bf/u3f8szzzyTP/zDP2zV/7zzzssPf/jDfP/7389HP/rRFEWR0aNH580338y6desyfvz4dz1HQ0NDDjzwwIwbNy7r1q3LoEEtM+KuXbsyYcKEbNiwIWvXrs2ECRNatNsanT2Z9UJXWTN0lTVDV1kzdFV/WjO9ujX6Y489li1btrQZpNatW5cXX3wxw4YNy1FHHZVdu3Y1V6iOPPLINo93xBFHJElWrlyZJFm9enW2bduW8ePHtxmk2hrz4osvJkkOP/zwVkEqefvtxZMmTWoxBgAAoDu6/Z6p7du3Z/Xq1XnooYdy7rnnZtu2bbn00kuz3377ZfPmzWlsbMyQIUMyevToNsc3BaaGhoYkydq1a5MkY8eObfecPTEGAACgO4Z09wB/8Ad/0FwZSpI5c+bkv//3/54kze+c6ijkjBs3rkXfpj+bPu+tMW0piiKbN29ut/3dDB8+PMOHDy89HgAA6J6mVySV1ZWnoLodpn7v934vW7duzWuvvZaiKHLffffl7LPPzplnntk8kY4mNHjw4CTJzp07W/Tt7TFtWb16dfbbb79229/Nddddl+uvv770eAAAoHvmzZuXG264oU/O1e0w9cgjjyRJtmzZkv/23/5bvvKVr+S8887L888/31wN2rhxY4qiaLUzX/IflaJ99tmnxZ8bNmxo95w9MaYtBx98cJ5//vl229+NqhQAAFTWNddck6uvvrr0+GOPPTarV6/uVN9uh6kmY8aMyU033ZSlS5fm//l//p/cfffdueaaazJs2LA0NjbmjTfeyJgxY1qNW7NmTZI077DX9OfGjRvbPVdPjGlLVVVVxXcPAQAAyuvuozdtFYDa06UNKNauXZvbb789d999d7t9ZsyYkSR5+eWXM2jQoBx++OFJkhdeeKHN/s8991yS5KijjkqSTJw4MaNGjcqGDRuybt26To1p+nPlypVt3sa3c+fO5vdjNfUFAADoji6FqUGDBuWKK67IpZde2m6fTZs2JXn7lrnk7fdSJcnDDz/cqm9jY2MWL16cJHnf+96X5O0kOH369BRFkZ/85CetxqxevTpLly7NyJEjM3Xq1CRJdXV1Jk2alE2bNmXJkiWtxjzxxBPZuHFjJk2alOrq6i5ccWUMHz481113ndsG6RTrha6yZugqa4ausmboqj11zXQpTO2///459NBDs23btjz66KOt2nft2pUf/vCHSdL8HqqZM2cmSe6+++5Wu2r84Ac/yBtvvJGpU6fm0EMPbf68aczChQtbbSqxcOHCJMkZZ5yRESNGNH/+4Q9/OEly5513tppX05jzzjuv09daScOHD8/111+/xy0mKsN6oausGbrKmqGrrBm6ak9dM11+z9QVV1yRJPn0pz+dxx57rPnz1157LRdffHGeeuqpHHfccTnnnHOSvB1gjjnmmCxdujSXX3551q5dm507d+aRRx5pPtYXv/jFFueYPXt29t9//zz88MO59tprm99Xde+99+a6665LVVVVvvCFL7QYM3fu3AwbNiwLFizIbbfdljfffDNbt27N/Pnzs2DBggwbNixz587t6uUCAAC0qaroykbqSXbs2JE/+7M/y+OPP57k7d3x9tlnn+YNHg488MA89NBDOfHEE5vHPP3005kxY0a2bNmSQYMGZfTo0c3vc5o1a1a+853vtDrPQw89lPPPPz87duzI0KFDM2zYsGzdujVJ8uUvfzk33XRTqzHf+ta3csUVV6QoiowcOTK7du3K9u3bU1VVlW9961uZPXt2m9dUU1OT+vr6TJw4Ma+++mpXfh0AAMAA0pVs0OXK1NChQ/Poo49m/vz5+ZM/+ZPss88+aWxszMknn5wvfvGLWb58eYsglSQnnnhinnzyyVxwwQXZf//909jYmClTpuS2227Lt7/97TbPc8455+TRRx/NOeeck9GjRydJpk2blrvvvrvNIJUkl112WX70ox9lxowZGTp0aIYPH54ZM2Zk0aJF7QYpAACAMrpcmRqIVKYAAICklytTAAAACFMAAAClCFMAAAAlCFMAAAAlCFMAAAAlCFMAAAAlCFMAAAAlCFMAAAAlCFMAAAAlCFMAAAAlCFMAAAAlCFMAAAAlCFMAAAAlCFMAALAXmDF/RaWnMOAIUwAAACUMqfQE+pOGhoZMnjy5zbba2trU1tb28YwAAICeVldXl7q6ujbbGhoaOn0cYWo31dXVWbZsWaWnAQAA9KKOCiU1NTWpr6/v1HHc5gcAAFCCMAUAAFCCMAUAAFCCMAUAAFCCMAUAAFCCMAUAAHuZGfNXeIlvDxCmAAAAShCmAAAAShCmAABggHDrXt8SpgAAgA55xqptQyo9AQAAoPcIQb1HZQoAAKAElSkAANhLqFL1LJUpAACAEoQpAAAYQHp6swjVrPYJUwAAACUIUwAAACUIUwAAACUIUwAAsJfzXFQ5whQAAEAJ3jMFAAB7KRWp7lGZAgCAPUxPb39OOcIUAABACcIUAABACZ6Z2k1DQ0MmT57cZlttbW1qa2v7eEYAAEBPq6urS11dXZttDQ0NnT6OMLWb6urqLFu2rNLTAAAAelFHhZKamprU19d36jjCFAAA9ENNG0wsvuqobo2n93hmCgAAsENgCcIUAABACW7zAwCAPUhfVY9Uqd6dyhQAAEAJwhQAAEAJbvMDAIA9gNv7+h+VKQAAgBKEKQAAgBKEKQAAgBKEKQAAgBJsQAEAAHs4m0ZUhsoUAABACcIUAABACcIUAABACcIUAABACcIUAABACcIUAABACbZGBwCAPZQt0StLZQoAAKAEYQoAAKAEYQoAAKAEYQoAAKAEG1DspqGhIZMnT26zrba2NrW1tX08IwAAoKfV1dWlrq6uzbaGhoZOH0eY2k11dXWWLVtW6WkAAAC9qKNCSU1NTerr6zt1HLf5AQAAlCBMAQAAlCBMAQAAlCBMAQAAlCBMAQAAlCBMAQBAhcyYvyIz5q+o9DQoydboAADQjwlb/ZfKFAAAQAnCFAAAQAnCFAAA0CWe9XqbZ6YAAKDCdg8mi686qoIzoStUpgAAAEoQpgAAoA+4NW7gEaYAAABKEKYAAABKsAEFAAD0Irf2DVwqUwAAACUIUwAAACUIUwAAACV4ZgoAAPoRz1jtOVSmAACgm7xDau8kTAEAAJQgTAEAAJTgmandNDQ0ZPLkyW221dbWpra2to9nBAAA9LS6urrU1dW12dbQ0NDp4whTu6murs6yZcsqPQ0AAOiXBspzYR0VSmpqalJfX9+p47jNDwAAoARhCgAAoARhCgAAoATPTAEAQC/o6PmigfLs0d5OZQoAAKAEYQoAAPqQqtTAIUwBAACUIEwBAACUIEwBAACUIEwBAACUIEwBAACUIEwBAACUIEwBAACUIEwBAACUIEwBAACUUDpMvfTSS/nP//k/Z+rUqRk9enSmTJmST3/603n55Zd7bHJLlizJzJkzM2HChIwePTrTp0/PXXfd1eGYRYsW5bTTTsvYsWMzduzYnHrqqVm0aFGPzQkAAN7NjPkrKj0F+kCpMPWjH/0oU6ZMybe//e38+te/zujRo/Pcc8/lzjvvzJQpU3L//fe36P+Rj3wkVVVV7f6ccMIJrc7x0EMP5ZRTTsmDDz6YTZs2paqqKkuWLMmsWbNy7bXXtjmv22+/PWeffXZ+9rOfZfv27dm+fXsWL16cs88+O7fffnuZSwUAgBZmzF8hLP0fe/vvosthaseOHfnMZz6TN954I5deemk2btyY1157LRs2bMjcuXOzZcuWfPrTn86aNWuax6xY8fYv+IgjjsiRRx7Z6ueQQw5pcY7Nmzfn4osvzo4dO/KlL30p69aty/r163PPPfdkyJAhmTdvXh599NEWY1atWpU5c+akKIrceuutef311/P666/nG9/4RoqiyJw5c7Jq1aoyvyMAAIBWuhym7r333qxatSrHHXdcbr/99uy7775Jkv322y+33HJLPv7xj2f9+vW59dZbkyRFUWTlypUZN25cXnzxxaxYsaLVzw9/+MMW57jjjjuyfv36nHXWWbn55puz3377ZejQobngggty4403Jkm+/vWvtxgzf/78NDY25vLLL8+VV16ZUaNGZdSoUbnqqqty2WWXpbGxMbfddlupXxIAAMA7dTlMLVu2LEkya9asVFVVtWr/1Kc+lSR55plnkiT19fV58803c/TRR3f6HA888ECS5JJLLml1jksuuSRJ8uMf/ziNjY2txjSdv605NfUBAADori6HqZdeeilJMmnSpDbbDzrooBb9XnzxxSTpdJgqiiJPPPFEqqqqcvrpp7d5/OOPPz7btm3Ls88+myRpaGjIb37zm4wbNy4nnXRSqzHTpk1rroytW7euU/MAAADoSJfD1NVXX51Fixblgx/8YJvtTz75ZJI0PwfV9LzUpEmTMn/+/HzoQx/KCSeckFmzZuUf/uEfsmvXrhbjV69enW3btmX8+PEZP358m+c44ogjkiQrV65M8h+B7fDDD8+gQa0vadCgQc3hr2kMAAD0tL19Q4a9zZCuDnjve9/bbtuGDRsyb968JMlZZ52V5D+Czrx581rclverX/0qd911V77zne/ke9/7Xqqrq5Mka9euTZKMHTu23fM0hayGhobSY9pSFEU2b97cbvu7GT58eIYPH156PAAA0D1Nu3qXVRRFp/v22Et7V61alQ984ANZtWpVDj744PzlX/5lkv+oTI0aNSrf+ta38tJLL6WhoSH33ntvDjrooPzrv/5r5s6d23ycbdu2JUnGjRvX7rma2pr6lhnTltWrV2e//fYr/dMUJAEAgMqYN29et77Tr169utPn6nJl6p127NiRW265JTfccEO2bduWffbZJ/fff3/GjBmTJDnmmGNy4YUX5rOf/WymTZvWPO7jH/94TjjhhBx33HG555578vnPfz4nnnhicxLsKBEOHjw4SbJz584Wfbsypi0HH3xwnn/++c5cdptUpQAAoLKuueaaXH311aXHH3vssZ0OVN0KU88//3wuvPDC5o0gjjvuuHzve9/L5MmTm/vcfPPN7Y4/6qij8rGPfSx33313Hn/88Zx44onZZ599krx9y2B7mqpLTX3LjGlLVVVV81bvAADAnqe7j960tWN5e0rf5rdw4cK8973vzbPPPpuRI0fmpptuylNPPdUiSHXGlClTkvzHlusTJkxIkmzcuLHdMU0vBG7qW2YMAABAd5SqTN1333359Kc/naIocuqpp+bOO+/MoYceWmoCTZWiptsCJ06cmFGjRmXDhg1Zt25dm+HnueeeS/J2ZWv3P1euXJmdO3c239LXZOfOnVm+fHmLvgAAAN3R5crUK6+8kosvvjhFUWTu3Ln56U9/2m6Q+vWvf50pU6bkvPPOa/d4TSGnqaJVVVWV6dOnpyiK/OQnP2nVf/Xq1Vm6dGlGjhyZqVOnJkmqq6szadKkbNq0KUuWLGk15oknnsjGjRszadKk5l0DAQAAuqPLYeof//Efs23btpx77rm55ZZb2nyvU5Pjjjsua9asyQ9/+MM89thjrdo3bNiQ7373uxkyZEj++I//uPnzmTNnJnn7VsJ3biqxcOHCJMkZZ5yRESNGNH/+4Q9/OEly5513tjpP05iOQh0AAEBXdDlM3XvvvUmSz3/+8+9+8EGDcumllyZJLrzwwvz85z9vbnvuuedy9tlnZ/369bnyyiubX8SbJLNnz87++++fhx9+ONdee202b96cxsbG3HvvvbnuuutSVVWVL3zhCy3ONXfu3AwbNiwLFizIbbfdljfffDNbt27N/Pnzs2DBggwbNqzFFuwAAADdUVV04a1Uu3btyogRI7Jjx45MmjQpQ4a0/8jVH/3RH+Wee+7JW2+9ldNOO605SO23335Jkk2bNiV5++W+9957b6td9B566KGcf/752bFjR4YOHZphw4Zl69atSZIvf/nLuemmm1qd81vf+lauuOKKFEWRkSNHZteuXdm+fXuqqqryrW99K7Nnz25zrjU1Namvr8/EiRPz6quvdvbXAQDAXmjG/Lffo7r4qqNafba32v13safrSjbo0gYUq1evzo4dO5IkL730Uod9DzzwwLdPMGRIHnnkkdx+++359re/nZUrV2bIkCE588wzc/755+fyyy9vc/w555yTRx99NDfeeGN++ctfprGxMdOmTcvcuXNz0UUXtTnmsssuy6GHHpqvfvWrefrpp5MkJ598cq655pqcccYZXblUAACADnWpMjVQqUwBANBZKlOt7a2VqdLvmQIAANibCVMAAEC37K2VuVIv7QUAgL3N3hoYaJ/KFAAAQAnCFAAAQAnCFAAAQAnCFAAAlOAZKoQpAACAEoQpAACAEmyNDgAAJbnVb++mMgUAAFCCMAUAAFCCMAUAAFCCMAUAAFCCDSh209DQkMmTJ7fZVltbm9ra2j6eEQAA0NPq6upSV1fXZltDQ0OnjyNM7aa6ujrLli2r9DQAAIBe1FGhpKamJvX19Z06jtv8AAAAShCmAAAAShCmAAAAShCmAAAAShCmAACAbpsxf0VmzF9R6Wn0Kbv5AQDAO+weChZfdVQFZ0J/pjIFAABQgjAFAABQgjAFAABQgjAFAABQgjAFAABQgjAFAABQgjAFAABQgvdMAQBAB/a2F9HSeSpTAAAAJQhTAADs9WbMX6ECRZcJUwAAACUIUwAAACUIUwAAACUIUwAAACUIUwAAACUIUwAAACUIUwAAACUIUwAAACUMqfQE+pOGhoZMnjy5zbba2trU1tb28YwAAICeVldXl7q6ujbbGhoaOn0cYWo31dXVWbZsWaWnAQAA9KKOCiU1NTWpr6/v1HGEKQAA9goz5q9Ikiy+6qh37QOd4ZkpAAD2KjPmrxCa6BHCFAAA0GP2prAqTAEAAJQgTAEAAJQgTAEAAJQgTAEAAJQgTAEAAJQgTAEAAJQgTAEAAJQgTAEAAJQgTAEAAJQgTAEAsFeaMX9FpafAHk6YAgAAKGFIpScAAACVojpFd6hMAQAAlCBMAQAAlCBMAQAAlCBMAQAAlCBMAQAAlCBMAQAAlCBMAQAAlCBMAQAAlOClvbtpaGjI5MmT22yrra1NbW1tH88IAIAmTS/YXXzVURWeCXu6urq61NXVtdnW0NDQ6eMIU7uprq7OsmXLKj0NAACgF3VUKKmpqUl9fX2njiNMAQAw4OxexWr6b+hpnpkCAAAoQWUKAIABQxWKvqQyBQAAUIIwBQAAUIIwBQDAgOW2P3qTMAUAAFCCMAUAwB5lxvwVKk70C8IUAABACcIUAABACcIUAABACV7aCwDAHmn356YWX3VUBWfC3kplCgAAoARhCgAAoARhCgAAoARhCgAAoARhCgAAoARhCgAAoARhCgCAfmvG/BUttkCH/kSYAgAAKMFLewEA2OOpXvU/Tf8/GcgvVBamAADod4Qj9gRu8wMAAChBZWo3DQ0NmTx5cptttbW1qa2t7eMZAQAAPa2uri51dXVttjU0NHT6OMLUbqqrq7Ns2bJKTwMAAOhFHRVKampqUl9f36njuM0PAACgBGEKAIB+z4YU9EfCFAAAQAnCFAAAQAnCFAAAQAnCFAAAQAnCFAAAQAnCFAAAPWbG/BV23mOvIUwBAACUIEwBAACUMKTSEwAAgCZuEWRPojIFAABQgjAFAABQgjAFAABQgjAFAABQQukw9dJLL+U//+f/nKlTp2b06NGZMmVKPv3pT+fll19us//y5ctz0UUX5cADD8yoUaMyderUfPOb30xRFO2eY8mSJZk5c2YmTJiQ0aNHZ/r06bnrrrs6nNeiRYty2mmnZezYsRk7dmxOPfXULFq0qOxlAgDQy7ybij1VqTD1ox/9KFOmTMm3v/3t/PrXv87o0aPz3HPP5c4778yUKVNy//33t+j/1FNP5aSTTso999yTNWvWZNiwYXn22WczZ86czJo1q81zPPTQQznllFPy4IMPZtOmTamqqsqSJUsya9asXHvttW2Ouf3223P22WfnZz/7WbZv357t27dn8eLFOfvss3P77beXuVQAAHqQ0MRA0uUwtWPHjnzmM5/JG2+8kUsvvTQbN27Ma6+9lg0bNmTu3LnZsmVLPv3pT2fNmjVJkl27duWTn/xktmzZkosvvjivvfZa1q9fn5/+9KcZM2ZM7r777lbVps2bN+fiiy/Ojh078qUvfSnr1q3L+vXrc88992TIkCGZN29eHn300RZjVq1alTlz5qQoitx66615/fXX8/rrr+cb3/hGiqLInDlzsmrVqm78qgAAKEv1iYGoy2Hq3nvvzapVq3Lcccfl9ttvz7777psk2W+//XLLLbfk4x//eNavX59bb701SXL//fdn+fLlOf7447NgwYIccMABGTRoUD7wgQ80V4u+9rWvtTjHHXfckfXr1+ess87KzTffnP322y9Dhw7NBRdckBtvvDFJ8vWvf73FmPnz56exsTGXX355rrzyyowaNSqjRo3KVVddlcsuuyyNjY257bbbuv4bAgAAaEOXw9SyZcuSJLNmzUpVVVWr9k996lNJkmeeeSZJ8sADDyRJPvGJT2TYsGEt+n70ox/N6NGj88wzz+TVV19t/rxpzCWXXNLqHJdcckmS5Mc//nEaGxtbjWk6f1tzauoDAEDfUJFiIOtymHrppZeSJJMmTWqz/aCDDmrR77HHHkuSnHnmma36Dh06NKeddlqS5PHHH0+SFEWRJ554IlVVVTn99NPbPP7xxx+fbdu25dlnn02SNDQ05De/+U3GjRuXk046qdWYadOmZdy4cXnxxRezbt26zl8sAABAO7ocpq6++uosWrQoH/zgB9tsf/LJJ5MkhxxySHbt2tX8nNKRRx7ZZv8jjjgiSbJy5cokyerVq7Nt27aMHz8+48eP79SYF198MUly+OGHZ9Cg1pc0aNCg5vDXNAYAAKA7hnR1wHvf+9522zZs2JB58+YlSc4666xs3rw5jY2NGTJkSEaPHt3mmKbA1NDQkCRZu3ZtkmTs2LHtnqcnxrSlKIps3ry53fZ3M3z48AwfPrz0eACAvUHTbX+LrzqqwjNhIGra1busjl7d9E5dDlPtWbVqVT760Y9m1apVOfjgg/OXf/mX2bJlS5KOQ864ceOSJNu2bWvxZ9PnvTWmLatXr85+++3Xbvu7ue6663L99deXHg8AAHTPvHnzcsMNN/TJubodpnbs2JFbbrklN9xwQ7Zt25Z99tkn999/f8aMGdNc5eko3Q0ePDhJsnPnzhZ9e3tMWw4++OA8//zz7ba/G1UpAIDOszEFveGaa67J1VdfXXr8sccem9WrV3eqb7fC1PPPP58LL7yweSOI4447Lt/73vcyefLkJMk+++yTJNm4cWOKomhz97+mSlFT36Y/N2zY0O55e2JMW6qqqpq3egcAAPY83X30pq3M0p4ub0DRZOHChXnve9+bZ599NiNHjsxNN92Up556qjlIJcm+++6bYcOGZefOnXnjjTfaPE7Ty30nTJjQ4s+NGze2e+6eGAMAQP+iUsWeplSYuu+++/LpT38627Zty6mnnprnn38+X/7yl1slwEGDBuXwww9PkrzwwgttHuu5555Lkhx11NsPIE6cODGjRo3Khg0b2t3G/J1jmv5cuXJlm7fx7dy5M8uXL2/RFwCAcrw7Ct7W5TD1yiuv5OKLL05RFJk7d25++tOf5tBDD223/8knn5wkefjhh1u1NTY2ZvHixUmS973vfUneLqtNnz49RVHkJz/5Sasxq1evztKlSzNy5MhMnTo1SVJdXZ1JkyZl06ZNWbJkSasxTzzxRDZu3JhJkyalurq6q5cMAADQSpfD1D/+4z9m27ZtOffcc3PLLbe0+V6n3c2cOTNJcvfdd7faovAHP/hB3njjjUydOrVFIGsas3DhwlabSixcuDBJcsYZZ2TEiBHNn3/4wx9Oktx5552t5tA05rzzzuvEFQIAALy7Loepe++9N0ny+c9/vlP9zzvvvBxzzDFZunRpLr/88qxduzY7d+7MI488kiuuuCJJ8sUvfrHFmNmzZ2f//ffPww8/nGuvvbb5fVX33ntvrrvuulRVVeULX/hCizFz587NsGHDsmDBgtx222158803s3Xr1syfPz8LFizIsGHDMnfu3K5eLgAAQJuqii68lWrXrl0ZMWJEduzYkUmTJmXIkPY3A/yjP/qj3HPPPUmSp59+OjNmzMiWLVsyaNCgjB49unnb9FmzZuU73/lOq/EPPfRQzj///OzYsSNDhw7NsGHDsnXr1iTJl7/85dx0002txnzrW9/KFVdckaIoMnLkyOzatSvbt29PVVVVvvWtb2X27NltzrWmpib19fWZOHFiXn311c7+OgAA9kodvXT3nW2erWJPezlzV7JBl7ZGX716dXbs2JEkeemllzrse+CBBzb/94knnpgnn3wy1113Xf7lX/4lW7ZsyZQpU3L55Zfnr//6r9scf8455+TRRx/NjTfemF/+8pdpbGzMtGnTMnfu3Fx00UVtjrnsssty6KGH5qtf/WqefvrpJG8/s3XNNdfkjDPO6MqlAgAAdKhLYaqmpqbDF+N25Oijj26uVHXWtGnT8uCDD3ZpzJlnnpkzzzyzS2MAACivo0oVzJi/YsCujdLvmQIAANibCVMAAAAldOk2PwAABr7dN40YqLdnQU9QmQIAAChBmAIAAChBmAIAAChBmAIA2IvMmL/Ci3ShhwhTAAAAJQhTAAC0SyUL2idMAQAAlCBMAQAAlCBMAQAAlCBMAQAAlCBMAQAAlCBMAQAAlDCk0hPoTxoaGjJ58uQ222pra1NbW9vHMwIA6L9smc6eqq6uLnV1dW22NTQ0dPo4wtRuqqurs2zZskpPAwCgIoQj9hYdFUpqampSX1/fqeO4zQ8AgB4hjLG3UZkCAKDHCVbsDVSmAADoNCEJ/oMwBQAAUILb/AAA9gIqStDzhCkAAN6VMAatuc0PAACgBGEKAGAvpNIE3SdMAQAAlCBMAQAAlCBMAQAAlGA3PwCAvZznp6AclSkAAIAShCkAAIAShCkAAIAShCkAAIASbEABADCA2VwCeo/KFAAAQAnCFAAAQAnCFADAAOUWP+hdwhQAAEAJwhQAwB5uxvwVqlBQAXbzAwDYSwlg0D3C1G4aGhoyefLkNttqa2tTW1vbxzMCAAB6Wl1dXerq6tpsa2ho6PRxhKndVFdXZ9myZZWeBgAA0Is6KpTU1NSkvr6+U8cRpgAA9lBu04PKsgEFAABACSpTAAADjIoV9A2VKQAAgBKEKQAAgBKEKQAAgBKEKQCAfmzG/BWegYJ+SpgCAAAoQZgCANgDqFBB/yNMAQAAlCBMAQAAvWqgVlaFKQAAgBKEKQCAfmKg/us9DFRDKj0BAAB6hiAGfUtlCgCgnxKOoH8TpgAAAEoQpgAAAEoQpgAAAEoQpgAAAEoQpgAAAEoQpgAAAEoQpgAAAEoQpgAAKmDG/BXeIwV7uCGVnkB/0tDQkMmTJ7fZVltbm9ra2j6eEQAA0NPq6upSV1fXZltDQ0OnjyNM7aa6ujrLli2r9DQAAIBe1FGhpKamJvX19Z06jtv8AAAAShCmAAAAShCmAAAAShCmAAAAShCmAAAASrCbHwBAhXnfFOyZVKYAAABKEKYAAABKEKYAAPZAbg2EyvPMFABAHxKCYOAQpgAA9iDCGPQfbvMDAOghM+avEHZgLyJMAQAAlOA2PwCAEt5ZgVp81VEVmglQKSpTAAA9zO1+sHcQpgAAAEoQpgAAAEoQpgAAAEoQpgAAAEqwmx8AQD9j8wrYM6hMAQAAlKAyBQDQB1SbYOBRmQIAqCAhC/ZcKlO7aWhoyOTJk9tsq62tTW1tbR/PCADYkzUFpcVXHVXhmQC7q6urS11dXZttDQ0NnT6OMLWb6urqLFu2rNLTAAAAelFHhZKamprU19d36jhu8wMAAChBmAIAAChBmAIABhQbOgB9RZgCAAAoQZgCAAAoQZgCAOhlbj2EgUmYAgAAKEGYAgDoAapPsPcRpgCAPdKM+SsEGKCihCkAAIAShCkAYK+ksgV0lzAFAABQgjAFAABQwpBKTwAAYE/i1kCgicoUAMD/8c7nqDxXBXSk22Fq3rx5qaqqys6dO3tiPs2WLFmSmTNnZsKECRk9enSmT5+eu+66q8MxixYtymmnnZaxY8dm7NixOfXUU7No0aIenRcAAEDSzTBVFEW+973vddjnIx/5SKqqqtr9OeGEE1qNeeihh3LKKafkwQcfzKZNm1JVVZUlS5Zk1qxZufbaa9s8z+23356zzz47P/vZz7J9+/Zs3749ixcvztlnn53bb7+9O5cJAKBKBbRSOkzt3LkzN954Y371q1912G/Firf/0jniiCNy5JFHtvo55JBDWvTfvHlzLr744uzYsSNf+tKXsm7duqxfvz733HNPhgwZknnz5uXRRx9tMWbVqlWZM2dOiqLIrbfemtdffz2vv/56vvGNb6QoisyZMyerVq0qe6kAAACtdHkDigcffDD33XdfFi9enJdeeqnDvkVRZOXKlRk3blxefPHFTh3/jjvuyPr163PWWWfl5ptvTlVVVZLkggsuyKpVq3Lttdfm61//ek455ZTmMfPnz09jY2Muv/zyXHnllc2fX3XVVVm2bFm+9a1v5bbbbsvXv/71rl4uAADQQ5qqu4uvOqrCM+kZXa5M3XfffVm4cOG7Bqkkqa+vz5tvvpmjjz6608d/4IEHkiSXXHJJc5BqcskllyRJfvzjH6exsbHVmE996lOtjtf0WVMfAIDduX0PKKvLYeorX/lKli5d2vzTkaZqVGfDVFEUeeKJJ1JVVZXTTz+9VftBBx2U448/Ptu2bcuzzz6bJGloaMhvfvObjBs3LieddFKrMdOmTWuujK1bt65T8wAA9j4dBSphC2hLl8PUxIkTc9xxxzX/dKTpealJkyZl/vz5+dCHPpQTTjghs2bNyj/8wz9k165dLfqvXr0627Zty/jx4zN+/Pg2j3nEEUckSVauXJnkPwLb4YcfnkGDWl/OoEGDMmnSpBZjAAAAuqtXX9rbFHTmzZvX4ra8X/3qV7nrrrvyne98J9/73vdSXV2dJFm7dm2SZOzYse0esylkNTQ0lB7TnqIosnnz5g77dGT48OEZPnx46fEAQP+gEgV7rqadvcsqiqLTfXs1TDVVpkaNGpXbbrstZ5xxRkaOHJnFixdn7ty5+dd//dfMnTs33/3ud5Mk27ZtS5KMGzeu3WM2tTX1LTOmPatXr85+++3XmUtr03XXXZfrr7++9HgAAKB75s2blxtuuKFPztWrYeqYY47JhRdemM9+9rOZNm1a8+cf//jHc8IJJ+S4447LPffck89//vM58cQTm1NgR2lw8ODBSdL8kuAyY9pz8MEH5/nnn+/ElbVNVQoA+obKEdCea665JldffXXp8ccee2xWr17dqb69GqZuvvnmdtuOOuqofOxjH8vdd9+dxx9/PCeeeGL22WefJMmGDRvaHddUXWrqW2ZMe6qqqrLvvvt22AcAAOi/uvvozTt3FO9I6Zf29oQpU6YkSZYtW5YkmTBhQpJk48aN7Y5Zs2ZNi75lxgAAAHRXRcNUU6VozJgxSd7eKXDUqFHZsGFDu9uYP/fcc0nermzt/ufKlSvbvI1v586dWb58eYu+AAAA3dVrYerXv/51pkyZkvPOO6/dPk0hZ/LkyUneLqlNnz49RVHkJz/5Sav+q1evztKlSzNy5MhMnTo1SVJdXZ1JkyZl06ZNWbJkSasxTzzxRDZu3JhJkyY17xoIAADQXb0Wpo477risWbMmP/zhD/PYY4+1at+wYUO++93vZsiQIfnjP/7j5s9nzpyZJFm4cGGrTSUWLlyYJDnjjDMyYsSI5s8//OEPJ0nuvPPOVudpGtNRqAMABqYZ81fYrALoNb0WpgYNGpRLL700SXLhhRfm5z//eXPbc889l7PPPjvr16/PlVde2fwi3iSZPXt29t9//zz88MO59tprs3nz5jQ2Nubee+/Nddddl6qqqnzhC19oca65c+dm2LBhWbBgQW677ba8+eab2bp1a+bPn58FCxZk2LBhmTt3bm9dKgAAsBfq1Wemrr/++vzpn/5pXnnllfzZn/1Zxo4dm7Fjx+YP/uAP8vjjj+ess85q9V6mMWPG5J/+6Z8ydOjQfPWrX82ECRMyfvz4XHjhhXnrrbfyN3/zNy0qWUly2GGH5Zvf/Gaqqqpy5ZVXZv/998/++++fuXPnpqqqKnV1dZk0aVJvXioAUCGdqT6pUAG9oVfD1JAhQ/LII4/km9/8Zk466aQMHjw4w4cPz5lnnpm///u/z49+9KM2tyI/55xz8uijj+acc87J6NGjkyTTpk3L3XffnZtuuqnNc1122WX50Y9+lBkzZmTo0KEZPnx4ZsyYkUWLFmX27Nm9eZkAAMBeqNvvmeroZblJMnTo0HzmM5/JZz7zmS4dd9q0aXnwwQe7NObMM8/MmWee2aUxAED/MmP+iiy+qvd24FWhAnpKr760FwCgjKbA0xSq3vl/dzQGoK9U9D1TAMDA09XnkzzPBOypVKYAgH5LyAL6M2EKANhjdDdcCWdATxKmAIABR2gC+oJnpgAAAEoQpgAAAEoQpgCAXmfHPmAgEqYAAABKEKYAAABKEKYAAABKEKYAAABKEKYAAABK8NJeAKDXdGUHP7v9AXsalSkAAIASVKZ209DQkMmTJ7fZVltbm9ra2j6eEQD0vaYK0eKrjqrwTAB6R11dXerq6tpsa2ho6PRxhKndVFdXZ9myZZWeBgDsFdzWB1RKR4WSmpqa1NfXd+o4bvMDAAAoQZgCADrUGxUkVSlgIBCmAAAAShCmAAAASrABBQDQZ9zeBwwkKlMAAAAlCFMAQJfNmL/iXatMqlDAQCdMAQDd0plgBTAQCVMAwLsSmABaswEFAAxQTeFn8VVH9en5APYWKlMAAAAlqEwBAJ2m+gTwH1SmAGAv4JkngJ4nTAEAAJQgTAEAqlYAJXhmCgBIIlABdJXKFAAAQAnCFAAAQAnCFAAAQAnCFAAAQAnCFAAAQAnCFAAAQAnCFAAMcL255bnt1IG9mfdM7aahoSGTJ09us622tja1tbV9PCMAAKCn1dXVpa6urs22hoaGTh9HmNpNdXV1li1bVulpAAAAvaijQklNTU3q6+s7dRy3+QEAAJQgTAEAAJTgNj8A2AM1bfyw+Kqjem28zSUAOqYyBQAAUILKFADsxVSfAMpTmQIAAChBmAIAAChBmAKAfmbG/BVdvv2us/3LHBuAtnlmCgD2YIIRQOWoTAFADypTUerpQKT6BNA3VKYAoBu6+76nniRAAfQtlSkAeBcqPQC0RZgCAAAoQZgCAAAoQZgCAAAoQZgCAAAoQZgCgH7OBhgA/ZOt0QGgnxKgAPo3YQoAShB0AHCbHwD0gK7ciieIAQwMwhQAdJJnlwDYnTAFAABQgjAFAD3snRUsFS2AgckGFLtpaGjI5MmT22yrra1NbW1tH88IAFoSygC6r66uLnV1dW22NTQ0dPo4wtRuqqurs2zZskpPA4ABShAC6B86KpTU1NSkvr6+U8dxmx8AAEAJwhQA9AOeqwLY8whTAAAAJXhmCoC9WlM1aPFVR/XasQEYmFSmAGAPIZwB9C/CFAAAQAnCFAD0I6pPAHsOYQqAAa+9nfIEFwC6Q5gCYI9mS3EAKkWYAmBAEa4A6CvCFAAV11fhR9ACoCd5zxQAe53uBiqBDIBEZQoAAKAUlSkABoSeqhbtfpzFVx3VI8d8t/MAsGdSmQIAAChBmAIAACjBbX4AELfdAdB1KlMAAAAlCFMAdJv3NwGwN3KbHwD9wjvDWE/tpCfkAdBbVKYAAABKUJkCYI/V21UnVS0AOqIyBUCXeUYKAFSmWmhoaMjkyZPbbKutrU1tbW0fzwigf+nLANV0rp56dgoAmtTV1aWurq7NtoaGhk4fR5jaTXV1dZYtW1bpaQD0S5WqRLV1XgELYM9W6X8w66hQUlNTk/r6+k4dx21+AAAAJQhTAPQqz1cBMFAJUwAAACV4ZgqAAUk1DIDeJkwB0CuEGQAGOrf5AdCsL16C2xPn8BwWAP2ByhQAHRJaAKBtKlMAAAAlCFMAA5BqEgD0PmEKAACgBGEKAACgBGEKAACgBGEKYC9mi3EAKM/W6ACUDlRtjRPOANhbqEwB7GV6M+x09dgqYwDsybodpubNm5eqqqrs3Lmz3T7Lly/PRRddlAMPPDCjRo3K1KlT881vfjNFUbQ7ZsmSJZk5c2YmTJiQ0aNHZ/r06bnrrrs6nMuiRYty2mmnZezYsRk7dmxOPfXULFq0qPS1AQAAtKdbt/kVRZHvfe97HfZ56qmncuqpp2bLli2pqqrKvvvum2effTZz5szJ448/3mZAeuihh3L++ednx44dGTJkSEaMGJElS5Zk1qxZee6553LzzTe3GnP77bfnr/7qr1IURUaMGJEkWbx4cf6//+//y//4H/8jl19+eXcuFWBAUQ0CgO4rXZnauXNnbrzxxvzqV79qt8+uXbvyyU9+Mlu2bMnFF1+c1157LevXr89Pf/rTjBkzJnfffXerMLV58+ZcfPHF2bFjR770pS9l3bp1Wb9+fe65554MGTIk8+bNy6OPPtpizKpVqzJnzpwURZFbb701r7/+el5//fV84xvfSFEUmTNnTlatWlX2UgH6zN5y29vecp0ADGxdDlMPPvhgPvWpT+XII4/M9ddf32Hf+++/P8uXL8/xxx+fBQsW5IADDsigQYPygQ98ILfffnuS5Gtf+1qLMXfccUfWr1+fs846KzfffHP222+/DB06NBdccEFuvPHGJMnXv/71FmPmz5+fxsbGXH755bnyyiszatSojBo1KldddVUuu+yyNDY25rbbbuvqpQIAALSry2Hqvvvuy8KFC/PSSy+9a98HHnggSfKJT3wiw4YNa9H20Y9+NKNHj84zzzyTV199tdWYSy65JFVVVS3GXHLJJUmSH//4x2lsbGw15lOf+lSrOTR91tQHYE/VmWrO7n1UfwCgd3U5TH3lK1/J0qVLm3868thjjyVJzjzzzFZtQ4cOzWmnnZYkefzxx5O8/QzWE088kaqqqpx++umtxhx00EE5/vjjs23btjz77LNJkoaGhvzmN7/JuHHjctJJJ7UaM23atIwbNy4vvvhi1q1b17WLBehFgg4A7Nm6HKYmTpyY4447rvmnPbt27Wp+TunII49ss88RRxyRJFm5cmWSZPXq1dm2bVvGjx+f8ePHd2rMiy++mCQ5/PDDM2hQ68sZNGhQJk2a1GIMAABAd/XaS3s3b96cxsbGDBkyJKNHj26zT1NgamhoSJKsXbs2STJ27Nh2j9sTY9pTFEU2b97cYZ+ODB8+PMOHDy89HqCrmqpbi686qtN9K6XS5wdg77B9+/Zs37699PiOXt/0Tr0WprZt25ak45Azbty4Fn2b/mz6vLfGtGf16tXZb7/9OuzTkeuuu+5dN+UA9i4z5q/oVNDpj4QfAPZE8+bNyw033NAn5+q1MNWU6DpKdoMHD06S5hf+9tWY9hx88MF5/vnnO+zTEVUpYCAQogDYk11zzTW5+uqrS48/9thjs3r16k717bUwtc8++yRJNm7cmKIoWu3Ml/xHpaipb9OfGzZsaPe4PTGmPU0vFQYAAPZM3X30pq3c0p7SL+19N/vuu2+GDRuWnTt35o033mizz5o1a5IkEyZMaPHnxo0b2z1uT4wB6Es9vUW5Lc8BoH/otTA1aNCgHH744UmSF154oc0+zz33XJLkqKPefp5g4sSJGTVqVDZs2NDuNubvHNP058qVK9u8jW/nzp1Zvnx5i74AAADd1WthKklOPvnkJMnDDz/cqq2xsTGLFy9Okrzvfe9L8nZJbfr06SmKIj/5yU9ajVm9enWWLl2akSNHZurUqUmS6urqTJo0KZs2bcqSJUtajXniiSeycePGTJo0KdXV1T11aQA9ojtVJtUpAKisXg1TM2fOTJLcfffdrbYn/MEPfpA33ngjU6dOzaGHHtpqzMKFC1ttKrFw4cIkyRlnnJERI0Y0f/7hD384SXLnnXe2mkPTmPPOO697FwPQDqEGAPZOvRqmzjvvvBxzzDFZunRpLr/88qxduzY7d+7MI488kiuuuCJJ8sUvfrHFmNmzZ2f//ffPww8/nGuvvbb5fVX33ntvrrvuulRVVeULX/hCizFz587NsGHDsmDBgtx222158803s3Xr1syfPz8LFizIsGHDMnfu3N68VGCA64nAVKYK1dn+nqMCgL7Xq2Fq0KBBueuuuzJmzJj80z/9Uw488MCMHz8+H/zgB7Nly5bMmjUrF110UYsxTX2HDh2ar371q5kwYULGjx+fCy+8MG+99Vb+5m/+Jn/8x3/cYsxhhx2Wb37zm6mqqsqVV16Z/fffP/vvv3/mzp2bqqqq1NXVZdKkSb15qUA/0J/CREfhpjPBRzgCgP6vV8NUkpx44ol58sknc8EFF2T//fdPY2NjpkyZkttuuy3f/va32xxzzjnn5NFHH80555yT0aNHJ0mmTZuWu+++OzfddFObYy677LL86Ec/yowZMzJ06NAMHz48M2bMyKJFizJ79uxeuz5gzyWwAADd0e33THX0stwmRx99dO65554uHXfatGl58MEHuzTmzDPPzJlnntmlMQD9ncAHAP1Tr1emAAAABqJuV6YA9jZNlaLFV/Xcu+tUnwBgz6MyBQAAUIIwBfB/qA4BAF0hTAEDih36AIC+IkwBAACUYAMKgDa0tcnEnlrx2lPnDQD9nTAF0AFBBABoj9v8gD3K7uGm0s9H7X7+Ss8FAOh7whQAAEAJbvMDBqSOnnnqyZfttndeAGDgU5kCKs4tcgDAnkhlCugTfVEVKkuQAwDKEKaAiukoxLwzfHU38AhMAEBPE6aADpWpKM2Yv6JUBao3qldthSjBCgDoCcLUbhoaGjJ58uQ222pra1NbW9vHM4LKEjoAgIGorq4udXV1bbY1NDR0+jjC1G6qq6uzbNmySk8DAADoRR0VSmpqalJfX9+p4whTwB5HxQwA6A+EKaBP9dVzUQAAvU2YAvqd3cORoAQA9FfCFOxlevN9TwMh+AyEawAA+oYwBXupvnqJrnACAAxUgyo9AQAAgD2RMEVFqVoAALCncpsf9ENlb8F7Zzjt7Vv4OiIoAwADncoUdGDG/BX9IhSUnUN/mT8AwECkMgV0SVvhrJIVMACASlGZgj2cyhMAQGWoTAHdJtABAHsjlSnoRb3xzNJAeQ5qIFwDALB3U5mCPVRXwsiM+Su69FyToAMA8O6EKRgAuht+ym7FDgCwNxOmoB9REQIA2HMIUwwYe3p1pbeDVHvHF+AAAMqxAQUAAEAJKlPQTXt6RayzVLAAAFpSmYIeMlC2LAcAoHOEKfqtngwnfRl02jpPT5xfWAMA6F+EKShhoIYagQ0AoPM8MwUVJrwAAOyZhKndNDQ0ZPLkyW221dbWpra2to9nRE/bPbiU2TBi9/FCEADAnqmuri51dXVttjU0NHT6OMLUbqqrq7Ns2bJKT4M+0pu78AlaAAD9V0eFkpqamtTX13fqOJ6Zokf0x/DQ1Tn1xfNC/fH3BABAOcIUe4T2go5wAgBApbjNj1L684tq+3vA6s+/OwAAOk+Yggrp76EPAICOuc0PAACgBJUpuqS/VFP6yzx6295ynQAAeyJhioooGxKECwAA+gu3+dHvCVAAAPRHKlP0iY52sPPyXAAA9kTC1ACxeyDprXDSE8GkP4abd85pxvwVrX53/XHeAABUljBFt/RGyBBcAADYE3hmCgAAoASVqb1MXzyf1BvH7muqYwAAvBthai9SqYDQ2+cVfAAAqARhil4j5AAAMJB5ZmoP1FFI6W6AEYAAAKBzVKb6qba25+6t8yQtn3N6Z6AaCM9AAQBATxOm9gADaWOHjqiKAQCwJxGm9nB9EUCEHAAAaE2Y2gsIQwAA0POEqT2UjSYAAKCyhKl+TOABAID+S5giieAGAABdJUztpqGhIZMnT26zrba2NrW1tX08IwAAoKfV1dWlrq6uzbaGhoZOH0eY2k11dXWWLVtW6Wn0GNUmAABoraNCSU1NTerr6zt1HGGKHifEAQCwNxCm9iBCCgAA9B+DKj0BAACAPZEwBQAAUIIwBQAAUIIwBQAAUIIwBQAAUIIwBQAAUIIwBQAAUIIwBQAAUIIwBQAAUIIwBQAAUIIwBQAAUIIwBQAAUIIwBQAAUIIwBQAAUIIwBQAAUIIwBQAAUIIwBQAAUIIwBQAAUIIwBQAAUIIwBQAAUIIwBQAAUMKQSk+gP2loaMjkyZPbbKutrU1tbW0fzwgAAOhpdXV1qaura7OtoaGh08cRpnZTXV2dZcuWVXoaAABAL+qoUFJTU5P6+vpOHcdtfgAAACUIUwAAACUIUwAAACUIUwAAACUIUwAAACUIUwAAACUIUwAAACUIUwAAACUIUwAAACUIUwAAACUIUwAAACUIUwAAACUIUwAAACUIUwAAACUIUwAAACX06zC1fPnyXHTRRTnwwAMzatSoTJ06Nd/85jdTFEW7Y5YsWZKZM2dmwoQJGT16dKZPn5677rqrD2cNAADsDfosTF199dWpqqpq92fcuHEt+j/11FM56aSTcs8992TNmjUZNmxYnn322cyZMyezZs1q8xwPPfRQTjnllDz44IPZtGlTqqqqsmTJksyaNSvXXnttX1wmAACwl+izMLVixYokye/93u/lyCOPbPVz2GGHNffdtWtXPvnJT2bLli25+OKL89prr2X9+vX56U9/mjFjxuTuu+9uVW3avHlzLr744uzYsSNf+tKXsm7duqxfvz733HNPhgwZknnz5uXRRx/tq8sFAAAGuD4LUy+++GKS5Nlnn82KFSta/Tz99NPNfe+///4sX748xx9/fBYsWJADDjgggwYNygc+8IHcfvvtSZKvfe1rLY5/xx13ZP369TnrrLNy8803Z7/99svQoUNzwQUX5MYbb0ySfP3rX++jqwUAAAa6PglTu3btyqpVq3LggQdmv/32e9f+DzzwQJLkE5/4RIYNG9ai7aMf/WhGjx6dZ555Jq+++mqrMZdcckmqqqpajLnkkkuSJD/+8Y/T2NjYnUsBAABI0kdh6pVXXkljY2OOPvroTvV/7LHHkiRnnnlmq7ahQ4fmtNNOS5I8/vjjSZKiKPLEE0+kqqoqp59+eqsxBx10UI4//vhs27Ytzz77bNnLAAAAaNYnYarpeamjjjoqCxcuzIc//OH84R/+YT7+8Y/nlltuyfbt25v7NlWxkuTII49s83hHHHFEkmTlypVJktWrV2fbtm0ZP358xo8f36kxAAAA3TGkL07S9LzUt7/97fzDP/xD8+f/+3//73z/+9/PP/7jP+a+++7L7//+72fz5s1pbGzMkCFDMnr06DaP1xSYGhoakiRr165NkowdO7bdObxzDAAAQHf0SZhqqkwNGjQo/9f/9X9l5syZOeCAA/L4449n7ty5Wbp0aS655JL84he/yLZt25J0HIyatlFv6tv05zu3V+9oTFuKosjmzZs7f2HvMHz48AwfPrz0eAAAoHu2b9/e4s63ruronbbv1Cdh6pBDDsmFF16YWbNm5Zxzzmn+/EMf+lCmT5+eI488Mo899lj++Z//OdOnT0/S8UUMHjw4SbJz584Wfbsypi2rV6/u1AYZ7bnuuuty/fXXlx4PAAB0z7x583LDDTf0ybn6JEx99rOfbbdt/Pjx+au/+qvcfPPNefzxx5s3l9i4cWOKomi1M1/yH9WlffbZp8WfGzZsaPc87xzTloMPPjjPP//8u1xN+1SlAACgsq655ppcffXVpccfe+yxWb16daf69kmYejdTpkxJkixbtiz77rtvhg0blsbGxrzxxhsZM2ZMq/5r1qxJkkyYMKHFnxs3bmz3HO8c05aqqqrsu+++pa4BAACovO4+etNWMac9ffbS3o40VYvGjBmTQYMG5fDDD0+SvPDCC232f+6555K8vTtgkkycODGjRo3Khg0bsm7duk6NAQAA6I5eD1Ovv/56pkyZkpNPPjlvvfVWm32WL1+eJJk8eXKS5OSTT06SPPzww636NjY2ZvHixUmS973vfUneTo/Tp09PURT5yU9+0mrM6tWrs3Tp0owcOTJTp07t9jUBAAD0epjaf//9M2LEiDz++OP5/ve/36p9x44dWbBgQZLkz/7sz5IkM2fOTJLcfffdrXbi+MEPfpA33ngjU6dOzaGHHtr8edOYhQsXttqIYuHChUmSM844IyNGjOiZCwMAAPZqfXKb3+WXX54k+eu//uv88Ic/bP785Zdfzkc+8pG88MILOf/88/P+978/SXLeeeflmGOOydKlS3P55Zdn7dq12blzZx555JFcccUVSZIvfvGLLc4xe/bs7L///nn44Ydz7bXXNr+v6t577811112XqqqqfOELX+iLywUAAPYCVUVXNlLvhk984hP57ne/m+TtZ6RGjBiR119/PUly0kkn5Z//+Z8zceLE5v5PP/10ZsyYkS1btmTQoEEZPXp08zugZs2ale985zutzvHQQw/l/PPPz44dOzJ06NAMGzYsW7duTZJ8+ctfzk033dTm3GpqalJfX5+JEyfm1Vdf7dHrLmvG/BWVngIAAPSqxVf1v/0MupIN+mwDirvuuiv/83/+z/zJn/xJ9tlnn+zatSunnnpqvvrVr+aXv/xliyCVJCeeeGKefPLJXHDBBdl///3T2NiYKVOm5Lbbbsu3v/3tNs9xzjnn5NFHH80555yT0aNHJ0mmTZuWu+++u90gBQAAUEafVab6M5UpAADoeypTAAAAeyFhCgAAoARhCgAAoARhCgAAoARhCgAAoARhCgAAoARhCgAAoARhCgAAoARhCgAAoARhCgAAoARhCgAAoARhCgAAoARhCgAAoARhCgAAoARhCgAAoIQhlZ5Af9LQ0JDJkye32VZbW5va2to+nhEAANDT6urqUldX12ZbQ0NDp48jTO2muro6y5Ytq/Q0AACAXtRRoaSmpib19fWdOo7b/AAAAEoQpgAAAEoQpgAAAEoQpgAAAEoQpgAAAEoQpgAAAEoQpgAAAEoQpgAAAEoQpgAAAEoQpgAAAEoQpgAAAEoQpgAAAEoQpgAAAEoQpgAAAEoQpgAAAEoQpgAAAEoQpgAAAEoQpgAAAEoQpgAAgIqYMX9FpafQLcIUAABACcIUAABACcIUAABACcIUAABACUMqPYH+pKGhIZMnT26zrba2NrW1tX08IwAAoKfV1dWlrq6uzbaGhoZOH0eY2k11dXWWLVtW6WkAAAC9qKNCSU1NTerr6zt1HLf5AQAAlCBMAQAAlCBMAQAAlCBMAQAAlCBMAQAAlCBMAQAAlCBMAQAAlCBMAQAAlCBMAQAAlCBMAQAAlCBMAQAAlCBMAQAAlCBMAQAAlCBMAQAAlCBMAQAAlCBMAQAAlCBMAQAAlCBMAQAAlCBMAQAAlCBMAQAAlCBMAQAAlCBMAQAAlCBMAQAAlDCk0hPoTxoaGjJ58uQ222pra1NbW9vHMwIAAHpaXV1d6urq2mxraGjo9HGEqd1UV1dn2bJllZ4GAADQizoqlNTU1KS+vr5Tx3GbHwAAQAnCFAAAQAnCFAAAQAnCFAAAQAnCFAAAQAnCFAAAQAnCFAAAQAnCFAAAQAnCFAAAQAnCFAAAQAnCFAAAQAnCFAAAQAnCFAAAQAnCFAAAQAnCFAAAQAnCFAAAQAnCFAAAQAnCFAAAQAnCFAAAQAnCFAAAQAnCFAAAQAnCFAAAQAnCFAAAQAlDKj2B/qShoSGTJ09us622tja1tbV9PCMAAKCn1dXVpa6urs22hoaGTh9HmNpNdXV1li1bVulpAAAAvaijQklNTU3q6+s7dRy3+QEAAJQgTAEAAJQgTAEAAJQgTAEAAJQgTAEAAJQgTAEAAJQgTAEAAJQgTPVD27dvz0s/ujW73mqs9FTYA+x6q9F6oUusGbrKmqGrrBm6avv27bn++uuzffv2Sk+lS4Spfmj79u15+ce3+QuITtn1VqP1QpdYM3SVNUNXWTN01fbt23PDDTcIUwAAAHsDYQoAAKAEYQoAAKAEYQoAAKAEYQoAAKAEYQoAAKCEARemfvvb3+ayyy5LTU1NRo4cmaOPPjo33nhjGhttzQkAAPScARWmXnnllZx44olZsGBB6uvrM2LEiLzwwgu57rrrcvrpp2fHjh2VnuIeqf7n/7PSU2hmLnuG/vS7MZc9Q3/63ZjLnqE//W7Mpf/rb7+X/jSf/jSXPdGAClN/+Zd/mddeey1nnHFGXnnllWzYsCFPPvlkJk6cmH/913/Nf/tv/63SU9wjrX70rkpPoZm57Bn60+/GXPYM/el3Yy57hv70uzGX/q+//V7603z601z2RAMmTD3zzDP56U9/mgMPPDD33HNPDjnkkCTJe9/73nz/+99PksyfPz9vvfVWJacJAAAMEAMmTD3wwANJkj//8z/PuHHjWrSdfPLJOfroo7N27do88cQTlZgeAAAwwAyYMPXYY48lSc4888w225s+b+oHAADQHQMmTL344otJkiOPPLLN9iOOOCJJsnLlyj6bEwAAMHANmDC1du3aJMnYsWPbbB8/fnySpKGhoa+mBAAADGBVRVEUlZ5ETxg2bFh27NiRN954I/vss0+r9oceeijnnntuzjzzzCxatKjNsYMGDcqBBx5Yeg5VVVWlx+6uKIqsXr06w/Y9IOmhY3bHji3rMnTMhEpPI4m5tKko0rh5Tb9ZL0k/+t3EXNpkzXTIXNpgzXTIXNrQz9ZMv/m9/B/9aT79YS7vGT2k+fvvwQcf3CPfqbsTcV577bXs2rUrQ4cOfdd31Q64MLVly5aMHj26VfuiRYvyoQ99KB/84Afzk5/8pEXb4MGDs2vXrr6aKgAA0M8NGjQoO3fu7LDPkD6aS68bNWpUNm3alA0bNrQZprZt25YkbVatRowYkd/97ncZPHhw3vOe95SeQ09VpgAAgPK6Uy9au3Ztdu7cmREjRrxr3wETpiZMmJBNmzZl48aNze+Y2t2aNWua+73T1q1be31+AADAwDJgNqA46qijkiQvvPBCm+3PPfdci34AAADdMWDC1Mknn5wkefjhh9ts//GPf5wked/73tdncwIAAAauAROmZs6cmSS5//77s379+hZtv/zlL7NixYpMmDAhf/zHf1yJ6QEAAAPMgAlTJ5xwQk4//fQ0NDTkE5/4RF599dUURZGnnnoqH//4x5MkV199dYYOHVrhmQIAAAPBgNkaPUleeeWVTJ8+Pa+99lqSt1/gu3HjxiTJqaeemocffjhDhgyYPTcAAIAKGjCVqST5vd/7vTz99NOZPXt2DjrooLz55pv5/d///dx4441ZtGhRrwap3/72t7nssstSU1OTkSNH5uijj86NN974ri/6asvGjRtz9dVXZ9q0aRk1alQOOeSQXHrppfn3f//3dsds3rw5n/vc53LYYYdlxIgROeyww/K5z30umzdv7s5l0YsqvWbWrVuXv/7rv8573/vejBkzJkcffXQuuuiiPPvss925LHpRpddMW/MZO3Zs/vRP/7TL56dv9Ic1c99992XGjBkZN25cDjrooMycOdPfM/1YpdfM5s2bc/XVV+fEE0/MmDFjcsIJJ+Szn/1sNm3a1J3Loo/MmzcvVVVV7/puprY0NjbmpptuyjHHHJORI0dm4sSJufTSS7N69ep2x/SL778F3fbyyy8XBx54YJGkSFKMHTu2+b//7M/+rGhsbOz0sX71q18VkyZNKpIUVVVVxYQJE5qPNW7cuGLp0qWtxmzcuLE49thjW/Rr+u9jjz222LhxY09eLj2g0mvmqaeeKg444IDmfgcccEAxePDgIkkxbNiw4n/8j//Rk5dLD6j0mmnL+eefXyQpTjnllLKXRS/qD2vmc5/7XHO/MWPGFCNGjCiSFEOHDi0WLVrUU5dKD6n0mvnNb35T1NTUNI+prq4uqqqqiiRFTU1NsWrVqp68XHrYrl27ij/8wz8skhRvvfVWl8Y2NjYW73//+9tcewceeGDx8ssvtxrTX77/ClM94IMf/GCRpDjjjDOKV155pSiKonjyySeLiRMnFkmKr3zlK506zs6dO4upU6cWSYpPfvKTxbp164qiKIpVq1YVf/qnf1okKY4//vhi165dLcbNnj27SFJMnTq1WL58eVEURfFv//ZvxfHHH18kKWbPnt2DV0tPqPSaOeWUU4okxcyZM4uGhoaiKIpi69atxbx584rBgwcXw4YNK5577rkevGK6q9Jr5p3uu+++5v/REqb6p0qvme9///tFkmLfffctHnrooaKxsbFobGws/uZv/qb5y/GWLVt69qLplkqvmTPOOKNIUnzkIx8p1q5dWxRFUaxbt675H27OOOOMHrxaetJbb71VXH/99c3/u9DVMPWVr3yl+e+Fp556qiiKt8P96aefXiQpPvjBD7Ya01++/wpT3fT00083p+b169e3aPvlL39ZJCne8573FDt27HjXY915551FkuK9731vq7Zt27YVBx10UJGkxb/mNTQ0FEOHDi1GjBjR6l9sVq1aVYwYMaIYNmxYsWbNmpJXSE+r9Jr5+c9/XiQpJkyYUGzbtq3VuC984QvN/wNI/1DpNfNOGzZsaO4nTPVPlV4zu3btav4X47bWUtO/QN93330lro7eUOk189JLLzXfKfHGG2+0GPPGG28U73nPe4okbVYoqJwHHniguOSSS5qrkGXCVGNjY3Pl8rHHHmvRtn79+uZq6a9+9avmz/vT998B9cxUJTzwwANJkj//8z/PuHHjWrSdfPLJOfroo7N27do88cQT73qsf/3Xf02SzJkzp1XbyJEjU1tbmyR58MEHmz9ftGhRduzYkRkzZuSwww5rMeawww7L+9///jQ2Nrb7/i36XqXXzLJly5Ikf/EXf5GRI0e2GvepT30qSfLMM8905nLoA5VeM+/0+c9/Pr/97W+b1wr9T6XXzFNPPZXnn38+xx13XM4888xW4+bMmZMZM2Z0+CwEfavSa6bpObrp06dnn332aTFmn332yfTp01v0o3+47777snDhwrz00kulj/HYY49l3bp1OeaYY1q9D3bcuHE577zzkvTf77/CVDc99thjSdLm/1js/nlTv448//zzSZJjjz22zfYpU6YkafkltyfPT9+o9Jpp+gtv0qRJbY456KCDWvSj8iq9Zna3ePHi3HHHHfngBz+Yiy+++F3PR2VUes00fYH5yEc+0uaYj3zkI/nZz36Wz3zmM+96fvpGpdfM1q1bk6TdjQveeuutJMm2bdve9fz0na985StZunRp808ZZdZef/r+a5/wbnrxxReTJEceeWSb7UcccUSSZOXKle96rDfffDNJsmvXrjbbm96RtfuxevL89I1Kr5lPfvKTef/735/Jkye3OebJJ59MkhxyyCHven76RqXXTJPf/e53ueyyyzJixIjcfvvtXdr5j75V6TXTVAE//vjjOzljKq3Sa+aEE05Ikvzyl7/MunXrMmHChOa2devWNX8ptqb6l4kTJ2bixIndOkaZtdefvv+qTHXT2rVrk7z9Tqu2jB8/PknS0NDwrsc65phjkiTLly9vs72ptL37do89eX76RqXXTNNtN22FpcbGxnz5y19Okpx11lnven76RqXXTJPrr78+K1asyA033JDDDz/8Xc9F5VR6zaxatSpJ8p73vCeLFi3KX/zFX+Tggw/OIYccknPPPTePPPJI5y6EPlPpNXP00UfnE5/4RDZu3JgPf/jDefLJJ7N169Y8+eSTmTlzZjZt2pSLLrqo+dgMHGXWXn/6/itMdVNTufmd9xc3afq8M2XppvuB/+7v/q5V2xtvvJFbb701SbJ9+/ZeOT99o9Jrpj1r167NueeemyeeeCJjxozJZz/72XcdQ9/oD2vmV7/6Vb72ta81v/OF/q3Sa6bpS/L3vve9nHvuufm//+//O2+99VYaGhry0EMP5fTTT89/+S//pQtXRG+r9JpJkjvuuCMf/ehH89hjj2XatGkZPXp0pk2blscffzwf+9jH8o//+I+dvyD2GGXWXn/6/itM9ZCiKNr8fPDgwUnavwd4d3/1V3+V3/u932v+S+O5557Lli1bsnjx4pxyyinND+qOGjWq1Xl74vz0rUqtmbbmcccdd+TYY4/NT37ykwwZMiR33XVXDj300BJXRW+q1JrZuXNnZs+enaIosmDBgl59ATo9q1Jr5ne/+12St79Mf+xjH0t9fX3WrFmTrVu3ZsGCBRk+fHi+8pWveJ63H6rk/zb9y7/8S37xi18kSQYNGpSDDjoogwa9/VX1F7/4RX72s5+Vvi76rzLfZfvT919hqpua/iLYsGFDm+1NifidO9O0ZcSIEbn77rtz4IEH5gc/+EH+4A/+IPvuu29OPfXULF26NJ/73OeSJGPGjGke03Tcnjg/faPSa2Z39fX1Oe200zJ79uy8/vrrqampyeLFizNz5swyl0YvqfSaueWWW/LUU09l7ty5+aM/+qPuXg59oNJrpulfhU8++eTcddddOfjgg5O8/azM7Nmz88UvfjFFUeS///f/Xv4i6VGVXjM///nP8+d//ufZuHFj/u7v/i7btm3L6tWrs23bttTV1WXDhg358z//8/z85z/v7qXSz5T5Ltufvv8KU93U9IDkxo0b22xfs2ZNi37v5k/+5E/yv//3/861116b008/PSeffHLmzp2bJ554ovkZlqaH6nrj/PS+Sq+ZJj/60Y8yderULF68OEOGDMncuXPz3HPP5U/+5E9KXBW9qZJr5rXXXst1112Xww47LDfeeGM3r4S+Uum/Zw488MAkySWXXNJcWdjdBRdckCT59a9/3bkLotdVes1cf/312bFjR7761a/mr/7qrzJ8+PAkyfDhw/PXf/3XmTdvXhobG3PDDTeUvUT6qTJrrz99/3WvRjcdddRRWblyZV544YXmrT5399xzzzX366wDDjggf/u3f9vq84ULFyZ5ewOB3c//yCOP5IUXXmjzWGXOT++q9JpJ3t4q9Pzzz8/27dszderUfOc732lzLvQPlVwzDQ0N2bZtW37zm9+0+y98jz76aKqqqpK8/WzV1KlTOz0Pekel/56prq5OknZ3+Wr6/Le//W2nz0/vqvSa+V//638laX87/b/4i7/I3Llzm/sxcDStqa58l+1P339Vprrp5JNPTpJ2Xwr24x//OElavYSsLb/5zW/yyCOPtPt+n3/+539O0nJP/Z48P32j0mtm27ZtzUHqYx/7WJ544glBqp+r5JoZNmxYjjzyyDZ/mr4QjxgxovmzYcOGdena6B2V/nvm6KOPTtL+l6Pf/OY3Sdp/DxF9r9JrZt99902S5n+YeaemZ2Oa+jFwlFl7/er7b0G3PP3000WSorq6unj99ddbtP3iF78okhQTJkwoGhsb3/VYP/zhD4skxRlnnNGq7cUXXyyGDh1avOc97ym2bt3a/Plrr71WDB06tBgxYkSxcuXKFmNWrlxZjBgxohg2bFjR0NBQ8grpaZVeM3feeWeRpPjDP/zDYseOHd2/IHpdpddMexYvXlwkKU455ZTOXwx9otJr5rnnniuSFEcffXSxffv2VuM+85nPFEmKK664osTV0RsqvWZmzpxZJCnmz5/f5jG/8Y1vFEmK8847r2sXRp9KUiQp3nrrrU6PaWxsLCZMmFAkKX7xi1+0aHv99deLAw88sEhSPPPMM82f96fvv8JUDzj99NOLJMWZZ55Z/Pu//3uxa9eu4n/9r/9VTJw4sUhS3HzzzS3619fXF8ccc0xxzDHHFEuWLGn+fOvWrcV73vOeIklx0003FTt27Ch27dpVLFmypDj00EOLJMUtt9zS6vyXXnpp85fj5cuXF0VRFP/2b/9WTJkypUhSXHbZZb16/XRdJdfMWWedVSQp/umf/qkvLpUeUum/Z9oiTPVvlV4z55xzTpGk+NCHPlS8/PLLzcf627/922LQoEHFmDFjin//93/v1d8BXVPJNfMv//IvxaBBg4qRI0cWf//3f98cwn/3u98Vf/d3f1eMHDmyGDRoUPEv//Ivvf57oLyOwlR766UoiuJv//ZviyRFTU1N8dRTTxVFURQvvfRS8cEPfrDdYN5fvv8KUz3g5Zdfbk7NSYqxY8c2//epp57a6l//X3rppeb2xYsXt2j7f//f/7cYPHhwkaQYOXJki2NdeOGFxa5du1qdf+PGjcWxxx7b3G/cuHHN/z158uRi06ZNvXr9dF0l18wRRxzR/BfWkUce2e6PL8j9S6X/nmmLMNW/VXrN1NfXF4ccckhzvwMOOKD5GKNGjSruueeeXr1+uq7Sa+bmm28uBg0aVCQpBg8eXBx88MEt/u958+b16vXTfR2FqY7WS2NjY/H+97+/ze+yBx10UPHKK6+0Ol5/+f4rTPWQ1atXF7Nnzy4OOuigYvjw4cXv//7vFzfeeGObtzd0tJiKoiieeeaZ4txzzy0OOuigYvTo0cVJJ51ULFiwoMMvOJs2bSquvvrq4tBDDy2GDx9eHHroocXnPve5YvPmzT16nfScSqyZnTt3FkOHDm0+Vkc/NTU1vXbtlFPpv2feSZjq/yq9ZtatW1fMmTOnmDRpUjFixIji2GOPLf7Tf/pPxYoVK3r0Ouk5lV4zzzzzTHHBBRcUxx57bDFq1Kji2GOPLS644ILiV7/6VY9eJ72jbJgqiqLYvn17ccMNNxRHHXVUMXz48OKggw4qLr300uK3v/1tu+frD99/q4qinbddAQAA0C67+QEAAJQgTAEAAJQgTAEAAJQgTAEAAJQgTAEAAJQgTAEAAJQgTAEAAJQgTAEAAJQgTAEAAJQgTAEAAJQgTAEAAJQgTAEAAJQgTAEAAJQgTAEAAJTw/wMVjui5MNu4owAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resample_ = 10\n",
    "RESAMPLE = (resample_) * 10  # Set to False for no resampling, otherwise sets the number of times to duplicate gjet data for resampling\n",
    "\n",
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"mass_sculpting_resample\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "score_cuts = [0.0, 0.7, 0.99, 0.9984]\n",
    "label_arr = [f'score above {score_cut}' for score_cut in score_cuts]\n",
    "plot_vars = ['mass', 'dijet_mass', 'HHbbggCandidate_mass']\n",
    "\n",
    "BDT_perf_resample = [\n",
    "    {\n",
    "        f'preds{score_cut}': copy.deepcopy({plot_var: list() for plot_var in plot_vars}) for score_cut in score_cuts\n",
    "    } for fold_idx in range(len(bdt_train_dict))\n",
    "]\n",
    "GJet_preds = []\n",
    "mean_values = {\n",
    "    'gj': list(),\n",
    "    'gg': list(),\n",
    "    'tth': list()\n",
    "}\n",
    "\n",
    "for fold_idx in range(len(bdt_train_dict)):\n",
    "    booster = xgb.Booster(param)\n",
    "    booster.load_model(os.path.join(OUTPUT_DIRPATH, f'{CURRENT_TIME}_BDT_fold{fold_idx}.model'))\n",
    "\n",
    "    nonres_bool = (data_test_aux_dict[f\"fold_{fold_idx}\"].loc[:, 'sample_name'] == \"GGJets\") | (data_test_aux_dict[f\"fold_{fold_idx}\"].loc[:, 'sample_name'] == \"GJetPt20To40\") | (data_test_aux_dict[f\"fold_{fold_idx}\"].loc[:, 'sample_name'] == \"GJetPt40\")\n",
    "\n",
    "    data_hlf_test = resample_grow_np(data_hlf_test_dict[f\"fold_{fold_idx}\"], nonres_bool, resample_)\n",
    "    data_test_aux = resample_grow_pd(data_test_aux_dict[f\"fold_{fold_idx}\"], nonres_bool, resample_)\n",
    "    weight_test = resample_grow_np(weight_test_dict[f\"fold_{fold_idx}\"], nonres_bool, resample_)\n",
    "    weights_plot = resample_grow_np(weights_plot_test[f\"fold_{fold_idx}\"], nonres_bool, resample_)\n",
    "    xgb_label_test = resample_grow_np(xgb_label_test_dict[f\"fold_{fold_idx}\"], nonres_bool, resample_)\n",
    "\n",
    "    gg_bool = (data_test_aux.loc[:, 'sample_name'] == \"GGJets\")\n",
    "    tth_bool = (data_test_aux.loc[:, 'sample_name'] == \"ttHToGG\")\n",
    "    gj_bool = (data_test_aux.loc[:, 'sample_name'] == \"GJetPt20To40\") | (data_test_aux.loc[:, 'sample_name'] == \"GJetPt40\")\n",
    "    hh_bool = (data_test_aux.loc[:, 'sample_name'] == \"GluGluToHH\")\n",
    "    nonres_bool = (data_test_aux.loc[:, 'sample_name'] == \"GGJets\") | (data_test_aux.loc[:, 'sample_name'] == \"GJetPt20To40\") | (data_test_aux.loc[:, 'sample_name'] == \"GJetPt40\")\n",
    "\n",
    "\n",
    "    for var_idx, plot_var in enumerate(plot_vars):\n",
    "\n",
    "        plot_dirpath_ = os.path.join(plot_dirpath, plot_var)\n",
    "        if not os.path.exists(plot_dirpath_):\n",
    "            os.makedirs(plot_dirpath_)\n",
    "\n",
    "        for _ in range(RESAMPLE // resample_):\n",
    "\n",
    "            for particle_type in ['lead', 'sublead']:\n",
    "\n",
    "                # gg_mvaID = data_hlf_test[\n",
    "                #     gg_bool, \n",
    "                #     hlf_vars_columns_dict[f\"fold_{fold_idx}\"][f\"{particle_type}_mvaID\"]\n",
    "                # ]\n",
    "                # data_hlf_test[\n",
    "                #     gj_bool, \n",
    "                #     hlf_vars_columns_dict[f\"fold_{fold_idx}\"][f\"{particle_type}_mvaID\"]\n",
    "                # ] = resample_from_var(\n",
    "                #     gg_mvaID, \n",
    "                #     weights_plot[gg_bool],\n",
    "                #     np.sum(gj_bool),\n",
    "                #     bins=190\n",
    "                # )\n",
    "\n",
    "                tth_pNetB = data_hlf_test[\n",
    "                    tth_bool, \n",
    "                    hlf_vars_columns_dict[f\"fold_{fold_idx}\"][f\"{particle_type}_bjet_btagPNetB\"]\n",
    "                ]\n",
    "                data_hlf_test[\n",
    "                    nonres_bool, \n",
    "                    hlf_vars_columns_dict[f\"fold_{fold_idx}\"][f\"{particle_type}_bjet_btagPNetB\"]\n",
    "                ] = resample_from_var(\n",
    "                    tth_pNetB, \n",
    "                    weights_plot[tth_bool],\n",
    "                    np.sum(nonres_bool),\n",
    "                    bins=100\n",
    "                )\n",
    "\n",
    "                # tth_sigmaE = data_hlf_test[\n",
    "                #     tth_bool, \n",
    "                #     hlf_vars_columns_dict[f\"fold_{fold_idx}\"][f\"{particle_type}_sigmaE_over_E\"]\n",
    "                # ]\n",
    "                # data_hlf_test[\n",
    "                #     gj_bool, \n",
    "                #     hlf_vars_columns_dict[f\"fold_{fold_idx}\"][f\"{particle_type}_sigmaE_over_E\"]\n",
    "                # ] = resample_from_var(\n",
    "                #     tth_sigmaE, \n",
    "                #     np.abs(weights_plot[tth_bool]),\n",
    "                #     np.sum(gj_bool),\n",
    "                #     bins=100\n",
    "                # )\n",
    "            # hh_dijet = data_hlf_test[\n",
    "            #     hh_bool, \n",
    "            #     hlf_vars_columns_dict[f\"fold_{fold_idx}\"][\"dijet_mass\"]\n",
    "            # ]\n",
    "            # data_hlf_test[\n",
    "            #     nonres_bool, \n",
    "            #     hlf_vars_columns_dict[f\"fold_{fold_idx}\"][\"dijet_mass\"]\n",
    "            # ] = resample_from_var(\n",
    "            #     hh_dijet, \n",
    "            #     np.abs(weights_plot[hh_bool]),\n",
    "            #     np.sum(nonres_bool),\n",
    "            #     bins=100\n",
    "            # )\n",
    "\n",
    "            nonres_ggf_preds = booster.predict(\n",
    "                xgb.DMatrix(\n",
    "                    data=data_hlf_test[nonres_bool], label=xgb_label_test[nonres_bool], \n",
    "                    weight=np.abs(weight_test)[nonres_bool],\n",
    "                    missing=-999.0, feature_names=list(hlf_vars_columns_dict[f\"fold_{fold_idx}\"])\n",
    "                ), \n",
    "                iteration_range=(0, booster.best_iteration+1)\n",
    "            )[:, 0]\n",
    "\n",
    "            # gg_ggf_preds = booster.predict(\n",
    "            #     xgb.DMatrix(\n",
    "            #         data=data_hlf_test[gg_bool], label=xgb_label_test[gg_bool], \n",
    "            #         weight=np.abs(weight_test)[gg_bool],\n",
    "            #         missing=-999.0, feature_names=list(hlf_vars_columns_dict[f\"fold_{fold_idx}\"])\n",
    "            #     ), \n",
    "            #     iteration_range=(0, booster.best_iteration+1)\n",
    "            # )[:, 0]\n",
    "            # tth_ggf_preds = booster.predict(\n",
    "            #     xgb.DMatrix(\n",
    "            #         data=data_hlf_test[tth_bool], label=xgb_label_test[tth_bool], \n",
    "            #         weight=np.abs(weight_test)[tth_bool],\n",
    "            #         missing=-999.0, feature_names=list(hlf_vars_columns_dict[f\"fold_{fold_idx}\"])\n",
    "            #     ), \n",
    "            #     iteration_range=(0, booster.best_iteration+1)\n",
    "            # )[:, 0]\n",
    "\n",
    "            if np.sum([len(GJet_preds[i]) for i in range(len(GJet_preds))]) < 100000:\n",
    "                GJet_preds.append(nonres_ggf_preds[nonres_ggf_preds > 0.9])\n",
    "\n",
    "            for score_cut in score_cuts:\n",
    "                if len(BDT_perf_resample[fold_idx][f'preds{score_cut}'][plot_var]) >= 10000:\n",
    "                    continue\n",
    "\n",
    "                BDT_perf_resample[fold_idx][f'preds{score_cut}'][plot_var].append(\n",
    "                    data_test_aux.loc[nonres_bool, plot_var].to_numpy()[nonres_ggf_preds > score_cut]\n",
    "                )\n",
    "        if fold_idx == 0 and plot_var == 'mass':\n",
    "            plt.figure()\n",
    "            plt.hist(np.concatenate(GJet_preds), bins=400, range=(0.9, 1.))\n",
    "            plt.savefig(os.path.join(plot_dirpath_, \"GJet_output_dist_with_resample0p9\"))\n",
    "\n",
    "        test_hists = [hist.Hist(VARIABLES[plot_var]).fill(var=np.concatenate(BDT_perf_resample[fold_idx][f'preds{score_cut}'][plot_var])) for score_cut in score_cuts]\n",
    "        make_input_plot(\n",
    "            plot_dirpath_, plot_var,\n",
    "            test_hists, \n",
    "            fold_idx=fold_idx, labels=label_arr, \n",
    "            plot_prefix='test_non-res_scoreCut_'\n",
    "        )\n",
    "\n",
    "for var_idx, plot_var in enumerate(plot_vars):\n",
    "\n",
    "    plot_dirpath_ = os.path.join(plot_dirpath, plot_var)\n",
    "    if not os.path.exists(plot_dirpath_):\n",
    "        os.makedirs(plot_dirpath_)\n",
    "\n",
    "    test_hists = [hist.Hist(VARIABLES[plot_var]).fill(\n",
    "        var=np.concatenate(\n",
    "            [np.concatenate(BDT_perf_resample[fold_idx][f'preds{score_cut}'][plot_var]) for fold_idx in range(len(BDT_perf_resample))]\n",
    "        )\n",
    "    ) for score_cut in score_cuts]\n",
    "    make_input_plot(\n",
    "        plot_dirpath_, plot_var,\n",
    "        test_hists, \n",
    "        fold_idx=None, labels=label_arr, \n",
    "        plot_prefix='test_non-res_scoreCut_'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"pre_std\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "label_arr_fold = [\n",
    "    MC_NAMES_PRETTY[\"GluGluToHH\"]+\" train\", MC_NAMES_PRETTY[\"GluGluToHH\"]+\" val\", MC_NAMES_PRETTY[\"GluGluToHH\"]+\" test\",\n",
    "    MC_NAMES_PRETTY[\"ttHToGG\"]+\" train\", MC_NAMES_PRETTY[\"ttHToGG\"]+\" val\", MC_NAMES_PRETTY[\"ttHToGG\"]+\" test\",\n",
    "    # MC_NAMES_PRETTY[\"single-H\"]+\" train\", MC_NAMES_PRETTY[\"single-H\"]+\" val\", MC_NAMES_PRETTY[\"single-H\"]+\" test\",\n",
    "    # MC_NAMES_PRETTY[\"non-res\"]+\" train\", MC_NAMES_PRETTY[\"non-res\"]+\" val\", MC_NAMES_PRETTY[\"non-res\"]+\" test\",\n",
    "    MC_NAMES_PRETTY[\"VH\"]+\" train\", MC_NAMES_PRETTY[\"VH\"]+\" val\", MC_NAMES_PRETTY[\"VH\"]+\" test\",\n",
    "    MC_NAMES_PRETTY[\"non-res + ggFH + VBFH\"]+\" train\", MC_NAMES_PRETTY[\"non-res + ggFH + VBFH\"]+\" val\", MC_NAMES_PRETTY[\"non-res + ggFH + VBFH\"]+\" test\",\n",
    "]\n",
    "# Loop over and plot the per-fold variables\n",
    "for fold_idx in range(len(hlf_vars_columns_dict)):\n",
    "\n",
    "    for var_name in hlf_vars_columns_dict['fold_0']:\n",
    "        if var_name in {'puppiMET_eta'}:\n",
    "            continue\n",
    "\n",
    "        plot_dirpath_ = os.path.join(plot_dirpath, var_name)\n",
    "        if not os.path.exists(plot_dirpath_):\n",
    "            os.makedirs(plot_dirpath_)\n",
    "\n",
    "        train_hists, val_hists, test_hists = {}, {}, {}\n",
    "        for i, sample_name in enumerate(order):\n",
    "            train_mask = xgb_label_train_dict[f'fold_{fold_idx}'] == i\n",
    "            val_mask = xgb_label_val_dict[f'fold_{fold_idx}'] == i\n",
    "            test_mask = xgb_label_test_dict[f'fold_{fold_idx}'] == i\n",
    "\n",
    "            train_np = (\n",
    "                data_df_dict[f'fold_{fold_idx}'].iloc[train_idxs_dict[f'fold_{fold_idx}']]\n",
    "            ).loc[train_mask, var_name].to_numpy()\n",
    "            val_np = (\n",
    "                data_df_dict[f'fold_{fold_idx}'].iloc[val_idxs_dict[f'fold_{fold_idx}']]\n",
    "            ).loc[val_mask, var_name].to_numpy()\n",
    "            test_np = data_test_df_dict[f'fold_{fold_idx}'].loc[test_mask, var_name].to_numpy()\n",
    "\n",
    "            train_hists[sample_name] = hist.Hist(VARIABLES[var_name]).fill(var=train_np)\n",
    "            val_hists[sample_name] = hist.Hist(VARIABLES[var_name]).fill(var=val_np)\n",
    "            test_hists[sample_name] = hist.Hist(VARIABLES[var_name]).fill(var=test_np)\n",
    "    \n",
    "            make_input_plot(\n",
    "                plot_dirpath_, var_name,\n",
    "                [train_hists[sample_name], val_hists[sample_name], test_hists[sample_name]], \n",
    "                fold_idx=fold_idx, labels=label_arr_fold[3*i : 3*(i+1)], plot_prefix=f'train_val_test_{sample_name}_'\n",
    "            )\n",
    "        for j, (plot_type, histdict) in enumerate([('train_', train_hists), ('val_', val_hists), ('test_', test_hists)]):\n",
    "            make_input_plot(\n",
    "                plot_dirpath_, var_name,\n",
    "                [histdict[sample_name] for sample_name in order], \n",
    "                fold_idx=fold_idx, labels=label_arr_fold[j::3], plot_prefix=plot_type\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"post_std\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "label_arr_fold = [\n",
    "    MC_NAMES_PRETTY[\"GluGluToHH\"]+\" train\", MC_NAMES_PRETTY[\"GluGluToHH\"]+\" val\", MC_NAMES_PRETTY[\"GluGluToHH\"]+\" test\",\n",
    "    MC_NAMES_PRETTY[\"ttHToGG\"]+\" train\", MC_NAMES_PRETTY[\"ttHToGG\"]+\" val\", MC_NAMES_PRETTY[\"ttHToGG\"]+\" test\",\n",
    "    # MC_NAMES_PRETTY[\"single-H\"]+\" train\", MC_NAMES_PRETTY[\"single-H\"]+\" val\", MC_NAMES_PRETTY[\"single-H\"]+\" test\",\n",
    "    # MC_NAMES_PRETTY[\"non-res\"]+\" train\", MC_NAMES_PRETTY[\"non-res\"]+\" val\", MC_NAMES_PRETTY[\"non-res\"]+\" test\",\n",
    "    MC_NAMES_PRETTY[\"VH\"]+\" train\", MC_NAMES_PRETTY[\"VH\"]+\" val\", MC_NAMES_PRETTY[\"VH\"]+\" test\",\n",
    "    MC_NAMES_PRETTY[\"non-res + ggFH + VBFH\"]+\" train\", MC_NAMES_PRETTY[\"non-res + ggFH + VBFH\"]+\" val\", MC_NAMES_PRETTY[\"non-res + ggFH + VBFH\"]+\" test\",\n",
    "]\n",
    "# Loop over and plot the per-fold variables\n",
    "for fold_idx in range(len(hlf_vars_columns_dict)):\n",
    "\n",
    "    for var_idx, var_name in enumerate(hlf_vars_columns_dict['fold_0']):\n",
    "        if var_name in {'puppiMET_eta'}:\n",
    "            continue\n",
    "\n",
    "        plot_dirpath_ = os.path.join(plot_dirpath, var_name)\n",
    "        if not os.path.exists(plot_dirpath_):\n",
    "            os.makedirs(plot_dirpath_)\n",
    "\n",
    "        train_hists, val_hists, test_hists = {}, {}, {}\n",
    "        for i, sample_name in enumerate(order):\n",
    "            train_mask = xgb_label_train_dict[f'fold_{fold_idx}'] == i\n",
    "            val_mask = xgb_label_val_dict[f'fold_{fold_idx}'] == i\n",
    "            test_mask = xgb_label_test_dict[f'fold_{fold_idx}'] == i\n",
    "\n",
    "            train_np = train_data_dict[f'fold_{fold_idx}'][train_mask, var_idx]\n",
    "            val_np = val_data_dict[f'fold_{fold_idx}'][val_mask, var_idx]\n",
    "            test_np = data_hlf_test_dict[f'fold_{fold_idx}'][test_mask, var_idx]\n",
    "\n",
    "            train_hists[sample_name] = hist.Hist(VARIABLES_STD[var_name]).fill(var=train_np)\n",
    "            val_hists[sample_name] = hist.Hist(VARIABLES_STD[var_name]).fill(var=val_np)\n",
    "            test_hists[sample_name] = hist.Hist(VARIABLES_STD[var_name]).fill(var=test_np)\n",
    "    \n",
    "            make_input_plot(\n",
    "                plot_dirpath_, var_name,\n",
    "                [train_hists[sample_name], val_hists[sample_name], test_hists[sample_name]], \n",
    "                fold_idx=fold_idx, labels=label_arr_fold[3*i : 3*(i+1)], plot_prefix=f'train_val_test_{sample_name}_'\n",
    "            )\n",
    "        for j, (plot_type, histdict) in enumerate([('train_', train_hists), ('val_', val_hists), ('test_', test_hists)]):\n",
    "            make_input_plot(\n",
    "                plot_dirpath_, var_name,\n",
    "                [histdict[sample_name] for sample_name in order], \n",
    "                fold_idx=fold_idx, labels=label_arr_fold[j::3], plot_prefix=plot_type\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save out new parquets for Yibo to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL_DATA_ON_ALL_FOLDS = True\n",
    "\n",
    "# load and pre-process the data\n",
    "DATA_FILEPATHS_DICT = {\n",
    "    'Data': [\n",
    "        lpc_fileprefix+f\"/Run3_2022preEE_merged_v5/Data_EraC/nominal/*\", \n",
    "        lpc_fileprefix+f\"/Run3_2022preEE_merged_v5/Data_EraD/nominal/*\",\n",
    "        lpc_fileprefix+f\"/Run3_2022postEE_merged_v5/Data_EraE/nominal/*\",\n",
    "        lpc_fileprefix+f\"/Run3_2022postEE_merged_v5/Data_EraF/nominal/*\",\n",
    "        lpc_fileprefix+f\"/Run3_2022postEE_merged_v5/Data_EraG/nominal/*\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "(\n",
    "    NOTHING_IGNORE,\n",
    "    DATA_data_df_dict, DATA_data_test_df_dict, \n",
    "    DATA_data_hlf_dict, DATA_label_dict,\n",
    "    DATA_data_hlf_test_dict, DATA_label_test_dict, \n",
    "    DATA_hlf_vars_columns_dict,\n",
    "    DATA_data_aux_dict, DATA_data_test_aux_dict\n",
    ") = process_data(\n",
    "    DATA_FILEPATHS_DICT, OUTPUT_DIRPATH, order=['Data'], mod_vals=MOD_VALS, k_fold_test=True,\n",
    "    save=False, std_json_dirpath=OUTPUT_DIRPATH\n",
    ")\n",
    "\n",
    "BDT_DATA_preds = []\n",
    "\n",
    "if EVAL_DATA_ON_ALL_FOLDS:\n",
    "\n",
    "    bdt_train_data_dict = xgb.DMatrix(\n",
    "        data=DATA_data_hlf_dict[f\"fold_0\"], label=DATA_label_dict[f\"fold_0\"], \n",
    "        missing=-999.0, feature_names=list(DATA_hlf_vars_columns_dict[f\"fold_0\"])\n",
    "    )\n",
    "    bdt_test_data_dict = xgb.DMatrix(\n",
    "        data=DATA_data_hlf_test_dict[f\"fold_0\"], label=DATA_label_test_dict[f\"fold_0\"], \n",
    "        missing=-999.0, feature_names=list(DATA_hlf_vars_columns_dict[f\"fold_0\"])\n",
    "    )\n",
    "\n",
    "    for fold_idx in range(len(DATA_label_test_dict)):\n",
    "        booster = xgb.Booster(param)\n",
    "        booster.load_model(os.path.join(OUTPUT_DIRPATH, f'{CURRENT_TIME}_BDT_fold{fold_idx}.model'))\n",
    "\n",
    "        BDT_train_preds = booster.predict(\n",
    "            bdt_train_data_dict, \n",
    "            iteration_range=(0, booster.best_iteration+1)\n",
    "        )\n",
    "        BDT_test_preds = booster.predict(\n",
    "            bdt_test_data_dict, \n",
    "            iteration_range=(0, booster.best_iteration+1)\n",
    "        )\n",
    "\n",
    "        BDT_all_preds = np.concatenate([BDT_train_preds, BDT_test_preds])\n",
    "        BDT_all_preds = BDT_all_preds[\n",
    "            np.argsort(\n",
    "                np.concatenate([DATA_data_aux_dict[f\"fold_0\"].loc[:, 'hash'].to_numpy(), DATA_data_test_aux_dict[f\"fold_0\"].loc[:, 'hash'].to_numpy()])\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        if fold_idx == 0:\n",
    "            BDT_DATA_preds = copy.deepcopy(BDT_all_preds)\n",
    "        else:\n",
    "            BDT_DATA_preds += BDT_all_preds\n",
    "\n",
    "            if fold_idx == len(DATA_label_test_dict) - 1:\n",
    "                BDT_DATA_preds = BDT_DATA_preds / len(DATA_label_test_dict)\n",
    "else:\n",
    "\n",
    "    bdt_train_data_dict, bdt_test_data_dict = {}, {}\n",
    "    for fold_idx in range(len(DATA_label_test_dict)):\n",
    "        \n",
    "        bdt_train_data_dict[f\"fold_{fold_idx}\"] = xgb.DMatrix(\n",
    "            data=DATA_data_hlf_dict[f\"fold_{fold_idx}\"], label=DATA_label_dict[f\"fold_{fold_idx}\"], \n",
    "            missing=-999.0, feature_names=list(DATA_hlf_vars_columns_dict[f\"fold_{fold_idx}\"])\n",
    "        )\n",
    "        bdt_test_data_dict[f\"fold_{fold_idx}\"] = xgb.DMatrix(\n",
    "            data=DATA_data_hlf_test_dict[f\"fold_{fold_idx}\"], label=DATA_label_test_dict[f\"fold_{fold_idx}\"], \n",
    "            missing=-999.0, feature_names=list(DATA_hlf_vars_columns_dict[f\"fold_{fold_idx}\"])\n",
    "        )\n",
    "\n",
    "        booster = xgb.Booster(param)\n",
    "        booster.load_model(os.path.join(OUTPUT_DIRPATH, f'{CURRENT_TIME}_BDT_fold{fold_idx}.model'))\n",
    "\n",
    "        BDT_DATA_preds.append(\n",
    "            booster.predict(\n",
    "                bdt_test_data_dict[f\"fold_{fold_idx}\"], \n",
    "                iteration_range=(0, booster.best_iteration+1)\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0QAAANUCAYAAACTz+21AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABQhUlEQVR4nO3dfZSdVX0v8O+ZF8NLhCREB8igokB0xDcKhmCt2vLibeuVSgXhprUUyq13arvk1kXtsg1EvLS2tsu2p3qL9FIrNaJUEdoLSIsvrYgQ4AqMBcFiZAIHNANoiElm5rl/jDNkkpmTyeScOWfm+XzWmrVg9nOe+c3kIZzv7L1/u1IURREAAIAS6mh1AQAAAK0iEAEAAKUlEAEAAKUlEAEAAKUlEAEAAKUlEAEAAKUlEAEAAKXV1eoCGuXAAw/Mj3/843R2dub5z39+q8sBAABa5PHHH8/IyEj222+/bNmype61lYVyMGtnZ2dGR0dbXQYAANAmOjo6MjIyUveaBTNDNB6IOjo6cthhh7W0lqIosmnTphx++OGpVCotrWVcrVZLT09Pq8tIopapeGbqU8vu2u2ZaZefy7h2qqddavHM1NdO9bRLLZ6Z6bVTLUn71NNOz8yjjz6a0dHRdHZ27vHaBTND1Nvbm8HBwaxYsSKPPPJIS2t5+umnc/DBB+epp57KQQcd1NJaxvX19WVgYKDVZSRRy1Q8M/WpZXft9sy0y89lXDvV0y61eGbqa6d62qUWz8z02qmWpH3qaadnZm+ygaYKAABAaQlEAABAaQlEAABAaQlEAABAaQlEAABAaQlEJdHf39/qEiaoZX5op5+NWtpfu/1c2qmedqqlnbTbz6Wd6mmnWtpJO/1c2qmWpP3qmW+03W6Cdmo5yPzgmWFveWbYW54Z9pZnhr3VTs+MttsAAAAzIBABAAClJRABAAClJRABAAClJRABAACl1dXqAhqtVqulr69vyrH+/n5tCQEAYAGoVqupVqtTjtVqtRnfZ8EFop6engwMDLS6DAAAoInqTXaMt92eCUvmmmDRokVZu3ZtFi1a1OpSmCc8M+wtzwx7yzPD3vLMsLfm6zPjYFYAAGBBcTArAADADAhEAABAaQlEAABAaQlEAABAaQlEAABAaQlEAABAaQlEAABAaQlEAABAaQlEAABAaQlEAABAaQlEAABAaQlEAABAaQlEAABAaQlEAABAaXW1uoCFpiiKDI/u+bqujqRSqTS/IAAAYFoCUYMNjyafvH3zHq9bc8KydHfOQUEAAMC0BKImGxktcs+mrUmSVxy+fzo7zAoBAEC7EIia6B0/tTRdOwWg4dEi6zcMtbAiAABgZwJRE3V1VNLdaUYIAADalS5zAABAaQlEAABAaQlEAABAaQlEAABAaQlEAABAaQlEAABAaQlEAABAaQlEAABAaQlEAABAaQlEAABAaQlEAABAaQlEAABAaQlEAABAaQlEAABAaQlEAABAaQlEAABAaQlEAABAaQlEAABAaQlEAABAaQlEAABAaQlEAABAaQlEAABAaQlEAABAaQlEAABAaQlEAABAaQlEAABAaQlEAABAaQlEAABAaQlEAABAaQlEAABAaQlEAABAaQlEAABAaQlEAABAaQlEAABAaXW1uoCpjI6OZuvWrbt9vrOzM/vtt18LKgIAABaitpwhuuWWW7J48eLdPt7+9re3ujQAAGABacsZou985zs55JBDcu211076/NKlS1tUEQAAsBC1bSA66qij8rrXva7VpQAAAAtYQ5bMXXbZZalUKhkZGZn2mkcffTQXXHBBent7s//++2flypVZt25dtm/fvtu1Dz30UF784hcnSd17AgAA7It9DkRFUeTqq6+ue83GjRtz3HHH5fLLL8/g4GD222+/PPDAA1m7dm1OOeWU7NixY9L13/nOd7Jx48Yce+yxec5znpMXvvCFueSSS3a7DgAAYF/sUyAaGRnJunXrcvfdd9e97rzzzstjjz2WU089NRs3bszQ0FBuv/32rFixIl/5ylfyoQ99aNL1Dz30UO65556cf/75uf7663POOefkgx/8YN773vfuS7kAAACTzGoP0fXXX59rrrkmX/rSl/Lwww/Xvfauu+7KzTffnEMPPTTr16+faIxw/PHH5zOf+UxOOumkfOQjH8lFF12Urq6ujI6O5mMf+1he9apX5aUvfWmS5L/8l/+SRYsW5dJLL826dety0EEHzaZsAACASWY1Q3TNNdfkyiuv3GMYSpLrrrsuSXL66afv1iVu9erVWblyZZ544oncdtttYwV1dOSss86aCEPjfvEXfzEjIyMZGBiYTckAAAC7mVUguvTSS3PvvfdOfNRz6623JklOO+20KcfHPz9+3eDgYP7pn/5pt/1CHR1jpZodAgAAGmVWS+ZWrFiRFStWzOjaBx98MEly1FFHTTn+kpe8JMnYvqEk2bp1a37xF38x//AP/5Czzz574rrrrrsuS5cuzdFHHz2bkgEAAHbT9HOInnjiiSTJkiVLphxftmxZkqRWqyUZC05nnHFGfvM3fzPf+MY3snr16nz961/PX/7lX+ajH/1ouru76369oijy9NNPz7reRYsWZdGiRbN+PQAAsG+2bduWbdu2zfr1RVHM+NqmB6JnnnkmSXbbPzRu/PPj1yXJlVdemT/4gz/IZz/72Vx++eV5+ctfnvXr1+eMM87Y49fbtGlTDj744FnXu3bt2lx88cWzfj0AALBvLrvsslxyySVz8rWaHojGTZfSOjs7k0w+gHXx4sX58z//8/z5n//5Xn+dww8/PN/61rdmV2RidggAAFrsfe97Xy688MJZv/5lL3tZNm3aNKNrmx6IDjjggDz11FMZGhrK4sWLdxsfnxk68MADG/L1KpWKxgsAADCP7es2lkqlMuNr9+lg1plYvnx5kuTJJ5+ccvzxxx+fdB0AAMBcaXogGu8K98ADD0w5ft999026DgAAYK40PRCtXr06SXLTTTdNOX7jjTcmSU488cRmlwIAADBJ0wPRW97yliTJtddem82bN08a+9rXvpZvf/vbWb58eU466aRmlwIAADBJ0wPRa17zmpxyyimp1Wo555xz8sgjj6QoimzYsCFnnnlmkuTCCy/c4/lCAAAAjTYnbbc//vGPZ9WqVbnxxhtzxBFHZMmSJRNNFt70pjflve9971yUAQAAMEnTZ4iS5AUveEHuvPPOnH/++TnssMOydevWHHPMMVm3bl1uuOGGdHXN2XFIAAAAExqSRKY7dHVnhx12WC6//PJGfLm6arVa+vr6phzr7+9Pf39/02sAAACaq1qtplqtTjlWq9VmfJ8FNzXT09OTgYGBVpcBAAA0Ub3Jjt7e3gwODs7oPnOyZA4AAKAdCUQAAEBpCUQAAEBpCUQAAEBpCUQAAEBpCUQAAEBpCUQAAEBpCUQAAEBpCUQAAEBpCUQAAEBpdbW6gEar1Wrp6+ubcqy/vz/9/f1zXBEAANBo1Wo11Wp1yrFarTbj+yy4QNTT05OBgYFWlwEAADRRvcmO3t7eDA4Ozug+lswBAAClJRABAAClJRABAAClJRABAAClJRABAAClJRABAAClJRABAAClJRABAAClJRABAAClJRABAAClJRABAACl1dXqAhqtVqulr69vyrH+/v709/fPcUUAAECjVavVVKvVKcdqtdqM77PgAlFPT08GBgZaXQYAANBE9SY7ent7Mzg4OKP7WDIHAACUlkAEAACUlkAEAACUlkAEAACUlkAEAACUlkAEAACUlkAEAACUlkAEAACUlkAEAACUlkAEAACUlkAEAACUlkAEAACUlkAEAACUVlerC2i0Wq2Wvr6+Kcf6+/vT398/xxUBAACNVq1WU61Wpxyr1Wozvs+CC0Q9PT0ZGBhodRkAAEAT1Zvs6O3tzeDg4IzuY8kcAABQWgIRAABQWgIRAABQWgIRAABQWgIRAABQWgIRAABQWgIRAABQWgIRAABQWgIRAABQWgIRAABQWgIRAABQWgIRAABQWgIRAABQWgIRAABQWgIRAABQWgIRAABQWl2tLqDRarVa+vr6phzr7+9Pf3//HFcEAAA0WrVaTbVanXKsVqvN+D4LLhD19PRkYGCg1WUAAABNVG+yo7e3N4ODgzO6jyVzAABAaQlEAABAaQlEAABAaQlEAABAaQlEAABAaQlEAABAaQlEAABAaQlEAABAaQlEAABAaQlEAABAaQlEAABAaQlEAABAaQlEAABAaQlEAABAaQlEAABAaQlEAABAaQlEAABAaQlEAABAaQlEAABAaQlEAABAaXW1uoBGq9Vq6evrm3Ksv78//f39c1wRAADQaNVqNdVqdcqxWq024/ssuEDU09OTgYGBVpcBAAA0Ub3Jjt7e3gwODs7oPpbMAQAApSUQAQAApSUQAQAApSUQAQAApSUQAQAApSUQAQAApSUQAQAApSUQAQAApSUQAQAApSUQAQAApSUQAQAApSUQAQAApSUQAQAApSUQAQAApSUQAQAApdXV6gLKani0mHasqyOpVCpzWA0AAJSTQNQi6zcMTTu25oRl6e6cw2IAAKCkBKIWGhktcs+mrUmSVxy+fzo7zAoBAMBcEojmUFfH2OzPVIZHi7qzRgAAQOMJRHOoUqlYCgcAAG1ElzkAAKC0BCIAAKC0BCIAAKC0BCIAAKC0BCIAAKC0BCIAAKC0BCIAAKC0Ftw5RLVaLX19fVOO9ff3p7+/f44rAgAAGq1araZarU45VqvVZnyfBReIenp6MjAw0OoyAACAJqo32dHb25vBwcEZ3ceSOQAAoLQEIgAAoLQEIgAAoLQEIgAAoLQEIgAAoLQEIgAAoLQEIgAAoLQEIgAAoLQEIgAAoLQEIgAAoLQEIgAAoLQEIgAAoLQEIgAAoLQEIgAAoLQEIgAAoLQEIgAAoLQEIgAAoLQEIgAAoLQEIgAAoLQEIgAAoLQEIgAAoLQEIgAAoLQEIgAAoLQEIgAAoLQEIgAAoLQEIgAAoLQEIgAAoLQEIgAAoLQEIgAAoLQEIgAAoLQEIgAAoLQEIgAAoLQEIgAAoLQEIgAAoLQEIgAAoLQEIgAAoLQEIgAAoLQEIgAAoLS6Wl1Ao9VqtfT19U051t/fn/7+/jmuCAAAaLRqtZpqtTrlWK1Wm/F9Flwg6unpycDAQKvLAAAAmqjeZEdvb28GBwdndB9L5gAAgNISiAAAgNISiAAAgNISiAAAgNISiAAAgNISiAAAgNISiAAAgNISiAAAgNISiAAAgNISiAAAgNISiAAAgNISiAAAgNLqanUB7G54tKg73tWRVCqVOaoGAAAWLoGoDa3fMJSR0SL3bNqaJHnF4funs+PZALTmhGXp7mxVdQAAsHBYMgcAAJSWGaI20dUxNvMzneHRIus3DM1hRQAAsPAJRG2iUqlYBgcAAHPMkjkAAKC0BCIAAKC0BCIAAKC0BCIAAKC0BCIAAKC0BCIAAKC0BCIAAKC0BCIAAKC0BCIAAKC0BCIAAKC0BCIAAKC0BCIAAKC0BCIAAKC0BCIAAKC0BCIAAKC0BCIAAKC0BCIAAKC0BCIAAKC0BCIAAKC0BCIAAKC0BCIAAKC0BCIAAKC0BCIAAKC0BCIAAKC0BCIAAKC0BCIAAKC0BCIAAKC0BCIAAKC0BCIAAKC0BCIAAKC0BCIAAKC0BCIAAKC0BCIAAKC0BCIAAKC0BCIAAKC0BCIAAKC0BCIAAKC0BCIAAKC0BCIAAKC05kUg+oVf+IWcffbZrS4DAABYYNo+EP3t3/5t/vmf/7nVZbSV4dEiO0am/iiKotXlAQDAvNHV6gLq+d73vpf3vOc9Oeigg1pdSlu56vbNuWfT1iTJKw7fP50dlYmxNScsS3dnqyoDAID5pSEzRJdddlkqlUpGRkamvebRRx/NBRdckN7e3uy///5ZuXJl1q1bl+3bt0/7mvPPPz9vectbctxxxzWiTAAAgEn2eYaoKIpcffXVda/ZuHFjVq1alcceeyxJsmTJkjzwwANZu3Zt/uVf/iU333xzuru7J73mb/7mb/LNb34z9913X84444x9LXPe6+oYm/2ZyvBokfUbhua4IgAAmP/2aYZoZGQk69aty9133133uvPOOy+PPfZYTj311GzcuDFDQ0O5/fbbs2LFinzlK1/Jhz70oUnXf/e7383v/u7v5mMf+1iWLZs6BJRNpVJJd+fUH107LZkDAABmblaB6Prrr8+5556bo446KhdffHHda++6667cfPPNOfTQQ7N+/focccQRSZLjjz8+n/nMZ5IkH/nIRzI8PJxkbMbp13/91/PWt741b33rW2dTHgAAwIzMKhBdc801ufLKK/Pwww/v8drrrrsuSXL66adn6dKlk8ZWr16dlStX5oknnshtt92WZKyr3De/+c188IMfzJYtW7Jly5aMjIxkx44d2bJly0RwAgAA2FezCkSXXnpp7r333omPem699dYkyWmnnTbl+Pjnx6+799578/3vfz8vfOELs3jx4ixevDhf/epXc80112Tx4sX59Kc/PZuSAQAAdjOrpgorVqzIihUrZnTtgw8+mCQ56qijphx/yUtekiR56KGHkiS//du/nV/+5V+edM273/3uLFu2LJdcckmOOeaYul+vKIo8/fTTM6ptKosWLcqiRYtm/XoAAGDfbNu2Ldu2bZv16/fmbM6mn0P0xBNPJBnrLDeV8aYJtVotSXLkkUfmyCOPnHTNwQcfnOc973l53etet8evt2nTphx88MGzrnft2rV73BcFAAA0z2WXXZZLLrlkTr5W0wPRM888kyS77R8aN/758ev21eGHH55vfetbs3692SEAAGit973vfbnwwgtn/fqXvexl2bRp04yubXogGjfdtFVnZ2eS1D3U9ZZbbpnx16lUKjnooIP2rjgAAKBt7Os2lkpl5sfS7NM5RDNxwAEHJEmGhqY+OHR8ZujAAw9sdikAAACTND0QLV++PEny5JNPTjn++OOPT7oOAABgrjQ9EB199NFJkgceeGDK8fvuu2/SdQAAAHOl6YFo9erVSZKbbrppyvEbb7wxSXLiiSc2uxQAAIBJmh6I3vKWtyRJrr322mzevHnS2Ne+9rV8+9vfzvLly3PSSSc1uxQAAIBJmh6IXvOa1+SUU05JrVbLOeeck0ceeSRFUWTDhg0588wzkyQXXnhhuru7m10KAADAJHPSdvvjH/94Vq1alRtvvDFHHHFElixZMtFk4U1velPe+973zkUZAAAAkzR9hihJXvCCF+TOO+/M+eefn8MOOyxbt27NMccck3Xr1uWGG25IV9ecHYcEAAAwoSFJZLpDV3d22GGH5fLLL2/El6urVqulr69vyrH+/v709/c3vQYAAKC5qtVqqtXqlGO1Wm3G91lwUzM9PT0ZGBhodRkAAEAT1Zvs6O3tzeDg4IzuMydL5gAAANqRQAQAAJSWQAQAAJSWQAQAAJSWQAQAAJSWQAQAAJSWQAQAAJSWQAQAAJSWQAQAAJRWV6sLaLRarZa+vr4px+qdZgsAAMwf1Wo11Wp1yrFarTbj+yy4QNTT05OBgYFWlwEAADRRvcmO3t7eDA4Ozug+Cy4Qld3waDHtWFdHUqlU5rAaAABobwLRAnPV7Ztzz6atSZJXHL5/OjueDUBrTliW7s5WVQYAAO1HUwUAAKC0zBAtAF0dY7M/UxkeLbJ+w9AcVwQAAPODQLQAVCoVS+EAAGAWLJkDAABKSyACAABKSyACAABKSyACAABKSyACAABKSyACAABKSyACAABKa8GdQ1Sr1dLX1zflWH9/f/r7++e4IgAAoNGq1Wqq1eqUY7Vabcb3WXCBqKenJwMDA60uAwAAaKJ6kx29vb0ZHByc0X0smQMAAEpLIAIAAEpLIAIAAEpLIAIAAEpLIAIAAEpLIAIAAEpLIAIAAEpLIAIAAEpLIAIAAEpLIAIAAEpLIAIAAEpLIAIAAEpLIAIAAEqrq9UFNFqtVktfX9+UY/39/env75/jigAAgEarVqupVqtTjtVqtRnfZ8EFop6engwMDLS6DAAAoInqTXb09vZmcHBwRvexZA4AACitBTdDxPSGR4tpx7o6kkqlMofVAABA6wlEJXLV7Ztzz6atSZJXHL5/OjueDUBrTliW7s5WVQYAAK1hyRwAAFBaZogWuK6OsdmfqQyPFlm/YWiOKwIAgPYhEC1wlUrFUjgAAJiGJXMAAEBpCUQAAEBpCUQAAEBpCUQAAEBpCUQAAEBpCUQAAEBpCUQAAEBpCUQAAEBpCUQAAEBpCUQAAEBpdbW6gEar1Wrp6+ubcqy/vz/9/f1zXBEAANBo1Wo11Wp1yrFarTbj+yy4QNTT05OBgYFWlwEAADRRvcmO3t7eDA4Ozug+lswBAAClJRABAAClJRABAAClJRABAAClJRABAAClJRABAAClJRABAAClteDOIWJ2tu4YzSduG0qSnH38snR3VibGujqSSqUy3UsBAGDeEohIklx951Du2bQ1SVLcsTmdHc8GoDUnLEt3Z6sqAwCA5rFkDgAAKC0zRCXW1TE2+zOV4dEi6zcMzXFFAAAwtwSiEqtUKpbCAQBQapbMAQAApSUQAQAApSUQAQAApSUQAQAApSUQAQAApSUQAQAApSUQAQAApSUQAQAApbXgDmat1Wrp6+ubcqy/vz/9/f1zXBEAANBo1Wo11Wp1yrFarTbj+yy4QNTT05OBgYFWlwEAADRRvcmO3t7eDA4Ozug+lswBAAClJRABAAClteCWzNF4w6PFtGNdHUmlUpnDagAAoHEEIvboqts3555NW5Mkrzh8/3R2PBuA1pywLN2draoMAAD2jSVzAABAaZkhYkpdHWOzP0myY6TIp+7YnCQ5+/hlqVSS9RuGWlkeAAA0hEDElCqVysRSuO7OSs47afnE2I6R6fcUAQDAfGLJHAAAUFoCEQAAUFoCEQAAUFoCEQAAUFoCEQAAUFoCEQAAUFoCEQAAUFoCEQAAUFoCEQAAUFoCEQAAUFoCEQAAUFoCEQAAUFoCEQAAUFoCEQAAUFoCEQAAUFoCEQAAUFoCEQAAUFpdrS6A+W3rjtF84rahJMnZxy9Ld2dlYqyrI6lUKtO9FAAAWk4gYp9cfedQ7tm0NUlS3LE5nR3PBqA1JyxLd2erKgMAgD1bcIGoVqulr69vyrH+/v709/fPcUUAAECjVavVVKvVKcdqtdqM77PgAlFPT08GBgZaXcaC1tUxNvuTJDtGinzqjs1JxpbMVSrJ+g1DrSwPAIASqDfZ0dvbm8HBwRndZ8EFIpqvUqlMLIXr7qzkvJOWT4ztGClaVBUAAOw9XeYAAIDSEogAAIDSEogAAIDSEogAAIDSEogAAIDSEogAAIDSEogAAIDSEogAAIDSEogAAIDSEogAAIDS6mp1ASxcW3eM5hO3DSVJzj5+Wbo7KxNjXR1JpVKZ7qUAADAnBCKa5uo7h3LPpq1JkuKOzenseDYArTlhWbo7W1UZAACMsWQOAAAoLTNENFRXx9jsT5LsGCnyqTs2JxlbMlepJOs3DLWyPAAAmEQgoqEqlcrEUrjuzkrOO2n5xNiOkaJFVQEAwNQsmQMAAEpLIAIAAEpLIAIAAEpLIAIAAEpLIAIAAEpLIAIAAEpLIAIAAEpLIAIAAEpLIAIAAEqrq9UFUE5bd4zmE7cNJUnOPn5ZujsrE2NdHUmlUpnupQAA0DACES1x9Z1DuWfT1iRJccfmdHY8G4DWnLAs3Z2tqgwAgDKxZA4AACgtM0TMma6OsdmfJNkxUuRTd2xOMrZkrlJJ1m8YamV5AACUkEDEnKlUKhNL4bo7KznvpOUTYztGihZVBQBAmVkyBwAAlJZABAAAlJZABAAAlJZABAAAlJZABAAAlJZABAAAlJZABAAAlJZABAAAlNaCO5i1Vqulr69vyrH+/v709/fPcUXsra07RvOJ24aSJGcfvyzdnZWJsa6OsQNeAQAot2q1mmq1OuVYrVab8X0WXCDq6enJwMBAq8tgH1x951Du2bQ1SVLcsTmdHc8GoDUnLEt3Z6sqAwCgXdSb7Ojt7c3g4OCM7mPJHAAAUFoLboaI+amrY2z2J0l2jBT51B2bk4wtmatUkvUbhlpZHgAAC5RARFuoVCqTlsJ1/GSZ3M77hwAAoNEEItpOd2cl5554yMS/7xgpWlgNAAALmT1EAABAaQlEAABAaQlEAABAadlDxLzi0FYAABpJIGJecWgrAACNZMkcAABQWmaIaHsObQUAoFkEItqeQ1sBAGgWgYh5xaGtAAA0kj1EAABAaQlEAABAaQlEAABAaQlEAABAaQlEAABAaQlEAABAaQlEAABAaQlEAABAaQlEAABAaQlEAABAaXW1ugBopB0jRT55++YkyZoTlqW7s9LiigAAaGcCEQvG8GiRokhGR4skY+FoXFdHUqkIRwAATCYQsWCs3zCUkdEi92zamiQp7ticzo6xEDQ2W9TK6gAAaEf2EAEAAKVlhoh5ratjbPZn3I6RIp+6Y2wP0duPW5pr7n6yRZUBADAfCETMa5VKZdJSuO7OSs47aXmSyXuIAABgKpbMAQAApSUQAQAApSUQAQAApWUPEaUwPFpMarhw9vHPHtrqjCIAgPISiCgFZxQBADAVS+YAAIDSMkPEguWMIgAA9kQgYsHa9YyiJOnoGN83ZM8QAAACESXS3VnJuSceksShrQAAjLGHCAAAKC2BCAAAKC2BCAAAKC17iCBje4o+eftYB7qxc4k0XQAAKAOBiNIbHi1SFMno6FijhZ0bLnR1jHWrAwBgYRKIKL31G4YyMlrknk1bkyTFHZvT+ZO23GOzRa2sDgCAZrKHCAAAKC0zRJRSV8fY7M+4HSNFPnXH2B6itx+3NNfc/WSLKgMAYC4JRJRSpVLZbSlcx0+WyXV12DMEAFAWAhEk6e6s5NwTD0kyuakCAAALmz1EAABAaQlEAABAaQlEAABAaQlEAABAaWmqAHuwY6TIJ28fa8k9dlCrLnQAAAuFQAR1DI8WKYpkdHSs89zOHei6OsbadwMAMH8JRFDH+g1DGRktcs+mrUmS4o7N6fzJOUVjs0WtrA4AgH1lDxEAAFBabRmInn766fzWb/1WjjzyyCxevDjHHXdc1q9f3+qyKImujrHZn/GPc45fllcevn9eefj+OfO4pa0uDwCABmrLJXPnnXdebrnllrz//e/PEUcckeuvvz5nn312nvvc5+YXfuEXWl0eC1ylUtltKVzHT5bJdXXYMwQAsJC0XSD6wQ9+kM9+9rO54oor8uu//utJkjPOOCP33ntvPvnJTwpEzLnuzkrOPfGQJJObKgAAMP81ZMncZZddlkqlkpGRkWmvefTRR3PBBRekt7c3+++/f1auXJl169Zl+/btk67bvHlzTj755Lz+9a+f9PkXvOAF2bp1ayPKhYbZMVLk/3z9B/k/X/+BsAQAMA/t8wxRURS5+uqr616zcePGrFq1Ko899liSZMmSJXnggQeydu3a/Mu//EtuvvnmdHd3J0mOPvrofPGLX0ySbNu2Ld///vfz1a9+NTfddFP++q//el/LhYbRkhsAYP7bpxmikZGRrFu3LnfffXfd684777w89thjOfXUU7Nx48YMDQ3l9ttvz4oVK/KVr3wlH/rQh6Z83V/91V+lt7c3Z599ds4444ysWbNmX8qFhlq/YSj/cMfmfHPT1nxz09b8wx2b88nbxz6GR1tdHQAAMzGrQHT99dfn3HPPzVFHHZWLL7647rV33XVXbr755hx66KFZv359jjjiiCTJ8ccfn8985jNJko985CMZHh7e7bXveMc78sUvfjEf/OAH89nPfjbvfe97Z1MutITldAAA7W9WS+auueaaXHnllTO69rrrrkuSnH766Vm6dHLL4tWrV2flypW5//77c9ttt+V1r3vdpPEVK1ZkxYoVOfnkk1OpVPLnf/7n+ZM/+RNLkWiZ8Zbc43aMFPnUHZuTJG8/bmmuufvJJJbTAQDMF7OaIbr00ktz7733TnzUc+uttyZJTjvttCnHxz8/ft1VV12VV73qVbs1aDj66KPzxBNP5Mknn5xNydAQYy25J390dIx97NyS23I6AID5YVYzROMzNzPx4IMPJkmOOuqoKcdf8pKXJEkeeuihJElvb2+++c1v5vbbb8+JJ544cd2XvvSlHHbYYbvNMkErackNADC/Nf0coieeeCLJWGe5qSxbNrb8qFarJUle//rX57WvfW3OOuusXHTRRenp6cktt9ySj370o/noRz+6x69XFEWefvrpWde7aNGiLFq0aNavp7xmupwOAID6tm3blm3bts369UUx819UNz0QPfPMM0ky7czO+OfHr+vo6MgXvvCFXHTRRbnsssvy5JNP5qUvfWmuuuqqvOMd79jj19u0aVMOPvjgWde7du3aPTaKgKmMLaeb/LmOnyyj23k5HQAA9V122WW55JJL5uRrNT0QjZsupXV2jr2D3HnPUE9Pz4ybNuzq8MMPz7e+9a1ZvTaJ2SEaxnI6AIDZed/73pcLL7xw1q9/2ctelk2bNs3o2qYHogMOOCBPPfVUhoaGsnjx4t3Gx2eGDjzwwIZ8vUqlkoMOOqgh9wIAAObevm5j2ZuOvvt0MOtMLF++PEmm7Q73+OOPT7oOAABgrjQ9EB199NFJkgceeGDK8fvuu2/SdQAAAHOl6YFo9erVSZKbbrppyvEbb7wxSSa12AYAAJgLTQ9Eb3nLW5Ik1157bTZv3jxp7Gtf+1q+/e1vZ/ny5TnppJOaXQoAAMAkTQ9Er3nNa3LKKaekVqvlnHPOySOPPJKiKLJhw4aceeaZSZILL7ww3d3dzS4F2saOkSL/5+s/yP/5+g90oAMAaKE5abv98Y9/PKtWrcqNN96YI444IkuWLJlosvCmN70p733ve+eiDGgLw6NFiiIZHR0LQjsHoq6OveuKAgDAvpmTQPSCF7wgd955Z/7wD/8w//RP/5TNmzfnmGOOyZo1a3LRRRelq2vOjkOCllu/YSgjo0Xu2bQ1SVLcsTmdPzm4dc0Jy3Y73BUAgOZpSBKZ7tDVnR122GG5/PLLG/Hl6qrVaunr65tyrL+/P/39/U2vAQAAaK5qtZpqtTrlWK1Wm/F9FtzUTE9PTwYGBlpdBkzS1TE2+zNux0iRT90x1mTk7cctzTV3P9miygAA5qd6kx29vb0ZHByc0X0WXCCCdlSpVHZbCtfxk2VyXR2T9wztGCnyydvHwtLYEjp7igAAmqXpXeYAAADalRkiaIHuzkrOPfGQJJO7zOlABwAwtwQiaCM60AEAzC1L5gAAgNIyQwQtpgMdAEDrCETQYnvTgQ4AgMYSiKDNTNdwAQCAxrOHCAAAKC0zRDCPOLQVAKCxFlwgqtVq6evrm3Ksv78//f39c1wRNIYzigAAnlWtVlOtVqccq9VqM77PggtEPT09GRgYaHUZ0HDOKAIAeFa9yY7e3t4MDg7O6D72EAEAAKW14GaIYCFxRhEAQHMJRNDGnFEEANBcAhEsEDrQAQDsPYEI5pHZHtoqLAEATE0gggWgXkvu8X/XrhsAYHcCESwA9VpyJ9GuGwBgGtpuAwAApWWGCOapei25zz5+8j4h7boBAKYmEME8Va8ld3dnZbfGCdp1AwDszpI5AACgtBbcDFGtVktfX9+UY/39/env75/jimBu7NySu97Y3rTrBgBoV9VqNdVqdcqxWq024/ssuEDU09OTgYGBVpcBAAA0Ub3Jjt7e3gwODs7oPpbMAQAApbXgZoiAvbNjpMgnbx/rQDd2LpGmCwBAeZghAgAASssMEZTY8GiRokhGR8caLezacKEoilx1x1ASs0cAwMIkEEGJrd8wlJHRIvds2pokKe7YnM6dzik667ilrSoNAGBOCETAtIZHi2lnj7o6xg6HBQCYzwQiKJmujrHlb+N2jBT51B1jTRXOPn5ZKpWxmaMkufrOoWlnj8aW0M1h4QAATSAQQclUKpXdgkzHT4KOPUIAQNkIRMAkO88g1Zs9AgBYCAQiKLnuzkrOPfGQXT737D9PN3vk/CIAYCFwDhEAAFBaZoiAae06e7Rzpzkd6ACAhUAgAmZFBzoAYCFYcIGoVqulr69vyrH+/v709/fPcUUAAECjVavVVKvVKcdqtdqM77PgAlFPT08GBgZaXQYsSDrQAQDtot5kR29vbwYHB2d0nwUXiIDm2fUMI+cXAQDznS5zAABAaQlEAABAaVkyB8xKvZbcDm0FAOYLM0QAAEBpmSECGs6hrQDAfCEQAQ3n0FYAYL4QiIA5ZX8RANBOBCKgIRzaCgDMRwIR0BAzPbTV/iIAoJ0IRMCcsr8IAGgnAhHQcPXOKKrH/iIAYK4JREDT2V8EALQrgQhoOvuLAIB2JRABbaPe/qKzjluaT99pOR0A0FgCETCnZru/CACgGRZcIKrVaunr65tyrL+/P/39/XNcEVCP/UUAwGxUq9VUq9Upx2q12ozvs+ACUU9PTwYGBlpdBjBD9hcBALNRb7Kjt7c3g4ODM7rPggtEwMLk/CIAoBk6Wl0AAABAq5ghAtrGrg0XiqKwvwgAaCqBCGhbM91fBAAwWwIRsKDtGCnyydudXwQATE0gAuYF5xcBAM2gqQIAAFBaZoiAeW/XZXFdHcnw6LNjzi8CAKYjEAELzvBoJgLSyGjh/CIAYFqWzAEAAKVlhgiY94ZHJy+L23kV3JnHLc34vzq/CADYlUAEzHtX3zk07bK4ro6K84sAgGlZMgcAAJSWGSJgXurqGGuKkIwtk/vUHWNNFM4+fvLhq0Ux/XlFDm0FAAQiYF6qVCqTOsTtvCxucrBxoCsAMD2BCGAWzC4BwMIgEAHzXnfn5Fmgmdq1O93OHNoKAOUgEAGlVa87nUNbAaAcBCKAKey6JK6rIxkenTw+1eySmSUAmF8EIqBU6nWnq3do6/BoJgJSkoyMFlPOLplZAoD5ZcEFolqtlr6+vinH+vv709/fP8cVAe2kXnc6AGD+qFarqVarU47VarUZ32fBBaKenp4MDAy0ugxgntu14cLOq+De8VNLUxSZmF16+3FLc83dT06M60AHAM1Xb7Kjt7c3g4ODM7rPggtEAI1Qr+FC10/+eXx2qatD4AGA+UogAkpr13bdDm0FgPIRiAB+ol7DhZ2Xve3acW5nw6NFiiI60AHAPCEQAfxEvYYLu+4D6u7MxOzSzqFn/YYhHegAYB7paHUBAAAArWKGCGAf7bzULpm83G7XDnQAQHsRiACmsGvDhXp2XWqX6EAHAPOFQASwgDkTCQDqE4gA5pCAAgDtRVMFAACgtMwQATTYzvuP5vqw16IoJp2RtGOkcCYSANQhEAEsIMOjmViSl8SZSACwBwIRwBwZHi1SFJnVjI29RwDQHAIRwBxZv2GoKTM2O4els45bOvH5d/zU0hRFZnUmkgAGQFkIRABtotEhZPwMJGciAcD0BCKAJurqGAs343aMFLOasQEAmkMgAmiiSqWy21K4mczYFEWRHSPP/nu9bnEAwOwJRABtaHg0+fSde+4WN75PaDwsDY/Ors33XLTrti8JgHYkEAG0gV070M002OzWqCGZCEvJzM9E0q4bgLISiADm0HQBpV6w2ZducQBAfQIRQJvbtVvcfl2VaRs1nH38s0vRZru/aE8BzNI3ABYSgQigRep1oNs12Oy8v2esUcPkEDIelro7dx/b+7oa0657pvuSxr7G7PcmAdAcZfkFmEAE0CL1OtDtHmxm1yyhlWa6LymxNwmA1hGIAOaBnfcelU1ZfkMJQGsIRADzXDPC0nTNH3bthjfTlty77ks6+/hlqVTGmkkAQCsJRABtYj7MAu3WDW+GLbl33ZdklgegPe28/7Msez8FIgAAIMnk/Z9l2fu54AJRrVZLX1/flGP9/f3p7++f44oA5rd63fCadSZSs39DaV8SwPxXrVZTrVanHKvVajO+z4ILRD09PRkYGGh1GQALRr1ueHvTknvXJYG7hpudlfE3lADt5szjlmb8b9x23PtZb7Kjt7c3g4ODM7rPggtEAMw/u87YANB6XR2VUuz9FIgAaGvt/htKAOY3gQiAttao31CWsXMSQLMspL2YAhEAe2W6M4ranX1JAExFIAIAAHazN81w5jOBCICWGx6dvISt2SvW7EsCYJxABEDLXX3n0LRL2JrxG8qydE4CaJZdf5G1s/m2F1MgAiipnTfEnnXc0hZXA8B8Uu8XWfNtL6ZABEDD7E3I6up49syhHSNFPnXH2OvOPn5yt6KujiYVCwARiABokUqlMuk3iDsvYZvpMraF1PYVoN3V+0XWfN6LKRABUDpl6ZwE0Ej1fpE1nwlEACU0PFqkKDKxIXZ4VCAYZ9YJoFwEIoASWr9haPLhpMmkDbGzIWQBMB8JRAA0xL6ErF2XsM1UvbavRVHkqjvG1rOPr3kHgF0JRAAlsfNm2GT6zm7zqatbvbavWokD7Nmuy4TLSCACKIldN8Mms+vstrOFGLIA2LOF1JxGIAJg1poRsvak2W1fF9Lp6wDsmUAEwLzS7LavC+n0daA8dMicPYEIgAVp15medp3YadabGG+OAGZGIAIoqdl2dpsv6s307Gqhnr4OMJWiKDI8OvbPO0bmxy+PmkkgAqD0Furp641m1gnmp6k6yY3/+6TjEvbwy6OFSiACoGFaPetUb6Zn5zfvzeh6JywAzE8CEQDz1lQBbLqZHgEFWGjqLX3b9brpnHnc0oz/7TgXvzxqRwIRAMxQo2aBZvomZm/afO98z3r31TocFo7h0Zktfat3UHVXR6X0vzwSiABgjs30TczetPne+Z717rs39xSyYO41Y/ntfOm62SoCEQDsZCGdvj4bO78ZO+u4pfn0nc922GtEyAKaY9elbzt3yNybrptlJBABwCw1YulbvTcxs/WOn1qaoshEU4m3H7c019z95D7dk3LTNKT97br0jZkTiABYkOai410jlr41401M10/uN37frgb8NljIgtabqn32dPam6+ZCPpNuJgQiAJihMq/Db0bIAsY0olvcruqdr2YGaTKBCABmqN46/GYsfduTXff7tKt6y60sxYLGdItj9gQiAGiA+bp+v14nueHRcjWUAMpJIAKAOma6Dr/eUpZ66/731NVutjMoO9+3Xqe8uu26E92oSkrL9daZ7WzzXOybXKgEIgCoY6br8HeMzHVl0DzNONeKmak321zmfYzNJBABAEl27yS38yzY+EzATGadgOaY7XlCZo/qE4gAYJ4oimLSTFSj9/vs2klutt2o9ma51WxpxjB3tFxnoROIAKAB9rQXqBGGR5NP39n++31mutxq/I12u+xNEbKmNp9ari/EP8O9OU+I2RGIAGCGLDtprPUbhubN3pSF+Eab1tmbA1adJ9R8AhEANNlsN0IPjxaTZlB2Xha3p/0+7cJyK9pFM0JtM+7pFy9zb8EFolqtlr6+vinH+vv709/fP8cVAVB2s90IvdsMSp5dFteo/T6NMt0hsbvWuV9XZdJvxHdeAiQssZCYVWy+arWaarU65VitVpvxfRZcIOrp6cnAwECrywCAeanZv50eW/4z+Y3hfNibArSfepMdvb29GRwcnNF9FlwgAoB2MNuN0Du/rt5ruzoyqZPb3phuNqedNeug0J3vO909x68rs5ke9LurZs+S6GhIIwhEANAEs90Ivevr6r+2PG/Sm3VQ6M73ne6eydwHR2/CZ2ZvnotWqxe+Z5rh7S9qDoEIACiNvenutbNdG2PsrBUtwmmNemeB7WlWcabhm7knEAHAPNUuvy2u1w0vaXydzepcd+ZxSzP+tvTs45elUhlrbJHUb4zRbi3Cy6rec7HrMzrbZZZ1zwLb5bk449VLZjULxNwTiACAfVKvG96ezGZvSrMOCu3qqExansj8Uu+5aMWZV/VC9K7h2wGrrSUQAQBMoV5jjJ1nj+z3KaepzgLb+bmoZ9fw7ZlpLYEIAJpsX5aMNXq52Z6Wt83U3nTDm2uNCij1GmMwtWZ1A5yNes9ovWWW9b6Hnf97meossJl2lyx718J2IxABQInsy/K2ne1dNzxmYqYtwGcbJvYUFBvRjr1Z3QBnY7ZnXtX9HlL/v5eZdpfcuTEDrScQAQALWiPaHc+FmXYh08QBGksgAoAFrp2Xt83W3jRj0O64NZrVDXAuTbVPqBGHI9NeBCIAWOAsb5uZdmljntRvAT5fNKsbYL2lfY3+M5xqn1BZD0deyAQiAKA0ZtvueNc32jvPSjXj0FYtwOdWI/ZP7Y12Ct8IRADAAjLVAZw755FmtDue7aGtuzY5mK/mOkzM1mzOvNqbezJ/CUQAwD5rxhvD2bzRrncAZxnNtHPdruOzbcfOs4Sl+UMgAgDYSzM9tLXV9qahRCPascN8JBABAPPaTLvoJY07ENOhrbBwCEQAUDILbSnP3nTRm+sDMfd0GOpcqtdQImlOO/Z6+3bq/Wx2Hvtvxy+d1Jhirpf2LbT/XtidQAQAlMZ8eXNbr6vdbM2koUQ7tmMfHk0+fefmiX9v9NK+XRtx2D9VPgIRAMAcqdfkYKbduWc6szIXnesWQpjYrRFH7J8qG4EIAGg7C+GN9lT2psnBfDDXYeIdP7U0RZGGL+2j3AQiAKDt+K09U+n6yTOwr0v7ZtqIQ8gqB4EIAGAfzHa/T70mB+38RnwhhIm9acTBwicQAQBtoVFvtOdL44SZNDloR8IEC41ABAC0hYX4Rnt4dHaNE5phT0FxLoPkrnvEpmrJvdD2j9G+BCIAgCa5+s6hed84oRl22yO2y8/G/jHmkkAEADCP7DrrtLPZtvKGMhOIAAAaaOe9UNPtg0rGziSajXqzTu3cynume8TqjXV1jC2tnA97xJg/BCIAgAbadS/UdPugdozMdWWttbd7xOZy/9h8acRBcwhEAAAtsDdvwmc661RvrFltsIUJ5juBCABoS95oP2ums057GgN218ZHZgEAADSXQAQAAJSWQAQAAJSWPUQAAE1iH9T06v1s/NyYS2aIAACA0jJDBAAwj5hZgcYyQwQAAJSWQAQAAJSWQAQAAJSWQAQAAJSWQAQAAJSWQAQAAJSWQAQAAJSWQAQAAJSWQAQAAJSWQAQAAJSWQAQAAJSWQAQAAJSWQAQAAJSWQAQAAJSWQAQAAJSWQAQAAJSWQAQAAJSWQNQEO7Zvy+c//sfZtm1bq0thnti2bVsuvvhizwwz5plhb3lm2FueGfbWfH0PLBA1wfCO7fnCFX8y7x4GWmfbtm255JJLPDPMmGeGveWZYW95Zthb8/U9cFsGoqIoUq1Wc+yxx2bx4sU59thj8+EPfzgjIyOtLg0AAFhA2jIQ/dVf/VV++7d/O6eeemquvPLK/OIv/mJ+//d/PxdddFGrSwMAABaQrlYXMJU//dM/zTvf+c782Z/9WZLkl3/5l7Ns2bL8/u//ftauXZvnPve5La4QAABYCBoyQ3TZZZelUqnUXdL26KOP5oILLkhvb2/233//rFy5MuvWrcv27dsnXbd169Z873vfy8/93M9N+vzP/MzPZGRkJPfff38jSgYAANj3GaKiKHL11VfXvWbjxo1ZtWpVHnvssSTJkiVL8sADD2Tt2rX5l3/5l9x8883p7u5OknR2dubWW2/NypUrJ93jq1/9aiqVSg4//PB9LRkAACDJPs4QjYyMZN26dbn77rvrXnfeeeflsccey6mnnpqNGzdmaGgot99+e1asWJGvfOUr+dCHPjRx7XOe85ysWrUqS5Ysmfjc5z73ufzhH/5h3va2twlEAABAw8wqEF1//fU599xzc9RRR+Xiiy+ue+1dd92Vm2++OYceemjWr1+fI444Ikly/PHH5zOf+UyS5CMf+UiGh4d3e+1jjz2WX/3VX83b3va2/NRP/VSuuOKK2ZQLAAAwpVkFomuuuSZXXnllHn744T1ee9111yVJTj/99CxdunTS2OrVq7Ny5co88cQTue2223b7Gscee2w+//nP50/+5E/y5S9/OQcffPBsyiVJtVptdQkT1DI/tNPPRi3tr91+Lu1UTzvV0k7a7efSTvW0Uy3tpJ1+Lu1US9J+9cw3swpEl156ae69996Jj3puvfXWJMlpp5025fj458evS5Krr746b3/727Nq1ao88MAD+d3f/d10dnbOplR+op3+Q1HL/NBOPxu1tL92+7m0Uz3tVEs7abefSzvV0061tJN2+rm0Uy1J+9Uz38yqqcKKFSuyYsWKGV374IMPJkmOOuqoKcdf8pKXJEkeeuihJMmOHTvy7ne/O6eddlquu+66dHS05VFJAADAAtD0c4ieeOKJJJnUJGFny5YtS5LUarUkyde//vU8/vjjWbVqVb74xS/udv1rX/va3Zbe7awoijz99NOzrnfRokVZtGjRrF8PAADsm23btmXbtm2zfn1RFDO+tumB6JlnnkmSaUPM+OfHrxtvzX3JJZdMef2XvvSlvOENb5j2623atGmf9hqtXbt2j40iAACA5rnsssumzQON1vRANG66lDa+N2j8UNe3v/3te5XodnX44YfnW9/61qxfb3YIAABa633ve18uvPDCWb/+ZS97WTZt2jSja5seiA444IA89dRTGRoayuLFi3cbH58ZOvDAAxvy9SqVSg466KCG3AsAAJh7+7qNpVKpzPjapgei5cuX56mnnsqTTz45cQbRzh5//PGJ6/bF+H0effTR9Pb27tO99tWWbWOzXa94eV86Omb+h9FMtVqt5T+XcWrZ3fis6Mte9rK9+g+4mdrlZ5OoZSrt9sy0y89lXDvV0y61eGbqa6d62qUWz8z02qmWpH3qaaf3wI8++miSZzNCXUUDJCmSFMPDw7uNvfnNby6SFJ/97GenfO1v/dZvFUmKP/qjP9qnGjo6Oibq8OHDhw8fPnz48OHDh4+Ojo495oimzxCtXr06N9xwQ2666aacccYZu43feOONSZITTzxxn77Ofvvtlx//+Mfp7OzM85///H26FwAAMH89/vjjGRkZyX777bfHays/meHZJ+PTqMPDw7sdoHrXXXfluOOOS09PTwYGBibabCfJ1772tbzuda/L8uXLs2nTpnR3d+9rKQAAADPW9FNPX/Oa1+SUU05JrVbLOeeck0ceeSRFUWTDhg0588wzkyQXXnihMAQAAMy5ps8QJcnGjRuzatWqiTOGlixZkieffDJJ8qY3vSk33XRTurrmrAM4AABAkjmYIUqSF7zgBbnzzjtz/vnn57DDDsvWrVtzzDHHZN26dbnhhhuEIQAAoCUaMkMEAAAwH83JDBEAAEA7EogAAIDSEohm4NFHH80FF1yQ3t7e7L///lm5cmXWrVuX7du37/W9tm/fng984AN56Utfmv333z8rVqzIb/zGb2TTpk1NqJxWaeQzs2XLlvze7/1eVq9enSVLluTII4/ML/3SL+XLX/5yEyqnVRr5zOxqy5YtOfLII3PEEUc0oFLaRaOfmX/913/Nz//8z+d5z3teDjnkkJx88sn+nllgGvnMbNu2LZdccklOPPHEHHTQQXn5y1+e888/P48++mgTKqcdXHbZZalUKhkZGdnr17b9+989Ht1act/97neLQw89dOK02yVLlkz888/8zM8U27dvn/G9tm/fXrzhDW+Y8l6HHnpo8d3vfreJ3wlzpZHPzMMPP1y8+MUvnnj98uXLi+7u7iJJUalUive///1N/E6YK418Zqbynve8p0hS9Pb2NqhiWq3Rz8xHPvKRolKpFEmK/fffv1i8ePHE3zMf//jHm/RdMJca+cw8+eSTxctf/vKJ1z//+c8vOjs7iyTF0qVLi9tuu62J3wmtMDo6Wrz61a8ukhTDw8N79dr58P5XINqDk08+uUhSnHrqqcXGjRuLoiiK22+/vVixYkWRpLj00ktnfK9LL7104k3Jhg0biqIY+wvqlFNOKZIUJ598clO+B+ZWI5+ZNWvWFEmK1atXFw899FBRFEWxbdu24vLLLy8OPPDAIknxxS9+sSnfB3Onkc/Mrr7xjW9MvFERiBaORj4zt956a9HZ2Vl0d3cXf//3f18888wzxcjISPHRj360qFQqxeLFi4vvfe97zfpWmCONfGYuuOCCIknx0z/908XDDz9cFEVR/OhHPyre9a53FUmKY489dp9/kUP7GB4eLi6++OKJELO3gWg+vP8ViOq48847J9Lr5s2bJ4197WtfK5IUz3ve84odO3bs8V7bt28vli9fXiQpbr311kljmzdvnvitzd13393Q74G51chn5rvf/W7R0dFRdHd3F4888shu43/9139dJCle97rXNax+5l4jn5ldbd++vXjlK1858T8xgWhhaPQzc9pppxVJio997GO7jb3zne8skhQf/vCHG1I7rdHo9zPd3d3Fc57znN3+3zQyMlIce+yxRZLiy1/+ckO/B+beddddV/zar/1a8aIXvWji/yN7G4jmy/tfe4jquO6665Ikp59+epYuXTppbPXq1Vm5cmWeeOKJ3HbbbXu816233prvf//7eelLX5oTTzxx0tjSpUvz1re+NUly/fXXN6h6WqGRz8x//Md/ZHR0ND/7sz+bFStW7Db+q7/6q+no6Mjdd9+dQvf8eauRz8yuPvShD+Wb3/xmzj333IbUSnto5DPz+OOP56abbsqSJUvy67/+67uNX3DBBXnjG9+YzZs3N6Z4WqLR/2/asWNHVq5cudv/mzo6OvLGN74xSfLNb36zMcXTMtdcc02uvPLKPPzww7O+x3x5/ysQ1XHrrbcmSU477bQpx8c/P37dXN2L9tXIP+fxv4Be9KIXTTl+4IEH5qCDDsqWLVvy/e9/f++LpS006++G+++/Px/4wAfS19eX3/u939u3ImkrjXxmbr755hRFkbe85S3p7u7ebfykk07KLbfckksvvXQfKqbVGvnMbNmyJUmm3Vg/PDycJHnmmWf2uk7ay6WXXpp777134mM25sv7366WfvU29+CDDyZJjjrqqCnHX/KSlyRJHnrooTm9F+2rkX/OJ598cm644YYceeSR036tJ598Mvvtt1+WL18+y4pptWb83VAURX7jN34j27dvz+WXX55Fixbte6G0jUY+MwMDA0mSV77ylQ2qjnbUyGfmZS97WRYtWpT7778/999/f1auXDkxtm3bttx0001Jkle96lX7WjYttmLFiilXqOyN+fL+1wxRHU888USSZMmSJVOOL1u2LElSq9Xm9F60r0b+Ob/4xS/OaaedlmOOOWa3saIoctFFFyUZ++1KpVKZZcW0WjP+bvjf//t/56tf/Wre9a535aSTTtrnGmkvjXxmvvOd7yRJnve85+Ub3/hGzjnnnBx55JF5/vOfn9NOOy2f/vSnG1M0LdXIZ+bggw/O//yf/zMjIyM5/fTTc8stt+RHP/pR7rvvvpxxxhn5zne+k5/+6Z/OySef3LD6mb/my/tfM0R1jE/37rredtz452cyLdzIe9G+5uLPecuWLfnv//2/5x//8R/T1dWV973vfbO+F63X6GdmcHAwF110UVasWJHLLrusMUXSVhr5zDz99NNJMhGgt27dmmXLlmXr1q256aabctNNN+Wf//mf83d/93cNqp5WaPTfMx/4wAfyox/9KH/xF3+Rn/3Zn5009oY3vCGf+9zn0tnZuQ8Vs1DMl/e/ZohmYLoN6+P/sc/kgKrxezTiXrS/Zv05X3vttenr68tVV12VJPnIRz6SVatWza5I2kqjnpn+/v48/fTTqVarOeiggxpWH+2nEc/Mj3/84yTJFVdckde97nW5//7784Mf/CA//OEP84//+I9ZtmxZPvGJT5gpWiAa9ffMHXfckRtuuCFJUqlUcuihh07sQft//+//TTRxgPny/lcgquOAAw5IkgwNDU05Pp5mDzzwwD3ea/yaRtyL9tXIZ2ZnTz75ZM4888ycfvrp2bhxY5YuXZrPfe5z+R//43/sW8G0XCOfmc9+9rO59tprc8YZZ0x07mHhaeQzM/7b2Re/+MW59tprJ5bodnZ25pd+6Zfy4Q9/OMlYx0Lmr0Y+Mw888EBOPfXUPPjgg1m3bl2efvrpPProo3nmmWeyfv36dHZ25p3vfGfWr1/fuG+AeWu+vP8ViOoY36j+5JNPTjn++OOPT7puru5F+2rGn/Ptt9+eV7/61fnMZz6TJPmVX/mVDAwM5PTTT9+nWmkPjXpmtm/fnne/+905+OCD85d/+ZcNrZH20si/Zw499NAkyVlnnTXxpnlnZ555ZiqVSgYGBlr+G1xmr5HPzB//8R/nqaeeyu/8zu/kD/7gD7J48eIkSVdXV84666xcccUVSZL3v//9Daic+W6+vP8ViOo4+uijk4z9NmQq991336Tr5upetK9G/zk/+OCDefOb35zvfve7edGLXpSvfOUr+cQnPjHxJob5r1HPzNatW/PYY4/lqaeeyuGHH55KpTLxMd66/ZFHHpn43LXXXtu4b4I51ci/Z3p6epJk2k5SBxxwQJYsWZIf//jH076hof018pm54447kiRve9vbphz/hV/4hSxatCgPPfSQZ4Z58/5XIKpj9erVSTLRQnJXN954Y5LsdtBUs+9F+2rkn3NRFHnb296WzZs35/Wvf33uvvvuvP71r29csbSFRj0zHR0dOeqoo6b8eOELX5hkbBnU+OdavTyB2Wvk3zPjLZOne7Py1FNPZWhoKMuXL88hhxwym3JpA418Zsb3Ju6pu2lXV1f222+/vSmTBWjevP8tmNadd95ZJCl6enqKH/zgB5PG/v3f/71IUixfvrzYvn37Hu+1ffv2Yvny5UWS4t///d8njf3gBz8oDj300CJJcddddzXyW2CONfKZueWWW4okxeGHH1489dRTzSqZFmvkMzOdhx9+uEhS9Pb27mu5tIFGPjNDQ0PFc57znGL58uW73asoiuJP//RPiyTFm9/85obVz9xr5DPz7ne/u0hSvOc975ly/POf/3yRpHjVq17ViNJpI0mKJMXw8PCMXzNf3v8KRHtwyimnFEmK0047rfje975XjI6OFnfccUexYsWKIknxv/7X/5p0/eDgYPHSl760eOlLX1p84xvfmDT2wQ9+cOJNyYYNG4qiGHujcvLJJxdJilNPPXXOvi+ap1HPzG/+5m8WSYpLLrlkrr8F5lgj/56ZikC08DTymenv7y+SFK997WuL++67ryiKoti2bVvxN3/zN8X+++9fdHZ2Tvw/i/mrUc/MwMBAsf/++xcdHR3FpZdeWvzoRz8qiqIoduzYUXzqU58qDjnkkCJJ8Xd/93dz+v3RfPUC0Xx//ysQ7cF3v/vdifSapFiyZMnEP7/pTW8qduzYMen68TceSYovfelLk8a2b99evOENb5gYX7p06cQ/H3bYYcXGjRvn8lujSRr1zPzcz/3cxG/0jjrqqLofe/PbGtpPI/+emYpAtPA08pl5+umni1e96lUT44ccckjxnOc8p0hSdHV1FX/2Z382l98aTdLIZ+bv/u7vikWLFhVJikqlUhx22GFFd3f3xPXvete75vJbY47UC0Tz/f2vPUR78IIXvCB33nlnzj///Bx22GHZunVrjjnmmKxbty433HBDurpmfrZtd3d3brrpplxyySU5+uij88wzz+Swww7Lb/zGb+TOO+/MEUcc0cTvhLnSqGfm4YcfTjJ2evODDz5Y94P5rZF/z1AOjXxmnvvc5+ZrX/ta3v/+9+eYY47Jli1bcsQRR+Ttb397br311rznPe9p4nfCXGnkM/Orv/qrGRgYyLnnnptXvOIVeeqpp/LCF74wb33rW3PLLbfkr//6r5v4nTDfzIf3v5WimOakJAAAgAXODBEAAFBaAhEAAFBaAhEAAFBaAhEAAFBaAhEAAFBaAhEAAFBaAhEAAFBaAhEAAFBaAhEAAFBaAhEAAFBaAhEAAFBaAhEAAFBaAhEAAFBaAhEAAFBaAhEAAFBaAhEAADBrv/u7v5tKpZLu7u4MDQ1Ne92NN96YSqWSSqWSa6+9duLzTzzxRC6++OK89rWvzYoVK7LffvvlhS98YX76p386f/mXf5kf/vCHU97vTW9608S9RkdH86d/+qd5yUteks7Oznz5y1+ecf1dM/9WAQAAJjvrrLPy4Q9/OMPDw7n++uvzK7/yK1Ned/XVVydJli9fnp//+Z9PkvzHf/xHVq1alaeffnrStRs3bszGjRvz7//+7/mrv/qr3HrrrVm2bNmU9x0dHc0555yTT3/607Oq3wwRAAAwayeccEJe/OIXJ0n+8R//ccprduzYkc997nNJknPOOSfd3d1JkjPPPDNPP/10DjzwwFx88cX56le/mnvvvTc333xz3vWudyVJHnjggaxdu3bar/9Hf/RH+fSnP52f+ZmfyRVXXJEvf/nLOeGEE2ZcvxkiAABgn5x55pn5oz/6o9x4443ZsmVLDjzwwEnjX/ziFyeW073zne9Mkjz++OO55557kiQf/ehHJ80svfzlL8/P/dzPZWRkJH/zN3+Tr3/969N+7W984xt573vfmz/+4z9OpVLZ69rNEAEAAPvkrLPOSpJs3bo1N9xww27j48vZjj322Bx33HFJkqGhoaxZsyZr1qzJGWecMeV9V61alST5/ve/P+3XXr58edauXTurMJQIRAAAwD569atfnZUrVybZfdnc9u3bJ5oo/Nqv/drE51euXJm///u/z9///d/ngAMO2O2eRVHk3/7t3/b4td/4xjfuNiO1NyyZAwAA9tlZZ52VdevW5Z/+6Z+yffv2POc5z0mS3HDDDXnqqafS2dmZ//bf/tuUr92yZUvuvvvu3H///fnP//zPfPvb385tt92Whx9+eI9f9/DDD9+nugUiAABgn40Hoqeeeir/+q//mje/+c1Jnu0ud9ppp+XQQw+d9Jr77rsvv//7v58bbrgh27dvnzS2bNmyvOY1r8ldd91V9+suXbp0n+q2ZA4AANhnfX19OfbYY5M8u2zuxz/+cb7whS8kebaZwri77rorq1evzhe+8IV0d3dnzZo1+Yu/+IvcfPPN+c///M98//vfz+/8zu/s8evOdu/QODNEAABAQ5x11lm599578/nPfz4f+9jH8n//7//ND3/4wyxZsiT/9b/+10nXvu9978sPf/jDrFy5Ml/96lfzvOc9b7f77dixo+k1myECAAAaYrzb3BNPPJF/+7d/m1gu9453vCP77bffpGtvvfXWJMmaNWumDEM7X9NMAhEAANAQRx999ERb7U9+8pO57rrrkuy+XC5Jnvvc5yZJHnnkkSnvddNNN+Wqq65KkgwPDzej3CQCEQAA0EDjs0RXXHFFtmzZkmOOOSYnnnjibteddNJJSZKPf/zjWbt2bW677bbcc889ufbaa7NmzZr8/M///EQQeuSRR3LFFVdMG572hUAEAAA0zJlnnpkkGR0dTTL17FCS/Nmf/VmWL1+ekZGRrFu3LieeeGJe+cpX5vTTT89VV12Vk08+Offdd99EZ7rzzz8/7373uxter0AEAAA0zIte9KKJGaGOjo78yq/8ypTX9fb25t57781v//Zv59hjj82BBx6YQw45JG984xvzt3/7t7nhhhuycuXK/O3f/m1e9KIX5eCDD87q1asbXm+lKIqi4XcFAACYB8wQAQAApSUQAQAApSUQAQAApSUQAQAApSUQAQAApSUQAQAApSUQAQAApSUQAQAApSUQAQAApSUQAQAApSUQAQAApSUQAQAApSUQAQAApSUQAQAApfX/ASgVy9O6N2JjAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Plot to show data labels look ok\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "hist_axis = hist.axis.Regular(100, 0., 1., name='var', growth=False, underflow=False, overflow=False)\n",
    "\n",
    "data_hists, data_plot_labels = [], []\n",
    "if not EVAL_DATA_ON_ALL_FOLDS:\n",
    "    \n",
    "    for fold_idx in range(len(BDT_DATA_preds)):\n",
    "\n",
    "        data_hists.append(\n",
    "            hist.Hist(hist_axis, storage='weight').fill(\n",
    "                var=np.array(BDT_DATA_preds[fold_idx])[:, 0],\n",
    "            )\n",
    "        )\n",
    "        data_plot_labels.append(f\"fold {fold_idx}\")\n",
    "else:\n",
    "\n",
    "    data_hists.append(\n",
    "        hist.Hist(hist_axis, storage='weight').fill(\n",
    "            var=np.array(BDT_DATA_preds)[:, 0],\n",
    "        )\n",
    "    )\n",
    "    data_plot_labels.append(f\"sum over folds\")\n",
    "\n",
    "hep.histplot(\n",
    "    data_hists,\n",
    "    alpha=0.5, density=False, histtype='step',\n",
    "    label=data_plot_labels\n",
    ")\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022preEE_merged_v5_MultiBDT_output/GluGluToHH/nominal/GluGluToHH_nominal_MultiBDT_output.parquet\n",
      "============================================================\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022postEE_merged_v5_MultiBDT_output/GluGluToHH/nominal/GluGluToHH_nominal_MultiBDT_output.parquet\n",
      "============================================================\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022preEE_merged_v5_MultiBDT_output/ttHToGG/nominal/ttHToGG_nominal_MultiBDT_output.parquet\n",
      "============================================================\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022postEE_merged_v5_MultiBDT_output/ttHToGG/nominal/ttHToGG_nominal_MultiBDT_output.parquet\n",
      "============================================================\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022preEE_merged_v5_MultiBDT_output/VHToGG/nominal/VHToGG_nominal_MultiBDT_output.parquet\n",
      "============================================================\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022postEE_merged_v5_MultiBDT_output/VHToGG/nominal/VHToGG_nominal_MultiBDT_output.parquet\n",
      "============================================================\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022preEE_merged_v5_MultiBDT_output/GGJets/nominal/GGJets_nominal_MultiBDT_output.parquet\n",
      "============================================================\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022postEE_merged_v5_MultiBDT_output/GGJets/nominal/GGJets_nominal_MultiBDT_output.parquet\n",
      "============================================================\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022preEE_merged_v5_MultiBDT_output/GJetPt20To40/nominal/GJetPt20To40_nominal_MultiBDT_output.parquet\n",
      "============================================================\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022postEE_merged_v5_MultiBDT_output/GJetPt20To40/nominal/GJetPt20To40_nominal_MultiBDT_output.parquet\n",
      "============================================================\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022preEE_merged_v5_MultiBDT_output/GJetPt40/nominal/GJetPt40_nominal_MultiBDT_output.parquet\n",
      "============================================================\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022postEE_merged_v5_MultiBDT_output/GJetPt40/nominal/GJetPt40_nominal_MultiBDT_output.parquet\n",
      "============================================================\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022preEE_merged_v5_MultiBDT_output/GluGluHToGG/nominal/GluGluHToGG_nominal_MultiBDT_output.parquet\n",
      "============================================================\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022postEE_merged_v5_MultiBDT_output/GluGluHToGG/nominal/GluGluHToGG_nominal_MultiBDT_output.parquet\n",
      "============================================================\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022preEE_merged_v5_MultiBDT_output/VBFHToGG/nominal/VBFHToGG_nominal_MultiBDT_output.parquet\n",
      "============================================================\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022postEE_merged_v5_MultiBDT_output/VBFHToGG/nominal/VBFHToGG_nominal_MultiBDT_output.parquet\n",
      "============================================================\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022preEE_merged_v5_MultiBDT_output/Data_EraC/nominal/Data_EraC_nominal_MultiBDT_output.parquet\n",
      "============================================================\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022preEE_merged_v5_MultiBDT_output/Data_EraD/nominal/Data_EraD_nominal_MultiBDT_output.parquet\n",
      "============================================================\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022postEE_merged_v5_MultiBDT_output/Data_EraE/nominal/Data_EraE_nominal_MultiBDT_output.parquet\n",
      "============================================================\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022postEE_merged_v5_MultiBDT_output/Data_EraF/nominal/Data_EraF_nominal_MultiBDT_output.parquet\n",
      "============================================================\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022postEE_merged_v5_MultiBDT_output/Data_EraG/nominal/Data_EraG_nominal_MultiBDT_output.parquet\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# load and pre-process the data\n",
    "DATA_FILEPATHS_DICT = {\n",
    "    'Data': [\n",
    "        lpc_fileprefix+f\"/Run3_2022preEE_merged_v5/Data_EraC/nominal/*\", \n",
    "        lpc_fileprefix+f\"/Run3_2022preEE_merged_v5/Data_EraD/nominal/*\",\n",
    "        lpc_fileprefix+f\"/Run3_2022postEE_merged_v5/Data_EraE/nominal/*\",\n",
    "        lpc_fileprefix+f\"/Run3_2022postEE_merged_v5/Data_EraF/nominal/*\",\n",
    "        lpc_fileprefix+f\"/Run3_2022postEE_merged_v5/Data_EraG/nominal/*\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Sorts the predictions to map the output to the correct event\n",
    "def sorted_preds(preds, data_aux, sample, sorted_preds=False):\n",
    "    if not sorted_preds:\n",
    "        flat_preds = np.concatenate([preds[fold_idx] for fold_idx in range(len(data_aux))])\n",
    "        preds_sort = np.argsort(\n",
    "            np.concatenate([data_aux[f\"fold_{fold_idx}\"].loc[:, 'hash'].to_numpy() for fold_idx in range(len(data_aux))])\n",
    "        )\n",
    "    else:\n",
    "        flat_preds = preds\n",
    "        preds_sort = np.arange(len(flat_preds))\n",
    "\n",
    "    sample_sort = np.argsort(np.argsort(\n",
    "        ak.to_numpy(sample['hash'], allow_missing=False)\n",
    "    ))\n",
    "\n",
    "    return flat_preds[preds_sort][sample_sort]\n",
    "\n",
    "## MC SAMPLES ##\n",
    "# Load parquet files #\n",
    "for i, sample_name in enumerate(order):\n",
    "    for dirpath in FILEPATHS_DICT[sample_name]:\n",
    "        parquet_filepath = glob.glob(dirpath)[0]\n",
    "        sample = ak.from_parquet(parquet_filepath)\n",
    "\n",
    "        (\n",
    "            NOTHING_IGNORE,\n",
    "            IGNORE_data_df_dict, SAMPLE_data_test_df_dict, \n",
    "            IGNORE_data_hlf_dict, IGNORE_label_dict,\n",
    "            SAMPLE_data_hlf_test_dict, SAMPLE_label_test_dict, \n",
    "            SAMPLE_hlf_vars_columns_dict,\n",
    "            IGNORE_data_aux_dict, SAMPLE_data_test_aux_dict\n",
    "        ) = process_data(\n",
    "            {\"sample\": [parquet_filepath]}, OUTPUT_DIRPATH, order=['sample'], mod_vals=MOD_VALS, k_fold_test=True,\n",
    "            save=False, std_json_dirpath=OUTPUT_DIRPATH\n",
    "        )\n",
    "\n",
    "        sample_preds = []\n",
    "        for fold_idx in range(len(SAMPLE_data_test_df_dict)):\n",
    "            booster = xgb.Booster(param)\n",
    "            booster.load_model(os.path.join(OUTPUT_DIRPATH, f'{CURRENT_TIME}_BDT_fold{fold_idx}.model'))\n",
    "\n",
    "            bdt_test_sample_dict = xgb.DMatrix(\n",
    "                data=SAMPLE_data_hlf_test_dict[f\"fold_{fold_idx}\"], label=SAMPLE_label_test_dict[f\"fold_{fold_idx}\"], \n",
    "                missing=-999.0, feature_names=list(SAMPLE_hlf_vars_columns_dict[f\"fold_{fold_idx}\"])\n",
    "            )\n",
    "\n",
    "            sample_preds.append(\n",
    "                booster.predict(\n",
    "                    bdt_test_sample_dict, \n",
    "                    iteration_range=(0, booster.best_iteration+1)\n",
    "                )\n",
    "            )\n",
    "\n",
    "        sample['MultiBDT_output'] = sorted_preds(\n",
    "            sample_preds, SAMPLE_data_test_aux_dict, sample\n",
    "        )\n",
    "\n",
    "        dest_filepath = parquet_filepath[:parquet_filepath.find('v5')+2] + '_MultiBDT_output' + parquet_filepath[parquet_filepath.find('v5')+2:parquet_filepath.rfind('.')] + '_MultiBDT_output' + parquet_filepath[parquet_filepath.rfind('.'):]\n",
    "        if not os.path.exists(dest_filepath[:dest_filepath.rfind('/')]):\n",
    "            os.makedirs(dest_filepath[:dest_filepath.rfind('/')])\n",
    "        print(dest_filepath)\n",
    "        print('='*60)\n",
    "        merged_parquet = ak.to_parquet(sample, dest_filepath)\n",
    "\n",
    "## DATA ##\n",
    "for dirpath in DATA_FILEPATHS_DICT['Data']:\n",
    "    parquet_filepath = glob.glob(dirpath)[0]\n",
    "    data_sample = ak.from_parquet(parquet_filepath)\n",
    "\n",
    "    (\n",
    "        NOTHING_IGNORE,\n",
    "        DATA_data_df_dict, DATA_data_test_df_dict, \n",
    "        DATA_data_hlf_dict, DATA_label_dict,\n",
    "        DATA_data_hlf_test_dict, DATA_label_test_dict, \n",
    "        DATA_hlf_vars_columns_dict,\n",
    "        DATA_data_aux_dict, DATA_data_test_aux_dict\n",
    "    ) = process_data(\n",
    "        {\"sample\": [parquet_filepath]}, OUTPUT_DIRPATH, order=['sample'], mod_vals=MOD_VALS, k_fold_test=True,\n",
    "        save=False, std_json_dirpath=OUTPUT_DIRPATH\n",
    "    )\n",
    "\n",
    "    bdt_train_data_dict = xgb.DMatrix(\n",
    "        data=DATA_data_hlf_dict[f\"fold_0\"], label=DATA_label_dict[f\"fold_0\"], \n",
    "        missing=-999.0, feature_names=list(DATA_hlf_vars_columns_dict[f\"fold_0\"])\n",
    "    )\n",
    "    bdt_test_data_dict = xgb.DMatrix(\n",
    "        data=DATA_data_hlf_test_dict[f\"fold_0\"], label=DATA_label_test_dict[f\"fold_0\"], \n",
    "        missing=-999.0, feature_names=list(DATA_hlf_vars_columns_dict[f\"fold_0\"])\n",
    "    )\n",
    "\n",
    "    for fold_idx in range(len(DATA_label_test_dict)):\n",
    "        booster = xgb.Booster(param)\n",
    "        booster.load_model(os.path.join(OUTPUT_DIRPATH, f'{CURRENT_TIME}_BDT_fold{fold_idx}.model'))\n",
    "\n",
    "        BDT_train_preds = booster.predict(\n",
    "            bdt_train_data_dict, \n",
    "            iteration_range=(0, booster.best_iteration+1)\n",
    "        )\n",
    "        BDT_test_preds = booster.predict(\n",
    "            bdt_test_data_dict, \n",
    "            iteration_range=(0, booster.best_iteration+1)\n",
    "        )\n",
    "\n",
    "        BDT_all_preds = np.concatenate([BDT_train_preds, BDT_test_preds])\n",
    "        BDT_all_preds = BDT_all_preds[\n",
    "            np.argsort(\n",
    "                np.concatenate([DATA_data_aux_dict[f\"fold_0\"].loc[:, 'hash'].to_numpy(), DATA_data_test_aux_dict[f\"fold_0\"].loc[:, 'hash'].to_numpy()])\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        if fold_idx == 0:\n",
    "            data_preds = copy.deepcopy(BDT_all_preds)\n",
    "        else:\n",
    "            data_preds += BDT_all_preds\n",
    "\n",
    "            if fold_idx == len(DATA_label_test_dict) - 1:\n",
    "                data_preds = data_preds / len(DATA_label_test_dict)\n",
    "\n",
    "    data_sample['MultiBDT_output'] = sorted_preds(\n",
    "        data_preds, DATA_data_test_aux_dict, data_sample,\n",
    "        sorted_preds=True\n",
    "    )\n",
    "\n",
    "    dest_filepath = parquet_filepath[:parquet_filepath.find('v5')+2] + '_MultiBDT_output' + parquet_filepath[parquet_filepath.find('v5')+2:parquet_filepath.rfind('.')] + '_MultiBDT_output' + parquet_filepath[parquet_filepath.rfind('.'):]\n",
    "    if not os.path.exists(dest_filepath[:dest_filepath.rfind('/')]):\n",
    "        os.makedirs(dest_filepath[:dest_filepath.rfind('/')])\n",
    "    print(dest_filepath)\n",
    "    print('='*60)\n",
    "    merged_parquet = ak.to_parquet(data_sample, dest_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
