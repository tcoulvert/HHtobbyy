{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmslpcgpu3.fnal.gov      Tue Feb 18 12:12:19 2025  555.42.06\n",
      "[0] Tesla P100-PCIE-12GB | 53Â°C,  89 % |  8986 / 12288 MB | nvenkata(8984M)\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib widget\n",
    "# Stdlib packages\n",
    "import copy\n",
    "import datetime\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "# Common Py packages\n",
    "import awkward as ak\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from prettytable import PrettyTable\n",
    "from scipy.special import logit as inverse_sigmoid\n",
    "\n",
    "# HEP packages\n",
    "import gpustat\n",
    "import h5py\n",
    "import hist\n",
    "import mplhep as hep\n",
    "import xgboost as xgb\n",
    "from cycler import cycler\n",
    "\n",
    "# ML packages\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, fbeta_score\n",
    "from scipy.integrate import trapezoid\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Integer\n",
    "from skopt.utils import use_named_args\n",
    "\n",
    "# Module packages\n",
    "from data_processing_BDT_v2 import process_data\n",
    "\n",
    "gpustat.print_gpustat()\n",
    "\n",
    "plt.style.use(hep.style.CMS)\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "cmap_petroff10 = [\"#3f90da\", \"#ffa90e\", \"#bd1f01\", \"#94a4a2\", \"#832db6\", \"#a96b59\", \"#e76300\", \"#b9ac70\", \"#717581\", \"#92dadd\"]\n",
    "plt.rcParams.update({\"axes.prop_cycle\": cycler(\"color\", cmap_petroff10)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Locations and Model Naming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lpc_fileprefix = \"/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v2/Run3_2022_merged_v1/sim\"\n",
    "\n",
    "FILEPATHS_DICT = {\n",
    "    'ggF HH': [\n",
    "        lpc_fileprefix+f\"/preEE/GluGlutoHHto2B2G_kl_1p00_kt_1p00_c2_0p00/nominal/*merged.parquet\", \n",
    "        lpc_fileprefix+f\"/postEE/GluGluToHH/nominal/*merged.parquet\"\n",
    "    ],\n",
    "    # 'VBF HH': [\n",
    "    #     lpc_fileprefix+f\"/Run3_2022preEE_merged_v4/VBFHHto2B2G_CV_1_C2V_1_C3_1/nominal/*\", \n",
    "    #     lpc_fileprefix+f\"/Run3_2022postEE_merged_v4/VBFHHto2B2G_CV_1_C2V_1_C3_1/nominal/*\"\n",
    "    # ],\n",
    "    'ttH': [\n",
    "        # ttH\n",
    "        lpc_fileprefix+f\"/preEE/ttHtoGG_M_125/nominal/*merged.parquet\", \n",
    "        lpc_fileprefix+f\"/postEE/ttHToGG/nominal/*merged.parquet\",\n",
    "        # bbH\n",
    "        lpc_fileprefix+f\"/preEE/BBHto2G_M_125/nominal/*merged.parquet\", \n",
    "        lpc_fileprefix+f\"/postEE/BBHto2G_M_125/nominal/*merged.parquet\",\n",
    "    ],\n",
    "    'VH': [\n",
    "        # VH\n",
    "        lpc_fileprefix+f\"/preEE/VHtoGG_M_125/nominal/*merged.parquet\", \n",
    "        lpc_fileprefix+f\"/postEE/VHToGG/nominal/*merged.parquet\",\n",
    "        # ZH\n",
    "        lpc_fileprefix+f\"/preEE/ZH_Hto2G_Zto2Q_M-125/nominal/*merged.parquet\", \n",
    "        lpc_fileprefix+f\"/postEE/ZH_Hto2G_Zto2Q_M-125/nominal/*merged.parquet\",\n",
    "        # W-H\n",
    "        lpc_fileprefix+f\"/preEE/WminusH_Hto2G_Wto2Q_M-125/nominal/*merged.parquet\", \n",
    "        lpc_fileprefix+f\"/postEE/WminusH_Hto2G_Wto2Q_M-125/nominal/*merged.parquet\",\n",
    "        # W+H\n",
    "        lpc_fileprefix+f\"/preEE/WplusH_Hto2G_Wto2Q_M-125/nominal/*merged.parquet\", \n",
    "        lpc_fileprefix+f\"/postEE/WplusH_Hto2G_Wto2Q_M-125/nominal/*merged.parquet\",\n",
    "    ],\n",
    "    'non-res + ggFH + VBFH': [\n",
    "        # GG + 3Jets\n",
    "        lpc_fileprefix+f\"/preEE/GGJets/nominal/*merged.parquet\", \n",
    "        lpc_fileprefix+f\"/postEE/GGJets/nominal/*merged.parquet\",\n",
    "        # GJet pT 20-40\n",
    "        lpc_fileprefix+f\"/preEE/GJetPt20To40/nominal/*merged.parquet\", \n",
    "        lpc_fileprefix+f\"/postEE/GJetPt20To40/nominal/*merged.parquet\",\n",
    "        # GJet pT 40-inf\n",
    "        # lpc_fileprefix+f\"/preEE/GJetPt40/nominal/*merged.parquet\", \n",
    "        lpc_fileprefix+f\"/postEE/GJetPt40/nominal/*merged.parquet\",\n",
    "        # ggF H\n",
    "        lpc_fileprefix+f\"/preEE/GluGluHToGG_M_125/nominal/*merged.parquet\", \n",
    "        lpc_fileprefix+f\"/postEE/GluGluHToGG/nominal/*merged.parquet\",\n",
    "        # VBF H\n",
    "        lpc_fileprefix+f\"/preEE/VBFHToGG_M_125/nominal/*merged.parquet\", \n",
    "        lpc_fileprefix+f\"/postEE/VBFHToGG/nominal/*merged.parquet\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "CURRENT_DIRPATH = str(Path().absolute())\n",
    "VERSION = 'v10'  # 10\n",
    "MOD_VALS = (5, 5)\n",
    "VARS = 'v2_vars'\n",
    "# CURRENT_TIME = '2025-02-13_14-47-47'\n",
    "# CURRENT_TIME = '2025-02-12_01-04-19'\n",
    "if 'CURRENT_TIME' in globals():\n",
    "    OUTPUT_DIRPATH = os.path.join(CURRENT_DIRPATH, f\"MultiClassBDT_model_outputs/{VERSION}/{VARS}\", CURRENT_TIME)\n",
    "else:\n",
    "    OUTPUT_DIRPATH = os.path.join(CURRENT_DIRPATH, f\"MultiClassBDT_model_outputs/{VERSION}/{VARS}\")\n",
    "\n",
    "if not os.path.exists(OUTPUT_DIRPATH):\n",
    "    os.makedirs(OUTPUT_DIRPATH)\n",
    "\n",
    "OTHER_BKG_RESCALE = 100\n",
    "OPTIMIZE_SPACE = True\n",
    "FORCE_RERUN = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_weights(event_weights, labels, order=None, weighttype='rescaled_and_shifted', sig_rescale_factor=None):\n",
    "    if weighttype == 'abs':\n",
    "        return np.abs(event_weights)\n",
    "    \n",
    "    if order is not None:\n",
    "        sig_idx, big_bkg_idx = -1, -1\n",
    "        for i, sample_name in enumerate(order):\n",
    "            if re.search('ggF HH', sample_name) is not None:\n",
    "                sig_idx = i\n",
    "                continue\n",
    "            if re.search('non-res', sample_name) is not None:\n",
    "                big_bkg_idx = i\n",
    "                continue\n",
    "    else:\n",
    "        sig_idx, big_bkg_idx = 0, len(order)-1\n",
    "    \n",
    "    if sig_rescale_factor is None:\n",
    "        sig_sum = np.sum(event_weights[labels[:, sig_idx] == 1])\n",
    "        bkg_sum = np.sum(event_weights[labels[:, sig_idx] == 0])\n",
    "        \n",
    "        sig_rescale_factor = bkg_sum / sig_sum\n",
    "\n",
    "    scaled_weights = np.where(\n",
    "        labels[:, sig_idx] == 0, \n",
    "        np.where(\n",
    "            np.argmax(labels, axis=1) != big_bkg_idx,  \n",
    "            event_weights * OTHER_BKG_RESCALE,  # if not big bkg, rescale\n",
    "            event_weights  # otherwise do nothing\n",
    "        ),\n",
    "        event_weights * sig_rescale_factor  # if sig, rescale to equal sum of all bkgs\n",
    "    )\n",
    "\n",
    "    abs_weights = np.abs(scaled_weights)\n",
    "\n",
    "    if weighttype == 'rescaled':\n",
    "        return abs_weights\n",
    "    elif weighttype == 'rescaled_and_shifted':\n",
    "        mean_weights = np.mean(scaled_weights)\n",
    "        rescaled_weights = abs_weights / mean_weights\n",
    "        return rescaled_weights\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"The only options for weighttype are 'abs', 'rescaled', and 'rescaled_and_shifted'. You provided {weighttype}\"\n",
    "        )\n",
    "\n",
    "# def training_weights(event_weights, labels, order=None, sig_rescale_factor=None):\n",
    "#     if order is None:\n",
    "#         order = [i for v in range(np.shape(labels)[0])]\n",
    "#     sum_dict, max_sum, max_i = {}, 0, 0\n",
    "#     for i, sample_name in enumerate(order):\n",
    "#         sum_dict[i] = np.sum(event_weights[labels[:, i] == 1])\n",
    "#         if np.sum(event_weights[labels[:, i] == 1]) > max_sum:\n",
    "#             max_sum, max_i = np.sum(event_weights[labels[:, i] == 1]), i\n",
    "\n",
    "#     label_i = np.sum(\n",
    "#         np.tile([i for i in range(np.shape(labels)[1])], (np.shape(labels)[0], 1)) * labels,\n",
    "#         axis=1\n",
    "#     )\n",
    "\n",
    "#     weight_factors = []\n",
    "#     for i in range(len(label_i)):\n",
    "#         weight_factors.append(\n",
    "#             max_sum / sum_dict[label_i[i]] if label_i[i] != max_i else 1\n",
    "#         )\n",
    "#     weights = event_weights * np.array(weight_factors)\n",
    "\n",
    "#     mean_weight = np.mean(weights)\n",
    "#     abs_weights = np.abs(weights)\n",
    "#     scaled_weights = abs_weights / mean_weight\n",
    "\n",
    "#     return scaled_weights\n",
    "\n",
    "\n",
    "def xgb_labels(labels):\n",
    "    label_i = np.sum(\n",
    "        np.tile([i for i in range(np.shape(labels)[1])], (np.shape(labels)[0], 1)) * labels,\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    return label_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading and Input Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lead_seediEtaOriX\n",
      "------------------------------------------------------------\n",
      "lead_cutBased\n",
      "------------------------------------------------------------\n",
      "lead_electronVeto\n",
      "------------------------------------------------------------\n",
      "lead_hasConversionTracks\n",
      "------------------------------------------------------------\n",
      "lead_isScEtaEB\n",
      "------------------------------------------------------------\n",
      "lead_isScEtaEE\n",
      "------------------------------------------------------------\n",
      "lead_mvaID_WP80\n",
      "------------------------------------------------------------\n",
      "lead_mvaID_WP90\n",
      "------------------------------------------------------------\n",
      "lead_pixelSeed\n",
      "------------------------------------------------------------\n",
      "lead_seedGain\n",
      "------------------------------------------------------------\n",
      "lead_electronIdx\n",
      "------------------------------------------------------------\n",
      "lead_jetIdx\n",
      "------------------------------------------------------------\n",
      "lead_seediPhiOriY\n",
      "------------------------------------------------------------\n",
      "lead_vidNestedWPBitmap\n",
      "------------------------------------------------------------\n",
      "lead_energyRaw\n",
      "------------------------------------------------------------\n",
      "lead_eta\n",
      "------------------------------------------------------------\n",
      "lead_haloTaggerMVAVal\n",
      "------------------------------------------------------------\n",
      "lead_hoe_PUcorr\n",
      "------------------------------------------------------------\n",
      "lead_pfChargedIsoPFPV\n",
      "------------------------------------------------------------\n",
      "lead_pfPhoIso03\n",
      "------------------------------------------------------------\n",
      "lead_pfRelIso03_all_quadratic\n",
      "------------------------------------------------------------\n",
      "lead_pfRelIso03_chg_quadratic\n",
      "------------------------------------------------------------\n",
      "lead_phi\n",
      "------------------------------------------------------------\n",
      "lead_sipip\n",
      "------------------------------------------------------------\n",
      "lead_x_calo\n",
      "------------------------------------------------------------\n",
      "lead_y_calo\n",
      "------------------------------------------------------------\n",
      "lead_z_calo\n",
      "------------------------------------------------------------\n",
      "lead_genPartFlav\n",
      "------------------------------------------------------------\n",
      "lead_genPartIdx\n",
      "------------------------------------------------------------\n",
      "lead_electronIdxG\n",
      "------------------------------------------------------------\n",
      "lead_genPartIdxG\n",
      "------------------------------------------------------------\n",
      "lead_jetIdxG\n",
      "------------------------------------------------------------\n",
      "lead_ScEta\n",
      "------------------------------------------------------------\n",
      "lead_rho_smear\n",
      "------------------------------------------------------------\n",
      "lead_energy\n",
      "------------------------------------------------------------\n",
      "lead_pt\n",
      "------------------------------------------------------------\n",
      "lead_mvaID_run3\n",
      "------------------------------------------------------------\n",
      "lead_mvaID_nano\n",
      "------------------------------------------------------------\n",
      "lead_raw_r9\n",
      "------------------------------------------------------------\n",
      "lead_r9\n",
      "------------------------------------------------------------\n",
      "lead_raw_sieie\n",
      "------------------------------------------------------------\n",
      "lead_sieie\n",
      "------------------------------------------------------------\n",
      "lead_raw_etaWidth\n",
      "------------------------------------------------------------\n",
      "lead_etaWidth\n",
      "------------------------------------------------------------\n",
      "lead_raw_phiWidth\n",
      "------------------------------------------------------------\n",
      "lead_phiWidth\n",
      "------------------------------------------------------------\n",
      "lead_raw_sieip\n",
      "------------------------------------------------------------\n",
      "lead_sieip\n",
      "------------------------------------------------------------\n",
      "lead_raw_s4\n",
      "------------------------------------------------------------\n",
      "lead_s4\n",
      "------------------------------------------------------------\n",
      "lead_raw_hoe\n",
      "------------------------------------------------------------\n",
      "lead_hoe\n",
      "------------------------------------------------------------\n",
      "lead_raw_ecalPFClusterIso\n",
      "------------------------------------------------------------\n",
      "lead_ecalPFClusterIso\n",
      "------------------------------------------------------------\n",
      "lead_raw_trkSumPtHollowConeDR03\n",
      "------------------------------------------------------------\n",
      "lead_trkSumPtHollowConeDR03\n",
      "------------------------------------------------------------\n",
      "lead_raw_trkSumPtSolidConeDR04\n",
      "------------------------------------------------------------\n",
      "lead_trkSumPtSolidConeDR04\n",
      "------------------------------------------------------------\n",
      "lead_raw_pfChargedIso\n",
      "------------------------------------------------------------\n",
      "lead_pfChargedIso\n",
      "------------------------------------------------------------\n",
      "lead_raw_pfChargedIsoWorstVtx\n",
      "------------------------------------------------------------\n",
      "lead_pfChargedIsoWorstVtx\n",
      "------------------------------------------------------------\n",
      "lead_raw_esEffSigmaRR\n",
      "------------------------------------------------------------\n",
      "lead_esEffSigmaRR\n",
      "------------------------------------------------------------\n",
      "lead_raw_esEnergyOverRawE\n",
      "------------------------------------------------------------\n",
      "lead_esEnergyOverRawE\n",
      "------------------------------------------------------------\n",
      "lead_raw_hcalPFClusterIso\n",
      "------------------------------------------------------------\n",
      "lead_hcalPFClusterIso\n",
      "------------------------------------------------------------\n",
      "lead_raw_energyErr\n",
      "------------------------------------------------------------\n",
      "lead_energyErr\n",
      "------------------------------------------------------------\n",
      "lead_mvaID\n",
      "------------------------------------------------------------\n",
      "lead_charge\n",
      "------------------------------------------------------------\n",
      "sublead_seediEtaOriX\n",
      "------------------------------------------------------------\n",
      "sublead_cutBased\n",
      "------------------------------------------------------------\n",
      "sublead_electronVeto\n",
      "------------------------------------------------------------\n",
      "sublead_hasConversionTracks\n",
      "------------------------------------------------------------\n",
      "sublead_isScEtaEB\n",
      "------------------------------------------------------------\n",
      "sublead_isScEtaEE\n",
      "------------------------------------------------------------\n",
      "sublead_mvaID_WP80\n",
      "------------------------------------------------------------\n",
      "sublead_mvaID_WP90\n",
      "------------------------------------------------------------\n",
      "sublead_pixelSeed\n",
      "------------------------------------------------------------\n",
      "sublead_seedGain\n",
      "------------------------------------------------------------\n",
      "sublead_electronIdx\n",
      "------------------------------------------------------------\n",
      "sublead_jetIdx\n",
      "------------------------------------------------------------\n",
      "sublead_seediPhiOriY\n",
      "------------------------------------------------------------\n",
      "sublead_vidNestedWPBitmap\n",
      "------------------------------------------------------------\n",
      "sublead_energyRaw\n",
      "------------------------------------------------------------\n",
      "sublead_eta\n",
      "------------------------------------------------------------\n",
      "sublead_haloTaggerMVAVal\n",
      "------------------------------------------------------------\n",
      "sublead_hoe_PUcorr\n",
      "------------------------------------------------------------\n",
      "sublead_pfChargedIsoPFPV\n",
      "------------------------------------------------------------\n",
      "sublead_pfPhoIso03\n",
      "------------------------------------------------------------\n",
      "sublead_pfRelIso03_all_quadratic\n",
      "------------------------------------------------------------\n",
      "sublead_pfRelIso03_chg_quadratic\n",
      "------------------------------------------------------------\n",
      "sublead_phi\n",
      "------------------------------------------------------------\n",
      "sublead_sipip\n",
      "------------------------------------------------------------\n",
      "sublead_x_calo\n",
      "------------------------------------------------------------\n",
      "sublead_y_calo\n",
      "------------------------------------------------------------\n",
      "sublead_z_calo\n",
      "------------------------------------------------------------\n",
      "sublead_genPartFlav\n",
      "------------------------------------------------------------\n",
      "sublead_genPartIdx\n",
      "------------------------------------------------------------\n",
      "sublead_electronIdxG\n",
      "------------------------------------------------------------\n",
      "sublead_genPartIdxG\n",
      "------------------------------------------------------------\n",
      "sublead_jetIdxG\n",
      "------------------------------------------------------------\n",
      "sublead_ScEta\n",
      "------------------------------------------------------------\n",
      "sublead_rho_smear\n",
      "------------------------------------------------------------\n",
      "sublead_energy\n",
      "------------------------------------------------------------\n",
      "sublead_pt\n",
      "------------------------------------------------------------\n",
      "sublead_mvaID_run3\n",
      "------------------------------------------------------------\n",
      "sublead_mvaID_nano\n",
      "------------------------------------------------------------\n",
      "sublead_raw_r9\n",
      "------------------------------------------------------------\n",
      "sublead_r9\n",
      "------------------------------------------------------------\n",
      "sublead_raw_sieie\n",
      "------------------------------------------------------------\n",
      "sublead_sieie\n",
      "------------------------------------------------------------\n",
      "sublead_raw_etaWidth\n",
      "------------------------------------------------------------\n",
      "sublead_etaWidth\n",
      "------------------------------------------------------------\n",
      "sublead_raw_phiWidth\n",
      "------------------------------------------------------------\n",
      "sublead_phiWidth\n",
      "------------------------------------------------------------\n",
      "sublead_raw_sieip\n",
      "------------------------------------------------------------\n",
      "sublead_sieip\n",
      "------------------------------------------------------------\n",
      "sublead_raw_s4\n",
      "------------------------------------------------------------\n",
      "sublead_s4\n",
      "------------------------------------------------------------\n",
      "sublead_raw_hoe\n",
      "------------------------------------------------------------\n",
      "sublead_hoe\n",
      "------------------------------------------------------------\n",
      "sublead_raw_ecalPFClusterIso\n",
      "------------------------------------------------------------\n",
      "sublead_ecalPFClusterIso\n",
      "------------------------------------------------------------\n",
      "sublead_raw_trkSumPtHollowConeDR03\n",
      "------------------------------------------------------------\n",
      "sublead_trkSumPtHollowConeDR03\n",
      "------------------------------------------------------------\n",
      "sublead_raw_trkSumPtSolidConeDR04\n",
      "------------------------------------------------------------\n",
      "sublead_trkSumPtSolidConeDR04\n",
      "------------------------------------------------------------\n",
      "sublead_raw_pfChargedIso\n",
      "------------------------------------------------------------\n",
      "sublead_pfChargedIso\n",
      "------------------------------------------------------------\n",
      "sublead_raw_pfChargedIsoWorstVtx\n",
      "------------------------------------------------------------\n",
      "sublead_pfChargedIsoWorstVtx\n",
      "------------------------------------------------------------\n",
      "sublead_raw_esEffSigmaRR\n",
      "------------------------------------------------------------\n",
      "sublead_esEffSigmaRR\n",
      "------------------------------------------------------------\n",
      "sublead_raw_esEnergyOverRawE\n",
      "------------------------------------------------------------\n",
      "sublead_esEnergyOverRawE\n",
      "------------------------------------------------------------\n",
      "sublead_raw_hcalPFClusterIso\n",
      "------------------------------------------------------------\n",
      "sublead_hcalPFClusterIso\n",
      "------------------------------------------------------------\n",
      "sublead_raw_energyErr\n",
      "------------------------------------------------------------\n",
      "sublead_energyErr\n",
      "------------------------------------------------------------\n",
      "sublead_mvaID\n",
      "------------------------------------------------------------\n",
      "sublead_charge\n",
      "------------------------------------------------------------\n",
      "pt\n",
      "------------------------------------------------------------\n",
      "eta\n",
      "------------------------------------------------------------\n",
      "phi\n",
      "------------------------------------------------------------\n",
      "mass\n",
      "------------------------------------------------------------\n",
      "charge\n",
      "------------------------------------------------------------\n",
      "rapidity\n",
      "------------------------------------------------------------\n",
      "pass_fiducial_classical\n",
      "------------------------------------------------------------\n",
      "pass_fiducial_geometric\n",
      "------------------------------------------------------------\n",
      "fiducialClassicalFlag\n",
      "------------------------------------------------------------\n",
      "fiducialGeometricFlag\n",
      "------------------------------------------------------------\n",
      "GenPTH\n",
      "------------------------------------------------------------\n",
      "n_electrons\n",
      "------------------------------------------------------------\n",
      "n_muons\n",
      "------------------------------------------------------------\n",
      "n_electrons_after_dxy_dz_cuts\n",
      "------------------------------------------------------------\n",
      "n_muons_after_dxy_dz_cuts\n",
      "------------------------------------------------------------\n",
      "n_jets\n",
      "------------------------------------------------------------\n",
      "Njets2p5\n",
      "------------------------------------------------------------\n",
      "jet1_pt\n",
      "------------------------------------------------------------\n",
      "jet1_eta\n",
      "------------------------------------------------------------\n",
      "jet1_phi\n",
      "------------------------------------------------------------\n",
      "jet1_mass\n",
      "------------------------------------------------------------\n",
      "jet1_charge\n",
      "------------------------------------------------------------\n",
      "jet1_btagDeepFlav_B\n",
      "------------------------------------------------------------\n",
      "jet1_btagPNetB\n",
      "------------------------------------------------------------\n",
      "jet1_PNetRegPtRawCorr\n",
      "------------------------------------------------------------\n",
      "jet1_PNetRegPtRawCorrNeutrino\n",
      "------------------------------------------------------------\n",
      "jet1_PNetRegPtRawRes\n",
      "------------------------------------------------------------\n",
      "jet1_btagRobustParTAK4B\n",
      "------------------------------------------------------------\n",
      "jet1_index\n",
      "------------------------------------------------------------\n",
      "jet2_pt\n",
      "------------------------------------------------------------\n",
      "jet2_eta\n",
      "------------------------------------------------------------\n",
      "jet2_phi\n",
      "------------------------------------------------------------\n",
      "jet2_mass\n",
      "------------------------------------------------------------\n",
      "jet2_charge\n",
      "------------------------------------------------------------\n",
      "jet2_btagDeepFlav_B\n",
      "------------------------------------------------------------\n",
      "jet2_btagPNetB\n",
      "------------------------------------------------------------\n",
      "jet2_PNetRegPtRawCorr\n",
      "------------------------------------------------------------\n",
      "jet2_PNetRegPtRawCorrNeutrino\n",
      "------------------------------------------------------------\n",
      "jet2_PNetRegPtRawRes\n",
      "------------------------------------------------------------\n",
      "jet2_btagRobustParTAK4B\n",
      "------------------------------------------------------------\n",
      "jet2_index\n",
      "------------------------------------------------------------\n",
      "jet3_pt\n",
      "------------------------------------------------------------\n",
      "jet3_eta\n",
      "------------------------------------------------------------\n",
      "jet3_phi\n",
      "------------------------------------------------------------\n",
      "jet3_mass\n",
      "------------------------------------------------------------\n",
      "jet3_charge\n",
      "------------------------------------------------------------\n",
      "jet3_btagDeepFlav_B\n",
      "------------------------------------------------------------\n",
      "jet3_btagPNetB\n",
      "------------------------------------------------------------\n",
      "jet3_PNetRegPtRawCorr\n",
      "------------------------------------------------------------\n",
      "jet3_PNetRegPtRawCorrNeutrino\n",
      "------------------------------------------------------------\n",
      "jet3_PNetRegPtRawRes\n",
      "------------------------------------------------------------\n",
      "jet3_btagRobustParTAK4B\n",
      "------------------------------------------------------------\n",
      "jet3_index\n",
      "------------------------------------------------------------\n",
      "jet4_pt\n",
      "------------------------------------------------------------\n",
      "jet4_eta\n",
      "------------------------------------------------------------\n",
      "jet4_phi\n",
      "------------------------------------------------------------\n",
      "jet4_mass\n",
      "------------------------------------------------------------\n",
      "jet4_charge\n",
      "------------------------------------------------------------\n",
      "jet4_btagDeepFlav_B\n",
      "------------------------------------------------------------\n",
      "jet4_btagPNetB\n",
      "------------------------------------------------------------\n",
      "jet4_PNetRegPtRawCorr\n",
      "------------------------------------------------------------\n",
      "jet4_PNetRegPtRawCorrNeutrino\n",
      "------------------------------------------------------------\n",
      "jet4_PNetRegPtRawRes\n",
      "------------------------------------------------------------\n",
      "jet4_btagRobustParTAK4B\n",
      "------------------------------------------------------------\n",
      "jet4_index\n",
      "------------------------------------------------------------\n",
      "jet5_pt\n",
      "------------------------------------------------------------\n",
      "jet5_eta\n",
      "------------------------------------------------------------\n",
      "jet5_phi\n",
      "------------------------------------------------------------\n",
      "jet5_mass\n",
      "------------------------------------------------------------\n",
      "jet5_charge\n",
      "------------------------------------------------------------\n",
      "jet5_btagDeepFlav_B\n",
      "------------------------------------------------------------\n",
      "jet5_btagPNetB\n",
      "------------------------------------------------------------\n",
      "jet5_PNetRegPtRawCorr\n",
      "------------------------------------------------------------\n",
      "jet5_PNetRegPtRawCorrNeutrino\n",
      "------------------------------------------------------------\n",
      "jet5_PNetRegPtRawRes\n",
      "------------------------------------------------------------\n",
      "jet5_btagRobustParTAK4B\n",
      "------------------------------------------------------------\n",
      "jet5_index\n",
      "------------------------------------------------------------\n",
      "jet6_pt\n",
      "------------------------------------------------------------\n",
      "jet6_eta\n",
      "------------------------------------------------------------\n",
      "jet6_phi\n",
      "------------------------------------------------------------\n",
      "jet6_mass\n",
      "------------------------------------------------------------\n",
      "jet6_charge\n",
      "------------------------------------------------------------\n",
      "jet6_btagDeepFlav_B\n",
      "------------------------------------------------------------\n",
      "jet6_btagPNetB\n",
      "------------------------------------------------------------\n",
      "jet6_PNetRegPtRawCorr\n",
      "------------------------------------------------------------\n",
      "jet6_PNetRegPtRawCorrNeutrino\n",
      "------------------------------------------------------------\n",
      "jet6_PNetRegPtRawRes\n",
      "------------------------------------------------------------\n",
      "jet6_btagRobustParTAK4B\n",
      "------------------------------------------------------------\n",
      "jet6_index\n",
      "------------------------------------------------------------\n",
      "jet7_pt\n",
      "------------------------------------------------------------\n",
      "jet7_eta\n",
      "------------------------------------------------------------\n",
      "jet7_phi\n",
      "------------------------------------------------------------\n",
      "jet7_mass\n",
      "------------------------------------------------------------\n",
      "jet7_charge\n",
      "------------------------------------------------------------\n",
      "jet7_btagDeepFlav_B\n",
      "------------------------------------------------------------\n",
      "jet7_btagPNetB\n",
      "------------------------------------------------------------\n",
      "jet7_PNetRegPtRawCorr\n",
      "------------------------------------------------------------\n",
      "jet7_PNetRegPtRawCorrNeutrino\n",
      "------------------------------------------------------------\n",
      "jet7_PNetRegPtRawRes\n",
      "------------------------------------------------------------\n",
      "jet7_btagRobustParTAK4B\n",
      "------------------------------------------------------------\n",
      "jet7_index\n",
      "------------------------------------------------------------\n",
      "jet8_pt\n",
      "------------------------------------------------------------\n",
      "jet8_eta\n",
      "------------------------------------------------------------\n",
      "jet8_phi\n",
      "------------------------------------------------------------\n",
      "jet8_mass\n",
      "------------------------------------------------------------\n",
      "jet8_charge\n",
      "------------------------------------------------------------\n",
      "jet8_btagDeepFlav_B\n",
      "------------------------------------------------------------\n",
      "jet8_btagPNetB\n",
      "------------------------------------------------------------\n",
      "jet8_PNetRegPtRawCorr\n",
      "------------------------------------------------------------\n",
      "jet8_PNetRegPtRawCorrNeutrino\n",
      "------------------------------------------------------------\n",
      "jet8_PNetRegPtRawRes\n",
      "------------------------------------------------------------\n",
      "jet8_btagRobustParTAK4B\n",
      "------------------------------------------------------------\n",
      "jet8_index\n",
      "------------------------------------------------------------\n",
      "jet9_pt\n",
      "------------------------------------------------------------\n",
      "jet9_eta\n",
      "------------------------------------------------------------\n",
      "jet9_phi\n",
      "------------------------------------------------------------\n",
      "jet9_mass\n",
      "------------------------------------------------------------\n",
      "jet9_charge\n",
      "------------------------------------------------------------\n",
      "jet9_btagDeepFlav_B\n",
      "------------------------------------------------------------\n",
      "jet9_btagPNetB\n",
      "------------------------------------------------------------\n",
      "jet9_PNetRegPtRawCorr\n",
      "------------------------------------------------------------\n",
      "jet9_PNetRegPtRawCorrNeutrino\n",
      "------------------------------------------------------------\n",
      "jet9_PNetRegPtRawRes\n",
      "------------------------------------------------------------\n",
      "jet9_btagRobustParTAK4B\n",
      "------------------------------------------------------------\n",
      "jet9_index\n",
      "------------------------------------------------------------\n",
      "jet10_pt\n",
      "------------------------------------------------------------\n",
      "jet10_eta\n",
      "------------------------------------------------------------\n",
      "jet10_phi\n",
      "------------------------------------------------------------\n",
      "jet10_mass\n",
      "------------------------------------------------------------\n",
      "jet10_charge\n",
      "------------------------------------------------------------\n",
      "jet10_btagDeepFlav_B\n",
      "------------------------------------------------------------\n",
      "jet10_btagPNetB\n",
      "------------------------------------------------------------\n",
      "jet10_PNetRegPtRawCorr\n",
      "------------------------------------------------------------\n",
      "jet10_PNetRegPtRawCorrNeutrino\n",
      "------------------------------------------------------------\n",
      "jet10_PNetRegPtRawRes\n",
      "------------------------------------------------------------\n",
      "jet10_btagRobustParTAK4B\n",
      "------------------------------------------------------------\n",
      "jet10_index\n",
      "------------------------------------------------------------\n",
      "jet1_genMatched\n",
      "------------------------------------------------------------\n",
      "jet1_genFlav\n",
      "------------------------------------------------------------\n",
      "jet2_genMatched\n",
      "------------------------------------------------------------\n",
      "jet2_genFlav\n",
      "------------------------------------------------------------\n",
      "jet3_genMatched\n",
      "------------------------------------------------------------\n",
      "jet3_genFlav\n",
      "------------------------------------------------------------\n",
      "jet4_genMatched\n",
      "------------------------------------------------------------\n",
      "jet4_genFlav\n",
      "------------------------------------------------------------\n",
      "jet5_genMatched\n",
      "------------------------------------------------------------\n",
      "jet5_genFlav\n",
      "------------------------------------------------------------\n",
      "jet6_genMatched\n",
      "------------------------------------------------------------\n",
      "jet6_genFlav\n",
      "------------------------------------------------------------\n",
      "jet7_genMatched\n",
      "------------------------------------------------------------\n",
      "jet7_genFlav\n",
      "------------------------------------------------------------\n",
      "jet8_genMatched\n",
      "------------------------------------------------------------\n",
      "jet8_genFlav\n",
      "------------------------------------------------------------\n",
      "jet9_genMatched\n",
      "------------------------------------------------------------\n",
      "jet9_genFlav\n",
      "------------------------------------------------------------\n",
      "jet10_genMatched\n",
      "------------------------------------------------------------\n",
      "jet10_genFlav\n",
      "------------------------------------------------------------\n",
      "jet1_genMatched_Hbb\n",
      "------------------------------------------------------------\n",
      "jet2_genMatched_Hbb\n",
      "------------------------------------------------------------\n",
      "jet3_genMatched_Hbb\n",
      "------------------------------------------------------------\n",
      "jet4_genMatched_Hbb\n",
      "------------------------------------------------------------\n",
      "jet5_genMatched_Hbb\n",
      "------------------------------------------------------------\n",
      "jet6_genMatched_Hbb\n",
      "------------------------------------------------------------\n",
      "jet7_genMatched_Hbb\n",
      "------------------------------------------------------------\n",
      "jet8_genMatched_Hbb\n",
      "------------------------------------------------------------\n",
      "jet9_genMatched_Hbb\n",
      "------------------------------------------------------------\n",
      "jet10_genMatched_Hbb\n",
      "------------------------------------------------------------\n",
      "fatjet1_genMatched\n",
      "------------------------------------------------------------\n",
      "fatjet1_genFlav\n",
      "------------------------------------------------------------\n",
      "fatjet2_genMatched\n",
      "------------------------------------------------------------\n",
      "fatjet2_genFlav\n",
      "------------------------------------------------------------\n",
      "fatjet3_genMatched\n",
      "------------------------------------------------------------\n",
      "fatjet3_genFlav\n",
      "------------------------------------------------------------\n",
      "fatjet4_genMatched\n",
      "------------------------------------------------------------\n",
      "fatjet4_genFlav\n",
      "------------------------------------------------------------\n",
      "genHiggs_tobb_pt\n",
      "------------------------------------------------------------\n",
      "genHiggs_tobb_eta\n",
      "------------------------------------------------------------\n",
      "genHiggs_tobb_phi\n",
      "------------------------------------------------------------\n",
      "genHiggs_tobb_mass\n",
      "------------------------------------------------------------\n",
      "genHiggs_toGG_pt\n",
      "------------------------------------------------------------\n",
      "genHiggs_toGG_eta\n",
      "------------------------------------------------------------\n",
      "genHiggs_toGG_phi\n",
      "------------------------------------------------------------\n",
      "genHiggs_toGG_mass\n",
      "------------------------------------------------------------\n",
      "gen_mHH\n",
      "------------------------------------------------------------\n",
      "kl\n",
      "------------------------------------------------------------\n",
      "kt\n",
      "------------------------------------------------------------\n",
      "c2\n",
      "------------------------------------------------------------\n",
      "n_fatjets\n",
      "------------------------------------------------------------\n",
      "nonRes_lead_bjet_genMatched\n",
      "------------------------------------------------------------\n",
      "nonRes_lead_bjet_genFlav\n",
      "------------------------------------------------------------\n",
      "nonRes_sublead_bjet_genMatched\n",
      "------------------------------------------------------------\n",
      "nonRes_sublead_bjet_genFlav\n",
      "------------------------------------------------------------\n",
      "nonRes_Higgs_toGG_genMatched\n",
      "------------------------------------------------------------\n",
      "nonRes_Higgs_tobb_genMatched\n",
      "------------------------------------------------------------\n",
      "nonRes_HHbbggCandidate_pt\n",
      "------------------------------------------------------------\n",
      "nonRes_HHbbggCandidate_eta\n",
      "------------------------------------------------------------\n",
      "nonRes_HHbbggCandidate_phi\n",
      "------------------------------------------------------------\n",
      "nonRes_HHbbggCandidate_mass\n",
      "------------------------------------------------------------\n",
      "nonRes_M_X\n",
      "------------------------------------------------------------\n",
      "nonRes_lead_bjet_pt\n",
      "------------------------------------------------------------\n",
      "nonRes_lead_bjet_eta\n",
      "------------------------------------------------------------\n",
      "nonRes_lead_bjet_phi\n",
      "------------------------------------------------------------\n",
      "nonRes_lead_bjet_mass\n",
      "------------------------------------------------------------\n",
      "nonRes_lead_bjet_charge\n",
      "------------------------------------------------------------\n",
      "nonRes_lead_bjet_btagPNetB\n",
      "------------------------------------------------------------\n",
      "nonRes_lead_bjet_PNetRegPtRawCorr\n",
      "------------------------------------------------------------\n",
      "nonRes_lead_bjet_PNetRegPtRawCorrNeutrino\n",
      "------------------------------------------------------------\n",
      "nonRes_lead_bjet_PNetRegPtRawRes\n",
      "------------------------------------------------------------\n",
      "nonRes_lead_bjet_jet_idx\n",
      "------------------------------------------------------------\n",
      "nonRes_sublead_bjet_pt\n",
      "------------------------------------------------------------\n",
      "nonRes_sublead_bjet_eta\n",
      "------------------------------------------------------------\n",
      "nonRes_sublead_bjet_phi\n",
      "------------------------------------------------------------\n",
      "nonRes_sublead_bjet_mass\n",
      "------------------------------------------------------------\n",
      "nonRes_sublead_bjet_charge\n",
      "------------------------------------------------------------\n",
      "nonRes_sublead_bjet_btagPNetB\n",
      "------------------------------------------------------------\n",
      "nonRes_sublead_bjet_PNetRegPtRawCorr\n",
      "------------------------------------------------------------\n",
      "nonRes_sublead_bjet_PNetRegPtRawCorrNeutrino\n",
      "------------------------------------------------------------\n",
      "nonRes_sublead_bjet_PNetRegPtRawRes\n",
      "------------------------------------------------------------\n",
      "nonRes_sublead_bjet_jet_idx\n",
      "------------------------------------------------------------\n",
      "nonRes_dijet_pt\n",
      "------------------------------------------------------------\n",
      "nonRes_dijet_eta\n",
      "------------------------------------------------------------\n",
      "nonRes_dijet_phi\n",
      "------------------------------------------------------------\n",
      "nonRes_dijet_mass\n",
      "------------------------------------------------------------\n",
      "nonRes_dijet_charge\n",
      "------------------------------------------------------------\n",
      "nonRes_pholead_PtOverM\n",
      "------------------------------------------------------------\n",
      "nonRes_phosublead_PtOverM\n",
      "------------------------------------------------------------\n",
      "nonRes_FirstJet_PtOverM\n",
      "------------------------------------------------------------\n",
      "nonRes_SecondJet_PtOverM\n",
      "------------------------------------------------------------\n",
      "nonRes_DeltaR_j1g1\n",
      "------------------------------------------------------------\n",
      "nonRes_DeltaR_j2g1\n",
      "------------------------------------------------------------\n",
      "nonRes_DeltaR_j1g2\n",
      "------------------------------------------------------------\n",
      "nonRes_DeltaR_j2g2\n",
      "------------------------------------------------------------\n",
      "nonRes_DeltaR_jg_min\n",
      "------------------------------------------------------------\n",
      "nonRes_chi_t0\n",
      "------------------------------------------------------------\n",
      "nonRes_chi_t1\n",
      "------------------------------------------------------------\n",
      "nonRes_DeltaPhi_j1MET\n",
      "------------------------------------------------------------\n",
      "nonRes_DeltaPhi_j2MET\n",
      "------------------------------------------------------------\n",
      "nonRes_CosThetaStar_CS\n",
      "------------------------------------------------------------\n",
      "nonRes_CosThetaStar_gg\n",
      "------------------------------------------------------------\n",
      "nonRes_CosThetaStar_jj\n",
      "------------------------------------------------------------\n",
      "VBF_first_jet_pt\n",
      "------------------------------------------------------------\n",
      "VBF_first_jet_eta\n",
      "------------------------------------------------------------\n",
      "VBF_first_jet_phi\n",
      "------------------------------------------------------------\n",
      "VBF_first_jet_mass\n",
      "------------------------------------------------------------\n",
      "VBF_first_jet_charge\n",
      "------------------------------------------------------------\n",
      "VBF_first_jet_btagPNetB\n",
      "------------------------------------------------------------\n",
      "VBF_first_jet_PNetRegPtRawCorr\n",
      "------------------------------------------------------------\n",
      "VBF_first_jet_PNetRegPtRawCorrNeutrino\n",
      "------------------------------------------------------------\n",
      "VBF_first_jet_PNetRegPtRawRes\n",
      "------------------------------------------------------------\n",
      "VBF_first_jet_btagPNetQvG\n",
      "------------------------------------------------------------\n",
      "VBF_first_jet_btagDeepFlav_QG\n",
      "------------------------------------------------------------\n",
      "VBF_second_jet_pt\n",
      "------------------------------------------------------------\n",
      "VBF_second_jet_eta\n",
      "------------------------------------------------------------\n",
      "VBF_second_jet_phi\n",
      "------------------------------------------------------------\n",
      "VBF_second_jet_mass\n",
      "------------------------------------------------------------\n",
      "VBF_second_jet_charge\n",
      "------------------------------------------------------------\n",
      "VBF_second_jet_btagPNetB\n",
      "------------------------------------------------------------\n",
      "VBF_second_jet_PNetRegPtRawCorr\n",
      "------------------------------------------------------------\n",
      "VBF_second_jet_PNetRegPtRawCorrNeutrino\n",
      "------------------------------------------------------------\n",
      "VBF_second_jet_PNetRegPtRawRes\n",
      "------------------------------------------------------------\n",
      "VBF_second_jet_btagPNetQvG\n",
      "------------------------------------------------------------\n",
      "VBF_second_jet_btagDeepFlav_QG\n",
      "------------------------------------------------------------\n",
      "VBF_dijet_pt\n",
      "------------------------------------------------------------\n",
      "VBF_dijet_eta\n",
      "------------------------------------------------------------\n",
      "VBF_dijet_phi\n",
      "------------------------------------------------------------\n",
      "VBF_dijet_mass\n",
      "------------------------------------------------------------\n",
      "VBF_dijet_charge\n",
      "------------------------------------------------------------\n",
      "VBF_first_jet_PtOverM\n",
      "------------------------------------------------------------\n",
      "VBF_second_jet_PtOverM\n",
      "------------------------------------------------------------\n",
      "VBF_first_jet_index\n",
      "------------------------------------------------------------\n",
      "VBF_second_jet_index\n",
      "------------------------------------------------------------\n",
      "VBF_jet_eta_prod\n",
      "------------------------------------------------------------\n",
      "VBF_jet_eta_diff\n",
      "------------------------------------------------------------\n",
      "VBF_jet_eta_sum\n",
      "------------------------------------------------------------\n",
      "VBF_DeltaR_j1b1\n",
      "------------------------------------------------------------\n",
      "VBF_DeltaR_j1b2\n",
      "------------------------------------------------------------\n",
      "VBF_DeltaR_j2b1\n",
      "------------------------------------------------------------\n",
      "VBF_DeltaR_j2b2\n",
      "------------------------------------------------------------\n",
      "VBF_DeltaR_j1g1\n",
      "------------------------------------------------------------\n",
      "VBF_DeltaR_j1g2\n",
      "------------------------------------------------------------\n",
      "VBF_DeltaR_j2g1\n",
      "------------------------------------------------------------\n",
      "VBF_DeltaR_j2g2\n",
      "------------------------------------------------------------\n",
      "VBF_DeltaR_jb_min\n",
      "------------------------------------------------------------\n",
      "VBF_DeltaR_jg_min\n",
      "------------------------------------------------------------\n",
      "VBF_Cgg\n",
      "------------------------------------------------------------\n",
      "VBF_Cbb\n",
      "------------------------------------------------------------\n",
      "nonRes_has_two_btagged_jets\n",
      "------------------------------------------------------------\n",
      "nonRes_has_atleast_one_fatjet\n",
      "------------------------------------------------------------\n",
      "is_nonRes\n",
      "------------------------------------------------------------\n",
      "is_Res\n",
      "------------------------------------------------------------\n",
      "nBTight\n",
      "------------------------------------------------------------\n",
      "nBMedium\n",
      "------------------------------------------------------------\n",
      "nBLoose\n",
      "------------------------------------------------------------\n",
      "n_leptons\n",
      "------------------------------------------------------------\n",
      "lepton1_pt\n",
      "------------------------------------------------------------\n",
      "lepton1_eta\n",
      "------------------------------------------------------------\n",
      "lepton1_phi\n",
      "------------------------------------------------------------\n",
      "lepton1_mass\n",
      "------------------------------------------------------------\n",
      "lepton1_charge\n",
      "------------------------------------------------------------\n",
      "lepton1_generation\n",
      "------------------------------------------------------------\n",
      "lepton1_mvaID\n",
      "------------------------------------------------------------\n",
      "lepton1_pfRelIso03_all\n",
      "------------------------------------------------------------\n",
      "lepton1_pfRelIso04_all\n",
      "------------------------------------------------------------\n",
      "lepton1_pfIsoId\n",
      "------------------------------------------------------------\n",
      "lepton1_dxy\n",
      "------------------------------------------------------------\n",
      "lepton1_dz\n",
      "------------------------------------------------------------\n",
      "lepton2_pt\n",
      "------------------------------------------------------------\n",
      "lepton2_eta\n",
      "------------------------------------------------------------\n",
      "lepton2_phi\n",
      "------------------------------------------------------------\n",
      "lepton2_mass\n",
      "------------------------------------------------------------\n",
      "lepton2_charge\n",
      "------------------------------------------------------------\n",
      "lepton2_generation\n",
      "------------------------------------------------------------\n",
      "lepton2_mvaID\n",
      "------------------------------------------------------------\n",
      "lepton2_pfRelIso03_all\n",
      "------------------------------------------------------------\n",
      "lepton2_pfRelIso04_all\n",
      "------------------------------------------------------------\n",
      "lepton2_pfIsoId\n",
      "------------------------------------------------------------\n",
      "lepton2_dxy\n",
      "------------------------------------------------------------\n",
      "lepton2_dz\n",
      "------------------------------------------------------------\n",
      "lepton3_pt\n",
      "------------------------------------------------------------\n",
      "lepton3_eta\n",
      "------------------------------------------------------------\n",
      "lepton3_phi\n",
      "------------------------------------------------------------\n",
      "lepton3_mass\n",
      "------------------------------------------------------------\n",
      "lepton3_charge\n",
      "------------------------------------------------------------\n",
      "lepton3_generation\n",
      "------------------------------------------------------------\n",
      "lepton3_mvaID\n",
      "------------------------------------------------------------\n",
      "lepton3_pfRelIso03_all\n",
      "------------------------------------------------------------\n",
      "lepton3_pfRelIso04_all\n",
      "------------------------------------------------------------\n",
      "lepton3_pfIsoId\n",
      "------------------------------------------------------------\n",
      "lepton3_dxy\n",
      "------------------------------------------------------------\n",
      "lepton3_dz\n",
      "------------------------------------------------------------\n",
      "lepton4_pt\n",
      "------------------------------------------------------------\n",
      "lepton4_eta\n",
      "------------------------------------------------------------\n",
      "lepton4_phi\n",
      "------------------------------------------------------------\n",
      "lepton4_mass\n",
      "------------------------------------------------------------\n",
      "lepton4_charge\n",
      "------------------------------------------------------------\n",
      "lepton4_generation\n",
      "------------------------------------------------------------\n",
      "lepton4_mvaID\n",
      "------------------------------------------------------------\n",
      "lepton4_pfRelIso03_all\n",
      "------------------------------------------------------------\n",
      "lepton4_pfRelIso04_all\n",
      "------------------------------------------------------------\n",
      "lepton4_pfIsoId\n",
      "------------------------------------------------------------\n",
      "lepton4_dxy\n",
      "------------------------------------------------------------\n",
      "lepton4_dz\n",
      "------------------------------------------------------------\n",
      "DeltaR_j1l1\n",
      "------------------------------------------------------------\n",
      "DeltaR_j1l2\n",
      "------------------------------------------------------------\n",
      "DeltaR_j1l3\n",
      "------------------------------------------------------------\n",
      "DeltaR_j1l4\n",
      "------------------------------------------------------------\n",
      "DeltaR_j2l1\n",
      "------------------------------------------------------------\n",
      "DeltaR_j2l2\n",
      "------------------------------------------------------------\n",
      "DeltaR_j2l3\n",
      "------------------------------------------------------------\n",
      "DeltaR_j2l4\n",
      "------------------------------------------------------------\n",
      "DeltaR_j3l1\n",
      "------------------------------------------------------------\n",
      "DeltaR_j3l2\n",
      "------------------------------------------------------------\n",
      "DeltaR_j3l3\n",
      "------------------------------------------------------------\n",
      "DeltaR_j3l4\n",
      "------------------------------------------------------------\n",
      "DeltaR_j4l1\n",
      "------------------------------------------------------------\n",
      "DeltaR_j4l2\n",
      "------------------------------------------------------------\n",
      "DeltaR_j4l3\n",
      "------------------------------------------------------------\n",
      "DeltaR_j4l4\n",
      "------------------------------------------------------------\n",
      "DeltaR_j5l1\n",
      "------------------------------------------------------------\n",
      "DeltaR_j5l2\n",
      "------------------------------------------------------------\n",
      "DeltaR_j5l3\n",
      "------------------------------------------------------------\n",
      "DeltaR_j5l4\n",
      "------------------------------------------------------------\n",
      "DeltaR_j6l1\n",
      "------------------------------------------------------------\n",
      "DeltaR_j6l2\n",
      "------------------------------------------------------------\n",
      "DeltaR_j6l3\n",
      "------------------------------------------------------------\n",
      "DeltaR_j6l4\n",
      "------------------------------------------------------------\n",
      "DeltaR_j7l1\n",
      "------------------------------------------------------------\n",
      "DeltaR_j7l2\n",
      "------------------------------------------------------------\n",
      "DeltaR_j7l3\n",
      "------------------------------------------------------------\n",
      "DeltaR_j7l4\n",
      "------------------------------------------------------------\n",
      "DeltaR_j8l1\n",
      "------------------------------------------------------------\n",
      "DeltaR_j8l2\n",
      "------------------------------------------------------------\n",
      "DeltaR_j8l3\n",
      "------------------------------------------------------------\n",
      "DeltaR_j8l4\n",
      "------------------------------------------------------------\n",
      "DeltaR_j9l1\n",
      "------------------------------------------------------------\n",
      "DeltaR_j9l2\n",
      "------------------------------------------------------------\n",
      "DeltaR_j9l3\n",
      "------------------------------------------------------------\n",
      "DeltaR_j9l4\n",
      "------------------------------------------------------------\n",
      "DeltaR_j10l1\n",
      "------------------------------------------------------------\n",
      "DeltaR_j10l2\n",
      "------------------------------------------------------------\n",
      "DeltaR_j10l3\n",
      "------------------------------------------------------------\n",
      "DeltaR_j10l4\n",
      "------------------------------------------------------------\n",
      "DeltaR_b1l1\n",
      "------------------------------------------------------------\n",
      "DeltaR_b2l1\n",
      "------------------------------------------------------------\n",
      "DeltaR_b1l2\n",
      "------------------------------------------------------------\n",
      "DeltaR_b2l2\n",
      "------------------------------------------------------------\n",
      "lepton1_genMatched\n",
      "------------------------------------------------------------\n",
      "lepton2_genMatched\n",
      "------------------------------------------------------------\n",
      "lepton3_genMatched\n",
      "------------------------------------------------------------\n",
      "lepton4_genMatched\n",
      "------------------------------------------------------------\n",
      "fatjet1_jetId\n",
      "------------------------------------------------------------\n",
      "fatjet1_nConstituents\n",
      "------------------------------------------------------------\n",
      "fatjet1_subjet1_btagDeepB\n",
      "------------------------------------------------------------\n",
      "fatjet1_subjet1_eta\n",
      "------------------------------------------------------------\n",
      "fatjet1_subjet1_mass\n",
      "------------------------------------------------------------\n",
      "fatjet1_subjet1_phi\n",
      "------------------------------------------------------------\n",
      "fatjet1_subjet1_pt\n",
      "------------------------------------------------------------\n",
      "fatjet1_subjet1_rawFactor\n",
      "------------------------------------------------------------\n",
      "fatjet1_subjet2_btagDeepB\n",
      "------------------------------------------------------------\n",
      "fatjet1_subjet2_eta\n",
      "------------------------------------------------------------\n",
      "fatjet1_subjet2_mass\n",
      "------------------------------------------------------------\n",
      "fatjet1_subjet2_phi\n",
      "------------------------------------------------------------\n",
      "fatjet1_subjet2_pt\n",
      "------------------------------------------------------------\n",
      "fatjet1_subjet2_rawFactor\n",
      "------------------------------------------------------------\n",
      "fatjet1_area\n",
      "------------------------------------------------------------\n",
      "fatjet1_btagDDBvLV2\n",
      "------------------------------------------------------------\n",
      "fatjet1_btagDDCvBV2\n",
      "------------------------------------------------------------\n",
      "fatjet1_btagDDCvLV2\n",
      "------------------------------------------------------------\n",
      "fatjet1_btagDeepB\n",
      "------------------------------------------------------------\n",
      "fatjet1_btagHbb\n",
      "------------------------------------------------------------\n",
      "fatjet1_eta\n",
      "------------------------------------------------------------\n",
      "fatjet1_mass\n",
      "------------------------------------------------------------\n",
      "fatjet1_msoftdrop\n",
      "------------------------------------------------------------\n",
      "fatjet1_n2b1\n",
      "------------------------------------------------------------\n",
      "fatjet1_n3b1\n",
      "------------------------------------------------------------\n",
      "fatjet1_particleNetWithMass_HbbvsQCD\n",
      "------------------------------------------------------------\n",
      "fatjet1_particleNetWithMass_QCD\n",
      "------------------------------------------------------------\n",
      "fatjet1_particleNet_QCD\n",
      "------------------------------------------------------------\n",
      "fatjet1_particleNet_QCD0HF\n",
      "------------------------------------------------------------\n",
      "fatjet1_particleNet_QCD1HF\n",
      "------------------------------------------------------------\n",
      "fatjet1_particleNet_QCD2HF\n",
      "------------------------------------------------------------\n",
      "fatjet1_particleNet_XbbVsQCD\n",
      "------------------------------------------------------------\n",
      "fatjet1_particleNet_XccVsQCD\n",
      "------------------------------------------------------------\n",
      "fatjet1_particleNet_XggVsQCD\n",
      "------------------------------------------------------------\n",
      "fatjet1_particleNet_XqqVsQCD\n",
      "------------------------------------------------------------\n",
      "fatjet1_particleNet_massCorr\n",
      "------------------------------------------------------------\n",
      "fatjet1_phi\n",
      "------------------------------------------------------------\n",
      "fatjet1_pt\n",
      "------------------------------------------------------------\n",
      "fatjet1_rawFactor\n",
      "------------------------------------------------------------\n",
      "fatjet1_tau1\n",
      "------------------------------------------------------------\n",
      "fatjet1_tau2\n",
      "------------------------------------------------------------\n",
      "fatjet1_tau3\n",
      "------------------------------------------------------------\n",
      "fatjet1_tau4\n",
      "------------------------------------------------------------\n",
      "fatjet1_hadronFlavour\n",
      "------------------------------------------------------------\n",
      "fatjet1_nBHadrons\n",
      "------------------------------------------------------------\n",
      "fatjet1_nCHadrons\n",
      "------------------------------------------------------------\n",
      "fatjet1_genjetAK8_eta\n",
      "------------------------------------------------------------\n",
      "fatjet1_genjetAK8_mass\n",
      "------------------------------------------------------------\n",
      "fatjet1_genjetAK8_phi\n",
      "------------------------------------------------------------\n",
      "fatjet1_genjetAK8_pt\n",
      "------------------------------------------------------------\n",
      "fatjet1_genjetAK8_hadronFlavour\n",
      "------------------------------------------------------------\n",
      "fatjet1_genjetAK8_partonFlavour\n",
      "------------------------------------------------------------\n",
      "fatjet2_jetId\n",
      "------------------------------------------------------------\n",
      "fatjet2_nConstituents\n",
      "------------------------------------------------------------\n",
      "fatjet2_subjet1_btagDeepB\n",
      "------------------------------------------------------------\n",
      "fatjet2_subjet1_eta\n",
      "------------------------------------------------------------\n",
      "fatjet2_subjet1_mass\n",
      "------------------------------------------------------------\n",
      "fatjet2_subjet1_phi\n",
      "------------------------------------------------------------\n",
      "fatjet2_subjet1_pt\n",
      "------------------------------------------------------------\n",
      "fatjet2_subjet1_rawFactor\n",
      "------------------------------------------------------------\n",
      "fatjet2_subjet2_btagDeepB\n",
      "------------------------------------------------------------\n",
      "fatjet2_subjet2_eta\n",
      "------------------------------------------------------------\n",
      "fatjet2_subjet2_mass\n",
      "------------------------------------------------------------\n",
      "fatjet2_subjet2_phi\n",
      "------------------------------------------------------------\n",
      "fatjet2_subjet2_pt\n",
      "------------------------------------------------------------\n",
      "fatjet2_subjet2_rawFactor\n",
      "------------------------------------------------------------\n",
      "fatjet2_area\n",
      "------------------------------------------------------------\n",
      "fatjet2_btagDDBvLV2\n",
      "------------------------------------------------------------\n",
      "fatjet2_btagDDCvBV2\n",
      "------------------------------------------------------------\n",
      "fatjet2_btagDDCvLV2\n",
      "------------------------------------------------------------\n",
      "fatjet2_btagDeepB\n",
      "------------------------------------------------------------\n",
      "fatjet2_btagHbb\n",
      "------------------------------------------------------------\n",
      "fatjet2_eta\n",
      "------------------------------------------------------------\n",
      "fatjet2_mass\n",
      "------------------------------------------------------------\n",
      "fatjet2_msoftdrop\n",
      "------------------------------------------------------------\n",
      "fatjet2_n2b1\n",
      "------------------------------------------------------------\n",
      "fatjet2_n3b1\n",
      "------------------------------------------------------------\n",
      "fatjet2_particleNetWithMass_HbbvsQCD\n",
      "------------------------------------------------------------\n",
      "fatjet2_particleNetWithMass_QCD\n",
      "------------------------------------------------------------\n",
      "fatjet2_particleNet_QCD\n",
      "------------------------------------------------------------\n",
      "fatjet2_particleNet_QCD0HF\n",
      "------------------------------------------------------------\n",
      "fatjet2_particleNet_QCD1HF\n",
      "------------------------------------------------------------\n",
      "fatjet2_particleNet_QCD2HF\n",
      "------------------------------------------------------------\n",
      "fatjet2_particleNet_XbbVsQCD\n",
      "------------------------------------------------------------\n",
      "fatjet2_particleNet_XccVsQCD\n",
      "------------------------------------------------------------\n",
      "fatjet2_particleNet_XggVsQCD\n",
      "------------------------------------------------------------\n",
      "fatjet2_particleNet_XqqVsQCD\n",
      "------------------------------------------------------------\n",
      "fatjet2_particleNet_massCorr\n",
      "------------------------------------------------------------\n",
      "fatjet2_phi\n",
      "------------------------------------------------------------\n",
      "fatjet2_pt\n",
      "------------------------------------------------------------\n",
      "fatjet2_rawFactor\n",
      "------------------------------------------------------------\n",
      "fatjet2_tau1\n",
      "------------------------------------------------------------\n",
      "fatjet2_tau2\n",
      "------------------------------------------------------------\n",
      "fatjet2_tau3\n",
      "------------------------------------------------------------\n",
      "fatjet2_tau4\n",
      "------------------------------------------------------------\n",
      "fatjet2_hadronFlavour\n",
      "------------------------------------------------------------\n",
      "fatjet2_nBHadrons\n",
      "------------------------------------------------------------\n",
      "fatjet2_nCHadrons\n",
      "------------------------------------------------------------\n",
      "fatjet2_genjetAK8_eta\n",
      "------------------------------------------------------------\n",
      "fatjet2_genjetAK8_mass\n",
      "------------------------------------------------------------\n",
      "fatjet2_genjetAK8_phi\n",
      "------------------------------------------------------------\n",
      "fatjet2_genjetAK8_pt\n",
      "------------------------------------------------------------\n",
      "fatjet2_genjetAK8_hadronFlavour\n",
      "------------------------------------------------------------\n",
      "fatjet2_genjetAK8_partonFlavour\n",
      "------------------------------------------------------------\n",
      "fatjet3_jetId\n",
      "------------------------------------------------------------\n",
      "fatjet3_nConstituents\n",
      "------------------------------------------------------------\n",
      "fatjet3_subjet1_btagDeepB\n",
      "------------------------------------------------------------\n",
      "fatjet3_subjet1_eta\n",
      "------------------------------------------------------------\n",
      "fatjet3_subjet1_mass\n",
      "------------------------------------------------------------\n",
      "fatjet3_subjet1_phi\n",
      "------------------------------------------------------------\n",
      "fatjet3_subjet1_pt\n",
      "------------------------------------------------------------\n",
      "fatjet3_subjet1_rawFactor\n",
      "------------------------------------------------------------\n",
      "fatjet3_subjet2_btagDeepB\n",
      "------------------------------------------------------------\n",
      "fatjet3_subjet2_eta\n",
      "------------------------------------------------------------\n",
      "fatjet3_subjet2_mass\n",
      "------------------------------------------------------------\n",
      "fatjet3_subjet2_phi\n",
      "------------------------------------------------------------\n",
      "fatjet3_subjet2_pt\n",
      "------------------------------------------------------------\n",
      "fatjet3_subjet2_rawFactor\n",
      "------------------------------------------------------------\n",
      "fatjet3_area\n",
      "------------------------------------------------------------\n",
      "fatjet3_btagDDBvLV2\n",
      "------------------------------------------------------------\n",
      "fatjet3_btagDDCvBV2\n",
      "------------------------------------------------------------\n",
      "fatjet3_btagDDCvLV2\n",
      "------------------------------------------------------------\n",
      "fatjet3_btagDeepB\n",
      "------------------------------------------------------------\n",
      "fatjet3_btagHbb\n",
      "------------------------------------------------------------\n",
      "fatjet3_eta\n",
      "------------------------------------------------------------\n",
      "fatjet3_mass\n",
      "------------------------------------------------------------\n",
      "fatjet3_msoftdrop\n",
      "------------------------------------------------------------\n",
      "fatjet3_n2b1\n",
      "------------------------------------------------------------\n",
      "fatjet3_n3b1\n",
      "------------------------------------------------------------\n",
      "fatjet3_particleNetWithMass_HbbvsQCD\n",
      "------------------------------------------------------------\n",
      "fatjet3_particleNetWithMass_QCD\n",
      "------------------------------------------------------------\n",
      "fatjet3_particleNet_QCD\n",
      "------------------------------------------------------------\n",
      "fatjet3_particleNet_QCD0HF\n",
      "------------------------------------------------------------\n",
      "fatjet3_particleNet_QCD1HF\n",
      "------------------------------------------------------------\n",
      "fatjet3_particleNet_QCD2HF\n",
      "------------------------------------------------------------\n",
      "fatjet3_particleNet_XbbVsQCD\n",
      "------------------------------------------------------------\n",
      "fatjet3_particleNet_XccVsQCD\n",
      "------------------------------------------------------------\n",
      "fatjet3_particleNet_XggVsQCD\n",
      "------------------------------------------------------------\n",
      "fatjet3_particleNet_XqqVsQCD\n",
      "------------------------------------------------------------\n",
      "fatjet3_particleNet_massCorr\n",
      "------------------------------------------------------------\n",
      "fatjet3_phi\n",
      "------------------------------------------------------------\n",
      "fatjet3_pt\n",
      "------------------------------------------------------------\n",
      "fatjet3_rawFactor\n",
      "------------------------------------------------------------\n",
      "fatjet3_tau1\n",
      "------------------------------------------------------------\n",
      "fatjet3_tau2\n",
      "------------------------------------------------------------\n",
      "fatjet3_tau3\n",
      "------------------------------------------------------------\n",
      "fatjet3_tau4\n",
      "------------------------------------------------------------\n",
      "fatjet3_hadronFlavour\n",
      "------------------------------------------------------------\n",
      "fatjet3_nBHadrons\n",
      "------------------------------------------------------------\n",
      "fatjet3_nCHadrons\n",
      "------------------------------------------------------------\n",
      "fatjet3_genjetAK8_eta\n",
      "------------------------------------------------------------\n",
      "fatjet3_genjetAK8_mass\n",
      "------------------------------------------------------------\n",
      "fatjet3_genjetAK8_phi\n",
      "------------------------------------------------------------\n",
      "fatjet3_genjetAK8_pt\n",
      "------------------------------------------------------------\n",
      "fatjet3_genjetAK8_hadronFlavour\n",
      "------------------------------------------------------------\n",
      "fatjet3_genjetAK8_partonFlavour\n",
      "------------------------------------------------------------\n",
      "fatjet4_jetId\n",
      "------------------------------------------------------------\n",
      "fatjet4_nConstituents\n",
      "------------------------------------------------------------\n",
      "fatjet4_subjet1_btagDeepB\n",
      "------------------------------------------------------------\n",
      "fatjet4_subjet1_eta\n",
      "------------------------------------------------------------\n",
      "fatjet4_subjet1_mass\n",
      "------------------------------------------------------------\n",
      "fatjet4_subjet1_phi\n",
      "------------------------------------------------------------\n",
      "fatjet4_subjet1_pt\n",
      "------------------------------------------------------------\n",
      "fatjet4_subjet1_rawFactor\n",
      "------------------------------------------------------------\n",
      "fatjet4_subjet2_btagDeepB\n",
      "------------------------------------------------------------\n",
      "fatjet4_subjet2_eta\n",
      "------------------------------------------------------------\n",
      "fatjet4_subjet2_mass\n",
      "------------------------------------------------------------\n",
      "fatjet4_subjet2_phi\n",
      "------------------------------------------------------------\n",
      "fatjet4_subjet2_pt\n",
      "------------------------------------------------------------\n",
      "fatjet4_subjet2_rawFactor\n",
      "------------------------------------------------------------\n",
      "fatjet4_area\n",
      "------------------------------------------------------------\n",
      "fatjet4_btagDDBvLV2\n",
      "------------------------------------------------------------\n",
      "fatjet4_btagDDCvBV2\n",
      "------------------------------------------------------------\n",
      "fatjet4_btagDDCvLV2\n",
      "------------------------------------------------------------\n",
      "fatjet4_btagDeepB\n",
      "------------------------------------------------------------\n",
      "fatjet4_btagHbb\n",
      "------------------------------------------------------------\n",
      "fatjet4_eta\n",
      "------------------------------------------------------------\n",
      "fatjet4_mass\n",
      "------------------------------------------------------------\n",
      "fatjet4_msoftdrop\n",
      "------------------------------------------------------------\n",
      "fatjet4_n2b1\n",
      "------------------------------------------------------------\n",
      "fatjet4_n3b1\n",
      "------------------------------------------------------------\n",
      "fatjet4_particleNetWithMass_HbbvsQCD\n",
      "------------------------------------------------------------\n",
      "fatjet4_particleNetWithMass_QCD\n",
      "------------------------------------------------------------\n",
      "fatjet4_particleNet_QCD\n",
      "------------------------------------------------------------\n",
      "fatjet4_particleNet_QCD0HF\n",
      "------------------------------------------------------------\n",
      "fatjet4_particleNet_QCD1HF\n",
      "------------------------------------------------------------\n",
      "fatjet4_particleNet_QCD2HF\n",
      "------------------------------------------------------------\n",
      "fatjet4_particleNet_XbbVsQCD\n",
      "------------------------------------------------------------\n",
      "fatjet4_particleNet_XccVsQCD\n",
      "------------------------------------------------------------\n",
      "fatjet4_particleNet_XggVsQCD\n",
      "------------------------------------------------------------\n",
      "fatjet4_particleNet_XqqVsQCD\n",
      "------------------------------------------------------------\n",
      "fatjet4_particleNet_massCorr\n",
      "------------------------------------------------------------\n",
      "fatjet4_phi\n",
      "------------------------------------------------------------\n",
      "fatjet4_pt\n",
      "------------------------------------------------------------\n",
      "fatjet4_rawFactor\n",
      "------------------------------------------------------------\n",
      "fatjet4_tau1\n",
      "------------------------------------------------------------\n",
      "fatjet4_tau2\n",
      "------------------------------------------------------------\n",
      "fatjet4_tau3\n",
      "------------------------------------------------------------\n",
      "fatjet4_tau4\n",
      "------------------------------------------------------------\n",
      "fatjet4_hadronFlavour\n",
      "------------------------------------------------------------\n",
      "fatjet4_nBHadrons\n",
      "------------------------------------------------------------\n",
      "fatjet4_nCHadrons\n",
      "------------------------------------------------------------\n",
      "fatjet4_genjetAK8_eta\n",
      "------------------------------------------------------------\n",
      "fatjet4_genjetAK8_mass\n",
      "------------------------------------------------------------\n",
      "fatjet4_genjetAK8_phi\n",
      "------------------------------------------------------------\n",
      "fatjet4_genjetAK8_pt\n",
      "------------------------------------------------------------\n",
      "fatjet4_genjetAK8_hadronFlavour\n",
      "------------------------------------------------------------\n",
      "fatjet4_genjetAK8_partonFlavour\n",
      "------------------------------------------------------------\n",
      "puppiMET_phi\n",
      "------------------------------------------------------------\n",
      "puppiMET_phiJERDown\n",
      "------------------------------------------------------------\n",
      "puppiMET_phiJERUp\n",
      "------------------------------------------------------------\n",
      "puppiMET_phiJESDown\n",
      "------------------------------------------------------------\n",
      "puppiMET_phiJESUp\n",
      "------------------------------------------------------------\n",
      "puppiMET_phiUnclusteredDown\n",
      "------------------------------------------------------------\n",
      "puppiMET_phiUnclusteredUp\n",
      "------------------------------------------------------------\n",
      "puppiMET_pt\n",
      "------------------------------------------------------------\n",
      "puppiMET_ptJERDown\n",
      "------------------------------------------------------------\n",
      "puppiMET_ptJERUp\n",
      "------------------------------------------------------------\n",
      "puppiMET_ptJESDown\n",
      "------------------------------------------------------------\n",
      "puppiMET_ptJESUp\n",
      "------------------------------------------------------------\n",
      "puppiMET_ptUnclusteredDown\n",
      "------------------------------------------------------------\n",
      "puppiMET_ptUnclusteredUp\n",
      "------------------------------------------------------------\n",
      "puppiMET_sumEt\n",
      "------------------------------------------------------------\n",
      "event\n",
      "------------------------------------------------------------\n",
      "lumi\n",
      "------------------------------------------------------------\n",
      "run\n",
      "------------------------------------------------------------\n",
      "nPV\n",
      "------------------------------------------------------------\n",
      "fixedGridRhoAll\n",
      "------------------------------------------------------------\n",
      "genWeight\n",
      "------------------------------------------------------------\n",
      "dZ\n",
      "------------------------------------------------------------\n",
      "HTXS_Higgs_pt\n",
      "------------------------------------------------------------\n",
      "HTXS_Higgs_y\n",
      "------------------------------------------------------------\n",
      "HTXS_njets30\n",
      "------------------------------------------------------------\n",
      "HTXS_stage_0\n",
      "------------------------------------------------------------\n",
      "bTagWeight\n",
      "------------------------------------------------------------\n",
      "weight_central\n",
      "------------------------------------------------------------\n",
      "weight_interference\n",
      "------------------------------------------------------------\n",
      "sigma_m_over_m\n",
      "------------------------------------------------------------\n",
      "sigma_m_over_m_corr\n",
      "------------------------------------------------------------\n",
      "sigma_m_over_m_Smeared_corr\n",
      "------------------------------------------------------------\n",
      "sigma_m_over_m_Smeared\n",
      "------------------------------------------------------------\n",
      "sigma_m_over_m_nominal_decorr\n",
      "------------------------------------------------------------\n",
      "sigma_m_over_m_smeared_decorr\n",
      "------------------------------------------------------------\n",
      "sigma_m_over_m_corr_decorr\n",
      "------------------------------------------------------------\n",
      "sigma_m_over_m_decorr\n",
      "------------------------------------------------------------\n",
      "sigma_m_over_m_corr_smeared_decorr\n",
      "------------------------------------------------------------\n",
      "weight_nominal\n",
      "------------------------------------------------------------\n",
      "weight_TriggerSFUp\n",
      "------------------------------------------------------------\n",
      "weight_PreselSFDown\n",
      "------------------------------------------------------------\n",
      "weight_PreselSFUp\n",
      "------------------------------------------------------------\n",
      "weight_TriggerSFDown\n",
      "------------------------------------------------------------\n",
      "weight_PileupUp\n",
      "------------------------------------------------------------\n",
      "weight_ElectronVetoSFUp\n",
      "------------------------------------------------------------\n",
      "weight_PileupDown\n",
      "------------------------------------------------------------\n",
      "weight_ElectronVetoSFDown\n",
      "------------------------------------------------------------\n",
      "weight\n",
      "------------------------------------------------------------\n",
      "weight_bTagSF_sys_lfstats1Up\n",
      "------------------------------------------------------------\n",
      "weight_bTagSF_sys_lfstats1Down\n",
      "------------------------------------------------------------\n",
      "weight_bTagSF_sys_hfstats2Up\n",
      "------------------------------------------------------------\n",
      "weight_bTagSF_sys_hfstats2Down\n",
      "------------------------------------------------------------\n",
      "weight_bTagSF_sys_jesUp\n",
      "------------------------------------------------------------\n",
      "weight_bTagSF_sys_jesDown\n",
      "------------------------------------------------------------\n",
      "weight_bTagSF_sys_cferr2Up\n",
      "------------------------------------------------------------\n",
      "weight_bTagSF_sys_cferr2Down\n",
      "------------------------------------------------------------\n",
      "weight_bTagSF_sys_lfUp\n",
      "------------------------------------------------------------\n",
      "weight_bTagSF_sys_lfDown\n",
      "------------------------------------------------------------\n",
      "weight_bTagSF_sys_hfUp\n",
      "------------------------------------------------------------\n",
      "weight_bTagSF_sys_hfDown\n",
      "------------------------------------------------------------\n",
      "weight_bTagSF_sys_lfstats2Up\n",
      "------------------------------------------------------------\n",
      "weight_bTagSF_sys_lfstats2Down\n",
      "------------------------------------------------------------\n",
      "weight_bTagSF_sys_hfstats1Up\n",
      "------------------------------------------------------------\n",
      "weight_bTagSF_sys_hfstats1Down\n",
      "------------------------------------------------------------\n",
      "weight_bTagSF_sys_cferr1Up\n",
      "------------------------------------------------------------\n",
      "weight_bTagSF_sys_cferr1Down\n",
      "------------------------------------------------------------\n",
      "sample_name\n",
      "------------------------------------------------------------\n",
      "eventWeight\n",
      "------------------------------------------------------------\n",
      "lead_bjet_btagRobustParTAK4B\n",
      "------------------------------------------------------------\n",
      "lead_bjet_PNetRegPt\n",
      "------------------------------------------------------------\n",
      "lead_bjet_sigmapT_over_pT\n",
      "------------------------------------------------------------\n",
      "lead_bjet_sigmapT_over_RegPt\n",
      "------------------------------------------------------------\n",
      "sublead_bjet_btagRobustParTAK4B\n",
      "------------------------------------------------------------\n",
      "sublead_bjet_PNetRegPt\n",
      "------------------------------------------------------------\n",
      "sublead_bjet_sigmapT_over_pT\n",
      "------------------------------------------------------------\n",
      "sublead_bjet_sigmapT_over_RegPt\n",
      "------------------------------------------------------------\n",
      "dijet_PNetRegPt\n",
      "------------------------------------------------------------\n",
      "dijet_PNetRegEta\n",
      "------------------------------------------------------------\n",
      "dijet_PNetRegPhi\n",
      "------------------------------------------------------------\n",
      "dijet_PNetRegMass\n",
      "------------------------------------------------------------\n",
      "HH_PNetRegPt\n",
      "------------------------------------------------------------\n",
      "HH_PNetRegEta\n",
      "------------------------------------------------------------\n",
      "HH_PNetRegPhi\n",
      "------------------------------------------------------------\n",
      "HH_PNetRegMass\n",
      "------------------------------------------------------------\n",
      "lead_sigmaE_over_E\n",
      "------------------------------------------------------------\n",
      "lead_bjet_pt_over_Mjj\n",
      "------------------------------------------------------------\n",
      "lead_bjet_RegPt_over_Mjj\n",
      "------------------------------------------------------------\n",
      "sublead_sigmaE_over_E\n",
      "------------------------------------------------------------\n",
      "sublead_bjet_pt_over_Mjj\n",
      "------------------------------------------------------------\n",
      "sublead_bjet_RegPt_over_Mjj\n",
      "------------------------------------------------------------\n",
      "RegPt_balance\n",
      "------------------------------------------------------------\n",
      "pt_balance\n",
      "------------------------------------------------------------\n",
      "DeltaPhi_jj\n",
      "------------------------------------------------------------\n",
      "DeltaEta_jj\n",
      "------------------------------------------------------------\n",
      "isr_jet_RegPt\n",
      "------------------------------------------------------------\n",
      "DeltaPhi_isr_jet_z\n",
      "------------------------------------------------------------\n",
      "hash\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# order = ['ggF HH', 'ttH', 'single-H', 'non-res']\n",
    "order = ['ggF HH', 'ttH', 'VH', 'non-res + ggFH + VBFH']\n",
    "\n",
    "(\n",
    "    sig_rescale_factor,\n",
    "    data_df_dict, data_test_df_dict, \n",
    "    data_hlf_dict, label_dict,\n",
    "    data_hlf_test_dict, label_test_dict, \n",
    "    hlf_vars_columns_dict,\n",
    "    data_aux_dict, data_test_aux_dict\n",
    ") = process_data(\n",
    "    FILEPATHS_DICT, OUTPUT_DIRPATH, order=order, mod_vals=MOD_VALS,\n",
    "    save=False if 'CURRENT_TIME' in globals() else True,\n",
    "    std_json_dirpath=OUTPUT_DIRPATH if 'CURRENT_TIME' in globals() else None,\n",
    "    other_bkg_rescale=OTHER_BKG_RESCALE\n",
    ")\n",
    "\n",
    "# Make xgb-like labels (NOT one-hot encoded, but integer encoded for each class)\n",
    "xgb_label_dict = {\n",
    "    f\"fold_{fold_idx}\": copy.deepcopy(xgb_labels(label_dict[f\"fold_{fold_idx}\"])) for fold_idx in range(len(data_test_aux_dict))\n",
    "}\n",
    "xgb_label_test_dict = {\n",
    "    f\"fold_{fold_idx}\": copy.deepcopy(xgb_labels(label_test_dict[f\"fold_{fold_idx}\"])) for fold_idx in range(len(data_test_aux_dict))\n",
    "}\n",
    "\n",
    "# Make weight dicts:\n",
    "#   - the top two are with the training rescale (i.e. rescale sig eventWeight to match bkg and then shift for gradients)\n",
    "#   - the bottom two are the standard eventWeights (i.e. xs * lumi * genWeight) for proper plotting\n",
    "weight_train_dict = {\n",
    "    f\"fold_{fold_idx}\": copy.deepcopy(training_weights(data_aux_dict[f'fold_{fold_idx}'].loc[:, \"eventWeight\"].to_numpy(), label_dict[f'fold_{fold_idx}'], order=order, sig_rescale_factor=sig_rescale_factor)) for fold_idx in range(len(data_aux_dict))\n",
    "}\n",
    "weight_test_dict = {\n",
    "    f'fold_{fold_idx}': copy.deepcopy(training_weights(data_test_aux_dict[f'fold_{fold_idx}'].loc[:, \"eventWeight\"].to_numpy(), label_test_dict[f'fold_{fold_idx}'], order=order, sig_rescale_factor=sig_rescale_factor)) for fold_idx in range(len(data_test_aux_dict))\n",
    "}\n",
    "weights_plot_train_dict = {\n",
    "    f\"fold_{fold_idx}\": copy.deepcopy(data_aux_dict[f'fold_{fold_idx}'].loc[:, \"eventWeight\"].to_numpy()) for fold_idx in range(len(data_aux_dict))\n",
    "}\n",
    "weights_plot_test = {\n",
    "    f'fold_{fold_idx}': copy.deepcopy(data_test_aux_dict[f'fold_{fold_idx}'].loc[:, \"eventWeight\"].to_numpy()) for fold_idx in range(len(data_test_aux_dict))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "Num train: 2623120 -> 105311 sig & 220605 ttH bkg & 97164 single-H bkg & 2200040 non-res bkg\n",
      "Num val: 655780 -> 26136 sig & 55286 ttH bkg & 24390 single-H bkg & 549968 non-res bkg\n",
      "Num test: 820895 -> 32955 sig & 69145 ttH bkg & 30390 single-H bkg & & 688405 non-res bkg\n",
      "============================================================\n",
      "fold 1\n",
      "Num train: 2624540 -> 105125 sig & 221236 ttH bkg & 97255 single-H bkg & 2200924 non-res bkg\n",
      "Num val: 656136 -> 26285 sig & 55182 ttH bkg & 24153 single-H bkg & 550516 non-res bkg\n",
      "Num test: 819119 -> 32992 sig & 68618 ttH bkg & 30536 single-H bkg & & 686973 non-res bkg\n",
      "============================================================\n",
      "fold 2\n",
      "Num train: 2622752 -> 105060 sig & 220521 ttH bkg & 97375 single-H bkg & 2199796 non-res bkg\n",
      "Num val: 655688 -> 26426 sig & 54930 ttH bkg & 24355 single-H bkg & 549977 non-res bkg\n",
      "Num test: 821355 -> 32916 sig & 69585 ttH bkg & 30214 single-H bkg & & 688640 non-res bkg\n",
      "============================================================\n",
      "fold 3\n",
      "Num train: 2625108 -> 105259 sig & 220900 ttH bkg & 97410 single-H bkg & 2201539 non-res bkg\n",
      "Num val: 656277 -> 26363 sig & 55018 ttH bkg & 24163 single-H bkg & 550733 non-res bkg\n",
      "Num test: 818410 -> 32780 sig & 69118 ttH bkg & 30371 single-H bkg & & 686141 non-res bkg\n",
      "============================================================\n",
      "fold 4\n",
      "Num train: 2623823 -> 105182 sig & 221313 ttH bkg & 97545 single-H bkg & 2199783 non-res bkg\n",
      "Num val: 655956 -> 26461 sig & 55153 ttH bkg & 23966 single-H bkg & 550376 non-res bkg\n",
      "Num test: 820016 -> 32759 sig & 68570 ttH bkg & 30433 single-H bkg & & 688254 non-res bkg\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "bdt_train_dict, bdt_val_dict, bdt_test_dict = {}, {}, {}\n",
    "\n",
    "train_data_dict, val_data_dict = {}, {}\n",
    "xgb_label_train_dict, xgb_label_val_dict = {}, {}\n",
    "weights_plot_train, weights_plot_val= {}, {}\n",
    "train_idxs_dict, val_idxs_dict = {}, {}\n",
    "for fold_idx in range(len(data_df_dict)):\n",
    "    if re.search('no_std', VARS) is not None:\n",
    "        print('no standardization')\n",
    "        train_val_data_dict = {key: value.to_numpy() for key, value in data_df_dict.items()}\n",
    "        test_data_dict = {key: value.to_numpy() for key, value in data_test_df_dict.items()}\n",
    "    else:\n",
    "        train_val_data_dict = data_hlf_dict\n",
    "        test_data_dict = data_hlf_test_dict\n",
    "    (\n",
    "        X_train, X_val, \n",
    "        y_train, y_val, \n",
    "        weight_train, weight_val, \n",
    "        weight_plot_train, weight_plot_val,\n",
    "        train_idxs, val_idxs\n",
    "    ) = train_test_split(\n",
    "        train_val_data_dict[f\"fold_{fold_idx}\"], xgb_label_dict[f\"fold_{fold_idx}\"], \n",
    "        weight_train_dict[f\"fold_{fold_idx}\"], weights_plot_train_dict[f\"fold_{fold_idx}\"],\n",
    "        range(len(train_val_data_dict[f\"fold_{fold_idx}\"])),\n",
    "        test_size=0.2, random_state=21\n",
    "    )\n",
    "\n",
    "    train_data_dict[f\"fold_{fold_idx}\"] = copy.deepcopy(X_train)\n",
    "    val_data_dict[f\"fold_{fold_idx}\"] = copy.deepcopy(X_val)\n",
    "\n",
    "    xgb_label_train_dict[f\"fold_{fold_idx}\"] = copy.deepcopy(y_train)\n",
    "    xgb_label_val_dict[f\"fold_{fold_idx}\"] = copy.deepcopy(y_val)\n",
    "\n",
    "    weights_plot_train[f\"fold_{fold_idx}\"] = copy.deepcopy(weight_plot_train)\n",
    "    weights_plot_val[f\"fold_{fold_idx}\"] = copy.deepcopy(weight_plot_val)\n",
    "\n",
    "    train_idxs_dict[f\"fold_{fold_idx}\"] = copy.deepcopy(train_idxs)\n",
    "    val_idxs_dict[f\"fold_{fold_idx}\"] = copy.deepcopy(val_idxs)\n",
    "\n",
    "    bdt_train_dict[f\"fold_{fold_idx}\"] = xgb.DMatrix(\n",
    "        data=X_train, label=y_train, \n",
    "        weight=weight_train,\n",
    "        missing=-999.0, feature_names=list(hlf_vars_columns_dict[f\"fold_{fold_idx}\"])\n",
    "    )\n",
    "    bdt_val_dict[f\"fold_{fold_idx}\"] = xgb.DMatrix(\n",
    "        data=X_val, label=y_val, \n",
    "        weight=weight_val,\n",
    "        missing=-999.0, feature_names=list(hlf_vars_columns_dict[f\"fold_{fold_idx}\"])\n",
    "    )\n",
    "    \n",
    "    bdt_test_dict[f\"fold_{fold_idx}\"] = xgb.DMatrix(\n",
    "        data=test_data_dict[f\"fold_{fold_idx}\"], label=xgb_label_test_dict[f\"fold_{fold_idx}\"], \n",
    "        weight=np.abs(weight_test_dict[f\"fold_{fold_idx}\"]),\n",
    "        missing=-999.0, feature_names=list(hlf_vars_columns_dict[f\"fold_{fold_idx}\"])\n",
    "    )\n",
    "\n",
    "    print(f\"fold {fold_idx}\")\n",
    "    print(f\"Num train: {len(y_train)} -> {sum(y_train == 0)} sig & {sum(y_train == 1)} ttH bkg & {sum(y_train == 2)} single-H bkg & {sum(y_train == 3)} non-res bkg\")\n",
    "    print(f\"Num val: {len(y_val)} -> {sum(y_val == 0)} sig & {sum(y_val == 1)} ttH bkg & {sum(y_val == 2)} single-H bkg & {sum(y_val == 3)} non-res bkg\")\n",
    "    print(f\"Num test: {len(label_test_dict[f'fold_{fold_idx}'])} -> {sum(label_test_dict[f'fold_{fold_idx}'] == np.array([1, 0, 0, 0]))[0]} sig & {sum(label_test_dict[f'fold_{fold_idx}'] == np.array([0, 1, 0, 0]))[1]} ttH bkg & {sum(label_test_dict[f'fold_{fold_idx}'] == np.array([0, 0, 1, 0]))[2]} single-H bkg & & {sum(label_test_dict[f'fold_{fold_idx}'] == np.array([0, 0, 0, 1]))[3]} non-res bkg\")\n",
    "    print('='*60)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Parameterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/57986259/multiclass-classification-with-xgboost-classifier\n",
    "# https://forecastegy.com/posts/xgboost-multiclass-classification-python/\n",
    "# https://indico.cern.ch/event/915265/contributions/3848138/attachments/2048174/3432202/kunlinRan_bbyy_20200531.pdf\n",
    "\n",
    "# https://xgboost.readthedocs.io/en/stable/tutorials/intercept.html - for looking at logits level BDT output\n",
    "# https://indico.cern.ch/event/915265/contributions/3848138/attachments/2048174/3432202/kunlinRan_bbyy_20200531.pdf - ATLAS HHbbgg BDT\n",
    "\n",
    "\n",
    "param = {}\n",
    "\n",
    "# Booster parameters\n",
    "param['eta']              = 0.05 # learning rate\n",
    "num_trees = round(25 / param['eta'])  # number of trees to make\n",
    "param['max_depth']        = 20  # maximum depth of a tree\n",
    "param['subsample']        = 0.6 # fraction of events to train tree on\n",
    "param['colsample_bytree'] = 0.6 # fraction of features to train tree on\n",
    "param['num_class']        = len(order) # num classes for multi-class training\n",
    "param['device']           = 'cuda'\n",
    "# param['min_child_weight'] = 0.25\n",
    "\n",
    "# Learning task parameters\n",
    "param['objective']   = 'multi:softprob'   # objective function\n",
    "param['eval_metric'] = 'merror'           # evaluation metric for cross validation\n",
    "param = list(param.items()) + [('eval_metric', 'mlogloss')]\n",
    "# param[\"disable_default_eval_metric\"] = True\n",
    "# param = list(param.items())\n",
    "\n",
    "\n",
    "def thresholded_weighted_merror(predt: np.ndarray, dtrain: xgb.DMatrix, threshold=0.95):\n",
    "    \"\"\"Used when there's no custom objective.\"\"\"\n",
    "    # No need to do transform, XGBoost handles it internally.\n",
    "    weights = dtrain.get_weight()\n",
    "    thresh_weight_merror = np.where(\n",
    "        np.logical_and(\n",
    "            np.max(predt, axis=1) >= threshold,\n",
    "            np.argmax(predt, axis=1) == dtrain.get_label()\n",
    "        ),\n",
    "        0,\n",
    "        weights\n",
    "    )\n",
    "    return f'WeightedMError@{threshold:.2f}', np.sum(thresh_weight_merror)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_param_dict():\n",
    "    param = {}\n",
    "    # Booster parameters\n",
    "    param['eta']              = 0.1 # learning rate\n",
    "    param['subsample']        = 0.5 # fraction of events to train tree on\n",
    "    param['colsample_bytree'] = 0.8 # fraction of features to train tree on\n",
    "    param['num_class']        = len(order) # num classes for multi-class training\n",
    "    # param['device']           = 'cuda'\n",
    "    # param['sampling_method']  = 'gradient_based'\n",
    "    param['tree_method']      = 'hist'\n",
    "    param['max_bin']          = 500\n",
    "    param['grow_policy']      = 'lossguide'\n",
    "    # Learning task parameters\n",
    "    param['objective']   = 'multi:softprob'   # objective function\n",
    "    param['eval_metric'] = 'mlogloss'           # evaluation metric for cross validation\n",
    "\n",
    "    return param, round(25 / param['eta'])  # number of trees to make\n",
    "\n",
    "def optimize_hyperparams(\n",
    "    dtrain_dict: dict, dval_dict: dict, verbose: bool=False, verbose_eval: bool=False\n",
    "):\n",
    "    # order and grouping of optimization taken from: \n",
    "    #   https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/#:~:text=min_child_weight%20%3D%201%3A%20A%20smaller%20value,%2C%20anyways%2C%20be%20tuned%20later.\n",
    "    rng = np.random.default_rng()\n",
    "    param, num_trees = init_param_dict()\n",
    "    print(\"Baseline parameters: {}\".format(param))\n",
    "\n",
    "    score_arrs = {\n",
    "        'max_depth_and_min_child_weight': list(),\n",
    "        'min_split_loss': list(),\n",
    "        'subsample_and_colsample_bytree': list(),\n",
    "        'reg_lambda': list(),\n",
    "        'eta': list()\n",
    "    }\n",
    "\n",
    "## max_depth and min_child_weight ##\n",
    "    max_depth_and_min_child_weight_space  = [\n",
    "        Integer(3, 10, \"uniform\", name='max_depth'),\n",
    "        Real(0.1, 10., \"log-uniform\", name='min_child_weight'),\n",
    "    ]\n",
    "    @use_named_args(max_depth_and_min_child_weight_space)\n",
    "    def max_depth_and_min_child_weight_objective(**X):\n",
    "        if verbose:\n",
    "            print(\"New configuration: {}\".format(X))\n",
    "\n",
    "        for key, val in X.items():\n",
    "            param[key] = val\n",
    "\n",
    "        # randomly sample a fold to evaluate\n",
    "        fold_idx = rng.integers(0, 4)\n",
    "\n",
    "        evallist = [(dtrain_dict[f\"fold_{fold_idx}\"], 'train'), (dval_dict[f\"fold_{fold_idx}\"], 'val')]\n",
    "        booster = xgb.train(\n",
    "            param, dtrain_dict[f\"fold_{fold_idx}\"], num_boost_round=num_trees, \n",
    "            evals=evallist, early_stopping_rounds=10, verbose_eval=verbose_eval,\n",
    "        )\n",
    "\n",
    "        eval_str = booster.eval(dval_dict[f\"fold_{fold_idx}\"], name='val', iteration=booster.best_iteration)\n",
    "\n",
    "        best_mlogloss = float(eval_str[eval_str.find('val-mlogloss:')+len('val-mlogloss:'):])\n",
    "        score_arrs['max_depth_and_min_child_weight'].append(best_mlogloss)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Best val. mlogloss on fold{fold_idx} = {best_mlogloss}\")\n",
    "\n",
    "        return -best_mlogloss\n",
    "    \n",
    "    print(\"Optimizing max_depth (max depth of tree) and min_child_weight (min sum of weights in final nodes)\")\n",
    "    result_max_depth_and_min_child_weight = gp_minimize(max_depth_and_min_child_weight_objective, max_depth_and_min_child_weight_space)\n",
    "    param['max_depth'] = int(result_max_depth_and_min_child_weight.x[0])\n",
    "    param['min_child_weight'] = int(result_max_depth_and_min_child_weight.x[1])\n",
    "\n",
    "## min_split_loss ##\n",
    "    min_split_loss_space  = [\n",
    "        Real(0.0, 0.5, \"uniform\", name='min_split_loss'),\n",
    "    ]\n",
    "    @use_named_args(min_split_loss_space)\n",
    "    def min_split_loss_objective(**X):\n",
    "        if verbose:\n",
    "            print(\"New configuration: {}\".format(X))\n",
    "\n",
    "        for key, val in X.items():\n",
    "            param[key] = val\n",
    "\n",
    "        # randomly sample a fold to evaluate\n",
    "        fold_idx = rng.integers(0, 4)\n",
    "\n",
    "        evallist = [(dtrain_dict[f\"fold_{fold_idx}\"], 'train'), (dval_dict[f\"fold_{fold_idx}\"], 'val')]\n",
    "        booster = xgb.train(\n",
    "            param, dtrain_dict[f\"fold_{fold_idx}\"], num_boost_round=num_trees, \n",
    "            evals=evallist, early_stopping_rounds=10, verbose_eval=verbose_eval,\n",
    "        )\n",
    "\n",
    "        eval_str = booster.eval(dval_dict[f\"fold_{fold_idx}\"], name='val', iteration=booster.best_iteration)\n",
    "\n",
    "        best_mlogloss = float(eval_str[eval_str.find('val-mlogloss:')+len('val-mlogloss:'):])\n",
    "        score_arrs['min_split_loss'].append(best_mlogloss)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Best val. mlogloss on fold{fold_idx} = {best_mlogloss}\")\n",
    "\n",
    "        return -best_mlogloss\n",
    "\n",
    "    print(\"Optimizing min_split_loss (min loss change to add leaf)\")\n",
    "    result_min_split_loss = gp_minimize(min_split_loss_objective, min_split_loss_space)\n",
    "    param['min_split_loss'] = float(result_min_split_loss.x[0])\n",
    "\n",
    "## subsample and colsample_by_tree ##\n",
    "    subsample_and_colsample_bytree_space  = [\n",
    "        Real(0.1, 0.5, \"log-uniform\", name='subsample'),\n",
    "        Real(0.3, 0.9, \"uniform\", name='colsample_bytree'),\n",
    "    ]\n",
    "    @use_named_args(subsample_and_colsample_bytree_space)\n",
    "    def subsample_and_colsample_bytree_objective(**X):\n",
    "        if verbose:\n",
    "            print(\"New configuration: {}\".format(X))\n",
    "\n",
    "        for key, val in X.items():\n",
    "            param[key] = val\n",
    "\n",
    "        # randomly sample a fold to evaluate\n",
    "        fold_idx = rng.integers(0, 4)\n",
    "\n",
    "        evallist = [(dtrain_dict[f\"fold_{fold_idx}\"], 'train'), (dval_dict[f\"fold_{fold_idx}\"], 'val')]\n",
    "        booster = xgb.train(\n",
    "            param, dtrain_dict[f\"fold_{fold_idx}\"], num_boost_round=num_trees, \n",
    "            evals=evallist, early_stopping_rounds=10, verbose_eval=verbose_eval,\n",
    "        )\n",
    "\n",
    "        eval_str = booster.eval(dval_dict[f\"fold_{fold_idx}\"], name='val', iteration=booster.best_iteration)\n",
    "\n",
    "        best_mlogloss = float(eval_str[eval_str.find('val-mlogloss:')+len('val-mlogloss:'):])\n",
    "        score_arrs['subsample_and_colsample_bytree'].append(best_mlogloss)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Best val. mlogloss on fold{fold_idx} = {best_mlogloss}\")\n",
    "\n",
    "        return -best_mlogloss\n",
    "\n",
    "    print(\"Optimizing subsample (fraction of training events) and colsample_bytree (fraction of training features per tree)\")\n",
    "    result_subsample_and_colsample_bytree = gp_minimize(subsample_and_colsample_bytree_objective, subsample_and_colsample_bytree_space)\n",
    "    param['subsample'] = float(result_subsample_and_colsample_bytree.x[0])\n",
    "    param['colsample_bytree'] = float(result_subsample_and_colsample_bytree.x[1])\n",
    "\n",
    "## reg_lambda ##\n",
    "    reg_lambda_space  = [\n",
    "        Real(0.001, 0.1, \"log-uniform\", name='reg_lambda'),\n",
    "    ]\n",
    "    @use_named_args(reg_lambda_space)\n",
    "    def reg_lambda_objective(**X):\n",
    "        if verbose:\n",
    "            print(\"New configuration: {}\".format(X))\n",
    "\n",
    "        for key, val in X.items():\n",
    "            param[key] = val\n",
    "\n",
    "        # randomly sample a fold to evaluate\n",
    "        fold_idx = rng.integers(0, 4)\n",
    "\n",
    "        evallist = [(dtrain_dict[f\"fold_{fold_idx}\"], 'train'), (dval_dict[f\"fold_{fold_idx}\"], 'val')]\n",
    "        booster = xgb.train(\n",
    "            param, dtrain_dict[f\"fold_{fold_idx}\"], num_boost_round=num_trees, \n",
    "            evals=evallist, early_stopping_rounds=10, verbose_eval=verbose_eval,\n",
    "        )\n",
    "\n",
    "        eval_str = booster.eval(dval_dict[f\"fold_{fold_idx}\"], name='val', iteration=booster.best_iteration)\n",
    "\n",
    "        best_mlogloss = float(eval_str[eval_str.find('val-mlogloss:')+len('val-mlogloss:'):])\n",
    "        score_arrs['reg_lambda'].append(best_mlogloss)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Best val. mlogloss on fold{fold_idx} = {best_mlogloss}\")\n",
    "\n",
    "        return -best_mlogloss\n",
    "\n",
    "    print(\"Optimizing reg_lambda (L2 reg)\")\n",
    "    result_reg_lambda = gp_minimize(reg_lambda_objective, reg_lambda_space)\n",
    "    param['reg_lambda'] = float(result_reg_lambda.x[0])\n",
    "\n",
    "## eta ##\n",
    "    eta_space  = [\n",
    "        Real(0.01, 0.3, \"log-uniform\", name='eta'),\n",
    "    ]\n",
    "    @use_named_args(eta_space)\n",
    "    def eta_objective(**X):\n",
    "        if verbose:\n",
    "            print(\"New configuration: {}\".format(X))\n",
    "\n",
    "        for key, val in X.items():\n",
    "            param[key] = val\n",
    "        num_trees = round(25 / X['eta'])  # number of trees to make\n",
    "\n",
    "        # randomly sample a fold to evaluate\n",
    "        fold_idx = rng.integers(0, 4)\n",
    "\n",
    "        evallist = [(dtrain_dict[f\"fold_{fold_idx}\"], 'train'), (dval_dict[f\"fold_{fold_idx}\"], 'val')]\n",
    "        booster = xgb.train(\n",
    "            param, dtrain_dict[f\"fold_{fold_idx}\"], num_boost_round=num_trees, \n",
    "            evals=evallist, early_stopping_rounds=10, verbose_eval=verbose_eval,\n",
    "        )\n",
    "\n",
    "        eval_str = booster.eval(dval_dict[f\"fold_{fold_idx}\"], name='val', iteration=booster.best_iteration)\n",
    "\n",
    "        best_mlogloss = float(eval_str[eval_str.find('val-mlogloss:')+len('val-mlogloss:'):])\n",
    "        score_arrs['eta'].append(best_mlogloss)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Best val. mlogloss on fold{fold_idx} = {best_mlogloss}\")\n",
    "\n",
    "        return -best_mlogloss\n",
    "\n",
    "    print(\"Optimizing eta (step size)\")\n",
    "    result_eta = gp_minimize(eta_objective, eta_space)\n",
    "    param['eta'] = float(result_eta.x[0])\n",
    "\n",
    "    print(\"Best parameters: {}\".format(param))\n",
    "    \n",
    "    return param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPTIMIZING SPACE\n",
      "Baseline parameters: {'eta': 0.1, 'subsample': 0.5, 'colsample_bytree': 0.8, 'num_class': 4, 'tree_method': 'hist', 'max_bin': 500, 'grow_policy': 'lossguide', 'objective': 'multi:softprob', 'eval_metric': 'mlogloss'}\n",
      "Optimizing max_depth (max depth of tree) and min_child_weight (min sum of weights in final nodes)\n",
      "New configuration: {'max_depth': 3, 'min_child_weight': 0.10392774380802759}\n",
      "[0]\ttrain-mlogloss:1.23590\tval-mlogloss:1.23631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttrain-mlogloss:0.27169\tval-mlogloss:0.27747\n",
      "[100]\ttrain-mlogloss:0.24844\tval-mlogloss:0.25516\n",
      "[150]\ttrain-mlogloss:0.24017\tval-mlogloss:0.24806\n",
      "[200]\ttrain-mlogloss:0.23502\tval-mlogloss:0.24406\n",
      "[249]\ttrain-mlogloss:0.23142\tval-mlogloss:0.24182\n",
      "Best val. mlogloss on fold0 = 0.241815\n",
      "New configuration: {'max_depth': 9, 'min_child_weight': 2.743389990814161}\n",
      "[0]\ttrain-mlogloss:1.22630\tval-mlogloss:1.22815\n",
      "[50]\ttrain-mlogloss:0.20434\tval-mlogloss:0.24581\n",
      "[100]\ttrain-mlogloss:0.17234\tval-mlogloss:0.23514\n",
      "[133]\ttrain-mlogloss:0.15984\tval-mlogloss:0.23479\n",
      "Best val. mlogloss on fold0 = 0.234792\n",
      "New configuration: {'max_depth': 7, 'min_child_weight': 2.8507315500235517}\n",
      "[0]\ttrain-mlogloss:1.22842\tval-mlogloss:1.22942\n",
      "[50]\ttrain-mlogloss:0.22998\tval-mlogloss:0.25027\n",
      "[100]\ttrain-mlogloss:0.20295\tval-mlogloss:0.23539\n",
      "[150]\ttrain-mlogloss:0.18967\tval-mlogloss:0.23238\n",
      "[200]\ttrain-mlogloss:0.17851\tval-mlogloss:0.23100\n",
      "[201]\ttrain-mlogloss:0.17829\tval-mlogloss:0.23098\n",
      "Best val. mlogloss on fold0 = 0.23098\n",
      "New configuration: {'max_depth': 4, 'min_child_weight': 0.6179915272560528}\n",
      "[0]\ttrain-mlogloss:1.23301\tval-mlogloss:1.23353\n",
      "[50]\ttrain-mlogloss:0.26030\tval-mlogloss:0.26750\n",
      "[100]\ttrain-mlogloss:0.23799\tval-mlogloss:0.24766\n",
      "[150]\ttrain-mlogloss:0.22938\tval-mlogloss:0.24172\n",
      "[200]\ttrain-mlogloss:0.22345\tval-mlogloss:0.23854\n",
      "[249]\ttrain-mlogloss:0.21905\tval-mlogloss:0.23669\n",
      "Best val. mlogloss on fold0 = 0.236692\n",
      "New configuration: {'max_depth': 10, 'min_child_weight': 1.5584510896833674}\n",
      "[0]\ttrain-mlogloss:1.22527\tval-mlogloss:1.22785\n",
      "[50]\ttrain-mlogloss:0.18969\tval-mlogloss:0.24418\n",
      "[100]\ttrain-mlogloss:0.15426\tval-mlogloss:0.23574\n",
      "[103]\ttrain-mlogloss:0.15313\tval-mlogloss:0.23583\n",
      "Best val. mlogloss on fold3 = 0.235714\n",
      "New configuration: {'max_depth': 7, 'min_child_weight': 3.1364101799550035}\n",
      "[0]\ttrain-mlogloss:1.22842\tval-mlogloss:1.22942\n",
      "[50]\ttrain-mlogloss:0.22994\tval-mlogloss:0.25025\n",
      "[100]\ttrain-mlogloss:0.20340\tval-mlogloss:0.23568\n",
      "[150]\ttrain-mlogloss:0.19000\tval-mlogloss:0.23255\n",
      "[200]\ttrain-mlogloss:0.17902\tval-mlogloss:0.23088\n",
      "[212]\ttrain-mlogloss:0.17679\tval-mlogloss:0.23086\n",
      "Best val. mlogloss on fold0 = 0.230858\n",
      "New configuration: {'max_depth': 9, 'min_child_weight': 1.5061621851670954}\n",
      "[0]\ttrain-mlogloss:1.22629\tval-mlogloss:1.22815\n",
      "[50]\ttrain-mlogloss:0.20414\tval-mlogloss:0.24556\n",
      "[100]\ttrain-mlogloss:0.17139\tval-mlogloss:0.23453\n",
      "[130]\ttrain-mlogloss:0.15953\tval-mlogloss:0.23436\n",
      "Best val. mlogloss on fold0 = 0.234359\n",
      "New configuration: {'max_depth': 3, 'min_child_weight': 0.23714692952744135}\n",
      "[0]\ttrain-mlogloss:1.23617\tval-mlogloss:1.23540\n",
      "[50]\ttrain-mlogloss:0.27275\tval-mlogloss:0.26762\n",
      "[100]\ttrain-mlogloss:0.24933\tval-mlogloss:0.24558\n",
      "[150]\ttrain-mlogloss:0.24134\tval-mlogloss:0.23895\n",
      "[200]\ttrain-mlogloss:0.23625\tval-mlogloss:0.23518\n",
      "[249]\ttrain-mlogloss:0.23253\tval-mlogloss:0.23262\n",
      "Best val. mlogloss on fold2 = 0.232625\n",
      "New configuration: {'max_depth': 9, 'min_child_weight': 5.0399538713574925}\n",
      "[0]\ttrain-mlogloss:1.22633\tval-mlogloss:1.22814\n",
      "[50]\ttrain-mlogloss:0.20491\tval-mlogloss:0.24563\n",
      "[100]\ttrain-mlogloss:0.17313\tval-mlogloss:0.23471\n",
      "[122]\ttrain-mlogloss:0.16413\tval-mlogloss:0.23435\n",
      "Best val. mlogloss on fold0 = 0.234349\n",
      "New configuration: {'max_depth': 4, 'min_child_weight': 0.16526244721157202}\n",
      "[0]\ttrain-mlogloss:1.23324\tval-mlogloss:1.23256\n",
      "[50]\ttrain-mlogloss:0.26104\tval-mlogloss:0.25782\n",
      "[100]\ttrain-mlogloss:0.23866\tval-mlogloss:0.23811\n",
      "[150]\ttrain-mlogloss:0.22998\tval-mlogloss:0.23212\n",
      "[200]\ttrain-mlogloss:0.22428\tval-mlogloss:0.22902\n",
      "[249]\ttrain-mlogloss:0.21986\tval-mlogloss:0.22695\n",
      "Best val. mlogloss on fold2 = 0.226953\n",
      "New configuration: {'max_depth': 4, 'min_child_weight': 1.8241199977371412}\n",
      "[0]\ttrain-mlogloss:1.23324\tval-mlogloss:1.23256\n",
      "[50]\ttrain-mlogloss:0.26105\tval-mlogloss:0.25782\n",
      "[100]\ttrain-mlogloss:0.23859\tval-mlogloss:0.23805\n",
      "[150]\ttrain-mlogloss:0.22994\tval-mlogloss:0.23205\n",
      "[200]\ttrain-mlogloss:0.22443\tval-mlogloss:0.22913\n",
      "[249]\ttrain-mlogloss:0.21996\tval-mlogloss:0.22698\n",
      "Best val. mlogloss on fold2 = 0.22698\n",
      "New configuration: {'max_depth': 10, 'min_child_weight': 4.50347056488115}\n",
      "[0]\ttrain-mlogloss:1.22533\tval-mlogloss:1.22783\n",
      "[50]\ttrain-mlogloss:0.19090\tval-mlogloss:0.24549\n",
      "[100]\ttrain-mlogloss:0.15638\tval-mlogloss:0.23682\n",
      "[111]\ttrain-mlogloss:0.15112\tval-mlogloss:0.23723\n",
      "Best val. mlogloss on fold0 = 0.237281\n",
      "New configuration: {'max_depth': 3, 'min_child_weight': 0.12758119895612172}\n",
      "[0]\ttrain-mlogloss:1.23573\tval-mlogloss:1.23597\n",
      "[50]\ttrain-mlogloss:0.27120\tval-mlogloss:0.27445\n",
      "[100]\ttrain-mlogloss:0.24808\tval-mlogloss:0.25261\n",
      "[150]\ttrain-mlogloss:0.23993\tval-mlogloss:0.24574\n",
      "[200]\ttrain-mlogloss:0.23489\tval-mlogloss:0.24200\n",
      "[249]\ttrain-mlogloss:0.23111\tval-mlogloss:0.23944\n",
      "Best val. mlogloss on fold3 = 0.239435\n",
      "New configuration: {'max_depth': 10, 'min_child_weight': 0.30725435597479533}\n",
      "[0]\ttrain-mlogloss:1.22527\tval-mlogloss:1.22781\n",
      "[50]\ttrain-mlogloss:0.18853\tval-mlogloss:0.24594\n",
      "[95]\ttrain-mlogloss:0.15499\tval-mlogloss:0.23778\n",
      "Best val. mlogloss on fold0 = 0.237748\n",
      "New configuration: {'max_depth': 10, 'min_child_weight': 0.10064550458000783}\n",
      "[0]\ttrain-mlogloss:1.22538\tval-mlogloss:1.22720\n",
      "[50]\ttrain-mlogloss:0.18792\tval-mlogloss:0.24156\n",
      "[99]\ttrain-mlogloss:0.15224\tval-mlogloss:0.23387\n",
      "Best val. mlogloss on fold1 = 0.233875\n",
      "New configuration: {'max_depth': 6, 'min_child_weight': 0.10018280657226758}\n",
      "[0]\ttrain-mlogloss:1.22952\tval-mlogloss:1.23029\n",
      "[50]\ttrain-mlogloss:0.24039\tval-mlogloss:0.25388\n",
      "[100]\ttrain-mlogloss:0.21601\tval-mlogloss:0.23786\n",
      "[150]\ttrain-mlogloss:0.20451\tval-mlogloss:0.23376\n",
      "[200]\ttrain-mlogloss:0.19557\tval-mlogloss:0.23181\n",
      "[249]\ttrain-mlogloss:0.18840\tval-mlogloss:0.23074\n",
      "Best val. mlogloss on fold0 = 0.230739\n",
      "New configuration: {'max_depth': 8, 'min_child_weight': 0.10235086594132811}\n",
      "[0]\ttrain-mlogloss:1.22734\tval-mlogloss:1.22870\n",
      "[50]\ttrain-mlogloss:0.21718\tval-mlogloss:0.24724\n",
      "[100]\ttrain-mlogloss:0.18728\tval-mlogloss:0.23409\n",
      "[150]\ttrain-mlogloss:0.17089\tval-mlogloss:0.23241\n",
      "[176]\ttrain-mlogloss:0.16366\tval-mlogloss:0.23238\n",
      "Best val. mlogloss on fold0 = 0.232376\n",
      "New configuration: {'max_depth': 9, 'min_child_weight': 0.15284471632272287}\n",
      "[0]\ttrain-mlogloss:1.22624\tval-mlogloss:1.22803\n",
      "[50]\ttrain-mlogloss:0.20342\tval-mlogloss:0.24409\n",
      "[100]\ttrain-mlogloss:0.17090\tval-mlogloss:0.23325\n",
      "[136]\ttrain-mlogloss:0.15657\tval-mlogloss:0.23271\n",
      "Best val. mlogloss on fold3 = 0.232707\n",
      "New configuration: {'max_depth': 10, 'min_child_weight': 9.969244929182308}\n",
      "[0]\ttrain-mlogloss:1.22535\tval-mlogloss:1.22782\n",
      "[50]\ttrain-mlogloss:0.19337\tval-mlogloss:0.24382\n",
      "[100]\ttrain-mlogloss:0.15993\tval-mlogloss:0.23414\n",
      "[126]\ttrain-mlogloss:0.14960\tval-mlogloss:0.23416\n",
      "Best val. mlogloss on fold3 = 0.234156\n",
      "New configuration: {'max_depth': 3, 'min_child_weight': 0.1}\n",
      "[0]\ttrain-mlogloss:1.23617\tval-mlogloss:1.23540\n",
      "[50]\ttrain-mlogloss:0.27275\tval-mlogloss:0.26762\n",
      "[100]\ttrain-mlogloss:0.24933\tval-mlogloss:0.24559\n",
      "[150]\ttrain-mlogloss:0.24133\tval-mlogloss:0.23896\n",
      "[200]\ttrain-mlogloss:0.23620\tval-mlogloss:0.23506\n",
      "[249]\ttrain-mlogloss:0.23253\tval-mlogloss:0.23268\n",
      "Best val. mlogloss on fold2 = 0.232677\n",
      "New configuration: {'max_depth': 5, 'min_child_weight': 4.432312812069766}\n",
      "[0]\ttrain-mlogloss:1.23119\tval-mlogloss:1.23061\n",
      "[50]\ttrain-mlogloss:0.25117\tval-mlogloss:0.25027\n",
      "[100]\ttrain-mlogloss:0.22848\tval-mlogloss:0.23262\n",
      "[150]\ttrain-mlogloss:0.21873\tval-mlogloss:0.22757\n",
      "[200]\ttrain-mlogloss:0.21198\tval-mlogloss:0.22514\n",
      "[249]\ttrain-mlogloss:0.20607\tval-mlogloss:0.22345\n",
      "Best val. mlogloss on fold2 = 0.223446\n",
      "New configuration: {'max_depth': 8, 'min_child_weight': 9.994862482651788}\n",
      "[0]\ttrain-mlogloss:1.22723\tval-mlogloss:1.22844\n",
      "[50]\ttrain-mlogloss:0.21887\tval-mlogloss:0.24538\n",
      "[100]\ttrain-mlogloss:0.19067\tval-mlogloss:0.23225\n",
      "[150]\ttrain-mlogloss:0.17466\tval-mlogloss:0.23006\n",
      "[157]\ttrain-mlogloss:0.17281\tval-mlogloss:0.23015\n",
      "Best val. mlogloss on fold3 = 0.230131\n",
      "New configuration: {'max_depth': 6, 'min_child_weight': 9.98206359040905}\n",
      "[0]\ttrain-mlogloss:1.22975\tval-mlogloss:1.22938\n",
      "[50]\ttrain-mlogloss:0.24155\tval-mlogloss:0.24528\n",
      "[100]\ttrain-mlogloss:0.21757\tval-mlogloss:0.22911\n",
      "[150]\ttrain-mlogloss:0.20627\tval-mlogloss:0.22497\n",
      "[200]\ttrain-mlogloss:0.19790\tval-mlogloss:0.22300\n",
      "[249]\ttrain-mlogloss:0.19033\tval-mlogloss:0.22166\n",
      "Best val. mlogloss on fold2 = 0.22166\n",
      "New configuration: {'max_depth': 3, 'min_child_weight': 10.0}\n",
      "[0]\ttrain-mlogloss:1.23573\tval-mlogloss:1.23597\n",
      "[50]\ttrain-mlogloss:0.27112\tval-mlogloss:0.27433\n",
      "[100]\ttrain-mlogloss:0.24809\tval-mlogloss:0.25262\n",
      "[150]\ttrain-mlogloss:0.24011\tval-mlogloss:0.24583\n",
      "[200]\ttrain-mlogloss:0.23512\tval-mlogloss:0.24219\n",
      "[249]\ttrain-mlogloss:0.23142\tval-mlogloss:0.23960\n",
      "Best val. mlogloss on fold3 = 0.239601\n",
      "New configuration: {'max_depth': 3, 'min_child_weight': 9.970531066962453}\n",
      "[0]\ttrain-mlogloss:1.23590\tval-mlogloss:1.23631\n",
      "[50]\ttrain-mlogloss:0.27174\tval-mlogloss:0.27749\n",
      "[100]\ttrain-mlogloss:0.24867\tval-mlogloss:0.25538\n",
      "[150]\ttrain-mlogloss:0.24039\tval-mlogloss:0.24827\n",
      "[200]\ttrain-mlogloss:0.23534\tval-mlogloss:0.24442\n",
      "[249]\ttrain-mlogloss:0.23180\tval-mlogloss:0.24222\n",
      "Best val. mlogloss on fold0 = 0.242216\n",
      "New configuration: {'max_depth': 3, 'min_child_weight': 9.989664200577975}\n",
      "[0]\ttrain-mlogloss:1.23573\tval-mlogloss:1.23597\n",
      "[50]\ttrain-mlogloss:0.27112\tval-mlogloss:0.27433\n",
      "[100]\ttrain-mlogloss:0.24809\tval-mlogloss:0.25262\n",
      "[150]\ttrain-mlogloss:0.24011\tval-mlogloss:0.24583\n",
      "[200]\ttrain-mlogloss:0.23512\tval-mlogloss:0.24219\n",
      "[249]\ttrain-mlogloss:0.23142\tval-mlogloss:0.23960\n",
      "Best val. mlogloss on fold3 = 0.239602\n",
      "New configuration: {'max_depth': 3, 'min_child_weight': 9.982609845150678}\n",
      "[0]\ttrain-mlogloss:1.23573\tval-mlogloss:1.23597\n",
      "[50]\ttrain-mlogloss:0.27112\tval-mlogloss:0.27433\n",
      "[100]\ttrain-mlogloss:0.24809\tval-mlogloss:0.25262\n",
      "[150]\ttrain-mlogloss:0.24011\tval-mlogloss:0.24583\n",
      "[200]\ttrain-mlogloss:0.23512\tval-mlogloss:0.24219\n",
      "[249]\ttrain-mlogloss:0.23142\tval-mlogloss:0.23960\n",
      "Best val. mlogloss on fold3 = 0.239602\n",
      "New configuration: {'max_depth': 7, 'min_child_weight': 0.10011221545125588}\n",
      "[0]\ttrain-mlogloss:1.22841\tval-mlogloss:1.22942\n",
      "[50]\ttrain-mlogloss:0.22973\tval-mlogloss:0.25030\n",
      "[100]\ttrain-mlogloss:0.20244\tval-mlogloss:0.23565\n",
      "[150]\ttrain-mlogloss:0.18872\tval-mlogloss:0.23257\n",
      "[200]\ttrain-mlogloss:0.17726\tval-mlogloss:0.23109\n",
      "[226]\ttrain-mlogloss:0.17241\tval-mlogloss:0.23091\n",
      "Best val. mlogloss on fold0 = 0.230903\n",
      "New configuration: {'max_depth': 10, 'min_child_weight': 0.10042183098602299}\n",
      "[0]\ttrain-mlogloss:1.22524\tval-mlogloss:1.22784\n",
      "[50]\ttrain-mlogloss:0.18918\tval-mlogloss:0.24416\n",
      "[100]\ttrain-mlogloss:0.15214\tval-mlogloss:0.23589\n",
      "[117]\ttrain-mlogloss:0.14392\tval-mlogloss:0.23592\n",
      "Best val. mlogloss on fold3 = 0.236049\n",
      "New configuration: {'max_depth': 3, 'min_child_weight': 9.978861696678322}\n",
      "[0]\ttrain-mlogloss:1.23590\tval-mlogloss:1.23631\n",
      "[50]\ttrain-mlogloss:0.27174\tval-mlogloss:0.27749\n",
      "[100]\ttrain-mlogloss:0.24867\tval-mlogloss:0.25538\n",
      "[150]\ttrain-mlogloss:0.24039\tval-mlogloss:0.24827\n",
      "[200]\ttrain-mlogloss:0.23534\tval-mlogloss:0.24442\n",
      "[249]\ttrain-mlogloss:0.23180\tval-mlogloss:0.24222\n",
      "Best val. mlogloss on fold0 = 0.242216\n",
      "New configuration: {'max_depth': 8, 'min_child_weight': 0.10099018601533728}\n",
      "[0]\ttrain-mlogloss:1.22754\tval-mlogloss:1.22781\n",
      "[50]\ttrain-mlogloss:0.21794\tval-mlogloss:0.23875\n",
      "[100]\ttrain-mlogloss:0.18826\tval-mlogloss:0.22575\n",
      "[150]\ttrain-mlogloss:0.17157\tval-mlogloss:0.22336\n",
      "[176]\ttrain-mlogloss:0.16436\tval-mlogloss:0.22330\n",
      "Best val. mlogloss on fold2 = 0.223323\n",
      "New configuration: {'max_depth': 5, 'min_child_weight': 0.10025704238809463}\n",
      "[0]\ttrain-mlogloss:1.23118\tval-mlogloss:1.23061\n",
      "[50]\ttrain-mlogloss:0.25120\tval-mlogloss:0.25028\n",
      "[100]\ttrain-mlogloss:0.22826\tval-mlogloss:0.23264\n",
      "[150]\ttrain-mlogloss:0.21845\tval-mlogloss:0.22766\n",
      "[200]\ttrain-mlogloss:0.21160\tval-mlogloss:0.22517\n",
      "[249]\ttrain-mlogloss:0.20553\tval-mlogloss:0.22347\n",
      "Best val. mlogloss on fold2 = 0.223473\n",
      "New configuration: {'max_depth': 10, 'min_child_weight': 9.7485674819218}\n",
      "[0]\ttrain-mlogloss:1.22543\tval-mlogloss:1.22793\n",
      "[50]\ttrain-mlogloss:0.19294\tval-mlogloss:0.24584\n",
      "[100]\ttrain-mlogloss:0.15951\tval-mlogloss:0.23661\n",
      "[111]\ttrain-mlogloss:0.15462\tval-mlogloss:0.23686\n",
      "Best val. mlogloss on fold0 = 0.236866\n",
      "New configuration: {'max_depth': 3, 'min_child_weight': 9.983067475719466}\n",
      "[0]\ttrain-mlogloss:1.23590\tval-mlogloss:1.23631\n",
      "[50]\ttrain-mlogloss:0.27174\tval-mlogloss:0.27749\n",
      "[100]\ttrain-mlogloss:0.24867\tval-mlogloss:0.25538\n",
      "[150]\ttrain-mlogloss:0.24039\tval-mlogloss:0.24827\n",
      "[200]\ttrain-mlogloss:0.23534\tval-mlogloss:0.24442\n",
      "[249]\ttrain-mlogloss:0.23180\tval-mlogloss:0.24222\n",
      "Best val. mlogloss on fold0 = 0.242216\n",
      "New configuration: {'max_depth': 4, 'min_child_weight': 9.998363295908197}\n",
      "[0]\ttrain-mlogloss:1.23297\tval-mlogloss:1.23275\n",
      "[50]\ttrain-mlogloss:0.26047\tval-mlogloss:0.26074\n",
      "[100]\ttrain-mlogloss:0.23814\tval-mlogloss:0.24170\n",
      "[150]\ttrain-mlogloss:0.22960\tval-mlogloss:0.23604\n",
      "[200]\ttrain-mlogloss:0.22389\tval-mlogloss:0.23309\n",
      "[249]\ttrain-mlogloss:0.21944\tval-mlogloss:0.23119\n",
      "Best val. mlogloss on fold1 = 0.23119\n",
      "New configuration: {'max_depth': 3, 'min_child_weight': 0.10090971782607919}\n",
      "[0]\ttrain-mlogloss:1.23596\tval-mlogloss:1.23553\n",
      "[50]\ttrain-mlogloss:0.27200\tval-mlogloss:0.27069\n",
      "[100]\ttrain-mlogloss:0.24862\tval-mlogloss:0.24912\n",
      "[150]\ttrain-mlogloss:0.24024\tval-mlogloss:0.24231\n",
      "[200]\ttrain-mlogloss:0.23504\tval-mlogloss:0.23875\n",
      "[249]\ttrain-mlogloss:0.23131\tval-mlogloss:0.23643\n",
      "Best val. mlogloss on fold1 = 0.236428\n",
      "New configuration: {'max_depth': 9, 'min_child_weight': 0.10027959682906949}\n",
      "[0]\ttrain-mlogloss:1.22628\tval-mlogloss:1.22814\n",
      "[50]\ttrain-mlogloss:0.20361\tval-mlogloss:0.24581\n",
      "[100]\ttrain-mlogloss:0.17050\tval-mlogloss:0.23521\n",
      "[121]\ttrain-mlogloss:0.16161\tval-mlogloss:0.23477\n",
      "Best val. mlogloss on fold0 = 0.23476\n",
      "New configuration: {'max_depth': 3, 'min_child_weight': 9.99735194943614}\n",
      "[0]\ttrain-mlogloss:1.23617\tval-mlogloss:1.23540\n",
      "[50]\ttrain-mlogloss:0.27277\tval-mlogloss:0.26765\n",
      "[100]\ttrain-mlogloss:0.24928\tval-mlogloss:0.24534\n",
      "[150]\ttrain-mlogloss:0.24126\tval-mlogloss:0.23862\n",
      "[200]\ttrain-mlogloss:0.23620\tval-mlogloss:0.23473\n",
      "[249]\ttrain-mlogloss:0.23259\tval-mlogloss:0.23234\n",
      "Best val. mlogloss on fold2 = 0.232339\n",
      "New configuration: {'max_depth': 10, 'min_child_weight': 0.10086820119249097}\n",
      "[0]\ttrain-mlogloss:1.22524\tval-mlogloss:1.22784\n",
      "[50]\ttrain-mlogloss:0.18905\tval-mlogloss:0.24392\n",
      "[100]\ttrain-mlogloss:0.15241\tval-mlogloss:0.23561\n",
      "[107]\ttrain-mlogloss:0.14924\tval-mlogloss:0.23573\n",
      "Best val. mlogloss on fold3 = 0.235731\n",
      "New configuration: {'max_depth': 9, 'min_child_weight': 9.907273902465283}\n",
      "[0]\ttrain-mlogloss:1.22647\tval-mlogloss:1.22752\n",
      "[50]\ttrain-mlogloss:0.20554\tval-mlogloss:0.24188\n",
      "[100]\ttrain-mlogloss:0.17495\tval-mlogloss:0.23110\n",
      "[146]\ttrain-mlogloss:0.15902\tval-mlogloss:0.23020\n",
      "Best val. mlogloss on fold1 = 0.230219\n",
      "New configuration: {'max_depth': 7, 'min_child_weight': 9.992246336543316}\n",
      "[0]\ttrain-mlogloss:1.22845\tval-mlogloss:1.22856\n",
      "[50]\ttrain-mlogloss:0.23005\tval-mlogloss:0.24521\n",
      "[100]\ttrain-mlogloss:0.20423\tval-mlogloss:0.23140\n",
      "[150]\ttrain-mlogloss:0.19105\tval-mlogloss:0.22873\n",
      "[200]\ttrain-mlogloss:0.18020\tval-mlogloss:0.22782\n",
      "[249]\ttrain-mlogloss:0.17141\tval-mlogloss:0.22726\n",
      "Best val. mlogloss on fold1 = 0.227264\n",
      "New configuration: {'max_depth': 10, 'min_child_weight': 9.925185468650662}\n",
      "[0]\ttrain-mlogloss:1.22543\tval-mlogloss:1.22792\n",
      "[50]\ttrain-mlogloss:0.19292\tval-mlogloss:0.24586\n",
      "[100]\ttrain-mlogloss:0.15975\tval-mlogloss:0.23689\n",
      "[111]\ttrain-mlogloss:0.15505\tval-mlogloss:0.23692\n",
      "Best val. mlogloss on fold0 = 0.236977\n",
      "New configuration: {'max_depth': 6, 'min_child_weight': 0.10001430456631298}\n",
      "[0]\ttrain-mlogloss:1.22937\tval-mlogloss:1.22984\n",
      "[50]\ttrain-mlogloss:0.24034\tval-mlogloss:0.25175\n",
      "[100]\ttrain-mlogloss:0.21599\tval-mlogloss:0.23584\n",
      "[150]\ttrain-mlogloss:0.20425\tval-mlogloss:0.23174\n",
      "[200]\ttrain-mlogloss:0.19526\tval-mlogloss:0.22968\n",
      "[249]\ttrain-mlogloss:0.18776\tval-mlogloss:0.22843\n",
      "Best val. mlogloss on fold3 = 0.228434\n",
      "New configuration: {'max_depth': 3, 'min_child_weight': 0.10060800335997531}\n",
      "[0]\ttrain-mlogloss:1.23590\tval-mlogloss:1.23631\n",
      "[50]\ttrain-mlogloss:0.27169\tval-mlogloss:0.27747\n",
      "[100]\ttrain-mlogloss:0.24844\tval-mlogloss:0.25516\n",
      "[150]\ttrain-mlogloss:0.24017\tval-mlogloss:0.24806\n",
      "[200]\ttrain-mlogloss:0.23502\tval-mlogloss:0.24406\n",
      "[249]\ttrain-mlogloss:0.23142\tval-mlogloss:0.24182\n",
      "Best val. mlogloss on fold0 = 0.241815\n",
      "New configuration: {'max_depth': 3, 'min_child_weight': 9.908680943695222}\n",
      "[0]\ttrain-mlogloss:1.23617\tval-mlogloss:1.23540\n",
      "[50]\ttrain-mlogloss:0.27277\tval-mlogloss:0.26765\n",
      "[100]\ttrain-mlogloss:0.24931\tval-mlogloss:0.24547\n",
      "[150]\ttrain-mlogloss:0.24122\tval-mlogloss:0.23868\n",
      "[200]\ttrain-mlogloss:0.23621\tval-mlogloss:0.23489\n",
      "[249]\ttrain-mlogloss:0.23256\tval-mlogloss:0.23246\n",
      "Best val. mlogloss on fold2 = 0.232463\n",
      "New configuration: {'max_depth': 8, 'min_child_weight': 9.974892494269561}\n",
      "[0]\ttrain-mlogloss:1.22741\tval-mlogloss:1.22793\n",
      "[50]\ttrain-mlogloss:0.21850\tval-mlogloss:0.24286\n",
      "[100]\ttrain-mlogloss:0.19006\tval-mlogloss:0.23028\n",
      "[150]\ttrain-mlogloss:0.17485\tval-mlogloss:0.22873\n",
      "[174]\ttrain-mlogloss:0.16840\tval-mlogloss:0.22846\n",
      "Best val. mlogloss on fold1 = 0.228454\n",
      "New configuration: {'max_depth': 4, 'min_child_weight': 0.10159641783912145}\n",
      "[0]\ttrain-mlogloss:1.23276\tval-mlogloss:1.23311\n",
      "[50]\ttrain-mlogloss:0.25960\tval-mlogloss:0.26427\n",
      "[100]\ttrain-mlogloss:0.23764\tval-mlogloss:0.24514\n",
      "[150]\ttrain-mlogloss:0.22927\tval-mlogloss:0.23933\n",
      "[200]\ttrain-mlogloss:0.22325\tval-mlogloss:0.23610\n",
      "[249]\ttrain-mlogloss:0.21876\tval-mlogloss:0.23409\n",
      "Best val. mlogloss on fold3 = 0.234095\n",
      "New configuration: {'max_depth': 5, 'min_child_weight': 9.993461564342976}\n",
      "[0]\ttrain-mlogloss:1.23099\tval-mlogloss:1.23164\n",
      "[50]\ttrain-mlogloss:0.25056\tval-mlogloss:0.25964\n",
      "[100]\ttrain-mlogloss:0.22802\tval-mlogloss:0.24189\n",
      "[150]\ttrain-mlogloss:0.21863\tval-mlogloss:0.23722\n",
      "[200]\ttrain-mlogloss:0.21151\tval-mlogloss:0.23447\n",
      "[249]\ttrain-mlogloss:0.20618\tval-mlogloss:0.23316\n",
      "Best val. mlogloss on fold0 = 0.23316\n",
      "New configuration: {'max_depth': 3, 'min_child_weight': 9.99946682066669}\n",
      "[0]\ttrain-mlogloss:1.23596\tval-mlogloss:1.23553\n",
      "[50]\ttrain-mlogloss:0.27200\tval-mlogloss:0.27069\n",
      "[100]\ttrain-mlogloss:0.24862\tval-mlogloss:0.24913\n",
      "[150]\ttrain-mlogloss:0.24032\tval-mlogloss:0.24249\n",
      "[200]\ttrain-mlogloss:0.23511\tval-mlogloss:0.23883\n",
      "[249]\ttrain-mlogloss:0.23146\tval-mlogloss:0.23654\n",
      "Best val. mlogloss on fold1 = 0.236537\n",
      "New configuration: {'max_depth': 10, 'min_child_weight': 0.10237394321614618}\n",
      "[0]\ttrain-mlogloss:1.22545\tval-mlogloss:1.22696\n",
      "[50]\ttrain-mlogloss:0.18948\tval-mlogloss:0.23733\n",
      "[100]\ttrain-mlogloss:0.15274\tval-mlogloss:0.22902\n",
      "[108]\ttrain-mlogloss:0.14887\tval-mlogloss:0.22944\n",
      "Best val. mlogloss on fold2 = 0.229522\n",
      "New configuration: {'max_depth': 3, 'min_child_weight': 9.961556987981815}\n",
      "[0]\ttrain-mlogloss:1.23596\tval-mlogloss:1.23553\n",
      "[50]\ttrain-mlogloss:0.27200\tval-mlogloss:0.27069\n",
      "[100]\ttrain-mlogloss:0.24862\tval-mlogloss:0.24913\n",
      "[150]\ttrain-mlogloss:0.24032\tval-mlogloss:0.24249\n",
      "[200]\ttrain-mlogloss:0.23512\tval-mlogloss:0.23884\n",
      "[249]\ttrain-mlogloss:0.23143\tval-mlogloss:0.23645\n",
      "Best val. mlogloss on fold1 = 0.236449\n",
      "New configuration: {'max_depth': 3, 'min_child_weight': 0.10201076550992867}\n",
      "[0]\ttrain-mlogloss:1.23596\tval-mlogloss:1.23553\n",
      "[50]\ttrain-mlogloss:0.27200\tval-mlogloss:0.27069\n",
      "[100]\ttrain-mlogloss:0.24862\tval-mlogloss:0.24912\n",
      "[150]\ttrain-mlogloss:0.24024\tval-mlogloss:0.24231\n",
      "[200]\ttrain-mlogloss:0.23504\tval-mlogloss:0.23875\n",
      "[249]\ttrain-mlogloss:0.23131\tval-mlogloss:0.23643\n",
      "Best val. mlogloss on fold1 = 0.236428\n",
      "New configuration: {'max_depth': 9, 'min_child_weight': 0.10035471234216164}\n",
      "[0]\ttrain-mlogloss:1.22646\tval-mlogloss:1.22735\n",
      "[50]\ttrain-mlogloss:0.20436\tval-mlogloss:0.23752\n",
      "[100]\ttrain-mlogloss:0.17048\tval-mlogloss:0.22645\n",
      "[126]\ttrain-mlogloss:0.15999\tval-mlogloss:0.22629\n",
      "Best val. mlogloss on fold2 = 0.226289\n",
      "New configuration: {'max_depth': 3, 'min_child_weight': 9.99914711743018}\n",
      "[0]\ttrain-mlogloss:1.23617\tval-mlogloss:1.23540\n",
      "[50]\ttrain-mlogloss:0.27277\tval-mlogloss:0.26765\n",
      "[100]\ttrain-mlogloss:0.24928\tval-mlogloss:0.24534\n",
      "[150]\ttrain-mlogloss:0.24126\tval-mlogloss:0.23862\n",
      "[200]\ttrain-mlogloss:0.23620\tval-mlogloss:0.23473\n",
      "[249]\ttrain-mlogloss:0.23259\tval-mlogloss:0.23234\n",
      "Best val. mlogloss on fold2 = 0.232339\n",
      "New configuration: {'max_depth': 4, 'min_child_weight': 9.961546700183211}\n",
      "[0]\ttrain-mlogloss:1.23297\tval-mlogloss:1.23275\n",
      "[50]\ttrain-mlogloss:0.26047\tval-mlogloss:0.26074\n",
      "[100]\ttrain-mlogloss:0.23826\tval-mlogloss:0.24180\n",
      "[150]\ttrain-mlogloss:0.22962\tval-mlogloss:0.23618\n",
      "[200]\ttrain-mlogloss:0.22377\tval-mlogloss:0.23318\n",
      "[249]\ttrain-mlogloss:0.21944\tval-mlogloss:0.23133\n",
      "Best val. mlogloss on fold1 = 0.23133\n",
      "New configuration: {'max_depth': 3, 'min_child_weight': 0.10016288990342585}\n",
      "[0]\ttrain-mlogloss:1.23573\tval-mlogloss:1.23597\n",
      "[50]\ttrain-mlogloss:0.27120\tval-mlogloss:0.27445\n",
      "[100]\ttrain-mlogloss:0.24808\tval-mlogloss:0.25261\n",
      "[150]\ttrain-mlogloss:0.23993\tval-mlogloss:0.24574\n",
      "[200]\ttrain-mlogloss:0.23489\tval-mlogloss:0.24200\n",
      "[249]\ttrain-mlogloss:0.23111\tval-mlogloss:0.23943\n",
      "Best val. mlogloss on fold3 = 0.239432\n",
      "New configuration: {'max_depth': 10, 'min_child_weight': 9.98905656926718}\n",
      "[0]\ttrain-mlogloss:1.22544\tval-mlogloss:1.22792\n",
      "[50]\ttrain-mlogloss:0.19283\tval-mlogloss:0.24549\n",
      "[100]\ttrain-mlogloss:0.15963\tval-mlogloss:0.23661\n",
      "[112]\ttrain-mlogloss:0.15446\tval-mlogloss:0.23693\n",
      "Best val. mlogloss on fold0 = 0.236926\n",
      "New configuration: {'max_depth': 6, 'min_child_weight': 9.993014510816792}\n",
      "[0]\ttrain-mlogloss:1.22953\tval-mlogloss:1.23030\n",
      "[50]\ttrain-mlogloss:0.24081\tval-mlogloss:0.25412\n",
      "[100]\ttrain-mlogloss:0.21698\tval-mlogloss:0.23803\n",
      "[150]\ttrain-mlogloss:0.20582\tval-mlogloss:0.23410\n",
      "[200]\ttrain-mlogloss:0.19699\tval-mlogloss:0.23202\n",
      "[249]\ttrain-mlogloss:0.19016\tval-mlogloss:0.23128\n",
      "Best val. mlogloss on fold0 = 0.231281\n",
      "New configuration: {'max_depth': 7, 'min_child_weight': 0.10095063214406695}\n",
      "[0]\ttrain-mlogloss:1.22845\tval-mlogloss:1.22856\n",
      "[50]\ttrain-mlogloss:0.22937\tval-mlogloss:0.24525\n",
      "[100]\ttrain-mlogloss:0.20267\tval-mlogloss:0.23155\n",
      "[150]\ttrain-mlogloss:0.18904\tval-mlogloss:0.22851\n",
      "[200]\ttrain-mlogloss:0.17756\tval-mlogloss:0.22757\n",
      "[249]\ttrain-mlogloss:0.16837\tval-mlogloss:0.22723\n",
      "Best val. mlogloss on fold1 = 0.227227\n",
      "New configuration: {'max_depth': 5, 'min_child_weight': 0.10074717245387396}\n",
      "[0]\ttrain-mlogloss:1.23084\tval-mlogloss:1.23119\n",
      "[50]\ttrain-mlogloss:0.24999\tval-mlogloss:0.25692\n",
      "[100]\ttrain-mlogloss:0.22749\tval-mlogloss:0.23957\n",
      "[150]\ttrain-mlogloss:0.21776\tval-mlogloss:0.23458\n",
      "[200]\ttrain-mlogloss:0.21090\tval-mlogloss:0.23231\n",
      "[249]\ttrain-mlogloss:0.20501\tval-mlogloss:0.23065\n",
      "Best val. mlogloss on fold3 = 0.230654\n",
      "New configuration: {'max_depth': 3, 'min_child_weight': 0.10111469555571423}\n",
      "[0]\ttrain-mlogloss:1.23573\tval-mlogloss:1.23597\n",
      "[50]\ttrain-mlogloss:0.27120\tval-mlogloss:0.27445\n",
      "[100]\ttrain-mlogloss:0.24808\tval-mlogloss:0.25261\n",
      "[150]\ttrain-mlogloss:0.23993\tval-mlogloss:0.24574\n",
      "[200]\ttrain-mlogloss:0.23489\tval-mlogloss:0.24200\n",
      "[249]\ttrain-mlogloss:0.23111\tval-mlogloss:0.23943\n",
      "Best val. mlogloss on fold3 = 0.239432\n",
      "New configuration: {'max_depth': 10, 'min_child_weight': 9.957028930622476}\n",
      "[0]\ttrain-mlogloss:1.22543\tval-mlogloss:1.22792\n",
      "[50]\ttrain-mlogloss:0.19268\tval-mlogloss:0.24556\n",
      "[100]\ttrain-mlogloss:0.15905\tval-mlogloss:0.23616\n",
      "[111]\ttrain-mlogloss:0.15440\tval-mlogloss:0.23618\n",
      "Best val. mlogloss on fold0 = 0.236222\n",
      "New configuration: {'max_depth': 8, 'min_child_weight': 9.995747991869509}\n",
      "[0]\ttrain-mlogloss:1.22741\tval-mlogloss:1.22793\n",
      "[50]\ttrain-mlogloss:0.21849\tval-mlogloss:0.24301\n",
      "[100]\ttrain-mlogloss:0.18996\tval-mlogloss:0.23041\n",
      "[146]\ttrain-mlogloss:0.17600\tval-mlogloss:0.22888\n",
      "Best val. mlogloss on fold1 = 0.228865\n",
      "New configuration: {'max_depth': 4, 'min_child_weight': 0.10018226282904016}\n",
      "[0]\ttrain-mlogloss:1.23301\tval-mlogloss:1.23353\n",
      "[50]\ttrain-mlogloss:0.26030\tval-mlogloss:0.26750\n",
      "[100]\ttrain-mlogloss:0.23798\tval-mlogloss:0.24767\n",
      "[150]\ttrain-mlogloss:0.22934\tval-mlogloss:0.24157\n",
      "[200]\ttrain-mlogloss:0.22330\tval-mlogloss:0.23819\n",
      "[249]\ttrain-mlogloss:0.21892\tval-mlogloss:0.23640\n",
      "Best val. mlogloss on fold0 = 0.236403\n",
      "New configuration: {'max_depth': 3, 'min_child_weight': 0.10034545191263776}\n",
      "[0]\ttrain-mlogloss:1.23596\tval-mlogloss:1.23553\n",
      "[50]\ttrain-mlogloss:0.27200\tval-mlogloss:0.27069\n",
      "[100]\ttrain-mlogloss:0.24862\tval-mlogloss:0.24912\n",
      "[150]\ttrain-mlogloss:0.24024\tval-mlogloss:0.24231\n",
      "[200]\ttrain-mlogloss:0.23504\tval-mlogloss:0.23875\n",
      "[249]\ttrain-mlogloss:0.23131\tval-mlogloss:0.23643\n",
      "Best val. mlogloss on fold1 = 0.236428\n",
      "New configuration: {'max_depth': 10, 'min_child_weight': 0.10032409245547536}\n",
      "[0]\ttrain-mlogloss:1.22538\tval-mlogloss:1.22720\n",
      "[50]\ttrain-mlogloss:0.18809\tval-mlogloss:0.24160\n",
      "[100]\ttrain-mlogloss:0.15169\tval-mlogloss:0.23461\n",
      "Best val. mlogloss on fold1 = 0.234612\n",
      "New configuration: {'max_depth': 10, 'min_child_weight': 9.864508720198549}\n",
      "[0]\ttrain-mlogloss:1.22543\tval-mlogloss:1.22792\n",
      "[50]\ttrain-mlogloss:0.19284\tval-mlogloss:0.24561\n",
      "[100]\ttrain-mlogloss:0.15975\tval-mlogloss:0.23629\n",
      "[111]\ttrain-mlogloss:0.15493\tval-mlogloss:0.23638\n",
      "Best val. mlogloss on fold0 = 0.236383\n",
      "New configuration: {'max_depth': 3, 'min_child_weight': 0.10004454623655337}\n",
      "[0]\ttrain-mlogloss:1.23590\tval-mlogloss:1.23631\n",
      "[50]\ttrain-mlogloss:0.27169\tval-mlogloss:0.27747\n",
      "[100]\ttrain-mlogloss:0.24844\tval-mlogloss:0.25516\n",
      "[150]\ttrain-mlogloss:0.24017\tval-mlogloss:0.24806\n",
      "[200]\ttrain-mlogloss:0.23502\tval-mlogloss:0.24406\n",
      "[249]\ttrain-mlogloss:0.23142\tval-mlogloss:0.24182\n",
      "Best val. mlogloss on fold0 = 0.241815\n",
      "New configuration: {'max_depth': 3, 'min_child_weight': 0.10244515318685449}\n",
      "[0]\ttrain-mlogloss:1.23596\tval-mlogloss:1.23553\n",
      "[50]\ttrain-mlogloss:0.27200\tval-mlogloss:0.27069\n",
      "[100]\ttrain-mlogloss:0.24862\tval-mlogloss:0.24912\n",
      "[150]\ttrain-mlogloss:0.24024\tval-mlogloss:0.24231\n",
      "[200]\ttrain-mlogloss:0.23504\tval-mlogloss:0.23875\n",
      "[249]\ttrain-mlogloss:0.23131\tval-mlogloss:0.23643\n",
      "Best val. mlogloss on fold1 = 0.236428\n",
      "New configuration: {'max_depth': 3, 'min_child_weight': 0.10131904072440921}\n",
      "[0]\ttrain-mlogloss:1.23573\tval-mlogloss:1.23597\n",
      "[50]\ttrain-mlogloss:0.27120\tval-mlogloss:0.27445\n",
      "[100]\ttrain-mlogloss:0.24808\tval-mlogloss:0.25261\n",
      "[150]\ttrain-mlogloss:0.23993\tval-mlogloss:0.24574\n",
      "[200]\ttrain-mlogloss:0.23489\tval-mlogloss:0.24200\n",
      "[249]\ttrain-mlogloss:0.23111\tval-mlogloss:0.23943\n",
      "Best val. mlogloss on fold3 = 0.239432\n",
      "New configuration: {'max_depth': 6, 'min_child_weight': 0.10005099374687694}\n",
      "[0]\ttrain-mlogloss:1.22964\tval-mlogloss:1.22948\n",
      "[50]\ttrain-mlogloss:0.24002\tval-mlogloss:0.24868\n",
      "[100]\ttrain-mlogloss:0.21569\tval-mlogloss:0.23325\n",
      "[150]\ttrain-mlogloss:0.20413\tval-mlogloss:0.22942\n",
      "[200]\ttrain-mlogloss:0.19490\tval-mlogloss:0.22759\n",
      "[249]\ttrain-mlogloss:0.18745\tval-mlogloss:0.22634\n",
      "Best val. mlogloss on fold1 = 0.226337\n",
      "New configuration: {'max_depth': 3, 'min_child_weight': 0.10027084916670215}\n",
      "[0]\ttrain-mlogloss:1.23573\tval-mlogloss:1.23597\n",
      "[50]\ttrain-mlogloss:0.27120\tval-mlogloss:0.27445\n",
      "[100]\ttrain-mlogloss:0.24808\tval-mlogloss:0.25261\n",
      "[150]\ttrain-mlogloss:0.23993\tval-mlogloss:0.24574\n",
      "[200]\ttrain-mlogloss:0.23489\tval-mlogloss:0.24200\n",
      "[249]\ttrain-mlogloss:0.23111\tval-mlogloss:0.23943\n",
      "Best val. mlogloss on fold3 = 0.239432\n",
      "New configuration: {'max_depth': 3, 'min_child_weight': 0.1000654680637076}\n",
      "[0]\ttrain-mlogloss:1.23617\tval-mlogloss:1.23540\n",
      "[50]\ttrain-mlogloss:0.27275\tval-mlogloss:0.26762\n",
      "[100]\ttrain-mlogloss:0.24933\tval-mlogloss:0.24559\n",
      "[150]\ttrain-mlogloss:0.24133\tval-mlogloss:0.23896\n",
      "[200]\ttrain-mlogloss:0.23620\tval-mlogloss:0.23506\n",
      "[249]\ttrain-mlogloss:0.23253\tval-mlogloss:0.23268\n",
      "Best val. mlogloss on fold2 = 0.232677\n",
      "New configuration: {'max_depth': 4, 'min_child_weight': 9.852477116239402}\n",
      "[0]\ttrain-mlogloss:1.23276\tval-mlogloss:1.23311\n",
      "[50]\ttrain-mlogloss:0.25965\tval-mlogloss:0.26420\n",
      "[100]\ttrain-mlogloss:0.23790\tval-mlogloss:0.24523\n",
      "[150]\ttrain-mlogloss:0.22958\tval-mlogloss:0.23935\n",
      "[200]\ttrain-mlogloss:0.22376\tval-mlogloss:0.23601\n",
      "[249]\ttrain-mlogloss:0.21932\tval-mlogloss:0.23414\n",
      "Best val. mlogloss on fold3 = 0.234145\n",
      "New configuration: {'max_depth': 9, 'min_child_weight': 9.99341481913026}\n",
      "[0]\ttrain-mlogloss:1.22647\tval-mlogloss:1.22752\n",
      "[50]\ttrain-mlogloss:0.20563\tval-mlogloss:0.24194\n",
      "[100]\ttrain-mlogloss:0.17450\tval-mlogloss:0.23109\n",
      "[136]\ttrain-mlogloss:0.16161\tval-mlogloss:0.23078\n",
      "Best val. mlogloss on fold1 = 0.230819\n",
      "New configuration: {'max_depth': 10, 'min_child_weight': 0.10098070100893317}\n",
      "[0]\ttrain-mlogloss:1.22524\tval-mlogloss:1.22784\n",
      "[50]\ttrain-mlogloss:0.18885\tval-mlogloss:0.24380\n",
      "[100]\ttrain-mlogloss:0.15310\tval-mlogloss:0.23568\n",
      "[106]\ttrain-mlogloss:0.15020\tval-mlogloss:0.23567\n",
      "Best val. mlogloss on fold3 = 0.235647\n",
      "New configuration: {'max_depth': 5, 'min_child_weight': 9.972766822245172}\n",
      "[0]\ttrain-mlogloss:1.23110\tval-mlogloss:1.23091\n",
      "[50]\ttrain-mlogloss:0.25033\tval-mlogloss:0.25369\n",
      "[100]\ttrain-mlogloss:0.22788\tval-mlogloss:0.23701\n",
      "[150]\ttrain-mlogloss:0.21843\tval-mlogloss:0.23226\n",
      "[200]\ttrain-mlogloss:0.21126\tval-mlogloss:0.22995\n",
      "[249]\ttrain-mlogloss:0.20563\tval-mlogloss:0.22831\n",
      "Best val. mlogloss on fold1 = 0.228315\n",
      "New configuration: {'max_depth': 8, 'min_child_weight': 0.1005598941582154}\n",
      "[0]\ttrain-mlogloss:1.22754\tval-mlogloss:1.22781\n",
      "[50]\ttrain-mlogloss:0.21813\tval-mlogloss:0.23904\n",
      "[100]\ttrain-mlogloss:0.18785\tval-mlogloss:0.22579\n",
      "[150]\ttrain-mlogloss:0.17132\tval-mlogloss:0.22360\n",
      "[181]\ttrain-mlogloss:0.16289\tval-mlogloss:0.22336\n",
      "Best val. mlogloss on fold2 = 0.223364\n",
      "New configuration: {'max_depth': 4, 'min_child_weight': 0.10092141932329206}\n",
      "[0]\ttrain-mlogloss:1.23276\tval-mlogloss:1.23311\n",
      "[50]\ttrain-mlogloss:0.25960\tval-mlogloss:0.26427\n",
      "[100]\ttrain-mlogloss:0.23764\tval-mlogloss:0.24514\n",
      "[150]\ttrain-mlogloss:0.22927\tval-mlogloss:0.23933\n",
      "[200]\ttrain-mlogloss:0.22325\tval-mlogloss:0.23610\n",
      "[249]\ttrain-mlogloss:0.21876\tval-mlogloss:0.23409\n",
      "Best val. mlogloss on fold3 = 0.234095\n",
      "New configuration: {'max_depth': 7, 'min_child_weight': 9.986585907497398}\n",
      "[0]\ttrain-mlogloss:1.22827\tval-mlogloss:1.22903\n",
      "[50]\ttrain-mlogloss:0.23053\tval-mlogloss:0.24838\n",
      "[100]\ttrain-mlogloss:0.20469\tval-mlogloss:0.23399\n",
      "[150]\ttrain-mlogloss:0.19115\tval-mlogloss:0.23064\n",
      "[200]\ttrain-mlogloss:0.18040\tval-mlogloss:0.22935\n",
      "[247]\ttrain-mlogloss:0.17214\tval-mlogloss:0.22888\n",
      "Best val. mlogloss on fold3 = 0.228881\n",
      "New configuration: {'max_depth': 3, 'min_child_weight': 0.10069613290370828}\n",
      "[0]\ttrain-mlogloss:1.23590\tval-mlogloss:1.23631\n",
      "[50]\ttrain-mlogloss:0.27169\tval-mlogloss:0.27747\n",
      "[100]\ttrain-mlogloss:0.24844\tval-mlogloss:0.25516\n",
      "[150]\ttrain-mlogloss:0.24017\tval-mlogloss:0.24806\n",
      "[200]\ttrain-mlogloss:0.23502\tval-mlogloss:0.24406\n",
      "[249]\ttrain-mlogloss:0.23142\tval-mlogloss:0.24182\n",
      "Best val. mlogloss on fold0 = 0.241815\n",
      "New configuration: {'max_depth': 3, 'min_child_weight': 0.10000948545901467}\n",
      "[0]\ttrain-mlogloss:1.23573\tval-mlogloss:1.23597\n",
      "[50]\ttrain-mlogloss:0.27120\tval-mlogloss:0.27445\n",
      "[100]\ttrain-mlogloss:0.24808\tval-mlogloss:0.25261\n",
      "[150]\ttrain-mlogloss:0.23993\tval-mlogloss:0.24574\n",
      "[200]\ttrain-mlogloss:0.23489\tval-mlogloss:0.24200\n",
      "[249]\ttrain-mlogloss:0.23111\tval-mlogloss:0.23943\n",
      "Best val. mlogloss on fold3 = 0.239432\n",
      "New configuration: {'max_depth': 3, 'min_child_weight': 0.10059578587018198}\n",
      "[0]\ttrain-mlogloss:1.23573\tval-mlogloss:1.23597\n",
      "[50]\ttrain-mlogloss:0.27120\tval-mlogloss:0.27445\n",
      "[100]\ttrain-mlogloss:0.24808\tval-mlogloss:0.25261\n",
      "[150]\ttrain-mlogloss:0.23993\tval-mlogloss:0.24574\n",
      "[200]\ttrain-mlogloss:0.23489\tval-mlogloss:0.24200\n",
      "[249]\ttrain-mlogloss:0.23111\tval-mlogloss:0.23943\n",
      "Best val. mlogloss on fold3 = 0.239432\n",
      "New configuration: {'max_depth': 9, 'min_child_weight': 9.968477275609954}\n",
      "[0]\ttrain-mlogloss:1.22628\tval-mlogloss:1.22801\n",
      "[50]\ttrain-mlogloss:0.20619\tval-mlogloss:0.24410\n",
      "[100]\ttrain-mlogloss:0.17526\tval-mlogloss:0.23253\n",
      "[149]\ttrain-mlogloss:0.15786\tval-mlogloss:0.23178\n",
      "Best val. mlogloss on fold3 = 0.23178\n",
      "New configuration: {'max_depth': 10, 'min_child_weight': 9.984457632631962}\n",
      "[0]\ttrain-mlogloss:1.22535\tval-mlogloss:1.22782\n",
      "[50]\ttrain-mlogloss:0.19321\tval-mlogloss:0.24368\n",
      "[100]\ttrain-mlogloss:0.16002\tval-mlogloss:0.23411\n",
      "[119]\ttrain-mlogloss:0.15228\tval-mlogloss:0.23431\n",
      "Best val. mlogloss on fold3 = 0.234324\n",
      "New configuration: {'max_depth': 3, 'min_child_weight': 0.10010617000738746}\n",
      "[0]\ttrain-mlogloss:1.23573\tval-mlogloss:1.23597\n",
      "[50]\ttrain-mlogloss:0.27120\tval-mlogloss:0.27445\n",
      "[100]\ttrain-mlogloss:0.24808\tval-mlogloss:0.25261\n",
      "[150]\ttrain-mlogloss:0.23993\tval-mlogloss:0.24574\n",
      "[200]\ttrain-mlogloss:0.23489\tval-mlogloss:0.24200\n",
      "[249]\ttrain-mlogloss:0.23111\tval-mlogloss:0.23943\n",
      "Best val. mlogloss on fold3 = 0.239432\n",
      "New configuration: {'max_depth': 3, 'min_child_weight': 0.1009087180766731}\n",
      "[0]\ttrain-mlogloss:1.23596\tval-mlogloss:1.23553\n",
      "[50]\ttrain-mlogloss:0.27200\tval-mlogloss:0.27069\n",
      "[100]\ttrain-mlogloss:0.24862\tval-mlogloss:0.24912\n",
      "[150]\ttrain-mlogloss:0.24024\tval-mlogloss:0.24231\n",
      "[200]\ttrain-mlogloss:0.23504\tval-mlogloss:0.23875\n",
      "[249]\ttrain-mlogloss:0.23131\tval-mlogloss:0.23643\n",
      "Best val. mlogloss on fold1 = 0.236428\n",
      "New configuration: {'max_depth': 4, 'min_child_weight': 9.969335298562946}\n",
      "[0]\ttrain-mlogloss:1.23297\tval-mlogloss:1.23275\n",
      "[50]\ttrain-mlogloss:0.26047\tval-mlogloss:0.26074\n",
      "[100]\ttrain-mlogloss:0.23814\tval-mlogloss:0.24168\n",
      "[150]\ttrain-mlogloss:0.22962\tval-mlogloss:0.23608\n",
      "[200]\ttrain-mlogloss:0.22376\tval-mlogloss:0.23296\n",
      "[249]\ttrain-mlogloss:0.21942\tval-mlogloss:0.23104\n",
      "Best val. mlogloss on fold1 = 0.231038\n",
      "New configuration: {'max_depth': 6, 'min_child_weight': 9.992621772236408}\n",
      "[0]\ttrain-mlogloss:1.22953\tval-mlogloss:1.23030\n",
      "[50]\ttrain-mlogloss:0.24081\tval-mlogloss:0.25412\n",
      "[100]\ttrain-mlogloss:0.21698\tval-mlogloss:0.23803\n",
      "[150]\ttrain-mlogloss:0.20582\tval-mlogloss:0.23410\n",
      "[200]\ttrain-mlogloss:0.19719\tval-mlogloss:0.23195\n",
      "[249]\ttrain-mlogloss:0.19018\tval-mlogloss:0.23110\n",
      "Best val. mlogloss on fold0 = 0.231103\n",
      "New configuration: {'max_depth': 3, 'min_child_weight': 0.10064880919207292}\n",
      "[0]\ttrain-mlogloss:1.23596\tval-mlogloss:1.23553\n",
      "[50]\ttrain-mlogloss:0.27200\tval-mlogloss:0.27069\n",
      "[100]\ttrain-mlogloss:0.24862\tval-mlogloss:0.24912\n",
      "[150]\ttrain-mlogloss:0.24024\tval-mlogloss:0.24231\n",
      "[200]\ttrain-mlogloss:0.23504\tval-mlogloss:0.23875\n",
      "[249]\ttrain-mlogloss:0.23131\tval-mlogloss:0.23643\n",
      "Best val. mlogloss on fold1 = 0.236428\n",
      "New configuration: {'max_depth': 5, 'min_child_weight': 0.10048326501644056}\n",
      "[0]\ttrain-mlogloss:1.23084\tval-mlogloss:1.23119\n",
      "[50]\ttrain-mlogloss:0.24999\tval-mlogloss:0.25692\n",
      "[100]\ttrain-mlogloss:0.22749\tval-mlogloss:0.23957\n",
      "[150]\ttrain-mlogloss:0.21776\tval-mlogloss:0.23458\n",
      "[200]\ttrain-mlogloss:0.21090\tval-mlogloss:0.23231\n",
      "[249]\ttrain-mlogloss:0.20501\tval-mlogloss:0.23065\n",
      "Best val. mlogloss on fold3 = 0.230654\n",
      "New configuration: {'max_depth': 10, 'min_child_weight': 0.10063844486127352}\n",
      "[0]\ttrain-mlogloss:1.22524\tval-mlogloss:1.22784\n",
      "[50]\ttrain-mlogloss:0.18917\tval-mlogloss:0.24393\n",
      "[100]\ttrain-mlogloss:0.15319\tval-mlogloss:0.23589\n",
      "[113]\ttrain-mlogloss:0.14686\tval-mlogloss:0.23599\n",
      "Best val. mlogloss on fold3 = 0.236006\n",
      "New configuration: {'max_depth': 3, 'min_child_weight': 0.10063448001324844}\n",
      "[0]\ttrain-mlogloss:1.23596\tval-mlogloss:1.23553\n",
      "[50]\ttrain-mlogloss:0.27200\tval-mlogloss:0.27069\n",
      "[100]\ttrain-mlogloss:0.24862\tval-mlogloss:0.24912\n",
      "[150]\ttrain-mlogloss:0.24024\tval-mlogloss:0.24231\n",
      "[200]\ttrain-mlogloss:0.23504\tval-mlogloss:0.23875\n",
      "[249]\ttrain-mlogloss:0.23131\tval-mlogloss:0.23643\n",
      "Best val. mlogloss on fold1 = 0.236428\n",
      "New configuration: {'max_depth': 9, 'min_child_weight': 0.10011114413015687}\n",
      "[0]\ttrain-mlogloss:1.22628\tval-mlogloss:1.22814\n",
      "[50]\ttrain-mlogloss:0.20367\tval-mlogloss:0.24561\n",
      "[100]\ttrain-mlogloss:0.17063\tval-mlogloss:0.23471\n",
      "[126]\ttrain-mlogloss:0.16002\tval-mlogloss:0.23440\n",
      "Best val. mlogloss on fold0 = 0.234402\n",
      "New configuration: {'max_depth': 3, 'min_child_weight': 0.10043427765735259}\n",
      "[0]\ttrain-mlogloss:1.23617\tval-mlogloss:1.23540\n",
      "[50]\ttrain-mlogloss:0.27275\tval-mlogloss:0.26762\n",
      "[100]\ttrain-mlogloss:0.24933\tval-mlogloss:0.24559\n",
      "[150]\ttrain-mlogloss:0.24133\tval-mlogloss:0.23896\n",
      "[200]\ttrain-mlogloss:0.23620\tval-mlogloss:0.23506\n",
      "[249]\ttrain-mlogloss:0.23253\tval-mlogloss:0.23268\n",
      "Best val. mlogloss on fold2 = 0.232677\n",
      "New configuration: {'max_depth': 3, 'min_child_weight': 9.974927267023904}\n",
      "[0]\ttrain-mlogloss:1.23590\tval-mlogloss:1.23631\n",
      "[50]\ttrain-mlogloss:0.27174\tval-mlogloss:0.27749\n",
      "[100]\ttrain-mlogloss:0.24867\tval-mlogloss:0.25538\n",
      "[150]\ttrain-mlogloss:0.24039\tval-mlogloss:0.24827\n",
      "[200]\ttrain-mlogloss:0.23534\tval-mlogloss:0.24442\n",
      "[249]\ttrain-mlogloss:0.23180\tval-mlogloss:0.24222\n",
      "Best val. mlogloss on fold0 = 0.242216\n",
      "New configuration: {'max_depth': 7, 'min_child_weight': 0.10027232278077804}\n",
      "[0]\ttrain-mlogloss:1.22827\tval-mlogloss:1.22902\n",
      "[50]\ttrain-mlogloss:0.22964\tval-mlogloss:0.24831\n",
      "[100]\ttrain-mlogloss:0.20302\tval-mlogloss:0.23359\n",
      "[150]\ttrain-mlogloss:0.18872\tval-mlogloss:0.23058\n",
      "[185]\ttrain-mlogloss:0.18066\tval-mlogloss:0.22986\n",
      "Best val. mlogloss on fold3 = 0.22986\n",
      "New configuration: {'max_depth': 3, 'min_child_weight': 9.999447624191715}\n",
      "[0]\ttrain-mlogloss:1.23590\tval-mlogloss:1.23631\n",
      "[50]\ttrain-mlogloss:0.27174\tval-mlogloss:0.27749\n",
      "[100]\ttrain-mlogloss:0.24867\tval-mlogloss:0.25538\n",
      "[150]\ttrain-mlogloss:0.24039\tval-mlogloss:0.24827\n",
      "[200]\ttrain-mlogloss:0.23534\tval-mlogloss:0.24442\n",
      "[249]\ttrain-mlogloss:0.23180\tval-mlogloss:0.24222\n",
      "Best val. mlogloss on fold0 = 0.242216\n",
      "New configuration: {'max_depth': 4, 'min_child_weight': 9.971603468176077}\n",
      "[0]\ttrain-mlogloss:1.23324\tval-mlogloss:1.23257\n",
      "[50]\ttrain-mlogloss:0.26108\tval-mlogloss:0.25777\n",
      "[100]\ttrain-mlogloss:0.23878\tval-mlogloss:0.23811\n",
      "[150]\ttrain-mlogloss:0.23047\tval-mlogloss:0.23236\n",
      "[200]\ttrain-mlogloss:0.22482\tval-mlogloss:0.22910\n",
      "[249]\ttrain-mlogloss:0.22040\tval-mlogloss:0.22701\n",
      "Best val. mlogloss on fold2 = 0.227011\n",
      "New configuration: {'max_depth': 6, 'min_child_weight': 9.980620215422409}\n",
      "[0]\ttrain-mlogloss:1.22964\tval-mlogloss:1.22948\n",
      "[50]\ttrain-mlogloss:0.24042\tval-mlogloss:0.24880\n",
      "[100]\ttrain-mlogloss:0.21663\tval-mlogloss:0.23367\n",
      "[150]\ttrain-mlogloss:0.20556\tval-mlogloss:0.22994\n",
      "[200]\ttrain-mlogloss:0.19663\tval-mlogloss:0.22822\n",
      "[249]\ttrain-mlogloss:0.18946\tval-mlogloss:0.22720\n",
      "Best val. mlogloss on fold1 = 0.227199\n",
      "Optimizing min_split_loss (min loss change to add leaf)\n",
      "New configuration: {'min_split_loss': 0.0009249032828189121}\n",
      "[0]\ttrain-mlogloss:1.23590\tval-mlogloss:1.23631\n",
      "[50]\ttrain-mlogloss:0.27174\tval-mlogloss:0.27749\n",
      "[100]\ttrain-mlogloss:0.24862\tval-mlogloss:0.25533\n",
      "[150]\ttrain-mlogloss:0.24036\tval-mlogloss:0.24821\n",
      "[200]\ttrain-mlogloss:0.23519\tval-mlogloss:0.24423\n",
      "[249]\ttrain-mlogloss:0.23170\tval-mlogloss:0.24198\n",
      "Best val. mlogloss on fold0 = 0.241983\n",
      "New configuration: {'min_split_loss': 0.10338848971321277}\n",
      "[0]\ttrain-mlogloss:1.23573\tval-mlogloss:1.23597\n",
      "[50]\ttrain-mlogloss:0.27120\tval-mlogloss:0.27444\n",
      "[100]\ttrain-mlogloss:0.24807\tval-mlogloss:0.25250\n",
      "[150]\ttrain-mlogloss:0.24002\tval-mlogloss:0.24566\n",
      "[200]\ttrain-mlogloss:0.23505\tval-mlogloss:0.24204\n",
      "[249]\ttrain-mlogloss:0.23128\tval-mlogloss:0.23947\n",
      "Best val. mlogloss on fold3 = 0.239474\n",
      "New configuration: {'min_split_loss': 0.33441372361011057}\n",
      "[0]\ttrain-mlogloss:1.23596\tval-mlogloss:1.23553\n",
      "[50]\ttrain-mlogloss:0.27200\tval-mlogloss:0.27069\n",
      "[100]\ttrain-mlogloss:0.24861\tval-mlogloss:0.24914\n",
      "[150]\ttrain-mlogloss:0.24035\tval-mlogloss:0.24244\n",
      "[200]\ttrain-mlogloss:0.23521\tval-mlogloss:0.23886\n",
      "[249]\ttrain-mlogloss:0.23145\tval-mlogloss:0.23647\n",
      "Best val. mlogloss on fold1 = 0.236473\n",
      "New configuration: {'min_split_loss': 0.3227108430077591}\n",
      "[0]\ttrain-mlogloss:1.23617\tval-mlogloss:1.23540\n",
      "[50]\ttrain-mlogloss:0.27284\tval-mlogloss:0.26772\n",
      "[100]\ttrain-mlogloss:0.24930\tval-mlogloss:0.24542\n",
      "[150]\ttrain-mlogloss:0.24130\tval-mlogloss:0.23864\n",
      "[200]\ttrain-mlogloss:0.23625\tval-mlogloss:0.23490\n",
      "[249]\ttrain-mlogloss:0.23251\tval-mlogloss:0.23233\n",
      "Best val. mlogloss on fold2 = 0.232334\n",
      "New configuration: {'min_split_loss': 0.32675251632398045}\n",
      "[0]\ttrain-mlogloss:1.23617\tval-mlogloss:1.23540\n",
      "[50]\ttrain-mlogloss:0.27284\tval-mlogloss:0.26772\n",
      "[100]\ttrain-mlogloss:0.24930\tval-mlogloss:0.24542\n",
      "[150]\ttrain-mlogloss:0.24130\tval-mlogloss:0.23864\n",
      "[200]\ttrain-mlogloss:0.23625\tval-mlogloss:0.23490\n",
      "[249]\ttrain-mlogloss:0.23251\tval-mlogloss:0.23233\n",
      "Best val. mlogloss on fold2 = 0.232334\n",
      "New configuration: {'min_split_loss': 0.1005267969338132}\n",
      "[0]\ttrain-mlogloss:1.23617\tval-mlogloss:1.23540\n",
      "[50]\ttrain-mlogloss:0.27284\tval-mlogloss:0.26772\n",
      "[100]\ttrain-mlogloss:0.24930\tval-mlogloss:0.24542\n",
      "[150]\ttrain-mlogloss:0.24130\tval-mlogloss:0.23864\n",
      "[200]\ttrain-mlogloss:0.23628\tval-mlogloss:0.23496\n",
      "[249]\ttrain-mlogloss:0.23256\tval-mlogloss:0.23244\n",
      "Best val. mlogloss on fold2 = 0.232444\n",
      "New configuration: {'min_split_loss': 0.30772549950154}\n",
      "[0]\ttrain-mlogloss:1.23590\tval-mlogloss:1.23631\n",
      "[50]\ttrain-mlogloss:0.27174\tval-mlogloss:0.27749\n",
      "[100]\ttrain-mlogloss:0.24862\tval-mlogloss:0.25533\n",
      "[150]\ttrain-mlogloss:0.24036\tval-mlogloss:0.24821\n",
      "[200]\ttrain-mlogloss:0.23519\tval-mlogloss:0.24423\n",
      "[249]\ttrain-mlogloss:0.23171\tval-mlogloss:0.24201\n",
      "Best val. mlogloss on fold0 = 0.242012\n",
      "New configuration: {'min_split_loss': 0.4700247048343159}\n",
      "[0]\ttrain-mlogloss:1.23617\tval-mlogloss:1.23540\n",
      "[50]\ttrain-mlogloss:0.27284\tval-mlogloss:0.26772\n",
      "[100]\ttrain-mlogloss:0.24930\tval-mlogloss:0.24542\n",
      "[150]\ttrain-mlogloss:0.24130\tval-mlogloss:0.23864\n",
      "[200]\ttrain-mlogloss:0.23625\tval-mlogloss:0.23490\n",
      "[249]\ttrain-mlogloss:0.23251\tval-mlogloss:0.23233\n",
      "Best val. mlogloss on fold2 = 0.232334\n",
      "New configuration: {'min_split_loss': 0.3125023501290123}\n",
      "[0]\ttrain-mlogloss:1.23590\tval-mlogloss:1.23631\n",
      "[50]\ttrain-mlogloss:0.27174\tval-mlogloss:0.27749\n",
      "[100]\ttrain-mlogloss:0.24862\tval-mlogloss:0.25533\n",
      "[150]\ttrain-mlogloss:0.24036\tval-mlogloss:0.24822\n",
      "[200]\ttrain-mlogloss:0.23519\tval-mlogloss:0.24423\n",
      "[249]\ttrain-mlogloss:0.23171\tval-mlogloss:0.24201\n",
      "Best val. mlogloss on fold0 = 0.242012\n",
      "New configuration: {'min_split_loss': 0.4546429527303187}\n",
      "[0]\ttrain-mlogloss:1.23573\tval-mlogloss:1.23597\n",
      "[50]\ttrain-mlogloss:0.27120\tval-mlogloss:0.27444\n",
      "[100]\ttrain-mlogloss:0.24807\tval-mlogloss:0.25250\n",
      "[150]\ttrain-mlogloss:0.24002\tval-mlogloss:0.24566\n",
      "[200]\ttrain-mlogloss:0.23505\tval-mlogloss:0.24204\n",
      "[249]\ttrain-mlogloss:0.23128\tval-mlogloss:0.23947\n",
      "Best val. mlogloss on fold3 = 0.239474\n",
      "New configuration: {'min_split_loss': 0.30987771222610283}\n",
      "[0]\ttrain-mlogloss:1.23590\tval-mlogloss:1.23631\n",
      "[50]\ttrain-mlogloss:0.27174\tval-mlogloss:0.27749\n",
      "[100]\ttrain-mlogloss:0.24862\tval-mlogloss:0.25533\n",
      "[150]\ttrain-mlogloss:0.24036\tval-mlogloss:0.24821\n",
      "[200]\ttrain-mlogloss:0.23519\tval-mlogloss:0.24423\n",
      "[249]\ttrain-mlogloss:0.23171\tval-mlogloss:0.24201\n",
      "Best val. mlogloss on fold0 = 0.242012\n",
      "New configuration: {'min_split_loss': 0.008385239031515836}\n",
      "[0]\ttrain-mlogloss:1.23573\tval-mlogloss:1.23597\n",
      "[50]\ttrain-mlogloss:0.27120\tval-mlogloss:0.27444\n",
      "[100]\ttrain-mlogloss:0.24807\tval-mlogloss:0.25250\n",
      "[150]\ttrain-mlogloss:0.24003\tval-mlogloss:0.24569\n",
      "[200]\ttrain-mlogloss:0.23502\tval-mlogloss:0.24200\n",
      "[249]\ttrain-mlogloss:0.23133\tval-mlogloss:0.23940\n",
      "Best val. mlogloss on fold3 = 0.239396\n",
      "New configuration: {'min_split_loss': 0.3026528810656535}\n",
      "[0]\ttrain-mlogloss:1.23573\tval-mlogloss:1.23597\n",
      "[50]\ttrain-mlogloss:0.27120\tval-mlogloss:0.27444\n",
      "[100]\ttrain-mlogloss:0.24807\tval-mlogloss:0.25250\n",
      "[150]\ttrain-mlogloss:0.24002\tval-mlogloss:0.24566\n",
      "[200]\ttrain-mlogloss:0.23505\tval-mlogloss:0.24204\n",
      "[249]\ttrain-mlogloss:0.23128\tval-mlogloss:0.23947\n",
      "Best val. mlogloss on fold3 = 0.239474\n",
      "New configuration: {'min_split_loss': 0.11263893119434584}\n",
      "[0]\ttrain-mlogloss:1.23596\tval-mlogloss:1.23553\n",
      "[50]\ttrain-mlogloss:0.27200\tval-mlogloss:0.27069\n",
      "[100]\ttrain-mlogloss:0.24861\tval-mlogloss:0.24914\n",
      "[150]\ttrain-mlogloss:0.24035\tval-mlogloss:0.24244\n",
      "[200]\ttrain-mlogloss:0.23521\tval-mlogloss:0.23886\n",
      "[249]\ttrain-mlogloss:0.23145\tval-mlogloss:0.23647\n",
      "Best val. mlogloss on fold1 = 0.236473\n",
      "New configuration: {'min_split_loss': 0.4436492102530908}\n",
      "[0]\ttrain-mlogloss:1.23573\tval-mlogloss:1.23597\n",
      "[50]\ttrain-mlogloss:0.27120\tval-mlogloss:0.27444\n",
      "[100]\ttrain-mlogloss:0.24807\tval-mlogloss:0.25250\n",
      "[150]\ttrain-mlogloss:0.24002\tval-mlogloss:0.24566\n",
      "[200]\ttrain-mlogloss:0.23505\tval-mlogloss:0.24204\n",
      "[249]\ttrain-mlogloss:0.23128\tval-mlogloss:0.23947\n",
      "Best val. mlogloss on fold3 = 0.239474\n",
      "New configuration: {'min_split_loss': 0.4314407877432142}\n",
      "[0]\ttrain-mlogloss:1.23617\tval-mlogloss:1.23540\n",
      "[50]\ttrain-mlogloss:0.27284\tval-mlogloss:0.26772\n",
      "[100]\ttrain-mlogloss:0.24930\tval-mlogloss:0.24542\n",
      "[150]\ttrain-mlogloss:0.24130\tval-mlogloss:0.23864\n",
      "[200]\ttrain-mlogloss:0.23625\tval-mlogloss:0.23490\n",
      "[249]\ttrain-mlogloss:0.23251\tval-mlogloss:0.23233\n",
      "Best val. mlogloss on fold2 = 0.232334\n",
      "New configuration: {'min_split_loss': 0.02023440184328085}\n",
      "[0]\ttrain-mlogloss:1.23573\tval-mlogloss:1.23597\n",
      "[50]\ttrain-mlogloss:0.27120\tval-mlogloss:0.27444\n",
      "[100]\ttrain-mlogloss:0.24807\tval-mlogloss:0.25250\n",
      "[150]\ttrain-mlogloss:0.24003\tval-mlogloss:0.24569\n",
      "[200]\ttrain-mlogloss:0.23502\tval-mlogloss:0.24200\n",
      "[249]\ttrain-mlogloss:0.23133\tval-mlogloss:0.23940\n",
      "Best val. mlogloss on fold3 = 0.239396\n",
      "New configuration: {'min_split_loss': 0.031212274066454666}\n",
      "[0]\ttrain-mlogloss:1.23596\tval-mlogloss:1.23553\n",
      "[50]\ttrain-mlogloss:0.27200\tval-mlogloss:0.27069\n",
      "[100]\ttrain-mlogloss:0.24861\tval-mlogloss:0.24914\n",
      "[150]\ttrain-mlogloss:0.24035\tval-mlogloss:0.24244\n",
      "[200]\ttrain-mlogloss:0.23521\tval-mlogloss:0.23886\n",
      "[249]\ttrain-mlogloss:0.23145\tval-mlogloss:0.23647\n",
      "Best val. mlogloss on fold1 = 0.236473\n",
      "New configuration: {'min_split_loss': 0.003439548580442489}\n",
      "[0]\ttrain-mlogloss:1.23617\tval-mlogloss:1.23540\n",
      "[50]\ttrain-mlogloss:0.27284\tval-mlogloss:0.26772\n",
      "[100]\ttrain-mlogloss:0.24930\tval-mlogloss:0.24542\n",
      "[150]\ttrain-mlogloss:0.24130\tval-mlogloss:0.23864\n",
      "[200]\ttrain-mlogloss:0.23625\tval-mlogloss:0.23490\n",
      "[249]\ttrain-mlogloss:0.23251\tval-mlogloss:0.23233\n",
      "Best val. mlogloss on fold2 = 0.232334\n",
      "New configuration: {'min_split_loss': 0.29310225812492524}\n",
      "[0]\ttrain-mlogloss:1.23596\tval-mlogloss:1.23553\n",
      "[50]\ttrain-mlogloss:0.27200\tval-mlogloss:0.27069\n",
      "[100]\ttrain-mlogloss:0.24861\tval-mlogloss:0.24914\n",
      "[150]\ttrain-mlogloss:0.24035\tval-mlogloss:0.24244\n",
      "[200]\ttrain-mlogloss:0.23521\tval-mlogloss:0.23886\n",
      "[249]\ttrain-mlogloss:0.23145\tval-mlogloss:0.23647\n",
      "Best val. mlogloss on fold1 = 0.236473\n",
      "New configuration: {'min_split_loss': 0.2043043618162368}\n",
      "[0]\ttrain-mlogloss:1.23596\tval-mlogloss:1.23553\n",
      "[50]\ttrain-mlogloss:0.27200\tval-mlogloss:0.27069\n",
      "[100]\ttrain-mlogloss:0.24861\tval-mlogloss:0.24914\n",
      "[150]\ttrain-mlogloss:0.24035\tval-mlogloss:0.24244\n",
      "[200]\ttrain-mlogloss:0.23521\tval-mlogloss:0.23886\n",
      "[249]\ttrain-mlogloss:0.23145\tval-mlogloss:0.23647\n",
      "Best val. mlogloss on fold1 = 0.236473\n",
      "New configuration: {'min_split_loss': 0.3801879396213924}\n",
      "[0]\ttrain-mlogloss:1.23590\tval-mlogloss:1.23631\n",
      "[50]\ttrain-mlogloss:0.27174\tval-mlogloss:0.27749\n",
      "[100]\ttrain-mlogloss:0.24862\tval-mlogloss:0.25533\n",
      "[150]\ttrain-mlogloss:0.24036\tval-mlogloss:0.24821\n",
      "[200]\ttrain-mlogloss:0.23519\tval-mlogloss:0.24423\n",
      "[249]\ttrain-mlogloss:0.23171\tval-mlogloss:0.24201\n",
      "Best val. mlogloss on fold0 = 0.242012\n",
      "New configuration: {'min_split_loss': 0.3729373443026742}\n",
      "[0]\ttrain-mlogloss:1.23617\tval-mlogloss:1.23540\n",
      "[50]\ttrain-mlogloss:0.27284\tval-mlogloss:0.26772\n",
      "[100]\ttrain-mlogloss:0.24930\tval-mlogloss:0.24542\n",
      "[150]\ttrain-mlogloss:0.24130\tval-mlogloss:0.23864\n",
      "[200]\ttrain-mlogloss:0.23625\tval-mlogloss:0.23490\n",
      "[249]\ttrain-mlogloss:0.23251\tval-mlogloss:0.23233\n",
      "Best val. mlogloss on fold2 = 0.232334\n",
      "New configuration: {'min_split_loss': 0.3874917200740813}\n",
      "[0]\ttrain-mlogloss:1.23596\tval-mlogloss:1.23553\n",
      "[50]\ttrain-mlogloss:0.27200\tval-mlogloss:0.27069\n",
      "[100]\ttrain-mlogloss:0.24861\tval-mlogloss:0.24914\n",
      "[150]\ttrain-mlogloss:0.24035\tval-mlogloss:0.24244\n",
      "[200]\ttrain-mlogloss:0.23521\tval-mlogloss:0.23886\n",
      "[249]\ttrain-mlogloss:0.23145\tval-mlogloss:0.23647\n",
      "Best val. mlogloss on fold1 = 0.236473\n",
      "New configuration: {'min_split_loss': 0.15846222440277505}\n",
      "[0]\ttrain-mlogloss:1.23573\tval-mlogloss:1.23597\n",
      "[50]\ttrain-mlogloss:0.27120\tval-mlogloss:0.27444\n",
      "[100]\ttrain-mlogloss:0.24807\tval-mlogloss:0.25250\n",
      "[150]\ttrain-mlogloss:0.24002\tval-mlogloss:0.24566\n",
      "[200]\ttrain-mlogloss:0.23505\tval-mlogloss:0.24204\n",
      "[249]\ttrain-mlogloss:0.23128\tval-mlogloss:0.23947\n",
      "Best val. mlogloss on fold3 = 0.239474\n",
      "New configuration: {'min_split_loss': 0.16819993288996718}\n",
      "[0]\ttrain-mlogloss:1.23596\tval-mlogloss:1.23553\n",
      "[50]\ttrain-mlogloss:0.27200\tval-mlogloss:0.27069\n",
      "[100]\ttrain-mlogloss:0.24861\tval-mlogloss:0.24914\n",
      "[150]\ttrain-mlogloss:0.24035\tval-mlogloss:0.24244\n",
      "[200]\ttrain-mlogloss:0.23521\tval-mlogloss:0.23886\n",
      "[249]\ttrain-mlogloss:0.23145\tval-mlogloss:0.23647\n",
      "Best val. mlogloss on fold1 = 0.236473\n",
      "New configuration: {'min_split_loss': 0.14877649546674246}\n",
      "[0]\ttrain-mlogloss:1.23596\tval-mlogloss:1.23553\n",
      "[50]\ttrain-mlogloss:0.27200\tval-mlogloss:0.27069\n",
      "[100]\ttrain-mlogloss:0.24861\tval-mlogloss:0.24914\n",
      "[150]\ttrain-mlogloss:0.24035\tval-mlogloss:0.24244\n",
      "[200]\ttrain-mlogloss:0.23521\tval-mlogloss:0.23886\n",
      "[249]\ttrain-mlogloss:0.23145\tval-mlogloss:0.23647\n",
      "Best val. mlogloss on fold1 = 0.236473\n",
      "New configuration: {'min_split_loss': 0.3093962098255579}\n",
      "[0]\ttrain-mlogloss:1.23573\tval-mlogloss:1.23597\n",
      "[50]\ttrain-mlogloss:0.27120\tval-mlogloss:0.27444\n",
      "[100]\ttrain-mlogloss:0.24807\tval-mlogloss:0.25250\n",
      "[150]\ttrain-mlogloss:0.24002\tval-mlogloss:0.24566\n",
      "[200]\ttrain-mlogloss:0.23505\tval-mlogloss:0.24204\n",
      "[249]\ttrain-mlogloss:0.23128\tval-mlogloss:0.23947\n",
      "Best val. mlogloss on fold3 = 0.239474\n",
      "New configuration: {'min_split_loss': 0.24863699729415084}\n",
      "[0]\ttrain-mlogloss:1.23590\tval-mlogloss:1.23631\n",
      "[50]\ttrain-mlogloss:0.27174\tval-mlogloss:0.27749\n",
      "[100]\ttrain-mlogloss:0.24862\tval-mlogloss:0.25533\n",
      "[150]\ttrain-mlogloss:0.24036\tval-mlogloss:0.24821\n",
      "[200]\ttrain-mlogloss:0.23519\tval-mlogloss:0.24423\n",
      "[249]\ttrain-mlogloss:0.23171\tval-mlogloss:0.24201\n",
      "Best val. mlogloss on fold0 = 0.242012\n",
      "New configuration: {'min_split_loss': 0.2414663313691418}\n",
      "[0]\ttrain-mlogloss:1.23590\tval-mlogloss:1.23631\n",
      "[50]\ttrain-mlogloss:0.27174\tval-mlogloss:0.27749\n",
      "[100]\ttrain-mlogloss:0.24862\tval-mlogloss:0.25533\n",
      "[150]\ttrain-mlogloss:0.24036\tval-mlogloss:0.24821\n",
      "[200]\ttrain-mlogloss:0.23519\tval-mlogloss:0.24423\n",
      "[249]\ttrain-mlogloss:0.23171\tval-mlogloss:0.24201\n",
      "Best val. mlogloss on fold0 = 0.242012\n",
      "New configuration: {'min_split_loss': 0.25555642400119094}\n",
      "[0]\ttrain-mlogloss:1.23596\tval-mlogloss:1.23553\n",
      "[50]\ttrain-mlogloss:0.27200\tval-mlogloss:0.27069\n",
      "[100]\ttrain-mlogloss:0.24861\tval-mlogloss:0.24914\n",
      "[150]\ttrain-mlogloss:0.24035\tval-mlogloss:0.24244\n",
      "[200]\ttrain-mlogloss:0.23521\tval-mlogloss:0.23886\n",
      "[249]\ttrain-mlogloss:0.23145\tval-mlogloss:0.23647\n",
      "Best val. mlogloss on fold1 = 0.236473\n",
      "New configuration: {'min_split_loss': 0.23454617231976405}\n",
      "[0]\ttrain-mlogloss:1.23590\tval-mlogloss:1.23631\n",
      "[50]\ttrain-mlogloss:0.27174\tval-mlogloss:0.27749\n",
      "[100]\ttrain-mlogloss:0.24862\tval-mlogloss:0.25533\n",
      "[150]\ttrain-mlogloss:0.24036\tval-mlogloss:0.24821\n",
      "[200]\ttrain-mlogloss:0.23519\tval-mlogloss:0.24423\n",
      "[249]\ttrain-mlogloss:0.23171\tval-mlogloss:0.24201\n",
      "Best val. mlogloss on fold0 = 0.242012\n",
      "New configuration: {'min_split_loss': 0.22753187962445565}\n",
      "[0]\ttrain-mlogloss:1.23573\tval-mlogloss:1.23597\n",
      "[50]\ttrain-mlogloss:0.27120\tval-mlogloss:0.27444\n",
      "[100]\ttrain-mlogloss:0.24807\tval-mlogloss:0.25250\n",
      "[150]\ttrain-mlogloss:0.24002\tval-mlogloss:0.24566\n",
      "[200]\ttrain-mlogloss:0.23505\tval-mlogloss:0.24204\n",
      "[249]\ttrain-mlogloss:0.23128\tval-mlogloss:0.23947\n",
      "Best val. mlogloss on fold3 = 0.239474\n",
      "New configuration: {'min_split_loss': 0.21813325837939446}\n",
      "[0]\ttrain-mlogloss:1.23573\tval-mlogloss:1.23597\n",
      "[50]\ttrain-mlogloss:0.27120\tval-mlogloss:0.27444\n",
      "[100]\ttrain-mlogloss:0.24807\tval-mlogloss:0.25250\n",
      "[150]\ttrain-mlogloss:0.24002\tval-mlogloss:0.24566\n",
      "[200]\ttrain-mlogloss:0.23505\tval-mlogloss:0.24204\n",
      "[249]\ttrain-mlogloss:0.23128\tval-mlogloss:0.23947\n",
      "Best val. mlogloss on fold3 = 0.239474\n",
      "New configuration: {'min_split_loss': 0.06417316746024616}\n",
      "[0]\ttrain-mlogloss:1.23590\tval-mlogloss:1.23631\n",
      "[50]\ttrain-mlogloss:0.27174\tval-mlogloss:0.27749\n",
      "[100]\ttrain-mlogloss:0.24862\tval-mlogloss:0.25533\n",
      "[150]\ttrain-mlogloss:0.24036\tval-mlogloss:0.24821\n",
      "[200]\ttrain-mlogloss:0.23519\tval-mlogloss:0.24423\n",
      "[249]\ttrain-mlogloss:0.23170\tval-mlogloss:0.24198\n",
      "Best val. mlogloss on fold0 = 0.241983\n",
      "New configuration: {'min_split_loss': 0.23874646961778231}\n",
      "[0]\ttrain-mlogloss:1.23590\tval-mlogloss:1.23631\n",
      "[50]\ttrain-mlogloss:0.27174\tval-mlogloss:0.27749\n",
      "[100]\ttrain-mlogloss:0.24862\tval-mlogloss:0.25533\n",
      "[150]\ttrain-mlogloss:0.24036\tval-mlogloss:0.24821\n",
      "[200]\ttrain-mlogloss:0.23519\tval-mlogloss:0.24423\n",
      "[249]\ttrain-mlogloss:0.23171\tval-mlogloss:0.24201\n",
      "Best val. mlogloss on fold0 = 0.242012\n",
      "New configuration: {'min_split_loss': 0.07198133965373411}\n",
      "[0]\ttrain-mlogloss:1.23590\tval-mlogloss:1.23631\n",
      "[50]\ttrain-mlogloss:0.27174\tval-mlogloss:0.27749\n",
      "[100]\ttrain-mlogloss:0.24862\tval-mlogloss:0.25533\n",
      "[150]\ttrain-mlogloss:0.24036\tval-mlogloss:0.24821\n",
      "[200]\ttrain-mlogloss:0.23519\tval-mlogloss:0.24423\n",
      "[249]\ttrain-mlogloss:0.23170\tval-mlogloss:0.24198\n",
      "Best val. mlogloss on fold0 = 0.241983\n",
      "New configuration: {'min_split_loss': 0.055618739488084226}\n",
      "[0]\ttrain-mlogloss:1.23617\tval-mlogloss:1.23540\n",
      "[50]\ttrain-mlogloss:0.27284\tval-mlogloss:0.26772\n",
      "[100]\ttrain-mlogloss:0.24930\tval-mlogloss:0.24542\n",
      "[150]\ttrain-mlogloss:0.24130\tval-mlogloss:0.23864\n",
      "[200]\ttrain-mlogloss:0.23625\tval-mlogloss:0.23490\n",
      "[249]\ttrain-mlogloss:0.23251\tval-mlogloss:0.23233\n",
      "Best val. mlogloss on fold2 = 0.232334\n",
      "New configuration: {'min_split_loss': 0.23800703712690266}\n",
      "[0]\ttrain-mlogloss:1.23573\tval-mlogloss:1.23597\n",
      "[50]\ttrain-mlogloss:0.27120\tval-mlogloss:0.27444\n",
      "[100]\ttrain-mlogloss:0.24807\tval-mlogloss:0.25250\n",
      "[150]\ttrain-mlogloss:0.24002\tval-mlogloss:0.24566\n",
      "[200]\ttrain-mlogloss:0.23505\tval-mlogloss:0.24204\n",
      "[249]\ttrain-mlogloss:0.23128\tval-mlogloss:0.23947\n",
      "Best val. mlogloss on fold3 = 0.239474\n",
      "New configuration: {'min_split_loss': 0.07933419124628695}\n",
      "[0]\ttrain-mlogloss:1.23573\tval-mlogloss:1.23597\n",
      "[50]\ttrain-mlogloss:0.27120\tval-mlogloss:0.27444\n",
      "[100]\ttrain-mlogloss:0.24807\tval-mlogloss:0.25250\n",
      "[150]\ttrain-mlogloss:0.24002\tval-mlogloss:0.24566\n",
      "[200]\ttrain-mlogloss:0.23505\tval-mlogloss:0.24204\n",
      "[249]\ttrain-mlogloss:0.23128\tval-mlogloss:0.23947\n",
      "Best val. mlogloss on fold3 = 0.239474\n",
      "New configuration: {'min_split_loss': 0.24403899147914088}\n",
      "[0]\ttrain-mlogloss:1.23573\tval-mlogloss:1.23597\n",
      "[50]\ttrain-mlogloss:0.27120\tval-mlogloss:0.27444\n",
      "[100]\ttrain-mlogloss:0.24807\tval-mlogloss:0.25250\n",
      "[150]\ttrain-mlogloss:0.24002\tval-mlogloss:0.24566\n",
      "[200]\ttrain-mlogloss:0.23505\tval-mlogloss:0.24204\n",
      "[249]\ttrain-mlogloss:0.23128\tval-mlogloss:0.23947\n",
      "Best val. mlogloss on fold3 = 0.239474\n",
      "New configuration: {'min_split_loss': 0.49993448419500836}\n",
      "[0]\ttrain-mlogloss:1.23596\tval-mlogloss:1.23553\n",
      "[50]\ttrain-mlogloss:0.27200\tval-mlogloss:0.27069\n",
      "[100]\ttrain-mlogloss:0.24861\tval-mlogloss:0.24914\n",
      "[150]\ttrain-mlogloss:0.24035\tval-mlogloss:0.24244\n",
      "[200]\ttrain-mlogloss:0.23521\tval-mlogloss:0.23886\n",
      "[249]\ttrain-mlogloss:0.23145\tval-mlogloss:0.23647\n",
      "Best val. mlogloss on fold1 = 0.236473\n",
      "New configuration: {'min_split_loss': 0.40780618318829}\n",
      "[0]\ttrain-mlogloss:1.23590\tval-mlogloss:1.23631\n",
      "[50]\ttrain-mlogloss:0.27174\tval-mlogloss:0.27749\n",
      "[100]\ttrain-mlogloss:0.24862\tval-mlogloss:0.25533\n",
      "[150]\ttrain-mlogloss:0.24036\tval-mlogloss:0.24821\n",
      "[200]\ttrain-mlogloss:0.23519\tval-mlogloss:0.24423\n",
      "[249]\ttrain-mlogloss:0.23171\tval-mlogloss:0.24201\n",
      "Best val. mlogloss on fold0 = 0.242012\n",
      "New configuration: {'min_split_loss': 0.41496455766244966}\n",
      "[0]\ttrain-mlogloss:1.23596\tval-mlogloss:1.23553\n",
      "[50]\ttrain-mlogloss:0.27200\tval-mlogloss:0.27069\n",
      "[100]\ttrain-mlogloss:0.24861\tval-mlogloss:0.24914\n",
      "[150]\ttrain-mlogloss:0.24035\tval-mlogloss:0.24244\n",
      "[200]\ttrain-mlogloss:0.23521\tval-mlogloss:0.23886\n",
      "[249]\ttrain-mlogloss:0.23145\tval-mlogloss:0.23647\n",
      "Best val. mlogloss on fold1 = 0.236473\n",
      "New configuration: {'min_split_loss': 0.4005668429613424}\n",
      "[0]\ttrain-mlogloss:1.23617\tval-mlogloss:1.23540\n",
      "[50]\ttrain-mlogloss:0.27284\tval-mlogloss:0.26772\n",
      "[100]\ttrain-mlogloss:0.24930\tval-mlogloss:0.24542\n",
      "[150]\ttrain-mlogloss:0.24130\tval-mlogloss:0.23864\n",
      "[200]\ttrain-mlogloss:0.23625\tval-mlogloss:0.23490\n",
      "[249]\ttrain-mlogloss:0.23251\tval-mlogloss:0.23233\n",
      "Best val. mlogloss on fold2 = 0.232334\n",
      "New configuration: {'min_split_loss': 0.06872675765078205}\n",
      "[0]\ttrain-mlogloss:1.23573\tval-mlogloss:1.23597\n",
      "[50]\ttrain-mlogloss:0.27120\tval-mlogloss:0.27444\n",
      "[100]\ttrain-mlogloss:0.24807\tval-mlogloss:0.25250\n",
      "[150]\ttrain-mlogloss:0.24003\tval-mlogloss:0.24569\n",
      "[200]\ttrain-mlogloss:0.23502\tval-mlogloss:0.24200\n",
      "[249]\ttrain-mlogloss:0.23133\tval-mlogloss:0.23940\n",
      "Best val. mlogloss on fold3 = 0.239396\n",
      "New configuration: {'min_split_loss': 0.23535321637298498}\n",
      "[0]\ttrain-mlogloss:1.23596\tval-mlogloss:1.23553\n",
      "[50]\ttrain-mlogloss:0.27200\tval-mlogloss:0.27069\n",
      "[100]\ttrain-mlogloss:0.24861\tval-mlogloss:0.24914\n",
      "[150]\ttrain-mlogloss:0.24035\tval-mlogloss:0.24244\n",
      "[200]\ttrain-mlogloss:0.23521\tval-mlogloss:0.23886\n",
      "[249]\ttrain-mlogloss:0.23145\tval-mlogloss:0.23647\n",
      "Best val. mlogloss on fold1 = 0.236473\n",
      "New configuration: {'min_split_loss': 0.27433735614593074}\n",
      "[0]\ttrain-mlogloss:1.23617\tval-mlogloss:1.23540\n",
      "[50]\ttrain-mlogloss:0.27284\tval-mlogloss:0.26772\n",
      "[100]\ttrain-mlogloss:0.24930\tval-mlogloss:0.24542\n",
      "[150]\ttrain-mlogloss:0.24130\tval-mlogloss:0.23864\n",
      "[200]\ttrain-mlogloss:0.23625\tval-mlogloss:0.23490\n",
      "[249]\ttrain-mlogloss:0.23251\tval-mlogloss:0.23233\n",
      "Best val. mlogloss on fold2 = 0.232334\n",
      "New configuration: {'min_split_loss': 0.3103810447741894}\n",
      "[0]\ttrain-mlogloss:1.23617\tval-mlogloss:1.23540\n",
      "[50]\ttrain-mlogloss:0.27284\tval-mlogloss:0.26772\n",
      "[100]\ttrain-mlogloss:0.24930\tval-mlogloss:0.24542\n",
      "[150]\ttrain-mlogloss:0.24130\tval-mlogloss:0.23864\n",
      "[200]\ttrain-mlogloss:0.23625\tval-mlogloss:0.23490\n",
      "[249]\ttrain-mlogloss:0.23251\tval-mlogloss:0.23233\n",
      "Best val. mlogloss on fold2 = 0.232334\n",
      "New configuration: {'min_split_loss': 0.18608707734896743}\n",
      "[0]\ttrain-mlogloss:1.23573\tval-mlogloss:1.23597\n",
      "[50]\ttrain-mlogloss:0.27120\tval-mlogloss:0.27444\n",
      "[100]\ttrain-mlogloss:0.24807\tval-mlogloss:0.25250\n",
      "[150]\ttrain-mlogloss:0.24002\tval-mlogloss:0.24566\n",
      "[200]\ttrain-mlogloss:0.23505\tval-mlogloss:0.24204\n",
      "[249]\ttrain-mlogloss:0.23128\tval-mlogloss:0.23947\n",
      "Best val. mlogloss on fold3 = 0.239474\n",
      "New configuration: {'min_split_loss': 0.1308092294919143}\n",
      "[0]\ttrain-mlogloss:1.23617\tval-mlogloss:1.23540\n",
      "[50]\ttrain-mlogloss:0.27284\tval-mlogloss:0.26772\n",
      "[100]\ttrain-mlogloss:0.24930\tval-mlogloss:0.24542\n",
      "[150]\ttrain-mlogloss:0.24130\tval-mlogloss:0.23864\n",
      "[200]\ttrain-mlogloss:0.23628\tval-mlogloss:0.23496\n",
      "[249]\ttrain-mlogloss:0.23256\tval-mlogloss:0.23244\n",
      "Best val. mlogloss on fold2 = 0.232444\n",
      "New configuration: {'min_split_loss': 0.24150565975113245}\n",
      "[0]\ttrain-mlogloss:1.23596\tval-mlogloss:1.23553\n",
      "[50]\ttrain-mlogloss:0.27200\tval-mlogloss:0.27069\n",
      "[100]\ttrain-mlogloss:0.24861\tval-mlogloss:0.24914\n",
      "[150]\ttrain-mlogloss:0.24035\tval-mlogloss:0.24244\n",
      "[200]\ttrain-mlogloss:0.23521\tval-mlogloss:0.23886\n",
      "[249]\ttrain-mlogloss:0.23145\tval-mlogloss:0.23647\n",
      "Best val. mlogloss on fold1 = 0.236473\n",
      "New configuration: {'min_split_loss': 0.35240423746211735}\n",
      "[0]\ttrain-mlogloss:1.23573\tval-mlogloss:1.23597\n",
      "[50]\ttrain-mlogloss:0.27120\tval-mlogloss:0.27444\n",
      "[100]\ttrain-mlogloss:0.24807\tval-mlogloss:0.25250\n",
      "[150]\ttrain-mlogloss:0.24002\tval-mlogloss:0.24566\n",
      "[200]\ttrain-mlogloss:0.23505\tval-mlogloss:0.24204\n",
      "[249]\ttrain-mlogloss:0.23128\tval-mlogloss:0.23947\n",
      "Best val. mlogloss on fold3 = 0.239474\n",
      "New configuration: {'min_split_loss': 4.023435523572481e-05}\n",
      "[0]\ttrain-mlogloss:1.23573\tval-mlogloss:1.23597\n",
      "[50]\ttrain-mlogloss:0.27120\tval-mlogloss:0.27444\n",
      "[100]\ttrain-mlogloss:0.24807\tval-mlogloss:0.25250\n",
      "[150]\ttrain-mlogloss:0.24003\tval-mlogloss:0.24569\n",
      "[200]\ttrain-mlogloss:0.23502\tval-mlogloss:0.24200\n",
      "[249]\ttrain-mlogloss:0.23133\tval-mlogloss:0.23940\n",
      "Best val. mlogloss on fold3 = 0.239396\n",
      "New configuration: {'min_split_loss': 8.341613536454737e-05}\n",
      "[0]\ttrain-mlogloss:1.23596\tval-mlogloss:1.23553\n",
      "[50]\ttrain-mlogloss:0.27200\tval-mlogloss:0.27069\n",
      "[100]\ttrain-mlogloss:0.24861\tval-mlogloss:0.24914\n",
      "[150]\ttrain-mlogloss:0.24035\tval-mlogloss:0.24244\n",
      "[200]\ttrain-mlogloss:0.23521\tval-mlogloss:0.23886\n",
      "[249]\ttrain-mlogloss:0.23145\tval-mlogloss:0.23647\n",
      "Best val. mlogloss on fold1 = 0.236473\n",
      "New configuration: {'min_split_loss': 0.4572181894576244}\n",
      "[0]\ttrain-mlogloss:1.23573\tval-mlogloss:1.23597\n",
      "[50]\ttrain-mlogloss:0.27120\tval-mlogloss:0.27444\n",
      "[100]\ttrain-mlogloss:0.24807\tval-mlogloss:0.25250\n",
      "[150]\ttrain-mlogloss:0.24002\tval-mlogloss:0.24566\n",
      "[200]\ttrain-mlogloss:0.23505\tval-mlogloss:0.24204\n",
      "[249]\ttrain-mlogloss:0.23128\tval-mlogloss:0.23947\n",
      "Best val. mlogloss on fold3 = 0.239474\n",
      "New configuration: {'min_split_loss': 0.4234831114126233}\n",
      "[0]\ttrain-mlogloss:1.23617\tval-mlogloss:1.23540\n",
      "[50]\ttrain-mlogloss:0.27284\tval-mlogloss:0.26772\n",
      "[100]\ttrain-mlogloss:0.24930\tval-mlogloss:0.24542\n",
      "[150]\ttrain-mlogloss:0.24130\tval-mlogloss:0.23864\n",
      "[200]\ttrain-mlogloss:0.23625\tval-mlogloss:0.23490\n",
      "[249]\ttrain-mlogloss:0.23251\tval-mlogloss:0.23233\n",
      "Best val. mlogloss on fold2 = 0.232334\n",
      "New configuration: {'min_split_loss': 0.48651995558440747}\n",
      "[0]\ttrain-mlogloss:1.23596\tval-mlogloss:1.23553\n",
      "[50]\ttrain-mlogloss:0.27200\tval-mlogloss:0.27069\n",
      "[100]\ttrain-mlogloss:0.24861\tval-mlogloss:0.24914\n",
      "[150]\ttrain-mlogloss:0.24035\tval-mlogloss:0.24244\n",
      "[200]\ttrain-mlogloss:0.23521\tval-mlogloss:0.23886\n",
      "[249]\ttrain-mlogloss:0.23145\tval-mlogloss:0.23647\n",
      "Best val. mlogloss on fold1 = 0.236473\n",
      "New configuration: {'min_split_loss': 0.24066335606544373}\n",
      "[0]\ttrain-mlogloss:1.23590\tval-mlogloss:1.23631\n",
      "[50]\ttrain-mlogloss:0.27174\tval-mlogloss:0.27749\n",
      "[100]\ttrain-mlogloss:0.24862\tval-mlogloss:0.25533\n",
      "[150]\ttrain-mlogloss:0.24036\tval-mlogloss:0.24821\n",
      "[200]\ttrain-mlogloss:0.23519\tval-mlogloss:0.24423\n",
      "[249]\ttrain-mlogloss:0.23171\tval-mlogloss:0.24201\n",
      "Best val. mlogloss on fold0 = 0.242012\n",
      "New configuration: {'min_split_loss': 0.08756471885253754}\n",
      "[0]\ttrain-mlogloss:1.23596\tval-mlogloss:1.23553\n",
      "[50]\ttrain-mlogloss:0.27200\tval-mlogloss:0.27069\n",
      "[100]\ttrain-mlogloss:0.24861\tval-mlogloss:0.24914\n",
      "[150]\ttrain-mlogloss:0.24035\tval-mlogloss:0.24244\n",
      "[200]\ttrain-mlogloss:0.23521\tval-mlogloss:0.23886\n",
      "[249]\ttrain-mlogloss:0.23145\tval-mlogloss:0.23647\n",
      "Best val. mlogloss on fold1 = 0.236473\n",
      "New configuration: {'min_split_loss': 0.19426524167470555}\n",
      "[0]\ttrain-mlogloss:1.23573\tval-mlogloss:1.23597\n",
      "[50]\ttrain-mlogloss:0.27120\tval-mlogloss:0.27444\n",
      "[100]\ttrain-mlogloss:0.24807\tval-mlogloss:0.25250\n",
      "[150]\ttrain-mlogloss:0.24002\tval-mlogloss:0.24566\n",
      "[200]\ttrain-mlogloss:0.23505\tval-mlogloss:0.24204\n",
      "[249]\ttrain-mlogloss:0.23128\tval-mlogloss:0.23947\n",
      "Best val. mlogloss on fold3 = 0.239474\n",
      "New configuration: {'min_split_loss': 0.17807810284305262}\n",
      "[0]\ttrain-mlogloss:1.23590\tval-mlogloss:1.23631\n",
      "[50]\ttrain-mlogloss:0.27174\tval-mlogloss:0.27749\n",
      "[100]\ttrain-mlogloss:0.24862\tval-mlogloss:0.25533\n",
      "[150]\ttrain-mlogloss:0.24036\tval-mlogloss:0.24821\n",
      "[200]\ttrain-mlogloss:0.23519\tval-mlogloss:0.24423\n",
      "[249]\ttrain-mlogloss:0.23171\tval-mlogloss:0.24201\n",
      "Best val. mlogloss on fold0 = 0.242012\n",
      "New configuration: {'min_split_loss': 0.24191008098551975}\n",
      "[0]\ttrain-mlogloss:1.23590\tval-mlogloss:1.23631\n",
      "[50]\ttrain-mlogloss:0.27174\tval-mlogloss:0.27749\n",
      "[100]\ttrain-mlogloss:0.24862\tval-mlogloss:0.25533\n",
      "[150]\ttrain-mlogloss:0.24036\tval-mlogloss:0.24821\n",
      "[200]\ttrain-mlogloss:0.23519\tval-mlogloss:0.24423\n",
      "[249]\ttrain-mlogloss:0.23171\tval-mlogloss:0.24201\n",
      "Best val. mlogloss on fold0 = 0.242012\n",
      "New configuration: {'min_split_loss': 0.042301314665824326}\n",
      "[0]\ttrain-mlogloss:1.23573\tval-mlogloss:1.23597\n",
      "[50]\ttrain-mlogloss:0.27120\tval-mlogloss:0.27444\n",
      "[100]\ttrain-mlogloss:0.24807\tval-mlogloss:0.25250\n",
      "[150]\ttrain-mlogloss:0.24003\tval-mlogloss:0.24569\n",
      "[200]\ttrain-mlogloss:0.23502\tval-mlogloss:0.24200\n",
      "[249]\ttrain-mlogloss:0.23133\tval-mlogloss:0.23940\n",
      "Best val. mlogloss on fold3 = 0.239396\n",
      "New configuration: {'min_split_loss': 0.3607429845547082}\n",
      "[0]\ttrain-mlogloss:1.23573\tval-mlogloss:1.23597\n",
      "[50]\ttrain-mlogloss:0.27120\tval-mlogloss:0.27444\n",
      "[100]\ttrain-mlogloss:0.24807\tval-mlogloss:0.25250\n",
      "[150]\ttrain-mlogloss:0.24002\tval-mlogloss:0.24566\n",
      "[200]\ttrain-mlogloss:0.23505\tval-mlogloss:0.24204\n",
      "[249]\ttrain-mlogloss:0.23128\tval-mlogloss:0.23947\n",
      "Best val. mlogloss on fold3 = 0.239474\n",
      "New configuration: {'min_split_loss': 0.24318634922439644}\n",
      "[0]\ttrain-mlogloss:1.23573\tval-mlogloss:1.23597\n",
      "[50]\ttrain-mlogloss:0.27120\tval-mlogloss:0.27444\n",
      "[100]\ttrain-mlogloss:0.24807\tval-mlogloss:0.25250\n",
      "[150]\ttrain-mlogloss:0.24002\tval-mlogloss:0.24566\n",
      "[200]\ttrain-mlogloss:0.23505\tval-mlogloss:0.24204\n",
      "[249]\ttrain-mlogloss:0.23128\tval-mlogloss:0.23947\n",
      "Best val. mlogloss on fold3 = 0.239474\n",
      "New configuration: {'min_split_loss': 0.34468047467059804}\n",
      "[0]\ttrain-mlogloss:1.23617\tval-mlogloss:1.23540\n",
      "[50]\ttrain-mlogloss:0.27284\tval-mlogloss:0.26772\n",
      "[100]\ttrain-mlogloss:0.24930\tval-mlogloss:0.24542\n",
      "[150]\ttrain-mlogloss:0.24130\tval-mlogloss:0.23864\n",
      "[200]\ttrain-mlogloss:0.23625\tval-mlogloss:0.23490\n",
      "[249]\ttrain-mlogloss:0.23251\tval-mlogloss:0.23233\n",
      "Best val. mlogloss on fold2 = 0.232334\n",
      "New configuration: {'min_split_loss': 0.2434652742580537}\n",
      "[0]\ttrain-mlogloss:1.23573\tval-mlogloss:1.23597\n",
      "[50]\ttrain-mlogloss:0.27120\tval-mlogloss:0.27444\n",
      "[100]\ttrain-mlogloss:0.24807\tval-mlogloss:0.25250\n",
      "[150]\ttrain-mlogloss:0.24002\tval-mlogloss:0.24566\n",
      "[200]\ttrain-mlogloss:0.23505\tval-mlogloss:0.24204\n",
      "[249]\ttrain-mlogloss:0.23128\tval-mlogloss:0.23947\n",
      "Best val. mlogloss on fold3 = 0.239474\n",
      "New configuration: {'min_split_loss': 0.2636711028056439}\n",
      "[0]\ttrain-mlogloss:1.23617\tval-mlogloss:1.23540\n",
      "[50]\ttrain-mlogloss:0.27284\tval-mlogloss:0.26772\n",
      "[100]\ttrain-mlogloss:0.24930\tval-mlogloss:0.24542\n",
      "[150]\ttrain-mlogloss:0.24130\tval-mlogloss:0.23864\n",
      "[200]\ttrain-mlogloss:0.23625\tval-mlogloss:0.23490\n",
      "[249]\ttrain-mlogloss:0.23251\tval-mlogloss:0.23233\n",
      "Best val. mlogloss on fold2 = 0.232334\n",
      "New configuration: {'min_split_loss': 0.23934462281832541}\n",
      "[0]\ttrain-mlogloss:1.23617\tval-mlogloss:1.23540\n",
      "[50]\ttrain-mlogloss:0.27284\tval-mlogloss:0.26772\n",
      "[100]\ttrain-mlogloss:0.24930\tval-mlogloss:0.24542\n",
      "[150]\ttrain-mlogloss:0.24130\tval-mlogloss:0.23864\n",
      "[200]\ttrain-mlogloss:0.23625\tval-mlogloss:0.23490\n",
      "[249]\ttrain-mlogloss:0.23251\tval-mlogloss:0.23233\n",
      "Best val. mlogloss on fold2 = 0.232334\n",
      "New configuration: {'min_split_loss': 0.2121403543887735}\n",
      "[0]\ttrain-mlogloss:1.23617\tval-mlogloss:1.23540\n",
      "[50]\ttrain-mlogloss:0.27284\tval-mlogloss:0.26772\n",
      "[100]\ttrain-mlogloss:0.24930\tval-mlogloss:0.24542\n",
      "[150]\ttrain-mlogloss:0.24130\tval-mlogloss:0.23864\n",
      "[200]\ttrain-mlogloss:0.23625\tval-mlogloss:0.23490\n",
      "[249]\ttrain-mlogloss:0.23251\tval-mlogloss:0.23233\n",
      "Best val. mlogloss on fold2 = 0.232334\n",
      "New configuration: {'min_split_loss': 0.28508751862588144}\n",
      "[0]\ttrain-mlogloss:1.23596\tval-mlogloss:1.23553\n",
      "[50]\ttrain-mlogloss:0.27200\tval-mlogloss:0.27069\n",
      "[100]\ttrain-mlogloss:0.24861\tval-mlogloss:0.24914\n",
      "[150]\ttrain-mlogloss:0.24035\tval-mlogloss:0.24244\n",
      "[200]\ttrain-mlogloss:0.23521\tval-mlogloss:0.23886\n",
      "[249]\ttrain-mlogloss:0.23145\tval-mlogloss:0.23647\n",
      "Best val. mlogloss on fold1 = 0.236473\n",
      "New configuration: {'min_split_loss': 0.24544993594512737}\n",
      "[0]\ttrain-mlogloss:1.23596\tval-mlogloss:1.23553\n",
      "[50]\ttrain-mlogloss:0.27200\tval-mlogloss:0.27069\n",
      "[100]\ttrain-mlogloss:0.24861\tval-mlogloss:0.24914\n",
      "[150]\ttrain-mlogloss:0.24035\tval-mlogloss:0.24244\n",
      "[200]\ttrain-mlogloss:0.23521\tval-mlogloss:0.23886\n",
      "[249]\ttrain-mlogloss:0.23145\tval-mlogloss:0.23647\n",
      "Best val. mlogloss on fold1 = 0.236473\n",
      "New configuration: {'min_split_loss': 0.17540039016024786}\n",
      "[0]\ttrain-mlogloss:1.23596\tval-mlogloss:1.23553\n",
      "[50]\ttrain-mlogloss:0.27200\tval-mlogloss:0.27069\n",
      "[100]\ttrain-mlogloss:0.24861\tval-mlogloss:0.24914\n",
      "[150]\ttrain-mlogloss:0.24035\tval-mlogloss:0.24244\n",
      "[200]\ttrain-mlogloss:0.23521\tval-mlogloss:0.23886\n",
      "[249]\ttrain-mlogloss:0.23145\tval-mlogloss:0.23647\n",
      "Best val. mlogloss on fold1 = 0.236473\n",
      "New configuration: {'min_split_loss': 0.14086159255755162}\n",
      "[0]\ttrain-mlogloss:1.23573\tval-mlogloss:1.23597\n",
      "[50]\ttrain-mlogloss:0.27120\tval-mlogloss:0.27444\n",
      "[100]\ttrain-mlogloss:0.24807\tval-mlogloss:0.25250\n",
      "[150]\ttrain-mlogloss:0.24002\tval-mlogloss:0.24566\n",
      "[200]\ttrain-mlogloss:0.23505\tval-mlogloss:0.24204\n",
      "[249]\ttrain-mlogloss:0.23128\tval-mlogloss:0.23947\n",
      "Best val. mlogloss on fold3 = 0.239474\n",
      "New configuration: {'min_split_loss': 0.12088320740110617}\n",
      "[0]\ttrain-mlogloss:1.23596\tval-mlogloss:1.23553\n",
      "[50]\ttrain-mlogloss:0.27200\tval-mlogloss:0.27069\n",
      "[100]\ttrain-mlogloss:0.24861\tval-mlogloss:0.24914\n",
      "[150]\ttrain-mlogloss:0.24035\tval-mlogloss:0.24244\n",
      "[200]\ttrain-mlogloss:0.23521\tval-mlogloss:0.23886\n",
      "[249]\ttrain-mlogloss:0.23145\tval-mlogloss:0.23647\n",
      "Best val. mlogloss on fold1 = 0.236473\n",
      "New configuration: {'min_split_loss': 0.015413204893642011}\n",
      "[0]\ttrain-mlogloss:1.23573\tval-mlogloss:1.23597\n",
      "[50]\ttrain-mlogloss:0.27120\tval-mlogloss:0.27444\n",
      "[100]\ttrain-mlogloss:0.24807\tval-mlogloss:0.25250\n",
      "[150]\ttrain-mlogloss:0.24003\tval-mlogloss:0.24569\n",
      "[200]\ttrain-mlogloss:0.23502\tval-mlogloss:0.24200\n",
      "[249]\ttrain-mlogloss:0.23133\tval-mlogloss:0.23940\n",
      "Best val. mlogloss on fold3 = 0.239396\n",
      "New configuration: {'min_split_loss': 0.24240079211066726}\n",
      "[0]\ttrain-mlogloss:1.23617\tval-mlogloss:1.23540\n",
      "[50]\ttrain-mlogloss:0.27284\tval-mlogloss:0.26772\n",
      "[100]\ttrain-mlogloss:0.24930\tval-mlogloss:0.24542\n",
      "[150]\ttrain-mlogloss:0.24130\tval-mlogloss:0.23864\n",
      "[200]\ttrain-mlogloss:0.23625\tval-mlogloss:0.23490\n",
      "[249]\ttrain-mlogloss:0.23251\tval-mlogloss:0.23233\n",
      "Best val. mlogloss on fold2 = 0.232334\n",
      "New configuration: {'min_split_loss': 0.44824301728328314}\n",
      "[0]\ttrain-mlogloss:1.23596\tval-mlogloss:1.23553\n",
      "[50]\ttrain-mlogloss:0.27200\tval-mlogloss:0.27069\n",
      "[100]\ttrain-mlogloss:0.24861\tval-mlogloss:0.24914\n",
      "[150]\ttrain-mlogloss:0.24035\tval-mlogloss:0.24244\n",
      "[200]\ttrain-mlogloss:0.23521\tval-mlogloss:0.23886\n",
      "[249]\ttrain-mlogloss:0.23145\tval-mlogloss:0.23647\n",
      "Best val. mlogloss on fold1 = 0.236473\n",
      "New configuration: {'min_split_loss': 0.47922864934335113}\n",
      "[0]\ttrain-mlogloss:1.23617\tval-mlogloss:1.23540\n",
      "[50]\ttrain-mlogloss:0.27284\tval-mlogloss:0.26772\n",
      "[100]\ttrain-mlogloss:0.24930\tval-mlogloss:0.24542\n",
      "[150]\ttrain-mlogloss:0.24130\tval-mlogloss:0.23864\n",
      "[200]\ttrain-mlogloss:0.23625\tval-mlogloss:0.23490\n",
      "[249]\ttrain-mlogloss:0.23251\tval-mlogloss:0.23233\n",
      "Best val. mlogloss on fold2 = 0.232334\n",
      "New configuration: {'min_split_loss': 0.04716554890909215}\n",
      "[0]\ttrain-mlogloss:1.23596\tval-mlogloss:1.23553\n",
      "[50]\ttrain-mlogloss:0.27200\tval-mlogloss:0.27069\n",
      "[100]\ttrain-mlogloss:0.24861\tval-mlogloss:0.24914\n",
      "[150]\ttrain-mlogloss:0.24035\tval-mlogloss:0.24244\n",
      "[200]\ttrain-mlogloss:0.23521\tval-mlogloss:0.23886\n",
      "[249]\ttrain-mlogloss:0.23145\tval-mlogloss:0.23647\n",
      "Best val. mlogloss on fold1 = 0.236473\n",
      "New configuration: {'min_split_loss': 0.18953715235947388}\n",
      "[0]\ttrain-mlogloss:1.23573\tval-mlogloss:1.23597\n",
      "[50]\ttrain-mlogloss:0.27120\tval-mlogloss:0.27444\n",
      "[100]\ttrain-mlogloss:0.24807\tval-mlogloss:0.25250\n",
      "[150]\ttrain-mlogloss:0.24002\tval-mlogloss:0.24566\n",
      "[200]\ttrain-mlogloss:0.23505\tval-mlogloss:0.24204\n",
      "[249]\ttrain-mlogloss:0.23128\tval-mlogloss:0.23947\n",
      "Best val. mlogloss on fold3 = 0.239474\n",
      "New configuration: {'min_split_loss': 0.07091312185263493}\n",
      "[0]\ttrain-mlogloss:1.23596\tval-mlogloss:1.23553\n",
      "[50]\ttrain-mlogloss:0.27200\tval-mlogloss:0.27069\n",
      "[100]\ttrain-mlogloss:0.24861\tval-mlogloss:0.24914\n",
      "[150]\ttrain-mlogloss:0.24035\tval-mlogloss:0.24244\n",
      "[200]\ttrain-mlogloss:0.23521\tval-mlogloss:0.23886\n",
      "[249]\ttrain-mlogloss:0.23145\tval-mlogloss:0.23647\n",
      "Best val. mlogloss on fold1 = 0.236473\n",
      "New configuration: {'min_split_loss': 0.025640115625484523}\n",
      "[0]\ttrain-mlogloss:1.23573\tval-mlogloss:1.23597\n",
      "[50]\ttrain-mlogloss:0.27120\tval-mlogloss:0.27444\n",
      "[100]\ttrain-mlogloss:0.24807\tval-mlogloss:0.25250\n",
      "[150]\ttrain-mlogloss:0.24003\tval-mlogloss:0.24569\n",
      "[200]\ttrain-mlogloss:0.23502\tval-mlogloss:0.24200\n",
      "[249]\ttrain-mlogloss:0.23133\tval-mlogloss:0.23940\n",
      "Best val. mlogloss on fold3 = 0.239396\n",
      "New configuration: {'min_split_loss': 0.36493176483826884}\n",
      "[0]\ttrain-mlogloss:1.23573\tval-mlogloss:1.23597\n",
      "[50]\ttrain-mlogloss:0.27120\tval-mlogloss:0.27444\n",
      "[100]\ttrain-mlogloss:0.24807\tval-mlogloss:0.25250\n",
      "[150]\ttrain-mlogloss:0.24002\tval-mlogloss:0.24566\n",
      "[200]\ttrain-mlogloss:0.23505\tval-mlogloss:0.24204\n",
      "[249]\ttrain-mlogloss:0.23128\tval-mlogloss:0.23947\n",
      "Best val. mlogloss on fold3 = 0.239474\n",
      "New configuration: {'min_split_loss': 0.1616540764390524}\n",
      "[0]\ttrain-mlogloss:1.23590\tval-mlogloss:1.23631\n",
      "[50]\ttrain-mlogloss:0.27174\tval-mlogloss:0.27749\n",
      "[100]\ttrain-mlogloss:0.24862\tval-mlogloss:0.25533\n",
      "[150]\ttrain-mlogloss:0.24036\tval-mlogloss:0.24821\n",
      "[200]\ttrain-mlogloss:0.23519\tval-mlogloss:0.24423\n",
      "[249]\ttrain-mlogloss:0.23171\tval-mlogloss:0.24201\n",
      "Best val. mlogloss on fold0 = 0.242012\n",
      "New configuration: {'min_split_loss': 0.3321314924345558}\n",
      "[0]\ttrain-mlogloss:1.23596\tval-mlogloss:1.23553\n",
      "[50]\ttrain-mlogloss:0.27200\tval-mlogloss:0.27069\n",
      "[100]\ttrain-mlogloss:0.24861\tval-mlogloss:0.24914\n",
      "[150]\ttrain-mlogloss:0.24035\tval-mlogloss:0.24244\n",
      "[200]\ttrain-mlogloss:0.23521\tval-mlogloss:0.23886\n",
      "[249]\ttrain-mlogloss:0.23145\tval-mlogloss:0.23647\n",
      "Best val. mlogloss on fold1 = 0.236473\n",
      "New configuration: {'min_split_loss': 0.34972034034420485}\n",
      "[0]\ttrain-mlogloss:1.23573\tval-mlogloss:1.23597\n",
      "[50]\ttrain-mlogloss:0.27120\tval-mlogloss:0.27444\n",
      "[100]\ttrain-mlogloss:0.24807\tval-mlogloss:0.25250\n",
      "[150]\ttrain-mlogloss:0.24002\tval-mlogloss:0.24566\n",
      "[200]\ttrain-mlogloss:0.23505\tval-mlogloss:0.24204\n",
      "[249]\ttrain-mlogloss:0.23128\tval-mlogloss:0.23947\n",
      "Best val. mlogloss on fold3 = 0.239474\n",
      "New configuration: {'min_split_loss': 0.15351185810118248}\n",
      "[0]\ttrain-mlogloss:1.23617\tval-mlogloss:1.23540\n",
      "[50]\ttrain-mlogloss:0.27284\tval-mlogloss:0.26772\n",
      "[100]\ttrain-mlogloss:0.24930\tval-mlogloss:0.24542\n",
      "[150]\ttrain-mlogloss:0.24130\tval-mlogloss:0.23864\n",
      "[200]\ttrain-mlogloss:0.23628\tval-mlogloss:0.23496\n",
      "[249]\ttrain-mlogloss:0.23256\tval-mlogloss:0.23244\n",
      "Best val. mlogloss on fold2 = 0.232444\n",
      "New configuration: {'min_split_loss': 0.22391051815893193}\n",
      "[0]\ttrain-mlogloss:1.23573\tval-mlogloss:1.23597\n",
      "[50]\ttrain-mlogloss:0.27120\tval-mlogloss:0.27444\n",
      "[100]\ttrain-mlogloss:0.24807\tval-mlogloss:0.25250\n",
      "[150]\ttrain-mlogloss:0.24002\tval-mlogloss:0.24566\n",
      "[200]\ttrain-mlogloss:0.23505\tval-mlogloss:0.24204\n",
      "[249]\ttrain-mlogloss:0.23128\tval-mlogloss:0.23947\n",
      "Best val. mlogloss on fold3 = 0.239474\n",
      "New configuration: {'min_split_loss': 0.49459168276794263}\n",
      "[0]\ttrain-mlogloss:1.23590\tval-mlogloss:1.23631\n",
      "[50]\ttrain-mlogloss:0.27174\tval-mlogloss:0.27749\n",
      "[100]\ttrain-mlogloss:0.24862\tval-mlogloss:0.25533\n",
      "[150]\ttrain-mlogloss:0.24036\tval-mlogloss:0.24821\n",
      "[200]\ttrain-mlogloss:0.23519\tval-mlogloss:0.24423\n",
      "[249]\ttrain-mlogloss:0.23171\tval-mlogloss:0.24201\n",
      "Best val. mlogloss on fold0 = 0.242012\n",
      "New configuration: {'min_split_loss': 0.036566566073576785}\n",
      "[0]\ttrain-mlogloss:1.23596\tval-mlogloss:1.23553\n",
      "[50]\ttrain-mlogloss:0.27200\tval-mlogloss:0.27069\n",
      "[100]\ttrain-mlogloss:0.24861\tval-mlogloss:0.24914\n",
      "[150]\ttrain-mlogloss:0.24035\tval-mlogloss:0.24244\n",
      "[200]\ttrain-mlogloss:0.23521\tval-mlogloss:0.23886\n",
      "[249]\ttrain-mlogloss:0.23145\tval-mlogloss:0.23647\n",
      "Best val. mlogloss on fold1 = 0.236473\n",
      "New configuration: {'min_split_loss': 0.3929375442238576}\n",
      "[0]\ttrain-mlogloss:1.23573\tval-mlogloss:1.23597\n",
      "[50]\ttrain-mlogloss:0.27120\tval-mlogloss:0.27444\n",
      "[100]\ttrain-mlogloss:0.24807\tval-mlogloss:0.25250\n",
      "[150]\ttrain-mlogloss:0.24002\tval-mlogloss:0.24566\n",
      "[200]\ttrain-mlogloss:0.23505\tval-mlogloss:0.24204\n",
      "[249]\ttrain-mlogloss:0.23128\tval-mlogloss:0.23947\n",
      "Best val. mlogloss on fold3 = 0.239474\n",
      "New configuration: {'min_split_loss': 0.23887348747740583}\n",
      "[0]\ttrain-mlogloss:1.23590\tval-mlogloss:1.23631\n",
      "[50]\ttrain-mlogloss:0.27174\tval-mlogloss:0.27749\n",
      "[100]\ttrain-mlogloss:0.24862\tval-mlogloss:0.25533\n",
      "[150]\ttrain-mlogloss:0.24036\tval-mlogloss:0.24821\n",
      "[200]\ttrain-mlogloss:0.23519\tval-mlogloss:0.24423\n",
      "[249]\ttrain-mlogloss:0.23171\tval-mlogloss:0.24201\n",
      "Best val. mlogloss on fold0 = 0.242012\n",
      "New configuration: {'min_split_loss': 0.23678567867399555}\n",
      "[0]\ttrain-mlogloss:1.23596\tval-mlogloss:1.23553\n",
      "[50]\ttrain-mlogloss:0.27200\tval-mlogloss:0.27069\n",
      "[100]\ttrain-mlogloss:0.24861\tval-mlogloss:0.24914\n",
      "[150]\ttrain-mlogloss:0.24035\tval-mlogloss:0.24244\n",
      "[200]\ttrain-mlogloss:0.23521\tval-mlogloss:0.23886\n",
      "[249]\ttrain-mlogloss:0.23145\tval-mlogloss:0.23647\n",
      "Best val. mlogloss on fold1 = 0.236473\n",
      "New configuration: {'min_split_loss': 0.29773763297898886}\n",
      "[0]\ttrain-mlogloss:1.23590\tval-mlogloss:1.23631\n",
      "[50]\ttrain-mlogloss:0.27174\tval-mlogloss:0.27749\n",
      "[100]\ttrain-mlogloss:0.24862\tval-mlogloss:0.25533\n",
      "[150]\ttrain-mlogloss:0.24036\tval-mlogloss:0.24821\n",
      "[200]\ttrain-mlogloss:0.23519\tval-mlogloss:0.24423\n",
      "[249]\ttrain-mlogloss:0.23171\tval-mlogloss:0.24201\n",
      "Best val. mlogloss on fold0 = 0.242012\n",
      "New configuration: {'min_split_loss': 0.19826116365654106}\n",
      "[0]\ttrain-mlogloss:1.23573\tval-mlogloss:1.23597\n",
      "[50]\ttrain-mlogloss:0.27120\tval-mlogloss:0.27444\n",
      "[100]\ttrain-mlogloss:0.24807\tval-mlogloss:0.25250\n",
      "[150]\ttrain-mlogloss:0.24002\tval-mlogloss:0.24566\n",
      "[200]\ttrain-mlogloss:0.23505\tval-mlogloss:0.24204\n",
      "[249]\ttrain-mlogloss:0.23128\tval-mlogloss:0.23947\n",
      "Best val. mlogloss on fold3 = 0.239474\n",
      "New configuration: {'min_split_loss': 0.23813841745659403}\n",
      "[0]\ttrain-mlogloss:1.23617\tval-mlogloss:1.23540\n",
      "[50]\ttrain-mlogloss:0.27284\tval-mlogloss:0.26772\n",
      "[100]\ttrain-mlogloss:0.24930\tval-mlogloss:0.24542\n",
      "[150]\ttrain-mlogloss:0.24130\tval-mlogloss:0.23864\n",
      "[200]\ttrain-mlogloss:0.23625\tval-mlogloss:0.23490\n",
      "[249]\ttrain-mlogloss:0.23251\tval-mlogloss:0.23233\n",
      "Best val. mlogloss on fold2 = 0.232334\n",
      "New configuration: {'min_split_loss': 0.2945537697307722}\n",
      "[0]\ttrain-mlogloss:1.23590\tval-mlogloss:1.23631\n",
      "[50]\ttrain-mlogloss:0.27174\tval-mlogloss:0.27749\n",
      "[100]\ttrain-mlogloss:0.24862\tval-mlogloss:0.25533\n",
      "[150]\ttrain-mlogloss:0.24036\tval-mlogloss:0.24821\n",
      "[200]\ttrain-mlogloss:0.23519\tval-mlogloss:0.24423\n",
      "[249]\ttrain-mlogloss:0.23171\tval-mlogloss:0.24201\n",
      "Best val. mlogloss on fold0 = 0.242012\n",
      "New configuration: {'min_split_loss': 0.3022813115691691}\n",
      "[0]\ttrain-mlogloss:1.23596\tval-mlogloss:1.23553\n",
      "[50]\ttrain-mlogloss:0.27200\tval-mlogloss:0.27069\n",
      "[100]\ttrain-mlogloss:0.24861\tval-mlogloss:0.24914\n",
      "[150]\ttrain-mlogloss:0.24035\tval-mlogloss:0.24244\n",
      "[200]\ttrain-mlogloss:0.23521\tval-mlogloss:0.23886\n",
      "[249]\ttrain-mlogloss:0.23145\tval-mlogloss:0.23647\n",
      "Best val. mlogloss on fold1 = 0.236473\n",
      "Optimizing subsample (fraction of training events) and colsample_bytree (fraction of training features per tree)\n",
      "New configuration: {'subsample': 0.17214433354208042, 'colsample_bytree': 0.5905886377836497}\n",
      "[0]\ttrain-mlogloss:1.23934\tval-mlogloss:1.23867\n",
      "[50]\ttrain-mlogloss:0.27317\tval-mlogloss:0.26804\n",
      "[100]\ttrain-mlogloss:0.24832\tval-mlogloss:0.24418\n",
      "[150]\ttrain-mlogloss:0.24088\tval-mlogloss:0.23793\n",
      "[200]\ttrain-mlogloss:0.23628\tval-mlogloss:0.23475\n",
      "[249]\ttrain-mlogloss:0.23314\tval-mlogloss:0.23291\n",
      "Best val. mlogloss on fold2 = 0.232914\n",
      "New configuration: {'subsample': 0.3552435587114033, 'colsample_bytree': 0.7243297604556704}\n",
      "[0]\ttrain-mlogloss:1.23897\tval-mlogloss:1.23860\n",
      "[50]\ttrain-mlogloss:0.27189\tval-mlogloss:0.27064\n",
      "[100]\ttrain-mlogloss:0.24831\tval-mlogloss:0.24864\n",
      "[150]\ttrain-mlogloss:0.23986\tval-mlogloss:0.24189\n",
      "[200]\ttrain-mlogloss:0.23497\tval-mlogloss:0.23856\n",
      "[249]\ttrain-mlogloss:0.23149\tval-mlogloss:0.23653\n",
      "Best val. mlogloss on fold1 = 0.236528\n",
      "New configuration: {'subsample': 0.3223256064167364, 'colsample_bytree': 0.8481670071250391}\n",
      "[0]\ttrain-mlogloss:1.23606\tval-mlogloss:1.23524\n",
      "[50]\ttrain-mlogloss:0.27257\tval-mlogloss:0.26703\n",
      "[100]\ttrain-mlogloss:0.24906\tval-mlogloss:0.24482\n",
      "[150]\ttrain-mlogloss:0.24097\tval-mlogloss:0.23802\n",
      "[200]\ttrain-mlogloss:0.23608\tval-mlogloss:0.23432\n",
      "[249]\ttrain-mlogloss:0.23245\tval-mlogloss:0.23186\n",
      "Best val. mlogloss on fold2 = 0.231857\n",
      "New configuration: {'subsample': 0.11572614992316375, 'colsample_bytree': 0.7232692942843472}\n",
      "[0]\ttrain-mlogloss:1.23895\tval-mlogloss:1.23834\n",
      "[50]\ttrain-mlogloss:0.27209\tval-mlogloss:0.26674\n",
      "[100]\ttrain-mlogloss:0.24848\tval-mlogloss:0.24434\n",
      "[150]\ttrain-mlogloss:0.24116\tval-mlogloss:0.23854\n",
      "[200]\ttrain-mlogloss:0.23688\tval-mlogloss:0.23558\n",
      "[249]\ttrain-mlogloss:0.23375\tval-mlogloss:0.23374\n",
      "Best val. mlogloss on fold2 = 0.233736\n",
      "New configuration: {'subsample': 0.3601645225024573, 'colsample_bytree': 0.8540387868679469}\n",
      "[0]\ttrain-mlogloss:1.23617\tval-mlogloss:1.23574\n",
      "[50]\ttrain-mlogloss:0.27193\tval-mlogloss:0.27064\n",
      "[100]\ttrain-mlogloss:0.24845\tval-mlogloss:0.24879\n",
      "[150]\ttrain-mlogloss:0.23994\tval-mlogloss:0.24206\n",
      "[200]\ttrain-mlogloss:0.23505\tval-mlogloss:0.23879\n",
      "[249]\ttrain-mlogloss:0.23146\tval-mlogloss:0.23674\n",
      "Best val. mlogloss on fold1 = 0.236741\n",
      "New configuration: {'subsample': 0.34125145518075295, 'colsample_bytree': 0.8839494540392394}\n",
      "[0]\ttrain-mlogloss:1.23617\tval-mlogloss:1.23578\n",
      "[50]\ttrain-mlogloss:0.27196\tval-mlogloss:0.27053\n",
      "[100]\ttrain-mlogloss:0.24863\tval-mlogloss:0.24901\n",
      "[150]\ttrain-mlogloss:0.24033\tval-mlogloss:0.24242\n",
      "[200]\ttrain-mlogloss:0.23520\tval-mlogloss:0.23883\n",
      "[249]\ttrain-mlogloss:0.23153\tval-mlogloss:0.23658\n",
      "Best val. mlogloss on fold1 = 0.236577\n",
      "New configuration: {'subsample': 0.15218321945666485, 'colsample_bytree': 0.7045082193883907}\n",
      "[0]\ttrain-mlogloss:1.23923\tval-mlogloss:1.23883\n",
      "[50]\ttrain-mlogloss:0.27174\tval-mlogloss:0.26987\n",
      "[100]\ttrain-mlogloss:0.24780\tval-mlogloss:0.24796\n",
      "[150]\ttrain-mlogloss:0.24017\tval-mlogloss:0.24213\n",
      "[200]\ttrain-mlogloss:0.23570\tval-mlogloss:0.23907\n",
      "[249]\ttrain-mlogloss:0.23233\tval-mlogloss:0.23714\n",
      "Best val. mlogloss on fold1 = 0.237145\n",
      "New configuration: {'subsample': 0.15615501567738266, 'colsample_bytree': 0.46198150388738934}\n",
      "[0]\ttrain-mlogloss:1.23930\tval-mlogloss:1.23974\n",
      "[50]\ttrain-mlogloss:0.27667\tval-mlogloss:0.28217\n",
      "[100]\ttrain-mlogloss:0.24913\tval-mlogloss:0.25549\n",
      "[150]\ttrain-mlogloss:0.24102\tval-mlogloss:0.24841\n",
      "[200]\ttrain-mlogloss:0.23650\tval-mlogloss:0.24499\n",
      "[249]\ttrain-mlogloss:0.23325\tval-mlogloss:0.24300\n",
      "Best val. mlogloss on fold0 = 0.243004\n",
      "New configuration: {'subsample': 0.11535183098199839, 'colsample_bytree': 0.4709773163895633}\n",
      "[0]\ttrain-mlogloss:1.23846\tval-mlogloss:1.23859\n",
      "[50]\ttrain-mlogloss:0.27619\tval-mlogloss:0.27878\n",
      "[100]\ttrain-mlogloss:0.24921\tval-mlogloss:0.25296\n",
      "[150]\ttrain-mlogloss:0.24132\tval-mlogloss:0.24631\n",
      "[200]\ttrain-mlogloss:0.23682\tval-mlogloss:0.24300\n",
      "[249]\ttrain-mlogloss:0.23373\tval-mlogloss:0.24094\n",
      "Best val. mlogloss on fold3 = 0.240939\n",
      "New configuration: {'subsample': 0.44614560078220694, 'colsample_bytree': 0.3021163578545276}\n",
      "[0]\ttrain-mlogloss:1.24655\tval-mlogloss:1.24587\n",
      "[50]\ttrain-mlogloss:0.29072\tval-mlogloss:0.28595\n",
      "[100]\ttrain-mlogloss:0.25499\tval-mlogloss:0.25088\n",
      "[150]\ttrain-mlogloss:0.24428\tval-mlogloss:0.24101\n",
      "[200]\ttrain-mlogloss:0.23871\tval-mlogloss:0.23660\n",
      "[249]\ttrain-mlogloss:0.23517\tval-mlogloss:0.23421\n",
      "Best val. mlogloss on fold2 = 0.234213\n",
      "New configuration: {'subsample': 0.2339240470435379, 'colsample_bytree': 0.44511122071536185}\n",
      "[0]\ttrain-mlogloss:1.23870\tval-mlogloss:1.23889\n",
      "[50]\ttrain-mlogloss:0.27754\tval-mlogloss:0.28002\n",
      "[100]\ttrain-mlogloss:0.24940\tval-mlogloss:0.25320\n",
      "[150]\ttrain-mlogloss:0.24104\tval-mlogloss:0.24604\n",
      "[200]\ttrain-mlogloss:0.23622\tval-mlogloss:0.24241\n",
      "[249]\ttrain-mlogloss:0.23300\tval-mlogloss:0.24016\n",
      "Best val. mlogloss on fold3 = 0.240157\n",
      "New configuration: {'subsample': 0.1166808737178913, 'colsample_bytree': 0.38856700441224873}\n",
      "[0]\ttrain-mlogloss:1.24267\tval-mlogloss:1.24201\n",
      "[50]\ttrain-mlogloss:0.28179\tval-mlogloss:0.27665\n",
      "[100]\ttrain-mlogloss:0.25142\tval-mlogloss:0.24700\n",
      "[150]\ttrain-mlogloss:0.24331\tval-mlogloss:0.24004\n",
      "[200]\ttrain-mlogloss:0.23869\tval-mlogloss:0.23674\n",
      "[249]\ttrain-mlogloss:0.23550\tval-mlogloss:0.23459\n",
      "Best val. mlogloss on fold2 = 0.234595\n",
      "New configuration: {'subsample': 0.25042988936399535, 'colsample_bytree': 0.5137809930817399}\n",
      "[0]\ttrain-mlogloss:1.23900\tval-mlogloss:1.23830\n",
      "[50]\ttrain-mlogloss:0.27593\tval-mlogloss:0.27078\n",
      "[100]\ttrain-mlogloss:0.24968\tval-mlogloss:0.24555\n",
      "[150]\ttrain-mlogloss:0.24185\tval-mlogloss:0.23896\n",
      "[200]\ttrain-mlogloss:0.23713\tval-mlogloss:0.23561\n",
      "[249]\ttrain-mlogloss:0.23389\tval-mlogloss:0.23359\n",
      "Best val. mlogloss on fold2 = 0.233587\n",
      "New configuration: {'subsample': 0.15615499215469283, 'colsample_bytree': 0.4619815323283958}\n",
      "[0]\ttrain-mlogloss:1.23857\tval-mlogloss:1.23876\n",
      "[50]\ttrain-mlogloss:0.27636\tval-mlogloss:0.27897\n",
      "[100]\ttrain-mlogloss:0.24895\tval-mlogloss:0.25272\n",
      "[150]\ttrain-mlogloss:0.24096\tval-mlogloss:0.24580\n",
      "[200]\ttrain-mlogloss:0.23641\tval-mlogloss:0.24268\n",
      "[249]\ttrain-mlogloss:0.23304\tval-mlogloss:0.24044\n",
      "Best val. mlogloss on fold3 = 0.240445\n",
      "New configuration: {'subsample': 0.4256759319043934, 'colsample_bytree': 0.6562298483249125}\n",
      "[0]\ttrain-mlogloss:1.23900\tval-mlogloss:1.23863\n",
      "[50]\ttrain-mlogloss:0.27219\tval-mlogloss:0.27077\n",
      "[100]\ttrain-mlogloss:0.24835\tval-mlogloss:0.24858\n",
      "[150]\ttrain-mlogloss:0.23989\tval-mlogloss:0.24166\n",
      "[200]\ttrain-mlogloss:0.23499\tval-mlogloss:0.23830\n",
      "[249]\ttrain-mlogloss:0.23161\tval-mlogloss:0.23630\n",
      "Best val. mlogloss on fold1 = 0.236301\n",
      "New configuration: {'subsample': 0.4986961226530504, 'colsample_bytree': 0.7825755902912173}\n",
      "[0]\ttrain-mlogloss:1.23617\tval-mlogloss:1.23541\n",
      "[50]\ttrain-mlogloss:0.27265\tval-mlogloss:0.26766\n",
      "[100]\ttrain-mlogloss:0.24925\tval-mlogloss:0.24546\n",
      "[150]\ttrain-mlogloss:0.24124\tval-mlogloss:0.23869\n",
      "[200]\ttrain-mlogloss:0.23601\tval-mlogloss:0.23473\n",
      "[249]\ttrain-mlogloss:0.23240\tval-mlogloss:0.23231\n",
      "Best val. mlogloss on fold2 = 0.232311\n",
      "New configuration: {'subsample': 0.3729478968893292, 'colsample_bytree': 0.4569687495049248}\n",
      "[0]\ttrain-mlogloss:1.23897\tval-mlogloss:1.23944\n",
      "[50]\ttrain-mlogloss:0.27694\tval-mlogloss:0.28257\n",
      "[100]\ttrain-mlogloss:0.24932\tval-mlogloss:0.25598\n",
      "[150]\ttrain-mlogloss:0.24115\tval-mlogloss:0.24887\n",
      "[200]\ttrain-mlogloss:0.23618\tval-mlogloss:0.24493\n",
      "[249]\ttrain-mlogloss:0.23290\tval-mlogloss:0.24268\n",
      "Best val. mlogloss on fold0 = 0.242683\n",
      "New configuration: {'subsample': 0.2018760398633783, 'colsample_bytree': 0.3454003540653413}\n",
      "[0]\ttrain-mlogloss:1.24375\tval-mlogloss:1.24435\n",
      "[50]\ttrain-mlogloss:0.28647\tval-mlogloss:0.29115\n",
      "[100]\ttrain-mlogloss:0.25261\tval-mlogloss:0.25852\n",
      "[150]\ttrain-mlogloss:0.24282\tval-mlogloss:0.24973\n",
      "[200]\ttrain-mlogloss:0.23776\tval-mlogloss:0.24575\n",
      "[249]\ttrain-mlogloss:0.23449\tval-mlogloss:0.24355\n",
      "Best val. mlogloss on fold0 = 0.243548\n",
      "New configuration: {'subsample': 0.4173915263165419, 'colsample_bytree': 0.3616157105348154}\n",
      "[0]\ttrain-mlogloss:1.24189\tval-mlogloss:1.24248\n",
      "[50]\ttrain-mlogloss:0.28453\tval-mlogloss:0.28976\n",
      "[100]\ttrain-mlogloss:0.25197\tval-mlogloss:0.25838\n",
      "[150]\ttrain-mlogloss:0.24226\tval-mlogloss:0.24979\n",
      "[200]\ttrain-mlogloss:0.23712\tval-mlogloss:0.24564\n",
      "[249]\ttrain-mlogloss:0.23372\tval-mlogloss:0.24320\n",
      "Best val. mlogloss on fold0 = 0.243203\n",
      "New configuration: {'subsample': 0.17386080159563577, 'colsample_bytree': 0.5518406981089501}\n",
      "[0]\ttrain-mlogloss:1.23932\tval-mlogloss:1.23865\n",
      "[50]\ttrain-mlogloss:0.27461\tval-mlogloss:0.26950\n",
      "[100]\ttrain-mlogloss:0.24883\tval-mlogloss:0.24462\n",
      "[150]\ttrain-mlogloss:0.24130\tval-mlogloss:0.23835\n",
      "[200]\ttrain-mlogloss:0.23664\tval-mlogloss:0.23492\n",
      "[249]\ttrain-mlogloss:0.23346\tval-mlogloss:0.23298\n",
      "Best val. mlogloss on fold2 = 0.232976\n",
      "New configuration: {'subsample': 0.19433006004368983, 'colsample_bytree': 0.625518625517367}\n",
      "[0]\ttrain-mlogloss:1.23898\tval-mlogloss:1.23951\n",
      "[50]\ttrain-mlogloss:0.27173\tval-mlogloss:0.27723\n",
      "[100]\ttrain-mlogloss:0.24780\tval-mlogloss:0.25401\n",
      "[150]\ttrain-mlogloss:0.24009\tval-mlogloss:0.24750\n",
      "[200]\ttrain-mlogloss:0.23549\tval-mlogloss:0.24429\n",
      "[249]\ttrain-mlogloss:0.23216\tval-mlogloss:0.24233\n",
      "Best val. mlogloss on fold0 = 0.242328\n",
      "New configuration: {'subsample': 0.19042944737433792, 'colsample_bytree': 0.42060894914141295}\n",
      "[0]\ttrain-mlogloss:1.24266\tval-mlogloss:1.24321\n",
      "[50]\ttrain-mlogloss:0.28022\tval-mlogloss:0.28546\n",
      "[100]\ttrain-mlogloss:0.25046\tval-mlogloss:0.25655\n",
      "[150]\ttrain-mlogloss:0.24191\tval-mlogloss:0.24897\n",
      "[200]\ttrain-mlogloss:0.23696\tval-mlogloss:0.24527\n",
      "[249]\ttrain-mlogloss:0.23369\tval-mlogloss:0.24321\n",
      "Best val. mlogloss on fold0 = 0.243205\n",
      "New configuration: {'subsample': 0.40727296033474036, 'colsample_bytree': 0.3291289729069493}\n",
      "[0]\ttrain-mlogloss:1.24375\tval-mlogloss:1.24308\n",
      "[50]\ttrain-mlogloss:0.28752\tval-mlogloss:0.28288\n",
      "[100]\ttrain-mlogloss:0.25346\tval-mlogloss:0.24961\n",
      "[150]\ttrain-mlogloss:0.24340\tval-mlogloss:0.24052\n",
      "[200]\ttrain-mlogloss:0.23819\tval-mlogloss:0.23646\n",
      "[249]\ttrain-mlogloss:0.23471\tval-mlogloss:0.23402\n",
      "Best val. mlogloss on fold2 = 0.234015\n",
      "New configuration: {'subsample': 0.13111171343340342, 'colsample_bytree': 0.3533976544611258}\n",
      "[0]\ttrain-mlogloss:1.24207\tval-mlogloss:1.24133\n",
      "[50]\ttrain-mlogloss:0.28518\tval-mlogloss:0.27987\n",
      "[100]\ttrain-mlogloss:0.25263\tval-mlogloss:0.24811\n",
      "[150]\ttrain-mlogloss:0.24369\tval-mlogloss:0.24022\n",
      "[200]\ttrain-mlogloss:0.23891\tval-mlogloss:0.23663\n",
      "[249]\ttrain-mlogloss:0.23560\tval-mlogloss:0.23443\n",
      "Best val. mlogloss on fold2 = 0.234426\n",
      "New configuration: {'subsample': 0.28138399706218314, 'colsample_bytree': 0.386889659326784}\n",
      "[0]\ttrain-mlogloss:1.24209\tval-mlogloss:1.24174\n",
      "[50]\ttrain-mlogloss:0.28179\tval-mlogloss:0.28027\n",
      "[100]\ttrain-mlogloss:0.25127\tval-mlogloss:0.25116\n",
      "[150]\ttrain-mlogloss:0.24182\tval-mlogloss:0.24312\n",
      "[200]\ttrain-mlogloss:0.23685\tval-mlogloss:0.23956\n",
      "[249]\ttrain-mlogloss:0.23339\tval-mlogloss:0.23723\n",
      "Best val. mlogloss on fold1 = 0.237229\n",
      "New configuration: {'subsample': 0.17698164827672822, 'colsample_bytree': 0.8999473511833638}\n",
      "[0]\ttrain-mlogloss:1.23612\tval-mlogloss:1.23526\n",
      "[50]\ttrain-mlogloss:0.27245\tval-mlogloss:0.26651\n",
      "[100]\ttrain-mlogloss:0.24936\tval-mlogloss:0.24471\n",
      "[150]\ttrain-mlogloss:0.24140\tval-mlogloss:0.23811\n",
      "[200]\ttrain-mlogloss:0.23660\tval-mlogloss:0.23474\n",
      "[249]\ttrain-mlogloss:0.23307\tval-mlogloss:0.23285\n",
      "Best val. mlogloss on fold2 = 0.232852\n",
      "New configuration: {'subsample': 0.1134139881011312, 'colsample_bytree': 0.4253050797701632}\n",
      "[0]\ttrain-mlogloss:1.23925\tval-mlogloss:1.23865\n",
      "[50]\ttrain-mlogloss:0.27802\tval-mlogloss:0.27278\n",
      "[100]\ttrain-mlogloss:0.25000\tval-mlogloss:0.24555\n",
      "[150]\ttrain-mlogloss:0.24242\tval-mlogloss:0.23934\n",
      "[200]\ttrain-mlogloss:0.23803\tval-mlogloss:0.23635\n",
      "[249]\ttrain-mlogloss:0.23508\tval-mlogloss:0.23447\n",
      "Best val. mlogloss on fold2 = 0.234472\n",
      "New configuration: {'subsample': 0.1977441270415788, 'colsample_bytree': 0.3004502841792876}\n",
      "[0]\ttrain-mlogloss:1.24623\tval-mlogloss:1.24704\n",
      "[50]\ttrain-mlogloss:0.28936\tval-mlogloss:0.29399\n",
      "[100]\ttrain-mlogloss:0.25396\tval-mlogloss:0.25974\n",
      "[150]\ttrain-mlogloss:0.24374\tval-mlogloss:0.25041\n",
      "[200]\ttrain-mlogloss:0.23848\tval-mlogloss:0.24628\n",
      "[249]\ttrain-mlogloss:0.23511\tval-mlogloss:0.24388\n",
      "Best val. mlogloss on fold0 = 0.243884\n",
      "New configuration: {'subsample': 0.21173475154342716, 'colsample_bytree': 0.8539671659837327}\n",
      "[0]\ttrain-mlogloss:1.23645\tval-mlogloss:1.23691\n",
      "[50]\ttrain-mlogloss:0.27148\tval-mlogloss:0.27730\n",
      "[100]\ttrain-mlogloss:0.24861\tval-mlogloss:0.25558\n",
      "[150]\ttrain-mlogloss:0.24053\tval-mlogloss:0.24863\n",
      "[200]\ttrain-mlogloss:0.23566\tval-mlogloss:0.24507\n",
      "[249]\ttrain-mlogloss:0.23208\tval-mlogloss:0.24278\n",
      "Best val. mlogloss on fold0 = 0.242781\n",
      "New configuration: {'subsample': 0.1000347427218882, 'colsample_bytree': 0.7798357046627671}\n",
      "[0]\ttrain-mlogloss:1.23623\tval-mlogloss:1.23580\n",
      "[50]\ttrain-mlogloss:0.27157\tval-mlogloss:0.26972\n",
      "[100]\ttrain-mlogloss:0.24825\tval-mlogloss:0.24818\n",
      "[150]\ttrain-mlogloss:0.24073\tval-mlogloss:0.24238\n",
      "[200]\ttrain-mlogloss:0.23622\tval-mlogloss:0.23975\n",
      "[249]\ttrain-mlogloss:0.23294\tval-mlogloss:0.23820\n",
      "Best val. mlogloss on fold1 = 0.238202\n",
      "New configuration: {'subsample': 0.20335976917950513, 'colsample_bytree': 0.8553397738339643}\n",
      "[0]\ttrain-mlogloss:1.23639\tval-mlogloss:1.23554\n",
      "[50]\ttrain-mlogloss:0.27263\tval-mlogloss:0.26703\n",
      "[100]\ttrain-mlogloss:0.24961\tval-mlogloss:0.24523\n",
      "[150]\ttrain-mlogloss:0.24156\tval-mlogloss:0.23853\n",
      "[200]\ttrain-mlogloss:0.23659\tval-mlogloss:0.23511\n",
      "[249]\ttrain-mlogloss:0.23307\tval-mlogloss:0.23304\n",
      "Best val. mlogloss on fold2 = 0.233036\n",
      "New configuration: {'subsample': 0.2092899701594225, 'colsample_bytree': 0.3038875413620552}\n",
      "[0]\ttrain-mlogloss:1.24577\tval-mlogloss:1.24557\n",
      "[50]\ttrain-mlogloss:0.28905\tval-mlogloss:0.29113\n",
      "[100]\ttrain-mlogloss:0.25377\tval-mlogloss:0.25690\n",
      "[150]\ttrain-mlogloss:0.24358\tval-mlogloss:0.24791\n",
      "[200]\ttrain-mlogloss:0.23822\tval-mlogloss:0.24369\n",
      "[249]\ttrain-mlogloss:0.23483\tval-mlogloss:0.24140\n",
      "Best val. mlogloss on fold3 = 0.2414\n",
      "New configuration: {'subsample': 0.19505083083496033, 'colsample_bytree': 0.30919546332663894}\n",
      "[0]\ttrain-mlogloss:1.24591\tval-mlogloss:1.24572\n",
      "[50]\ttrain-mlogloss:0.28902\tval-mlogloss:0.29112\n",
      "[100]\ttrain-mlogloss:0.25371\tval-mlogloss:0.25694\n",
      "[150]\ttrain-mlogloss:0.24337\tval-mlogloss:0.24795\n",
      "[200]\ttrain-mlogloss:0.23828\tval-mlogloss:0.24394\n",
      "[249]\ttrain-mlogloss:0.23484\tval-mlogloss:0.24157\n",
      "Best val. mlogloss on fold3 = 0.241571\n",
      "New configuration: {'subsample': 0.19948345017758445, 'colsample_bytree': 0.3}\n",
      "[0]\ttrain-mlogloss:1.24669\tval-mlogloss:1.24592\n",
      "[50]\ttrain-mlogloss:0.29010\tval-mlogloss:0.28511\n",
      "[100]\ttrain-mlogloss:0.25460\tval-mlogloss:0.25049\n",
      "[150]\ttrain-mlogloss:0.24454\tval-mlogloss:0.24124\n",
      "[200]\ttrain-mlogloss:0.23919\tval-mlogloss:0.23722\n",
      "[249]\ttrain-mlogloss:0.23565\tval-mlogloss:0.23467\n",
      "Best val. mlogloss on fold2 = 0.234665\n",
      "New configuration: {'subsample': 0.19213096159266177, 'colsample_bytree': 0.3151932555159534}\n",
      "[0]\ttrain-mlogloss:1.24620\tval-mlogloss:1.24698\n",
      "[50]\ttrain-mlogloss:0.28929\tval-mlogloss:0.29408\n",
      "[100]\ttrain-mlogloss:0.25397\tval-mlogloss:0.25977\n",
      "[150]\ttrain-mlogloss:0.24388\tval-mlogloss:0.25055\n",
      "[200]\ttrain-mlogloss:0.23870\tval-mlogloss:0.24654\n",
      "[249]\ttrain-mlogloss:0.23524\tval-mlogloss:0.24421\n",
      "Best val. mlogloss on fold0 = 0.244207\n",
      "New configuration: {'subsample': 0.22077525103981535, 'colsample_bytree': 0.5641650899939463}\n",
      "[0]\ttrain-mlogloss:1.23922\tval-mlogloss:1.23885\n",
      "[50]\ttrain-mlogloss:0.27387\tval-mlogloss:0.27231\n",
      "[100]\ttrain-mlogloss:0.24836\tval-mlogloss:0.24853\n",
      "[150]\ttrain-mlogloss:0.24009\tval-mlogloss:0.24187\n",
      "[200]\ttrain-mlogloss:0.23551\tval-mlogloss:0.23877\n",
      "[249]\ttrain-mlogloss:0.23218\tval-mlogloss:0.23680\n",
      "Best val. mlogloss on fold1 = 0.236795\n",
      "New configuration: {'subsample': 0.38555108365088686, 'colsample_bytree': 0.6430465012413251}\n",
      "[0]\ttrain-mlogloss:1.23884\tval-mlogloss:1.23937\n",
      "[50]\ttrain-mlogloss:0.27185\tval-mlogloss:0.27761\n",
      "[100]\ttrain-mlogloss:0.24779\tval-mlogloss:0.25456\n",
      "[150]\ttrain-mlogloss:0.23967\tval-mlogloss:0.24761\n",
      "[200]\ttrain-mlogloss:0.23485\tval-mlogloss:0.24393\n",
      "[249]\ttrain-mlogloss:0.23165\tval-mlogloss:0.24175\n",
      "Best val. mlogloss on fold0 = 0.241754\n",
      "New configuration: {'subsample': 0.14238078751361904, 'colsample_bytree': 0.5889166997462851}\n",
      "[0]\ttrain-mlogloss:1.23941\tval-mlogloss:1.23873\n",
      "[50]\ttrain-mlogloss:0.27303\tval-mlogloss:0.26747\n",
      "[100]\ttrain-mlogloss:0.24843\tval-mlogloss:0.24392\n",
      "[150]\ttrain-mlogloss:0.24109\tval-mlogloss:0.23773\n",
      "[200]\ttrain-mlogloss:0.23644\tval-mlogloss:0.23453\n",
      "[249]\ttrain-mlogloss:0.23333\tval-mlogloss:0.23272\n",
      "Best val. mlogloss on fold2 = 0.232722\n",
      "New configuration: {'subsample': 0.16224274652474407, 'colsample_bytree': 0.8701410619945524}\n",
      "[0]\ttrain-mlogloss:1.23551\tval-mlogloss:1.23559\n",
      "[50]\ttrain-mlogloss:0.27048\tval-mlogloss:0.27356\n",
      "[100]\ttrain-mlogloss:0.24765\tval-mlogloss:0.25183\n",
      "[150]\ttrain-mlogloss:0.23993\tval-mlogloss:0.24548\n",
      "[200]\ttrain-mlogloss:0.23525\tval-mlogloss:0.24208\n",
      "[249]\ttrain-mlogloss:0.23172\tval-mlogloss:0.23999\n",
      "Best val. mlogloss on fold3 = 0.23999\n",
      "New configuration: {'subsample': 0.191420998023147, 'colsample_bytree': 0.4615842042626075}\n",
      "[0]\ttrain-mlogloss:1.23941\tval-mlogloss:1.23903\n",
      "[50]\ttrain-mlogloss:0.27704\tval-mlogloss:0.27528\n",
      "[100]\ttrain-mlogloss:0.24957\tval-mlogloss:0.24932\n",
      "[150]\ttrain-mlogloss:0.24094\tval-mlogloss:0.24215\n",
      "[200]\ttrain-mlogloss:0.23637\tval-mlogloss:0.23895\n",
      "[249]\ttrain-mlogloss:0.23311\tval-mlogloss:0.23697\n",
      "Best val. mlogloss on fold1 = 0.236968\n",
      "New configuration: {'subsample': 0.1057022752632172, 'colsample_bytree': 0.3085733716830022}\n",
      "[0]\ttrain-mlogloss:1.24555\tval-mlogloss:1.24539\n",
      "[50]\ttrain-mlogloss:0.28837\tval-mlogloss:0.29010\n",
      "[100]\ttrain-mlogloss:0.25344\tval-mlogloss:0.25635\n",
      "[150]\ttrain-mlogloss:0.24367\tval-mlogloss:0.24780\n",
      "[200]\ttrain-mlogloss:0.23886\tval-mlogloss:0.24418\n",
      "[249]\ttrain-mlogloss:0.23549\tval-mlogloss:0.24169\n",
      "Best val. mlogloss on fold3 = 0.241685\n",
      "New configuration: {'subsample': 0.19353209348351194, 'colsample_bytree': 0.3204111602670268}\n",
      "[0]\ttrain-mlogloss:1.24576\tval-mlogloss:1.24554\n",
      "[50]\ttrain-mlogloss:0.28899\tval-mlogloss:0.29114\n",
      "[100]\ttrain-mlogloss:0.25367\tval-mlogloss:0.25695\n",
      "[150]\ttrain-mlogloss:0.24319\tval-mlogloss:0.24784\n",
      "[200]\ttrain-mlogloss:0.23809\tval-mlogloss:0.24383\n",
      "[249]\ttrain-mlogloss:0.23470\tval-mlogloss:0.24152\n",
      "Best val. mlogloss on fold3 = 0.241525\n",
      "New configuration: {'subsample': 0.29856383785745727, 'colsample_bytree': 0.7879505259985498}\n",
      "[0]\ttrain-mlogloss:1.23623\tval-mlogloss:1.23584\n",
      "[50]\ttrain-mlogloss:0.27208\tval-mlogloss:0.27080\n",
      "[100]\ttrain-mlogloss:0.24864\tval-mlogloss:0.24909\n",
      "[150]\ttrain-mlogloss:0.24022\tval-mlogloss:0.24227\n",
      "[200]\ttrain-mlogloss:0.23532\tval-mlogloss:0.23880\n",
      "[249]\ttrain-mlogloss:0.23176\tval-mlogloss:0.23672\n",
      "Best val. mlogloss on fold1 = 0.236721\n",
      "New configuration: {'subsample': 0.26684986810607975, 'colsample_bytree': 0.43228334608224733}\n",
      "[0]\ttrain-mlogloss:1.23915\tval-mlogloss:1.23967\n",
      "[50]\ttrain-mlogloss:0.27758\tval-mlogloss:0.28299\n",
      "[100]\ttrain-mlogloss:0.24936\tval-mlogloss:0.25564\n",
      "[150]\ttrain-mlogloss:0.24113\tval-mlogloss:0.24835\n",
      "[200]\ttrain-mlogloss:0.23619\tval-mlogloss:0.24439\n",
      "[249]\ttrain-mlogloss:0.23281\tval-mlogloss:0.24230\n",
      "Best val. mlogloss on fold0 = 0.242302\n",
      "New configuration: {'subsample': 0.490492268649353, 'colsample_bytree': 0.41405888257336265}\n",
      "[0]\ttrain-mlogloss:1.24167\tval-mlogloss:1.24217\n",
      "[50]\ttrain-mlogloss:0.28001\tval-mlogloss:0.28552\n",
      "[100]\ttrain-mlogloss:0.25049\tval-mlogloss:0.25715\n",
      "[150]\ttrain-mlogloss:0.24170\tval-mlogloss:0.24957\n",
      "[200]\ttrain-mlogloss:0.23661\tval-mlogloss:0.24557\n",
      "[249]\ttrain-mlogloss:0.23313\tval-mlogloss:0.24310\n",
      "Best val. mlogloss on fold0 = 0.2431\n",
      "New configuration: {'subsample': 0.4991074585098456, 'colsample_bytree': 0.4868801023389411}\n",
      "[0]\ttrain-mlogloss:1.23885\tval-mlogloss:1.23854\n",
      "[50]\ttrain-mlogloss:0.27610\tval-mlogloss:0.27495\n",
      "[100]\ttrain-mlogloss:0.24924\tval-mlogloss:0.24955\n",
      "[150]\ttrain-mlogloss:0.24082\tval-mlogloss:0.24252\n",
      "[200]\ttrain-mlogloss:0.23591\tval-mlogloss:0.23892\n",
      "[249]\ttrain-mlogloss:0.23235\tval-mlogloss:0.23663\n",
      "Best val. mlogloss on fold1 = 0.236624\n",
      "New configuration: {'subsample': 0.3847301533301513, 'colsample_bytree': 0.42561989015397117}\n",
      "[0]\ttrain-mlogloss:1.23894\tval-mlogloss:1.23941\n",
      "[50]\ttrain-mlogloss:0.27782\tval-mlogloss:0.28331\n",
      "[100]\ttrain-mlogloss:0.24951\tval-mlogloss:0.25604\n",
      "[150]\ttrain-mlogloss:0.24120\tval-mlogloss:0.24882\n",
      "[200]\ttrain-mlogloss:0.23627\tval-mlogloss:0.24501\n",
      "[249]\ttrain-mlogloss:0.23299\tval-mlogloss:0.24270\n",
      "Best val. mlogloss on fold0 = 0.242701\n",
      "New configuration: {'subsample': 0.4969921484523652, 'colsample_bytree': 0.5894664065033378}\n",
      "[0]\ttrain-mlogloss:1.23909\tval-mlogloss:1.23847\n",
      "[50]\ttrain-mlogloss:0.27375\tval-mlogloss:0.26879\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 25\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m OPTIMIZE_SPACE:\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOPTIMIZING SPACE\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 25\u001b[0m     param \u001b[38;5;241m=\u001b[39m \u001b[43moptimize_hyperparams\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbdt_train_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbdt_val_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(OUTPUT_DIRPATH, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCURRENT_TIME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_best_params.json\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     28\u001b[0m         json\u001b[38;5;241m.\u001b[39mdump(param, f)\n",
      "Cell \u001b[0;32mIn[11], line 141\u001b[0m, in \u001b[0;36moptimize_hyperparams\u001b[0;34m(dtrain_dict, dval_dict, verbose, verbose_eval)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39mbest_mlogloss\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizing subsample (fraction of training events) and colsample_bytree (fraction of training features per tree)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 141\u001b[0m result_subsample_and_colsample_bytree \u001b[38;5;241m=\u001b[39m \u001b[43mgp_minimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubsample_and_colsample_bytree_objective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubsample_and_colsample_bytree_space\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m param[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubsample\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(result_subsample_and_colsample_bytree\u001b[38;5;241m.\u001b[39mx[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    143\u001b[0m param[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolsample_bytree\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(result_subsample_and_colsample_bytree\u001b[38;5;241m.\u001b[39mx[\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[0;32m~/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/skopt/optimizer/gp.py:281\u001b[0m, in \u001b[0;36mgp_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, noise, n_jobs, model_queue_size, space_constraint)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m base_estimator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    274\u001b[0m     base_estimator \u001b[38;5;241m=\u001b[39m cook_estimator(\n\u001b[1;32m    275\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGP\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    276\u001b[0m         space\u001b[38;5;241m=\u001b[39mspace,\n\u001b[1;32m    277\u001b[0m         random_state\u001b[38;5;241m=\u001b[39mrng\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, np\u001b[38;5;241m.\u001b[39miinfo(np\u001b[38;5;241m.\u001b[39mint32)\u001b[38;5;241m.\u001b[39mmax),\n\u001b[1;32m    278\u001b[0m         noise\u001b[38;5;241m=\u001b[39mnoise,\n\u001b[1;32m    279\u001b[0m     )\n\u001b[0;32m--> 281\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbase_minimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m    \u001b[49m\u001b[43macq_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43macq_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkappa\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkappa\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m    \u001b[49m\u001b[43macq_optimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43macq_optimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_points\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_random_starts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_random_starts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_initial_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_initial_points\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_point_generator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_point_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_restarts_optimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_restarts_optimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43my0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrng\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspace_constraint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspace_constraint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/skopt/optimizer/base.py:332\u001b[0m, in \u001b[0;36mbase_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, n_jobs, model_queue_size, space_constraint)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_calls):\n\u001b[1;32m    331\u001b[0m     next_x \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mask()\n\u001b[0;32m--> 332\u001b[0m     next_y \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnext_x\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    333\u001b[0m     result \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mtell(next_x, next_y)\n\u001b[1;32m    334\u001b[0m     result\u001b[38;5;241m.\u001b[39mspecs \u001b[38;5;241m=\u001b[39m specs\n",
      "File \u001b[0;32m~/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/skopt/utils.py:779\u001b[0m, in \u001b[0;36muse_named_args.<locals>.decorator.<locals>.wrapper\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    776\u001b[0m arg_dict \u001b[38;5;241m=\u001b[39m {dim\u001b[38;5;241m.\u001b[39mname: value \u001b[38;5;28;01mfor\u001b[39;00m dim, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(dimensions, x)}\n\u001b[1;32m    778\u001b[0m \u001b[38;5;66;03m# Call the wrapped objective function with the named arguments.\u001b[39;00m\n\u001b[0;32m--> 779\u001b[0m objective_value \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marg_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m objective_value\n",
      "Cell \u001b[0;32mIn[11], line 125\u001b[0m, in \u001b[0;36moptimize_hyperparams.<locals>.subsample_and_colsample_bytree_objective\u001b[0;34m(**X)\u001b[0m\n\u001b[1;32m    122\u001b[0m fold_idx \u001b[38;5;241m=\u001b[39m rng\u001b[38;5;241m.\u001b[39mintegers(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m    124\u001b[0m evallist \u001b[38;5;241m=\u001b[39m [(dtrain_dict[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfold_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m), (dval_dict[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfold_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[0;32m--> 125\u001b[0m booster \u001b[38;5;241m=\u001b[39m \u001b[43mxgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfold_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfold_idx\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_trees\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevallist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m eval_str \u001b[38;5;241m=\u001b[39m booster\u001b[38;5;241m.\u001b[39meval(dval_dict[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfold_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m], name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m, iteration\u001b[38;5;241m=\u001b[39mbooster\u001b[38;5;241m.\u001b[39mbest_iteration)\n\u001b[1;32m    132\u001b[0m best_mlogloss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(eval_str[eval_str\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval-mlogloss:\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval-mlogloss:\u001b[39m\u001b[38;5;124m'\u001b[39m):])\n",
      "File \u001b[0;32m~/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/xgboost/training.py:188\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(params, dtrain, num_boost_round\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, evals\u001b[38;5;241m=\u001b[39m(), obj\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, feval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    116\u001b[0m           maximize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, early_stopping_rounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, evals_result\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    117\u001b[0m           verbose_eval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, xgb_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m# pylint: disable=too-many-statements,too-many-branches, attribute-defined-outside-init\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Train a booster with given parameters.\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \n\u001b[1;32m    121\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;124;03m    Booster : a trained booster model\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 188\u001b[0m     bst \u001b[38;5;241m=\u001b[39m \u001b[43m_train_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_boost_round\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxgb_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bst\n",
      "File \u001b[0;32m~/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/xgboost/training.py:82\u001b[0m, in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     81\u001b[0m     bst\u001b[38;5;241m.\u001b[39mupdate(dtrain, i, obj)\n\u001b[0;32m---> 82\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mafter_iteration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevals\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     85\u001b[0m bst \u001b[38;5;241m=\u001b[39m callbacks\u001b[38;5;241m.\u001b[39mafter_training(bst)\n",
      "File \u001b[0;32m~/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/xgboost/callback.py:434\u001b[0m, in \u001b[0;36mCallbackContainer.after_iteration\u001b[0;34m(self, model, epoch, dtrain, evals)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, name \u001b[38;5;129;01min\u001b[39;00m evals:\n\u001b[1;32m    433\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m name\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataset name should not contain `-`\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 434\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_set\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    435\u001b[0m score \u001b[38;5;241m=\u001b[39m score\u001b[38;5;241m.\u001b[39msplit()[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# into datasets\u001b[39;00m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;66;03m# split up `test-error:0.1234`\u001b[39;00m\n",
      "File \u001b[0;32m~/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/xgboost/core.py:1744\u001b[0m, in \u001b[0;36mBooster.eval_set\u001b[0;34m(self, evals, iteration, feval)\u001b[0m\n\u001b[1;32m   1742\u001b[0m evnames \u001b[38;5;241m=\u001b[39m c_array(ctypes\u001b[38;5;241m.\u001b[39mc_char_p, [c_str(d[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m evals])\n\u001b[1;32m   1743\u001b[0m msg \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mc_char_p()\n\u001b[0;32m-> 1744\u001b[0m _check_call(\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterEvalOneIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1746\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mdmats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1747\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mc_bst_ulong\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mevals\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1748\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1749\u001b[0m res \u001b[38;5;241m=\u001b[39m msg\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;241m.\u001b[39mdecode()  \u001b[38;5;66;03m# pylint: disable=no-member\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m feval \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if 'CURRENT_TIME' in globals() and not (\n",
    "    len(glob.glob(OUTPUT_DIRPATH+'/*.model')) < MOD_VALS[0]\n",
    "    and not FORCE_RERUN\n",
    "):\n",
    "    OUTPUT_DIRPATH, OLD_TIME = os.path.split(OUTPUT_DIRPATH)\n",
    "fold_start = 0\n",
    "if 'CURRENT_TIME' not in globals() or not (\n",
    "    len(glob.glob(OUTPUT_DIRPATH+'/*.model')) < MOD_VALS[0]\n",
    "    and not FORCE_RERUN\n",
    "):\n",
    "    CURRENT_TIME = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "    OUTPUT_DIRPATH = os.path.join(OUTPUT_DIRPATH, CURRENT_TIME)\n",
    "    if not os.path.exists(OUTPUT_DIRPATH):\n",
    "        os.makedirs(OUTPUT_DIRPATH)\n",
    "else:\n",
    "    for model_file in glob.glob(OUTPUT_DIRPATH+'/*.model'):\n",
    "        print(f\"Finished model fold {model_file[-7]}\")\n",
    "        fold_start += 1\n",
    "    print(f\"Starting from fold {fold_start}\")\n",
    "\n",
    "if OPTIMIZE_SPACE:\n",
    "\n",
    "    print('OPTIMIZING SPACE')\n",
    "        \n",
    "    param = optimize_hyperparams(bdt_train_dict, bdt_val_dict, verbose=True, verbose_eval=50)\n",
    "\n",
    "    with open(os.path.join(OUTPUT_DIRPATH, f'{CURRENT_TIME}_best_params.json'), 'w') as f:\n",
    "        json.dump(param, f)\n",
    "        print(param)\n",
    "\n",
    "    param['eval_metric'] = 'merror'\n",
    "    param = list(param.items()) + [('eval_metric', 'mlogloss')]\n",
    "\n",
    "evals_result_dict = {f\"fold_{fold_idx}\": dict() for fold_idx in range(len(bdt_train_dict))}\n",
    "for fold_idx in range(len(bdt_train_dict)):\n",
    "    print(f\"fold {fold_idx}\")\n",
    "    # Train bdt\n",
    "    evallist = [(bdt_train_dict[f\"fold_{fold_idx}\"], 'train'), (bdt_test_dict[f\"fold_{fold_idx}\"], 'test'), (bdt_val_dict[f\"fold_{fold_idx}\"], 'val')]\n",
    "    booster = xgb.train(\n",
    "        param, bdt_train_dict[f\"fold_{fold_idx}\"], num_boost_round=num_trees, \n",
    "        evals=evallist, early_stopping_rounds=10, verbose_eval=25, evals_result=evals_result_dict[f\"fold_{fold_idx}\"],\n",
    "        # custom_metric=thresholded_weighted_merror\n",
    "    )\n",
    "\n",
    "    booster.save_model(os.path.join(OUTPUT_DIRPATH, f'{CURRENT_TIME}_BDT_fold{fold_idx}.model'))\n",
    "    \n",
    "    # Print perf on test dataset\n",
    "    print(booster.eval(bdt_test_dict[f\"fold_{fold_idx}\"], name='test', iteration=booster.best_iteration))\n",
    "    print('='*100)\n",
    "\n",
    "with open(os.path.join(OUTPUT_DIRPATH, f'{CURRENT_TIME}_BDT_eval_result.json'), 'w') as f:\n",
    "    json.dump(evals_result_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance (ROC) Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_tpr = np.linspace(0, 1, 5000)  # copied from IN evaluate.py file\n",
    "roc_baseline = np.zeros(\n",
    "    (len(bdt_train_dict), len(base_tpr), len(order)), \n",
    "    dtype=float\n",
    ")\n",
    "area_baseline = np.zeros(\n",
    "    (len(bdt_train_dict), len(order)), \n",
    "    dtype=float\n",
    ")\n",
    "\n",
    "BDT_perf = {\n",
    "    sample_name: copy.deepcopy({\n",
    "        'base_tpr': base_tpr,\n",
    "        'class_order': copy.deepcopy(order),\n",
    "        # test data #\n",
    "        'preds': [],\n",
    "        'fprs_density': copy.deepcopy(roc_baseline), 'thresholds_density': copy.deepcopy(roc_baseline), 'areas_density': copy.deepcopy(area_baseline),\n",
    "        'fprs_weighted': copy.deepcopy(roc_baseline), 'thresholds_weighted': copy.deepcopy(roc_baseline), 'areas_weighted': copy.deepcopy(area_baseline),\n",
    "        'fprs_sum_density': copy.deepcopy(roc_baseline[0, ...]), 'thresholds_sum_density': copy.deepcopy(roc_baseline[0, ...]), 'areas_sum_density': copy.deepcopy(area_baseline[0, ...]),\n",
    "        'fprs_sum_weighted': copy.deepcopy(roc_baseline[0, ...]), 'thresholds_sum_weighted': copy.deepcopy(roc_baseline[0, ...]), 'areas_sum_weighted': copy.deepcopy(area_baseline[0, ...]),\n",
    "        # train data #\n",
    "        'train_preds': [], \n",
    "        'train_fprs_density': copy.deepcopy(roc_baseline), 'train_thresholds_density': copy.deepcopy(roc_baseline), 'train_areas_density': copy.deepcopy(area_baseline),\n",
    "        'train_fprs_weighted': copy.deepcopy(roc_baseline), 'train_thresholds_weighted': copy.deepcopy(roc_baseline), 'train_areas_weighted': copy.deepcopy(area_baseline),\n",
    "        'train_fprs_sum_density': copy.deepcopy(roc_baseline[0, ...]), 'train_thresholds_sum_density': copy.deepcopy(roc_baseline[0, ...]), 'train_areas_sum_density': copy.deepcopy(area_baseline[0, ...]),\n",
    "        'train_fprs_sum_weighted': copy.deepcopy(roc_baseline[0, ...]), 'train_thresholds_sum_weighted': copy.deepcopy(roc_baseline[0, ...]), 'train_areas_sum_weighted': copy.deepcopy(area_baseline[0, ...]),\n",
    "        # val data #\n",
    "        'val_preds': [],\n",
    "        'val_fprs_density': copy.deepcopy(roc_baseline), 'val_thresholds_density': copy.deepcopy(roc_baseline), 'val_areas_density': copy.deepcopy(area_baseline),\n",
    "        'val_fprs_weighted': copy.deepcopy(roc_baseline), 'val_thresholds_weighted': copy.deepcopy(roc_baseline), 'val_areas_weighted': copy.deepcopy(area_baseline),\n",
    "        'val_fprs_sum_density': copy.deepcopy(roc_baseline[0, ...]), 'val_thresholds_sum_density': copy.deepcopy(roc_baseline[0, ...]), 'val_areas_sum_density': copy.deepcopy(area_baseline[0, ...]),\n",
    "        'val_fprs_sum_weighted': copy.deepcopy(roc_baseline[0, ...]), 'val_thresholds_sum_weighted': copy.deepcopy(roc_baseline[0, ...]), 'val_areas_sum_weighted': copy.deepcopy(area_baseline[0, ...]),\n",
    "    }) for sample_name in order\n",
    "}\n",
    "\n",
    "for j, sample_name in enumerate(order):\n",
    "\n",
    "    for fold_idx in range(len(bdt_train_dict)):\n",
    "        booster = xgb.Booster(param)\n",
    "\n",
    "        try:\n",
    "            booster.load_model(os.path.join(OUTPUT_DIRPATH, f'{CURRENT_TIME}_BDT_fold{fold_idx}.model'))\n",
    "        except:\n",
    "            raise FileNotFoundError(f\"No model file at fold {fold_idx}.\")\n",
    "    \n",
    "        for pred_type, dataset in [\n",
    "            ('train_', bdt_train_dict[f\"fold_{fold_idx}\"]),\n",
    "            ('val_', bdt_val_dict[f\"fold_{fold_idx}\"]),\n",
    "            ('', bdt_test_dict[f\"fold_{fold_idx}\"])\n",
    "        ]:\n",
    "            \n",
    "            BDT_perf[sample_name][pred_type + 'preds'].append(\n",
    "                booster.predict(\n",
    "                    dataset, \n",
    "                    iteration_range=(0, booster.best_iteration+1)\n",
    "                ).tolist()\n",
    "            )\n",
    "\n",
    "            for i, sample_name_ in enumerate(order):\n",
    "                \n",
    "                if sample_name_ == sample_name:\n",
    "                    event_mask = dataset.get_label() > -1\n",
    "                    pred_rescale = np.ones_like(event_mask)\n",
    "                else:\n",
    "                    event_mask = np.logical_or(dataset.get_label() == j, dataset.get_label() == i)\n",
    "                    pred_rescale = np.array(BDT_perf[sample_name][pred_type + 'preds'][-1])[:, j][event_mask] + np.array(BDT_perf[sample_name][pred_type + 'preds'][-1])[:, i][event_mask]\n",
    "                class_preds = np.array(BDT_perf[sample_name][pred_type + 'preds'][-1])[:, j][event_mask] / pred_rescale\n",
    "                class_truths = np.where(dataset.get_label() == j, 1, 0)[event_mask]\n",
    "                \n",
    "                for roc_type in ['density', 'weighted']:\n",
    "\n",
    "                    if roc_type == 'weighted':\n",
    "                        if re.search('train', pred_type) is not None:\n",
    "                            roc_weights = weights_plot_train[f\"fold_{fold_idx}\"][event_mask]\n",
    "                        elif re.search('val', pred_type) is not None:\n",
    "                            roc_weights = weights_plot_val[f\"fold_{fold_idx}\"][event_mask]\n",
    "                        else:\n",
    "                            roc_weights = weights_plot_test[f\"fold_{fold_idx}\"][event_mask]\n",
    "                    else:\n",
    "                        roc_weights = None\n",
    "\n",
    "                    fpr_bdt, tpr_bdt, threshold_bdt = roc_curve(class_truths, class_preds, sample_weight=roc_weights)\n",
    "                    fpr_bdt = np.interp(base_tpr, tpr_bdt, fpr_bdt)\n",
    "                    threshold_bdt = np.interp(base_tpr, tpr_bdt, threshold_bdt)\n",
    "\n",
    "                    BDT_perf[sample_name][pred_type + 'fprs_' + roc_type][fold_idx][:, i] = fpr_bdt\n",
    "                    BDT_perf[sample_name][pred_type + 'thresholds_' + roc_type][fold_idx][:, i] = threshold_bdt\n",
    "                    BDT_perf[sample_name][pred_type + 'areas_' + roc_type][fold_idx][i] = float(trapezoid(base_tpr, fpr_bdt))\n",
    "    \n",
    "    for pred_type, dataset_dict in [\n",
    "        ('train_', bdt_train_dict),\n",
    "        ('val_', bdt_val_dict),\n",
    "        ('', bdt_test_dict)\n",
    "    ]:\n",
    "\n",
    "        flat_preds = np.concatenate(BDT_perf[sample_name][f'{pred_type}preds'], axis=0)\n",
    "        flat_truths = np.concatenate([dataset_dict[f\"fold_{fold_idx}\"].get_label() for fold_idx in range(len(dataset_dict))], axis=0)\n",
    "\n",
    "        for i, sample_name_ in enumerate(order):\n",
    "            \n",
    "            if sample_name_ == sample_name:\n",
    "                event_mask = flat_truths > -1\n",
    "                pred_rescale = np.ones_like(event_mask)\n",
    "            else:\n",
    "                event_mask = np.logical_or(flat_truths == j, flat_truths == i)\n",
    "                pred_rescale = flat_preds[:, j][event_mask] + flat_preds[:, i][event_mask]\n",
    "            class_preds = flat_preds[:, j][event_mask] / pred_rescale\n",
    "            class_truths = np.where(flat_truths == j, 1, 0)[event_mask]\n",
    "            \n",
    "            for roc_type in ['density', 'weighted']:\n",
    "\n",
    "                if roc_type == 'weighted':\n",
    "                    if re.search('train', pred_type) is not None:\n",
    "                        roc_weights = np.concatenate([weights_plot_train[f\"fold_{fold_idx}\"] for fold_idx in range(len(weights_plot_train))], axis=0)[event_mask]\n",
    "                    elif re.search('val', pred_type) is not None:\n",
    "                        roc_weights = np.concatenate([weights_plot_val[f\"fold_{fold_idx}\"] for fold_idx in range(len(weights_plot_val))], axis=0)[event_mask]\n",
    "                    else:\n",
    "                        roc_weights = np.concatenate([weights_plot_test[f\"fold_{fold_idx}\"] for fold_idx in range(len(weights_plot_test))], axis=0)[event_mask]\n",
    "                else:\n",
    "                    roc_weights = None\n",
    "\n",
    "                fpr_bdt, tpr_bdt, threshold_bdt = roc_curve(class_truths, class_preds, sample_weight=roc_weights)\n",
    "                fpr_bdt = np.interp(base_tpr, tpr_bdt, fpr_bdt)\n",
    "                threshold_bdt = np.interp(base_tpr, tpr_bdt, threshold_bdt)\n",
    "\n",
    "                BDT_perf[sample_name][pred_type + 'fprs_sum_' + roc_type][:, i] = fpr_bdt\n",
    "                BDT_perf[sample_name][pred_type + 'thresholds_sum_' + roc_type][:, i] = threshold_bdt\n",
    "                BDT_perf[sample_name][pred_type + 'areas_sum_' + roc_type][i] = float(trapezoid(base_tpr, fpr_bdt))\n",
    "    \n",
    "    for key in BDT_perf[sample_name].keys():\n",
    "        if type(BDT_perf[sample_name][key]) is list:\n",
    "            continue\n",
    "        BDT_perf[sample_name][key] = BDT_perf[sample_name][key].tolist()\n",
    "\n",
    "\n",
    "with open(os.path.join(OUTPUT_DIRPATH, CURRENT_TIME+f\"_BDT_perf.json\"), 'w') as f:\n",
    "    json.dump(BDT_perf, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_list(list_of_lists):\n",
    "    max_length = np.max([len(list_i) for list_i in list_of_lists])\n",
    "    for list_i in list_of_lists:\n",
    "        while len(list_i) < max_length:\n",
    "            list_i.append(list_i[-1])\n",
    "\n",
    "    return list_of_lists\n",
    "\n",
    "def plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix, format='png'):\n",
    "    plot_prefix = plot_prefix + ('_' if plot_prefix != '' else '')\n",
    "    plot_postfix = plot_postfix + ('_' if plot_postfix != '' else '')\n",
    "    plot_name = plot_prefix + plot_name + plot_postfix + f'.{format}'\n",
    "\n",
    "    plot_filepath = os.path.join(plot_dirpath, plot_name)\n",
    "    return plot_filepath\n",
    "\n",
    "def plot_train_val_losses(\n",
    "    losses_arrs, labels, plot_name, plot_dirpath, \n",
    "    plot_prefix='', plot_postfix='', linestyles=None,\n",
    "    losses_std_arrs=None\n",
    "):\n",
    "    plt.figure(figsize=(9,7))\n",
    "    \n",
    "    if type(losses_arrs[0]) is float:\n",
    "        losses_arrs = [losses_arrs]\n",
    "    if linestyles is None:\n",
    "        linestyles = ['solid'] * len(losses_arrs)\n",
    "    if labels is None:\n",
    "        labels = [i for i in range(len(losses_arrs))]\n",
    "\n",
    "    if losses_std_arrs is not None:\n",
    "        for i in range(len(losses_std_arrs)):\n",
    "            plt.fill_between(\n",
    "                range(len(losses_std_arrs[i])), \n",
    "                losses_arrs[i]+losses_std_arrs[i], losses_arrs[i]-losses_std_arrs[i],\n",
    "                alpha=0.7\n",
    "            )\n",
    "\n",
    "    for i in range(len(losses_arrs)):\n",
    "        plt.plot(\n",
    "            range(len(losses_arrs[i])), \n",
    "            losses_arrs[i], \n",
    "            label=f\"{labels[i]} losses\", linestyle=linestyles[i],\n",
    "            alpha=0.7\n",
    "        )\n",
    "        \n",
    "    plt.legend(bbox_to_anchor=(1, 1))\n",
    "    plt.xlabel('EPOCH')\n",
    "    plt.ylabel('Data Loss')\n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix, format='pdf'), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.close()\n",
    "\n",
    "def plot_rocs(\n",
    "    fprs, tprs, labels, plot_name, plot_dirpath,\n",
    "    plot_prefix='', plot_postfix='', close=True, log=None\n",
    "):\n",
    "    plt.figure(figsize=(9,7))\n",
    "    \n",
    "    for fpr, tpr, label in zip(fprs, tprs, labels):\n",
    "        linestyle = 'solid' if re.search('IN', label) is not None else ('dashed' if re.search('BDT', label) is not None else 'dotted')\n",
    "        plt.plot(fpr, tpr, label=label, linestyle=linestyle)\n",
    "\n",
    "    plt.legend(bbox_to_anchor=(1, 1))\n",
    "    plt.xlabel('Background contamination')\n",
    "    plt.ylabel('Signal efficiency')\n",
    "    if log is not None and re.search('x', log) is not None:\n",
    "        plt.xscale('log')\n",
    "    elif log is not None and re.search('y', log) is not None:\n",
    "        plt.yscale('log')\n",
    "    \n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix, format='pdf'), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    if close:\n",
    "        plt.close()\n",
    "\n",
    "def plot_output_scores(\n",
    "    sigs_and_bkgs, order, plot_name, plot_dirpath,\n",
    "    plot_prefix='', plot_postfix='', bins=1000, weights=None, log=False, arctanh=False\n",
    "):\n",
    "    plt.figure(figsize=(9,7))\n",
    "\n",
    "    if arctanh:\n",
    "        end_point = 6.\n",
    "    else:\n",
    "        end_point = 1.\n",
    "    hist_axis = hist.axis.Regular(bins, 0., end_point, name='var', growth=False, underflow=False, overflow=False)\n",
    "    hists, labels = [], []\n",
    "    for sample_name in order:\n",
    "        if sample_name not in sigs_and_bkgs:\n",
    "            continue\n",
    "        hists.append(\n",
    "            hist.Hist(hist_axis, storage='weight').fill(\n",
    "                var=sigs_and_bkgs[sample_name], \n",
    "                weight=weights[sample_name] if weights is not None else np.ones_like(sigs_and_bkgs[sample_name])\n",
    "            )\n",
    "        )\n",
    "        labels.append(sample_name)\n",
    "    hep.histplot(\n",
    "        hists,\n",
    "        yerr=(True if weights is not None else False),\n",
    "        alpha=0.2, density=(False if weights is not None else True), histtype='step',\n",
    "        label=labels\n",
    "    )\n",
    "\n",
    "    plt.legend(bbox_to_anchor=(1, 1))\n",
    "    plt.xlabel('Output score')\n",
    "    if log:\n",
    "        plt.yscale('log')\n",
    "    \n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix, format='pdf'), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.close()\n",
    "\n",
    "def plot_s_over_root_b(\n",
    "    sig, bkg, label, plot_name, plot_dirpath,\n",
    "    plot_prefix='', plot_postfix='', bins=1000, weights={'sig': None, 'bkg': None},\n",
    "    lines=None, lines_labels=None, line_colors=None, arctanh=False\n",
    "):\n",
    "    plt.figure(figsize=(9,7))\n",
    "\n",
    "    if arctanh:\n",
    "        end_point = 6.\n",
    "        hist_axis = hist.axis.Regular(bins, 0., end_point, name='var', growth=False, underflow=False, overflow=False)\n",
    "    else:\n",
    "        end_point = 1.\n",
    "        hist_axis = hist.axis.Regular(bins, 0., end_point, name='var', growth=False, underflow=False, overflow=False)\n",
    "    sig_hist = hist.Hist(hist_axis, storage='weight').fill(var=sig, weight=weights['sig'] if weights['sig'] is not None else np.ones_like(sig))\n",
    "    bkg_hist = hist.Hist(hist_axis, storage='weight').fill(var=bkg, weight=weights['bkg'] if weights['bkg'] is not None else np.ones_like(bkg))\n",
    "    s_over_root_b_points = sig_hist.values().flatten() / np.sqrt(bkg_hist.values().flatten())\n",
    "    plt.plot(\n",
    "        np.arange(0., end_point, end_point*(1/bins)), s_over_root_b_points, \n",
    "        label=f'{label} - s/âb', alpha=0.8\n",
    "    )\n",
    "\n",
    "    if lines is not None:\n",
    "        for i in range(len(lines)):\n",
    "            plt.vlines(\n",
    "                lines[i], 0, np.max(s_over_root_b_points), \n",
    "                label='s/âb'+(' - '+lines_labels[i] if lines_labels is not None else ''), \n",
    "                alpha=0.5, colors=line_colors[i]\n",
    "            )\n",
    "    \n",
    "    plt.legend(bbox_to_anchor=(1, 1))\n",
    "    plt.xlabel('Output score')\n",
    "    plt.ylabel('s/âb')\n",
    "    \n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix, format='pdf'), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.close()\n",
    "\n",
    "def plot_confusion_matrix(\n",
    "    conf_matrix, class_labels, plot_name, plot_dirpath, \n",
    "    plot_prefix='', plot_postfix=''\n",
    "):\n",
    "    plt.figure(figsize=(9,7))\n",
    "\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=class_labels)\n",
    "    disp.plot(im_kw={'norm': 'log'})\n",
    "    \n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix, format='pdf'), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.close()\n",
    "\n",
    "def plot_feature_importance(\n",
    "    feature_scores, feature_labels, plot_name, plot_dirpath, \n",
    "    plot_prefix='', plot_postfix='', fscore_method='total_gain', log=True\n",
    "):\n",
    "    plt.figure(figsize=(18,14))\n",
    "\n",
    "    plt.barh(\n",
    "        np.arange(len(feature_scores)), feature_scores, align='center'\n",
    "    )\n",
    "    plt.yticks(np.arange(len(feature_scores)), feature_labels, fontsize=8)\n",
    "    plt.ylabel('Features')\n",
    "    plt.xlabel(f'F score ({fscore_method})')\n",
    "    if log:\n",
    "        plt.xscale('log')\n",
    "    \n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix, format='pdf'), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_cut_boundaries(sigs, bkgs, weights, bins=10000, arctanh=False):\n",
    "    hist_list_fold = []\n",
    "    cut_boundaries_fold = []\n",
    "    cut_s_over_root_bs_fold = []\n",
    "    sig_weights_fold = []\n",
    "    bkg_weights_fold = []\n",
    "    if len(np.shape(sigs)) == 1:\n",
    "        sigs, bkgs = [sigs], [bkgs] \n",
    "    if arctanh:\n",
    "        end_point = 6.\n",
    "    else:\n",
    "        end_point = 1.\n",
    "    for sig, bkg in zip(sigs, bkgs):\n",
    "        hist_axis = hist.axis.Regular(bins, 0., end_point, name='var', growth=False, underflow=False, overflow=False)\n",
    "        sig_hist = hist.Hist(hist_axis, storage='weight').fill(var=sig, weight=weights['sig'])\n",
    "        bkg_hist = hist.Hist(hist_axis, storage='weight').fill(var=bkg, weight=weights['bkg'])\n",
    "        hist_list_fold.append({'sig': copy.deepcopy(sig_hist), 'bkg': copy.deepcopy(bkg_hist)})\n",
    "\n",
    "        fold_idx_cuts_bins_inclusive = []\n",
    "        fold_idx_sig_weights = []\n",
    "        fold_idx_bkg_weights = []\n",
    "        fold_idx_prev_s_over_root_b = []\n",
    "        prev_s_over_root_b = 0\n",
    "        for i in range(bins):\n",
    "            s = np.sum(sig_hist.values().flatten()[\n",
    "                (bins-1) - i : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "            ])\n",
    "            sqrt_b = np.sqrt(np.sum(bkg_hist.values().flatten()[\n",
    "                (bins-1) - i : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "            ]))\n",
    "            if prev_s_over_root_b < (s / sqrt_b) or s < 0.25:\n",
    "                prev_s_over_root_b = s / sqrt_b\n",
    "                continue\n",
    "            else:\n",
    "                fold_idx_sig_weights.append(\n",
    "                    {\n",
    "                        'value': np.sum(sig_hist.values().flatten()[\n",
    "                            (bins) - i : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                        ]),\n",
    "                        'w2': np.sqrt(np.sum(sig_hist.variances().flatten()[\n",
    "                            (bins) - i : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                        ])),\n",
    "                    }\n",
    "                )\n",
    "                fold_idx_bkg_weights.append(\n",
    "                    {\n",
    "                        'value': np.sum(bkg_hist.values().flatten()[\n",
    "                            (bins) - i : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                        ]),\n",
    "                        'w2': np.sqrt(np.sum(bkg_hist.variances().flatten()[\n",
    "                            (bins) - i : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                        ])),\n",
    "                    }\n",
    "                )\n",
    "                fold_idx_cuts_bins_inclusive.append(bins - i)\n",
    "                fold_idx_prev_s_over_root_b.append(prev_s_over_root_b)\n",
    "                prev_s_over_root_b = 0\n",
    "        fold_idx_sig_weights.append(\n",
    "            {\n",
    "                'value': np.sum(sig_hist.values().flatten()[\n",
    "                    0 : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                ]),\n",
    "                'w2': np.sqrt(np.sum(sig_hist.variances().flatten()[\n",
    "                    0 : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                ])),\n",
    "            }\n",
    "        )\n",
    "        fold_idx_bkg_weights.append(\n",
    "            {\n",
    "                'value': np.sum(bkg_hist.values().flatten()[\n",
    "                    0 : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                ]),\n",
    "                'w2': np.sqrt(np.sum(bkg_hist.variances().flatten()[\n",
    "                    0 : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                ])),\n",
    "            }\n",
    "        )\n",
    "        fold_idx_cuts_bins_inclusive.append(0)\n",
    "        fold_idx_prev_s_over_root_b.append(prev_s_over_root_b)\n",
    "        fold_idx_score_cuts = [end_point * (bin_i / bins) for bin_i in fold_idx_cuts_bins_inclusive]\n",
    "        cut_boundaries_fold.append(fold_idx_score_cuts)\n",
    "        cut_s_over_root_bs_fold.append(fold_idx_prev_s_over_root_b)\n",
    "        sig_weights_fold.append(fold_idx_sig_weights)\n",
    "        bkg_weights_fold.append(fold_idx_bkg_weights)\n",
    "    return cut_boundaries_fold, cut_s_over_root_bs_fold, sig_weights_fold, bkg_weights_fold\n",
    "\n",
    "def p_to_xyz(p, split=True):  # makes a tetrahedron with height 1 and vertices {(0, 0, 0),  (â3/2, 0, â3/2),  (0, â3/2, â3/2),  (â3/2, â3/2, 0)}\n",
    "    rt3o2 = np.sqrt(3) / 2\n",
    "\n",
    "    x = rt3o2 * (0*p[:, 0] + p[:, 1] + p[:, 2] + 0*p[:, 3])\n",
    "    y = rt3o2 * (0*p[:, 0] + 0*p[:, 1] + p[:, 2] + p[:, 3])\n",
    "    z = rt3o2 * (0*p[:, 0] + p[:, 1] + 0*p[:, 2] + p[:, 3])\n",
    "\n",
    "    if split:\n",
    "        return x, y, z\n",
    "    else:\n",
    "        return np.column_stack((x, y, z))\n",
    "\n",
    "def optimize_cuts(\n",
    "    preds: np.ndarray, binary_labels: np.ndarray, weights: np.ndarray,\n",
    "    init_guess=[1e-9, 2e-3, 1e-2], param_names=['r1', 'r2', 'r3'], param_range=[(1e-11, 1e-4), (1e-3, 5e-2), (0., 1.)], \n",
    "    n_steps=int(5e2), verbose: bool=False, min_sig: float=0.2, prefactor: float=1e3, rng_seed: int=21\n",
    "):\n",
    "    xyz_preds = p_to_xyz(preds, split=False)\n",
    "\n",
    "    space  = [Real(float(param_range[i][0]), float(param_range[i][1]), (\"log-uniform\" if param_name == 'r4' else \"uniform\"), name=param_name) for i, param_name in enumerate(param_names)]\n",
    "\n",
    "    def space_transform(X):\n",
    "        triangle_vertices = X['r1']**(1/3) * np.array([\n",
    "            [np.sqrt(3)/2,         0,            np.sqrt(3)/2], \n",
    "            [0,                np.sqrt(3)/2,     np.sqrt(3)/2], \n",
    "            [np.sqrt(3)/2,     np.sqrt(3)/2,                0]\n",
    "        ])\n",
    "\n",
    "        sampled_point = (\n",
    "            (1 - np.sqrt((1 - X['r2']))) * triangle_vertices[0, :]\n",
    "        ) + (\n",
    "            np.sqrt((1 - X['r2']))*(1 - X['r3']) * triangle_vertices[1, :]\n",
    "        ) + (\n",
    "            np.sqrt((1 - X['r2']))*X['r3'] * triangle_vertices[2, :]\n",
    "        )\n",
    "\n",
    "        if verbose:\n",
    "            print(sampled_point)\n",
    "\n",
    "        return sampled_point\n",
    "\n",
    "    @use_named_args(space)\n",
    "    def objective(**X):\n",
    "        if verbose:\n",
    "            print(\"New configuration: {}\".format(X))\n",
    "\n",
    "        thresholds = space_transform(X)\n",
    "        sample_mask = np.all(xyz_preds < thresholds, axis=1)\n",
    "\n",
    "        # print(f\"total sig = {np.sum(weights[binary_labels == 1])}\")\n",
    "        # print(f\"total bkg = {np.sum(weights[binary_labels == 0])}\")\n",
    "\n",
    "        num_sig = np.abs(\n",
    "            np.sum(\n",
    "                weights[\n",
    "                    np.logical_and(\n",
    "                        binary_labels == 1,\n",
    "                        sample_mask\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "\n",
    "        num_bkg = np.abs(\n",
    "            np.sum(\n",
    "                weights[\n",
    "                    np.logical_and(\n",
    "                        binary_labels == 0,\n",
    "                        sample_mask\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "\n",
    "        s_over_root_b = num_sig / np.sqrt(num_bkg)\n",
    "\n",
    "        if num_sig == 0 and num_bkg == 0:\n",
    "            both_0 = prefactor*1e1\n",
    "            if verbose:\n",
    "                print(f\"both sig and bkg 0 at this hyperplane => {both_0}\")\n",
    "            return both_0\n",
    "        elif num_sig < min_sig:\n",
    "            small_sig = prefactor*0\n",
    "            if verbose:\n",
    "                print(f\"too little sig ({num_sig}) at this hyperplane => {small_sig}\")\n",
    "            return small_sig\n",
    "        elif num_bkg == 0:\n",
    "            zero_bkg = -prefactor*num_sig\n",
    "            if verbose:\n",
    "                print(f\"zero bkg at this hyperplane (likely due to finite data rather than real bkg-free zone) => {zero_bkg}\")\n",
    "            return zero_bkg\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"s/âb = {s_over_root_b}, s = {num_sig}, b = {num_bkg}\")\n",
    "\n",
    "        return -prefactor*s_over_root_b\n",
    "    \n",
    "    res_gp = gp_minimize(\n",
    "        objective, space, random_state=rng_seed, \n",
    "        n_calls=(n_steps + (1 if len(np.shape(init_guess)) == 1 else np.shape(init_guess)[0])), \n",
    "        n_initial_points=n_steps, x0=init_guess\n",
    "    )\n",
    "\n",
    "    opt_params = [float(res_gp.x[i]) for i in range(len(space))]\n",
    "    opt_cuts = [float(opt_cut) for opt_cut in space_transform({param_names[i]: res_gp.x[i] for i in range(len(param_names))})]\n",
    "    if verbose:\n",
    "        print(\"Best parameters: {}\".format(opt_cuts))\n",
    "        print(f\"Best s/âb = {-res_gp.fun / prefactor}\")\n",
    "\n",
    "    return opt_cuts, opt_params\n",
    "\n",
    "\n",
    "def multi_optimize_cut_boundaries(preds: list, binary_labels: np.ndarray, weights: np.ndarray, num_categories: int=3, min_sig: float=0.2):\n",
    "    init_param_range = [(1e-8, 1e-7), (1e-6, 1e-5), (1e-2, 1e-1)]\n",
    "    init_guess = [5e-8, 5e-6, 5e-2]\n",
    "    clf_dict = {}\n",
    "    param_clf_dict = {}\n",
    "    for cat in range(num_categories):\n",
    "\n",
    "        clf_dict[cat] = []\n",
    "        param_clf_dict[cat] = []\n",
    "\n",
    "        if cat == 0:\n",
    "            sliced_preds = np.array(preds)\n",
    "            sliced_labels = binary_labels\n",
    "            sliced_weights = weights\n",
    "            param_range = init_param_range\n",
    "            guess = init_guess\n",
    "\n",
    "        else:\n",
    "            slice_array = np.ones_like(binary_labels, dtype=bool)\n",
    "            for prev_cat in range(cat):\n",
    "                slice_array = np.logical_and(\n",
    "                    slice_array,\n",
    "                    np.logical_not(\n",
    "                        np.all(\n",
    "                            p_to_xyz(np.array(preds), split=False) < clf_dict[prev_cat], \n",
    "                            axis=1\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            sliced_preds = np.array(preds)[slice_array]\n",
    "            sliced_labels = binary_labels[slice_array]\n",
    "            sliced_weights = weights[slice_array]\n",
    "            # param_range = [(param_clf_dict[cat-1][0], init_param_range[0][1]), (param_clf_dict[cat-1][1], init_param_range[1][1]), init_param_range[2]]\n",
    "            # guess = [param_clf_dict[cat-1][0] + 1e-11, param_clf_dict[cat-1][1] + 1e-11, 0.5 * init_param_range[2][1]]\n",
    "            param_range = init_param_range\n",
    "            guess = init_guess\n",
    "            \n",
    "        opt_cuts, opt_params = optimize_cuts(\n",
    "            sliced_preds, sliced_labels, sliced_weights, verbose=False,\n",
    "            param_range=param_range, init_guess=guess, n_steps=200, min_sig=min_sig, rng_seed=None\n",
    "        )\n",
    "\n",
    "        clf_dict[cat] = opt_cuts\n",
    "        param_clf_dict[cat] = opt_params\n",
    "\n",
    "    return clf_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "MC_NAMES_PRETTY = {\n",
    "    \"GGJets\": r\"$\\gamma\\gamma+3j$\",\n",
    "    \"GJetPt20To40\": r\"$\\gamma+j$, 20<$p_T$<40GeV\",\n",
    "    \"GJetPt40\": r\"$\\gamma+j$, 40GeV<$p_T$\",\n",
    "    \"GluGluHToGG\": r\"ggF $H\\rightarrow \\gamma\\gamma$\",\n",
    "    \"VBFHToGG\": r\"VBF $H\\rightarrow \\gamma\\gamma$\",\n",
    "    \"VHToGG\": r\"V$H\\rightarrow\\gamma\\gamma$\",\n",
    "    \"ttHToGG\": r\"$t\\bar{t}H\\rightarrow\\gamma\\gamma$\",\n",
    "    \"GluGluToHH\": r\"ggF $HH\\rightarrow bb\\gamma\\gamma$\",\n",
    "    # \"VBFHHto2B2G_CV_1_C2V_1_C3_1\": r\"VBF $HH\\rightarrow bb\\gamma\\gamma$\",\n",
    "    \"signal\": r\"ggF $HH\\rightarrow bb\\gamma\\gamma$ + VBF $HH\\rightarrow bb\\gamma\\gamma$\",\n",
    "    # Names for order #\n",
    "    \"ggF HH\": r\"ggF $H\\rightarrow \\gamma\\gamma$\",\n",
    "    \"ttH\": r\"$t\\bar{t}H\\rightarrow\\gamma\\gamma$\",\n",
    "    \"single-H\": r\"ggF $H\\rightarrow \\gamma\\gamma$ + VBF $H\\rightarrow \\gamma\\gamma$ + V$H\\rightarrow\\gamma\\gamma$\",\n",
    "    \"non-res\": r\"$\\gamma\\gamma+3j$ + $\\gamma+j$, 20GeV<$p_T$\",\n",
    "    \"VH\": r\"V$H\\rightarrow\\gamma\\gamma$\",\n",
    "    \"non-res + ggFH + VBFH\": r\"$\\gamma\\gamma+3j$ + $\\gamma+j$, 20GeV<$p_T$ + ggF $H\\rightarrow \\gamma\\gamma$ + VBF $H\\rightarrow \\gamma\\gamma$\"\n",
    "    # Need to fill in pretty print for BSM samples #\n",
    "}\n",
    "LUMINOSITIES = {\n",
    "    '2022preEE': 7.9804, \n",
    "    '2022postEE': 26.6717,\n",
    "    # Need to fill in lumis for other eras #\n",
    "}\n",
    "LUMINOSITIES['total_lumi'] = sum(LUMINOSITIES.values())\n",
    "\n",
    "# Dictionary of variables\n",
    "VARIABLES = {\n",
    "    # key: hist.axis axes for plotting #\n",
    "    # MET variables\n",
    "    'puppiMET_sumEt': hist.axis.Regular(40, 150., 2000, name='var', label=r'puppiMET $\\Sigma E_T$ [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'puppiMET_pt': hist.axis.Regular(40, 20., 250, name='var', label=r'puppiMET $p_T$ [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'puppiMET_phi': hist.axis.Regular(20,-3.2, 3.2, name='var', label=r'puppiMET $\\phi$', growth=False, underflow=False, overflow=False), \n",
    "    # jet-MET variables\n",
    "    'DeltaPhi_j1MET': hist.axis.Regular(20,-3.2, 3.2, name='var', label=r'$\\Delta\\phi (j_1,E_T^{miss})$', growth=False, underflow=False, overflow=False), \n",
    "    'DeltaPhi_j2MET': hist.axis.Regular(20, -3.2, 3.2, name='var', label=r'$\\Delta\\phi (j_2,E_T^{miss})$', growth=False, underflow=False, overflow=False), \n",
    "    # jet-photon variables\n",
    "    'DeltaR_jg_min': hist.axis.Regular(30, 0, 5, name='var', label=r'min$(\\Delta R(jet, \\gamma))$', growth=False, underflow=False, overflow=False), \n",
    "    # jet variables\n",
    "    # 'jet1_pt': hist.axis.Regular(40, 20., 250, name='var', label=r'lead jet $p_T$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    # 'jet2_pt': hist.axis.Regular(40, 20., 250, name='var', label=r'sublead jet $p_T$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    'lead_bjet_pt': hist.axis.Regular(40, 20., 250, name='var', label=r'lead bjet $p_T$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    'lead_bjet_eta': hist.axis.Regular(20, -5., 5., name='var', label=r'lead bjet $\\eta$', growth=False, underflow=False, overflow=False),\n",
    "    'lead_bjet_phi': hist.axis.Regular(20, -3.2, 3.2, name='var', label=r'lead bjet $\\phi$', growth=False, underflow=False, overflow=False),\n",
    "    'sublead_bjet_pt': hist.axis.Regular(40, 20., 250, name='var', label=r'lead bjet $p_T$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    'sublead_bjet_eta': hist.axis.Regular(20, -5., 5., name='var', label=r'lead bjet $\\eta$', growth=False, underflow=False, overflow=False),\n",
    "    'sublead_bjet_phi': hist.axis.Regular(20, -3.2, 3.2, name='var', label=r'lead bjet $\\phi$', growth=False, underflow=False, overflow=False),\n",
    "    'n_jets': hist.axis.Integer(0, 10, name='var', label=r'$n_{jets}$', growth=False, underflow=False, overflow=False), \n",
    "    'chi_t0': hist.axis.Regular(40, 0., 150, name='var', label=r'$\\chi_{t0}^2$', growth=False, underflow=False, overflow=False), \n",
    "    'chi_t1': hist.axis.Regular(30, 0., 500, name='var', label=r'$\\chi_{t1}^2$', growth=False, underflow=False, overflow=False), \n",
    "    # lepton variables\n",
    "    'n_leptons': hist.axis.Integer(0, 10, name='var', label=r'$n_{leptons}$', growth=False, underflow=False, overflow=False),\n",
    "    'lepton1_pt': hist.axis.Regular(40, 0., 200., name='var', label=r'lead lepton $p_T$ [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'lepton2_pt': hist.axis.Regular(40, 0., 200., name='var', label=r'sublead lepton $p_T$ [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'lepton1_eta': hist.axis.Regular(30, -5., 5., name='var', label=r'lead lepton $\\eta$', growth=False, underflow=False, overflow=False), \n",
    "    'lepton2_eta': hist.axis.Regular(30, -5., 5., name='var', label=r'sublead lepton $\\eta$', growth=False, underflow=False, overflow=False),\n",
    "    'lepton1_phi': hist.axis.Regular(20, -3.2, 3.2, name='var', label=r'lead lepton $\\phi$', growth=False, underflow=False, overflow=False), \n",
    "    'lepton2_phi': hist.axis.Regular(20, -3.2, 3.2, name='var', label=r'sublead lepton $\\phi$', growth=False, underflow=False, overflow=False),\n",
    "    # diphoton variables\n",
    "    'pt': hist.axis.Regular(40, 20., 2000, name='var', label=r' $\\gamma\\gamma p_{T}$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    'eta': hist.axis.Regular(20, -5., 5., name='var', label=r'$\\gamma\\gamma \\eta$', growth=False, underflow=False, overflow=False), \n",
    "    'phi': hist.axis.Regular(20, -3.2, 3.2, name='var', label=r'$\\gamma \\gamma \\phi$', growth=False, underflow=False, overflow=False),\n",
    "    # angular (cos) variables\n",
    "    'abs_CosThetaStar_CS': hist.axis.Regular(20, 0, 1, name='var', label=r'|cos$(\\theta_{CS})$|', growth=False, underflow=False, overflow=False), \n",
    "    'abs_CosThetaStar_jj': hist.axis.Regular(20, 0, 1, name='var', label=r'|cos$(\\theta_{jj})$|', growth=False, underflow=False, overflow=False),\n",
    "    'CosThetaStar_CS': hist.axis.Regular(20, -1, 1, name='var', label=r'cos$(\\theta_{CS})$', growth=False, underflow=False, overflow=False), \n",
    "    'CosThetaStar_jj': hist.axis.Regular(20, -1, 1, name='var', label=r'cos$(\\theta_{jj})$', growth=False, underflow=False, overflow=False), \n",
    "    # jet-lepton variables\n",
    "    'leadBjet_leadLepton': hist.axis.Regular(30, 0, 5, name='var', label=r'$\\Delta R(bjet_{lead}, l_{lead})$', growth=False, underflow=False, overflow=False), \n",
    "    'leadBjet_subleadLepton': hist.axis.Regular(30, 0, 5, name='var', label=r'$\\Delta R(bjet_{lead}, l_{sublead})$', growth=False, underflow=False, overflow=False), \n",
    "    'subleadBjet_leadLepton': hist.axis.Regular(30, 0, 5, name='var', label=r'$\\Delta R(bjet_{sublead}, l_{lead})$', growth=False, underflow=False, overflow=False), \n",
    "    'subleadBjet_subleadLepton': hist.axis.Regular(30, 0, 5, name='var', label=r'$\\Delta R(bjet_{sublead}, l_{sublead})$', growth=False, underflow=False, overflow=False),\n",
    "    # dijet variables (must be blinded on data)\n",
    "    'dijet_mass': hist.axis.Regular(25, 25., 180., name='var', label=r'$M_{jj}$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    # diphoton variables (must be blinded on data)\n",
    "    'mass': hist.axis.Regular(25, 25., 180., name='var', label=r'$M_{\\gamma\\gamma}$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    # Yibo's BDT variables\n",
    "    'lead_mvaID': hist.axis.Regular(50, -1., 1., name='var', label=r'$\\gamma_{lead}$ MVA ID', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_mvaID': hist.axis.Regular(50, -1., 1., name='var', label=r'$\\gamma_{sublead}$ MVA ID', growth=False, underflow=False, overflow=False),\n",
    "    'CosThetaStar_gg': hist.axis.Regular(50, -1., 1., name='var', label=r'cos$(\\theta_{gg})$', growth=False, underflow=False, overflow=False),\n",
    "    'lead_pt_over_Mgg': hist.axis.Regular(50, 0., 1., name='var', label=r'$p_{T,\\gamma_1} / M_{\\gamma\\gamma}$', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_pt_over_Mgg': hist.axis.Regular(50, 0., 1., name='var', label=r'$p_{T,\\gamma_2} / M_{\\gamma\\gamma}$', growth=False, underflow=False, overflow=False),\n",
    "    'lead_sigmaE_over_E': hist.axis.Regular(50, 0., 1., name='var', label=r'$\\sigma {E,\\gamma_1} / E_{\\gamma\\gamma}$', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_sigmaE_over_E': hist.axis.Regular(50, 0., 1., name='var', label=r'$\\sigma {E,\\gamma_2} / E_{\\gamma\\gamma}$', growth=False, underflow=False, overflow=False),\n",
    "    'lead_bjet_pt_over_Mjj': hist.axis.Regular(50, 0., 1., name='var', label=r'$p_{T,j1} / M_{jj}$', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_bjet_pt_over_Mjj': hist.axis.Regular(50, 0., 1., name='var', label=r'$p_{T,j2} / M_{jj}$', growth=False, underflow=False, overflow=False),\n",
    "    'lead_bjet_btagPNetB': hist.axis.Regular(50, -1., 1., name='var', label=r'$j_{lead}$ PNet btag score', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_bjet_btagPNetB': hist.axis.Regular(50, -1., 1., name='var', label=r'$j_{sublead}$ PNet btag score', growth=False, underflow=False, overflow=False),\n",
    "    'lead_bjet_sigmapT_over_pT': hist.axis.Regular(50, 0., 1., name='var', label=r'$\\sigma p_{T,j1} / p_{T,jj}$', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_bjet_sigmapT_over_pT': hist.axis.Regular(50, 0., 1., name='var', label=r'$\\sigma p_{T,j2} / p_{T,jj}$', growth=False, underflow=False, overflow=False),\n",
    "    'dipho_mass_over_Mggjj': hist.axis.Regular(50, 0., 1., name='var', label=r'$M_{\\gamma\\gamma} / M_{\\gamma\\gamma jj}$', growth=False, underflow=False, overflow=False), \n",
    "    'dijet_mass_over_Mggjj': hist.axis.Regular(50, 0., 1., name='var', label=r'$M_{jj} / M_{\\gamma\\gamma jj}$', growth=False, underflow=False, overflow=False),\n",
    "    # My variables for non-reso reduction #\n",
    "    'lead_pfRelIso03_all_quadratic': hist.axis.Regular(50, -1., 1., name='var', label=r'$\\gamma_{lead}$ PF RelIso03 all quad.', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_pfRelIso03_all_quadratic': hist.axis.Regular(50, -1., 1., name='var', label=r'$\\gamma_{sublead}$ PF RelIso03 all quad.', growth=False, underflow=False, overflow=False),\n",
    "    # Michael's DNN variables #\n",
    "    'DeltaR_j1g1': hist.axis.Regular(50, 0., 5., name='var', label=r'$\\Delta R(bjet_{lead}, \\gamma_{lead})$', growth=False, underflow=False, overflow=False), \n",
    "    'DeltaR_j1g2': hist.axis.Regular(50, 0., 5., name='var', label=r'$\\Delta R(bjet_{lead}, \\gamma_{sublead})$', growth=False, underflow=False, overflow=False), \n",
    "    'DeltaR_j2g1': hist.axis.Regular(50, 0., 5., name='var', label=r'$\\Delta R(bjet_{sublead}, \\gamma_{lead})$', growth=False, underflow=False, overflow=False), \n",
    "    'DeltaR_j2g2': hist.axis.Regular(50, 0., 5., name='var', label=r'$\\Delta R(bjet_{sublead}, \\gamma_{sublead})$', growth=False, underflow=False, overflow=False),\n",
    "    'HHbbggCandidate_pt': hist.axis.Regular(100, 0., 700., name='var', label=r'HH $p_T$ [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'HHbbggCandidate_eta': hist.axis.Regular(50, -5., 5., name='var', label=r'HH $\\eta$', growth=False, underflow=False, overflow=False), \n",
    "    'HHbbggCandidate_phi': hist.axis.Regular(50, -3.2, 3.2, name='var', label=r'HH $\\phi$', growth=False, underflow=False, overflow=False),\n",
    "    'HHbbggCandidate_mass': hist.axis.Regular(25, 0., 700., name='var', label=r'$M_{HH}$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    # ATLAS variables #\n",
    "    'pt_balance': hist.axis.Regular(100, 0., 2., name='var', label=r'$p_{T,HH} / (p_{T,\\gamma1} + p_{T,\\gamma2} + p_{T,j1} + p_{T,j2})$', growth=False, underflow=False, overflow=False), \n",
    "    # VH variables #\n",
    "    'DeltaPhi_jj': hist.axis.Regular(20, -3.2, 3.2, name='var', label=r'$\\Delta\\phi (j_1,j_2)$', growth=False, underflow=False, overflow=False),\n",
    "    'DeltaEta_jj': hist.axis.Regular(20, 0., 10., name='var', label=r'$\\Delta\\eta (j_1,j_2)$', growth=False, underflow=False, overflow=False),\n",
    "    'isr_jet_pt': hist.axis.Regular(100, 0., 200., name='var', label=r'ISR jet $p_T$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    'DeltaPhi_isr_jet_z': hist.axis.Regular(20, -3.2, 3.2, name='var', label=r'$\\Delta\\phi (j_{ISR},jj)$', growth=False, underflow=False, overflow=False),\n",
    "    'dijet_pt': hist.axis.Regular(100, 0., 500., name='var', label=r'jj $p_T$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    'lepton1_pfIsoId': hist.axis.Regular(50, -1., 1., name='var', label=r'$l_{lead}$ PF IsoId', growth=False, underflow=False, overflow=False), \n",
    "    'lepton1_mvaID': hist.axis.Regular(50, -1., 1., name='var', label=r'$\\l_{lead}$ MVA ID', growth=False, underflow=False, overflow=False), \n",
    "}\n",
    "# Dictionary of variables to do MC/Data comparison\n",
    "VARIABLES_STD = {\n",
    "    # key: hist.axis axes for plotting #\n",
    "    # MET variables\n",
    "    'puppiMET_sumEt': hist.axis.Regular(40, -4., 4., name='var', label=r'puppiMET ln($\\Sigma E_T$) [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'puppiMET_pt': hist.axis.Regular(40, -4., 4., name='var', label=r'puppiMET ln($p_T$) [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'puppiMET_phi': hist.axis.Regular(40, -4., 4., name='var', label=r'puppiMET $\\phi$', growth=False, underflow=False, overflow=False), \n",
    "    # jet-MET variables\n",
    "    'DeltaPhi_j1MET': hist.axis.Regular(40, -4., 4., name='var', label=r'$\\Delta\\phi (j_1,E_T^{miss})$', growth=False, underflow=False, overflow=False), \n",
    "    'DeltaPhi_j2MET': hist.axis.Regular(40, -4., 4., name='var', label=r'$\\Delta\\phi (j_2,E_T^{miss})$', growth=False, underflow=False, overflow=False), \n",
    "    # jet-photon variables\n",
    "    'DeltaR_jg_min': hist.axis.Regular(40, -4., 4., name='var', label=r'min$(\\Delta R(jet, \\gamma))$', growth=False, underflow=False, overflow=False), \n",
    "    # jet variables\n",
    "    'lead_bjet_pt': hist.axis.Regular(40, -4., 4., name='var', label=r'lead bjet ln($p_T$) [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_bjet_pt': hist.axis.Regular(40, -4., 4., name='var', label=r'sublead bjet ln($p_T$) [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'lead_bjet_eta': hist.axis.Regular(40, -4., 4., name='var', label=r'lead bjet $\\eta$', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_bjet_eta': hist.axis.Regular(40, -4., 4., name='var', label=r'sublead bjet $\\eta$', growth=False, underflow=False, overflow=False),\n",
    "    'lead_bjet_phi': hist.axis.Regular(40, -4., 4., name='var', label=r'lead bjet $\\phi$', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_bjet_phi': hist.axis.Regular(40, -4., 4., name='var', label=r'sublead bjet $\\phi$', growth=False, underflow=False, overflow=False),\n",
    "    'n_jets': hist.axis.Regular(12, -4., 4., name='var', label=r'$n_{jets}$', growth=False, underflow=False, overflow=False), \n",
    "    'chi_t0': hist.axis.Regular(40, -4., 10., name='var', label=r'ln($\\chi_{t0}^2$)', growth=False, underflow=False, overflow=False), \n",
    "    'chi_t1': hist.axis.Regular(40, -4., 10., name='var', label=r'ln($\\chi_{t1}^2$)', growth=False, underflow=False, overflow=False), \n",
    "    # lepton variables\n",
    "    'n_leptons': hist.axis.Regular(12, -4., 4., name='var', label=r'$n_{leptons}$', growth=False, underflow=False, overflow=False),\n",
    "    'lepton1_pt': hist.axis.Regular(40, -4., 4., name='var', label=r'lead lepton ln($p_T$) [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'lepton2_pt': hist.axis.Regular(40, -4., 4., name='var', label=r'sublead lepton ln($p_T$) [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'lepton1_eta': hist.axis.Regular(40, -4., 4., name='var', label=r'lead lepton $\\eta$', growth=False, underflow=False, overflow=False), \n",
    "    'lepton2_eta': hist.axis.Regular(40, -4., 4., name='var', label=r'sublead lepton $\\eta$', growth=False, underflow=False, overflow=False),\n",
    "    'lepton1_phi': hist.axis.Regular(40, -4., 4., name='var', label=r'lead lepton $\\phi$', growth=False, underflow=False, overflow=False), \n",
    "    'lepton2_phi': hist.axis.Regular(40, -4., 4., name='var', label=r'sublead lepton $\\phi$', growth=False, underflow=False, overflow=False),\n",
    "    # diphoton variables\n",
    "    'pt': hist.axis.Regular(40, -4., 4., name='var', label=r' $\\gamma\\gamma$ ln($p_{T}$) [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    'eta': hist.axis.Regular(40, -4., 4., name='var', label=r'$\\gamma\\gamma \\eta$', growth=False, underflow=False, overflow=False), \n",
    "    'phi': hist.axis.Regular(40, -4., 4., name='var', label=r'$\\gamma \\gamma \\phi$', growth=False, underflow=False, overflow=False),\n",
    "    # angular (cos) variables\n",
    "    'abs_CosThetaStar_CS': hist.axis.Regular(40, -4., 4., name='var', label=r'|cos$(\\theta_{CS})$|', growth=False, underflow=False, overflow=False), \n",
    "    'abs_CosThetaStar_jj': hist.axis.Regular(40, -4., 4., name='var', label=r'|cos$(\\theta_{jj})$|', growth=False, underflow=False, overflow=False), \n",
    "    'CosThetaStar_CS': hist.axis.Regular(40, -1., 1., name='var', label=r'cos$(\\theta_{CS})$', growth=False, underflow=False, overflow=False), \n",
    "    'CosThetaStar_jj': hist.axis.Regular(40, -1., 1., name='var', label=r'cos$(\\theta_{jj})$', growth=False, underflow=False, overflow=False), \n",
    "    # jet-lepton variables\n",
    "    'leadBjet_leadLepton': hist.axis.Regular(40, -4., 4., name='var', label=r'$\\Delta R(bjet_{lead}, l_{lead})$', growth=False, underflow=False, overflow=False), \n",
    "    'leadBjet_subleadLepton': hist.axis.Regular(40, -4., 4., name='var', label=r'$\\Delta R(bjet_{lead}, l_{sublead})$', growth=False, underflow=False, overflow=False), \n",
    "    'subleadBjet_leadLepton': hist.axis.Regular(40, -4., 4., name='var', label=r'$\\Delta R(bjet_{sublead}, l_{lead})$', growth=False, underflow=False, overflow=False), \n",
    "    'subleadBjet_subleadLepton': hist.axis.Regular(40, -4., 4., name='var', label=r'$\\Delta R(bjet_{sublead}, l_{sublead})$', growth=False, underflow=False, overflow=False),\n",
    "    # dijet variables (must be blinded on data)\n",
    "    'dijet_mass': hist.axis.Regular(40, -4., 4., name='var', label=r'ln($M_{jj}$) [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    # diphoton variables (must be blinded on data)\n",
    "    'mass': hist.axis.Regular(40, -4., 4., name='var', label=r'$M_{\\gamma\\gamma}$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    # Yibo's BDT variables\n",
    "    'lead_mvaID': hist.axis.Regular(50, -4., 4., name='var', label=r'$\\gamma_{lead}$ MVA ID', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_mvaID': hist.axis.Regular(50, -4., 4., name='var', label=r'$\\gamma_{sublead}$ MVA ID', growth=False, underflow=False, overflow=False),\n",
    "    'CosThetaStar_gg': hist.axis.Regular(50, -1., 1., name='var', label=r'cos$(\\theta_{gg})$', growth=False, underflow=False, overflow=False),\n",
    "    'lead_pt_over_Mgg': hist.axis.Regular(50, -4., 4., name='var', label=r'$p_{T,\\gamma_1} / M_{\\gamma\\gamma}$', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_pt_over_Mgg': hist.axis.Regular(50, -4., 4., name='var', label=r'$p_{T,\\gamma_2} / M_{\\gamma\\gamma}$', growth=False, underflow=False, overflow=False),\n",
    "    'lead_sigmaE_over_E': hist.axis.Regular(50, -4., 4., name='var', label=r'$\\sigma {E,\\gamma_1} / E_{\\gamma\\gamma}$', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_sigmaE_over_E': hist.axis.Regular(50, -4., 4., name='var', label=r'$\\sigma {E,\\gamma_2} / E_{\\gamma\\gamma}$', growth=False, underflow=False, overflow=False),\n",
    "    'lead_bjet_pt_over_Mjj': hist.axis.Regular(50, -4., 4., name='var', label=r'$p_{T,j1} / M_{jj}$', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_bjet_pt_over_Mjj': hist.axis.Regular(50, -4., 4., name='var', label=r'$p_{T,j2} / M_{jj}$', growth=False, underflow=False, overflow=False),\n",
    "    'lead_bjet_btagPNetB': hist.axis.Regular(50, -4., 4., name='var', label=r'$j_{lead}$ PNet btag score', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_bjet_btagPNetB': hist.axis.Regular(50, -4., 4., name='var', label=r'$j_{sublead}$ PNet btag score', growth=False, underflow=False, overflow=False),\n",
    "    'lead_bjet_sigmapT_over_pT': hist.axis.Regular(50, -4., 4., name='var', label=r'$\\sigma p_{T,j1} / p_{T,jj}$', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_bjet_sigmapT_over_pT': hist.axis.Regular(50, -4., 4., name='var', label=r'$\\sigma p_{T,j2} / p_{T,jj}$', growth=False, underflow=False, overflow=False),\n",
    "    'dipho_mass_over_Mggjj': hist.axis.Regular(50, -4., 4., name='var', label=r'$M_{\\gamma\\gamma} / M_{\\gamma\\gamma jj}$', growth=False, underflow=False, overflow=False), \n",
    "    'dijet_mass_over_Mggjj': hist.axis.Regular(50, -4., 4., name='var', label=r'$M_{jj} / M_{\\gamma\\gamma jj}$', growth=False, underflow=False, overflow=False),\n",
    "    # My variables for non-reso reduction #\n",
    "    'lead_pfRelIso03_all_quadratic': hist.axis.Regular(50, -4., 4., name='var', label=r'$\\gamma_{lead}$ PF RelIso03 all quad.', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_pfRelIso03_all_quadratic': hist.axis.Regular(50, -4., 4., name='var', label=r'$\\gamma_{sublead}$ PF RelIso03 all quad.', growth=False, underflow=False, overflow=False),\n",
    "    # Michael's DNN variables #\n",
    "    'DeltaR_j1g1': hist.axis.Regular(50, -4., 4., name='var', label=r'$\\Delta R(bjet_{lead}, \\gamma_{lead})$', growth=False, underflow=False, overflow=False), \n",
    "    'DeltaR_j1g2': hist.axis.Regular(50, -4., 4., name='var', label=r'$\\Delta R(bjet_{lead}, \\gamma_{sublead})$', growth=False, underflow=False, overflow=False), \n",
    "    'DeltaR_j2g1': hist.axis.Regular(50, -4., 4., name='var', label=r'$\\Delta R(bjet_{sublead}, \\gamma_{lead})$', growth=False, underflow=False, overflow=False), \n",
    "    'DeltaR_j2g2': hist.axis.Regular(50, -4., 4., name='var', label=r'$\\Delta R(bjet_{sublead}, \\gamma_{sublead})$', growth=False, underflow=False, overflow=False),\n",
    "    'HHbbggCandidate_pt': hist.axis.Regular(100, -4., 4., name='var', label=r'HH ln($p_T$) [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'HHbbggCandidate_eta': hist.axis.Regular(50, -4., 4., name='var', label=r'HH $\\eta$', growth=False, underflow=False, overflow=False), \n",
    "    'HHbbggCandidate_phi': hist.axis.Regular(50, -4., 4., name='var', label=r'HH $\\phi$', growth=False, underflow=False, overflow=False),\n",
    "    'HHbbggCandidate_mass': hist.axis.Regular(50, -4., 4., name='var', label=r'ln($M_{HH}$) [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    # ATLAS variables #\n",
    "    'pt_balance': hist.axis.Regular(100, -4., 4., name='var', label=r'ln($p_{T,HH} / (p_{T,\\gamma1} + p_{T,\\gamma2} + p_{T,j1} + p_{T,j2})$)', growth=False, underflow=False, overflow=False), \n",
    "    # VH variables #\n",
    "    'DeltaPhi_jj': hist.axis.Regular(20, -4., 4., name='var', label=r'$\\Delta\\phi (j_1,j_2)$', growth=False, underflow=False, overflow=False),\n",
    "    'DeltaEta_jj': hist.axis.Regular(20, -4., 4., name='var', label=r'$\\Delta\\eta (j_1,j_2)$', growth=False, underflow=False, overflow=False),\n",
    "    'isr_jet_pt': hist.axis.Regular(100, -4., 4., name='var', label=r'ISR jet ln($p_T$) [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    'DeltaPhi_isr_jet_z': hist.axis.Regular(20, -4., 4., name='var', label=r'$\\Delta\\phi (j_{ISR},jj)$', growth=False, underflow=False, overflow=False),\n",
    "    'dijet_pt': hist.axis.Regular(100, -4., 4., name='var', label=r'jj ln($p_T$) [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    'lepton1_pfIsoId': hist.axis.Regular(50, -4., 4., name='var', label=r'$l_{lead}$ PF IsoId', growth=False, underflow=False, overflow=False), \n",
    "    'lepton1_mvaID': hist.axis.Regular(50, -4., 4., name='var', label=r'$\\l_{lead}$ MVA ID', growth=False, underflow=False, overflow=False), \n",
    "}\n",
    "\n",
    "\n",
    "def make_input_plot(\n",
    "    output_dir, var_name, hist_list, fold_idx=None, labels=None, density=True, \n",
    "    plot_prefix='', plot_postfix='', alpha=0.8, linestyle=True\n",
    "):\n",
    "    fig, ax = plt.subplots()\n",
    "    if linestyle:\n",
    "        if fold_idx is not None:\n",
    "            linestyles = [\"solid\", \"dashed\", \"dotted\", \"solid\", \"dashed\", \"dotted\"]\n",
    "        else:\n",
    "            linestyles = [\"solid\", \"dotted\", \"solid\", \"dotted\"]\n",
    "        linestyles = linestyles * ((len(hist_list) // len(linestyles)) + 1)\n",
    "        linestyles = linestyles[:len(hist_list)]\n",
    "    else:\n",
    "        linestyles = None\n",
    "    hep.histplot(\n",
    "        hist_list, ax=ax, linewidth=3, histtype=\"step\", yerr=True, density=density,\n",
    "        linestyle=linestyles, label=labels, alpha=alpha\n",
    "    )\n",
    "    # Plotting niceties #\n",
    "    hep.cms.lumitext(f\"{LUMINOSITIES['total_lumi']:.2f}\" + r\"fb$^{-1}$ (13.6 TeV)\", ax=ax)\n",
    "    hep.cms.text(\"Work in Progress\", ax=ax)\n",
    "    # Plot legend properly\n",
    "    ax.legend(bbox_to_anchor=(1, 0.5))\n",
    "    # Make angular and chi^2 plots linear, otherwise log\n",
    "    if re.match('chi_t', var_name) is None and re.match('DeltaPhi', var_name) is None and re.match('mass', var_name) is None:\n",
    "        ax.set_yscale('log')\n",
    "    else:\n",
    "        ax.set_yscale('linear')\n",
    "    ax.set_yscale('linear')\n",
    "    # Save out the plot\n",
    "    if fold_idx is not None:\n",
    "        plt.savefig(f'{output_dir}/{plot_prefix}1dhist_{var_name}{plot_postfix}_fold{fold_idx}.pdf', bbox_inches='tight')\n",
    "        plt.savefig(f'{output_dir}/{plot_prefix}1dhist_{var_name}{plot_postfix}_fold{fold_idx}.png', bbox_inches='tight')\n",
    "    else:\n",
    "        plt.savefig(f'{output_dir}/{plot_prefix}1dhist_{var_name}{plot_postfix}.pdf', bbox_inches='tight')\n",
    "        plt.savefig(f'{output_dir}/{plot_prefix}1dhist_{var_name}{plot_postfix}.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss per Epoch Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"losses\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "if 'BDT_perf' not in globals():\n",
    "    with open(os.path.join(OUTPUT_DIRPATH, CURRENT_TIME+\"_BDT_perf.json\"), 'r') as f:\n",
    "        BDT_perf = json.load(f)\n",
    "\n",
    "if 'evals_result_dict' not in globals():\n",
    "    with open(os.path.join(OUTPUT_DIRPATH, CURRENT_TIME+\"_BDT_eval_result.json\"), 'r') as f:\n",
    "        evals_result_dict = json.load(f)\n",
    "\n",
    "# plot train/val/test losses\n",
    "all_train, all_val, all_test = [], [], []\n",
    "for fold_idx in range(len(evals_result_dict)):\n",
    "    all_train.append(evals_result_dict[f\"fold_{fold_idx}\"]['train']['mlogloss'])\n",
    "    all_val.append(evals_result_dict[f\"fold_{fold_idx}\"]['val']['mlogloss'])\n",
    "    all_test.append(evals_result_dict[f\"fold_{fold_idx}\"]['test']['mlogloss'])\n",
    "\n",
    "plot_train_val_losses(\n",
    "    all_train + all_val, [f'train fold {i}' for i in range(len(all_train))]+[f'val fold {i}' for i in range(len(all_val))],\n",
    "    'train_val_losses_vs_epoch', plot_dirpath, \n",
    "    linestyles=['solid']*len(all_train) + ['dashed']*len(all_val),\n",
    ")\n",
    "plot_train_val_losses(\n",
    "    all_train + all_test, [f'train fold {i}' for i in range(len(all_train))]+[f'test fold {i}' for i in range(len(all_test))],\n",
    "    'train_test_losses_vs_epoch', plot_dirpath,\n",
    "    linestyles=['solid']*len(all_train) + ['dotted']*len(all_test),\n",
    ")\n",
    "avg_train, avg_val, avg_test = np.mean(pad_list(all_train), axis=0), np.mean(pad_list(all_val), axis=0), np.mean(pad_list(all_test), axis=0)\n",
    "std_train, std_val, std_test = np.std(pad_list(all_train), axis=0), np.std(pad_list(all_val), axis=0), np.std(pad_list(all_test), axis=0)\n",
    "plot_train_val_losses(\n",
    "    [avg_train, avg_val, avg_test], ['train avg', 'val avg', 'test avg'],\n",
    "    'train_val_test_avg_vs_epoch', plot_dirpath,\n",
    "    losses_std_arrs=[std_train, std_val, std_test],\n",
    "    linestyles=['solid', 'dashed', 'dotted'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"ROCs\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "if 'BDT_perf' not in globals():\n",
    "    with open(os.path.join(OUTPUT_DIRPATH, CURRENT_TIME+\"_BDT_perf.json\"), 'r') as f:\n",
    "        BDT_perf = json.load(f)\n",
    "\n",
    "base_tpr = np.array(BDT_perf['ggF HH']['base_tpr'])\n",
    "\n",
    "# plot ROCs\n",
    "for j, sample_name in enumerate(order):\n",
    "\n",
    "    for fold_idx in range(len(bdt_train_dict)):\n",
    "\n",
    "        for roc_type in ['density', 'weighted']:\n",
    "\n",
    "            fprs = [np.array(BDT_perf[sample_name][f'fprs_{roc_type}'][fold_idx])[:, i] for i in range(len(order))]\n",
    "            tprs = [base_tpr for _ in range(len(order))]\n",
    "            labels = [\n",
    "                f\"{sample_name} vs. {'all' if i == j else sample_name_}, AUC = {BDT_perf[sample_name][f'areas_{roc_type}'][fold_idx][i]:.4f}\" \n",
    "                for i, sample_name_ in enumerate(order)\n",
    "            ]\n",
    "\n",
    "            plot_rocs(fprs, tprs, labels, f\"BDT_roc_{sample_name}_{roc_type}_testData_fold{fold_idx}\", plot_dirpath)\n",
    "\n",
    "    for roc_type in ['sum_density', 'sum_weighted']:\n",
    "\n",
    "        fprs = [np.array(BDT_perf[sample_name][f'fprs_{roc_type}'])[:, i] for i in range(len(order))]\n",
    "        tprs = [base_tpr for _ in range(len(order))]\n",
    "        labels = [\n",
    "            f\"{sample_name} vs. {'all' if i == j else sample_name_}, AUC = {BDT_perf[sample_name][f'areas_{roc_type}'][i]:.4f}\" \n",
    "            for i, sample_name_ in enumerate(order)\n",
    "        ]\n",
    "\n",
    "        plot_rocs(fprs, tprs, labels, f\"BDT_roc_{sample_name}_{roc_type}_testData_sum\", plot_dirpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Score Dist Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"output_scores\")\n",
    "# plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"output_scores_arctanh\")\n",
    "# plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"output_scores_resample\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "if 'BDT_perf' not in globals():\n",
    "    with open(os.path.join(OUTPUT_DIRPATH, CURRENT_TIME+\"_BDT_perf.json\"), 'r') as f:\n",
    "        BDT_perf = json.load(f)\n",
    "\n",
    "# plot Output scores\n",
    "for j, sample_name in enumerate(order):\n",
    "\n",
    "    for i, sample_name_ in enumerate(order):\n",
    "\n",
    "        for fold_idx in range(len(bdt_train_dict)):\n",
    "            \n",
    "            sigs_and_bkgs = {\n",
    "                sample_name__: np.array(BDT_perf[sample_name]['preds'][fold_idx])[:, j][bdt_test_dict[f\"fold_{fold_idx}\"].get_label() == k]\n",
    "                for k, sample_name__ in enumerate(order)\n",
    "            }\n",
    "            score_weights = {\n",
    "                sample_name__: weights_plot_test[f\"fold_{fold_idx}\"][bdt_test_dict[f\"fold_{fold_idx}\"].get_label() == k]\n",
    "                for k, sample_name__ in enumerate(order)\n",
    "            }\n",
    "\n",
    "            if sample_name_ != sample_name:\n",
    "                event_j_mask = bdt_test_dict[f\"fold_{fold_idx}\"].get_label() == j\n",
    "                pred_j_rescale = np.array(BDT_perf[sample_name]['preds'][fold_idx])[:, j][event_j_mask] + np.array(BDT_perf[sample_name]['preds'][fold_idx])[:, i][event_j_mask]\n",
    "                event_i_mask = bdt_test_dict[f\"fold_{fold_idx}\"].get_label() == i\n",
    "                pred_i_rescale = np.array(BDT_perf[sample_name]['preds'][fold_idx])[:, j][event_i_mask] + np.array(BDT_perf[sample_name]['preds'][fold_idx])[:, i][event_i_mask]\n",
    "\n",
    "                for sample_name__ in order:\n",
    "                    if sample_name__ == sample_name:\n",
    "                        sigs_and_bkgs[sample_name__] = sigs_and_bkgs[sample_name__] / pred_j_rescale\n",
    "                    elif sample_name__ == sample_name_:\n",
    "                        sigs_and_bkgs[sample_name__] = sigs_and_bkgs[sample_name__] / pred_i_rescale\n",
    "                    else:\n",
    "                        del sigs_and_bkgs[sample_name__]\n",
    "                        del score_weights[sample_name__]\n",
    "\n",
    "            if re.search('arctanh', plot_dirpath) is not None:\n",
    "                for key, value in sigs_and_bkgs.items():\n",
    "                    sigs_and_bkgs[key] = np.arctanh(value)\n",
    "\n",
    "            plot_output_scores(\n",
    "                sigs_and_bkgs, order, \n",
    "                f\"BDT_{sample_name}_vs_{sample_name_ if sample_name_ != sample_name else 'all'}_outputScoreWeighted_testData_fold{fold_idx}\", \n",
    "                plot_dirpath, weights=score_weights, log=True,\n",
    "                arctanh=True if re.search('arctanh', plot_dirpath) is not None else False\n",
    "            )\n",
    "            plot_output_scores(\n",
    "                sigs_and_bkgs, order, \n",
    "                f\"BDT_{sample_name}_vs_{sample_name_ if sample_name_ != sample_name else 'all'}_outputScoreDensity_testData_fold{fold_idx}\", \n",
    "                plot_dirpath,\n",
    "                arctanh=True if re.search('arctanh', plot_dirpath) is not None else False\n",
    "            )\n",
    "\n",
    "        flat_preds = np.concatenate([BDT_perf[sample_name]['preds'][fold_idx] for fold_idx in range(len(bdt_test_dict))], axis=0)\n",
    "        if re.search('arctanh', plot_dirpath) is not None:\n",
    "            flat_preds = np.arctanh(flat_preds)\n",
    "        flat_truths = np.concatenate([bdt_test_dict[f\"fold_{fold_idx}\"].get_label() for fold_idx in range(len(bdt_test_dict))], axis=0)\n",
    "        flat_weights = np.concatenate([weights_plot_test[f\"fold_{fold_idx}\"] for fold_idx in range(len(bdt_test_dict))], axis=0)\n",
    "\n",
    "        sigs_and_bkgs = {\n",
    "            sample_name__: flat_preds[:, j][flat_truths == k]\n",
    "            for k, sample_name__ in enumerate(order)\n",
    "        }\n",
    "        score_weights = {\n",
    "            sample_name__: flat_weights[flat_truths == k]\n",
    "            for k, sample_name__ in enumerate(order)\n",
    "        }\n",
    "        \n",
    "        if sample_name_ != sample_name:\n",
    "            event_j_mask = flat_truths == j\n",
    "            pred_j_rescale = (flat_preds[:, j] + flat_preds[:, i])[event_j_mask]\n",
    "            event_i_mask = flat_truths == i\n",
    "            pred_i_rescale = (flat_preds[:, j] + flat_preds[:, i])[event_i_mask]\n",
    "\n",
    "            for sample_name__ in order:\n",
    "                if sample_name__ == sample_name:\n",
    "                    sigs_and_bkgs[sample_name__] = sigs_and_bkgs[sample_name__] / pred_j_rescale\n",
    "                elif sample_name__ == sample_name_:\n",
    "                    sigs_and_bkgs[sample_name__] = sigs_and_bkgs[sample_name__] / pred_i_rescale\n",
    "                else:\n",
    "                    del sigs_and_bkgs[sample_name__]\n",
    "                    del score_weights[sample_name__]\n",
    "        \n",
    "        plot_output_scores(\n",
    "            sigs_and_bkgs, order, \n",
    "            f\"BDT_{sample_name}_vs_{sample_name_ if sample_name_ != sample_name else 'all'}_outputScoreWeighted_testData_sum\", \n",
    "            plot_dirpath, weights=score_weights, log=True,\n",
    "            arctanh=True if re.search('arctanh', plot_dirpath) is not None else False\n",
    "        )\n",
    "        plot_output_scores(\n",
    "            sigs_and_bkgs, order, \n",
    "            f\"BDT_{sample_name}_vs_{sample_name_ if sample_name_ != sample_name else 'all'}_outputScoreDensity_testData_sum\", \n",
    "            plot_dirpath,\n",
    "            arctanh=True if re.search('arctanh', plot_dirpath) is not None else False\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### s/âb Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "============================================================\n",
      "Cat1: 0.9976 < ggF HH score â¤ 1.0000 AND 120 GeV < m_HH < 130 GeV\n",
      "------------------------------------------------------------\n",
      "Cat1: Num ggF HH = 0.2451\n",
      "------------------------------------------------------------\n",
      "Cat1: Num ttH = 0.0197\n",
      "------------------------------------------------------------\n",
      "Cat1: Num VH = 0.0294\n",
      "------------------------------------------------------------\n",
      "Cat1: Num VH, no ZH or WH = 0.0294\n",
      "------------------------------------------------------------\n",
      "Cat1: Num non-res + ggFH + VBFH = 0.5363\n",
      "------------------------------------------------------------\n",
      "Cat1: Num GluGluHToGG = 0.0799\n",
      "------------------------------------------------------------\n",
      "Cat1: Num VBFHToGG = 0.0045\n",
      "------------------------------------------------------------\n",
      "Cat1: Num GGJets = 0.4519\n",
      "------------------------------------------------------------\n",
      "Cat1: Num GJetPt20To40 = 0.0000\n",
      "------------------------------------------------------------\n",
      "Cat1: Num GJetPt40 = 0.0000\n",
      "------------------------------------------------------------\n",
      "Cat1: S = 0.2451, B = 0.5855, S/âB = 0.3204\n",
      "============================================================\n",
      "============================================================\n",
      "Cat2: 0.9918 < ggF HH score â¤ 0.9976 AND 120 GeV < m_HH < 130 GeV\n",
      "------------------------------------------------------------\n",
      "Cat2: Num ggF HH = 0.2390\n",
      "------------------------------------------------------------\n",
      "Cat2: Num ttH = 0.1510\n",
      "------------------------------------------------------------\n",
      "Cat2: Num VH = 0.1060\n",
      "------------------------------------------------------------\n",
      "Cat2: Num VH, no ZH or WH = 0.1060\n",
      "------------------------------------------------------------\n",
      "Cat2: Num non-res + ggFH + VBFH = 4.0207\n",
      "------------------------------------------------------------\n",
      "Cat2: Num GluGluHToGG = 0.3568\n",
      "------------------------------------------------------------\n",
      "Cat2: Num VBFHToGG = 0.0328\n",
      "------------------------------------------------------------\n",
      "Cat2: Num GGJets = 2.7137\n",
      "------------------------------------------------------------\n",
      "Cat2: Num GJetPt20To40 = 0.0000\n",
      "------------------------------------------------------------\n",
      "Cat2: Num GJetPt40 = 0.9174\n",
      "------------------------------------------------------------\n",
      "Cat2: S = 0.2390, B = 4.2776, S/âB = 0.1156\n",
      "============================================================\n",
      "============================================================\n",
      "Cat3: 0.9630 < ggF HH score â¤ 0.9918 AND 120 GeV < m_HH < 130 GeV\n",
      "------------------------------------------------------------\n",
      "Cat3: Num ggF HH = 0.2392\n",
      "------------------------------------------------------------\n",
      "Cat3: Num ttH = 0.7181\n",
      "------------------------------------------------------------\n",
      "Cat3: Num VH = 0.2535\n",
      "------------------------------------------------------------\n",
      "Cat3: Num VH, no ZH or WH = 0.2535\n",
      "------------------------------------------------------------\n",
      "Cat3: Num non-res + ggFH + VBFH = 24.2952\n",
      "------------------------------------------------------------\n",
      "Cat3: Num GluGluHToGG = 1.1531\n",
      "------------------------------------------------------------\n",
      "Cat3: Num VBFHToGG = 0.0915\n",
      "------------------------------------------------------------\n",
      "Cat3: Num GGJets = 16.0490\n",
      "------------------------------------------------------------\n",
      "Cat3: Num GJetPt20To40 = 0.0000\n",
      "------------------------------------------------------------\n",
      "Cat3: Num GJetPt40 = 7.0016\n",
      "------------------------------------------------------------\n",
      "Cat3: S = 0.2392, B = 25.2668, S/âB = 0.0476\n",
      "============================================================\n",
      "============================================================\n",
      "Cat1: 0.9976 < ggF HH score â¤ 1.0000\n",
      "------------------------------------------------------------\n",
      "Cat1: Num ggF HH = 0.2536\n",
      "------------------------------------------------------------\n",
      "Cat1: Num ttH = 0.0210\n",
      "------------------------------------------------------------\n",
      "Cat1: Num VH = 0.0445\n",
      "------------------------------------------------------------\n",
      "Cat1: Num VH, no ZH or WH = 0.0445\n",
      "------------------------------------------------------------\n",
      "Cat1: Num non-res + ggFH + VBFH = 5.6563\n",
      "------------------------------------------------------------\n",
      "Cat1: Num GluGluHToGG = 0.0855\n",
      "------------------------------------------------------------\n",
      "Cat1: Num VBFHToGG = 0.0047\n",
      "------------------------------------------------------------\n",
      "Cat1: Num GGJets = 4.5329\n",
      "------------------------------------------------------------\n",
      "Cat1: Num GJetPt20To40 = 0.0000\n",
      "------------------------------------------------------------\n",
      "Cat1: Num GJetPt40 = 1.0331\n",
      "------------------------------------------------------------\n",
      "Cat1: S = 0.2536, B = 5.7217, S/âB = 0.1060\n",
      "============================================================\n",
      "============================================================\n",
      "Cat2: 0.9918 < ggF HH score â¤ 0.9976\n",
      "------------------------------------------------------------\n",
      "Cat2: Num ggF HH = 0.2482\n",
      "------------------------------------------------------------\n",
      "Cat2: Num ttH = 0.1605\n",
      "------------------------------------------------------------\n",
      "Cat2: Num VH = 0.1855\n",
      "------------------------------------------------------------\n",
      "Cat2: Num VH, no ZH or WH = 0.1855\n",
      "------------------------------------------------------------\n",
      "Cat2: Num non-res + ggFH + VBFH = 44.1105\n",
      "------------------------------------------------------------\n",
      "Cat2: Num GluGluHToGG = 0.3745\n",
      "------------------------------------------------------------\n",
      "Cat2: Num VBFHToGG = 0.0333\n",
      "------------------------------------------------------------\n",
      "Cat2: Num GGJets = 30.8171\n",
      "------------------------------------------------------------\n",
      "Cat2: Num GJetPt20To40 = 0.0000\n",
      "------------------------------------------------------------\n",
      "Cat2: Num GJetPt40 = 12.8856\n",
      "------------------------------------------------------------\n",
      "Cat2: S = 0.2482, B = 44.4565, S/âB = 0.0372\n",
      "============================================================\n",
      "============================================================\n",
      "Cat3: 0.9630 < ggF HH score â¤ 0.9918\n",
      "------------------------------------------------------------\n",
      "Cat3: Num ggF HH = 0.2511\n",
      "------------------------------------------------------------\n",
      "Cat3: Num ttH = 0.7616\n",
      "------------------------------------------------------------\n",
      "Cat3: Num VH = 0.4506\n",
      "------------------------------------------------------------\n",
      "Cat3: Num VH, no ZH or WH = 0.4506\n",
      "------------------------------------------------------------\n",
      "Cat3: Num non-res + ggFH + VBFH = 283.6765\n",
      "------------------------------------------------------------\n",
      "Cat3: Num GluGluHToGG = 1.2134\n",
      "------------------------------------------------------------\n",
      "Cat3: Num VBFHToGG = 0.0965\n",
      "------------------------------------------------------------\n",
      "Cat3: Num GGJets = 176.4320\n",
      "------------------------------------------------------------\n",
      "Cat3: Num GJetPt20To40 = 0.3555\n",
      "------------------------------------------------------------\n",
      "Cat3: Num GJetPt40 = 105.5791\n",
      "------------------------------------------------------------\n",
      "Cat3: S = 0.2511, B = 284.8886, S/âB = 0.0149\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 32\u001b[0m\n\u001b[1;32m     25\u001b[0m     bkg_mask \u001b[38;5;241m=\u001b[39m bdt_test_dict[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfold_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget_label() \u001b[38;5;241m==\u001b[39m i\n\u001b[1;32m     27\u001b[0m     sig_rescale \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     28\u001b[0m         np\u001b[38;5;241m.\u001b[39marray(BDT_perf[sample_name][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreds\u001b[39m\u001b[38;5;124m'\u001b[39m][fold_idx])[:, j] \n\u001b[1;32m     29\u001b[0m         \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39marray(BDT_perf[sample_name][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreds\u001b[39m\u001b[38;5;124m'\u001b[39m][fold_idx])[:, i]\n\u001b[1;32m     30\u001b[0m     )\n\u001b[1;32m     31\u001b[0m     bkg_rescale \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m---> 32\u001b[0m         \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBDT_perf\u001b[49m\u001b[43m[\u001b[49m\u001b[43msample_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpreds\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfold_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[:, j] \n\u001b[1;32m     33\u001b[0m         \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39marray(BDT_perf[sample_name][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreds\u001b[39m\u001b[38;5;124m'\u001b[39m][fold_idx])[:, i]\n\u001b[1;32m     34\u001b[0m     )\n\u001b[1;32m     36\u001b[0m sigs_and_bkgs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msig\u001b[39m\u001b[38;5;124m'\u001b[39m: (np\u001b[38;5;241m.\u001b[39marray(BDT_perf[sample_name][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreds\u001b[39m\u001b[38;5;124m'\u001b[39m][fold_idx])[:, j] \u001b[38;5;241m/\u001b[39m sig_rescale)[sig_mask],\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbkg\u001b[39m\u001b[38;5;124m'\u001b[39m: (np\u001b[38;5;241m.\u001b[39marray(BDT_perf[sample_name][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreds\u001b[39m\u001b[38;5;124m'\u001b[39m][fold_idx])[:, j] \u001b[38;5;241m/\u001b[39m bkg_rescale)[bkg_mask]\n\u001b[1;32m     39\u001b[0m }\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m re\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marctanh\u001b[39m\u001b[38;5;124m'\u001b[39m, plot_dirpath) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"s_over_rootb\")\n",
    "# plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"s_over_rootb_arctanh\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "if 'BDT_perf' not in globals():\n",
    "    with open(os.path.join(OUTPUT_DIRPATH, CURRENT_TIME+\"_BDT_perf.json\"), 'r') as f:\n",
    "        BDT_perf = json.load(f)\n",
    "\n",
    "# plot s/âb curves\n",
    "for j, sample_name in enumerate(order):\n",
    "\n",
    "    for i, sample_name_ in enumerate(order):\n",
    "\n",
    "        for fold_idx in range(len(BDT_perf['ggF HH']['preds'])):\n",
    "\n",
    "            if sample_name_ == sample_name:\n",
    "                sig_mask = bdt_test_dict[f\"fold_{fold_idx}\"].get_label() == j\n",
    "                bkg_mask = bdt_test_dict[f\"fold_{fold_idx}\"].get_label() != j\n",
    "\n",
    "                sig_rescale = np.ones_like(sig_mask)\n",
    "                bkg_rescale = np.ones_like(bkg_mask)\n",
    "            else:\n",
    "                sig_mask = bdt_test_dict[f\"fold_{fold_idx}\"].get_label() == j\n",
    "                bkg_mask = bdt_test_dict[f\"fold_{fold_idx}\"].get_label() == i\n",
    "\n",
    "                sig_rescale = (\n",
    "                    np.array(BDT_perf[sample_name]['preds'][fold_idx])[:, j] \n",
    "                    + np.array(BDT_perf[sample_name]['preds'][fold_idx])[:, i]\n",
    "                )\n",
    "                bkg_rescale = (\n",
    "                    np.array(BDT_perf[sample_name]['preds'][fold_idx])[:, j] \n",
    "                    + np.array(BDT_perf[sample_name]['preds'][fold_idx])[:, i]\n",
    "                )\n",
    "\n",
    "            sigs_and_bkgs = {\n",
    "                'sig': (np.array(BDT_perf[sample_name]['preds'][fold_idx])[:, j] / sig_rescale)[sig_mask],\n",
    "                'bkg': (np.array(BDT_perf[sample_name]['preds'][fold_idx])[:, j] / bkg_rescale)[bkg_mask]\n",
    "            }\n",
    "            if re.search('arctanh', plot_dirpath) is not None:\n",
    "                sigs_and_bkgs['sig'] = np.arctanh(sigs_and_bkgs['sig'])\n",
    "                sigs_and_bkgs['bkg'] = np.arctanh(sigs_and_bkgs['bkg'])\n",
    "            score_weights = {\n",
    "                'sig': weights_plot_test[f\"fold_{fold_idx}\"][sig_mask],\n",
    "                'bkg': weights_plot_test[f\"fold_{fold_idx}\"][bkg_mask]\n",
    "            }\n",
    "\n",
    "\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\")\n",
    "                plot_s_over_root_b(\n",
    "                    sigs_and_bkgs['sig'], sigs_and_bkgs['bkg'], f\"{sample_name} vs. {sample_name_ if sample_name_ != sample_name else 'all'}\", \n",
    "                    f\"BDT_{sample_name}_vs_{sample_name_ if sample_name_ != sample_name else 'all'}_sOverRootb_testData_fold{fold_idx}\", \n",
    "                    plot_dirpath, weights=score_weights,\n",
    "                    arctanh=True if re.search('arctanh', plot_dirpath) is not None else False  \n",
    "                )\n",
    "\n",
    "                (\n",
    "                    cut_boundaries_fold, cut_s_over_root_bs_fold, sig_weights_fold, bkg_weights_fold\n",
    "                ) = optimize_cut_boundaries(\n",
    "                    sigs_and_bkgs['sig'], sigs_and_bkgs['bkg'], score_weights,\n",
    "                    arctanh=True if re.search('arctanh', plot_dirpath) is not None else False\n",
    "                )\n",
    "\n",
    "                BDT_cut_labels = [\n",
    "                    f\"cut={cut_boundaries_fold[0][cut_idx]:.4f}: s/âb={cut_s_over_root_bs_fold[0][cut_idx]:.5f}, s={sig_weights_fold[0][cut_idx]['value']:.5f}Â±{sig_weights_fold[0][cut_idx]['w2']:.5f}, b={bkg_weights_fold[0][cut_idx]['value']:.5f}Â±{bkg_weights_fold[0][cut_idx]['w2']:.5f}\" for cut_idx in range(len(cut_s_over_root_bs_fold[0]))\n",
    "                ]\n",
    "                line_labels = BDT_cut_labels[:10]\n",
    "                lines = cut_boundaries_fold[0][:10]\n",
    "                line_colors = cmap_petroff10\n",
    "\n",
    "                plot_s_over_root_b(\n",
    "                    sigs_and_bkgs['sig'], sigs_and_bkgs['bkg'], f\"{sample_name} vs. {sample_name_ if sample_name_ != sample_name else 'all'}\", \n",
    "                    f\"BDT_{sample_name}_vs_{sample_name_ if sample_name_ != sample_name else 'all'}_sOverRootb_withCuts_testData_fold{fold_idx}_{sample_name}\", plot_dirpath, \n",
    "                    weights=score_weights,\n",
    "                    lines=lines, lines_labels=line_labels, line_colors=line_colors,\n",
    "                    arctanh=True if re.search('arctanh', plot_dirpath) is not None else False\n",
    "                )\n",
    "            \n",
    "        flat_preds = np.concatenate([BDT_perf[sample_name]['preds'][fold_idx] for fold_idx in range(len(BDT_perf['ggF HH']['preds']))], axis=0)\n",
    "        if re.search('arctanh', plot_dirpath) is not None:\n",
    "            flat_preds = np.arctanh(flat_preds)\n",
    "        flat_truths = np.concatenate([bdt_test_dict[f\"fold_{fold_idx}\"].get_label() for fold_idx in range(len(BDT_perf['ggF HH']['preds']))], axis=0)\n",
    "        flat_weights = np.concatenate([weights_plot_test[f\"fold_{fold_idx}\"] for fold_idx in range(len(BDT_perf['ggF HH']['preds']))], axis=0)\n",
    "        flat_sample_names = np.concatenate([data_test_aux_dict[f\"fold_{fold_idx}\"]['sample_name'] for fold_idx in range(len(BDT_perf['ggF HH']['preds']))], axis=0)\n",
    "\n",
    "        if sample_name_ == sample_name:\n",
    "            sig_mask = flat_truths == j\n",
    "            bkg_mask = flat_truths != j\n",
    "\n",
    "            sig_rescale = np.ones_like(sig_mask)\n",
    "            bkg_rescale = np.ones_like(bkg_mask)\n",
    "        else:\n",
    "            sig_mask = flat_truths == j\n",
    "            bkg_mask = flat_truths == i\n",
    "\n",
    "            sig_rescale = flat_preds[:, j] + flat_preds[:, i]\n",
    "            bkg_rescale = flat_preds[:, j] + flat_preds[:, i]\n",
    "\n",
    "        sigs_and_bkgs = {\n",
    "            'sig': (flat_preds[:, j] / sig_rescale)[sig_mask],\n",
    "            'bkg': (flat_preds[:, j] / bkg_rescale)[bkg_mask]\n",
    "        }\n",
    "        score_weights = {\n",
    "            'sig': flat_weights[sig_mask],\n",
    "            'bkg': flat_weights[bkg_mask]\n",
    "        }\n",
    "\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            plot_s_over_root_b(\n",
    "                sigs_and_bkgs['sig'], sigs_and_bkgs['bkg'], f\"{sample_name} vs. {sample_name_ if sample_name_ != sample_name else 'all'}\", \n",
    "                f\"BDT_{sample_name}_vs_{sample_name_ if sample_name_ != sample_name else 'all'}_sOverRootb_testData_sum\", \n",
    "                plot_dirpath, weights=score_weights,\n",
    "                arctanh=True if re.search('arctanh', plot_dirpath) is not None else False\n",
    "            )\n",
    "\n",
    "            (\n",
    "                cut_boundaries_fold, cut_s_over_root_bs_fold, sig_weights_fold, bkg_weights_fold\n",
    "            ) = optimize_cut_boundaries(\n",
    "                sigs_and_bkgs['sig'], sigs_and_bkgs['bkg'], score_weights,\n",
    "                arctanh=True if re.search('arctanh', plot_dirpath) is not None else False\n",
    "            )\n",
    "\n",
    "            BDT_cut_labels = [\n",
    "                f\"cut={cut_boundaries_fold[0][cut_idx]:.4f}: s/âb={cut_s_over_root_bs_fold[0][cut_idx]:.5f}, s={sig_weights_fold[0][cut_idx]['value']:.5f}Â±{sig_weights_fold[0][cut_idx]['w2']:.5f}, b={bkg_weights_fold[0][cut_idx]['value']:.5f}Â±{bkg_weights_fold[0][cut_idx]['w2']:.5f}\" for cut_idx in range(len(cut_s_over_root_bs_fold[0]))\n",
    "            ]\n",
    "            line_labels = BDT_cut_labels[:10]\n",
    "            lines = cut_boundaries_fold[0][:10]\n",
    "            line_colors = cmap_petroff10\n",
    "\n",
    "            plot_s_over_root_b(\n",
    "                sigs_and_bkgs['sig'], sigs_and_bkgs['bkg'], f\"{sample_name} vs. {sample_name_ if sample_name_ != sample_name else 'all'}\", \n",
    "                f\"BDT_{sample_name}_vs_{sample_name_ if sample_name_ != sample_name else 'all'}_sOverRootb_withCuts_testData_sum\", plot_dirpath, \n",
    "                weights=score_weights,\n",
    "                lines=lines, lines_labels=line_labels, line_colors=line_colors,\n",
    "                arctanh=True if re.search('arctanh', plot_dirpath) is not None else False\n",
    "            )\n",
    "\n",
    "        if j == 0 and i == 0:\n",
    "            flat_mass = np.concatenate([data_test_aux_dict[f\"fold_{fold_idx}\"]['mass'] for fold_idx in range(len(BDT_perf['ggF HH']['preds']))], axis=0)\n",
    "            if re.search('arctanh', plot_dirpath) is not None:\n",
    "                cat_lines = [6.0] + lines[:3]\n",
    "            else:\n",
    "                cat_lines = [1.0] + lines[:3]\n",
    "            cat_num_samples = {}\n",
    "            for k, cat in enumerate(['Cat1', 'Cat2', 'Cat3']):\n",
    "                cat_num_samples[cat] = {}\n",
    "                print('='*60)\n",
    "                print('='*60)\n",
    "                print(f\"{cat}: {cat_lines[k+1]:.4f} < ggF HH score â¤ {cat_lines[k]:.4f} AND 120 GeV < m_HH < 130 GeV\")\n",
    "                print('-'*60)\n",
    "                for m, sample_name in enumerate(order):\n",
    "                    sample_bool = np.logical_and(  # event passes conditions and is the right type (i.e. sample)\n",
    "                        np.logical_and(  # event passes category and mass conditions\n",
    "                            np.logical_and(  # prediction is within category bounds\n",
    "                                flat_preds[:, 0] <= cat_lines[k],\n",
    "                                flat_preds[:, 0] > cat_lines[k+1]\n",
    "                            ),\n",
    "                            np.logical_and(  # diphoton mass is within 120-130 window\n",
    "                                flat_mass < 130,\n",
    "                                flat_mass > 120\n",
    "                            ),\n",
    "                        ),\n",
    "                        flat_truths == m\n",
    "                    )\n",
    "                    cat_num_samples[cat][sample_name] = np.sum(\n",
    "                        flat_weights[sample_bool]\n",
    "                    )\n",
    "                    print(f\"{cat}: Num {sample_name} = {cat_num_samples[cat][sample_name]:.4f}\")\n",
    "                    print('-'*60)\n",
    "                    if sample_name == order[-1]:\n",
    "                        for smpl in [\n",
    "                            ['GluGluHToGG', 'GluGlutoHHto2B2G_kl_1p00_kt_1p00_c2_0p00'],\n",
    "                            ['VBFHToGG', 'VBFHToGG_M_125'],\n",
    "                            ['GGJets'], ['GJetPt20To40'], ['GJetPt40']\n",
    "                        ]:\n",
    "                            smpl_num = 0\n",
    "                            for smpl_ in smpl:\n",
    "                                smpl_num += np.sum(\n",
    "                                    flat_weights[\n",
    "                                        np.logical_and(\n",
    "                                            sample_bool,\n",
    "                                            flat_sample_names == smpl_\n",
    "                                        )\n",
    "                                    ]\n",
    "                                )\n",
    "                            print(f\"{cat}: Num {smpl[0]} = {smpl_num:.4f}\")\n",
    "                            print('-'*60)\n",
    "                    elif sample_name == order[-2]:\n",
    "                        smpl_num = np.sum(\n",
    "                            flat_weights[\n",
    "                                np.logical_and(\n",
    "                                    sample_bool,\n",
    "                                    np.logical_or(\n",
    "                                        flat_sample_names == 'VHToGG',\n",
    "                                        flat_sample_names == 'VHtoGG_M_125'\n",
    "                                    )\n",
    "                                )\n",
    "                            ]\n",
    "                        )\n",
    "                        print(f\"{cat}: Num VH, no ZH or WH = {smpl_num:.4f}\")\n",
    "                        print('-'*60)\n",
    "\n",
    "                print(f\"{cat}: S = {cat_num_samples[cat][order[0]]:.4f}, B = {np.sum([cat_num_samples[cat][order[v]] for v in range(1, len(order))]):.4f}, S/âB = {(cat_num_samples[cat][order[0]] / np.sqrt(np.sum([cat_num_samples[cat][order[v]] for v in range(1, len(order))]))):.4f}\")\n",
    "\n",
    "            for k, cat in enumerate(['Cat1', 'Cat2', 'Cat3']):\n",
    "                cat_num_samples[cat] = {}\n",
    "                print('='*60)\n",
    "                print('='*60)\n",
    "                print(f\"{cat}: {cat_lines[k+1]:.4f} < ggF HH score â¤ {cat_lines[k]:.4f}\")\n",
    "                print('-'*60)\n",
    "                for m, sample_name in enumerate(order):\n",
    "                    sample_bool = np.logical_and(  # event passes conditions and is the right type (i.e. sample)\n",
    "                        np.logical_and(  # prediction is within category bounds\n",
    "                            flat_preds[:, 0] <= cat_lines[k],\n",
    "                            flat_preds[:, 0] > cat_lines[k+1]\n",
    "                        ),\n",
    "                        flat_truths == m\n",
    "                    )\n",
    "                    cat_num_samples[cat][sample_name] = np.sum(\n",
    "                        flat_weights[sample_bool]\n",
    "                    )\n",
    "                    print(f\"{cat}: Num {sample_name} = {cat_num_samples[cat][sample_name]:.4f}\")\n",
    "                    print('-'*60)\n",
    "                    if sample_name == order[-1]:\n",
    "                        for smpl in [\n",
    "                            ['GluGluHToGG', 'GluGlutoHHto2B2G_kl_1p00_kt_1p00_c2_0p00'],\n",
    "                            ['VBFHToGG', 'VBFHToGG_M_125'],\n",
    "                            ['GGJets'], ['GJetPt20To40'], ['GJetPt40']\n",
    "                        ]:\n",
    "                            smpl_num = 0\n",
    "                            for smpl_ in smpl:\n",
    "                                smpl_num += np.sum(\n",
    "                                    flat_weights[\n",
    "                                        np.logical_and(\n",
    "                                            sample_bool,\n",
    "                                            flat_sample_names == smpl_\n",
    "                                        )\n",
    "                                    ]\n",
    "                                )\n",
    "                            print(f\"{cat}: Num {smpl[0]} = {smpl_num:.4f}\")\n",
    "                            print('-'*60)\n",
    "                    elif sample_name == order[-2]:\n",
    "                        smpl_num = np.sum(\n",
    "                            flat_weights[\n",
    "                                np.logical_and(\n",
    "                                    sample_bool,\n",
    "                                    np.logical_or(\n",
    "                                        flat_sample_names == 'VHToGG',\n",
    "                                        flat_sample_names == 'VHtoGG_M_125'\n",
    "                                    )\n",
    "                                )\n",
    "                            ]\n",
    "                        )\n",
    "                        print(f\"{cat}: Num VH, no ZH or WH = {smpl_num:.4f}\")\n",
    "                        print('-'*60)\n",
    "\n",
    "                print(f\"{cat}: S = {cat_num_samples[cat][order[0]]:.4f}, B = {np.sum([cat_num_samples[cat][order[v]] for v in range(1, len(order))]):.4f}, S/âB = {(cat_num_samples[cat][order[0]] / np.sqrt(np.sum([cat_num_samples[cat][order[v]] for v in range(1, len(order))]))):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (4076284,) (4099795,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 100\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[1;32m     99\u001b[0m     warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 100\u001b[0m     clf_dict \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_optimize_cut_boundaries\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m        \u001b[49m\u001b[43mflat_preds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_truths\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_weights\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;66;03m# plot_s_over_root_b(\u001b[39;00m\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;66;03m#     sigs_and_bkgs['sig'], sigs_and_bkgs['bkg'], f\"{sample_name} vs. {sample_name_ if sample_name_ != sample_name else 'all'}\", \u001b[39;00m\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;66;03m#     f\"BDT_{sample_name}_vs_{sample_name_ if sample_name_ != sample_name else 'all'}_sOverRootb_withCuts_testData_sum\", plot_dirpath, \u001b[39;00m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;66;03m#     weights=score_weights,\u001b[39;00m\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;66;03m#     lines=lines, lines_labels=line_labels, line_colors=line_colors\u001b[39;00m\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[1;32m    111\u001b[0m flat_mass \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([data_test_aux_dict[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfold_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmass\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m fold_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(data_test_aux_dict))], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "Cell \u001b[0;32mIn[9], line 237\u001b[0m, in \u001b[0;36mmulti_optimize_cut_boundaries\u001b[0;34m(preds, binary_labels, weights, num_categories, min_sig)\u001b[0m\n\u001b[1;32m    234\u001b[0m     param_range \u001b[38;5;241m=\u001b[39m init_param_range\n\u001b[1;32m    235\u001b[0m     guess \u001b[38;5;241m=\u001b[39m init_guess\n\u001b[0;32m--> 237\u001b[0m opt_cuts, opt_params \u001b[38;5;241m=\u001b[39m \u001b[43moptimize_cuts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43msliced_preds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msliced_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msliced_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparam_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparam_range\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_guess\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mguess\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_sig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_sig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrng_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m    240\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    242\u001b[0m clf_dict[cat] \u001b[38;5;241m=\u001b[39m opt_cuts\n\u001b[1;32m    243\u001b[0m param_clf_dict[cat] \u001b[38;5;241m=\u001b[39m opt_params\n",
      "Cell \u001b[0;32mIn[9], line 184\u001b[0m, in \u001b[0;36moptimize_cuts\u001b[0;34m(preds, binary_labels, weights, init_guess, param_names, param_range, n_steps, verbose, min_sig, prefactor, rng_seed)\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ms/âb = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms_over_root_b\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, s = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_sig\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, b = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_bkg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39mprefactor\u001b[38;5;241m*\u001b[39ms_over_root_b\n\u001b[0;32m--> 184\u001b[0m res_gp \u001b[38;5;241m=\u001b[39m \u001b[43mgp_minimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrng_seed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn_steps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43minit_guess\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43minit_guess\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_initial_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_guess\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    190\u001b[0m opt_params \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mfloat\u001b[39m(res_gp\u001b[38;5;241m.\u001b[39mx[i]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(space))]\n\u001b[1;32m    191\u001b[0m opt_cuts \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mfloat\u001b[39m(opt_cut) \u001b[38;5;28;01mfor\u001b[39;00m opt_cut \u001b[38;5;129;01min\u001b[39;00m space_transform({param_names[i]: res_gp\u001b[38;5;241m.\u001b[39mx[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(param_names))})]\n",
      "File \u001b[0;32m~/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/skopt/optimizer/gp.py:281\u001b[0m, in \u001b[0;36mgp_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, noise, n_jobs, model_queue_size, space_constraint)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m base_estimator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    274\u001b[0m     base_estimator \u001b[38;5;241m=\u001b[39m cook_estimator(\n\u001b[1;32m    275\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGP\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    276\u001b[0m         space\u001b[38;5;241m=\u001b[39mspace,\n\u001b[1;32m    277\u001b[0m         random_state\u001b[38;5;241m=\u001b[39mrng\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, np\u001b[38;5;241m.\u001b[39miinfo(np\u001b[38;5;241m.\u001b[39mint32)\u001b[38;5;241m.\u001b[39mmax),\n\u001b[1;32m    278\u001b[0m         noise\u001b[38;5;241m=\u001b[39mnoise,\n\u001b[1;32m    279\u001b[0m     )\n\u001b[0;32m--> 281\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbase_minimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m    \u001b[49m\u001b[43macq_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43macq_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkappa\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkappa\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m    \u001b[49m\u001b[43macq_optimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43macq_optimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_points\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_random_starts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_random_starts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_initial_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_initial_points\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_point_generator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_point_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_restarts_optimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_restarts_optimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43my0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrng\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspace_constraint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspace_constraint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/skopt/optimizer/base.py:314\u001b[0m, in \u001b[0;36mbase_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, n_jobs, model_queue_size, space_constraint)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;66;03m# evaluate y0 if only x0 is provided\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x0 \u001b[38;5;129;01mand\u001b[39;00m y0 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 314\u001b[0m     y0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m     n_calls \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(y0)\n\u001b[1;32m    316\u001b[0m \u001b[38;5;66;03m# record through tell function\u001b[39;00m\n",
      "File \u001b[0;32m~/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/skopt/utils.py:779\u001b[0m, in \u001b[0;36muse_named_args.<locals>.decorator.<locals>.wrapper\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    776\u001b[0m arg_dict \u001b[38;5;241m=\u001b[39m {dim\u001b[38;5;241m.\u001b[39mname: value \u001b[38;5;28;01mfor\u001b[39;00m dim, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(dimensions, x)}\n\u001b[1;32m    778\u001b[0m \u001b[38;5;66;03m# Call the wrapped objective function with the named arguments.\u001b[39;00m\n\u001b[0;32m--> 779\u001b[0m objective_value \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marg_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m objective_value\n",
      "Cell \u001b[0;32mIn[9], line 142\u001b[0m, in \u001b[0;36moptimize_cuts.<locals>.objective\u001b[0;34m(**X)\u001b[0m\n\u001b[1;32m    134\u001b[0m sample_mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mall(xyz_preds \u001b[38;5;241m<\u001b[39m thresholds, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# print(f\"total sig = {np.sum(weights[binary_labels == 1])}\")\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;66;03m# print(f\"total bkg = {np.sum(weights[binary_labels == 0])}\")\u001b[39;00m\n\u001b[1;32m    139\u001b[0m num_sig \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mabs(\n\u001b[1;32m    140\u001b[0m     np\u001b[38;5;241m.\u001b[39msum(\n\u001b[1;32m    141\u001b[0m         weights[\n\u001b[0;32m--> 142\u001b[0m             \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogical_and\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m                \u001b[49m\u001b[43mbinary_labels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m                \u001b[49m\u001b[43msample_mask\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m         ]\n\u001b[1;32m    147\u001b[0m     )\n\u001b[1;32m    148\u001b[0m )\n\u001b[1;32m    150\u001b[0m num_bkg \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mabs(\n\u001b[1;32m    151\u001b[0m     np\u001b[38;5;241m.\u001b[39msum(\n\u001b[1;32m    152\u001b[0m         weights[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    158\u001b[0m     )\n\u001b[1;32m    159\u001b[0m )\n\u001b[1;32m    161\u001b[0m s_over_root_b \u001b[38;5;241m=\u001b[39m num_sig \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(num_bkg)\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (4076284,) (4099795,) "
     ]
    }
   ],
   "source": [
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"s_over_rootb_multiOptim\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "if 'BDT_perf' not in globals():\n",
    "    with open(os.path.join(OUTPUT_DIRPATH, CURRENT_TIME+\"_BDT_perf.json\"), 'r') as f:\n",
    "        BDT_perf = json.load(f)\n",
    "\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(projection='3d')\n",
    "# # x_preds, y_preds, z_preds = p_to_xyz(np.concatenate([BDT_perf['ggF HH']['preds'][fold_idx] for fold_idx in range(len(bdt_test_dict))], axis=0))\n",
    "# for i, sample_name in enumerate(order):\n",
    "#     if i == 0:\n",
    "#         downsample = 100\n",
    "#     elif i == 1:\n",
    "#         downsample = 200\n",
    "#     elif i == 2:\n",
    "#         downsample = 400\n",
    "#     elif i == 3:\n",
    "#         downsample = 500\n",
    "\n",
    "#     x_preds, y_preds, z_preds = p_to_xyz(np.array(BDT_perf['ggF HH']['preds'][0])[bdt_test_dict[f\"fold_0\"].get_label() == i][::downsample])\n",
    "#     ax.scatter(x_preds, y_preds, z_preds, marker='.', label=sample_name)\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# # plot s/âb curves\n",
    "# for fold_idx in range(len(bdt_train_dict)):\n",
    "\n",
    "#     with warnings.catch_warnings():\n",
    "#         warnings.simplefilter(\"ignore\")\n",
    "#         clf_dict = multi_optimize_cut_boundaries(\n",
    "#             BDT_perf['ggF HH']['preds'][fold_idx], \n",
    "#             bdt_test_dict[f\"fold_{fold_idx}\"].get_label() == 0, \n",
    "#             weights_plot_test[f\"fold_{fold_idx}\"],\n",
    "#             min_sig=0.07\n",
    "#         )\n",
    "\n",
    "#     cat_dict = {}\n",
    "#     for cat in range(len(clf_dict)):\n",
    "#         prev_cat_slice = np.ones_like(weights_plot_test[f\"fold_{fold_idx}\"], dtype=bool)\n",
    "#         if cat > 0:\n",
    "#             for prev_cat in range(cat):\n",
    "#                 prev_cat_slice = np.logical_and(\n",
    "#                     prev_cat_slice,\n",
    "#                     np.logical_not(\n",
    "#                         np.all(\n",
    "#                             p_to_xyz(np.array(BDT_perf['ggF HH']['preds'][fold_idx]), split=False) < clf_dict[prev_cat], \n",
    "#                             axis=1\n",
    "#                         )\n",
    "#                     )\n",
    "#                 )\n",
    "#         cat_dict[cat] = np.logical_and(\n",
    "#             prev_cat_slice,\n",
    "#             np.all(\n",
    "#                 p_to_xyz(np.array(BDT_perf['ggF HH']['preds'][fold_idx]), split=False) < clf_dict[cat],\n",
    "#                 axis=1\n",
    "#             )\n",
    "#         )\n",
    "\n",
    "#     masses = data_test_aux_dict[f\"fold_{fold_idx}\"]['mass']\n",
    "#     cat_num_samples = {}\n",
    "#     for cat in range(len(clf_dict)):\n",
    "#         cat_num_samples[cat] = {}\n",
    "#         print('='*60)\n",
    "#         print('='*60)\n",
    "#         print(f\"Fold {fold_idx}: Category {cat} (SVM) AND 120 GeV < m_HH < 130 GeV\")\n",
    "#         print('-'*60)\n",
    "#         for m, sample_name in enumerate(order):\n",
    "#             cat_num_samples[cat][sample_name] = np.sum(\n",
    "#                 weights_plot_test[f\"fold_{fold_idx}\"][\n",
    "#                     np.logical_and(  # event passes conditions and is the right type (i.e. sample)\n",
    "#                         np.logical_and(  # event passes category and mass conditions\n",
    "#                             cat_dict[cat],  # event passes category selections\n",
    "#                             np.logical_and(  # diphoton mass is within 120-130 window\n",
    "#                                 masses < 130,\n",
    "#                                 masses > 120\n",
    "#                             ),\n",
    "#                         ),\n",
    "#                         bdt_test_dict[f\"fold_{fold_idx}\"].get_label() == m\n",
    "#                     )\n",
    "#                 ]\n",
    "#             )\n",
    "#             print(f\"{cat}: Num {sample_name} = {cat_num_samples[cat][sample_name]:.4f}\")\n",
    "#             print('-'*60)\n",
    "#         print(f\"{cat}: S = {cat_num_samples[cat][order[0]]:.4f}, B = {np.sum([cat_num_samples[cat][order[v]] for v in range(1, len(order))]):.4f}, S/âB = {(cat_num_samples[cat][order[0]] / np.sqrt(np.sum([cat_num_samples[cat][order[v]] for v in range(1, len(order))]))):.4f}\")\n",
    "\n",
    "# print('='*60)\n",
    "# print('='*60)\n",
    "# print('='*60)\n",
    "# print('='*60)\n",
    "\n",
    "flat_preds = np.concatenate([BDT_perf['ggF HH']['preds'][fold_idx] for fold_idx in range(len(bdt_test_dict))], axis=0)\n",
    "flat_truths = np.concatenate([bdt_test_dict[f\"fold_{fold_idx}\"].get_label() for fold_idx in range(len(bdt_test_dict))], axis=0)\n",
    "flat_weights = np.concatenate([weights_plot_test[f\"fold_{fold_idx}\"] for fold_idx in range(len(bdt_test_dict))], axis=0)\n",
    "# flat_weights = np.concatenate([weight_test_dict[f\"fold_{fold_idx}\"] for fold_idx in range(len(bdt_test_dict))], axis=0)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    clf_dict = multi_optimize_cut_boundaries(\n",
    "        flat_preds, flat_truths == 0, flat_weights\n",
    "    )\n",
    "\n",
    "    # plot_s_over_root_b(\n",
    "    #     sigs_and_bkgs['sig'], sigs_and_bkgs['bkg'], f\"{sample_name} vs. {sample_name_ if sample_name_ != sample_name else 'all'}\", \n",
    "    #     f\"BDT_{sample_name}_vs_{sample_name_ if sample_name_ != sample_name else 'all'}_sOverRootb_withCuts_testData_sum\", plot_dirpath, \n",
    "    #     weights=score_weights,\n",
    "    #     lines=lines, lines_labels=line_labels, line_colors=line_colors\n",
    "    # )\n",
    "\n",
    "flat_mass = np.concatenate([data_test_aux_dict[f\"fold_{fold_idx}\"]['mass'] for fold_idx in range(len(data_test_aux_dict))], axis=0)\n",
    "cat_dict = {}\n",
    "for cat in range(len(clf_dict)):\n",
    "    prev_cat_slice = np.ones_like(flat_weights, dtype=bool)\n",
    "    if cat > 0:\n",
    "        for prev_cat in range(cat):\n",
    "            prev_cat_slice = np.logical_and(\n",
    "                prev_cat_slice,\n",
    "                np.logical_not(\n",
    "                    np.all(\n",
    "                        p_to_xyz(flat_preds, split=False) < clf_dict[prev_cat], \n",
    "                        axis=1\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "    cat_dict[cat] = np.logical_and(\n",
    "        prev_cat_slice,\n",
    "        np.all(\n",
    "            p_to_xyz(flat_preds, split=False) < clf_dict[cat],\n",
    "            axis=1\n",
    "        )\n",
    "    )\n",
    "\n",
    "cat_num_samples = {}\n",
    "for cat in range(len(clf_dict)):\n",
    "    cat_num_samples[cat] = {}\n",
    "    print('='*60)\n",
    "    print('='*60)\n",
    "    print(f\"Category {cat} {f'3D outputs NOT< {clf_dict[cat-1]:.4f} AND ' if cat > 0 else ''}3D outputs < {clf_dict[cat]:.4f} AND 120 GeV < m_HH < 130 GeV\")\n",
    "    print('-'*60)\n",
    "    for m, sample_name in enumerate(order):\n",
    "        cat_num_samples[cat][sample_name] = np.sum(\n",
    "            flat_weights[\n",
    "                np.logical_and(  # event passes conditions and is the right type (i.e. sample)\n",
    "                    np.logical_and(  # event passes category and mass conditions\n",
    "                        cat_dict[cat],  # event passes category selections\n",
    "                        np.logical_and(  # diphoton mass is within 120-130 window\n",
    "                            flat_mass < 130,\n",
    "                            flat_mass > 120\n",
    "                        ),\n",
    "                    ),\n",
    "                    flat_truths == m\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "        print(f\"{cat}: Num {sample_name} = {cat_num_samples[cat][sample_name]:.4f}\")\n",
    "        print('-'*60)\n",
    "    print(f\"{cat}: S = {cat_num_samples[cat][order[0]]:.4f}, B = {np.sum([cat_num_samples[cat][order[v]] for v in range(1, len(order))]):.4f}, S/âB = {(cat_num_samples[cat][order[0]] / np.sqrt(np.sum([cat_num_samples[cat][order[v]] for v in range(1, len(order))]))):.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0: FÎ² (Î²=1) score = \n",
      "[4.60680190e-04 3.04259040e-01 1.30379892e-02 9.82596008e-01]\n",
      "fold 1: FÎ² (Î²=1) score = \n",
      "[4.35182073e-04 3.32092345e-01 1.42547780e-02 9.81410962e-01]\n",
      "fold 2: FÎ² (Î²=1) score = \n",
      "[4.33460186e-04 3.19364577e-01 2.16104580e-02 9.81466590e-01]\n",
      "fold 3: FÎ² (Î²=1) score = \n",
      "[4.50322650e-04 3.17277609e-01 1.76103989e-02 9.82174876e-01]\n",
      "fold 4: FÎ² (Î²=1) score = \n",
      "[4.41184847e-04 3.18747448e-01 1.76967452e-02 9.81886776e-01]\n",
      "Sum over folds: FÎ² (Î²=1) score = \n",
      "[4.43945421e-04 3.18169230e-01 1.68801291e-02 9.81908276e-01]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 900x700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 900x700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 900x700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 900x700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 900x700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 900x700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"confusion_matrix\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "if 'BDT_perf' not in globals():\n",
    "    with open(os.path.join(OUTPUT_DIRPATH, CURRENT_TIME+\"_BDT_perf.json\"), 'r') as f:\n",
    "        BDT_perf = json.load(f)\n",
    "\n",
    "beta = 1\n",
    "normalize = 'true'  # 'true' for normalize over rows, None for absoulte yields\n",
    "\n",
    "for fold_idx in range(len(BDT_perf['ggF HH']['preds'])):\n",
    "\n",
    "    pred_classes = np.argmax(BDT_perf['ggF HH']['preds'][fold_idx], axis=1)\n",
    "\n",
    "    conf_matrix = confusion_matrix(\n",
    "        bdt_test_dict[f\"fold_{fold_idx}\"].get_label(), \n",
    "        pred_classes,\n",
    "        sample_weight=weights_plot_test[f\"fold_{fold_idx}\"],\n",
    "        normalize=normalize\n",
    "    )\n",
    "\n",
    "    plot_confusion_matrix(\n",
    "        conf_matrix, order, f\"confusion_matrix_fold{fold_idx}{'_norm_'+normalize if normalize is not None else ''}\", plot_dirpath\n",
    "    )\n",
    "\n",
    "    f1_scores = fbeta_score(\n",
    "        bdt_test_dict[f\"fold_{fold_idx}\"].get_label(), \n",
    "        pred_classes,\n",
    "        beta=beta,\n",
    "        sample_weight=weights_plot_test[f\"fold_{fold_idx}\"], average=None\n",
    "    )\n",
    "    print(f\"fold {fold_idx}: FÎ² (Î²={beta}) score = \\n{f1_scores}\")\n",
    "\n",
    "full_pred_classes = np.argmax(\n",
    "    np.concatenate(\n",
    "        [\n",
    "            BDT_perf['ggF HH']['preds'][fold_idx] for fold_idx in range(len(BDT_perf['ggF HH']['preds']))\n",
    "        ]\n",
    "    ), axis=1\n",
    ")\n",
    "full_labels = np.concatenate(\n",
    "    [\n",
    "        bdt_test_dict[f\"fold_{fold_idx}\"].get_label() for fold_idx in range(len(BDT_perf['ggF HH']['preds']))\n",
    "    ]\n",
    ")\n",
    "full_weights = np.concatenate(\n",
    "    [\n",
    "        weights_plot_test[f\"fold_{fold_idx}\"] for fold_idx in range(len(BDT_perf['ggF HH']['preds']))\n",
    "    ]\n",
    ")\n",
    "\n",
    "conf_matrix = confusion_matrix(\n",
    "    full_labels, \n",
    "    full_pred_classes,\n",
    "    sample_weight=full_weights,\n",
    "    normalize=normalize\n",
    ")\n",
    "\n",
    "plot_confusion_matrix(\n",
    "    conf_matrix, order, f\"confusion_matrix_sum{'_norm_'+normalize if normalize is not None else ''}\", plot_dirpath\n",
    ")\n",
    "\n",
    "f1_scores = fbeta_score(\n",
    "    full_labels, \n",
    "    full_pred_classes,\n",
    "    beta=beta,\n",
    "    sample_weight=full_weights, average=None\n",
    ")\n",
    "print(f\"Sum over folds: FÎ² (Î²={beta}) score = \\n{f1_scores}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"variable_importance\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "for fold_idx in range(len(bdt_train_dict)):\n",
    "    booster = xgb.Booster(param, model_file=os.path.join(OUTPUT_DIRPATH, f'{CURRENT_TIME}_BDT_fold{fold_idx}.model'))\n",
    "\n",
    "    labels = copy.deepcopy([key for key in hlf_vars_columns_dict[f'fold_{fold_idx}'].keys()])\n",
    "    labels.sort()\n",
    "    \n",
    "    booster.feature_names = labels\n",
    "    score_dict = booster.get_score(importance_type='total_gain')\n",
    "\n",
    "    sorted_scores, sorted_labels = [], []\n",
    "    for label, score in score_dict.items():\n",
    "        sorted_scores.append(score)\n",
    "        sorted_labels.append(label)\n",
    "\n",
    "    sorted_labels = np.array(sorted_labels)[np.argsort(sorted_scores)]\n",
    "    sorted_scores = np.sort(sorted_scores)\n",
    "\n",
    "    plot_feature_importance(\n",
    "        sorted_scores, sorted_labels, f'xgb_importance_fold{fold_idx}', plot_dirpath\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Variable Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "------------------------------------------------------------\n",
      "mass                            1.000000\n",
      "DeltaEta_jj                    -0.014107\n",
      "DeltaPhi_isr_jet_z             -0.000925\n",
      "DeltaPhi_jj                     0.000092\n",
      "leadBjet_leadLepton            -0.042219\n",
      "HHbbggCandidate_eta             0.001160\n",
      "HHbbggCandidate_pt              0.076079\n",
      "dijet_mass                      0.016439\n",
      "dijet_pt                        0.092620\n",
      "eta                             0.002561\n",
      "isr_jet_pt                      0.011575\n",
      "lead_bjet_pt                    0.085730\n",
      "lead_bjet_btagPNetB             0.027514\n",
      "lead_bjet_pt_over_Mjj           0.079975\n",
      "lead_mvaID                      0.031512\n",
      "lead_sigmaE_over_E             -0.092546\n",
      "lepton1_mvaID                  -0.042219\n",
      "lepton1_pfIsoId                -0.042220\n",
      "lepton1_pt                     -0.042179\n",
      "n_jets                          0.016196\n",
      "CosThetaStar_CS                 0.003078\n",
      "CosThetaStar_gg                 0.000987\n",
      "CosThetaStar_jj                -0.000861\n",
      "DeltaPhi_j1MET                 -0.000664\n",
      "DeltaPhi_j2MET                  0.000155\n",
      "DeltaR_jg_min                  -0.056231\n",
      "chi_t0                          0.005899\n",
      "chi_t1                          0.005173\n",
      "lead_bjet_sigmapT_over_pT      -0.032764\n",
      "lead_bjet_eta                   0.000113\n",
      "sublead_bjet_sigmapT_over_pT    0.004297\n",
      "sublead_bjet_eta                0.000944\n",
      "pt                              0.176174\n",
      "pt_balance                     -0.105447\n",
      "puppiMET_pt                    -0.008868\n",
      "puppiMET_sumEt                  0.303636\n",
      "sublead_bjet_pt                 0.004647\n",
      "sublead_bjet_btagPNetB         -0.000868\n",
      "sublead_bjet_pt_over_Mjj       -0.000724\n",
      "sublead_mvaID                   0.033679\n",
      "sublead_sigmaE_over_E          -0.118233\n",
      "Name: mass, dtype: float64\n",
      "============================================================\n",
      "============================================================\n",
      "============================================================\n",
      "\n",
      "fold 1\n",
      "------------------------------------------------------------\n",
      "mass                            1.000000\n",
      "DeltaEta_jj                    -0.013996\n",
      "DeltaPhi_isr_jet_z             -0.000859\n",
      "DeltaPhi_jj                     0.000251\n",
      "leadBjet_leadLepton            -0.042222\n",
      "HHbbggCandidate_eta             0.001798\n",
      "HHbbggCandidate_pt              0.076220\n",
      "dijet_mass                      0.017465\n",
      "dijet_pt                        0.092708\n",
      "eta                             0.002941\n",
      "isr_jet_pt                      0.012096\n",
      "lead_bjet_pt                    0.086103\n",
      "lead_bjet_btagPNetB             0.026855\n",
      "lead_bjet_pt_over_Mjj           0.080079\n",
      "lead_mvaID                      0.031520\n",
      "lead_sigmaE_over_E             -0.091880\n",
      "lepton1_mvaID                  -0.042222\n",
      "lepton1_pfIsoId                -0.042223\n",
      "lepton1_pt                     -0.042175\n",
      "n_jets                          0.016748\n",
      "CosThetaStar_CS                 0.003003\n",
      "CosThetaStar_gg                 0.001055\n",
      "CosThetaStar_jj                 0.000039\n",
      "DeltaPhi_j1MET                 -0.000288\n",
      "DeltaPhi_j2MET                 -0.000636\n",
      "DeltaR_jg_min                  -0.056387\n",
      "chi_t0                          0.005826\n",
      "chi_t1                          0.005464\n",
      "lead_bjet_sigmapT_over_pT      -0.032660\n",
      "lead_bjet_eta                   0.000997\n",
      "sublead_bjet_sigmapT_over_pT    0.003761\n",
      "sublead_bjet_eta                0.000766\n",
      "pt                              0.176658\n",
      "pt_balance                     -0.105729\n",
      "puppiMET_pt                    -0.008513\n",
      "puppiMET_sumEt                  0.304005\n",
      "sublead_bjet_pt                 0.005259\n",
      "sublead_bjet_btagPNetB         -0.001125\n",
      "sublead_bjet_pt_over_Mjj       -0.000766\n",
      "sublead_mvaID                   0.034208\n",
      "sublead_sigmaE_over_E          -0.118610\n",
      "Name: mass, dtype: float64\n",
      "============================================================\n",
      "============================================================\n",
      "============================================================\n",
      "\n",
      "fold 2\n",
      "------------------------------------------------------------\n",
      "mass                            1.000000\n",
      "DeltaEta_jj                    -0.013856\n",
      "DeltaPhi_isr_jet_z             -0.001111\n",
      "DeltaPhi_jj                     0.000080\n",
      "leadBjet_leadLepton            -0.042217\n",
      "HHbbggCandidate_eta             0.001594\n",
      "HHbbggCandidate_pt              0.077042\n",
      "dijet_mass                      0.017564\n",
      "dijet_pt                        0.093043\n",
      "eta                             0.002778\n",
      "isr_jet_pt                      0.011537\n",
      "lead_bjet_pt                    0.086219\n",
      "lead_bjet_btagPNetB             0.027433\n",
      "lead_bjet_pt_over_Mjj           0.080031\n",
      "lead_mvaID                      0.031741\n",
      "lead_sigmaE_over_E             -0.092160\n",
      "lepton1_mvaID                  -0.042217\n",
      "lepton1_pfIsoId                -0.042218\n",
      "lepton1_pt                     -0.042179\n",
      "n_jets                          0.016733\n",
      "CosThetaStar_CS                 0.003433\n",
      "CosThetaStar_gg                 0.000928\n",
      "CosThetaStar_jj                -0.000352\n",
      "DeltaPhi_j1MET                 -0.000792\n",
      "DeltaPhi_j2MET                 -0.000535\n",
      "DeltaR_jg_min                  -0.055617\n",
      "chi_t0                          0.006730\n",
      "chi_t1                          0.005088\n",
      "lead_bjet_sigmapT_over_pT      -0.032920\n",
      "lead_bjet_eta                   0.000074\n",
      "sublead_bjet_sigmapT_over_pT    0.003927\n",
      "sublead_bjet_eta                0.000324\n",
      "pt                              0.177202\n",
      "pt_balance                     -0.105141\n",
      "puppiMET_pt                    -0.008236\n",
      "puppiMET_sumEt                  0.304886\n",
      "sublead_bjet_pt                 0.005898\n",
      "sublead_bjet_btagPNetB         -0.001063\n",
      "sublead_bjet_pt_over_Mjj       -0.000497\n",
      "sublead_mvaID                   0.033864\n",
      "sublead_sigmaE_over_E          -0.118050\n",
      "Name: mass, dtype: float64\n",
      "============================================================\n",
      "============================================================\n",
      "============================================================\n",
      "\n",
      "fold 3\n",
      "------------------------------------------------------------\n",
      "mass                            1.000000\n",
      "DeltaEta_jj                    -0.014483\n",
      "DeltaPhi_isr_jet_z             -0.001169\n",
      "DeltaPhi_jj                     0.000268\n",
      "leadBjet_leadLepton            -0.042173\n",
      "HHbbggCandidate_eta             0.001092\n",
      "HHbbggCandidate_pt              0.077145\n",
      "dijet_mass                      0.017178\n",
      "dijet_pt                        0.093165\n",
      "eta                             0.002774\n",
      "isr_jet_pt                      0.012027\n",
      "lead_bjet_pt                    0.086460\n",
      "lead_bjet_btagPNetB             0.027137\n",
      "lead_bjet_pt_over_Mjj           0.080442\n",
      "lead_mvaID                      0.031391\n",
      "lead_sigmaE_over_E             -0.092145\n",
      "lepton1_mvaID                  -0.042173\n",
      "lepton1_pfIsoId                -0.042174\n",
      "lepton1_pt                     -0.042137\n",
      "n_jets                          0.016546\n",
      "CosThetaStar_CS                 0.003075\n",
      "CosThetaStar_gg                 0.001061\n",
      "CosThetaStar_jj                -0.000841\n",
      "DeltaPhi_j1MET                 -0.000635\n",
      "DeltaPhi_j2MET                 -0.000458\n",
      "DeltaR_jg_min                  -0.056244\n",
      "chi_t0                          0.006422\n",
      "chi_t1                          0.005696\n",
      "lead_bjet_sigmapT_over_pT      -0.032813\n",
      "lead_bjet_eta                   0.000210\n",
      "sublead_bjet_sigmapT_over_pT    0.003819\n",
      "sublead_bjet_eta                0.001101\n",
      "pt                              0.177700\n",
      "pt_balance                     -0.105095\n",
      "puppiMET_pt                    -0.008445\n",
      "puppiMET_sumEt                  0.304518\n",
      "sublead_bjet_pt                 0.005517\n",
      "sublead_bjet_btagPNetB         -0.001075\n",
      "sublead_bjet_pt_over_Mjj       -0.000226\n",
      "sublead_mvaID                   0.033961\n",
      "sublead_sigmaE_over_E          -0.118316\n",
      "Name: mass, dtype: float64\n",
      "============================================================\n",
      "============================================================\n",
      "============================================================\n",
      "\n",
      "fold 4\n",
      "------------------------------------------------------------\n",
      "mass                            1.000000\n",
      "DeltaEta_jj                    -0.014231\n",
      "DeltaPhi_isr_jet_z             -0.000699\n",
      "DeltaPhi_jj                     0.000257\n",
      "leadBjet_leadLepton            -0.042266\n",
      "HHbbggCandidate_eta             0.000936\n",
      "HHbbggCandidate_pt              0.076650\n",
      "dijet_mass                      0.017476\n",
      "dijet_pt                        0.093200\n",
      "eta                             0.002256\n",
      "isr_jet_pt                      0.011958\n",
      "lead_bjet_pt                    0.086767\n",
      "lead_bjet_btagPNetB             0.027241\n",
      "lead_bjet_pt_over_Mjj           0.080583\n",
      "lead_mvaID                      0.031659\n",
      "lead_sigmaE_over_E             -0.092209\n",
      "lepton1_mvaID                  -0.042266\n",
      "lepton1_pfIsoId                -0.042267\n",
      "lepton1_pt                     -0.042228\n",
      "n_jets                          0.016575\n",
      "CosThetaStar_CS                 0.003208\n",
      "CosThetaStar_gg                 0.000910\n",
      "CosThetaStar_jj                -0.000402\n",
      "DeltaPhi_j1MET                 -0.000262\n",
      "DeltaPhi_j2MET                 -0.000472\n",
      "DeltaR_jg_min                  -0.056299\n",
      "chi_t0                          0.006548\n",
      "chi_t1                          0.004965\n",
      "lead_bjet_sigmapT_over_pT      -0.033263\n",
      "lead_bjet_eta                   0.000085\n",
      "sublead_bjet_sigmapT_over_pT    0.004345\n",
      "sublead_bjet_eta                0.000459\n",
      "pt                              0.177301\n",
      "pt_balance                     -0.105532\n",
      "puppiMET_pt                    -0.008498\n",
      "puppiMET_sumEt                  0.303577\n",
      "sublead_bjet_pt                 0.004780\n",
      "sublead_bjet_btagPNetB         -0.001191\n",
      "sublead_bjet_pt_over_Mjj       -0.001212\n",
      "sublead_mvaID                   0.033867\n",
      "sublead_sigmaE_over_E          -0.118450\n",
      "Name: mass, dtype: float64\n",
      "============================================================\n",
      "============================================================\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_corr_dict = {}\n",
    "for fold_idx in range(len(data_aux_dict)):\n",
    "    merged_pd = copy.deepcopy(data_df_dict[f\"fold_{fold_idx}\"])\n",
    "    for i, var_name in enumerate(['mass']):\n",
    "        merged_pd.insert(i, var_name, data_aux_dict[f\"fold_{fold_idx}\"].loc[:, var_name])\n",
    "    data_corr_dict[f\"fold_{fold_idx}\"] = merged_pd.corr()\n",
    "\n",
    "    print(f\"fold {fold_idx}\")\n",
    "    print('-'*60)\n",
    "    print(data_corr_dict[f\"fold_{fold_idx}\"].iloc[0, :])\n",
    "    print(f\"{'='*60}\\n{'='*60}\\n{'='*60}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mass Sculpting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 38\u001b[0m\n\u001b[1;32m     32\u001b[0m train_hists[sample_name], val_hists[sample_name], test_hists[sample_name] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(), \u001b[38;5;28mlist\u001b[39m(), \u001b[38;5;28mlist\u001b[39m()\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m score_cut \u001b[38;5;129;01min\u001b[39;00m score_cuts:\n\u001b[1;32m     35\u001b[0m     train_mask \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     36\u001b[0m         xgb_label_train_dict[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfold_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m i\n\u001b[1;32m     37\u001b[0m     ) \u001b[38;5;241m&\u001b[39m (\n\u001b[0;32m---> 38\u001b[0m         \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBDT_perf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mggF HH\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain_preds\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfold_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[:, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m score_cut\n\u001b[1;32m     39\u001b[0m     )\n\u001b[1;32m     40\u001b[0m     val_mask \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     41\u001b[0m         xgb_label_val_dict[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfold_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m i\n\u001b[1;32m     42\u001b[0m     ) \u001b[38;5;241m&\u001b[39m (\n\u001b[1;32m     43\u001b[0m         np\u001b[38;5;241m.\u001b[39marray(BDT_perf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mggF HH\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_preds\u001b[39m\u001b[38;5;124m'\u001b[39m][fold_idx])[:, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m score_cut\n\u001b[1;32m     44\u001b[0m     )\n\u001b[1;32m     45\u001b[0m     test_mask \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     46\u001b[0m         xgb_label_test_dict[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfold_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m i\n\u001b[1;32m     47\u001b[0m     ) \u001b[38;5;241m&\u001b[39m (\n\u001b[1;32m     48\u001b[0m         np\u001b[38;5;241m.\u001b[39marray(BDT_perf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mggF HH\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreds\u001b[39m\u001b[38;5;124m'\u001b[39m][fold_idx])[:, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m score_cut\n\u001b[1;32m     49\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"mass_sculpting\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "if 'BDT_perf' not in globals():\n",
    "    with open(os.path.join(OUTPUT_DIRPATH, CURRENT_TIME+f\"_BDT_perf.json\"), 'r') as f:\n",
    "        BDT_perf = json.load(f)\n",
    "\n",
    "score_cuts = [0.0, 0.7, 0.99]\n",
    "label_arr = {\n",
    "    MC_NAMES_PRETTY[sample_name]: [f'score above {score_cut}' for score_cut in score_cuts] for sample_name in order\n",
    "}\n",
    "\n",
    "# Loop over and plot the per-fold variables\n",
    "for fold_idx in range(len(hlf_vars_columns_dict)):\n",
    "\n",
    "    for var_idx, var_name in enumerate(['mass', 'dijet_mass']):\n",
    "\n",
    "        plot_dirpath_ = os.path.join(plot_dirpath, var_name)\n",
    "        if not os.path.exists(plot_dirpath_):\n",
    "            os.makedirs(plot_dirpath_)\n",
    "\n",
    "        train_hists, val_hists, test_hists = {}, {}, {}\n",
    "        for i, sample_name in enumerate(order):\n",
    "\n",
    "            train_hists[sample_name], val_hists[sample_name], test_hists[sample_name] = list(), list(), list()\n",
    "            for score_cut in score_cuts:\n",
    "\n",
    "                train_mask = (\n",
    "                    xgb_label_train_dict[f'fold_{fold_idx}'] == i\n",
    "                ) & (\n",
    "                    np.array(BDT_perf['ggF HH']['train_preds'][fold_idx])[:, 0] > score_cut\n",
    "                )\n",
    "                val_mask = (\n",
    "                    xgb_label_val_dict[f'fold_{fold_idx}'] == i\n",
    "                ) & (\n",
    "                    np.array(BDT_perf['ggF HH']['val_preds'][fold_idx])[:, 0] > score_cut\n",
    "                )\n",
    "                test_mask = (\n",
    "                    xgb_label_test_dict[f'fold_{fold_idx}'] == i\n",
    "                ) & (\n",
    "                    np.array(BDT_perf['ggF HH']['preds'][fold_idx])[:, 0] > score_cut\n",
    "                )\n",
    "            \n",
    "                train_np = (\n",
    "                    data_aux_dict[f'fold_{fold_idx}'].iloc[train_idxs_dict[f'fold_{fold_idx}']]\n",
    "                ).loc[train_mask, var_name].to_numpy()\n",
    "                val_np = (\n",
    "                    data_aux_dict[f'fold_{fold_idx}'].iloc[val_idxs_dict[f'fold_{fold_idx}']]\n",
    "                ).loc[val_mask, var_name].to_numpy()\n",
    "                test_np = data_test_aux_dict[f'fold_{fold_idx}'].loc[test_mask, var_name].to_numpy()\n",
    "            \n",
    "                train_hists[sample_name].append(hist.Hist(VARIABLES[var_name]).fill(var=train_np))\n",
    "                val_hists[sample_name].append(hist.Hist(VARIABLES[var_name]).fill(var=val_np))\n",
    "                test_hists[sample_name].append(hist.Hist(VARIABLES[var_name]).fill(var=test_np))\n",
    "    \n",
    "            for j, (plot_type, histdict) in enumerate([('train_', train_hists), ('val_', val_hists), ('test_', test_hists)]):\n",
    "                make_input_plot(\n",
    "                    plot_dirpath_, var_name,\n",
    "                    histdict[sample_name], \n",
    "                    fold_idx=fold_idx, labels=label_arr[MC_NAMES_PRETTY[sample_name]], \n",
    "                    plot_prefix=plot_type+f'{sample_name}_scoreCut_'\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling for Mass Sculpting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_from_var(sample_var, sample_weight, n_events, n_samples_per_event=1, bins=100, seed=None):\n",
    "    resample_rng = np.random.default_rng(seed=seed)\n",
    "\n",
    "    np_hist, bin_edges = np.histogram(sample_var, bins=bins, weights=sample_weight, density=True)\n",
    "    np_hist /= np.sum(np_hist)\n",
    "\n",
    "    bin_choices = resample_rng.choice(np.arange(len(np_hist)), size=n_events*n_samples_per_event, p=np_hist)\n",
    "\n",
    "    value_choices = (bin_edges[bin_choices+1] - bin_edges[bin_choices]) * resample_rng.random(size=n_events*n_samples_per_event) + bin_edges[bin_choices]\n",
    "\n",
    "    return value_choices\n",
    "\n",
    "def resample_grow_np(var, bool_arr, n_duplicates_per_event):\n",
    "    new_rows_shape = tuple([n_duplicates_per_event]+[1 for _ in range(1, len(np.shape(var)))])\n",
    "    new_rows = np.tile(\n",
    "        var[bool_arr],\n",
    "        new_rows_shape\n",
    "    )\n",
    "    return np.concatenate([var, new_rows])\n",
    "def resample_grow_pd(var, bool_arr, n_duplicates_per_event):\n",
    "    new_rows = pd.DataFrame(\n",
    "        np.tile(\n",
    "            ( var.loc[bool_arr] ).to_numpy(),\n",
    "            (n_duplicates_per_event, 1)\n",
    "        ),\n",
    "        columns=var.columns\n",
    "    )\n",
    "    return pd.concat([var, new_rows], ignore_index=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resample_ = 10\n",
    "RESAMPLE = (resample_) * 10  # Set to False for no resampling, otherwise sets the number of times to duplicate gjet data for resampling\n",
    "\n",
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"mass_sculpting_resample\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "score_cuts = [0.0, 0.7, 0.99, 0.9984]\n",
    "label_arr = [f'score above {score_cut}' for score_cut in score_cuts]\n",
    "plot_vars = ['mass', 'dijet_mass', 'HHbbggCandidate_mass']\n",
    "\n",
    "BDT_perf_resample = [\n",
    "    {\n",
    "        f'preds{score_cut}': copy.deepcopy({plot_var: list() for plot_var in plot_vars}) for score_cut in score_cuts\n",
    "    } for fold_idx in range(len(bdt_train_dict))\n",
    "]\n",
    "GJet_preds = []\n",
    "mean_values = {\n",
    "    'gj': list(),\n",
    "    'gg': list(),\n",
    "    'tth': list()\n",
    "}\n",
    "\n",
    "for fold_idx in range(len(bdt_train_dict)):\n",
    "    booster = xgb.Booster(param)\n",
    "    booster.load_model(os.path.join(OUTPUT_DIRPATH, f'{CURRENT_TIME}_BDT_fold{fold_idx}.model'))\n",
    "\n",
    "    nonres_bool = (data_test_aux_dict[f\"fold_{fold_idx}\"].loc[:, 'sample_name'] == \"GGJets\") | (data_test_aux_dict[f\"fold_{fold_idx}\"].loc[:, 'sample_name'] == \"GJetPt20To40\") | (data_test_aux_dict[f\"fold_{fold_idx}\"].loc[:, 'sample_name'] == \"GJetPt40\")\n",
    "\n",
    "    data_hlf_test = resample_grow_np(data_hlf_test_dict[f\"fold_{fold_idx}\"], nonres_bool, resample_)\n",
    "    data_test_aux = resample_grow_pd(data_test_aux_dict[f\"fold_{fold_idx}\"], nonres_bool, resample_)\n",
    "    weight_test = resample_grow_np(weight_test_dict[f\"fold_{fold_idx}\"], nonres_bool, resample_)\n",
    "    weights_plot = resample_grow_np(weights_plot_test[f\"fold_{fold_idx}\"], nonres_bool, resample_)\n",
    "    xgb_label_test = resample_grow_np(xgb_label_test_dict[f\"fold_{fold_idx}\"], nonres_bool, resample_)\n",
    "\n",
    "    gg_bool = (data_test_aux.loc[:, 'sample_name'] == \"GGJets\")\n",
    "    tth_bool = (data_test_aux.loc[:, 'sample_name'] == \"ttHToGG\")\n",
    "    gj_bool = (data_test_aux.loc[:, 'sample_name'] == \"GJetPt20To40\") | (data_test_aux.loc[:, 'sample_name'] == \"GJetPt40\")\n",
    "    hh_bool = (data_test_aux.loc[:, 'sample_name'] == \"GluGluToHH\")\n",
    "    nonres_bool = (data_test_aux.loc[:, 'sample_name'] == \"GGJets\") | (data_test_aux.loc[:, 'sample_name'] == \"GJetPt20To40\") | (data_test_aux.loc[:, 'sample_name'] == \"GJetPt40\")\n",
    "\n",
    "\n",
    "    for var_idx, plot_var in enumerate(plot_vars):\n",
    "\n",
    "        plot_dirpath_ = os.path.join(plot_dirpath, plot_var)\n",
    "        if not os.path.exists(plot_dirpath_):\n",
    "            os.makedirs(plot_dirpath_)\n",
    "\n",
    "        for _ in range(RESAMPLE // resample_):\n",
    "\n",
    "            for particle_type in ['lead', 'sublead']:\n",
    "\n",
    "                # gg_mvaID = data_hlf_test[\n",
    "                #     gg_bool, \n",
    "                #     hlf_vars_columns_dict[f\"fold_{fold_idx}\"][f\"{particle_type}_mvaID\"]\n",
    "                # ]\n",
    "                # data_hlf_test[\n",
    "                #     gj_bool, \n",
    "                #     hlf_vars_columns_dict[f\"fold_{fold_idx}\"][f\"{particle_type}_mvaID\"]\n",
    "                # ] = resample_from_var(\n",
    "                #     gg_mvaID, \n",
    "                #     weights_plot[gg_bool],\n",
    "                #     np.sum(gj_bool),\n",
    "                #     bins=190\n",
    "                # )\n",
    "\n",
    "                tth_pNetB = data_hlf_test[\n",
    "                    tth_bool, \n",
    "                    hlf_vars_columns_dict[f\"fold_{fold_idx}\"][f\"{particle_type}_bjet_btagPNetB\"]\n",
    "                ]\n",
    "                data_hlf_test[\n",
    "                    nonres_bool, \n",
    "                    hlf_vars_columns_dict[f\"fold_{fold_idx}\"][f\"{particle_type}_bjet_btagPNetB\"]\n",
    "                ] = resample_from_var(\n",
    "                    tth_pNetB, \n",
    "                    np.abs(weights_plot[tth_bool]),\n",
    "                    np.sum(nonres_bool),\n",
    "                    bins=100\n",
    "                )\n",
    "\n",
    "                # tth_sigmaE = data_hlf_test[\n",
    "                #     tth_bool, \n",
    "                #     hlf_vars_columns_dict[f\"fold_{fold_idx}\"][f\"{particle_type}_sigmaE_over_E\"]\n",
    "                # ]\n",
    "                # data_hlf_test[\n",
    "                #     gj_bool, \n",
    "                #     hlf_vars_columns_dict[f\"fold_{fold_idx}\"][f\"{particle_type}_sigmaE_over_E\"]\n",
    "                # ] = resample_from_var(\n",
    "                #     tth_sigmaE, \n",
    "                #     np.abs(weights_plot[tth_bool]),\n",
    "                #     np.sum(gj_bool),\n",
    "                #     bins=100\n",
    "                # )\n",
    "            # hh_dijet = data_hlf_test[\n",
    "            #     hh_bool, \n",
    "            #     hlf_vars_columns_dict[f\"fold_{fold_idx}\"][\"dijet_mass\"]\n",
    "            # ]\n",
    "            # data_hlf_test[\n",
    "            #     nonres_bool, \n",
    "            #     hlf_vars_columns_dict[f\"fold_{fold_idx}\"][\"dijet_mass\"]\n",
    "            # ] = resample_from_var(\n",
    "            #     hh_dijet, \n",
    "            #     np.abs(weights_plot[hh_bool]),\n",
    "            #     np.sum(nonres_bool),\n",
    "            #     bins=100\n",
    "            # )\n",
    "\n",
    "            nonres_ggf_preds = booster.predict(\n",
    "                xgb.DMatrix(\n",
    "                    data=data_hlf_test[nonres_bool], label=xgb_label_test[nonres_bool], \n",
    "                    weight=np.abs(weight_test)[nonres_bool],\n",
    "                    missing=-999.0, feature_names=list(hlf_vars_columns_dict[f\"fold_{fold_idx}\"])\n",
    "                ), \n",
    "                iteration_range=(0, booster.best_iteration+1)\n",
    "            )[:, 0]\n",
    "\n",
    "            # gg_ggf_preds = booster.predict(\n",
    "            #     xgb.DMatrix(\n",
    "            #         data=data_hlf_test[gg_bool], label=xgb_label_test[gg_bool], \n",
    "            #         weight=np.abs(weight_test)[gg_bool],\n",
    "            #         missing=-999.0, feature_names=list(hlf_vars_columns_dict[f\"fold_{fold_idx}\"])\n",
    "            #     ), \n",
    "            #     iteration_range=(0, booster.best_iteration+1)\n",
    "            # )[:, 0]\n",
    "            # tth_ggf_preds = booster.predict(\n",
    "            #     xgb.DMatrix(\n",
    "            #         data=data_hlf_test[tth_bool], label=xgb_label_test[tth_bool], \n",
    "            #         weight=np.abs(weight_test)[tth_bool],\n",
    "            #         missing=-999.0, feature_names=list(hlf_vars_columns_dict[f\"fold_{fold_idx}\"])\n",
    "            #     ), \n",
    "            #     iteration_range=(0, booster.best_iteration+1)\n",
    "            # )[:, 0]\n",
    "\n",
    "            if np.sum([len(GJet_preds[i]) for i in range(len(GJet_preds))]) < 100000:\n",
    "                GJet_preds.append(nonres_ggf_preds[nonres_ggf_preds > 0.9])\n",
    "\n",
    "            for score_cut in score_cuts:\n",
    "                if len(BDT_perf_resample[fold_idx][f'preds{score_cut}'][plot_var]) >= 10000:\n",
    "                    continue\n",
    "\n",
    "                BDT_perf_resample[fold_idx][f'preds{score_cut}'][plot_var].append(\n",
    "                    data_test_aux.loc[nonres_bool, plot_var].to_numpy()[nonres_ggf_preds > score_cut]\n",
    "                )\n",
    "        if fold_idx == 0 and plot_var == 'mass':\n",
    "            plt.figure()\n",
    "            plt.hist(np.concatenate(GJet_preds), bins=400, range=(0.9, 1.))\n",
    "            plt.savefig(os.path.join(plot_dirpath_, \"GJet_output_dist_with_resample0p9\"))\n",
    "\n",
    "        test_hists = [hist.Hist(VARIABLES[plot_var]).fill(var=np.concatenate(BDT_perf_resample[fold_idx][f'preds{score_cut}'][plot_var])) for score_cut in score_cuts]\n",
    "        make_input_plot(\n",
    "            plot_dirpath_, plot_var,\n",
    "            test_hists, \n",
    "            fold_idx=fold_idx, labels=label_arr, \n",
    "            plot_prefix='test_non-res_scoreCut_'\n",
    "        )\n",
    "\n",
    "for var_idx, plot_var in enumerate(plot_vars):\n",
    "\n",
    "    plot_dirpath_ = os.path.join(plot_dirpath, plot_var)\n",
    "    if not os.path.exists(plot_dirpath_):\n",
    "        os.makedirs(plot_dirpath_)\n",
    "\n",
    "    test_hists = [hist.Hist(VARIABLES[plot_var]).fill(\n",
    "        var=np.concatenate(\n",
    "            [np.concatenate(BDT_perf_resample[fold_idx][f'preds{score_cut}'][plot_var]) for fold_idx in range(len(BDT_perf_resample))]\n",
    "        )\n",
    "    ) for score_cut in score_cuts]\n",
    "    make_input_plot(\n",
    "        plot_dirpath_, plot_var,\n",
    "        test_hists, \n",
    "        fold_idx=None, labels=label_arr, \n",
    "        plot_prefix='test_non-res_scoreCut_'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/tmp/ipykernel_3372844/3163328249.py:231: UserWarning: Data has no positive values, and therefore cannot be log-scaled.\n",
      "  ax.set_yscale('log')\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/tmp/ipykernel_3372844/3163328249.py:231: UserWarning: Data has no positive values, and therefore cannot be log-scaled.\n",
      "  ax.set_yscale('log')\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/tmp/ipykernel_3372844/3163328249.py:231: UserWarning: Data has no positive values, and therefore cannot be log-scaled.\n",
      "  ax.set_yscale('log')\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/tmp/ipykernel_3372844/3163328249.py:231: UserWarning: Data has no positive values, and therefore cannot be log-scaled.\n",
      "  ax.set_yscale('log')\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/tmp/ipykernel_3372844/3163328249.py:231: UserWarning: Data has no positive values, and therefore cannot be log-scaled.\n",
      "  ax.set_yscale('log')\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/tmp/ipykernel_3372844/3163328249.py:231: UserWarning: Data has no positive values, and therefore cannot be log-scaled.\n",
      "  ax.set_yscale('log')\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/tmp/ipykernel_3372844/3163328249.py:231: UserWarning: Data has no positive values, and therefore cannot be log-scaled.\n",
      "  ax.set_yscale('log')\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/tmp/ipykernel_3372844/3163328249.py:231: UserWarning: Data has no positive values, and therefore cannot be log-scaled.\n",
      "  ax.set_yscale('log')\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/tmp/ipykernel_3372844/3163328249.py:231: UserWarning: Data has no positive values, and therefore cannot be log-scaled.\n",
      "  ax.set_yscale('log')\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/tmp/ipykernel_3372844/3163328249.py:231: UserWarning: Data has no positive values, and therefore cannot be log-scaled.\n",
      "  ax.set_yscale('log')\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/tmp/ipykernel_3372844/3163328249.py:231: UserWarning: Data has no positive values, and therefore cannot be log-scaled.\n",
      "  ax.set_yscale('log')\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/tmp/ipykernel_3372844/3163328249.py:231: UserWarning: Data has no positive values, and therefore cannot be log-scaled.\n",
      "  ax.set_yscale('log')\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/tmp/ipykernel_3372844/3163328249.py:231: UserWarning: Data has no positive values, and therefore cannot be log-scaled.\n",
      "  ax.set_yscale('log')\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/tmp/ipykernel_3372844/3163328249.py:231: UserWarning: Data has no positive values, and therefore cannot be log-scaled.\n",
      "  ax.set_yscale('log')\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/tmp/ipykernel_3372844/3163328249.py:231: UserWarning: Data has no positive values, and therefore cannot be log-scaled.\n",
      "  ax.set_yscale('log')\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/tmp/ipykernel_3372844/3163328249.py:231: UserWarning: Data has no positive values, and therefore cannot be log-scaled.\n",
      "  ax.set_yscale('log')\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/tmp/ipykernel_3372844/3163328249.py:231: UserWarning: Data has no positive values, and therefore cannot be log-scaled.\n",
      "  ax.set_yscale('log')\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/tmp/ipykernel_3372844/3163328249.py:231: UserWarning: Data has no positive values, and therefore cannot be log-scaled.\n",
      "  ax.set_yscale('log')\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/tmp/ipykernel_3372844/3163328249.py:231: UserWarning: Data has no positive values, and therefore cannot be log-scaled.\n",
      "  ax.set_yscale('log')\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/tmp/ipykernel_3372844/3163328249.py:231: UserWarning: Data has no positive values, and therefore cannot be log-scaled.\n",
      "  ax.set_yscale('log')\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/tmp/ipykernel_3372844/3163328249.py:231: UserWarning: Data has no positive values, and therefore cannot be log-scaled.\n",
      "  ax.set_yscale('log')\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/tmp/ipykernel_3372844/3163328249.py:231: UserWarning: Data has no positive values, and therefore cannot be log-scaled.\n",
      "  ax.set_yscale('log')\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/tmp/ipykernel_3372844/3163328249.py:231: UserWarning: Data has no positive values, and therefore cannot be log-scaled.\n",
      "  ax.set_yscale('log')\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/tmp/ipykernel_3372844/3163328249.py:231: UserWarning: Data has no positive values, and therefore cannot be log-scaled.\n",
      "  ax.set_yscale('log')\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/tmp/ipykernel_3372844/3163328249.py:231: UserWarning: Data has no positive values, and therefore cannot be log-scaled.\n",
      "  ax.set_yscale('log')\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/tmp/ipykernel_3372844/3163328249.py:231: UserWarning: Data has no positive values, and therefore cannot be log-scaled.\n",
      "  ax.set_yscale('log')\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/tmp/ipykernel_3372844/3163328249.py:231: UserWarning: Data has no positive values, and therefore cannot be log-scaled.\n",
      "  ax.set_yscale('log')\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/tmp/ipykernel_3372844/3163328249.py:231: UserWarning: Data has no positive values, and therefore cannot be log-scaled.\n",
      "  ax.set_yscale('log')\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/tmp/ipykernel_3372844/3163328249.py:231: UserWarning: Data has no positive values, and therefore cannot be log-scaled.\n",
      "  ax.set_yscale('log')\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/tmp/ipykernel_3372844/3163328249.py:231: UserWarning: Data has no positive values, and therefore cannot be log-scaled.\n",
      "  ax.set_yscale('log')\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/tmp/ipykernel_3372844/3163328249.py:231: UserWarning: Data has no positive values, and therefore cannot be log-scaled.\n",
      "  ax.set_yscale('log')\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/tmp/ipykernel_3372844/3163328249.py:231: UserWarning: Data has no positive values, and therefore cannot be log-scaled.\n",
      "  ax.set_yscale('log')\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/tmp/ipykernel_3372844/3163328249.py:231: UserWarning: Data has no positive values, and therefore cannot be log-scaled.\n",
      "  ax.set_yscale('log')\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/tmp/ipykernel_3372844/3163328249.py:231: UserWarning: Data has no positive values, and therefore cannot be log-scaled.\n",
      "  ax.set_yscale('log')\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/tmp/ipykernel_3372844/3163328249.py:231: UserWarning: Data has no positive values, and therefore cannot be log-scaled.\n",
      "  ax.set_yscale('log')\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n"
     ]
    }
   ],
   "source": [
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"pre_std\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "label_arr_fold = [\n",
    "    MC_NAMES_PRETTY[\"GluGluToHH\"]+\" train\", MC_NAMES_PRETTY[\"GluGluToHH\"]+\" val\", MC_NAMES_PRETTY[\"GluGluToHH\"]+\" test\",\n",
    "    MC_NAMES_PRETTY[\"ttHToGG\"]+\" train\", MC_NAMES_PRETTY[\"ttHToGG\"]+\" val\", MC_NAMES_PRETTY[\"ttHToGG\"]+\" test\",\n",
    "    # MC_NAMES_PRETTY[\"single-H\"]+\" train\", MC_NAMES_PRETTY[\"single-H\"]+\" val\", MC_NAMES_PRETTY[\"single-H\"]+\" test\",\n",
    "    # MC_NAMES_PRETTY[\"non-res\"]+\" train\", MC_NAMES_PRETTY[\"non-res\"]+\" val\", MC_NAMES_PRETTY[\"non-res\"]+\" test\",\n",
    "    MC_NAMES_PRETTY[\"VH\"]+\" train\", MC_NAMES_PRETTY[\"VH\"]+\" val\", MC_NAMES_PRETTY[\"VH\"]+\" test\",\n",
    "    MC_NAMES_PRETTY[\"non-res + ggFH + VBFH\"]+\" train\", MC_NAMES_PRETTY[\"non-res + ggFH + VBFH\"]+\" val\", MC_NAMES_PRETTY[\"non-res + ggFH + VBFH\"]+\" test\",\n",
    "]\n",
    "# Loop over and plot the per-fold variables\n",
    "for fold_idx in range(len(hlf_vars_columns_dict)):\n",
    "\n",
    "    for var_name in hlf_vars_columns_dict['fold_0']:\n",
    "        if var_name in {'puppiMET_eta'}:\n",
    "            continue\n",
    "\n",
    "        plot_dirpath_ = os.path.join(plot_dirpath, var_name)\n",
    "        if not os.path.exists(plot_dirpath_):\n",
    "            os.makedirs(plot_dirpath_)\n",
    "\n",
    "        train_hists, val_hists, test_hists = {}, {}, {}\n",
    "        for i, sample_name in enumerate(order):\n",
    "            train_mask = xgb_label_train_dict[f'fold_{fold_idx}'] == i\n",
    "            val_mask = xgb_label_val_dict[f'fold_{fold_idx}'] == i\n",
    "            test_mask = xgb_label_test_dict[f'fold_{fold_idx}'] == i\n",
    "\n",
    "            train_np = (\n",
    "                data_df_dict[f'fold_{fold_idx}'].iloc[train_idxs_dict[f'fold_{fold_idx}']]\n",
    "            ).loc[train_mask, var_name].to_numpy()\n",
    "            val_np = (\n",
    "                data_df_dict[f'fold_{fold_idx}'].iloc[val_idxs_dict[f'fold_{fold_idx}']]\n",
    "            ).loc[val_mask, var_name].to_numpy()\n",
    "            test_np = data_test_df_dict[f'fold_{fold_idx}'].loc[test_mask, var_name].to_numpy()\n",
    "\n",
    "            train_hists[sample_name] = hist.Hist(VARIABLES[var_name]).fill(var=train_np)\n",
    "            val_hists[sample_name] = hist.Hist(VARIABLES[var_name]).fill(var=val_np)\n",
    "            test_hists[sample_name] = hist.Hist(VARIABLES[var_name]).fill(var=test_np)\n",
    "    \n",
    "            make_input_plot(\n",
    "                plot_dirpath_, var_name,\n",
    "                [train_hists[sample_name], val_hists[sample_name], test_hists[sample_name]], \n",
    "                fold_idx=fold_idx, labels=label_arr_fold[3*i : 3*(i+1)], plot_prefix=f'train_val_test_{sample_name}_'\n",
    "            )\n",
    "        for j, (plot_type, histdict) in enumerate([('train_', train_hists), ('val_', val_hists), ('test_', test_hists)]):\n",
    "            make_input_plot(\n",
    "                plot_dirpath_, var_name,\n",
    "                [histdict[sample_name] for sample_name in order], \n",
    "                fold_idx=fold_idx, labels=label_arr_fold[j::3], plot_prefix=plot_type\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n"
     ]
    }
   ],
   "source": [
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"post_std\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "label_arr_fold = [\n",
    "    MC_NAMES_PRETTY[\"GluGluToHH\"]+\" train\", MC_NAMES_PRETTY[\"GluGluToHH\"]+\" val\", MC_NAMES_PRETTY[\"GluGluToHH\"]+\" test\",\n",
    "    MC_NAMES_PRETTY[\"ttHToGG\"]+\" train\", MC_NAMES_PRETTY[\"ttHToGG\"]+\" val\", MC_NAMES_PRETTY[\"ttHToGG\"]+\" test\",\n",
    "    # MC_NAMES_PRETTY[\"single-H\"]+\" train\", MC_NAMES_PRETTY[\"single-H\"]+\" val\", MC_NAMES_PRETTY[\"single-H\"]+\" test\",\n",
    "    # MC_NAMES_PRETTY[\"non-res\"]+\" train\", MC_NAMES_PRETTY[\"non-res\"]+\" val\", MC_NAMES_PRETTY[\"non-res\"]+\" test\",\n",
    "    MC_NAMES_PRETTY[\"VH\"]+\" train\", MC_NAMES_PRETTY[\"VH\"]+\" val\", MC_NAMES_PRETTY[\"VH\"]+\" test\",\n",
    "    MC_NAMES_PRETTY[\"non-res + ggFH + VBFH\"]+\" train\", MC_NAMES_PRETTY[\"non-res + ggFH + VBFH\"]+\" val\", MC_NAMES_PRETTY[\"non-res + ggFH + VBFH\"]+\" test\",\n",
    "]\n",
    "# Loop over and plot the per-fold variables\n",
    "for fold_idx in range(len(hlf_vars_columns_dict)):\n",
    "\n",
    "    for var_idx, var_name in enumerate(hlf_vars_columns_dict['fold_0']):\n",
    "        if var_name in {'puppiMET_eta'}:\n",
    "            continue\n",
    "\n",
    "        plot_dirpath_ = os.path.join(plot_dirpath, var_name)\n",
    "        if not os.path.exists(plot_dirpath_):\n",
    "            os.makedirs(plot_dirpath_)\n",
    "\n",
    "        train_hists, val_hists, test_hists = {}, {}, {}\n",
    "        for i, sample_name in enumerate(order):\n",
    "            train_mask = xgb_label_train_dict[f'fold_{fold_idx}'] == i\n",
    "            val_mask = xgb_label_val_dict[f'fold_{fold_idx}'] == i\n",
    "            test_mask = xgb_label_test_dict[f'fold_{fold_idx}'] == i\n",
    "\n",
    "            train_np = train_data_dict[f'fold_{fold_idx}'][train_mask, var_idx]\n",
    "            val_np = val_data_dict[f'fold_{fold_idx}'][val_mask, var_idx]\n",
    "            test_np = data_hlf_test_dict[f'fold_{fold_idx}'][test_mask, var_idx]\n",
    "\n",
    "            train_hists[sample_name] = hist.Hist(VARIABLES_STD[var_name]).fill(var=train_np)\n",
    "            val_hists[sample_name] = hist.Hist(VARIABLES_STD[var_name]).fill(var=val_np)\n",
    "            test_hists[sample_name] = hist.Hist(VARIABLES_STD[var_name]).fill(var=test_np)\n",
    "    \n",
    "            make_input_plot(\n",
    "                plot_dirpath_, var_name,\n",
    "                [train_hists[sample_name], val_hists[sample_name], test_hists[sample_name]], \n",
    "                fold_idx=fold_idx, labels=label_arr_fold[3*i : 3*(i+1)], plot_prefix=f'train_val_test_{sample_name}_'\n",
    "            )\n",
    "        for j, (plot_type, histdict) in enumerate([('train_', train_hists), ('val_', val_hists), ('test_', test_hists)]):\n",
    "            make_input_plot(\n",
    "                plot_dirpath_, var_name,\n",
    "                [histdict[sample_name] for sample_name in order], \n",
    "                fold_idx=fold_idx, labels=label_arr_fold[j::3], plot_prefix=plot_type\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save out new parquets for Yibo to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL_DATA_ON_ALL_FOLDS = True\n",
    "\n",
    "# load and pre-process the data\n",
    "DATA_FILEPATHS_DICT = {\n",
    "    'Data': [\n",
    "        lpc_fileprefix+f\"/Run3_2022preEE_merged_v5/Data_EraC/nominal/*\", \n",
    "        lpc_fileprefix+f\"/Run3_2022preEE_merged_v5/Data_EraD/nominal/*\",\n",
    "        lpc_fileprefix+f\"/Run3_2022postEE_merged_v5/Data_EraE/nominal/*\",\n",
    "        lpc_fileprefix+f\"/Run3_2022postEE_merged_v5/Data_EraF/nominal/*\",\n",
    "        lpc_fileprefix+f\"/Run3_2022postEE_merged_v5/Data_EraG/nominal/*\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "(\n",
    "    NOTHING_IGNORE,\n",
    "    DATA_data_df_dict, DATA_data_test_df_dict, \n",
    "    DATA_data_hlf_dict, DATA_label_dict,\n",
    "    DATA_data_hlf_test_dict, DATA_label_test_dict, \n",
    "    DATA_hlf_vars_columns_dict,\n",
    "    DATA_data_aux_dict, DATA_data_test_aux_dict\n",
    ") = process_data(\n",
    "    DATA_FILEPATHS_DICT, OUTPUT_DIRPATH, order=['Data'], mod_vals=MOD_VALS, k_fold_test=True,\n",
    "    save=False, std_json_dirpath=OUTPUT_DIRPATH\n",
    ")\n",
    "\n",
    "BDT_DATA_preds = []\n",
    "\n",
    "if EVAL_DATA_ON_ALL_FOLDS:\n",
    "\n",
    "    bdt_train_data_dict = xgb.DMatrix(\n",
    "        data=DATA_data_hlf_dict[f\"fold_0\"], label=DATA_label_dict[f\"fold_0\"], \n",
    "        missing=-999.0, feature_names=list(DATA_hlf_vars_columns_dict[f\"fold_0\"])\n",
    "    )\n",
    "    bdt_test_data_dict = xgb.DMatrix(\n",
    "        data=DATA_data_hlf_test_dict[f\"fold_0\"], label=DATA_label_test_dict[f\"fold_0\"], \n",
    "        missing=-999.0, feature_names=list(DATA_hlf_vars_columns_dict[f\"fold_0\"])\n",
    "    )\n",
    "\n",
    "    for fold_idx in range(len(DATA_label_test_dict)):\n",
    "        booster = xgb.Booster(param)\n",
    "        booster.load_model(os.path.join(OUTPUT_DIRPATH, f'{CURRENT_TIME}_BDT_fold{fold_idx}.model'))\n",
    "\n",
    "        BDT_train_preds = booster.predict(\n",
    "            bdt_train_data_dict, \n",
    "            iteration_range=(0, booster.best_iteration+1)\n",
    "        )\n",
    "        BDT_test_preds = booster.predict(\n",
    "            bdt_test_data_dict, \n",
    "            iteration_range=(0, booster.best_iteration+1)\n",
    "        )\n",
    "\n",
    "        BDT_all_preds = np.concatenate([BDT_train_preds, BDT_test_preds])\n",
    "        BDT_all_preds = BDT_all_preds[\n",
    "            np.argsort(\n",
    "                np.concatenate([DATA_data_aux_dict[f\"fold_0\"].loc[:, 'hash'].to_numpy(), DATA_data_test_aux_dict[f\"fold_0\"].loc[:, 'hash'].to_numpy()])\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        if fold_idx == 0:\n",
    "            BDT_DATA_preds = copy.deepcopy(BDT_all_preds)\n",
    "        else:\n",
    "            BDT_DATA_preds += BDT_all_preds\n",
    "\n",
    "            if fold_idx == len(DATA_label_test_dict) - 1:\n",
    "                BDT_DATA_preds = BDT_DATA_preds / len(DATA_label_test_dict)\n",
    "else:\n",
    "\n",
    "    bdt_train_data_dict, bdt_test_data_dict = {}, {}\n",
    "    for fold_idx in range(len(DATA_label_test_dict)):\n",
    "        \n",
    "        bdt_train_data_dict[f\"fold_{fold_idx}\"] = xgb.DMatrix(\n",
    "            data=DATA_data_hlf_dict[f\"fold_{fold_idx}\"], label=DATA_label_dict[f\"fold_{fold_idx}\"], \n",
    "            missing=-999.0, feature_names=list(DATA_hlf_vars_columns_dict[f\"fold_{fold_idx}\"])\n",
    "        )\n",
    "        bdt_test_data_dict[f\"fold_{fold_idx}\"] = xgb.DMatrix(\n",
    "            data=DATA_data_hlf_test_dict[f\"fold_{fold_idx}\"], label=DATA_label_test_dict[f\"fold_{fold_idx}\"], \n",
    "            missing=-999.0, feature_names=list(DATA_hlf_vars_columns_dict[f\"fold_{fold_idx}\"])\n",
    "        )\n",
    "\n",
    "        booster = xgb.Booster(param)\n",
    "        booster.load_model(os.path.join(OUTPUT_DIRPATH, f'{CURRENT_TIME}_BDT_fold{fold_idx}.model'))\n",
    "\n",
    "        BDT_DATA_preds.append(\n",
    "            booster.predict(\n",
    "                bdt_test_data_dict[f\"fold_{fold_idx}\"], \n",
    "                iteration_range=(0, booster.best_iteration+1)\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Plot to show data labels look ok\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "hist_axis = hist.axis.Regular(100, 0., 1., name='var', growth=False, underflow=False, overflow=False)\n",
    "\n",
    "data_hists, data_plot_labels = [], []\n",
    "if not EVAL_DATA_ON_ALL_FOLDS:\n",
    "    \n",
    "    for fold_idx in range(len(BDT_DATA_preds)):\n",
    "\n",
    "        data_hists.append(\n",
    "            hist.Hist(hist_axis, storage='weight').fill(\n",
    "                var=np.array(BDT_DATA_preds[fold_idx])[:, 0],\n",
    "            )\n",
    "        )\n",
    "        data_plot_labels.append(f\"fold {fold_idx}\")\n",
    "else:\n",
    "\n",
    "    data_hists.append(\n",
    "        hist.Hist(hist_axis, storage='weight').fill(\n",
    "            var=np.array(BDT_DATA_preds)[:, 0],\n",
    "        )\n",
    "    )\n",
    "    data_plot_labels.append(f\"sum over folds\")\n",
    "\n",
    "hep.histplot(\n",
    "    data_hists,\n",
    "    alpha=0.5, density=False, histtype='step',\n",
    "    label=data_plot_labels\n",
    ")\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022preEE_merged_v5_MultiBDT_output/GluGluToHH/nominal/GluGluToHH_nominal_MultiBDT_output.parquet\n",
      "============================================================\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022postEE_merged_v5_MultiBDT_output/GluGluToHH/nominal/GluGluToHH_nominal_MultiBDT_output.parquet\n",
      "============================================================\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022preEE_merged_v5_MultiBDT_output/ttHToGG/nominal/ttHToGG_nominal_MultiBDT_output.parquet\n",
      "============================================================\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022postEE_merged_v5_MultiBDT_output/ttHToGG/nominal/ttHToGG_nominal_MultiBDT_output.parquet\n",
      "============================================================\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022preEE_merged_v5_MultiBDT_output/VHToGG/nominal/VHToGG_nominal_MultiBDT_output.parquet\n",
      "============================================================\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022postEE_merged_v5_MultiBDT_output/VHToGG/nominal/VHToGG_nominal_MultiBDT_output.parquet\n",
      "============================================================\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022preEE_merged_v5_MultiBDT_output/GGJets/nominal/GGJets_nominal_MultiBDT_output.parquet\n",
      "============================================================\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022postEE_merged_v5_MultiBDT_output/GGJets/nominal/GGJets_nominal_MultiBDT_output.parquet\n",
      "============================================================\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022preEE_merged_v5_MultiBDT_output/GJetPt20To40/nominal/GJetPt20To40_nominal_MultiBDT_output.parquet\n",
      "============================================================\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022postEE_merged_v5_MultiBDT_output/GJetPt20To40/nominal/GJetPt20To40_nominal_MultiBDT_output.parquet\n",
      "============================================================\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022preEE_merged_v5_MultiBDT_output/GJetPt40/nominal/GJetPt40_nominal_MultiBDT_output.parquet\n",
      "============================================================\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022postEE_merged_v5_MultiBDT_output/GJetPt40/nominal/GJetPt40_nominal_MultiBDT_output.parquet\n",
      "============================================================\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022preEE_merged_v5_MultiBDT_output/GluGluHToGG/nominal/GluGluHToGG_nominal_MultiBDT_output.parquet\n",
      "============================================================\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022postEE_merged_v5_MultiBDT_output/GluGluHToGG/nominal/GluGluHToGG_nominal_MultiBDT_output.parquet\n",
      "============================================================\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022preEE_merged_v5_MultiBDT_output/VBFHToGG/nominal/VBFHToGG_nominal_MultiBDT_output.parquet\n",
      "============================================================\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022postEE_merged_v5_MultiBDT_output/VBFHToGG/nominal/VBFHToGG_nominal_MultiBDT_output.parquet\n",
      "============================================================\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022preEE_merged_v5_MultiBDT_output/Data_EraC/nominal/Data_EraC_nominal_MultiBDT_output.parquet\n",
      "============================================================\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022preEE_merged_v5_MultiBDT_output/Data_EraD/nominal/Data_EraD_nominal_MultiBDT_output.parquet\n",
      "============================================================\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022postEE_merged_v5_MultiBDT_output/Data_EraE/nominal/Data_EraE_nominal_MultiBDT_output.parquet\n",
      "============================================================\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022postEE_merged_v5_MultiBDT_output/Data_EraF/nominal/Data_EraF_nominal_MultiBDT_output.parquet\n",
      "============================================================\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022postEE_merged_v5_MultiBDT_output/Data_EraG/nominal/Data_EraG_nominal_MultiBDT_output.parquet\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# load and pre-process the data\n",
    "DATA_FILEPATHS_DICT = {\n",
    "    'Data': [\n",
    "        lpc_fileprefix+f\"/Run3_2022preEE_merged_v5/Data_EraC/nominal/*\", \n",
    "        lpc_fileprefix+f\"/Run3_2022preEE_merged_v5/Data_EraD/nominal/*\",\n",
    "        lpc_fileprefix+f\"/Run3_2022postEE_merged_v5/Data_EraE/nominal/*\",\n",
    "        lpc_fileprefix+f\"/Run3_2022postEE_merged_v5/Data_EraF/nominal/*\",\n",
    "        lpc_fileprefix+f\"/Run3_2022postEE_merged_v5/Data_EraG/nominal/*\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Sorts the predictions to map the output to the correct event\n",
    "def sorted_preds(preds, data_aux, sample, sorted_preds=False):\n",
    "    if not sorted_preds:\n",
    "        flat_preds = np.concatenate([preds[fold_idx] for fold_idx in range(len(data_aux))])\n",
    "        preds_sort = np.argsort(\n",
    "            np.concatenate([data_aux[f\"fold_{fold_idx}\"].loc[:, 'hash'].to_numpy() for fold_idx in range(len(data_aux))])\n",
    "        )\n",
    "    else:\n",
    "        flat_preds = preds\n",
    "        preds_sort = np.arange(len(flat_preds))\n",
    "\n",
    "    sample_sort = np.argsort(np.argsort(\n",
    "        ak.to_numpy(sample['hash'], allow_missing=False)\n",
    "    ))\n",
    "\n",
    "    return flat_preds[preds_sort][sample_sort]\n",
    "\n",
    "## MC SAMPLES ##\n",
    "# Load parquet files #\n",
    "for i, sample_name in enumerate(order):\n",
    "    for dirpath in FILEPATHS_DICT[sample_name]:\n",
    "        parquet_filepath = glob.glob(dirpath)[0]\n",
    "        sample = ak.from_parquet(parquet_filepath)\n",
    "\n",
    "        (\n",
    "            NOTHING_IGNORE,\n",
    "            IGNORE_data_df_dict, SAMPLE_data_test_df_dict, \n",
    "            IGNORE_data_hlf_dict, IGNORE_label_dict,\n",
    "            SAMPLE_data_hlf_test_dict, SAMPLE_label_test_dict, \n",
    "            SAMPLE_hlf_vars_columns_dict,\n",
    "            IGNORE_data_aux_dict, SAMPLE_data_test_aux_dict\n",
    "        ) = process_data(\n",
    "            {\"sample\": [parquet_filepath]}, OUTPUT_DIRPATH, order=['sample'], mod_vals=MOD_VALS, k_fold_test=True,\n",
    "            save=False, std_json_dirpath=OUTPUT_DIRPATH\n",
    "        )\n",
    "\n",
    "        sample_preds = []\n",
    "        for fold_idx in range(len(SAMPLE_data_test_df_dict)):\n",
    "            booster = xgb.Booster(param)\n",
    "            booster.load_model(os.path.join(OUTPUT_DIRPATH, f'{CURRENT_TIME}_BDT_fold{fold_idx}.model'))\n",
    "\n",
    "            bdt_test_sample_dict = xgb.DMatrix(\n",
    "                data=SAMPLE_data_hlf_test_dict[f\"fold_{fold_idx}\"], label=SAMPLE_label_test_dict[f\"fold_{fold_idx}\"], \n",
    "                missing=-999.0, feature_names=list(SAMPLE_hlf_vars_columns_dict[f\"fold_{fold_idx}\"])\n",
    "            )\n",
    "\n",
    "            sample_preds.append(\n",
    "                booster.predict(\n",
    "                    bdt_test_sample_dict, \n",
    "                    iteration_range=(0, booster.best_iteration+1)\n",
    "                )\n",
    "            )\n",
    "\n",
    "        sample['MultiBDT_output'] = sorted_preds(\n",
    "            sample_preds, SAMPLE_data_test_aux_dict, sample\n",
    "        )\n",
    "\n",
    "        dest_filepath = parquet_filepath[:parquet_filepath.find('v5')+2] + '_MultiBDT_output' + parquet_filepath[parquet_filepath.find('v5')+2:parquet_filepath.rfind('.')] + '_MultiBDT_output' + parquet_filepath[parquet_filepath.rfind('.'):]\n",
    "        if not os.path.exists(dest_filepath[:dest_filepath.rfind('/')]):\n",
    "            os.makedirs(dest_filepath[:dest_filepath.rfind('/')])\n",
    "        print(dest_filepath)\n",
    "        print('='*60)\n",
    "        merged_parquet = ak.to_parquet(sample, dest_filepath)\n",
    "\n",
    "## DATA ##\n",
    "for dirpath in DATA_FILEPATHS_DICT['Data']:\n",
    "    parquet_filepath = glob.glob(dirpath)[0]\n",
    "    data_sample = ak.from_parquet(parquet_filepath)\n",
    "\n",
    "    (\n",
    "        NOTHING_IGNORE,\n",
    "        DATA_data_df_dict, DATA_data_test_df_dict, \n",
    "        DATA_data_hlf_dict, DATA_label_dict,\n",
    "        DATA_data_hlf_test_dict, DATA_label_test_dict, \n",
    "        DATA_hlf_vars_columns_dict,\n",
    "        DATA_data_aux_dict, DATA_data_test_aux_dict\n",
    "    ) = process_data(\n",
    "        {\"sample\": [parquet_filepath]}, OUTPUT_DIRPATH, order=['sample'], mod_vals=MOD_VALS, k_fold_test=True,\n",
    "        save=False, std_json_dirpath=OUTPUT_DIRPATH\n",
    "    )\n",
    "\n",
    "    bdt_train_data_dict = xgb.DMatrix(\n",
    "        data=DATA_data_hlf_dict[f\"fold_0\"], label=DATA_label_dict[f\"fold_0\"], \n",
    "        missing=-999.0, feature_names=list(DATA_hlf_vars_columns_dict[f\"fold_0\"])\n",
    "    )\n",
    "    bdt_test_data_dict = xgb.DMatrix(\n",
    "        data=DATA_data_hlf_test_dict[f\"fold_0\"], label=DATA_label_test_dict[f\"fold_0\"], \n",
    "        missing=-999.0, feature_names=list(DATA_hlf_vars_columns_dict[f\"fold_0\"])\n",
    "    )\n",
    "\n",
    "    for fold_idx in range(len(DATA_label_test_dict)):\n",
    "        booster = xgb.Booster(param)\n",
    "        booster.load_model(os.path.join(OUTPUT_DIRPATH, f'{CURRENT_TIME}_BDT_fold{fold_idx}.model'))\n",
    "\n",
    "        BDT_train_preds = booster.predict(\n",
    "            bdt_train_data_dict, \n",
    "            iteration_range=(0, booster.best_iteration+1)\n",
    "        )\n",
    "        BDT_test_preds = booster.predict(\n",
    "            bdt_test_data_dict, \n",
    "            iteration_range=(0, booster.best_iteration+1)\n",
    "        )\n",
    "\n",
    "        BDT_all_preds = np.concatenate([BDT_train_preds, BDT_test_preds])\n",
    "        BDT_all_preds = BDT_all_preds[\n",
    "            np.argsort(\n",
    "                np.concatenate([DATA_data_aux_dict[f\"fold_0\"].loc[:, 'hash'].to_numpy(), DATA_data_test_aux_dict[f\"fold_0\"].loc[:, 'hash'].to_numpy()])\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        if fold_idx == 0:\n",
    "            data_preds = copy.deepcopy(BDT_all_preds)\n",
    "        else:\n",
    "            data_preds += BDT_all_preds\n",
    "\n",
    "            if fold_idx == len(DATA_label_test_dict) - 1:\n",
    "                data_preds = data_preds / len(DATA_label_test_dict)\n",
    "\n",
    "    data_sample['MultiBDT_output'] = sorted_preds(\n",
    "        data_preds, DATA_data_test_aux_dict, data_sample,\n",
    "        sorted_preds=True\n",
    "    )\n",
    "\n",
    "    dest_filepath = parquet_filepath[:parquet_filepath.find('v5')+2] + '_MultiBDT_output' + parquet_filepath[parquet_filepath.find('v5')+2:parquet_filepath.rfind('.')] + '_MultiBDT_output' + parquet_filepath[parquet_filepath.rfind('.'):]\n",
    "    if not os.path.exists(dest_filepath[:dest_filepath.rfind('/')]):\n",
    "        os.makedirs(dest_filepath[:dest_filepath.rfind('/')])\n",
    "    print(dest_filepath)\n",
    "    print('='*60)\n",
    "    merged_parquet = ak.to_parquet(data_sample, dest_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
