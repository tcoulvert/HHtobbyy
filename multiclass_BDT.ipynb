{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmslpcgpu3.fnal.gov      Sun Apr  6 11:36:40 2025  555.42.06\n",
      "[0] Tesla P100-PCIE-12GB | 40Â°C,   0 % |     2 / 12288 MB |\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib widget\n",
    "# Stdlib packages\n",
    "import copy\n",
    "import datetime\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "# Common Py packages\n",
    "import awkward as ak\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from prettytable import PrettyTable\n",
    "from scipy.special import logit as inverse_sigmoid\n",
    "\n",
    "# HEP packages\n",
    "import gpustat\n",
    "import h5py\n",
    "import hist\n",
    "import mplhep as hep\n",
    "import xgboost as xgb\n",
    "from cycler import cycler\n",
    "\n",
    "# ML packages\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, fbeta_score\n",
    "from scipy.integrate import trapezoid\n",
    "from scipy.optimize import curve_fit\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Integer\n",
    "from skopt.utils import use_named_args\n",
    "\n",
    "# Module packages\n",
    "from data_processing_BDT import process_data\n",
    "\n",
    "gpustat.print_gpustat()\n",
    "\n",
    "plt.style.use(hep.style.CMS)\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "cmap_petroff10 = [\"#3f90da\", \"#ffa90e\", \"#bd1f01\", \"#94a4a2\", \"#832db6\", \"#a96b59\", \"#e76300\", \"#b9ac70\", \"#717581\", \"#92dadd\"]\n",
    "plt.rcParams.update({\"axes.prop_cycle\": cycler(\"color\", cmap_petroff10)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Locations and Model Naming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "lpc_fileprefix = \"/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v2/\"\n",
    "Run3_2022 = 'Run3_2022_merged/sim'\n",
    "Run3_2023 = 'Run3_2023_merged/sim'\n",
    "\n",
    "def get_filepath_dict(syst_name: str='nominal'):\n",
    "    return {\n",
    "        'ggF HH': [\n",
    "            lpc_fileprefix+Run3_2022+f\"/preEE/GluGlutoHHto2B2G_kl_1p00_kt_1p00_c2_0p00/{syst_name}/*merged.parquet\", \n",
    "            lpc_fileprefix+Run3_2022+f\"/postEE/GluGluToHH/{syst_name}/*merged.parquet\",\n",
    "            lpc_fileprefix+Run3_2023+f\"/preBPix/GluGlutoHHto2B2G_kl-1p00_kt-1p00_c2-0p00/{syst_name}/*merged.parquet\", \n",
    "            lpc_fileprefix+Run3_2023+f\"/postBPix/GluGlutoHHto2B2G_kl-1p00_kt-1p00_c2-0p00/{syst_name}/*merged.parquet\"\n",
    "        ],\n",
    "        'ttH + bbH': [\n",
    "            # ttH\n",
    "            lpc_fileprefix+Run3_2022+f\"/preEE/ttHtoGG_M_125/{syst_name}/*merged.parquet\", \n",
    "            lpc_fileprefix+Run3_2022+f\"/postEE/ttHToGG/{syst_name}/*merged.parquet\",\n",
    "            lpc_fileprefix+Run3_2023+f\"/preBPix/ttHtoGG/{syst_name}/*merged.parquet\", \n",
    "            lpc_fileprefix+Run3_2023+f\"/postBPix/ttHtoGG/{syst_name}/*merged.parquet\",\n",
    "            # bbH\n",
    "            lpc_fileprefix+Run3_2022+f\"/preEE/BBHto2G_M_125/{syst_name}/*merged.parquet\", \n",
    "            lpc_fileprefix+Run3_2022+f\"/postEE/BBHto2G_M_125/{syst_name}/*merged.parquet\",\n",
    "            lpc_fileprefix+Run3_2023+f\"/preBPix/bbHtoGG/{syst_name}/*merged.parquet\", \n",
    "            lpc_fileprefix+Run3_2023+f\"/postBPix/bbHtoGG/{syst_name}/*merged.parquet\",\n",
    "        ],\n",
    "        'VH': [\n",
    "            # VH\n",
    "            lpc_fileprefix+Run3_2022+f\"/preEE/VHtoGG_M_125/{syst_name}/*merged.parquet\", \n",
    "            lpc_fileprefix+Run3_2022+f\"/postEE/VHtoGG_M-125/{syst_name}/*merged.parquet\",\n",
    "            lpc_fileprefix+Run3_2023+f\"/preBPix/VHtoGG/{syst_name}/*merged.parquet\", \n",
    "            lpc_fileprefix+Run3_2023+f\"/postBPix/VHtoGG/{syst_name}/*merged.parquet\",\n",
    "            # ZH\n",
    "            lpc_fileprefix+Run3_2022+f\"/preEE/ZH_Hto2G_Zto2Q_M-125/{syst_name}/*merged.parquet\", \n",
    "            lpc_fileprefix+Run3_2022+f\"/postEE/ZH_Hto2G_Zto2Q_M-125/{syst_name}/*merged.parquet\",\n",
    "            # W-H\n",
    "            lpc_fileprefix+Run3_2022+f\"/preEE/WminusH_Hto2G_Wto2Q_M-125/{syst_name}/*merged.parquet\", \n",
    "            lpc_fileprefix+Run3_2022+f\"/postEE/WminusH_Hto2G_Wto2Q_M-125/{syst_name}/*merged.parquet\",\n",
    "            # W+H\n",
    "            lpc_fileprefix+Run3_2022+f\"/preEE/WplusH_Hto2G_Wto2Q_M-125/{syst_name}/*merged.parquet\", \n",
    "            lpc_fileprefix+Run3_2022+f\"/postEE/WplusH_Hto2G_Wto2Q_M-125/{syst_name}/*merged.parquet\",\n",
    "        ],\n",
    "        'non-res + ggFH + VBFH': [\n",
    "            # GG + 3Jets\n",
    "            lpc_fileprefix+Run3_2022+f\"/preEE/GGJets/{syst_name}/*merged.parquet\", \n",
    "            lpc_fileprefix+Run3_2022+f\"/postEE/GGJets/{syst_name}/*merged.parquet\",\n",
    "            lpc_fileprefix+Run3_2023+f\"/preBPix/GGJets/{syst_name}/*merged.parquet\", \n",
    "            lpc_fileprefix+Run3_2023+f\"/postBPix/GGJets/{syst_name}/*merged.parquet\",\n",
    "            # GJet pT 20-40\n",
    "            lpc_fileprefix+Run3_2022+f\"/preEE/GJetPt20To40/{syst_name}/*merged.parquet\", \n",
    "            lpc_fileprefix+Run3_2022+f\"/postEE/GJetPt20To40/{syst_name}/*merged.parquet\",\n",
    "            lpc_fileprefix+Run3_2023+f\"/preBPix/GJetPt20To40/{syst_name}/*merged.parquet\", \n",
    "            lpc_fileprefix+Run3_2023+f\"/postBPix/GJetPt20To40/{syst_name}/*merged.parquet\",\n",
    "            # GJet pT 40-inf\n",
    "            lpc_fileprefix+Run3_2022+f\"/preEE/GJetPt40/{syst_name}/*merged.parquet\", \n",
    "            lpc_fileprefix+Run3_2022+f\"/postEE/GJetPt40/{syst_name}/*merged.parquet\",\n",
    "            lpc_fileprefix+Run3_2023+f\"/preBPix/GJetPt40/{syst_name}/*merged.parquet\", \n",
    "            lpc_fileprefix+Run3_2023+f\"/postBPix/GJetPt40/{syst_name}/*merged.parquet\",\n",
    "            # ggF H\n",
    "            lpc_fileprefix+Run3_2022+f\"/preEE/GluGluHToGG_M_125/{syst_name}/*merged.parquet\", \n",
    "            lpc_fileprefix+Run3_2022+f\"/postEE/GluGluHToGG/{syst_name}/*merged.parquet\",\n",
    "            lpc_fileprefix+Run3_2023+f\"/preBPix/GluGluHtoGG/{syst_name}/*merged.parquet\", \n",
    "            lpc_fileprefix+Run3_2023+f\"/postBPix/GluGluHtoGG/{syst_name}/*merged.parquet\",\n",
    "            # VBF H\n",
    "            lpc_fileprefix+Run3_2022+f\"/preEE/VBFHToGG_M_125/{syst_name}/*merged.parquet\", \n",
    "            lpc_fileprefix+Run3_2022+f\"/postEE/VBFHToGG/{syst_name}/*merged.parquet\",\n",
    "            lpc_fileprefix+Run3_2023+f\"/preBPix/VBFHtoGG/{syst_name}/*merged.parquet\", \n",
    "            lpc_fileprefix+Run3_2023+f\"/postBPix/VBFHtoGG/{syst_name}/*merged.parquet\",\n",
    "        ],\n",
    "    }\n",
    "\n",
    "FILEPATHS_DICT = get_filepath_dict()\n",
    "\n",
    "CURRENT_DIRPATH = str(Path().absolute())\n",
    "MOD_VALS = (5, 5)\n",
    "# VERSION = 'v11'\n",
    "# VARS = 'v2_vars'\n",
    "# CURRENT_TIME = '2025-03-07_21-02-53'\n",
    "# VERSION = 'v11'\n",
    "# VARS = 'v2_vars_mvaID'\n",
    "# CURRENT_TIME = '2025-04-02_02-36-30'\n",
    "# VERSION = 'v12'\n",
    "# VARS = 'v2_vars_22_23'\n",
    "# CURRENT_TIME = '2025-03-31_15-03-45'\n",
    "VERSION = 'v12'\n",
    "VARS = 'v2_vars_mvaIDCorr_22_23'\n",
    "CURRENT_TIME = '2025-04-05_12-04-41'\n",
    "if 'CURRENT_TIME' in globals():\n",
    "    OUTPUT_DIRPATH = os.path.join(CURRENT_DIRPATH, f\"MultiClassBDT_model_outputs/{VERSION}/{VARS}\", CURRENT_TIME)\n",
    "else:\n",
    "    OUTPUT_DIRPATH = os.path.join(CURRENT_DIRPATH, f\"MultiClassBDT_model_outputs/{VERSION}/{VARS}\")\n",
    "\n",
    "if not os.path.exists(OUTPUT_DIRPATH):\n",
    "    os.makedirs(OUTPUT_DIRPATH)\n",
    "\n",
    "OTHER_BKG_RESCALE = 100\n",
    "OPTIMIZE_SPACE = False\n",
    "FORCE_RERUN = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def training_weights(event_weights, labels, order=None, weighttype='rescaled_and_shifted', sig_rescale_factor=None):\n",
    "    if weighttype == 'abs':\n",
    "        return np.abs(event_weights)\n",
    "    \n",
    "    if order is not None:\n",
    "        sig_idx, big_bkg_idx = -1, -1\n",
    "        for i, sample_name in enumerate(order):\n",
    "            if re.search('ggF HH', sample_name) is not None:\n",
    "                sig_idx = i\n",
    "                continue\n",
    "            if re.search('non-res', sample_name) is not None:\n",
    "                big_bkg_idx = i\n",
    "                continue\n",
    "    else:\n",
    "        sig_idx, big_bkg_idx = 0, len(order)-1\n",
    "    \n",
    "    if sig_rescale_factor is None:\n",
    "        sig_sum = np.sum(event_weights[labels[:, sig_idx] == 1])\n",
    "        bkg_sum = np.sum(event_weights[labels[:, sig_idx] == 0])\n",
    "        \n",
    "        sig_rescale_factor = bkg_sum / sig_sum\n",
    "\n",
    "    scaled_weights = np.where(\n",
    "        labels[:, sig_idx] == 0, \n",
    "        np.where(\n",
    "            np.argmax(labels, axis=1) != big_bkg_idx,  \n",
    "            event_weights * OTHER_BKG_RESCALE,  # if not big bkg, rescale\n",
    "            event_weights  # otherwise do nothing\n",
    "        ),\n",
    "        event_weights * sig_rescale_factor  # if sig, rescale to equal sum of all bkgs\n",
    "    )\n",
    "\n",
    "    abs_weights = np.abs(scaled_weights)\n",
    "\n",
    "    if weighttype == 'rescaled':\n",
    "        return abs_weights\n",
    "    elif weighttype == 'rescaled_and_shifted':\n",
    "        mean_weights = np.mean(scaled_weights)\n",
    "        rescaled_weights = abs_weights / mean_weights\n",
    "        return rescaled_weights\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"The only options for weighttype are 'abs', 'rescaled', and 'rescaled_and_shifted'. You provided {weighttype}\"\n",
    "        )\n",
    "\n",
    "# def training_weights(event_weights, labels, order=None, sig_rescale_factor=None):\n",
    "#     if order is None:\n",
    "#         order = [i for v in range(np.shape(labels)[0])]\n",
    "#     sum_dict, max_sum, max_i = {}, 0, 0\n",
    "#     for i, sample_name in enumerate(order):\n",
    "#         sum_dict[i] = np.sum(event_weights[labels[:, i] == 1])\n",
    "#         if np.sum(event_weights[labels[:, i] == 1]) > max_sum:\n",
    "#             max_sum, max_i = np.sum(event_weights[labels[:, i] == 1]), i\n",
    "\n",
    "#     label_i = np.sum(\n",
    "#         np.tile([i for i in range(np.shape(labels)[1])], (np.shape(labels)[0], 1)) * labels,\n",
    "#         axis=1\n",
    "#     )\n",
    "\n",
    "#     weight_factors = []\n",
    "#     for i in range(len(label_i)):\n",
    "#         weight_factors.append(\n",
    "#             max_sum / sum_dict[label_i[i]] if label_i[i] != max_i else 1\n",
    "#         )\n",
    "#     weights = event_weights * np.array(weight_factors)\n",
    "\n",
    "#     mean_weight = np.mean(weights)\n",
    "#     abs_weights = np.abs(weights)\n",
    "#     scaled_weights = abs_weights / mean_weight\n",
    "\n",
    "#     return scaled_weights\n",
    "\n",
    "\n",
    "def xgb_labels(labels):\n",
    "    label_i = np.sum(\n",
    "        np.tile([i for i in range(np.shape(labels)[1])], (np.shape(labels)[0], 1)) * labels,\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    return label_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading and Input Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# order = ['ggF HH', 'ttH', 'single-H', 'non-res']\n",
    "# order = ['ggF HH', 'ttH', 'VH', 'non-res + ggFH + VBFH']\n",
    "order = ['ggF HH', 'ttH + bbH', 'VH', 'non-res + ggFH + VBFH']\n",
    "\n",
    "(\n",
    "    sig_rescale_factor,\n",
    "    data_df_dict, data_test_df_dict, \n",
    "    data_hlf_dict, label_dict,\n",
    "    data_hlf_test_dict, label_test_dict, \n",
    "    hlf_vars_columns_dict,\n",
    "    data_aux_dict, data_test_aux_dict\n",
    ") = process_data(\n",
    "    FILEPATHS_DICT, OUTPUT_DIRPATH, order=order, mod_vals=MOD_VALS,\n",
    "    save=False if 'CURRENT_TIME' in globals() else True,\n",
    "    std_json_dirpath=OUTPUT_DIRPATH if 'CURRENT_TIME' in globals() else None,\n",
    "    other_bkg_rescale=OTHER_BKG_RESCALE\n",
    ")\n",
    "\n",
    "# Make xgb-like labels (NOT one-hot encoded, but integer encoded for each class)\n",
    "xgb_label_dict = {\n",
    "    f\"fold_{fold_idx}\": copy.deepcopy(xgb_labels(label_dict[f\"fold_{fold_idx}\"])) for fold_idx in range(len(data_test_aux_dict))\n",
    "}\n",
    "xgb_label_test_dict = {\n",
    "    f\"fold_{fold_idx}\": copy.deepcopy(xgb_labels(label_test_dict[f\"fold_{fold_idx}\"])) for fold_idx in range(len(data_test_aux_dict))\n",
    "}\n",
    "\n",
    "# Make weight dicts:\n",
    "#   - the top two are with the training rescale (i.e. rescale sig eventWeight to match bkg and then shift for gradients)\n",
    "#   - the bottom two are the standard eventWeights (i.e. xs * lumi * genWeight) for proper plotting\n",
    "weight_train_dict = {\n",
    "    f\"fold_{fold_idx}\": copy.deepcopy(training_weights(data_aux_dict[f'fold_{fold_idx}'].loc[:, \"eventWeight\"].to_numpy(), label_dict[f'fold_{fold_idx}'], order=order, sig_rescale_factor=sig_rescale_factor)) for fold_idx in range(len(data_aux_dict))\n",
    "}\n",
    "weight_test_dict = {\n",
    "    f'fold_{fold_idx}': copy.deepcopy(training_weights(data_test_aux_dict[f'fold_{fold_idx}'].loc[:, \"eventWeight\"].to_numpy(), label_test_dict[f'fold_{fold_idx}'], order=order, sig_rescale_factor=sig_rescale_factor)) for fold_idx in range(len(data_test_aux_dict))\n",
    "}\n",
    "weights_plot_train_dict = {\n",
    "    f\"fold_{fold_idx}\": copy.deepcopy(data_aux_dict[f'fold_{fold_idx}'].loc[:, \"eventWeight\"].to_numpy()) for fold_idx in range(len(data_aux_dict))\n",
    "}\n",
    "weights_plot_test = {\n",
    "    f'fold_{fold_idx}': copy.deepcopy(data_test_aux_dict[f'fold_{fold_idx}'].loc[:, \"eventWeight\"].to_numpy()) for fold_idx in range(len(data_test_aux_dict))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "Num train: 4152583 -> 201286 sig & 337266 ttH bkg & 100840 single-H bkg & 3513191 non-res bkg\n",
      "Num val: 1038146 -> 50283 sig & 84206 ttH bkg & 25461 single-H bkg & 878196 non-res bkg\n",
      "Num test: 1299637 -> 62969 sig & 105417 ttH bkg & 31518 single-H bkg & & 1099733 non-res bkg\n",
      "============================================================\n",
      "fold 1\n",
      "Num train: 4154899 -> 201069 sig & 337473 ttH bkg & 101323 single-H bkg & 3515034 non-res bkg\n",
      "Num val: 1038725 -> 50615 sig & 84244 ttH bkg & 24996 single-H bkg & 878870 non-res bkg\n",
      "Num test: 1296742 -> 62854 sig & 105172 ttH bkg & 31500 single-H bkg & & 1097216 non-res bkg\n",
      "============================================================\n",
      "fold 2\n",
      "Num train: 4152710 -> 201254 sig & 336488 ttH bkg & 100753 single-H bkg & 3514215 non-res bkg\n",
      "Num val: 1038178 -> 50193 sig & 84437 ttH bkg & 25396 single-H bkg & 878152 non-res bkg\n",
      "Num test: 1299478 -> 63091 sig & 105964 ttH bkg & 31670 single-H bkg & & 1098753 non-res bkg\n",
      "============================================================\n",
      "fold 3\n",
      "Num train: 4155336 -> 201480 sig & 337439 ttH bkg & 100862 single-H bkg & 3515555 non-res bkg\n",
      "Num val: 1038834 -> 50255 sig & 84263 ttH bkg & 25340 single-H bkg & 878976 non-res bkg\n",
      "Num test: 1296196 -> 62803 sig & 105187 ttH bkg & 31617 single-H bkg & & 1096589 non-res bkg\n",
      "============================================================\n",
      "fold 4\n",
      "Num train: 4153642 -> 201337 sig & 337800 ttH bkg & 101186 single-H bkg & 3513319 non-res bkg\n",
      "Num val: 1038411 -> 50380 sig & 83940 ttH bkg & 25119 single-H bkg & 878972 non-res bkg\n",
      "Num test: 1298313 -> 62821 sig & 105149 ttH bkg & 31514 single-H bkg & & 1098829 non-res bkg\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "bdt_train_dict, bdt_val_dict, bdt_test_dict = {}, {}, {}\n",
    "\n",
    "train_data_dict, val_data_dict = {}, {}\n",
    "xgb_label_train_dict, xgb_label_val_dict = {}, {}\n",
    "weights_plot_train, weights_plot_val= {}, {}\n",
    "train_idxs_dict, val_idxs_dict = {}, {}\n",
    "for fold_idx in range(len(data_df_dict)):\n",
    "    if re.search('no_std', VARS) is not None:\n",
    "        print('no standardization')\n",
    "        train_val_data_dict = {key: value.to_numpy() for key, value in data_df_dict.items()}\n",
    "        test_data_dict = {key: value.to_numpy() for key, value in data_test_df_dict.items()}\n",
    "    else:\n",
    "        train_val_data_dict = data_hlf_dict\n",
    "        test_data_dict = data_hlf_test_dict\n",
    "    (\n",
    "        X_train, X_val, \n",
    "        y_train, y_val, \n",
    "        weight_train, weight_val, \n",
    "        weight_plot_train, weight_plot_val,\n",
    "        train_idxs, val_idxs\n",
    "    ) = train_test_split(\n",
    "        train_val_data_dict[f\"fold_{fold_idx}\"], xgb_label_dict[f\"fold_{fold_idx}\"], \n",
    "        weight_train_dict[f\"fold_{fold_idx}\"], weights_plot_train_dict[f\"fold_{fold_idx}\"],\n",
    "        range(len(train_val_data_dict[f\"fold_{fold_idx}\"])),\n",
    "        test_size=0.2, random_state=21\n",
    "    )\n",
    "\n",
    "    train_data_dict[f\"fold_{fold_idx}\"] = copy.deepcopy(X_train)\n",
    "    val_data_dict[f\"fold_{fold_idx}\"] = copy.deepcopy(X_val)\n",
    "\n",
    "    xgb_label_train_dict[f\"fold_{fold_idx}\"] = copy.deepcopy(y_train)\n",
    "    xgb_label_val_dict[f\"fold_{fold_idx}\"] = copy.deepcopy(y_val)\n",
    "\n",
    "    weights_plot_train[f\"fold_{fold_idx}\"] = copy.deepcopy(weight_plot_train)\n",
    "    weights_plot_val[f\"fold_{fold_idx}\"] = copy.deepcopy(weight_plot_val)\n",
    "\n",
    "    train_idxs_dict[f\"fold_{fold_idx}\"] = copy.deepcopy(train_idxs)\n",
    "    val_idxs_dict[f\"fold_{fold_idx}\"] = copy.deepcopy(val_idxs)\n",
    "\n",
    "    bdt_train_dict[f\"fold_{fold_idx}\"] = xgb.DMatrix(\n",
    "        data=X_train, label=y_train, \n",
    "        weight=weight_train,\n",
    "        missing=-999.0, feature_names=list(hlf_vars_columns_dict[f\"fold_{fold_idx}\"])\n",
    "    )\n",
    "    bdt_val_dict[f\"fold_{fold_idx}\"] = xgb.DMatrix(\n",
    "        data=X_val, label=y_val, \n",
    "        weight=weight_val,\n",
    "        missing=-999.0, feature_names=list(hlf_vars_columns_dict[f\"fold_{fold_idx}\"])\n",
    "    )\n",
    "    \n",
    "    bdt_test_dict[f\"fold_{fold_idx}\"] = xgb.DMatrix(\n",
    "        data=test_data_dict[f\"fold_{fold_idx}\"], label=xgb_label_test_dict[f\"fold_{fold_idx}\"], \n",
    "        weight=np.abs(weight_test_dict[f\"fold_{fold_idx}\"]),\n",
    "        missing=-999.0, feature_names=list(hlf_vars_columns_dict[f\"fold_{fold_idx}\"])\n",
    "    )\n",
    "\n",
    "    print(f\"fold {fold_idx}\")\n",
    "    print(f\"Num train: {len(y_train)} -> {sum(y_train == 0)} sig & {sum(y_train == 1)} ttH bkg & {sum(y_train == 2)} single-H bkg & {sum(y_train == 3)} non-res bkg\")\n",
    "    print(f\"Num val: {len(y_val)} -> {sum(y_val == 0)} sig & {sum(y_val == 1)} ttH bkg & {sum(y_val == 2)} single-H bkg & {sum(y_val == 3)} non-res bkg\")\n",
    "    print(f\"Num test: {len(label_test_dict[f'fold_{fold_idx}'])} -> {sum(label_test_dict[f'fold_{fold_idx}'] == np.array([1, 0, 0, 0]))[0]} sig & {sum(label_test_dict[f'fold_{fold_idx}'] == np.array([0, 1, 0, 0]))[1]} ttH bkg & {sum(label_test_dict[f'fold_{fold_idx}'] == np.array([0, 0, 1, 0]))[2]} single-H bkg & & {sum(label_test_dict[f'fold_{fold_idx}'] == np.array([0, 0, 0, 1]))[3]} non-res bkg\")\n",
    "    print('='*60)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Parameterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/57986259/multiclass-classification-with-xgboost-classifier\n",
    "# https://forecastegy.com/posts/xgboost-multiclass-classification-python/\n",
    "# https://indico.cern.ch/event/915265/contributions/3848138/attachments/2048174/3432202/kunlinRan_bbyy_20200531.pdf\n",
    "\n",
    "# https://xgboost.readthedocs.io/en/stable/tutorials/intercept.html - for looking at logits level BDT output\n",
    "# https://indico.cern.ch/event/915265/contributions/3848138/attachments/2048174/3432202/kunlinRan_bbyy_20200531.pdf - ATLAS HHbbgg BDT\n",
    "\n",
    "param = {}\n",
    "\n",
    "# Booster parameters #\n",
    "\n",
    "# v11 #\n",
    "# param['eta']              = 0.05 # learning rate\n",
    "# num_trees = round(25 / param['eta'])  # number of trees to make\n",
    "# param['max_depth']        = 10  # maximum depth of a tree\n",
    "# param['subsample']        = 0.6 # fraction of events to train tree on\n",
    "# param['colsample_bytree'] = 0.6 # fraction of features to train tree on\n",
    "# param['num_class']        = len(order) # num classes for multi-class training\n",
    "\n",
    "# v12 #\n",
    "param['eta']              = 0.05 # learning rate\n",
    "num_trees = round(25 / param['eta'])  # number of trees to make\n",
    "param['max_depth']        = 10  # maximum depth of a tree\n",
    "param['subsample']        = 0.2 # fraction of events to train tree on\n",
    "param['colsample_bytree'] = 0.6 # fraction of features to train tree on\n",
    "param['num_class']        = len(order) # num classes for multi-class training\n",
    "param['device']           = 'cuda'\n",
    "param['tree_method']      = 'gpu_hist'\n",
    "param['max_bin']          = 500\n",
    "param['grow_policy']      = 'lossguide'\n",
    "param['sampling_method']  = 'gradient_based'\n",
    "param['min_child_weight'] = 0.25\n",
    "\n",
    "\n",
    "# Learning task parameters\n",
    "param['objective']   = 'multi:softprob'   # objective function\n",
    "param['eval_metric'] = 'merror'           # evaluation metric for cross validation\n",
    "param = list(param.items()) + [('eval_metric', 'mlogloss')]\n",
    "# param[\"disable_default_eval_metric\"] = True\n",
    "# param = list(param.items())\n",
    "\n",
    "\n",
    "def thresholded_weighted_merror(predt: np.ndarray, dtrain: xgb.DMatrix, threshold=0.95):\n",
    "    \"\"\"Used when there's no custom objective.\"\"\"\n",
    "    # No need to do transform, XGBoost handles it internally.\n",
    "    weights = dtrain.get_weight()\n",
    "    thresh_weight_merror = np.where(\n",
    "        np.logical_and(\n",
    "            np.max(predt, axis=1) >= threshold,\n",
    "            np.argmax(predt, axis=1) == dtrain.get_label()\n",
    "        ),\n",
    "        0,\n",
    "        weights\n",
    "    )\n",
    "    return f'WeightedMError@{threshold:.2f}', np.sum(thresh_weight_merror)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def init_param_dict(static_params_dict):\n",
    "    param = {}\n",
    "    # Booster parameters\n",
    "    param['eta']              = 0.1 # learning rate\n",
    "    param['subsample']        = 0.5 # fraction of events to train tree on\n",
    "    param['colsample_bytree'] = 0.8 # fraction of features to train tree on\n",
    "    param['num_class']        = len(order) # num classes for multi-class training\n",
    "    param['min_child_weight'] = 1.0\n",
    "    param['tree_method']      = 'hist'\n",
    "    param['max_bin']          = 500\n",
    "    param['grow_policy']      = 'lossguide'\n",
    "    # Learning task parameters\n",
    "    param['objective']   = 'multi:softprob'   # objective function\n",
    "    param['eval_metric'] = 'mlogloss'           # evaluation metric for cross validation\n",
    "\n",
    "    if static_params_dict is not None:\n",
    "        for key, value in static_params_dict.items():\n",
    "            param[key] = value\n",
    "\n",
    "    return param, round(25 / param['eta'])  # number of trees to make\n",
    "\n",
    "def optimize_hyperparams(\n",
    "    dtrain_dict: dict, dval_dict: dict, param_filepath: str, verbose: bool=False, verbose_eval: bool=False, start_point: int=0,\n",
    "    static_params_dict: dict=None\n",
    "):\n",
    "    # order and grouping of optimization taken from: \n",
    "    #   https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/#:~:text=min_child_weight%20%3D%201%3A%20A%20smaller%20value,%2C%20anyways%2C%20be%20tuned%20later.\n",
    "    rng = np.random.default_rng()\n",
    "    param, num_trees = init_param_dict(static_params_dict)\n",
    "    print(\"Baseline parameters: {}\".format(param))\n",
    "\n",
    "    score_arrs = {\n",
    "        'max_depth_and_min_child_weight': list(),\n",
    "        'min_split_loss': list(),\n",
    "        'subsample_and_colsample_bytree': list(),\n",
    "        'reg_lambda': list(),\n",
    "        'eta': list()\n",
    "    }\n",
    "\n",
    "## max_depth and min_child_weight ##\n",
    "    max_depth_and_min_child_weight_space  = [\n",
    "        Integer(3, 10, \"uniform\", name='max_depth'),\n",
    "        Real(0.1, 10., \"log-uniform\", name='min_child_weight'),\n",
    "    ]\n",
    "    if 'max_depth' in static_params_dict.keys() and 'min_child_weight' in static_params_dict.keys():\n",
    "        max_depth_and_min_child_weight_space = []\n",
    "    elif 'max_depth' in static_params_dict.keys():\n",
    "        max_depth_and_min_child_weight_space  = [\n",
    "            Real(0.1, 10., \"log-uniform\", name='min_child_weight'),\n",
    "        ]\n",
    "    elif 'min_child_weight' in static_params_dict.keys():\n",
    "        max_depth_and_min_child_weight_space  = [\n",
    "            Integer(3, 10, \"uniform\", name='max_depth'),\n",
    "        ]\n",
    "    @use_named_args(max_depth_and_min_child_weight_space)\n",
    "    def max_depth_and_min_child_weight_objective(**X):\n",
    "        if verbose:\n",
    "            print(\"New configuration: {}\".format(X))\n",
    "\n",
    "        for key, val in X.items():\n",
    "            param[key] = val\n",
    "\n",
    "        # randomly sample a fold to evaluate\n",
    "        fold_idx = rng.integers(0, 4)\n",
    "\n",
    "        evallist = [(dtrain_dict[f\"fold_{fold_idx}\"], 'train'), (dval_dict[f\"fold_{fold_idx}\"], 'val')]\n",
    "        booster = xgb.train(\n",
    "            param, dtrain_dict[f\"fold_{fold_idx}\"], num_boost_round=num_trees, \n",
    "            evals=evallist, early_stopping_rounds=10, verbose_eval=verbose_eval,\n",
    "        )\n",
    "\n",
    "        eval_str = booster.eval(dval_dict[f\"fold_{fold_idx}\"], name='val', iteration=booster.best_iteration)\n",
    "\n",
    "        best_mlogloss = float(eval_str[eval_str.find('val-mlogloss:')+len('val-mlogloss:'):])\n",
    "        score_arrs['max_depth_and_min_child_weight'].append(best_mlogloss)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Best val. mlogloss on fold{fold_idx} = {best_mlogloss}\")\n",
    "\n",
    "        return -best_mlogloss\n",
    "    \n",
    "    if start_point == 0 and len(max_depth_and_min_child_weight_space) > 0:\n",
    "        print(\"Optimizing max_depth (max depth of tree) and min_child_weight (min sum of weights in final nodes)\")\n",
    "        result_max_depth_and_min_child_weight = gp_minimize(\n",
    "            max_depth_and_min_child_weight_objective, max_depth_and_min_child_weight_space,\n",
    "            n_calls=10, n_points=1\n",
    "        )\n",
    "\n",
    "        if len(max_depth_and_min_child_weight_space) == 2:\n",
    "            param['max_depth'] = int(result_max_depth_and_min_child_weight.x[0])\n",
    "            param['min_child_weight'] = float(result_max_depth_and_min_child_weight.x[1])\n",
    "        elif 'max_depth' not in static_params_dict.keys():\n",
    "            param['max_depth'] = int(result_max_depth_and_min_child_weight.x[0])\n",
    "        elif 'min_child_weight' not in static_params_dict.keys():\n",
    "            param['min_child_weight'] = int(result_max_depth_and_min_child_weight.x[0])\n",
    "\n",
    "        print(f\"Best max_depth = {param['max_depth']} and min_child_weight = {param['min_child_weight']}\")\n",
    "\n",
    "        with open(param_filepath, 'w') as f:\n",
    "            json.dump(param, f)\n",
    "\n",
    "## min_split_loss ##\n",
    "    min_split_loss_space  = [\n",
    "        Real(0.0, 0.5, \"uniform\", name='min_split_loss'),\n",
    "    ]\n",
    "    @use_named_args(min_split_loss_space)\n",
    "    def min_split_loss_objective(**X):\n",
    "        if verbose:\n",
    "            print(\"New configuration: {}\".format(X))\n",
    "\n",
    "        for key, val in X.items():\n",
    "            param[key] = val\n",
    "\n",
    "        # randomly sample a fold to evaluate\n",
    "        fold_idx = rng.integers(0, 4)\n",
    "\n",
    "        evallist = [(dtrain_dict[f\"fold_{fold_idx}\"], 'train'), (dval_dict[f\"fold_{fold_idx}\"], 'val')]\n",
    "        booster = xgb.train(\n",
    "            param, dtrain_dict[f\"fold_{fold_idx}\"], num_boost_round=num_trees, \n",
    "            evals=evallist, early_stopping_rounds=10, verbose_eval=verbose_eval,\n",
    "        )\n",
    "\n",
    "        eval_str = booster.eval(dval_dict[f\"fold_{fold_idx}\"], name='val', iteration=booster.best_iteration)\n",
    "\n",
    "        best_mlogloss = float(eval_str[eval_str.find('val-mlogloss:')+len('val-mlogloss:'):])\n",
    "        score_arrs['min_split_loss'].append(best_mlogloss)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Best val. mlogloss on fold{fold_idx} = {best_mlogloss}\")\n",
    "\n",
    "        return -best_mlogloss\n",
    "\n",
    "    if start_point <= 1 and 'min_split_loss' not in static_params_dict.keys():\n",
    "        if start_point > 0:\n",
    "            with open(param_filepath, 'r') as f:\n",
    "                param = json.load(f)\n",
    "            \n",
    "        print(\"Optimizing min_split_loss (min loss change to add leaf)\")\n",
    "        result_min_split_loss = gp_minimize(min_split_loss_objective, min_split_loss_space)\n",
    "        param['min_split_loss'] = float(result_min_split_loss.x[0])\n",
    "        print(f\"Best min_split_loss = {param['min_split_loss']}\")\n",
    "\n",
    "        with open(param_filepath, 'w') as f:\n",
    "            json.dump(param, f)\n",
    "\n",
    "## subsample and colsample_by_tree ##\n",
    "    subsample_and_colsample_bytree_space  = [\n",
    "        Real(0.3, 0.6, \"log-uniform\", name='subsample'),\n",
    "        Real(0.3, 0.9, \"uniform\", name='colsample_bytree'),\n",
    "    ]\n",
    "    @use_named_args(subsample_and_colsample_bytree_space)\n",
    "    def subsample_and_colsample_bytree_objective(**X):\n",
    "        if verbose:\n",
    "            print(\"New configuration: {}\".format(X))\n",
    "\n",
    "        for key, val in X.items():\n",
    "            param[key] = val\n",
    "\n",
    "        # randomly sample a fold to evaluate\n",
    "        fold_idx = rng.integers(0, 4)\n",
    "\n",
    "        evallist = [(dtrain_dict[f\"fold_{fold_idx}\"], 'train'), (dval_dict[f\"fold_{fold_idx}\"], 'val')]\n",
    "        booster = xgb.train(\n",
    "            param, dtrain_dict[f\"fold_{fold_idx}\"], num_boost_round=num_trees, \n",
    "            evals=evallist, early_stopping_rounds=10, verbose_eval=verbose_eval,\n",
    "        )\n",
    "\n",
    "        eval_str = booster.eval(dval_dict[f\"fold_{fold_idx}\"], name='val', iteration=booster.best_iteration)\n",
    "\n",
    "        best_mlogloss = float(eval_str[eval_str.find('val-mlogloss:')+len('val-mlogloss:'):])\n",
    "        score_arrs['subsample_and_colsample_bytree'].append(best_mlogloss)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Best val. mlogloss on fold{fold_idx} = {best_mlogloss}\")\n",
    "\n",
    "        return -best_mlogloss\n",
    "\n",
    "    if start_point <= 2:\n",
    "        if start_point > 0:\n",
    "            with open(param_filepath, 'r') as f:\n",
    "                param = json.load(f)\n",
    "                \n",
    "        print(\"Optimizing subsample (fraction of training events) and colsample_bytree (fraction of training features per tree)\")\n",
    "        result_subsample_and_colsample_bytree = gp_minimize(subsample_and_colsample_bytree_objective, subsample_and_colsample_bytree_space)\n",
    "        param['subsample'] = float(result_subsample_and_colsample_bytree.x[0])\n",
    "        param['colsample_bytree'] = float(result_subsample_and_colsample_bytree.x[1])\n",
    "        print(f\"Best subsample = {param['subsample']} and colsample_bytree = {param['colsample_bytree']}\")\n",
    "\n",
    "        with open(param_filepath, 'w') as f:\n",
    "            json.dump(param, f)\n",
    "        \n",
    "\n",
    "## reg_lambda ##\n",
    "    reg_lambda_space  = [\n",
    "        Real(0.001, 0.1, \"log-uniform\", name='reg_lambda'),\n",
    "    ]\n",
    "    @use_named_args(reg_lambda_space)\n",
    "    def reg_lambda_objective(**X):\n",
    "        if verbose:\n",
    "            print(\"New configuration: {}\".format(X))\n",
    "\n",
    "        for key, val in X.items():\n",
    "            param[key] = val\n",
    "\n",
    "        # randomly sample a fold to evaluate\n",
    "        fold_idx = rng.integers(0, 4)\n",
    "\n",
    "        evallist = [(dtrain_dict[f\"fold_{fold_idx}\"], 'train'), (dval_dict[f\"fold_{fold_idx}\"], 'val')]\n",
    "        booster = xgb.train(\n",
    "            param, dtrain_dict[f\"fold_{fold_idx}\"], num_boost_round=num_trees, \n",
    "            evals=evallist, early_stopping_rounds=10, verbose_eval=verbose_eval,\n",
    "        )\n",
    "\n",
    "        eval_str = booster.eval(dval_dict[f\"fold_{fold_idx}\"], name='val', iteration=booster.best_iteration)\n",
    "\n",
    "        best_mlogloss = float(eval_str[eval_str.find('val-mlogloss:')+len('val-mlogloss:'):])\n",
    "        score_arrs['reg_lambda'].append(best_mlogloss)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Best val. mlogloss on fold{fold_idx} = {best_mlogloss}\")\n",
    "\n",
    "        return -best_mlogloss\n",
    "\n",
    "    if start_point <= 3:\n",
    "        if start_point > 0:\n",
    "            with open(param_filepath, 'r') as f:\n",
    "                param = json.load(f)\n",
    "\n",
    "        print(\"Optimizing reg_lambda (L2 reg)\")\n",
    "        result_reg_lambda = gp_minimize(reg_lambda_objective, reg_lambda_space)\n",
    "        param['reg_lambda'] = float(result_reg_lambda.x[0])\n",
    "        print(f\"Best reg_lambda = {param['reg_lambda']}\")\n",
    "\n",
    "        with open(param_filepath, 'w') as f:\n",
    "            json.dump(param, f)\n",
    "\n",
    "## eta ##\n",
    "    eta_space  = [\n",
    "        Real(0.01, 0.3, \"log-uniform\", name='eta'),\n",
    "    ]\n",
    "    @use_named_args(eta_space)\n",
    "    def eta_objective(**X):\n",
    "        if verbose:\n",
    "            print(\"New configuration: {}\".format(X))\n",
    "\n",
    "        for key, val in X.items():\n",
    "            param[key] = val\n",
    "        num_trees = round(25 / X['eta'])  # number of trees to make\n",
    "\n",
    "        # randomly sample a fold to evaluate\n",
    "        fold_idx = rng.integers(0, 4)\n",
    "\n",
    "        evallist = [(dtrain_dict[f\"fold_{fold_idx}\"], 'train'), (dval_dict[f\"fold_{fold_idx}\"], 'val')]\n",
    "        booster = xgb.train(\n",
    "            param, dtrain_dict[f\"fold_{fold_idx}\"], num_boost_round=num_trees, \n",
    "            evals=evallist, early_stopping_rounds=10, verbose_eval=verbose_eval,\n",
    "        )\n",
    "\n",
    "        eval_str = booster.eval(dval_dict[f\"fold_{fold_idx}\"], name='val', iteration=booster.best_iteration)\n",
    "\n",
    "        best_mlogloss = float(eval_str[eval_str.find('val-mlogloss:')+len('val-mlogloss:'):])\n",
    "        score_arrs['eta'].append(best_mlogloss)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Best val. mlogloss on fold{fold_idx} = {best_mlogloss}\")\n",
    "\n",
    "        return -best_mlogloss\n",
    "\n",
    "    if start_point <= 4:\n",
    "        if start_point > 0:\n",
    "            with open(param_filepath, 'r') as f:\n",
    "                param = json.load(f)\n",
    "                \n",
    "        print(\"Optimizing eta (step size)\")\n",
    "        result_eta = gp_minimize(eta_objective, eta_space)\n",
    "        param['eta'] = float(result_eta.x[0])\n",
    "        print(f\"Best eta = {param['eta']}\")\n",
    "\n",
    "        with open(param_filepath, 'w') as f:\n",
    "            json.dump(param, f)\n",
    "\n",
    "    print(\"Best parameters: {}\".format(param))\n",
    "    \n",
    "    return param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "[12:04:42] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-merror:0.09409\ttrain-mlogloss:1.30824\ttest-merror:0.10357\ttest-mlogloss:1.30919\tval-merror:0.10487\tval-mlogloss:1.30930\n",
      "[25]\ttrain-merror:0.08353\ttrain-mlogloss:0.51681\ttest-merror:0.09551\ttest-mlogloss:0.53417\tval-merror:0.09538\tval-mlogloss:0.53513\n",
      "[50]\ttrain-merror:0.07850\ttrain-mlogloss:0.32598\ttest-merror:0.09264\ttest-mlogloss:0.35385\tval-merror:0.09248\tval-mlogloss:0.35543\n",
      "[75]\ttrain-merror:0.07418\ttrain-mlogloss:0.26307\ttest-merror:0.09090\ttest-mlogloss:0.30076\tval-merror:0.09085\tval-mlogloss:0.30254\n",
      "[100]\ttrain-merror:0.07087\ttrain-mlogloss:0.23535\ttest-merror:0.08990\ttest-mlogloss:0.28204\tval-merror:0.08977\tval-mlogloss:0.28377\n",
      "[125]\ttrain-merror:0.06789\ttrain-mlogloss:0.21939\ttest-merror:0.08936\ttest-mlogloss:0.27416\tval-merror:0.08881\tval-mlogloss:0.27584\n",
      "[150]\ttrain-merror:0.06507\ttrain-mlogloss:0.20813\ttest-merror:0.08888\ttest-mlogloss:0.27030\tval-merror:0.08865\tval-mlogloss:0.27176\n",
      "[175]\ttrain-merror:0.06296\ttrain-mlogloss:0.19980\ttest-merror:0.08895\ttest-mlogloss:0.26822\tval-merror:0.08864\tval-mlogloss:0.26964\n",
      "[200]\ttrain-merror:0.06098\ttrain-mlogloss:0.19269\ttest-merror:0.08878\ttest-mlogloss:0.26700\tval-merror:0.08867\tval-mlogloss:0.26833\n",
      "[225]\ttrain-merror:0.05919\ttrain-mlogloss:0.18713\ttest-merror:0.08873\ttest-mlogloss:0.26619\tval-merror:0.08866\tval-mlogloss:0.26746\n",
      "[250]\ttrain-merror:0.05764\ttrain-mlogloss:0.18222\ttest-merror:0.08875\ttest-mlogloss:0.26565\tval-merror:0.08841\tval-mlogloss:0.26688\n",
      "[275]\ttrain-merror:0.05589\ttrain-mlogloss:0.17738\ttest-merror:0.08880\ttest-mlogloss:0.26539\tval-merror:0.08844\tval-mlogloss:0.26661\n",
      "[297]\ttrain-merror:0.05450\ttrain-mlogloss:0.17330\ttest-merror:0.08901\ttest-mlogloss:0.26528\tval-merror:0.08829\tval-mlogloss:0.26647\n",
      "[288]\ttest-merror:0.088958\ttest-mlogloss:0.265289\n",
      "====================================================================================================\n",
      "fold 1\n",
      "[12:08:51] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-merror:0.09357\ttrain-mlogloss:1.30824\ttest-merror:0.10495\ttest-mlogloss:1.30928\tval-merror:0.10525\tval-mlogloss:1.30927\n",
      "[25]\ttrain-merror:0.08297\ttrain-mlogloss:0.51622\ttest-merror:0.09724\ttest-mlogloss:0.53528\tval-merror:0.09549\tval-mlogloss:0.53383\n",
      "[50]\ttrain-merror:0.07766\ttrain-mlogloss:0.32533\ttest-merror:0.09377\ttest-mlogloss:0.35577\tval-merror:0.09241\tval-mlogloss:0.35354\n",
      "[75]\ttrain-merror:0.07348\ttrain-mlogloss:0.26240\ttest-merror:0.09206\ttest-mlogloss:0.30313\tval-merror:0.09081\tval-mlogloss:0.30036\n",
      "[100]\ttrain-merror:0.07018\ttrain-mlogloss:0.23475\ttest-merror:0.09124\ttest-mlogloss:0.28447\tval-merror:0.08969\tval-mlogloss:0.28153\n",
      "[125]\ttrain-merror:0.06745\ttrain-mlogloss:0.21901\ttest-merror:0.09061\ttest-mlogloss:0.27665\tval-merror:0.08926\tval-mlogloss:0.27352\n",
      "[150]\ttrain-merror:0.06498\ttrain-mlogloss:0.20793\ttest-merror:0.08990\ttest-mlogloss:0.27255\tval-merror:0.08886\tval-mlogloss:0.26933\n",
      "[175]\ttrain-merror:0.06270\ttrain-mlogloss:0.19947\ttest-merror:0.08994\ttest-mlogloss:0.27051\tval-merror:0.08904\tval-mlogloss:0.26722\n",
      "[200]\ttrain-merror:0.06075\ttrain-mlogloss:0.19243\ttest-merror:0.09001\ttest-mlogloss:0.26899\tval-merror:0.08897\tval-mlogloss:0.26579\n",
      "[225]\ttrain-merror:0.05914\ttrain-mlogloss:0.18677\ttest-merror:0.08994\ttest-mlogloss:0.26813\tval-merror:0.08926\tval-mlogloss:0.26496\n",
      "[250]\ttrain-merror:0.05743\ttrain-mlogloss:0.18166\ttest-merror:0.09008\ttest-mlogloss:0.26739\tval-merror:0.08898\tval-mlogloss:0.26417\n",
      "[275]\ttrain-merror:0.05559\ttrain-mlogloss:0.17656\ttest-merror:0.09027\ttest-mlogloss:0.26697\tval-merror:0.08908\tval-mlogloss:0.26379\n",
      "[300]\ttrain-merror:0.05406\ttrain-mlogloss:0.17204\ttest-merror:0.09029\ttest-mlogloss:0.26690\tval-merror:0.08889\tval-mlogloss:0.26369\n",
      "[290]\ttest-merror:0.090287\ttest-mlogloss:0.266898\n",
      "====================================================================================================\n",
      "fold 2\n",
      "[12:12:57] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-merror:0.09301\ttrain-mlogloss:1.30817\ttest-merror:0.10457\ttest-mlogloss:1.30940\tval-merror:0.10465\tval-mlogloss:1.30930\n",
      "[25]\ttrain-merror:0.08280\ttrain-mlogloss:0.51549\ttest-merror:0.09643\ttest-mlogloss:0.53616\tval-merror:0.09708\tval-mlogloss:0.53540\n",
      "[50]\ttrain-merror:0.07757\ttrain-mlogloss:0.32445\ttest-merror:0.09410\ttest-mlogloss:0.35701\tval-merror:0.09448\tval-mlogloss:0.35634\n",
      "[75]\ttrain-merror:0.07345\ttrain-mlogloss:0.26159\ttest-merror:0.09232\ttest-mlogloss:0.30446\tval-merror:0.09209\tval-mlogloss:0.30383\n",
      "[100]\ttrain-merror:0.07032\ttrain-mlogloss:0.23389\ttest-merror:0.09145\ttest-mlogloss:0.28585\tval-merror:0.09149\tval-mlogloss:0.28538\n",
      "[125]\ttrain-merror:0.06728\ttrain-mlogloss:0.21793\ttest-merror:0.09091\ttest-mlogloss:0.27807\tval-merror:0.09066\tval-mlogloss:0.27764\n",
      "[150]\ttrain-merror:0.06460\ttrain-mlogloss:0.20685\ttest-merror:0.09053\ttest-mlogloss:0.27398\tval-merror:0.09047\tval-mlogloss:0.27359\n",
      "[175]\ttrain-merror:0.06249\ttrain-mlogloss:0.19861\ttest-merror:0.09044\ttest-mlogloss:0.27209\tval-merror:0.09047\tval-mlogloss:0.27171\n",
      "[200]\ttrain-merror:0.06045\ttrain-mlogloss:0.19159\ttest-merror:0.09039\ttest-mlogloss:0.27087\tval-merror:0.09027\tval-mlogloss:0.27044\n",
      "[225]\ttrain-merror:0.05871\ttrain-mlogloss:0.18583\ttest-merror:0.09016\ttest-mlogloss:0.27006\tval-merror:0.09029\tval-mlogloss:0.26953\n",
      "[250]\ttrain-merror:0.05705\ttrain-mlogloss:0.18082\ttest-merror:0.09007\ttest-mlogloss:0.26952\tval-merror:0.09004\tval-mlogloss:0.26883\n",
      "[275]\ttrain-merror:0.05529\ttrain-mlogloss:0.17591\ttest-merror:0.09012\ttest-mlogloss:0.26927\tval-merror:0.08993\tval-mlogloss:0.26846\n",
      "[292]\ttrain-merror:0.05406\ttrain-mlogloss:0.17262\ttest-merror:0.09028\ttest-mlogloss:0.26924\tval-merror:0.09004\tval-mlogloss:0.26844\n",
      "[282]\ttest-merror:0.090276\ttest-mlogloss:0.269242\n",
      "====================================================================================================\n",
      "fold 3\n",
      "[12:17:00] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-merror:0.09342\ttrain-mlogloss:1.30824\ttest-merror:0.10500\ttest-mlogloss:1.30934\tval-merror:0.10480\tval-mlogloss:1.30936\n",
      "[25]\ttrain-merror:0.08321\ttrain-mlogloss:0.51631\ttest-merror:0.09599\ttest-mlogloss:0.53546\tval-merror:0.09588\tval-mlogloss:0.53474\n",
      "[50]\ttrain-merror:0.07807\ttrain-mlogloss:0.32565\ttest-merror:0.09336\ttest-mlogloss:0.35570\tval-merror:0.09306\tval-mlogloss:0.35490\n",
      "[75]\ttrain-merror:0.07397\ttrain-mlogloss:0.26289\ttest-merror:0.09164\ttest-mlogloss:0.30273\tval-merror:0.09186\tval-mlogloss:0.30203\n",
      "[100]\ttrain-merror:0.07061\ttrain-mlogloss:0.23532\ttest-merror:0.09054\ttest-mlogloss:0.28403\tval-merror:0.09093\tval-mlogloss:0.28331\n",
      "[125]\ttrain-merror:0.06782\ttrain-mlogloss:0.21958\ttest-merror:0.08989\ttest-mlogloss:0.27622\tval-merror:0.09056\tval-mlogloss:0.27548\n",
      "[150]\ttrain-merror:0.06509\ttrain-mlogloss:0.20853\ttest-merror:0.08934\ttest-mlogloss:0.27229\tval-merror:0.09042\tval-mlogloss:0.27141\n",
      "[175]\ttrain-merror:0.06295\ttrain-mlogloss:0.20017\ttest-merror:0.08947\ttest-mlogloss:0.27028\tval-merror:0.09046\tval-mlogloss:0.26938\n",
      "[200]\ttrain-merror:0.06092\ttrain-mlogloss:0.19321\ttest-merror:0.08929\ttest-mlogloss:0.26900\tval-merror:0.09033\tval-mlogloss:0.26810\n",
      "[225]\ttrain-merror:0.05915\ttrain-mlogloss:0.18759\ttest-merror:0.08909\ttest-mlogloss:0.26811\tval-merror:0.09007\tval-mlogloss:0.26722\n",
      "[250]\ttrain-merror:0.05761\ttrain-mlogloss:0.18264\ttest-merror:0.08913\ttest-mlogloss:0.26763\tval-merror:0.08995\tval-mlogloss:0.26675\n",
      "[275]\ttrain-merror:0.05596\ttrain-mlogloss:0.17767\ttest-merror:0.08920\ttest-mlogloss:0.26732\tval-merror:0.09046\tval-mlogloss:0.26649\n",
      "[300]\ttrain-merror:0.05418\ttrain-mlogloss:0.17291\ttest-merror:0.08888\ttest-mlogloss:0.26708\tval-merror:0.09050\tval-mlogloss:0.26629\n",
      "[325]\ttrain-merror:0.05237\ttrain-mlogloss:0.16810\ttest-merror:0.08897\ttest-mlogloss:0.26685\tval-merror:0.09042\tval-mlogloss:0.26611\n",
      "[327]\ttrain-merror:0.05222\ttrain-mlogloss:0.16769\ttest-merror:0.08886\ttest-mlogloss:0.26681\tval-merror:0.09019\tval-mlogloss:0.26606\n",
      "[317]\ttest-merror:0.088861\ttest-mlogloss:0.266806\n",
      "====================================================================================================\n",
      "fold 4\n",
      "[12:21:28] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-merror:0.09321\ttrain-mlogloss:1.30822\ttest-merror:0.10400\ttest-mlogloss:1.30936\tval-merror:0.10484\tval-mlogloss:1.30944\n",
      "[25]\ttrain-merror:0.08268\ttrain-mlogloss:0.51573\ttest-merror:0.09567\ttest-mlogloss:0.53506\tval-merror:0.09757\tval-mlogloss:0.53689\n",
      "[50]\ttrain-merror:0.07752\ttrain-mlogloss:0.32505\ttest-merror:0.09344\ttest-mlogloss:0.35553\tval-merror:0.09481\tval-mlogloss:0.35770\n",
      "[75]\ttrain-merror:0.07359\ttrain-mlogloss:0.26238\ttest-merror:0.09166\ttest-mlogloss:0.30264\tval-merror:0.09315\tval-mlogloss:0.30504\n",
      "[100]\ttrain-merror:0.07042\ttrain-mlogloss:0.23479\ttest-merror:0.09087\ttest-mlogloss:0.28388\tval-merror:0.09218\tval-mlogloss:0.28649\n",
      "[125]\ttrain-merror:0.06759\ttrain-mlogloss:0.21913\ttest-merror:0.09036\ttest-mlogloss:0.27590\tval-merror:0.09177\tval-mlogloss:0.27881\n",
      "[150]\ttrain-merror:0.06492\ttrain-mlogloss:0.20791\ttest-merror:0.08999\ttest-mlogloss:0.27173\tval-merror:0.09130\tval-mlogloss:0.27495\n",
      "[175]\ttrain-merror:0.06265\ttrain-mlogloss:0.19935\ttest-merror:0.08979\ttest-mlogloss:0.26961\tval-merror:0.09122\tval-mlogloss:0.27300\n",
      "[200]\ttrain-merror:0.06069\ttrain-mlogloss:0.19237\ttest-merror:0.08984\ttest-mlogloss:0.26830\tval-merror:0.09129\tval-mlogloss:0.27174\n",
      "[225]\ttrain-merror:0.05915\ttrain-mlogloss:0.18709\ttest-merror:0.08987\ttest-mlogloss:0.26739\tval-merror:0.09128\tval-mlogloss:0.27094\n",
      "[250]\ttrain-merror:0.05768\ttrain-mlogloss:0.18224\ttest-merror:0.08990\ttest-mlogloss:0.26680\tval-merror:0.09149\tval-mlogloss:0.27040\n",
      "[275]\ttrain-merror:0.05599\ttrain-mlogloss:0.17739\ttest-merror:0.09003\ttest-mlogloss:0.26651\tval-merror:0.09123\tval-mlogloss:0.27008\n",
      "[295]\ttrain-merror:0.05468\ttrain-mlogloss:0.17349\ttest-merror:0.09002\ttest-mlogloss:0.26641\tval-merror:0.09141\tval-mlogloss:0.27007\n",
      "[286]\ttest-merror:0.090039\ttest-mlogloss:0.266405\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "if 'CURRENT_TIME' in globals() and not (\n",
    "    len(glob.glob(OUTPUT_DIRPATH+'/*.model')) < MOD_VALS[0]\n",
    "    and not FORCE_RERUN\n",
    "):\n",
    "    OUTPUT_DIRPATH, OLD_TIME = os.path.split(OUTPUT_DIRPATH)\n",
    "fold_start = 0\n",
    "if 'CURRENT_TIME' not in globals() or not (\n",
    "    len(glob.glob(OUTPUT_DIRPATH+'/*.model')) < MOD_VALS[0]\n",
    "    and not FORCE_RERUN\n",
    "):\n",
    "    CURRENT_TIME = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "    OUTPUT_DIRPATH = os.path.join(OUTPUT_DIRPATH, CURRENT_TIME)\n",
    "    if not os.path.exists(OUTPUT_DIRPATH):\n",
    "        os.makedirs(OUTPUT_DIRPATH)\n",
    "else:\n",
    "    for model_file in glob.glob(OUTPUT_DIRPATH+'/*.model'):\n",
    "        print(f\"Finished model fold {model_file[-7]}\")\n",
    "        fold_start += 1\n",
    "    print(f\"Starting from fold {fold_start}\")\n",
    "\n",
    "if OPTIMIZE_SPACE:\n",
    "    print('OPTIMIZING SPACE')\n",
    "        \n",
    "    param_filepath = os.path.join(OUTPUT_DIRPATH, f'{CURRENT_TIME}_best_params.json')\n",
    "    param = optimize_hyperparams(\n",
    "        bdt_train_dict, bdt_val_dict, param_filepath, \n",
    "        start_point=3, static_params_dict={'min_child_weight': 0.2, 'max_depth': 4}\n",
    "    )\n",
    "\n",
    "    param['eval_metric'] = 'merror'\n",
    "    param = list(param.items()) + [('eval_metric', 'mlogloss')]\n",
    "# else:\n",
    "#     # with open('/uscms/home/tsievert/nobackup/XHYbbgg/HHtobbyy/MultiClassBDT_model_outputs/v10/v2_vars/2025-02-19_12-45-38/2025-02-19_12-45-38_best_params.json', 'r') as f:\n",
    "#     with open('/uscms/home/tsievert/nobackup/XHYbbgg/HHtobbyy/MultiClassBDT_model_outputs/v11/v2_vars/2025-03-04_15-04-16/2025-03-04_15-04-16_best_params.json', 'r') as f:\n",
    "#         param = json.load(f)\n",
    "#     param['eval_metric'] = 'merror'\n",
    "#     param = list(param.items()) + [('eval_metric', 'mlogloss')]\n",
    "\n",
    "evals_result_dict = {f\"fold_{fold_idx}\": dict() for fold_idx in range(len(bdt_train_dict))}\n",
    "for fold_idx in range(fold_start, len(bdt_train_dict)):\n",
    "    print(f\"fold {fold_idx}\")\n",
    "    # Train bdt\n",
    "    evallist = [(bdt_train_dict[f\"fold_{fold_idx}\"], 'train'), (bdt_test_dict[f\"fold_{fold_idx}\"], 'test'), (bdt_val_dict[f\"fold_{fold_idx}\"], 'val')]\n",
    "    booster = xgb.train(\n",
    "        param, bdt_train_dict[f\"fold_{fold_idx}\"], num_boost_round=num_trees, \n",
    "        evals=evallist, early_stopping_rounds=10, verbose_eval=25, evals_result=evals_result_dict[f\"fold_{fold_idx}\"],\n",
    "        # custom_metric=thresholded_weighted_merror\n",
    "    )\n",
    "\n",
    "    booster.save_model(os.path.join(OUTPUT_DIRPATH, f'{CURRENT_TIME}_BDT_fold{fold_idx}.model'))\n",
    "    \n",
    "    # Print perf on test dataset\n",
    "    print(booster.eval(bdt_test_dict[f\"fold_{fold_idx}\"], name='test', iteration=booster.best_iteration))\n",
    "    print('='*100)\n",
    "\n",
    "    with open(os.path.join(OUTPUT_DIRPATH, f'{CURRENT_TIME}_BDT_eval_result.json'), 'w') as f:\n",
    "        json.dump(evals_result_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance (ROC) Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:25:33] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:26:59] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:28:23] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:29:45] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:31:10] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:33:37] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:34:59] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:36:23] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:37:42] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:39:09] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:41:33] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:42:59] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:44:18] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:45:36] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:47:07] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:49:29] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:50:54] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:52:29] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:53:53] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[12:55:21] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_tpr = np.linspace(0, 1, 5000)  # copied from IN evaluate.py file\n",
    "roc_baseline = np.zeros(\n",
    "    (len(bdt_train_dict), len(base_tpr), len(order)), \n",
    "    dtype=float\n",
    ")\n",
    "area_baseline = np.zeros(\n",
    "    (len(bdt_train_dict), len(order)), \n",
    "    dtype=float\n",
    ")\n",
    "\n",
    "BDT_perf = {\n",
    "    sample_name: copy.deepcopy({\n",
    "        'base_tpr': base_tpr,\n",
    "        'class_order': copy.deepcopy(order),\n",
    "        # test data #\n",
    "        'preds': [],\n",
    "        'fprs_density': copy.deepcopy(roc_baseline), 'thresholds_density': copy.deepcopy(roc_baseline), 'areas_density': copy.deepcopy(area_baseline),\n",
    "        'fprs_weighted': copy.deepcopy(roc_baseline), 'thresholds_weighted': copy.deepcopy(roc_baseline), 'areas_weighted': copy.deepcopy(area_baseline),\n",
    "        'fprs_sum_density': copy.deepcopy(roc_baseline[0, ...]), 'thresholds_sum_density': copy.deepcopy(roc_baseline[0, ...]), 'areas_sum_density': copy.deepcopy(area_baseline[0, ...]),\n",
    "        'fprs_sum_weighted': copy.deepcopy(roc_baseline[0, ...]), 'thresholds_sum_weighted': copy.deepcopy(roc_baseline[0, ...]), 'areas_sum_weighted': copy.deepcopy(area_baseline[0, ...]),\n",
    "        # train data #\n",
    "        'train_preds': [], \n",
    "        'train_fprs_density': copy.deepcopy(roc_baseline), 'train_thresholds_density': copy.deepcopy(roc_baseline), 'train_areas_density': copy.deepcopy(area_baseline),\n",
    "        'train_fprs_weighted': copy.deepcopy(roc_baseline), 'train_thresholds_weighted': copy.deepcopy(roc_baseline), 'train_areas_weighted': copy.deepcopy(area_baseline),\n",
    "        'train_fprs_sum_density': copy.deepcopy(roc_baseline[0, ...]), 'train_thresholds_sum_density': copy.deepcopy(roc_baseline[0, ...]), 'train_areas_sum_density': copy.deepcopy(area_baseline[0, ...]),\n",
    "        'train_fprs_sum_weighted': copy.deepcopy(roc_baseline[0, ...]), 'train_thresholds_sum_weighted': copy.deepcopy(roc_baseline[0, ...]), 'train_areas_sum_weighted': copy.deepcopy(area_baseline[0, ...]),\n",
    "        # val data #\n",
    "        'val_preds': [],\n",
    "        'val_fprs_density': copy.deepcopy(roc_baseline), 'val_thresholds_density': copy.deepcopy(roc_baseline), 'val_areas_density': copy.deepcopy(area_baseline),\n",
    "        'val_fprs_weighted': copy.deepcopy(roc_baseline), 'val_thresholds_weighted': copy.deepcopy(roc_baseline), 'val_areas_weighted': copy.deepcopy(area_baseline),\n",
    "        'val_fprs_sum_density': copy.deepcopy(roc_baseline[0, ...]), 'val_thresholds_sum_density': copy.deepcopy(roc_baseline[0, ...]), 'val_areas_sum_density': copy.deepcopy(area_baseline[0, ...]),\n",
    "        'val_fprs_sum_weighted': copy.deepcopy(roc_baseline[0, ...]), 'val_thresholds_sum_weighted': copy.deepcopy(roc_baseline[0, ...]), 'val_areas_sum_weighted': copy.deepcopy(area_baseline[0, ...]),\n",
    "    }) for sample_name in order\n",
    "}\n",
    "\n",
    "for j, sample_name in enumerate(order):\n",
    "\n",
    "    for fold_idx in range(len(bdt_train_dict)):\n",
    "        booster = xgb.Booster(param)\n",
    "\n",
    "        try:\n",
    "            booster.load_model(os.path.join(OUTPUT_DIRPATH, f'{CURRENT_TIME}_BDT_fold{fold_idx}.model'))\n",
    "        except:\n",
    "            raise FileNotFoundError(f\"No model file at fold {fold_idx}.\")\n",
    "    \n",
    "        for pred_type, dataset in [\n",
    "            ('train_', bdt_train_dict[f\"fold_{fold_idx}\"]),\n",
    "            ('val_', bdt_val_dict[f\"fold_{fold_idx}\"]),\n",
    "            ('', bdt_test_dict[f\"fold_{fold_idx}\"])\n",
    "        ]:\n",
    "            \n",
    "            BDT_perf[sample_name][pred_type + 'preds'].append(\n",
    "                booster.predict(\n",
    "                    dataset, \n",
    "                    iteration_range=(0, booster.best_iteration+1)\n",
    "                ).tolist()\n",
    "            )\n",
    "\n",
    "            for i, sample_name_ in enumerate(order):\n",
    "                \n",
    "                if sample_name_ == sample_name:\n",
    "                    event_mask = dataset.get_label() > -1\n",
    "                    pred_rescale = np.ones_like(event_mask)\n",
    "                else:\n",
    "                    event_mask = np.logical_or(dataset.get_label() == j, dataset.get_label() == i)\n",
    "                    pred_rescale = np.array(BDT_perf[sample_name][pred_type + 'preds'][-1])[:, j][event_mask] + np.array(BDT_perf[sample_name][pred_type + 'preds'][-1])[:, i][event_mask]\n",
    "                class_preds = np.array(BDT_perf[sample_name][pred_type + 'preds'][-1])[:, j][event_mask] / pred_rescale\n",
    "                class_truths = np.where(dataset.get_label() == j, 1, 0)[event_mask]\n",
    "                \n",
    "                for roc_type in ['density', 'weighted']:\n",
    "\n",
    "                    if roc_type == 'weighted':\n",
    "                        if re.search('train', pred_type) is not None:\n",
    "                            roc_weights = weights_plot_train[f\"fold_{fold_idx}\"][event_mask]\n",
    "                        elif re.search('val', pred_type) is not None:\n",
    "                            roc_weights = weights_plot_val[f\"fold_{fold_idx}\"][event_mask]\n",
    "                        else:\n",
    "                            roc_weights = weights_plot_test[f\"fold_{fold_idx}\"][event_mask]\n",
    "                    else:\n",
    "                        roc_weights = None\n",
    "\n",
    "                    fpr_bdt, tpr_bdt, threshold_bdt = roc_curve(class_truths, class_preds, sample_weight=roc_weights)\n",
    "                    fpr_bdt = np.interp(base_tpr, tpr_bdt, fpr_bdt)\n",
    "                    threshold_bdt = np.interp(base_tpr, tpr_bdt, threshold_bdt)\n",
    "\n",
    "                    BDT_perf[sample_name][pred_type + 'fprs_' + roc_type][fold_idx][:, i] = fpr_bdt\n",
    "                    BDT_perf[sample_name][pred_type + 'thresholds_' + roc_type][fold_idx][:, i] = threshold_bdt\n",
    "                    BDT_perf[sample_name][pred_type + 'areas_' + roc_type][fold_idx][i] = float(trapezoid(base_tpr, fpr_bdt))\n",
    "    \n",
    "    for pred_type, dataset_dict in [\n",
    "        ('train_', bdt_train_dict),\n",
    "        ('val_', bdt_val_dict),\n",
    "        ('', bdt_test_dict)\n",
    "    ]:\n",
    "\n",
    "        flat_preds = np.concatenate(BDT_perf[sample_name][f'{pred_type}preds'], axis=0)\n",
    "        flat_truths = np.concatenate([dataset_dict[f\"fold_{fold_idx}\"].get_label() for fold_idx in range(len(dataset_dict))], axis=0)\n",
    "\n",
    "        for i, sample_name_ in enumerate(order):\n",
    "            \n",
    "            if sample_name_ == sample_name:\n",
    "                event_mask = flat_truths > -1\n",
    "                pred_rescale = np.ones_like(event_mask)\n",
    "            else:\n",
    "                event_mask = np.logical_or(flat_truths == j, flat_truths == i)\n",
    "                pred_rescale = flat_preds[:, j][event_mask] + flat_preds[:, i][event_mask]\n",
    "            class_preds = flat_preds[:, j][event_mask] / pred_rescale\n",
    "            class_truths = np.where(flat_truths == j, 1, 0)[event_mask]\n",
    "            \n",
    "            for roc_type in ['density', 'weighted']:\n",
    "\n",
    "                if roc_type == 'weighted':\n",
    "                    if re.search('train', pred_type) is not None:\n",
    "                        roc_weights = np.concatenate([weights_plot_train[f\"fold_{fold_idx}\"] for fold_idx in range(len(weights_plot_train))], axis=0)[event_mask]\n",
    "                    elif re.search('val', pred_type) is not None:\n",
    "                        roc_weights = np.concatenate([weights_plot_val[f\"fold_{fold_idx}\"] for fold_idx in range(len(weights_plot_val))], axis=0)[event_mask]\n",
    "                    else:\n",
    "                        roc_weights = np.concatenate([weights_plot_test[f\"fold_{fold_idx}\"] for fold_idx in range(len(weights_plot_test))], axis=0)[event_mask]\n",
    "                else:\n",
    "                    roc_weights = None\n",
    "\n",
    "                fpr_bdt, tpr_bdt, threshold_bdt = roc_curve(class_truths, class_preds, sample_weight=roc_weights)\n",
    "                fpr_bdt = np.interp(base_tpr, tpr_bdt, fpr_bdt)\n",
    "                threshold_bdt = np.interp(base_tpr, tpr_bdt, threshold_bdt)\n",
    "\n",
    "                BDT_perf[sample_name][pred_type + 'fprs_sum_' + roc_type][:, i] = fpr_bdt\n",
    "                BDT_perf[sample_name][pred_type + 'thresholds_sum_' + roc_type][:, i] = threshold_bdt\n",
    "                BDT_perf[sample_name][pred_type + 'areas_sum_' + roc_type][i] = float(trapezoid(base_tpr, fpr_bdt))\n",
    "    \n",
    "    for key in BDT_perf[sample_name].keys():\n",
    "        if type(BDT_perf[sample_name][key]) is list:\n",
    "            continue\n",
    "        BDT_perf[sample_name][key] = BDT_perf[sample_name][key].tolist()\n",
    "\n",
    "\n",
    "with open(os.path.join(OUTPUT_DIRPATH, CURRENT_TIME+f\"_BDT_perf.json\"), 'w') as f:\n",
    "    json.dump(BDT_perf, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def pad_list(list_of_lists):\n",
    "    max_length = np.max([len(list_i) for list_i in list_of_lists])\n",
    "    for list_i in list_of_lists:\n",
    "        while len(list_i) < max_length:\n",
    "            list_i.append(list_i[-1])\n",
    "\n",
    "    return list_of_lists\n",
    "\n",
    "def plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix, format='png'):\n",
    "    plot_prefix = plot_prefix + ('_' if plot_prefix != '' else '')\n",
    "    plot_postfix = plot_postfix + ('_' if plot_postfix != '' else '')\n",
    "    plot_name = plot_prefix + plot_name + plot_postfix + f'.{format}'\n",
    "\n",
    "    plot_filepath = os.path.join(plot_dirpath, plot_name)\n",
    "    return plot_filepath\n",
    "\n",
    "def plot_train_val_losses(\n",
    "    losses_arrs, labels, plot_name, plot_dirpath, \n",
    "    plot_prefix='', plot_postfix='', linestyles=None,\n",
    "    losses_std_arrs=None\n",
    "):\n",
    "    plt.figure(figsize=(9,7))\n",
    "    \n",
    "    if type(losses_arrs[0]) is float:\n",
    "        losses_arrs = [losses_arrs]\n",
    "    if linestyles is None:\n",
    "        linestyles = ['solid'] * len(losses_arrs)\n",
    "    if labels is None:\n",
    "        labels = [i for i in range(len(losses_arrs))]\n",
    "\n",
    "    if losses_std_arrs is not None:\n",
    "        for i in range(len(losses_std_arrs)):\n",
    "            plt.fill_between(\n",
    "                range(len(losses_std_arrs[i])), \n",
    "                losses_arrs[i]+losses_std_arrs[i], losses_arrs[i]-losses_std_arrs[i],\n",
    "                alpha=0.7\n",
    "            )\n",
    "\n",
    "    for i in range(len(losses_arrs)):\n",
    "        plt.plot(\n",
    "            range(len(losses_arrs[i])), \n",
    "            losses_arrs[i], \n",
    "            label=f\"{labels[i]} losses\", linestyle=linestyles[i],\n",
    "            alpha=0.7\n",
    "        )\n",
    "        \n",
    "    plt.legend(bbox_to_anchor=(1, 1))\n",
    "    plt.xlabel('EPOCH')\n",
    "    plt.ylabel('Data Loss')\n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix, format='pdf'), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.close()\n",
    "\n",
    "def plot_rocs(\n",
    "    fprs, tprs, labels, plot_name, plot_dirpath,\n",
    "    plot_prefix='', plot_postfix='', close=True, log=None\n",
    "):\n",
    "    plt.figure(figsize=(9,7))\n",
    "    \n",
    "    for fpr, tpr, label in zip(fprs, tprs, labels):\n",
    "        plt.plot(fpr, tpr, label=label, linestyle='solid')\n",
    "\n",
    "    plt.legend(bbox_to_anchor=(1, 1))\n",
    "    plt.xlabel('Background contamination')\n",
    "    plt.ylabel('Signal efficiency')\n",
    "    if log is not None and re.search('x', log) is not None:\n",
    "        plt.xscale('log')\n",
    "    elif log is not None and re.search('y', log) is not None:\n",
    "        plt.yscale('log')\n",
    "    \n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix, format='pdf'), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    if close:\n",
    "        plt.close()\n",
    "\n",
    "def plot_output_scores(\n",
    "    sigs_and_bkgs, order, plot_name, plot_dirpath,\n",
    "    plot_prefix='', plot_postfix='', bins=1000, weights=None, log=False, arctanh=False\n",
    "):\n",
    "    plt.figure(figsize=(9,7))\n",
    "\n",
    "    if arctanh:\n",
    "        end_point = 6.\n",
    "    else:\n",
    "        end_point = 1.\n",
    "    hist_axis = hist.axis.Regular(bins, 0., end_point, name='var', growth=False, underflow=False, overflow=False)\n",
    "    hists, labels = [], []\n",
    "    for sample_name in order:\n",
    "        if sample_name not in sigs_and_bkgs:\n",
    "            continue\n",
    "        hists.append(\n",
    "            hist.Hist(hist_axis, storage='weight').fill(\n",
    "                var=sigs_and_bkgs[sample_name], \n",
    "                weight=weights[sample_name] if weights is not None else np.ones_like(sigs_and_bkgs[sample_name])\n",
    "            )\n",
    "        )\n",
    "        labels.append(sample_name)\n",
    "    hep.histplot(\n",
    "        hists,\n",
    "        yerr=(True if weights is not None else False),\n",
    "        alpha=0.8, density=(False if weights is not None else True), histtype='step',\n",
    "        label=labels\n",
    "    )\n",
    "\n",
    "    plt.legend(bbox_to_anchor=(1, 1))\n",
    "    plt.xlabel('Output score')\n",
    "    if log:\n",
    "        plt.yscale('log')\n",
    "    \n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix, format='pdf'), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.close()\n",
    "\n",
    "def plot_s_over_root_b(\n",
    "    sig, bkg, label, plot_name, plot_dirpath,\n",
    "    plot_prefix='', plot_postfix='', bins=1000, weights={'sig': None, 'bkg': None},\n",
    "    lines=None, lines_labels=None, line_colors=None, arctanh=False\n",
    "):\n",
    "    plt.figure(figsize=(9,7))\n",
    "\n",
    "    if arctanh:\n",
    "        end_point = 6.\n",
    "        hist_axis = hist.axis.Regular(bins, 0., end_point, name='var', growth=False, underflow=False, overflow=False)\n",
    "    else:\n",
    "        end_point = 1.\n",
    "        hist_axis = hist.axis.Regular(bins, 0., end_point, name='var', growth=False, underflow=False, overflow=False)\n",
    "    sig_hist = hist.Hist(hist_axis, storage='weight').fill(var=sig, weight=weights['sig'] if weights['sig'] is not None else np.ones_like(sig))\n",
    "    bkg_hist = hist.Hist(hist_axis, storage='weight').fill(var=bkg, weight=weights['bkg'] if weights['bkg'] is not None else np.ones_like(bkg))\n",
    "    s_over_root_b_points = sig_hist.values().flatten() / np.sqrt(bkg_hist.values().flatten())\n",
    "    plt.plot(\n",
    "        np.arange(0., end_point, end_point*(1/bins)), s_over_root_b_points, \n",
    "        label=f'{label} - s/âb', alpha=0.8\n",
    "    )\n",
    "\n",
    "    if lines is not None:\n",
    "        for i in range(len(lines)):\n",
    "            plt.vlines(\n",
    "                lines[i], 0, np.max(s_over_root_b_points), \n",
    "                label='s/âb'+(' - '+lines_labels[i] if lines_labels is not None else ''), \n",
    "                alpha=0.5, colors=line_colors[i]\n",
    "            )\n",
    "    \n",
    "    plt.legend(bbox_to_anchor=(1, 1))\n",
    "    plt.xlabel('Output score')\n",
    "    plt.ylabel('s/âb')\n",
    "    \n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix, format='pdf'), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.close()\n",
    "\n",
    "def plot_confusion_matrix(\n",
    "    conf_matrix, class_labels, plot_name, plot_dirpath, \n",
    "    plot_prefix='', plot_postfix=''\n",
    "):\n",
    "    plt.figure(figsize=(9,7))\n",
    "\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=class_labels)\n",
    "    disp.plot(im_kw={'norm': 'log'})\n",
    "    \n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix, format='pdf'), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.close()\n",
    "\n",
    "def plot_feature_importance(\n",
    "    feature_scores, feature_labels, plot_name, plot_dirpath, \n",
    "    plot_prefix='', plot_postfix='', fscore_method='total_gain', log=True\n",
    "):\n",
    "    plt.figure(figsize=(18,14))\n",
    "\n",
    "    plt.barh(\n",
    "        np.arange(len(feature_scores)), feature_scores, align='center'\n",
    "    )\n",
    "    plt.yticks(np.arange(len(feature_scores)), feature_labels, fontsize=8)\n",
    "    plt.ylabel('Features')\n",
    "    plt.xlabel(f'F score ({fscore_method})')\n",
    "    if log:\n",
    "        plt.xscale('log')\n",
    "    \n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix, format='pdf'), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def optimize_cut_boundaries(sigs, bkgs, weights, bins=10000, arctanh=False):\n",
    "    hist_list_fold = []\n",
    "    cut_boundaries_fold = []\n",
    "    cut_s_over_root_bs_fold = []\n",
    "    sig_weights_fold = []\n",
    "    bkg_weights_fold = []\n",
    "    if len(np.shape(sigs)) == 1:\n",
    "        sigs, bkgs = [sigs], [bkgs] \n",
    "    if arctanh:\n",
    "        end_point = 6.\n",
    "    else:\n",
    "        end_point = 1.\n",
    "    for sig, bkg in zip(sigs, bkgs):\n",
    "        hist_axis = hist.axis.Regular(bins, 0., end_point, name='var', growth=False, underflow=False, overflow=False)\n",
    "        sig_hist = hist.Hist(hist_axis, storage='weight').fill(var=sig, weight=weights['sig'])\n",
    "        bkg_hist = hist.Hist(hist_axis, storage='weight').fill(var=bkg, weight=weights['bkg'])\n",
    "        hist_list_fold.append({'sig': copy.deepcopy(sig_hist), 'bkg': copy.deepcopy(bkg_hist)})\n",
    "\n",
    "        fold_idx_cuts_bins_inclusive = []\n",
    "        fold_idx_sig_weights = []\n",
    "        fold_idx_bkg_weights = []\n",
    "        fold_idx_prev_s_over_root_b = []\n",
    "        prev_s_over_root_b = 0\n",
    "        for i in range(bins):\n",
    "            s = np.sum(sig_hist.values().flatten()[\n",
    "                (bins-1) - i : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "            ])\n",
    "            sqrt_b = np.sqrt(np.sum(bkg_hist.values().flatten()[\n",
    "                (bins-1) - i : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "            ]))\n",
    "            if prev_s_over_root_b < (s / sqrt_b) or s < 0.25:\n",
    "                prev_s_over_root_b = s / sqrt_b\n",
    "                continue\n",
    "            else:\n",
    "                fold_idx_sig_weights.append(\n",
    "                    {\n",
    "                        'value': np.sum(sig_hist.values().flatten()[\n",
    "                            (bins) - i : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                        ]),\n",
    "                        'w2': np.sqrt(np.sum(sig_hist.variances().flatten()[\n",
    "                            (bins) - i : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                        ])),\n",
    "                    }\n",
    "                )\n",
    "                fold_idx_bkg_weights.append(\n",
    "                    {\n",
    "                        'value': np.sum(bkg_hist.values().flatten()[\n",
    "                            (bins) - i : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                        ]),\n",
    "                        'w2': np.sqrt(np.sum(bkg_hist.variances().flatten()[\n",
    "                            (bins) - i : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                        ])),\n",
    "                    }\n",
    "                )\n",
    "                fold_idx_cuts_bins_inclusive.append(bins - i)\n",
    "                fold_idx_prev_s_over_root_b.append(prev_s_over_root_b)\n",
    "                prev_s_over_root_b = 0\n",
    "        fold_idx_sig_weights.append(\n",
    "            {\n",
    "                'value': np.sum(sig_hist.values().flatten()[\n",
    "                    0 : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                ]),\n",
    "                'w2': np.sqrt(np.sum(sig_hist.variances().flatten()[\n",
    "                    0 : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                ])),\n",
    "            }\n",
    "        )\n",
    "        fold_idx_bkg_weights.append(\n",
    "            {\n",
    "                'value': np.sum(bkg_hist.values().flatten()[\n",
    "                    0 : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                ]),\n",
    "                'w2': np.sqrt(np.sum(bkg_hist.variances().flatten()[\n",
    "                    0 : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                ])),\n",
    "            }\n",
    "        )\n",
    "        fold_idx_cuts_bins_inclusive.append(0)\n",
    "        fold_idx_prev_s_over_root_b.append(prev_s_over_root_b)\n",
    "        fold_idx_score_cuts = [end_point * (bin_i / bins) for bin_i in fold_idx_cuts_bins_inclusive]\n",
    "        cut_boundaries_fold.append(fold_idx_score_cuts)\n",
    "        cut_s_over_root_bs_fold.append(fold_idx_prev_s_over_root_b)\n",
    "        sig_weights_fold.append(fold_idx_sig_weights)\n",
    "        bkg_weights_fold.append(fold_idx_bkg_weights)\n",
    "    return cut_boundaries_fold, cut_s_over_root_bs_fold, sig_weights_fold, bkg_weights_fold\n",
    "\n",
    "def p_to_xyz(p, split=True):  # makes a tetrahedron with height 1 and vertices {(0, 0, 0),  (â3/2, 0, â3/2),  (0, â3/2, â3/2),  (â3/2, â3/2, 0)}\n",
    "    rt3o2 = np.sqrt(3) / 2\n",
    "\n",
    "    x = rt3o2 * (0*p[:, 0] + p[:, 1] + p[:, 2] + 0*p[:, 3])\n",
    "    y = rt3o2 * (0*p[:, 0] + 0*p[:, 1] + p[:, 2] + p[:, 3])\n",
    "    z = rt3o2 * (0*p[:, 0] + p[:, 1] + 0*p[:, 2] + p[:, 3])\n",
    "\n",
    "    if split:\n",
    "        return x, y, z\n",
    "    else:\n",
    "        return np.column_stack((x, y, z))\n",
    "    \n",
    "def tetrahedron_lines(split=True):\n",
    "    sig_to_ttH_like    = np.array([np.sqrt(3)/2,         0,            np.sqrt(3)/2])\n",
    "    sig_to_VH_like     = np.array([0,                np.sqrt(3)/2,     np.sqrt(3)/2])\n",
    "    sig_to_nonRes_like = np.array([np.sqrt(3)/2,     np.sqrt(3)/2,                0])\n",
    "\n",
    "    if split:\n",
    "        return sig_to_ttH_like, sig_to_VH_like, sig_to_nonRes_like\n",
    "    else:\n",
    "        return np.column_stack((sig_to_ttH_like, sig_to_VH_like, sig_to_nonRes_like))\n",
    "\n",
    "def output_to_3d_thresholds(p, split=True):\n",
    "    data = p_to_xyz(p, split=False)\n",
    "    tetrahedron_matrix = tetrahedron_lines(split=False)\n",
    "\n",
    "    thresholds = np.einsum('ij,jk', data, tetrahedron_matrix)\n",
    "\n",
    "    if split:\n",
    "        return thresholds[:, 0], thresholds[:, 1], thresholds[:, 2]\n",
    "    else:\n",
    "        return thresholds\n",
    "\n",
    "def optimize_cuts(\n",
    "    preds: np.ndarray, labels: np.ndarray, weights: np.ndarray,\n",
    "    param_names=['r1', 'r2', 'r3'], param_range=[(0., 1.), (0., 1.), (0., 1.)], \n",
    "    n_steps=int(5e2), verbose: bool=False, min_sig: float=0.25, prefactor: float=1e3, rng_seed: int=21,\n",
    "    fit_funcs_per_param: list=['power_law', 'power_law', 'power_law']\n",
    "):\n",
    "    # tetrahedron bkg vectors\n",
    "    sig_to_ttH_like, sig_to_VH_like, sig_to_nonRes_like = tetrahedron_lines()\n",
    "    tetrahedron_matrix = tetrahedron_lines(split=False)\n",
    "\n",
    "    # 3D outputs\n",
    "    xyz_preds = p_to_xyz(preds, split=False)\n",
    "    xyz_thresholds = np.einsum('ij,jk', xyz_preds, tetrahedron_matrix)\n",
    "\n",
    "    sig_to_ttH_preds = np.einsum('ij,j', xyz_preds, sig_to_ttH_like)\n",
    "    sig_to_VH_preds = np.einsum('ij,j', xyz_preds, sig_to_VH_like)\n",
    "    sig_to_nonRes_preds = np.einsum('ij,j', xyz_preds, sig_to_nonRes_like)\n",
    "\n",
    "    # histogramed counts\n",
    "    sig_to_ttH_counts, sig_to_ttH_bins = np.histogram(sig_to_ttH_preds[labels == 0], bins=1000, range=(0., 0.8), density=True)\n",
    "    sig_to_VH_counts, sig_to_VH_bins = np.histogram(sig_to_VH_preds[labels == 0], bins=1000, range=(0., 0.8), density=True)\n",
    "    sig_to_nonRes_counts, sig_to_nonRes_bins = np.histogram(sig_to_nonRes_preds[labels == 0], bins=1000, range=(0., 0.8), density=True)\n",
    "\n",
    "    # shift to center of bins\n",
    "    def bin_centers(bins_array):\n",
    "        return np.array([np.mean([bins_array[bin_i], bins_array[bin_i+1]]) for bin_i in range(len(bins_array)-1)])\n",
    "    \n",
    "    sig_to_ttH_bin_centers = bin_centers(sig_to_ttH_bins)\n",
    "    sig_to_VH_bin_centers = bin_centers(sig_to_VH_bins)\n",
    "    sig_to_nonRes_bin_centers = bin_centers(sig_to_nonRes_bins)\n",
    "\n",
    "    # fit data\n",
    "    def get_fit_funcs_per_param():\n",
    "        func_list, fit_func_list, transform_func_list = [], [], []\n",
    "        for func_name in fit_funcs_per_param:\n",
    "            if func_name == 'power_law':\n",
    "                func_list.append(power_law)\n",
    "                fit_func_list.append(fit_power_law)\n",
    "                transform_func_list.append(power_law_transform)\n",
    "            elif func_name == 'exponential':\n",
    "                func_list.append(exponential)\n",
    "                fit_func_list.append(fit_exponential)\n",
    "                transform_func_list.append(exponential_transform)\n",
    "            elif func_name == 'levy':\n",
    "                func_list.append(levy)\n",
    "                fit_func_list.append(fit_levy)\n",
    "                transform_func_list.append(levy_transform)\n",
    "            else:\n",
    "                raise Exception(f\"Fit function requested is not implemented. You asked for {func_name}, the implemented functions are power_law, exponential, and levy.\")\n",
    "        return func_list, fit_func_list, transform_func_list\n",
    "    \n",
    "    power_law = lambda x, a, k: a * np.power(x, -k)\n",
    "    def fit_power_law(x, y, sigma=None):\n",
    "        a_init = 1.\n",
    "        k_init = 5.\n",
    "\n",
    "        opt_params, opt_cov  = curve_fit(\n",
    "            power_law, \n",
    "            x,\n",
    "            y,\n",
    "            p0=[a_init, k_init],\n",
    "            sigma=sigma\n",
    "        )\n",
    "        return opt_params, opt_cov\n",
    "    power_law_transform = lambda a, k: (\n",
    "        lambda x: ((-k + 1) / a) * (x ** (1 / (-k + 1)))\n",
    "    )\n",
    "\n",
    "    exponential = lambda x, a, k: a * np.exp(-x * k)\n",
    "    def fit_exponential(x, y, sigma=None):\n",
    "        a_init = y[0]\n",
    "        k_init = 1 / np.mean([\n",
    "            x[y > (y[0] / np.exp(1))][-1],\n",
    "            x[y < (y[0] / np.exp(1))][0],\n",
    "        ])\n",
    "\n",
    "        opt_params, opt_cov = curve_fit(\n",
    "            exponential, \n",
    "            x,\n",
    "            y,\n",
    "            p0=[a_init, k_init],\n",
    "            sigma=sigma\n",
    "        )\n",
    "        return opt_params, opt_cov\n",
    "    exponential_transform = lambda a, k: (\n",
    "        lambda x: (-1 / k) * np.log(-k * x / a)\n",
    "    )\n",
    "\n",
    "    levy = lambda x, c, mu: (\n",
    "        np.sqrt(c / (2 * np.pi)) * np.exp(-c / (2 * (x - mu))) / np.power(x - mu, 3/2)\n",
    "    )\n",
    "    def fit_levy(x, y, sigma=None):\n",
    "        c_init = 0.01  # success of fit withint 600 tries (kwarg of curve_fit) HIGHLY\n",
    "        mu_init = 0.   #  sensitive to these initial choices of parameters. maybe rescale them by 1,000?\n",
    "\n",
    "        opt_params, opt_cov = curve_fit(\n",
    "            levy, \n",
    "            x,\n",
    "            y,\n",
    "            p0=[c_init, mu_init],\n",
    "            sigma=sigma,\n",
    "        )\n",
    "        return opt_params, opt_cov\n",
    "    gaussian_transfrom = lambda x: (10 / np.log(41)) * np.log(\n",
    "        1 - (np.log(-np.log2(x)) / np.log(22))\n",
    "    )  # approximation taken from https://dmi.units.it/~soranzo/epureAMS85-88-2014%202.pdf\n",
    "    levy_transform = lambda c, mu: (\n",
    "        lambda x: (c / np.power(gaussian_transfrom(1 - x/2), 2)) + mu\n",
    "    )\n",
    "    \n",
    "    funcs, fit_funcs, transform_funcs = get_fit_funcs_per_param()\n",
    "    sig_to_ttH_popt_func, sig_to_ttH_popt_cov = fit_funcs[0](sig_to_ttH_bin_centers, sig_to_ttH_counts, sigma=1/np.power(sig_to_ttH_counts, 1/2))\n",
    "    sig_to_VH_popt_func, sig_to_VH_popt_cov = fit_funcs[1](sig_to_VH_bin_centers, sig_to_VH_counts, sigma=1/np.power(sig_to_VH_counts, 1/2))\n",
    "    sig_to_nonRes_popt_func, sig_to_nonRes_popt_cov = fit_funcs[2](sig_to_nonRes_bin_centers, sig_to_nonRes_counts, sigma=1/np.power(sig_to_nonRes_counts, 1/2))\n",
    "    sig_to_ttH_transform = transform_funcs[0](*sig_to_ttH_popt_func)\n",
    "    sig_to_VH_transform = transform_funcs[1](*sig_to_VH_popt_func)\n",
    "    sig_to_nonRes_transform = transform_funcs[2](*sig_to_nonRes_popt_func)\n",
    "\n",
    "    sig_to_ttH_func = funcs[0](sig_to_ttH_bin_centers, *sig_to_ttH_popt_func)\n",
    "    sig_to_VH_func = funcs[1](sig_to_ttH_bin_centers, *sig_to_VH_popt_func)\n",
    "    sig_to_nonRes_func = funcs[2](sig_to_ttH_bin_centers, *sig_to_nonRes_popt_func)\n",
    "    plt.figure()\n",
    "    plt.plot(sig_to_ttH_bin_centers, sig_to_ttH_counts, alpha=0.7, color='r', linestyle='-', label='Sig to ttH-like')\n",
    "    plt.plot(sig_to_VH_bin_centers, sig_to_VH_counts, alpha=0.7, color='b', linestyle='-', label='Sig to VH-like')\n",
    "    plt.plot(sig_to_nonRes_bin_centers, sig_to_nonRes_counts, alpha=0.7, color='g', linestyle='-', label='Sig to nonRes-like')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    if np.all(np.array(fit_funcs_per_param) == 'levy'):\n",
    "        print(f\"opt ttH levy values: c = {sig_to_ttH_popt_func[0]}, $\\mu$ = {sig_to_ttH_popt_func[1]}\")\n",
    "        print(f\"opt VH levy values: c = {sig_to_VH_popt_func[0]}, $\\mu$ = {sig_to_VH_popt_func[1]}\")\n",
    "        print(f\"opt nonRes levy values: c = {sig_to_nonRes_popt_func[0]}, $\\mu$ = {sig_to_nonRes_popt_func[1]}\")\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(sig_to_ttH_bin_centers, sig_to_ttH_counts, alpha=0.7, color='r', linestyle='-', label='Sig to ttH-like')\n",
    "    plt.plot(sig_to_VH_bin_centers, sig_to_VH_counts, alpha=0.7, color='b', linestyle='-', label='Sig to VH-like')\n",
    "    plt.plot(sig_to_nonRes_bin_centers, sig_to_nonRes_counts, alpha=0.7, color='g', linestyle='-', label='Sig to nonRes-like')\n",
    "    plt.plot(sig_to_ttH_bin_centers, sig_to_ttH_func, alpha=0.7, color='r', linestyle='--', label='Sig to ttH-like - Fit exp')\n",
    "    plt.plot(sig_to_VH_bin_centers, sig_to_VH_func, alpha=0.7, color='b', linestyle='--', label='Sig to VH-like - Fit exp')\n",
    "    plt.plot(sig_to_nonRes_bin_centers, sig_to_nonRes_func, alpha=0.7, color='g', linestyle='--', label='Sig to nonRes-like - Fit exp')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    space  = [Real(float(param_range[i][0]), float(param_range[i][1]), \"uniform\", name=param_name) for i, param_name in enumerate(param_names)]\n",
    "    def space_transform(X):\n",
    "        return [\n",
    "            sig_to_ttH_transform(X[param_names[0]]),\n",
    "            sig_to_VH_transform(X[param_names[1]]),\n",
    "            sig_to_nonRes_transform(X[param_names[2]]),\n",
    "        ]\n",
    "\n",
    "    @use_named_args(space)\n",
    "    def objective(**X):\n",
    "        thresholds = space_transform(X)\n",
    "        if verbose:\n",
    "            print(\"New configuration: {}\".format(thresholds))\n",
    "        sample_mask = np.all(xyz_thresholds < thresholds, axis=1)\n",
    "\n",
    "        num_sig = np.abs(\n",
    "            np.sum(\n",
    "                weights[\n",
    "                    np.logical_and(\n",
    "                        labels == 0,\n",
    "                        sample_mask\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "        num_singleH_bkg = np.abs(\n",
    "            np.sum(\n",
    "                weights[\n",
    "                    np.logical_and(\n",
    "                        np.logical_or(\n",
    "                            labels == 1,\n",
    "                            labels == 2\n",
    "                        ),\n",
    "                        sample_mask\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "        num_nonRes_bkg = np.abs(\n",
    "            np.sum(\n",
    "                weights[\n",
    "                    np.logical_and(\n",
    "                        labels == 3,\n",
    "                        sample_mask\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "        singleH_to_nonRes_factor = 3.\n",
    "        num_rescale_bkg = (\n",
    "            singleH_to_nonRes_factor * num_singleH_bkg\n",
    "        ) + num_nonRes_bkg\n",
    "        num_bkg = num_singleH_bkg + num_nonRes_bkg\n",
    "\n",
    "        def s_over_b(s, b, case='realistic'):\n",
    "            if case == 'simplistic':\n",
    "                return s / np.sqrt(b)\n",
    "            elif case == 'realistic':\n",
    "                return np.sqrt(\n",
    "                    2 * (\n",
    "                        (s + b) * np.log(1 + (s / b)) - s\n",
    "                    )\n",
    "                )\n",
    "        s_over_root_b = s_over_b(num_sig, num_bkg)\n",
    "        opt_criteria = s_over_b(num_sig, num_rescale_bkg)\n",
    "\n",
    "        if num_sig == 0 and num_bkg == 0:\n",
    "            both_0 = prefactor*1e1\n",
    "            if verbose:\n",
    "                print(f\"both sig and bkg 0 at this hyperplane => {both_0}\")\n",
    "                print('='*60)\n",
    "            return both_0\n",
    "        elif num_sig < min_sig:\n",
    "            small_sig = prefactor*0\n",
    "            if verbose:\n",
    "                print(f\"too little sig ({num_sig}) at this hyperplane => {small_sig}\")\n",
    "                print('='*60)\n",
    "            return small_sig\n",
    "        elif num_bkg == 0:\n",
    "            zero_bkg = -prefactor*num_sig\n",
    "            if verbose:\n",
    "                print(f\"zero bkg at this hyperplane (likely due to finite data rather than real bkg-free zone) => {zero_bkg}\")\n",
    "                print('='*60)\n",
    "            return zero_bkg\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"s = {num_sig}, b = {num_bkg}, s/âb = {s_over_root_b} => {-prefactor*opt_criteria}\")\n",
    "            print('='*60)\n",
    "\n",
    "        return -prefactor*opt_criteria\n",
    "    \n",
    "    res_gp = gp_minimize(\n",
    "        objective, space, random_state=rng_seed, \n",
    "        n_calls=n_steps, n_initial_points=n_steps-100,\n",
    "        n_restarts_optimizer=5\n",
    "    )\n",
    "\n",
    "    opt_params = [float(res_gp.x[i]) for i in range(len(space))]\n",
    "    opt_cuts = [float(opt_cut) for opt_cut in space_transform({param_names[i]: res_gp.x[i] for i in range(len(param_names))})]\n",
    "    if verbose:\n",
    "        print(\"Best parameters: {}\".format(opt_cuts))\n",
    "        print(f\"Best s/âb = {-res_gp.fun / prefactor}\")\n",
    "\n",
    "    return opt_cuts, opt_params\n",
    "\n",
    "\n",
    "def multi_optimize_cut_boundaries(preds: list, labels: np.ndarray, weights: np.ndarray, num_categories: int=3, min_sig: float=0.25, n_steps: int=200):\n",
    "    clf_dict = {}\n",
    "    param_clf_dict = {}\n",
    "    # clf_dict[0] = [0.008485205139697272, 0.03976034437493922, 0.06505303760998234]\n",
    "    # for cat in range(1, num_categories):\n",
    "    for cat in range(num_categories):\n",
    "\n",
    "        clf_dict[cat] = []\n",
    "        param_clf_dict[cat] = []\n",
    "\n",
    "        if cat == 0:\n",
    "            opt_cuts, opt_params = optimize_cuts(\n",
    "                np.array(preds), labels, weights, verbose=True,\n",
    "                n_steps=n_steps, min_sig=min_sig, rng_seed=None,\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            slice_array = np.ones_like(labels, dtype=bool)\n",
    "            for prev_cat in range(cat):\n",
    "                slice_array = np.logical_and(\n",
    "                    slice_array,\n",
    "                    np.logical_not(\n",
    "                        np.all(\n",
    "                            output_to_3d_thresholds(np.array(preds), split=False) < clf_dict[prev_cat], \n",
    "                            axis=1\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            sliced_preds = np.array(preds)[slice_array]\n",
    "            sliced_labels = labels[slice_array]\n",
    "            sliced_weights = weights[slice_array]\n",
    "            \n",
    "            opt_cuts, opt_params = optimize_cuts(\n",
    "                sliced_preds, sliced_labels, sliced_weights, verbose=True,\n",
    "                n_steps=n_steps, min_sig=min_sig, rng_seed=None,\n",
    "                fit_funcs_per_param=['levy', 'levy', 'levy']\n",
    "            )\n",
    "\n",
    "        clf_dict[cat] = opt_cuts\n",
    "        param_clf_dict[cat] = opt_params\n",
    "\n",
    "    return clf_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "MC_NAMES_PRETTY = {\n",
    "    \"GGJets\": r\"$\\gamma\\gamma+3j$\",\n",
    "    \"GJetPt20To40\": r\"$\\gamma+j$, 20<$p_T$<40GeV\",\n",
    "    \"GJetPt40\": r\"$\\gamma+j$, 40GeV<$p_T$\",\n",
    "    \"GluGluHToGG\": r\"ggF $H\\rightarrow \\gamma\\gamma$\",\n",
    "    \"VBFHToGG\": r\"VBF $H\\rightarrow \\gamma\\gamma$\",\n",
    "    \"VHToGG\": r\"V$H\\rightarrow\\gamma\\gamma$\",\n",
    "    \"ttHToGG\": r\"$t\\bar{t}H\\rightarrow\\gamma\\gamma$\",\n",
    "    \"GluGluToHH\": r\"ggF $HH\\rightarrow bb\\gamma\\gamma$\",\n",
    "    # \"VBFHHto2B2G_CV_1_C2V_1_C3_1\": r\"VBF $HH\\rightarrow bb\\gamma\\gamma$\",\n",
    "    \"signal\": r\"ggF $HH\\rightarrow bb\\gamma\\gamma$ + VBF $HH\\rightarrow bb\\gamma\\gamma$\",\n",
    "    # Names for order #\n",
    "    \"ggF HH\": r\"ggF $H\\rightarrow \\gamma\\gamma$\",\n",
    "    \"ttH\": r\"$t\\bar{t}H\\rightarrow\\gamma\\gamma$\",\n",
    "    \"single-H\": r\"ggF $H\\rightarrow \\gamma\\gamma$ + VBF $H\\rightarrow \\gamma\\gamma$ + V$H\\rightarrow\\gamma\\gamma$\",\n",
    "    \"non-res\": r\"$\\gamma\\gamma+3j$ + $\\gamma+j$, 20GeV<$p_T$\",\n",
    "    \"VH\": r\"V$H\\rightarrow\\gamma\\gamma$\",\n",
    "    \"non-res + ggFH + VBFH\": r\"$\\gamma\\gamma+3j$ + $\\gamma+j$, 20GeV<$p_T$ + ggF $H\\rightarrow \\gamma\\gamma$ + VBF $H\\rightarrow \\gamma\\gamma$\",\n",
    "    \"ttH + bbH\": r\"$t\\bar{t}H\\rightarrow\\gamma\\gamma$ + $b\\bar{b}H\\rightarrow\\gamma\\gamma$\",\n",
    "    # Need to fill in pretty print for BSM samples #\n",
    "}\n",
    "LUMINOSITIES = {\n",
    "    '2022preEE': 7.9804, \n",
    "    '2022postEE': 26.6717,\n",
    "    # Need to fill in lumis for other eras #\n",
    "}\n",
    "LUMINOSITIES['total_lumi'] = sum(LUMINOSITIES.values())\n",
    "\n",
    "# Dictionary of variables\n",
    "VARIABLES = {\n",
    "    # key: hist.axis axes for plotting #\n",
    "    # MET variables\n",
    "    'puppiMET_sumEt': hist.axis.Regular(40, 150., 2000, name='var', label=r'puppiMET $\\Sigma E_T$ [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'puppiMET_pt': hist.axis.Regular(40, 20., 250, name='var', label=r'puppiMET $p_T$ [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'puppiMET_phi': hist.axis.Regular(20,-3.2, 3.2, name='var', label=r'puppiMET $\\phi$', growth=False, underflow=False, overflow=False), \n",
    "    # jet-MET variables\n",
    "    'DeltaPhi_j1MET': hist.axis.Regular(20,-3.2, 3.2, name='var', label=r'$\\Delta\\phi (j_1,E_T^{miss})$', growth=False, underflow=False, overflow=False), \n",
    "    'DeltaPhi_j2MET': hist.axis.Regular(20, -3.2, 3.2, name='var', label=r'$\\Delta\\phi (j_2,E_T^{miss})$', growth=False, underflow=False, overflow=False), \n",
    "    # jet-photon variables\n",
    "    'DeltaR_jg_min': hist.axis.Regular(30, 0, 5, name='var', label=r'min$(\\Delta R(jet, \\gamma))$', growth=False, underflow=False, overflow=False), \n",
    "    # jet variables\n",
    "    # 'jet1_pt': hist.axis.Regular(40, 20., 250, name='var', label=r'lead jet $p_T$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    # 'jet2_pt': hist.axis.Regular(40, 20., 250, name='var', label=r'sublead jet $p_T$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    'lead_bjet_pt': hist.axis.Regular(40, 20., 250, name='var', label=r'lead bjet $p_T$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    'lead_bjet_eta': hist.axis.Regular(20, -5., 5., name='var', label=r'lead bjet $\\eta$', growth=False, underflow=False, overflow=False),\n",
    "    'lead_bjet_phi': hist.axis.Regular(20, -3.2, 3.2, name='var', label=r'lead bjet $\\phi$', growth=False, underflow=False, overflow=False),\n",
    "    'sublead_bjet_pt': hist.axis.Regular(40, 20., 250, name='var', label=r'lead bjet $p_T$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    'sublead_bjet_eta': hist.axis.Regular(20, -5., 5., name='var', label=r'lead bjet $\\eta$', growth=False, underflow=False, overflow=False),\n",
    "    'sublead_bjet_phi': hist.axis.Regular(20, -3.2, 3.2, name='var', label=r'lead bjet $\\phi$', growth=False, underflow=False, overflow=False),\n",
    "    'n_jets': hist.axis.Integer(0, 10, name='var', label=r'$n_{jets}$', growth=False, underflow=False, overflow=False), \n",
    "    'chi_t0': hist.axis.Regular(40, 0., 150, name='var', label=r'$\\chi_{t0}^2$', growth=False, underflow=False, overflow=False), \n",
    "    'chi_t1': hist.axis.Regular(30, 0., 500, name='var', label=r'$\\chi_{t1}^2$', growth=False, underflow=False, overflow=False), \n",
    "    # lepton variables\n",
    "    'n_leptons': hist.axis.Integer(0, 10, name='var', label=r'$n_{leptons}$', growth=False, underflow=False, overflow=False),\n",
    "    'lepton1_pt': hist.axis.Regular(40, 0., 200., name='var', label=r'lead lepton $p_T$ [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'lepton2_pt': hist.axis.Regular(40, 0., 200., name='var', label=r'sublead lepton $p_T$ [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'lepton1_eta': hist.axis.Regular(30, -5., 5., name='var', label=r'lead lepton $\\eta$', growth=False, underflow=False, overflow=False), \n",
    "    'lepton2_eta': hist.axis.Regular(30, -5., 5., name='var', label=r'sublead lepton $\\eta$', growth=False, underflow=False, overflow=False),\n",
    "    'lepton1_phi': hist.axis.Regular(20, -3.2, 3.2, name='var', label=r'lead lepton $\\phi$', growth=False, underflow=False, overflow=False), \n",
    "    'lepton2_phi': hist.axis.Regular(20, -3.2, 3.2, name='var', label=r'sublead lepton $\\phi$', growth=False, underflow=False, overflow=False),\n",
    "    # diphoton variables\n",
    "    'pt': hist.axis.Regular(40, 20., 2000, name='var', label=r' $\\gamma\\gamma p_{T}$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    'eta': hist.axis.Regular(20, -5., 5., name='var', label=r'$\\gamma\\gamma \\eta$', growth=False, underflow=False, overflow=False), \n",
    "    'phi': hist.axis.Regular(20, -3.2, 3.2, name='var', label=r'$\\gamma \\gamma \\phi$', growth=False, underflow=False, overflow=False),\n",
    "    # angular (cos) variables\n",
    "    'abs_CosThetaStar_CS': hist.axis.Regular(20, 0, 1, name='var', label=r'|cos$(\\theta_{CS})$|', growth=False, underflow=False, overflow=False), \n",
    "    'abs_CosThetaStar_jj': hist.axis.Regular(20, 0, 1, name='var', label=r'|cos$(\\theta_{jj})$|', growth=False, underflow=False, overflow=False),\n",
    "    'CosThetaStar_CS': hist.axis.Regular(20, -1, 1, name='var', label=r'cos$(\\theta_{CS})$', growth=False, underflow=False, overflow=False), \n",
    "    'CosThetaStar_jj': hist.axis.Regular(20, -1, 1, name='var', label=r'cos$(\\theta_{jj})$', growth=False, underflow=False, overflow=False), \n",
    "    # jet-lepton variables\n",
    "    'leadBjet_leadLepton': hist.axis.Regular(30, 0, 5, name='var', label=r'$\\Delta R(bjet_{lead}, l_{lead})$', growth=False, underflow=False, overflow=False), \n",
    "    'leadBjet_subleadLepton': hist.axis.Regular(30, 0, 5, name='var', label=r'$\\Delta R(bjet_{lead}, l_{sublead})$', growth=False, underflow=False, overflow=False), \n",
    "    'subleadBjet_leadLepton': hist.axis.Regular(30, 0, 5, name='var', label=r'$\\Delta R(bjet_{sublead}, l_{lead})$', growth=False, underflow=False, overflow=False), \n",
    "    'subleadBjet_subleadLepton': hist.axis.Regular(30, 0, 5, name='var', label=r'$\\Delta R(bjet_{sublead}, l_{sublead})$', growth=False, underflow=False, overflow=False),\n",
    "    # dijet variables (must be blinded on data)\n",
    "    'dijet_mass': hist.axis.Regular(25, 25., 180., name='var', label=r'$M_{jj}$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    # diphoton variables (must be blinded on data)\n",
    "    'mass': hist.axis.Regular(25, 25., 180., name='var', label=r'$M_{\\gamma\\gamma}$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    # Yibo's BDT variables\n",
    "    'lead_mvaID': hist.axis.Regular(50, -1., 1., name='var', label=r'$\\gamma_{lead}$ MVA ID', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_mvaID': hist.axis.Regular(50, -1., 1., name='var', label=r'$\\gamma_{sublead}$ MVA ID', growth=False, underflow=False, overflow=False),\n",
    "    'CosThetaStar_gg': hist.axis.Regular(50, -1., 1., name='var', label=r'cos$(\\theta_{gg})$', growth=False, underflow=False, overflow=False),\n",
    "    'lead_pt_over_Mgg': hist.axis.Regular(50, 0., 1., name='var', label=r'$p_{T,\\gamma_1} / M_{\\gamma\\gamma}$', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_pt_over_Mgg': hist.axis.Regular(50, 0., 1., name='var', label=r'$p_{T,\\gamma_2} / M_{\\gamma\\gamma}$', growth=False, underflow=False, overflow=False),\n",
    "    'lead_sigmaE_over_E': hist.axis.Regular(50, 0., 0.06, name='var', label=r'$\\gamma_1 \\sigma {E} / E$', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_sigmaE_over_E': hist.axis.Regular(50, 0., 0.06, name='var', label=r'$\\gamma_2 \\sigma {E} / E$', growth=False, underflow=False, overflow=False),\n",
    "    'lead_bjet_pt_over_Mjj': hist.axis.Regular(50, 0., 4., name='var', label=r'$j1 p_{T} / M_{jj}$', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_bjet_pt_over_Mjj': hist.axis.Regular(50, 0., 2., name='var', label=r'$j2 p_{T} / M_{jj}$', growth=False, underflow=False, overflow=False),\n",
    "    'lead_bjet_btagPNetB': hist.axis.Regular(50, 0., 1., name='var', label=r'$j_{lead}$ PNet btag score', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_bjet_btagPNetB': hist.axis.Regular(50, 0., 1., name='var', label=r'$j_{sublead}$ PNet btag score', growth=False, underflow=False, overflow=False),\n",
    "    'lead_bjet_sigmapT_over_pT': hist.axis.Regular(50, 0., 0.02, name='var', label=r'$j1 \\sigma p_{T} / p_{T}$', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_bjet_sigmapT_over_pT': hist.axis.Regular(50, 0., 0.02, name='var', label=r'$j2 \\sigma p_{T} / p_{T}$', growth=False, underflow=False, overflow=False),\n",
    "    'dipho_mass_over_Mggjj': hist.axis.Regular(50, 0., 1., name='var', label=r'$M_{\\gamma\\gamma} / M_{\\gamma\\gamma jj}$', growth=False, underflow=False, overflow=False), \n",
    "    'dijet_mass_over_Mggjj': hist.axis.Regular(50, 0., 1., name='var', label=r'$M_{jj} / M_{\\gamma\\gamma jj}$', growth=False, underflow=False, overflow=False),\n",
    "    # My variables for non-reso reduction #\n",
    "    'lead_pfRelIso03_all_quadratic': hist.axis.Regular(50, -1., 1., name='var', label=r'$\\gamma_{lead}$ PF RelIso03 all quad.', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_pfRelIso03_all_quadratic': hist.axis.Regular(50, -1., 1., name='var', label=r'$\\gamma_{sublead}$ PF RelIso03 all quad.', growth=False, underflow=False, overflow=False),\n",
    "    # Michael's DNN variables #\n",
    "    'DeltaR_j1g1': hist.axis.Regular(50, 0., 5., name='var', label=r'$\\Delta R(bjet_{lead}, \\gamma_{lead})$', growth=False, underflow=False, overflow=False), \n",
    "    'DeltaR_j1g2': hist.axis.Regular(50, 0., 5., name='var', label=r'$\\Delta R(bjet_{lead}, \\gamma_{sublead})$', growth=False, underflow=False, overflow=False), \n",
    "    'DeltaR_j2g1': hist.axis.Regular(50, 0., 5., name='var', label=r'$\\Delta R(bjet_{sublead}, \\gamma_{lead})$', growth=False, underflow=False, overflow=False), \n",
    "    'DeltaR_j2g2': hist.axis.Regular(50, 0., 5., name='var', label=r'$\\Delta R(bjet_{sublead}, \\gamma_{sublead})$', growth=False, underflow=False, overflow=False),\n",
    "    'HHbbggCandidate_pt': hist.axis.Regular(100, 0., 700., name='var', label=r'HH $p_T$ [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'HHbbggCandidate_eta': hist.axis.Regular(50, -5., 5., name='var', label=r'HH $\\eta$', growth=False, underflow=False, overflow=False), \n",
    "    'HHbbggCandidate_phi': hist.axis.Regular(50, -3.2, 3.2, name='var', label=r'HH $\\phi$', growth=False, underflow=False, overflow=False),\n",
    "    'HHbbggCandidate_mass': hist.axis.Regular(25, 0., 700., name='var', label=r'$M_{HH}$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    # ATLAS variables #\n",
    "    'pt_balance': hist.axis.Regular(100, 0., 2., name='var', label=r'$p_{T,HH} / (p_{T,\\gamma1} + p_{T,\\gamma2} + p_{T,j1} + p_{T,j2})$', growth=False, underflow=False, overflow=False), \n",
    "    # VH variables #\n",
    "    'DeltaPhi_jj': hist.axis.Regular(20, -3.2, 3.2, name='var', label=r'$\\Delta\\phi (j_1,j_2)$', growth=False, underflow=False, overflow=False),\n",
    "    'DeltaEta_jj': hist.axis.Regular(20, 0., 10., name='var', label=r'$\\Delta\\eta (j_1,j_2)$', growth=False, underflow=False, overflow=False),\n",
    "    'isr_jet_pt': hist.axis.Regular(100, 0., 200., name='var', label=r'ISR jet $p_T$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    'DeltaPhi_isr_jet_z': hist.axis.Regular(20, -3.2, 3.2, name='var', label=r'$\\Delta\\phi (j_{ISR},jj)$', growth=False, underflow=False, overflow=False),\n",
    "    'dijet_pt': hist.axis.Regular(100, 0., 500., name='var', label=r'jj $p_T$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    'lepton1_pfIsoId': hist.axis.Integer(0, 12, name='var', label=r'$l_{lead}$ PF IsoId', growth=False, underflow=False, overflow=False), \n",
    "    'lepton1_mvaID': hist.axis.Regular(50, -1., 1., name='var', label=r'$\\l_{lead}$ MVA ID', growth=False, underflow=False, overflow=False), \n",
    "}\n",
    "# Dictionary of variables to do MC/Data comparison\n",
    "VARIABLES_STD = {\n",
    "    # key: hist.axis axes for plotting #\n",
    "    # MET variables\n",
    "    'puppiMET_sumEt': hist.axis.Regular(40, -4., 4., name='var', label=r'puppiMET ln($\\Sigma E_T$) [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'puppiMET_pt': hist.axis.Regular(40, -4., 4., name='var', label=r'puppiMET ln($p_T$) [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'puppiMET_phi': hist.axis.Regular(40, -4., 4., name='var', label=r'puppiMET $\\phi$', growth=False, underflow=False, overflow=False), \n",
    "    # jet-MET variables\n",
    "    'DeltaPhi_j1MET': hist.axis.Regular(40, -4., 4., name='var', label=r'$\\Delta\\phi (j_1,E_T^{miss})$', growth=False, underflow=False, overflow=False), \n",
    "    'DeltaPhi_j2MET': hist.axis.Regular(40, -4., 4., name='var', label=r'$\\Delta\\phi (j_2,E_T^{miss})$', growth=False, underflow=False, overflow=False), \n",
    "    # jet-photon variables\n",
    "    'DeltaR_jg_min': hist.axis.Regular(40, -4., 4., name='var', label=r'min$(\\Delta R(jet, \\gamma))$', growth=False, underflow=False, overflow=False), \n",
    "    # jet variables\n",
    "    'lead_bjet_pt': hist.axis.Regular(40, -4., 4., name='var', label=r'lead bjet ln($p_T$) [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_bjet_pt': hist.axis.Regular(40, -4., 4., name='var', label=r'sublead bjet ln($p_T$) [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'lead_bjet_eta': hist.axis.Regular(40, -4., 4., name='var', label=r'lead bjet $\\eta$', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_bjet_eta': hist.axis.Regular(40, -4., 4., name='var', label=r'sublead bjet $\\eta$', growth=False, underflow=False, overflow=False),\n",
    "    'lead_bjet_phi': hist.axis.Regular(40, -4., 4., name='var', label=r'lead bjet $\\phi$', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_bjet_phi': hist.axis.Regular(40, -4., 4., name='var', label=r'sublead bjet $\\phi$', growth=False, underflow=False, overflow=False),\n",
    "    'n_jets': hist.axis.Regular(12, -4., 4., name='var', label=r'$n_{jets}$', growth=False, underflow=False, overflow=False), \n",
    "    'chi_t0': hist.axis.Regular(40, -4., 10., name='var', label=r'ln($\\chi_{t0}^2$)', growth=False, underflow=False, overflow=False), \n",
    "    'chi_t1': hist.axis.Regular(40, -4., 10., name='var', label=r'ln($\\chi_{t1}^2$)', growth=False, underflow=False, overflow=False), \n",
    "    # lepton variables\n",
    "    'n_leptons': hist.axis.Regular(12, -4., 4., name='var', label=r'$n_{leptons}$', growth=False, underflow=False, overflow=False),\n",
    "    'lepton1_pt': hist.axis.Regular(40, -4., 4., name='var', label=r'lead lepton ln($p_T$) [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'lepton2_pt': hist.axis.Regular(40, -4., 4., name='var', label=r'sublead lepton ln($p_T$) [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'lepton1_eta': hist.axis.Regular(40, -4., 4., name='var', label=r'lead lepton $\\eta$', growth=False, underflow=False, overflow=False), \n",
    "    'lepton2_eta': hist.axis.Regular(40, -4., 4., name='var', label=r'sublead lepton $\\eta$', growth=False, underflow=False, overflow=False),\n",
    "    'lepton1_phi': hist.axis.Regular(40, -4., 4., name='var', label=r'lead lepton $\\phi$', growth=False, underflow=False, overflow=False), \n",
    "    'lepton2_phi': hist.axis.Regular(40, -4., 4., name='var', label=r'sublead lepton $\\phi$', growth=False, underflow=False, overflow=False),\n",
    "    # diphoton variables\n",
    "    'pt': hist.axis.Regular(40, -4., 4., name='var', label=r' $\\gamma\\gamma$ ln($p_{T}$) [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    'eta': hist.axis.Regular(40, -4., 4., name='var', label=r'$\\gamma\\gamma \\eta$', growth=False, underflow=False, overflow=False), \n",
    "    'phi': hist.axis.Regular(40, -4., 4., name='var', label=r'$\\gamma \\gamma \\phi$', growth=False, underflow=False, overflow=False),\n",
    "    # angular (cos) variables\n",
    "    'abs_CosThetaStar_CS': hist.axis.Regular(40, -4., 4., name='var', label=r'|cos$(\\theta_{CS})$|', growth=False, underflow=False, overflow=False), \n",
    "    'abs_CosThetaStar_jj': hist.axis.Regular(40, -4., 4., name='var', label=r'|cos$(\\theta_{jj})$|', growth=False, underflow=False, overflow=False), \n",
    "    'CosThetaStar_CS': hist.axis.Regular(40, -1., 1., name='var', label=r'cos$(\\theta_{CS})$', growth=False, underflow=False, overflow=False), \n",
    "    'CosThetaStar_jj': hist.axis.Regular(40, -1., 1., name='var', label=r'cos$(\\theta_{jj})$', growth=False, underflow=False, overflow=False), \n",
    "    # jet-lepton variables\n",
    "    'leadBjet_leadLepton': hist.axis.Regular(40, -4., 4., name='var', label=r'$\\Delta R(bjet_{lead}, l_{lead})$', growth=False, underflow=False, overflow=False), \n",
    "    'leadBjet_subleadLepton': hist.axis.Regular(40, -4., 4., name='var', label=r'$\\Delta R(bjet_{lead}, l_{sublead})$', growth=False, underflow=False, overflow=False), \n",
    "    'subleadBjet_leadLepton': hist.axis.Regular(40, -4., 4., name='var', label=r'$\\Delta R(bjet_{sublead}, l_{lead})$', growth=False, underflow=False, overflow=False), \n",
    "    'subleadBjet_subleadLepton': hist.axis.Regular(40, -4., 4., name='var', label=r'$\\Delta R(bjet_{sublead}, l_{sublead})$', growth=False, underflow=False, overflow=False),\n",
    "    # dijet variables (must be blinded on data)\n",
    "    'dijet_mass': hist.axis.Regular(40, -4., 4., name='var', label=r'ln($M_{jj}$) [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    # diphoton variables (must be blinded on data)\n",
    "    'mass': hist.axis.Regular(40, -4., 4., name='var', label=r'$M_{\\gamma\\gamma}$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    # Yibo's BDT variables\n",
    "    'lead_mvaID': hist.axis.Regular(50, -4., 4., name='var', label=r'$\\gamma_{lead}$ MVA ID', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_mvaID': hist.axis.Regular(50, -4., 4., name='var', label=r'$\\gamma_{sublead}$ MVA ID', growth=False, underflow=False, overflow=False),\n",
    "    'CosThetaStar_gg': hist.axis.Regular(50, -1., 1., name='var', label=r'cos$(\\theta_{gg})$', growth=False, underflow=False, overflow=False),\n",
    "    'lead_pt_over_Mgg': hist.axis.Regular(50, -4., 4., name='var', label=r'$p_{T,\\gamma_1} / M_{\\gamma\\gamma}$', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_pt_over_Mgg': hist.axis.Regular(50, -4., 4., name='var', label=r'$p_{T,\\gamma_2} / M_{\\gamma\\gamma}$', growth=False, underflow=False, overflow=False),\n",
    "    'lead_sigmaE_over_E': hist.axis.Regular(50, -4., 4., name='var', label=r'$\\gamma_1 \\sigma {E} / E$', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_sigmaE_over_E': hist.axis.Regular(50, -4., 4., name='var', label=r'$\\gamma_2 \\sigma {E} / E$', growth=False, underflow=False, overflow=False),\n",
    "    'lead_bjet_pt_over_Mjj': hist.axis.Regular(50, -4., 4., name='var', label=r'$p_{T,j1} / M_{jj}$', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_bjet_pt_over_Mjj': hist.axis.Regular(50, -4., 4., name='var', label=r'$p_{T,j2} / M_{jj}$', growth=False, underflow=False, overflow=False),\n",
    "    'lead_bjet_btagPNetB': hist.axis.Regular(50, -4., 4., name='var', label=r'$j_{lead}$ PNet btag score', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_bjet_btagPNetB': hist.axis.Regular(50, -4., 4., name='var', label=r'$j_{sublead}$ PNet btag score', growth=False, underflow=False, overflow=False),\n",
    "    'lead_bjet_sigmapT_over_pT': hist.axis.Regular(50, -4., 4., name='var', label=r'$j1 \\sigma p_{T} / p_{T}$', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_bjet_sigmapT_over_pT': hist.axis.Regular(50, -4., 4., name='var', label=r'$j2 \\sigma p_{T} / p_{T}$', growth=False, underflow=False, overflow=False),\n",
    "    'dipho_mass_over_Mggjj': hist.axis.Regular(50, -4., 4., name='var', label=r'$M_{\\gamma\\gamma} / M_{\\gamma\\gamma jj}$', growth=False, underflow=False, overflow=False), \n",
    "    'dijet_mass_over_Mggjj': hist.axis.Regular(50, -4., 4., name='var', label=r'$M_{jj} / M_{\\gamma\\gamma jj}$', growth=False, underflow=False, overflow=False),\n",
    "    # My variables for non-reso reduction #\n",
    "    'lead_pfRelIso03_all_quadratic': hist.axis.Regular(50, -4., 4., name='var', label=r'$\\gamma_{lead}$ PF RelIso03 all quad.', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_pfRelIso03_all_quadratic': hist.axis.Regular(50, -4., 4., name='var', label=r'$\\gamma_{sublead}$ PF RelIso03 all quad.', growth=False, underflow=False, overflow=False),\n",
    "    # Michael's DNN variables #\n",
    "    'DeltaR_j1g1': hist.axis.Regular(50, -4., 4., name='var', label=r'$\\Delta R(bjet_{lead}, \\gamma_{lead})$', growth=False, underflow=False, overflow=False), \n",
    "    'DeltaR_j1g2': hist.axis.Regular(50, -4., 4., name='var', label=r'$\\Delta R(bjet_{lead}, \\gamma_{sublead})$', growth=False, underflow=False, overflow=False), \n",
    "    'DeltaR_j2g1': hist.axis.Regular(50, -4., 4., name='var', label=r'$\\Delta R(bjet_{sublead}, \\gamma_{lead})$', growth=False, underflow=False, overflow=False), \n",
    "    'DeltaR_j2g2': hist.axis.Regular(50, -4., 4., name='var', label=r'$\\Delta R(bjet_{sublead}, \\gamma_{sublead})$', growth=False, underflow=False, overflow=False),\n",
    "    'HHbbggCandidate_pt': hist.axis.Regular(100, -4., 4., name='var', label=r'HH ln($p_T$) [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'HHbbggCandidate_eta': hist.axis.Regular(50, -4., 4., name='var', label=r'HH $\\eta$', growth=False, underflow=False, overflow=False), \n",
    "    'HHbbggCandidate_phi': hist.axis.Regular(50, -4., 4., name='var', label=r'HH $\\phi$', growth=False, underflow=False, overflow=False),\n",
    "    'HHbbggCandidate_mass': hist.axis.Regular(50, -4., 4., name='var', label=r'ln($M_{HH}$) [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    # ATLAS variables #\n",
    "    'pt_balance': hist.axis.Regular(100, -4., 4., name='var', label=r'ln($p_{T,HH} / (p_{T,\\gamma1} + p_{T,\\gamma2} + p_{T,j1} + p_{T,j2})$)', growth=False, underflow=False, overflow=False), \n",
    "    # VH variables #\n",
    "    'DeltaPhi_jj': hist.axis.Regular(20, -4., 4., name='var', label=r'$\\Delta\\phi (j_1,j_2)$', growth=False, underflow=False, overflow=False),\n",
    "    'DeltaEta_jj': hist.axis.Regular(20, -4., 4., name='var', label=r'$\\Delta\\eta (j_1,j_2)$', growth=False, underflow=False, overflow=False),\n",
    "    'isr_jet_pt': hist.axis.Regular(100, -4., 4., name='var', label=r'ISR jet ln($p_T$) [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    'DeltaPhi_isr_jet_z': hist.axis.Regular(20, -4., 4., name='var', label=r'$\\Delta\\phi (j_{ISR},jj)$', growth=False, underflow=False, overflow=False),\n",
    "    'dijet_pt': hist.axis.Regular(100, -4., 4., name='var', label=r'jj ln($p_T$) [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    'lepton1_pfIsoId': hist.axis.Regular(50, -4., 4., name='var', label=r'$l_{lead}$ PF IsoId', growth=False, underflow=False, overflow=False), \n",
    "    'lepton1_mvaID': hist.axis.Regular(50, -4., 4., name='var', label=r'$l_{lead}$ MVA ID', growth=False, underflow=False, overflow=False), \n",
    "}\n",
    "\n",
    "\n",
    "def make_input_plot(\n",
    "    output_dir, var_name, hist_list, fold_idx=None, labels=None, density=True, \n",
    "    plot_prefix='', plot_postfix='', alpha=0.8, linestyle=True\n",
    "):\n",
    "    fig, ax = plt.subplots()\n",
    "    if linestyle:\n",
    "        if fold_idx is not None:\n",
    "            linestyles = [\"solid\", \"dashed\", \"dotted\", \"solid\", \"dashed\", \"dotted\"]\n",
    "        else:\n",
    "            linestyles = [\"solid\", \"dotted\", \"solid\", \"dotted\"]\n",
    "        linestyles = linestyles * ((len(hist_list) // len(linestyles)) + 1)\n",
    "        linestyles = linestyles[:len(hist_list)]\n",
    "    else:\n",
    "        linestyles = None\n",
    "    hep.histplot(\n",
    "        hist_list, ax=ax, linewidth=3, histtype=\"step\", yerr=True, density=density,\n",
    "        linestyle=linestyles, label=labels, alpha=alpha\n",
    "    )\n",
    "    # Plotting niceties #\n",
    "    hep.cms.lumitext(f\"{LUMINOSITIES['total_lumi']:.2f}\" + r\"fb$^{-1}$ (13.6 TeV)\", ax=ax)\n",
    "    hep.cms.text(\"Work in Progress\", ax=ax)\n",
    "    # Plot legend properly\n",
    "    ax.legend(bbox_to_anchor=(1, 0.5))\n",
    "    # Make angular and chi^2 plots linear, otherwise log\n",
    "    if re.match('chi_t', var_name) is None and re.match('DeltaPhi', var_name) is None and re.match('mass', var_name) is None:\n",
    "        ax.set_yscale('log')\n",
    "    else:\n",
    "        ax.set_yscale('linear')\n",
    "    ax.set_yscale('linear')\n",
    "    # Save out the plot\n",
    "    if fold_idx is not None:\n",
    "        plt.savefig(f'{output_dir}/{plot_prefix}1dhist_{var_name}{plot_postfix}_fold{fold_idx}.pdf', bbox_inches='tight')\n",
    "        plt.savefig(f'{output_dir}/{plot_prefix}1dhist_{var_name}{plot_postfix}_fold{fold_idx}.png', bbox_inches='tight')\n",
    "    else:\n",
    "        plt.savefig(f'{output_dir}/{plot_prefix}1dhist_{var_name}{plot_postfix}.pdf', bbox_inches='tight')\n",
    "        plt.savefig(f'{output_dir}/{plot_prefix}1dhist_{var_name}{plot_postfix}.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss per Epoch Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"losses\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "if 'BDT_perf' not in globals():\n",
    "    with open(os.path.join(OUTPUT_DIRPATH, CURRENT_TIME+\"_BDT_perf.json\"), 'r') as f:\n",
    "        BDT_perf = json.load(f)\n",
    "\n",
    "if 'evals_result_dict' not in globals():\n",
    "    with open(os.path.join(OUTPUT_DIRPATH, CURRENT_TIME+\"_BDT_eval_result.json\"), 'r') as f:\n",
    "        evals_result_dict = json.load(f)\n",
    "\n",
    "# plot train/val/test losses\n",
    "all_train, all_val, all_test = [], [], []\n",
    "for fold_idx in range(len(evals_result_dict)):\n",
    "    all_train.append(evals_result_dict[f\"fold_{fold_idx}\"]['train']['mlogloss'])\n",
    "    all_val.append(evals_result_dict[f\"fold_{fold_idx}\"]['val']['mlogloss'])\n",
    "    all_test.append(evals_result_dict[f\"fold_{fold_idx}\"]['test']['mlogloss'])\n",
    "\n",
    "plot_train_val_losses(\n",
    "    all_train + all_val, [f'train fold {i}' for i in range(len(all_train))]+[f'val fold {i}' for i in range(len(all_val))],\n",
    "    'train_val_losses_vs_epoch', plot_dirpath, \n",
    "    linestyles=['solid']*len(all_train) + ['dashed']*len(all_val),\n",
    ")\n",
    "plot_train_val_losses(\n",
    "    all_train + all_test, [f'train fold {i}' for i in range(len(all_train))]+[f'test fold {i}' for i in range(len(all_test))],\n",
    "    'train_test_losses_vs_epoch', plot_dirpath,\n",
    "    linestyles=['solid']*len(all_train) + ['dotted']*len(all_test),\n",
    ")\n",
    "avg_train, avg_val, avg_test = np.mean(pad_list(all_train), axis=0), np.mean(pad_list(all_val), axis=0), np.mean(pad_list(all_test), axis=0)\n",
    "std_train, std_val, std_test = np.std(pad_list(all_train), axis=0), np.std(pad_list(all_val), axis=0), np.std(pad_list(all_test), axis=0)\n",
    "plot_train_val_losses(\n",
    "    [avg_train, avg_val, avg_test], ['train avg', 'val avg', 'test avg'],\n",
    "    'train_val_test_avg_vs_epoch', plot_dirpath,\n",
    "    losses_std_arrs=[std_train, std_val, std_test],\n",
    "    linestyles=['solid', 'dashed', 'dotted'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"ROCs\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "if 'BDT_perf' not in globals():\n",
    "    with open(os.path.join(OUTPUT_DIRPATH, CURRENT_TIME+\"_BDT_perf.json\"), 'r') as f:\n",
    "        BDT_perf = json.load(f)\n",
    "\n",
    "base_tpr = np.array(BDT_perf['ggF HH']['base_tpr'])\n",
    "\n",
    "# plot ROCs\n",
    "for j, sample_name in enumerate(order):\n",
    "\n",
    "    for fold_idx in range(len(bdt_train_dict)):\n",
    "\n",
    "        for roc_type in ['density', 'weighted']:\n",
    "\n",
    "            fprs = [np.array(BDT_perf[sample_name][f'fprs_{roc_type}'][fold_idx])[:, i] for i in range(len(order))]\n",
    "            tprs = [base_tpr for _ in range(len(order))]\n",
    "            labels = [\n",
    "                f\"{sample_name} vs. {'all' if i == j else sample_name_}, AUC = {BDT_perf[sample_name][f'areas_{roc_type}'][fold_idx][i]:.4f}\" \n",
    "                for i, sample_name_ in enumerate(order)\n",
    "            ]\n",
    "\n",
    "            plot_rocs(fprs, tprs, labels, f\"BDT_roc_{sample_name}_{roc_type}_testData_fold{fold_idx}\", plot_dirpath)\n",
    "\n",
    "    for roc_type in ['sum_density', 'sum_weighted']:\n",
    "\n",
    "        fprs = [np.array(BDT_perf[sample_name][f'fprs_{roc_type}'])[:, i] for i in range(len(order))]\n",
    "        tprs = [base_tpr for _ in range(len(order))]\n",
    "        labels = [\n",
    "            f\"{sample_name} vs. {'all' if i == j else sample_name_}, AUC = {BDT_perf[sample_name][f'areas_{roc_type}'][i]:.4f}\" \n",
    "            for i, sample_name_ in enumerate(order)\n",
    "        ]\n",
    "\n",
    "        plot_rocs(fprs, tprs, labels, f\"BDT_roc_{sample_name}_{roc_type}_testData_sum\", plot_dirpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Score Dist Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"output_scores\")\n",
    "# plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"output_scores_arctanh\")\n",
    "# plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"output_scores_resample\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "if 'BDT_perf' not in globals():\n",
    "    with open(os.path.join(OUTPUT_DIRPATH, CURRENT_TIME+\"_BDT_perf.json\"), 'r') as f:\n",
    "        BDT_perf = json.load(f)\n",
    "\n",
    "# plot Output scores\n",
    "for j, sample_name in enumerate(order):\n",
    "\n",
    "    for i, sample_name_ in enumerate(order):\n",
    "\n",
    "        for fold_idx in range(len(bdt_train_dict)):\n",
    "            \n",
    "            sigs_and_bkgs = {\n",
    "                sample_name__: np.array(BDT_perf[sample_name]['preds'][fold_idx])[:, j][bdt_test_dict[f\"fold_{fold_idx}\"].get_label() == k]\n",
    "                for k, sample_name__ in enumerate(order)\n",
    "            }\n",
    "            score_weights = {\n",
    "                sample_name__: weights_plot_test[f\"fold_{fold_idx}\"][bdt_test_dict[f\"fold_{fold_idx}\"].get_label() == k]\n",
    "                for k, sample_name__ in enumerate(order)\n",
    "            }\n",
    "\n",
    "            if sample_name_ != sample_name:\n",
    "                event_j_mask = bdt_test_dict[f\"fold_{fold_idx}\"].get_label() == j\n",
    "                pred_j_rescale = np.array(BDT_perf[sample_name]['preds'][fold_idx])[:, j][event_j_mask] + np.array(BDT_perf[sample_name]['preds'][fold_idx])[:, i][event_j_mask]\n",
    "                event_i_mask = bdt_test_dict[f\"fold_{fold_idx}\"].get_label() == i\n",
    "                pred_i_rescale = np.array(BDT_perf[sample_name]['preds'][fold_idx])[:, j][event_i_mask] + np.array(BDT_perf[sample_name]['preds'][fold_idx])[:, i][event_i_mask]\n",
    "\n",
    "                for sample_name__ in order:\n",
    "                    if sample_name__ == sample_name:\n",
    "                        sigs_and_bkgs[sample_name__] = sigs_and_bkgs[sample_name__] / pred_j_rescale\n",
    "                    elif sample_name__ == sample_name_:\n",
    "                        sigs_and_bkgs[sample_name__] = sigs_and_bkgs[sample_name__] / pred_i_rescale\n",
    "                    else:\n",
    "                        del sigs_and_bkgs[sample_name__]\n",
    "                        del score_weights[sample_name__]\n",
    "\n",
    "            if re.search('arctanh', plot_dirpath) is not None:\n",
    "                for key, value in sigs_and_bkgs.items():\n",
    "                    sigs_and_bkgs[key] = np.arctanh(value)\n",
    "\n",
    "            plot_output_scores(\n",
    "                sigs_and_bkgs, order, \n",
    "                f\"BDT_{sample_name}_vs_{sample_name_ if sample_name_ != sample_name else 'all'}_outputScoreWeighted_testData_fold{fold_idx}\", \n",
    "                plot_dirpath, weights=score_weights, log=True,\n",
    "                arctanh=True if re.search('arctanh', plot_dirpath) is not None else False\n",
    "            )\n",
    "            plot_output_scores(\n",
    "                sigs_and_bkgs, order, \n",
    "                f\"BDT_{sample_name}_vs_{sample_name_ if sample_name_ != sample_name else 'all'}_outputScoreDensity_testData_fold{fold_idx}\", \n",
    "                plot_dirpath, log=True,\n",
    "                arctanh=True if re.search('arctanh', plot_dirpath) is not None else False\n",
    "            )\n",
    "\n",
    "        flat_preds = np.concatenate([BDT_perf[sample_name]['preds'][fold_idx] for fold_idx in range(len(bdt_test_dict))], axis=0)\n",
    "        if re.search('arctanh', plot_dirpath) is not None:\n",
    "            flat_preds = np.arctanh(flat_preds)\n",
    "        flat_truths = np.concatenate([bdt_test_dict[f\"fold_{fold_idx}\"].get_label() for fold_idx in range(len(bdt_test_dict))], axis=0)\n",
    "        flat_weights = np.concatenate([weights_plot_test[f\"fold_{fold_idx}\"] for fold_idx in range(len(bdt_test_dict))], axis=0)\n",
    "\n",
    "        sigs_and_bkgs = {\n",
    "            sample_name__: flat_preds[:, j][flat_truths == k]\n",
    "            for k, sample_name__ in enumerate(order)\n",
    "        }\n",
    "        score_weights = {\n",
    "            sample_name__: flat_weights[flat_truths == k]\n",
    "            for k, sample_name__ in enumerate(order)\n",
    "        }\n",
    "        \n",
    "        if sample_name_ != sample_name:\n",
    "            event_j_mask = flat_truths == j\n",
    "            pred_j_rescale = (flat_preds[:, j] + flat_preds[:, i])[event_j_mask]\n",
    "            event_i_mask = flat_truths == i\n",
    "            pred_i_rescale = (flat_preds[:, j] + flat_preds[:, i])[event_i_mask]\n",
    "\n",
    "            for sample_name__ in order:\n",
    "                if sample_name__ == sample_name:\n",
    "                    sigs_and_bkgs[sample_name__] = sigs_and_bkgs[sample_name__] / pred_j_rescale\n",
    "                elif sample_name__ == sample_name_:\n",
    "                    sigs_and_bkgs[sample_name__] = sigs_and_bkgs[sample_name__] / pred_i_rescale\n",
    "                else:\n",
    "                    del sigs_and_bkgs[sample_name__]\n",
    "                    del score_weights[sample_name__]\n",
    "        \n",
    "        plot_output_scores(\n",
    "            sigs_and_bkgs, order, \n",
    "            f\"BDT_{sample_name}_vs_{sample_name_ if sample_name_ != sample_name else 'all'}_outputScoreWeighted_testData_sum\", \n",
    "            plot_dirpath, weights=score_weights, log=True,\n",
    "            arctanh=True if re.search('arctanh', plot_dirpath) is not None else False\n",
    "        )\n",
    "        plot_output_scores(\n",
    "            sigs_and_bkgs, order, \n",
    "            f\"BDT_{sample_name}_vs_{sample_name_ if sample_name_ != sample_name else 'all'}_outputScoreDensity_testData_sum\", \n",
    "            plot_dirpath, log=True,\n",
    "            arctanh=True if re.search('arctanh', plot_dirpath) is not None else False\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### s/âb Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "============================================================\n",
      "Cat1: 0.9983 < ggF HH score â¤ 1.0000 AND 120 GeV < m_HH < 130 GeV\n",
      "------------------------------------------------------------\n",
      "Cat1: Num ggF HH = 0.3087\n",
      "------------------------------------------------------------\n",
      "Cat1: Num ttH + bbH = 0.0143\n",
      "------------------------------------------------------------\n",
      "Cat1: Num VH = 0.0255\n",
      "------------------------------------------------------------\n",
      "Cat1: Num VH, no ZH or WH = 0.0145\n",
      "------------------------------------------------------------\n",
      "Cat1: Num non-res + ggFH + VBFH = 0.4196\n",
      "------------------------------------------------------------\n",
      "Cat1: Num GluGluHToGG = 0.0496\n",
      "------------------------------------------------------------\n",
      "Cat1: Num VBFHToGG = 0.0056\n",
      "------------------------------------------------------------\n",
      "Cat1: Num GGJets = 0.3644\n",
      "------------------------------------------------------------\n",
      "Cat1: Num GJetPt20To40 = 0.0000\n",
      "------------------------------------------------------------\n",
      "Cat1: Num GJetPt40 = 0.0000\n",
      "------------------------------------------------------------\n",
      "Cat1: S = 0.3087, B = 0.4594, S/âB = 0.4555\n",
      "============================================================\n",
      "============================================================\n",
      "Cat2: 0.9957 < ggF HH score â¤ 0.9983 AND 120 GeV < m_HH < 130 GeV\n",
      "------------------------------------------------------------\n",
      "Cat2: Num ggF HH = 0.2356\n",
      "------------------------------------------------------------\n",
      "Cat2: Num ttH + bbH = 0.0489\n",
      "------------------------------------------------------------\n",
      "Cat2: Num VH = 0.0743\n",
      "------------------------------------------------------------\n",
      "Cat2: Num VH, no ZH or WH = 0.0547\n",
      "------------------------------------------------------------\n",
      "Cat2: Num non-res + ggFH + VBFH = 1.8601\n",
      "------------------------------------------------------------\n",
      "Cat2: Num GluGluHToGG = 0.1266\n",
      "------------------------------------------------------------\n",
      "Cat2: Num VBFHToGG = 0.0140\n",
      "------------------------------------------------------------\n",
      "Cat2: Num GGJets = 1.0138\n",
      "------------------------------------------------------------\n",
      "Cat2: Num GJetPt20To40 = 0.0000\n",
      "------------------------------------------------------------\n",
      "Cat2: Num GJetPt40 = 0.7057\n",
      "------------------------------------------------------------\n",
      "Cat2: S = 0.2356, B = 1.9833, S/âB = 0.1673\n",
      "============================================================\n",
      "============================================================\n",
      "Cat3: 0.9894 < ggF HH score â¤ 0.9957 AND 120 GeV < m_HH < 130 GeV\n",
      "------------------------------------------------------------\n",
      "Cat3: Num ggF HH = 0.2785\n",
      "------------------------------------------------------------\n",
      "Cat3: Num ttH + bbH = 0.1705\n",
      "------------------------------------------------------------\n",
      "Cat3: Num VH = 0.2396\n",
      "------------------------------------------------------------\n",
      "Cat3: Num VH, no ZH or WH = 0.1924\n",
      "------------------------------------------------------------\n",
      "Cat3: Num non-res + ggFH + VBFH = 3.9019\n",
      "------------------------------------------------------------\n",
      "Cat3: Num GluGluHToGG = 0.6358\n",
      "------------------------------------------------------------\n",
      "Cat3: Num VBFHToGG = 0.0489\n",
      "------------------------------------------------------------\n",
      "Cat3: Num GGJets = 3.0773\n",
      "------------------------------------------------------------\n",
      "Cat3: Num GJetPt20To40 = 0.0000\n",
      "------------------------------------------------------------\n",
      "Cat3: Num GJetPt40 = 0.1399\n",
      "------------------------------------------------------------\n",
      "Cat3: S = 0.2785, B = 4.3120, S/âB = 0.1341\n",
      "============================================================\n",
      "============================================================\n",
      "Cat1: 0.9983 < ggF HH score â¤ 1.0000\n",
      "------------------------------------------------------------\n",
      "Cat1: Num ggF HH = 0.3185\n",
      "------------------------------------------------------------\n",
      "Cat1: Num ttH + bbH = 0.0147\n",
      "------------------------------------------------------------\n",
      "Cat1: Num VH = 0.0277\n",
      "------------------------------------------------------------\n",
      "Cat1: Num VH, no ZH or WH = 0.0163\n",
      "------------------------------------------------------------\n",
      "Cat1: Num non-res + ggFH + VBFH = 3.9303\n",
      "------------------------------------------------------------\n",
      "Cat1: Num GluGluHToGG = 0.0531\n",
      "------------------------------------------------------------\n",
      "Cat1: Num VBFHToGG = 0.0058\n",
      "------------------------------------------------------------\n",
      "Cat1: Num GGJets = 3.0767\n",
      "------------------------------------------------------------\n",
      "Cat1: Num GJetPt20To40 = 0.0000\n",
      "------------------------------------------------------------\n",
      "Cat1: Num GJetPt40 = 0.7947\n",
      "------------------------------------------------------------\n",
      "Cat1: S = 0.3185, B = 3.9728, S/âB = 0.1598\n",
      "============================================================\n",
      "============================================================\n",
      "Cat2: 0.9957 < ggF HH score â¤ 0.9983\n",
      "------------------------------------------------------------\n",
      "Cat2: Num ggF HH = 0.2445\n",
      "------------------------------------------------------------\n",
      "Cat2: Num ttH + bbH = 0.0511\n",
      "------------------------------------------------------------\n",
      "Cat2: Num VH = 0.0771\n",
      "------------------------------------------------------------\n",
      "Cat2: Num VH, no ZH or WH = 0.0565\n",
      "------------------------------------------------------------\n",
      "Cat2: Num non-res + ggFH + VBFH = 13.4524\n",
      "------------------------------------------------------------\n",
      "Cat2: Num GluGluHToGG = 0.1285\n",
      "------------------------------------------------------------\n",
      "Cat2: Num VBFHToGG = 0.0151\n",
      "------------------------------------------------------------\n",
      "Cat2: Num GGJets = 9.7085\n",
      "------------------------------------------------------------\n",
      "Cat2: Num GJetPt20To40 = 0.0000\n",
      "------------------------------------------------------------\n",
      "Cat2: Num GJetPt40 = 3.6002\n",
      "------------------------------------------------------------\n",
      "Cat2: S = 0.2445, B = 13.5805, S/âB = 0.0663\n",
      "============================================================\n",
      "============================================================\n",
      "Cat3: 0.9894 < ggF HH score â¤ 0.9957\n",
      "------------------------------------------------------------\n",
      "Cat3: Num ggF HH = 0.2899\n",
      "------------------------------------------------------------\n",
      "Cat3: Num ttH + bbH = 0.1785\n",
      "------------------------------------------------------------\n",
      "Cat3: Num VH = 0.2554\n",
      "------------------------------------------------------------\n",
      "Cat3: Num VH, no ZH or WH = 0.2062\n",
      "------------------------------------------------------------\n",
      "Cat3: Num non-res + ggFH + VBFH = 60.7253\n",
      "------------------------------------------------------------\n",
      "Cat3: Num GluGluHToGG = 0.6569\n",
      "------------------------------------------------------------\n",
      "Cat3: Num VBFHToGG = 0.0523\n",
      "------------------------------------------------------------\n",
      "Cat3: Num GGJets = 36.4154\n",
      "------------------------------------------------------------\n",
      "Cat3: Num GJetPt20To40 = 0.0000\n",
      "------------------------------------------------------------\n",
      "Cat3: Num GJetPt40 = 23.6008\n",
      "------------------------------------------------------------\n",
      "Cat3: S = 0.2899, B = 61.1593, S/âB = 0.0371\n"
     ]
    }
   ],
   "source": [
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"s_over_rootb\")\n",
    "# plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"s_over_rootb_arctanh\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "if 'BDT_perf' not in globals():\n",
    "    with open(os.path.join(OUTPUT_DIRPATH, CURRENT_TIME+\"_BDT_perf.json\"), 'r') as f:\n",
    "        BDT_perf = json.load(f)\n",
    "\n",
    "# plot s/âb curves\n",
    "for j, sample_name in enumerate(order):\n",
    "\n",
    "    for i, sample_name_ in enumerate(order):\n",
    "\n",
    "        for fold_idx in range(len(BDT_perf['ggF HH']['preds'])):\n",
    "\n",
    "            if sample_name_ == sample_name:\n",
    "                sig_mask = bdt_test_dict[f\"fold_{fold_idx}\"].get_label() == j\n",
    "                bkg_mask = bdt_test_dict[f\"fold_{fold_idx}\"].get_label() != j\n",
    "\n",
    "                sig_rescale = np.ones_like(sig_mask)\n",
    "                bkg_rescale = np.ones_like(bkg_mask)\n",
    "            else:\n",
    "                sig_mask = bdt_test_dict[f\"fold_{fold_idx}\"].get_label() == j\n",
    "                bkg_mask = bdt_test_dict[f\"fold_{fold_idx}\"].get_label() == i\n",
    "\n",
    "                sig_rescale = (\n",
    "                    np.array(BDT_perf[sample_name]['preds'][fold_idx])[:, j] \n",
    "                    + np.array(BDT_perf[sample_name]['preds'][fold_idx])[:, i]\n",
    "                )\n",
    "                bkg_rescale = (\n",
    "                    np.array(BDT_perf[sample_name]['preds'][fold_idx])[:, j] \n",
    "                    + np.array(BDT_perf[sample_name]['preds'][fold_idx])[:, i]\n",
    "                )\n",
    "\n",
    "            sigs_and_bkgs = {\n",
    "                'sig': (np.array(BDT_perf[sample_name]['preds'][fold_idx])[:, j] / sig_rescale)[sig_mask],\n",
    "                'bkg': (np.array(BDT_perf[sample_name]['preds'][fold_idx])[:, j] / bkg_rescale)[bkg_mask]\n",
    "            }\n",
    "            if re.search('arctanh', plot_dirpath) is not None:\n",
    "                sigs_and_bkgs['sig'] = np.arctanh(sigs_and_bkgs['sig'])\n",
    "                sigs_and_bkgs['bkg'] = np.arctanh(sigs_and_bkgs['bkg'])\n",
    "            score_weights = {\n",
    "                'sig': weights_plot_test[f\"fold_{fold_idx}\"][sig_mask],\n",
    "                'bkg': weights_plot_test[f\"fold_{fold_idx}\"][bkg_mask]\n",
    "            }\n",
    "\n",
    "\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\")\n",
    "                plot_s_over_root_b(\n",
    "                    sigs_and_bkgs['sig'], sigs_and_bkgs['bkg'], f\"{sample_name} vs. {sample_name_ if sample_name_ != sample_name else 'all'}\", \n",
    "                    f\"BDT_{sample_name}_vs_{sample_name_ if sample_name_ != sample_name else 'all'}_sOverRootb_testData_fold{fold_idx}\", \n",
    "                    plot_dirpath, weights=score_weights,\n",
    "                    arctanh=True if re.search('arctanh', plot_dirpath) is not None else False  \n",
    "                )\n",
    "\n",
    "                (\n",
    "                    cut_boundaries_fold, cut_s_over_root_bs_fold, sig_weights_fold, bkg_weights_fold\n",
    "                ) = optimize_cut_boundaries(\n",
    "                    sigs_and_bkgs['sig'], sigs_and_bkgs['bkg'], score_weights,\n",
    "                    arctanh=True if re.search('arctanh', plot_dirpath) is not None else False\n",
    "                )\n",
    "\n",
    "                BDT_cut_labels = [\n",
    "                    f\"cut={cut_boundaries_fold[0][cut_idx]:.4f}: s/âb={cut_s_over_root_bs_fold[0][cut_idx]:.5f}, s={sig_weights_fold[0][cut_idx]['value']:.5f}Â±{sig_weights_fold[0][cut_idx]['w2']:.5f}, b={bkg_weights_fold[0][cut_idx]['value']:.5f}Â±{bkg_weights_fold[0][cut_idx]['w2']:.5f}\" for cut_idx in range(len(cut_s_over_root_bs_fold[0]))\n",
    "                ]\n",
    "                line_labels = BDT_cut_labels[:10]\n",
    "                lines = cut_boundaries_fold[0][:10]\n",
    "                line_colors = cmap_petroff10\n",
    "\n",
    "                plot_s_over_root_b(\n",
    "                    sigs_and_bkgs['sig'], sigs_and_bkgs['bkg'], f\"{sample_name} vs. {sample_name_ if sample_name_ != sample_name else 'all'}\", \n",
    "                    f\"BDT_{sample_name}_vs_{sample_name_ if sample_name_ != sample_name else 'all'}_sOverRootb_withCuts_testData_fold{fold_idx}_{sample_name}\", plot_dirpath, \n",
    "                    weights=score_weights,\n",
    "                    lines=lines, lines_labels=line_labels, line_colors=line_colors,\n",
    "                    arctanh=True if re.search('arctanh', plot_dirpath) is not None else False\n",
    "                )\n",
    "            \n",
    "        flat_preds = np.concatenate([BDT_perf[sample_name]['preds'][fold_idx] for fold_idx in range(len(BDT_perf['ggF HH']['preds']))], axis=0)\n",
    "        if re.search('arctanh', plot_dirpath) is not None:\n",
    "            flat_preds = np.arctanh(flat_preds)\n",
    "        flat_truths = np.concatenate([bdt_test_dict[f\"fold_{fold_idx}\"].get_label() for fold_idx in range(len(BDT_perf['ggF HH']['preds']))], axis=0)\n",
    "        flat_weights = np.concatenate([weights_plot_test[f\"fold_{fold_idx}\"] for fold_idx in range(len(BDT_perf['ggF HH']['preds']))], axis=0)\n",
    "        flat_sample_names = np.concatenate([data_test_aux_dict[f\"fold_{fold_idx}\"]['sample_name'] for fold_idx in range(len(BDT_perf['ggF HH']['preds']))], axis=0)\n",
    "\n",
    "        if sample_name_ == sample_name:\n",
    "            sig_mask = flat_truths == j\n",
    "            bkg_mask = flat_truths != j\n",
    "\n",
    "            sig_rescale = np.ones_like(sig_mask)\n",
    "            bkg_rescale = np.ones_like(bkg_mask)\n",
    "        else:\n",
    "            sig_mask = flat_truths == j\n",
    "            bkg_mask = flat_truths == i\n",
    "\n",
    "            sig_rescale = flat_preds[:, j] + flat_preds[:, i]\n",
    "            bkg_rescale = flat_preds[:, j] + flat_preds[:, i]\n",
    "\n",
    "        sigs_and_bkgs = {\n",
    "            'sig': (flat_preds[:, j] / sig_rescale)[sig_mask],\n",
    "            'bkg': (flat_preds[:, j] / bkg_rescale)[bkg_mask]\n",
    "        }\n",
    "        score_weights = {\n",
    "            'sig': flat_weights[sig_mask],\n",
    "            'bkg': flat_weights[bkg_mask]\n",
    "        }\n",
    "\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            plot_s_over_root_b(\n",
    "                sigs_and_bkgs['sig'], sigs_and_bkgs['bkg'], f\"{sample_name} vs. {sample_name_ if sample_name_ != sample_name else 'all'}\", \n",
    "                f\"BDT_{sample_name}_vs_{sample_name_ if sample_name_ != sample_name else 'all'}_sOverRootb_testData_sum\", \n",
    "                plot_dirpath, weights=score_weights,\n",
    "                arctanh=True if re.search('arctanh', plot_dirpath) is not None else False\n",
    "            )\n",
    "\n",
    "            (\n",
    "                cut_boundaries_fold, cut_s_over_root_bs_fold, sig_weights_fold, bkg_weights_fold\n",
    "            ) = optimize_cut_boundaries(\n",
    "                sigs_and_bkgs['sig'], sigs_and_bkgs['bkg'], score_weights,\n",
    "                arctanh=True if re.search('arctanh', plot_dirpath) is not None else False\n",
    "            )\n",
    "\n",
    "            BDT_cut_labels = [\n",
    "                f\"cut={cut_boundaries_fold[0][cut_idx]:.4f}: s/âb={cut_s_over_root_bs_fold[0][cut_idx]:.5f}, s={sig_weights_fold[0][cut_idx]['value']:.5f}Â±{sig_weights_fold[0][cut_idx]['w2']:.5f}, b={bkg_weights_fold[0][cut_idx]['value']:.5f}Â±{bkg_weights_fold[0][cut_idx]['w2']:.5f}\" for cut_idx in range(len(cut_s_over_root_bs_fold[0]))\n",
    "            ]\n",
    "            line_labels = BDT_cut_labels[:10]\n",
    "            lines = cut_boundaries_fold[0][:10]\n",
    "            line_colors = cmap_petroff10\n",
    "\n",
    "            plot_s_over_root_b(\n",
    "                sigs_and_bkgs['sig'], sigs_and_bkgs['bkg'], f\"{sample_name} vs. {sample_name_ if sample_name_ != sample_name else 'all'}\", \n",
    "                f\"BDT_{sample_name}_vs_{sample_name_ if sample_name_ != sample_name else 'all'}_sOverRootb_withCuts_testData_sum\", plot_dirpath, \n",
    "                weights=score_weights,\n",
    "                lines=lines, lines_labels=line_labels, line_colors=line_colors,\n",
    "                arctanh=True if re.search('arctanh', plot_dirpath) is not None else False\n",
    "            )\n",
    "\n",
    "        if j == 0 and i == 0:\n",
    "            flat_mass = np.concatenate([data_test_aux_dict[f\"fold_{fold_idx}\"]['mass'] for fold_idx in range(len(BDT_perf['ggF HH']['preds']))], axis=0)\n",
    "            if re.search('arctanh', plot_dirpath) is not None:\n",
    "                cat_lines = [6.0] + lines[:3]\n",
    "            else:\n",
    "                cat_lines = [1.0] + lines[:3]\n",
    "            cat_num_samples = {}\n",
    "            for k, cat in enumerate(['Cat1', 'Cat2', 'Cat3']):\n",
    "                cat_num_samples[cat] = {}\n",
    "                print('='*60)\n",
    "                print('='*60)\n",
    "                print(f\"{cat}: {cat_lines[k+1]:.4f} < ggF HH score â¤ {cat_lines[k]:.4f} AND 120 GeV < m_HH < 130 GeV\")\n",
    "                print('-'*60)\n",
    "                for m, sample_name in enumerate(order):\n",
    "                    sample_bool = np.logical_and(  # event passes conditions and is the right type (i.e. sample)\n",
    "                        np.logical_and(  # event passes category and mass conditions\n",
    "                            np.logical_and(  # prediction is within category bounds\n",
    "                                flat_preds[:, 0] <= cat_lines[k],\n",
    "                                flat_preds[:, 0] > cat_lines[k+1]\n",
    "                            ),\n",
    "                            np.logical_and(  # diphoton mass is within 120-130 window\n",
    "                                flat_mass < 130,\n",
    "                                flat_mass > 120\n",
    "                            ),\n",
    "                        ),\n",
    "                        flat_truths == m\n",
    "                    )\n",
    "                    cat_num_samples[cat][sample_name] = np.sum(\n",
    "                        flat_weights[sample_bool]\n",
    "                    )\n",
    "                    print(f\"{cat}: Num {sample_name} = {cat_num_samples[cat][sample_name]:.4f}\")\n",
    "                    print('-'*60)\n",
    "                    if sample_name == order[-1]:\n",
    "                        for smpl in [\n",
    "                            ['GluGluHToGG', 'GluGlutoHHto2B2G_kl_1p00_kt_1p00_c2_0p00'],\n",
    "                            ['VBFHToGG', 'VBFHToGG_M_125'],\n",
    "                            ['GGJets'], ['GJetPt20To40'], ['GJetPt40']\n",
    "                        ]:\n",
    "                            smpl_num = 0\n",
    "                            for smpl_ in smpl:\n",
    "                                smpl_num += np.sum(\n",
    "                                    flat_weights[\n",
    "                                        np.logical_and(\n",
    "                                            sample_bool,\n",
    "                                            flat_sample_names == smpl_\n",
    "                                        )\n",
    "                                    ]\n",
    "                                )\n",
    "                            print(f\"{cat}: Num {smpl[0]} = {smpl_num:.4f}\")\n",
    "                            print('-'*60)\n",
    "                    elif sample_name == order[-2]:\n",
    "                        smpl_num = np.sum(\n",
    "                            flat_weights[\n",
    "                                np.logical_and(\n",
    "                                    sample_bool,\n",
    "                                    np.logical_or(\n",
    "                                        flat_sample_names == 'VHToGG',\n",
    "                                        flat_sample_names == 'VHtoGG_M_125'\n",
    "                                    )\n",
    "                                )\n",
    "                            ]\n",
    "                        )\n",
    "                        print(f\"{cat}: Num VH, no ZH or WH = {smpl_num:.4f}\")\n",
    "                        print('-'*60)\n",
    "\n",
    "                print(f\"{cat}: S = {cat_num_samples[cat][order[0]]:.4f}, B = {np.sum([cat_num_samples[cat][order[v]] for v in range(1, len(order))]):.4f}, S/âB = {(cat_num_samples[cat][order[0]] / np.sqrt(np.sum([cat_num_samples[cat][order[v]] for v in range(1, len(order))]))):.4f}\")\n",
    "\n",
    "            for k, cat in enumerate(['Cat1', 'Cat2', 'Cat3']):\n",
    "                cat_num_samples[cat] = {}\n",
    "                print('='*60)\n",
    "                print('='*60)\n",
    "                print(f\"{cat}: {cat_lines[k+1]:.4f} < ggF HH score â¤ {cat_lines[k]:.4f}\")\n",
    "                print('-'*60)\n",
    "                for m, sample_name in enumerate(order):\n",
    "                    sample_bool = np.logical_and(  # event passes conditions and is the right type (i.e. sample)\n",
    "                        np.logical_and(  # prediction is within category bounds\n",
    "                            flat_preds[:, 0] <= cat_lines[k],\n",
    "                            flat_preds[:, 0] > cat_lines[k+1]\n",
    "                        ),\n",
    "                        flat_truths == m\n",
    "                    )\n",
    "                    cat_num_samples[cat][sample_name] = np.sum(\n",
    "                        flat_weights[sample_bool]\n",
    "                    )\n",
    "                    print(f\"{cat}: Num {sample_name} = {cat_num_samples[cat][sample_name]:.4f}\")\n",
    "                    print('-'*60)\n",
    "                    if sample_name == order[-1]:\n",
    "                        for smpl in [\n",
    "                            ['GluGluHToGG', 'GluGlutoHHto2B2G_kl_1p00_kt_1p00_c2_0p00'],\n",
    "                            ['VBFHToGG', 'VBFHToGG_M_125'],\n",
    "                            ['GGJets'], ['GJetPt20To40'], ['GJetPt40']\n",
    "                        ]:\n",
    "                            smpl_num = 0\n",
    "                            for smpl_ in smpl:\n",
    "                                smpl_num += np.sum(\n",
    "                                    flat_weights[\n",
    "                                        np.logical_and(\n",
    "                                            sample_bool,\n",
    "                                            flat_sample_names == smpl_\n",
    "                                        )\n",
    "                                    ]\n",
    "                                )\n",
    "                            print(f\"{cat}: Num {smpl[0]} = {smpl_num:.4f}\")\n",
    "                            print('-'*60)\n",
    "                    elif sample_name == order[-2]:\n",
    "                        smpl_num = np.sum(\n",
    "                            flat_weights[\n",
    "                                np.logical_and(\n",
    "                                    sample_bool,\n",
    "                                    np.logical_or(\n",
    "                                        flat_sample_names == 'VHToGG',\n",
    "                                        flat_sample_names == 'VHtoGG_M_125'\n",
    "                                    )\n",
    "                                )\n",
    "                            ]\n",
    "                        )\n",
    "                        print(f\"{cat}: Num VH, no ZH or WH = {smpl_num:.4f}\")\n",
    "                        print('-'*60)\n",
    "\n",
    "                print(f\"{cat}: S = {cat_num_samples[cat][order[0]]:.4f}, B = {np.sum([cat_num_samples[cat][order[v]] for v in range(1, len(order))]):.4f}, S/âB = {(cat_num_samples[cat][order[0]] / np.sqrt(np.sum([cat_num_samples[cat][order[v]] for v in range(1, len(order))]))):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New configuration: [0.01234694198260139, 0.08509823839066034, 0.05248780762404958]\n",
      "s = 0.9073338977772518, b = 107.47529343425667, s/âb = 0.08739839514067041 => -86.79030216761747\n",
      "============================================================\n",
      "New configuration: [0.000855065279719276, 0.06955869678111375, 0.030751250168760867]\n",
      "too little sig (0.17323255912916533) at this hyperplane => 0.0\n",
      "============================================================\n",
      "New configuration: [0.060963586484017986, 0.0232961055138215, 0.063424497214423]\n",
      "s = 1.0723081508323093, b = 165.34944615811565, s/âb = 0.08330092785293379 => -82.61709554564912\n",
      "============================================================\n",
      "New configuration: [0.08898553916008502, 0.16616787611674474, 0.03493498075016281]\n",
      "s = 1.2278544907103468, b = 362.2566753788521, s/âb = 0.06447534042084992 => -64.12374321118676\n",
      "============================================================\n",
      "New configuration: [0.018731692152111092, 0.0033037333738742455, 0.08656620375885256]\n",
      "s = 0.4765008656580338, b = 8.355109187876645, s/âb = 0.16331867483806706 => -161.02044102821893\n",
      "============================================================\n",
      "New configuration: [0.1251472523984849, 0.06601068488808856, 0.0798280139973717]\n",
      "s = 1.3207994503643756, b = 480.10175235885856, s/âb = 0.060251974876133055 => -59.867640643891654\n",
      "============================================================\n",
      "New configuration: [0.08910013403511326, 0.14793317447506668, 0.017625126651342866]\n",
      "s = 1.042905642524642, b = 158.47713192826703, s/âb = 0.0827535099509235 => -82.19085810665754\n",
      "============================================================\n",
      "New configuration: [0.06815099526180339, 0.0007297486216700511, 6.588539763908607e-05]\n",
      "both sig and bkg 0 at this hyperplane => 10000.0\n",
      "============================================================\n",
      "New configuration: [0.0025364047339871934, 0.06176891952766056, 0.18155908254346492]\n",
      "s = 0.4176107373889381, b = 6.978671751295523, s/âb = 0.1565444533226748 => -154.6578292595363\n",
      "============================================================\n",
      "New configuration: [0.13736842842056587, 0.0003944743463051194, 0.02294438291246581]\n",
      "too little sig (0.03230502413683225) at this hyperplane => 0.0\n",
      "============================================================\n",
      "New configuration: [0.00899159133554274, 0.1244379854755652, 0.017262702536915198]\n",
      "s = 0.8077496740650248, b = 76.77394127204641, s/âb = 0.09202609295906398 => -91.39806431581175\n",
      "============================================================\n",
      "New configuration: [0.006005881030102622, 0.003179850673137873, 0.009858159894082646]\n",
      "s = 0.4666270790182075, b = 8.067823264359161, s/âb = 0.1627360239136416 => -160.5221012801312\n",
      "============================================================\n",
      "New configuration: [0.003555841177718674, 0.07883247477116304, 0.005085748617354853]\n",
      "s = 0.5107450674282108, b = 14.605403673699671, s/âb = 0.13287558924869958 => -131.7326637052299\n",
      "============================================================\n",
      "New configuration: [0.053764435766085576, 0.1279947966718481, 0.07172523728233222]\n",
      "s = 1.2940533277712603, b = 549.6329231815234, s/âb = 0.05517540390736229 => -54.919659504656174\n",
      "============================================================\n",
      "New configuration: [0.11893944382755543, 0.012668664062918122, 0.06265858835443672]\n",
      "s = 0.8922905000560708, b = 84.84881073195574, s/âb = 0.09669963896916302 => -95.8453956625661\n",
      "============================================================\n",
      "New configuration: [0.0051378972329256065, 0.011595019227416225, 0.01374411808808181]\n",
      "s = 0.6272977697947986, b = 28.673672522369888, s/âb = 0.11672395205004531 => -115.73424644819427\n",
      "============================================================\n",
      "New configuration: [0.1223652350811061, 0.0004719036499513235, 0.007343189377117371]\n",
      "too little sig (0.05644049341561329) at this hyperplane => 0.0\n",
      "============================================================\n",
      "New configuration: [0.03509817392230967, 0.0022251361125388636, 0.1650274293809179]\n",
      "s = 0.37776582033231526, b = 5.07981024781688, s/âb = 0.1655940384695203 => -163.34338108970437\n",
      "============================================================\n",
      "New configuration: [0.12146351479052643, 0.08119264641625544, 0.09774857970240604]\n",
      "s = 1.3563959982969236, b = 583.9528318303, s/âb = 0.056108623805418055 => -55.781610914289345\n",
      "============================================================\n",
      "New configuration: [0.12982933883471032, 0.056647905436043505, 0.1052405425681825]\n",
      "s = 1.2901722451201263, b = 424.06921514536793, s/âb = 0.06261946186622779 => -62.207363629904194\n",
      "============================================================\n",
      "New configuration: [0.05451285690416187, 0.1667159380792954, 0.005030526901289778]\n",
      "s = 0.6356229795696199, b = 27.78695709622458, s/âb = 0.12012567353505223 => -119.2342247741583\n",
      "============================================================\n",
      "New configuration: [0.0012657704339474557, 0.05019971520059396, 0.0018517558806572397]\n",
      "s = 0.25391142732158045, b = 3.1553675856082015, s/âb = 0.14108563160009543 => -139.85254346600703\n",
      "============================================================\n",
      "New configuration: [0.0024493713202031844, 0.15940794348844287, 0.11020173578637875]\n",
      "s = 0.40838764021563945, b = 6.643652764234323, s/âb = 0.15685853786617968 => -154.9732648551329\n",
      "============================================================\n",
      "New configuration: [0.010302853952417526, 0.0291187779572596, 0.08263805892108678]\n",
      "s = 0.849761675763107, b = 91.94640540954269, s/âb = 0.0884836157635964 => -87.903682772465\n",
      "============================================================\n",
      "New configuration: [0.07118608526682559, 5.233540679124162e-06, 0.002254373642356906]\n",
      "both sig and bkg 0 at this hyperplane => 10000.0\n",
      "============================================================\n",
      "New configuration: [0.0009300504098174435, 0.12379338968250854, 0.029640390551422188]\n",
      "too little sig (0.18999467356066216) at this hyperplane => 0.0\n",
      "============================================================\n",
      "New configuration: [0.15722680391197089, 0.0051445989429670085, 0.010844301321678004]\n",
      "s = 0.6052032029999004, b = 20.82304844985855, s/âb = 0.13199133355735954 => -130.54947098489856\n",
      "============================================================\n",
      "New configuration: [0.03071065630106458, 0.016070424526659445, 0.031785440087911676]\n",
      "s = 0.9644910307025287, b = 109.71362722906173, s/âb = 0.09194612903095548 => -91.13368690801325\n",
      "============================================================\n",
      "New configuration: [0.08025333366110929, 0.050633045321178086, 0.0751882861741057]\n",
      "s = 1.2606548264388089, b = 367.56337828454997, s/âb = 0.06571766171435042 => -65.27225820586551\n",
      "============================================================\n",
      "New configuration: [0.005592801552839901, 0.0037726187586774426, 0.10615383281137211]\n",
      "s = 0.5104456092043421, b = 9.979332483090927, s/âb = 0.1602351796162615 => -157.88685817923584\n",
      "============================================================\n",
      "New configuration: [0.05347777689207577, 0.07107553380709607, 0.1545142161529146]\n",
      "s = 1.2764482342332117, b = 469.2643590114451, s/âb = 0.0588976154548642 => -58.577705039525846\n",
      "============================================================\n",
      "New configuration: [0.013172995414684328, 0.04200636947561338, 0.13992146529668845]\n",
      "s = 0.927002851536715, b = 118.85691322249947, s/âb = 0.0849191766731651 => -84.34748367982775\n",
      "============================================================\n",
      "New configuration: [0.10223161073892427, 0.16514811832304271, 0.07439213043813424]\n",
      "s = 1.3810099007919465, b = 773.892684973707, s/âb = 0.049628063794721414 => -49.40977505288526\n",
      "============================================================\n",
      "New configuration: [0.1342156056855011, 0.05117505782683674, 0.038467461002041146]\n",
      "s = 1.2375785075803891, b = 355.4281903349523, s/âb = 0.06560623034073523 => -65.21492612794974\n",
      "============================================================\n",
      "New configuration: [0.10003576597098864, 0.011937027675785328, 0.09835964457478581]\n",
      "s = 0.873853822498985, b = 77.52992054681677, s/âb = 0.09905840551705886 => -98.1720236941544\n",
      "============================================================\n",
      "New configuration: [0.0234673921357223, 0.019538358676643885, 0.007194087147871533]\n",
      "s = 0.7540402363193285, b = 50.832747209540045, s/âb = 0.10550044626710713 => -104.7575410051986\n",
      "============================================================\n",
      "New configuration: [0.013804633424837752, 0.0830851487908657, 0.04204011861761484]\n",
      "s = 0.9405197747890331, b = 123.79230897179102, s/âb = 0.08442528917991184 => -83.85484017406661\n",
      "============================================================\n",
      "New configuration: [0.095711640175576, 0.004257181564250176, 0.028290877034124882]\n",
      "s = 0.5486562845064814, b = 12.46405930788027, s/âb = 0.15428728091461213 => -152.14110346396274\n",
      "============================================================\n",
      "New configuration: [0.05055548734034158, 0.13310683292956643, 0.028158369452701566]\n",
      "s = 1.1720235366157021, b = 286.8499669184099, s/âb = 0.0691534083704905 => -68.75567476589414\n",
      "============================================================\n",
      "New configuration: [0.1646848038287244, 0.15471405026858223, 0.000530105307963393]\n",
      "too little sig (0.0788638458100556) at this hyperplane => 0.0\n",
      "============================================================\n",
      "New configuration: [0.15365889342704073, 0.08339047623253124, 0.14135550195246138]\n",
      "s = 1.368727331459285, b = 604.3936506216539, s/âb = 0.0556535916610848 => -55.31770526581724\n",
      "============================================================\n",
      "New configuration: [0.16724895671534548, 0.0030534450059007054, 0.06086592842723996]\n",
      "s = 0.4557010931316771, b = 7.34933130151731, s/âb = 0.16640177700532421 => -164.04970166739506\n",
      "============================================================\n",
      "New configuration: [0.02758753223921706, 0.053294071739697246, 0.1790042670586798]\n",
      "s = 1.1382534520513985, b = 279.61793200524465, s/âb = 0.06802400765940854 => -67.64389239816573\n",
      "============================================================\n",
      "New configuration: [0.008657179798168801, 0.05688619318503805, 0.00641422809474035]\n",
      "s = 0.7032726057260872, b = 37.88678163340763, s/âb = 0.11390544416260101 => -113.02742043832374\n",
      "============================================================\n",
      "New configuration: [0.1046983374858053, 0.03716210526729167, 0.16895864897327412]\n",
      "s = 1.193658892379307, b = 278.20749854606265, s/âb = 0.07151311670321435 => -70.99299486491932\n",
      "============================================================\n",
      "New configuration: [0.055258475533534974, 0.07228729656687367, 0.018922528787350873]\n",
      "s = 1.0638023230786797, b = 173.74798936832568, s/âb = 0.08062296546839601 => -80.09245463367242\n",
      "============================================================\n",
      "New configuration: [0.07496282826679852, 0.002165690972521156, 0.11532526220373449]\n",
      "s = 0.37160055377959383, b = 4.992292558901358, s/âb = 0.16431128015874458 => -162.1416532569986\n",
      "============================================================\n",
      "New configuration: [0.035103897459135384, 0.07697903580792999, 0.09877568564926316]\n",
      "s = 1.1986785871292711, b = 357.55460457474004, s/âb = 0.06335620757383849 => -63.02178996745177\n",
      "============================================================\n",
      "New configuration: [0.0926163804357969, 0.01593429672517836, 0.005490267592470248]\n",
      "s = 0.6636860947162203, b = 31.485033855251675, s/âb = 0.1178678777906802 => -116.9647995722826\n",
      "============================================================\n",
      "New configuration: [0.16029994902697345, 0.17704343893067068, 0.03163683737594173]\n",
      "s = 1.2030381819953375, b = 324.29434604639846, s/âb = 0.06676387514631939 => -66.38773606539782\n",
      "============================================================\n",
      "New configuration: [0.17047349343918244, 0.010711043522123851, 0.03666344279005068]\n",
      "s = 0.8398959994789802, b = 69.48424807962672, s/âb = 0.10055667566178536 => -99.65505678898829\n",
      "============================================================\n",
      "New configuration: [0.10394805357436561, 0.04464746310660198, 0.00470814348868055]\n",
      "s = 0.6148883200115282, b = 25.681242424869897, s/âb = 0.1208561720303998 => -119.99994304904332\n",
      "============================================================\n",
      "New configuration: [0.0666794763354424, 0.03161722249068206, 0.0005001541989114898]\n",
      "too little sig (0.06893195662409865) at this hyperplane => 0.0\n",
      "============================================================\n",
      "New configuration: [0.09017856735205476, 0.0719497521649414, 0.07905575348800117]\n",
      "s = 1.3222986524952978, b = 521.8060197324412, s/âb = 0.057861774007672256 => -57.52866484602588\n",
      "============================================================\n",
      "New configuration: [0.06764704282219791, 0.10279466234714517, 0.08392208233040738]\n",
      "s = 1.3352414469564495, b = 658.30327639848, s/âb = 0.052023561667098435 => -51.79073894918463\n",
      "============================================================\n",
      "New configuration: [0.12832924906630339, 0.1610718937888319, 0.17854600731537054]\n",
      "s = 1.4452412458292045, b = 1049.7067303508663, s/âb = 0.04459711303121951 => -44.40652804848247\n",
      "============================================================\n",
      "New configuration: [0.08430959063807843, 0.0005470947089155959, 3.352207979892466e-06]\n",
      "both sig and bkg 0 at this hyperplane => 10000.0\n",
      "============================================================\n",
      "New configuration: [0.005526999355265828, 0.09775617448923661, 0.15479437408691665]\n",
      "s = 0.6504858369557157, b = 31.202483203268812, s/âb = 0.11604987252806385 => -115.04305468734296\n",
      "============================================================\n",
      "New configuration: [0.0249887222640214, 0.17342142333732594, 0.01946687919269808]\n",
      "s = 1.0518311367145998, b = 181.64288841372655, s/âb = 0.07796837598267904 => -77.49449846685856\n",
      "============================================================\n",
      "New configuration: [0.07545284459170008, 0.03229763129222507, 0.06508653358263619]\n",
      "s = 1.1585742297115558, b = 237.99235563944134, s/âb = 0.07503960940894348 => -74.47682429274239\n",
      "============================================================\n",
      "New configuration: [0.17002770705689801, 0.15681576779729683, 0.15354516510779717]\n",
      "s = 1.4601789909455796, b = 1050.3221031089238, s/âb = 0.045044758425929594 => -44.838785236698364\n",
      "============================================================\n",
      "New configuration: [0.14334295451536214, 0.10640869362355967, 0.05333266132238081]\n",
      "s = 1.3258475934069618, b = 569.0407833747864, s/âb = 0.05555886817810173 => -55.28329029747696\n",
      "============================================================\n",
      "New configuration: [0.1560634743370008, 0.00547039040344177, 0.07317917355799992]\n",
      "s = 0.6245593135452714, b = 23.45099270095319, s/âb = 0.1284050873237447 => -127.05445454004\n",
      "============================================================\n",
      "New configuration: [0.1311182633476849, 0.0833660375597934, 0.07603645217048127]\n",
      "s = 1.35972674679737, b = 597.1261095808296, s/âb = 0.05562293633192909 => -55.30670265298324\n",
      "============================================================\n",
      "New configuration: [0.012746229911349256, 0.05599848359949233, 0.17681118426870215]\n",
      "s = 0.9166669791649136, b = 113.73686080028946, s/âb = 0.08583791502741625 => -85.25268057146992\n",
      "============================================================\n",
      "New configuration: [0.048247876011810284, 0.0006145282591965773, 0.1151324541740027]\n",
      "too little sig (0.09927497347958464) at this hyperplane => 0.0\n",
      "============================================================\n",
      "New configuration: [0.08471191341059045, 0.042972537758591035, 0.0704964901671902]\n",
      "s = 1.227504541509896, b = 322.7803483269997, s/âb = 0.06828017870651575 => -67.80055748568746\n",
      "============================================================\n",
      "New configuration: [0.07877169253039316, 0.014586826200789358, 0.0017434960337385434]\n",
      "s = 0.33817664535309383, b = 4.533443164042227, s/âb = 0.15691318940071267 => -155.40396435615273\n",
      "============================================================\n",
      "New configuration: [0.1045497623517688, 0.04520514107773507, 0.0061544276608374165]\n",
      "s = 0.7020107797363513, b = 36.69256383416804, s/âb = 0.11552571382985899 => -114.63447866970962\n",
      "============================================================\n",
      "New configuration: [0.06159383275540214, 0.13044304862212683, 0.05485333945983422]\n",
      "s = 1.300370156739393, b = 561.917587616837, s/âb = 0.054835689097488045 => -54.5890624607407\n",
      "============================================================\n",
      "New configuration: [0.0037113284754725115, 0.08537416942592163, 0.004980759789059522]\n",
      "s = 0.5218365132514111, b = 16.94275131207621, s/âb = 0.12613501199452531 => -125.12315279148967\n",
      "============================================================\n",
      "New configuration: [0.00010907848562756194, 0.10971858778572069, 0.0004832393028973793]\n",
      "both sig and bkg 0 at this hyperplane => 10000.0\n",
      "============================================================\n",
      "New configuration: [0.009391651328776868, 0.11712587434657348, 0.10591981815831306]\n",
      "s = 0.821328277488524, b = 79.53568869389365, s/âb = 0.09193711091426082 => -91.30634547726913\n",
      "============================================================\n",
      "New configuration: [0.07876592971414897, 0.009237002813508333, 0.015037404230098169]\n",
      "s = 0.7912347355577979, b = 50.95587860517453, s/âb = 0.1105579625973229 => -109.45627878648665\n",
      "============================================================\n",
      "New configuration: [0.1256111005633236, 0.05170247141323577, 0.16091387963073367]\n",
      "s = 1.2705589109656867, b = 375.3651437867789, s/âb = 0.06554251574510002 => -65.08569940601906\n",
      "============================================================\n",
      "New configuration: [0.18084136053054126, 0.0017594477680138367, 0.12835138708401905]\n",
      "s = 0.3222708223642666, b = 4.0189520853596585, s/âb = 0.15867535129290428 => -156.9813796417258\n",
      "============================================================\n",
      "New configuration: [0.17376769948660645, 0.131338432690686, 0.16221017359972723]\n",
      "s = 1.440819833173156, b = 918.1179250237246, s/âb = 0.047538657504664086 => -47.30092579375281\n",
      "============================================================\n",
      "New configuration: [0.009680105805435907, 0.07048222623994589, 0.10061565519137666]\n",
      "s = 0.8306417894721012, b = 83.78621247312306, s/âb = 0.09059667734620606 => -89.98163675439146\n",
      "============================================================\n",
      "New configuration: [0.0827370066290027, 0.15523805094599435, 0.007664912211985149]\n",
      "s = 0.7753161128148016, b = 55.99199738531273, s/âb = 0.10337562553168689 => -102.6485450985861\n",
      "============================================================\n",
      "New configuration: [0.05276313796833531, 0.014723629801218677, 0.1006827693804461]\n",
      "s = 0.9384961672740709, b = 98.51589698390711, s/âb = 0.09440434529862586 => -93.55086745149273\n",
      "============================================================\n",
      "New configuration: [0.08872351768194749, 0.014713509332946913, 0.044908286928224184]\n",
      "s = 0.9382440712118446, b = 98.46379960816049, s/âb = 0.09440391265208173 => -93.55159198512831\n",
      "============================================================\n",
      "New configuration: [0.04556299185479498, 0.16222088459041972, 0.08631246285278749]\n",
      "s = 1.2596198020463472, b = 460.5528504379247, s/âb = 0.05866809076860597 => -58.36744954262888\n",
      "============================================================\n",
      "New configuration: [0.1469837712721497, 0.000520583173273514, 0.005523860679810989]\n",
      "too little sig (0.07129032421339673) at this hyperplane => 0.0\n",
      "============================================================\n",
      "New configuration: [0.05309890868754161, 0.0030719991151837785, 0.07842216841493484]\n",
      "s = 0.4574291262767495, b = 7.466102414256238, s/âb = 0.16574101341995354 => -163.4267862104276\n",
      "============================================================\n",
      "New configuration: [0.13267044104151632, 0.015067504077212591, 0.04878246929142568]\n",
      "s = 0.9453689876432599, b = 102.42777718324345, s/âb = 0.09326666790345253 => -92.43257491247459\n",
      "============================================================\n",
      "New configuration: [0.13859072806896125, 0.010794767765067893, 0.04992726677458894]\n",
      "s = 0.8427570554126593, b = 70.04302340078704, s/âb = 0.10049686681636379 => -99.59788509981908\n",
      "============================================================\n",
      "New configuration: [0.009699025854907874, 0.019651851201347412, 0.10193638830452706]\n",
      "s = 0.8312574337447027, b = 83.86302061693142, s/âb = 0.09062232277221505 => -90.00696999963557\n",
      "============================================================\n",
      "New configuration: [0.004032888901035923, 0.08413261982806416, 0.14080454513063406]\n",
      "s = 0.5505127234022177, b = 19.50980858981053, s/âb = 0.12405588282122651 => -123.02550666810316\n",
      "============================================================\n",
      "New configuration: [0.025037987761005742, 0.001420188226537771, 0.006826171185150321]\n",
      "s = 0.2731142475476182, b = 3.1576609086250476, s/âb = 0.1515562975858447 => -149.94548866670573\n",
      "============================================================\n",
      "New configuration: [0.028846335013097423, 0.0018890303115154888, 0.01617075474951543]\n",
      "s = 0.33906094981602036, b = 4.340245422673388, s/âb = 0.16069698663653167 => -158.85264046926807\n",
      "============================================================\n",
      "New configuration: [0.004911355237186696, 0.10522225099391298, 0.0006429137870191682]\n",
      "too little sig (0.11536970457024623) at this hyperplane => 0.0\n",
      "============================================================\n",
      "New configuration: [0.041613556120924836, 0.09466081415625285, 0.006735872452229068]\n",
      "s = 0.7321478710470428, b = 44.259927281238795, s/âb = 0.10974952584825826 => -108.9459086618332\n",
      "============================================================\n",
      "New configuration: [0.1265619339341098, 0.0037689020731669757, 0.03533197108775401]\n",
      "s = 0.5140746999250951, b = 10.03804488269513, s/âb = 0.16090014818189183 => -158.5134007295111\n",
      "============================================================\n",
      "New configuration: [0.14466679248777625, 0.03143316321962053, 0.16134534472513615]\n",
      "s = 1.151463250057509, b = 227.87134000593255, s/âb = 0.0762149353110924 => -75.63198601005047\n",
      "============================================================\n",
      "New configuration: [0.09394238324194895, 0.12186760954224432, 0.17345624841191898]\n",
      "s = 1.3910882672443348, b = 824.9315414746328, s/âb = 0.048419883767471986 => -48.200683768666764\n",
      "============================================================\n",
      "New configuration: [0.02014017644080442, 0.09828396930387481, 0.005305081216101005]\n",
      "s = 0.6531100054501452, b = 29.32140542783158, s/âb = 0.1201692978054081 => -119.24276278894418\n",
      "============================================================\n",
      "New configuration: [0.012679129160236344, 0.03724786420522649, 0.07610101471561026]\n",
      "s = 0.9149998433940106, b = 111.12667246467856, s/âb = 0.08667972163249366 => -86.08042780704415\n",
      "============================================================\n",
      "New configuration: [0.002736241948467147, 0.05049652264310769, 0.021167397539354402]\n",
      "s = 0.43810069300229626, b = 7.875093129110209, s/âb = 0.15470059686079857 => -152.94214709787784\n",
      "============================================================\n",
      "New configuration: [0.00550224309899611, 0.12175002110725062, 0.031364342473857824]\n",
      "s = 0.6490947964752102, b = 31.004840206816414, s/âb = 0.11616853066121376 => -115.16294529745791\n",
      "============================================================\n",
      "New configuration: [0.035210109805865517, 0.0020266172730949395, 0.043171504368107703]\n",
      "s = 0.35598471863395537, b = 4.7130377011175995, s/âb = 0.16197436508284996 => -159.93608447819318\n",
      "============================================================\n",
      "New configuration: [0.19415166985862162, 0.061572220637684895, 0.003638250170465153]\n",
      "s = 0.5338576132433606, b = 14.892550210570196, s/âb = 0.13752341207117116 => -136.3144064763492\n",
      "============================================================\n",
      "New configuration: [0.11987661112416884, 0.03824456167496127, 0.004691623120313543]\n",
      "s = 0.6138724035583945, b = 25.647719134002134, s/âb = 0.12073548588157125 => -119.87734638541673\n",
      "============================================================\n",
      "New configuration: [0.19415166985862162, 0.17905850557986921, 0.007644972338320864]\n",
      "s = 0.7743914440656078, b = 55.694531494394376, s/âb = 0.10352672509254464 => -102.79926235451755\n",
      "============================================================\n",
      "New configuration: [0.19415166985862162, 0.0, 0.182740011180593]\n",
      "both sig and bkg 0 at this hyperplane => 10000.0\n",
      "============================================================\n",
      "New configuration: [0.17296576747405873, 0.0031452255406321686, 0.10842652642325598]\n",
      "s = 0.4638102538520175, b = 7.888775571010019, s/âb = 0.1635538975579298 => -161.29952265495612\n",
      "============================================================\n",
      "New configuration: [0.002668282982220404, 0.04411559853115969, 0.0025194562464574562]\n",
      "s = 0.4020344156211513, b = 6.47069645607504, s/âb = 0.15645187669251376 => -154.81366058355334\n",
      "============================================================\n",
      "New configuration: [0.17331006851595543, 0.004034837127754432, 0.10380566887846278]\n",
      "s = 0.5336003786875837, b = 10.878211358335173, s/âb = 0.16048834758332825 => -158.06982345943126\n",
      "============================================================\n",
      "New configuration: [0.006263079028467099, 0.10199950872083265, 0.0009676401279977695]\n",
      "too little sig (0.20211759622513853) at this hyperplane => 0.0\n",
      "============================================================\n",
      "New configuration: [0.08423889887885759, 0.022023741959224512, 0.005543586349251183]\n",
      "s = 0.6669479813252913, b = 31.823558153267676, s/âb = 0.11781785513520386 => -116.9132939121244\n",
      "============================================================\n",
      "New configuration: [0.17269664574085544, 0.004287211502583833, 0.10223294506177019]\n",
      "s = 0.550753784963747, b = 12.511112994569604, s/âb = 0.15458554816303371 => -152.41832490947428\n",
      "============================================================\n",
      "New configuration: [0.007876856435295922, 0.09385337021979846, 0.001773555541015465]\n",
      "s = 0.34224304006114614, b = 4.5682643126827, s/âb = 0.15818553312748082 => -156.68584360342743\n",
      "============================================================\n",
      "New configuration: [0.13199101606382574, 0.0024707625592862202, 0.01232478293223788]\n",
      "s = 0.40267318416194614, b = 5.535829528153294, s/âb = 0.16912951879529206 => -166.73998191691246\n",
      "============================================================\n",
      "New configuration: [0.023256896009640236, 0.0035204649110151176, 0.011799890859366988]\n",
      "s = 0.494567191844758, b = 9.24986940898023, s/âb = 0.16119610624704045 => -158.93485586223306\n",
      "============================================================\n",
      "New configuration: [0.1723213286049687, 0.004402569491090201, 0.10116121820196897]\n",
      "s = 0.5584856364220698, b = 15.22049989944124, s/âb = 0.14228971564778314 => -140.55526310176526\n",
      "============================================================\n",
      "New configuration: [0.001184709445956896, 0.12559288950542877, 0.03790222668538289]\n",
      "too little sig (0.240341018557241) at this hyperplane => 0.0\n",
      "============================================================\n",
      "New configuration: [0.1773222538040005, 0.0027327992906037413, 0.11647184844101162]\n",
      "s = 0.42729113202863894, b = 6.39914560670383, s/âb = 0.16708356385993964 => -164.77017853657722\n",
      "============================================================\n",
      "New configuration: [0.07934905002545319, 0.01949922784221895, 0.002962832269343219]\n",
      "s = 0.47459568340463426, b = 8.932390636290705, s/âb = 0.15742018884399447 => -155.67883320133802\n",
      "============================================================\n",
      "New configuration: [0.00468710045291854, 0.07649205897642669, 0.005937079906505484]\n",
      "s = 0.5916793305639465, b = 23.30763153656023, s/âb = 0.12204365387976729 => -121.11809715826952\n",
      "============================================================\n",
      "New configuration: [0.17596056454351636, 0.0031249087649376167, 0.11210847019725012]\n",
      "s = 0.4622297751174711, b = 7.848375198208714, s/âb = 0.16341289992635208 => -161.20152911325584\n",
      "============================================================\n",
      "New configuration: [0.002045790672296717, 0.044887784422486685, 0.00240443481057296]\n",
      "s = 0.35684911487601084, b = 5.293718694251672, s/âb = 0.1534019610838188 => -151.98404693442575\n",
      "============================================================\n",
      "New configuration: [0.12857958189017757, 0.0015262490616148457, 0.010607072218877607]\n",
      "s = 0.29000063162306344, b = 3.3973387482758666, s/âb = 0.1551741549689055 => -153.2986108982301\n",
      "============================================================\n",
      "New configuration: [0.07921404903486123, 0.01862106514569129, 0.002857442411495208]\n",
      "s = 0.4644047435231559, b = 8.467346074102519, s/âb = 0.15816984038693355 => -156.43962068667543\n",
      "============================================================\n",
      "New configuration: [0.07915270802931232, 0.018368505504614736, 0.0027673844939803695]\n",
      "s = 0.4551614860322728, b = 8.222572605325444, s/âb = 0.15729931051353385 => -155.58894110933022\n",
      "============================================================\n",
      "New configuration: [0.09661725907392951, 0.004504459572502983, 0.030487895588674]\n",
      "s = 0.5653072553344853, b = 16.410168598784445, s/âb = 0.13875949285254022 => -137.12984365884498\n",
      "============================================================\n",
      "New configuration: [0.0080779240229135, 0.09104856490834061, 0.002016406971713018]\n",
      "s = 0.37347429348372774, b = 5.236837174167326, s/âb = 0.16131788794038895 => -159.79780441748392\n",
      "============================================================\n",
      "New configuration: [0.002506863797114265, 0.050746768450714304, 0.0021734957066219538]\n",
      "s = 0.37325936940551513, b = 5.4239561873813384, s/âb = 0.158482717635548 => -157.1156337415813\n",
      "============================================================\n",
      "New configuration: [0.1799317834059973, 0.0020098253029470067, 0.125089938851754]\n",
      "s = 0.3539549796464594, b = 4.6765905855096594, s/âb = 0.1616732166589749 => -159.64037442184141\n",
      "============================================================\n",
      "New configuration: [0.078880523968081, 0.015779450924476756, 0.0019374901041983082]\n",
      "s = 0.3639359038332324, b = 4.990772574055867, s/âb = 0.16098539666493633 => -159.49962927544394\n",
      "============================================================\n",
      "New configuration: [0.023995633059236895, 0.0017045723837324134, 0.008129456472538299]\n",
      "s = 0.3150509463315837, b = 3.896611435909444, s/âb = 0.15752027061000445 => -155.88109995593226\n",
      "============================================================\n",
      "New configuration: [0.003489018356994064, 0.1151342845989827, 0.02402767904053495]\n",
      "s = 0.5070907573084323, b = 14.189804222427295, s/âb = 0.1338261786760842 => -132.6261352693618\n",
      "============================================================\n",
      "New configuration: [0.13223863558493937, 0.0028008226046357643, 0.012887259911511085]\n",
      "s = 0.433512716845242, b = 6.555477239874492, s/âb = 0.1675001237745432 => -165.14685671339285\n",
      "============================================================\n",
      "New configuration: [0.027886112886735703, 0.002490262837125967, 0.01646411073215343]\n",
      "s = 0.40443671230236056, b = 5.582179495944571, s/âb = 0.16917127582841052 => -166.78318659299075\n",
      "============================================================\n",
      "New configuration: [0.08026605086294923, 0.011297443388565078, 0.016351242346935704]\n",
      "s = 0.8549880728058296, b = 73.99418493241164, s/âb = 0.09920375224374546 => -98.3506736869965\n",
      "============================================================\n",
      "New configuration: [0.00456655976077428, 0.0408834283186513, 0.0025423492361208596]\n",
      "s = 0.4321944283862454, b = 7.254157225256907, s/âb = 0.1589118734217902 => -157.16638423393178\n",
      "============================================================\n",
      "New configuration: [0.07892311984420036, 0.015234079768732176, 0.0030779120313979484]\n",
      "s = 0.48531349526415885, b = 9.497239832667661, s/âb = 0.15616593181785005 => -154.46609885240946\n",
      "============================================================\n",
      "New configuration: [0.024573503809864387, 0.004594120513352272, 0.00971880169746561]\n",
      "s = 0.5711854862549443, b = 16.787828253878768, s/âb = 0.13862598198397025 => -136.97953023289458\n",
      "============================================================\n",
      "New configuration: [0.0100135291019409, 0.04530951671516755, 0.008421739657272146]\n",
      "s = 0.782154293356629, b = 62.962668030753974, s/âb = 0.09836835318713663 => -97.73890411426544\n",
      "============================================================\n",
      "New configuration: [0.0014857572789585926, 0.04722792272263194, 0.0020128000786750525]\n",
      "s = 0.28831049594560937, b = 3.688978932115052, s/âb = 0.1482149820592881 => -146.77496777317725\n",
      "============================================================\n",
      "New configuration: [0.001865873981564835, 0.05162788253314823, 0.0028548019165574624]\n",
      "s = 0.3399526979404479, b = 4.802090599263336, s/âb = 0.15335427898803924 => -151.78178586176227\n",
      "============================================================\n",
      "New configuration: [0.027614018609667355, 0.002459530666600859, 0.016685114640970687]\n",
      "s = 0.4016374272780765, b = 5.527084417351595, s/âb = 0.1688298284644923 => -166.4692693654783\n",
      "============================================================\n",
      "New configuration: [0.055074555346341335, 0.004128626977598759, 0.074318234787647]\n",
      "s = 0.5401265734963846, b = 11.99289135085121, s/âb = 0.15481802909496076 => -152.62404275028575\n",
      "============================================================\n",
      "New configuration: [0.13341429531611332, 0.0028795955727339857, 0.011934360607822403]\n",
      "s = 0.44072397389790985, b = 6.8549789741575635, s/âb = 0.16657374170876318 => -164.27270476074642\n",
      "============================================================\n",
      "New configuration: [0.002726946381644546, 0.16439663366795446, 0.11852346435870025]\n",
      "s = 0.4369522086510312, b = 7.821097233301367, s/âb = 0.15482084579925948 => -153.05506343970637\n",
      "============================================================\n",
      "New configuration: [0.0023897427430919637, 0.05202293639083597, 0.0011239513266273064]\n",
      "too little sig (0.23633122647939342) at this hyperplane => 0.0\n",
      "============================================================\n",
      "New configuration: [0.0026540414235762515, 0.049938629904297455, 0.0026840517527309425]\n",
      "s = 0.41002650160438237, b = 6.7575414719068245, s/âb = 0.1561751035886765 => -154.50219842716317\n",
      "============================================================\n",
      "New configuration: [0.008491664649693453, 0.09406846338287628, 0.0023812903439245896]\n",
      "s = 0.41509942836070707, b = 6.498791671851066, s/âb = 0.1611416717389564 => -159.477658222529\n",
      "============================================================\n",
      "New configuration: [0.17944393045062054, 0.0021423356541117387, 0.12330565868111636]\n",
      "s = 0.3690990485052304, b = 4.969800323183913, s/âb = 0.16357840920973002 => -161.4202740160773\n",
      "============================================================\n",
      "New configuration: [0.0028305730761941004, 0.05037619974828162, 0.0248772481006985]\n",
      "s = 0.44718693798978376, b = 8.127237202080275, s/âb = 0.15545546237937558 => -153.579240896107\n",
      "============================================================\n",
      "New configuration: [0.004795396403049072, 0.08654600369583493, 0.003446194375383557]\n",
      "s = 0.5096712961462139, b = 13.791942045176079, s/âb = 0.13640646809624452 => -135.22974241294102\n",
      "============================================================\n",
      "New configuration: [0.009026009471159408, 0.09214137937143192, 0.0017957977762437386]\n",
      "s = 0.34546663506911585, b = 4.617846276778614, s/âb = 0.15881863376663935 => -157.3530001363373\n",
      "============================================================\n",
      "New configuration: [0.1767328506214322, 0.00439250320453745, 0.11437461897973714]\n",
      "s = 0.5579762331545048, b = 12.856219664245074, s/âb = 0.15451193670114838 => -152.29957002910695\n",
      "============================================================\n",
      "New configuration: [0.033612688813752054, 0.0028104035802032413, 0.16727336756277963]\n",
      "s = 0.4342970813149601, b = 6.601425358208854, s/âb = 0.16722730130223523 => -164.88912922462546\n",
      "============================================================\n",
      "New configuration: [0.04992625655077829, 0.01340018836091212, 0.02121678832688158]\n",
      "s = 0.9083601904136318, b = 88.7984233162259, s/âb = 0.09623156390231474 => -95.37730662552525\n",
      "============================================================\n",
      "New configuration: [0.17900815991706073, 0.0030187114231488015, 0.10564919986798472]\n",
      "s = 0.4526864748859234, b = 7.196742694128758, s/âb = 0.16702022744922776 => -164.65932646991885\n",
      "============================================================\n",
      "New configuration: [0.0747910899732355, 0.002894414724848683, 0.11175082076209886]\n",
      "s = 0.4421087367563688, b = 6.873439539240106, s/âb = 0.16687180734208454 => -164.61061176162588\n",
      "============================================================\n",
      "New configuration: [0.15863917346551168, 0.0034442481585999444, 0.06024347592436825]\n",
      "s = 0.48888709451265117, b = 8.844528190175936, s/âb = 0.16290782930685901 => -160.50889518776893\n",
      "============================================================\n",
      "New configuration: [0.0033130756520355466, 0.08074925505009435, 0.016516324755705733]\n",
      "s = 0.4919243274244362, b = 12.739876586889308, s/âb = 0.1369481186601701 => -135.67345514477046\n",
      "============================================================\n",
      "New configuration: [0.09682973216971304, 0.004985799788759236, 0.023378635207300377]\n",
      "s = 0.595608694457807, b = 20.104629327848933, s/âb = 0.13218722726020696 => -130.75328154879236\n",
      "============================================================\n",
      "New configuration: [0.07800457421273051, 0.006384829724824355, 0.032587017839979866]\n",
      "s = 0.6728725756072581, b = 28.664985879992983, s/âb = 0.12519039738320575 => -123.82108698927561\n",
      "============================================================\n",
      "New configuration: [0.010363113297640138, 0.14608965389849246, 0.034071230199050374]\n",
      "s = 0.8516159950795601, b = 92.31257948243807, s/âb = 0.08850089385274346 => -87.91506527314135\n",
      "============================================================\n",
      "New configuration: [0.002177158648639508, 0.0506670106571462, 0.0040921179800985355]\n",
      "s = 0.3782055672788389, b = 5.665580428621372, s/âb = 0.15717295594221284 => -155.22326508402332\n",
      "============================================================\n",
      "New configuration: [0.0790807168088013, 0.016673765413285777, 0.0019119591643356362]\n",
      "s = 0.36061690724588713, b = 4.924840264305619, s/âb = 0.1605737706993652 => -159.10021221064298\n",
      "============================================================\n",
      "New configuration: [0.12714863179218752, 0.0005545001627271488, 0.011710655181149271]\n",
      "too little sig (0.08187250947052341) at this hyperplane => 0.0\n",
      "============================================================\n",
      "New configuration: [0.1281464852547241, 0.0018490219096445096, 0.009181307096568725]\n",
      "s = 0.334258310530815, b = 4.173201086211221, s/âb = 0.16150974647059024 => -159.70572144642682\n",
      "============================================================\n",
      "New configuration: [0.14433054726958122, 0.002455387847451389, 0.029176106016765815]\n",
      "s = 0.40112134783567543, b = 5.5216856075109, s/âb = 0.16869590397949016 => -166.33494329415228\n",
      "============================================================\n",
      "New configuration: [0.0009923171729868917, 0.04643169756682016, 0.002525121872792198]\n",
      "too little sig (0.20326216960992033) at this hyperplane => 0.0\n",
      "============================================================\n",
      "New configuration: [0.005017979123003969, 0.03845592220725133, 0.0030745531359903933]\n",
      "s = 0.48362156097140063, b = 9.48024055460556, s/âb = 0.15576313770768177 => -154.07115882617268\n",
      "============================================================\n",
      "New configuration: [0.0027809244844212958, 0.05618308495756369, 0.006782878773479601]\n",
      "s = 0.4425377104412376, b = 7.985664999099386, s/âb = 0.1551871027814759 => -153.42163177510866\n",
      "============================================================\n",
      "New configuration: [0.007324332968169845, 0.007233850367315021, 0.016933429779050185]\n",
      "s = 0.6807842243250694, b = 31.151913374066556, s/âb = 0.12153369255210388 => -120.21923351843047\n",
      "============================================================\n",
      "New configuration: [0.13143239335894358, 0.002765142300228098, 0.037760932825769054]\n",
      "s = 0.4302817849583932, b = 6.443795685792497, s/âb = 0.1676690208222958 => -165.34874067921163\n",
      "============================================================\n",
      "New configuration: [0.14535991982287436, 0.0031859536054144972, 0.01912859711954011]\n",
      "s = 0.4672143263336686, b = 8.084540653723051, s/âb = 0.16277349968214708 => -160.5578313250463\n",
      "============================================================\n",
      "New configuration: [0.16609519546876592, 0.002304759625364083, 0.0592370359231683]\n",
      "s = 0.38645558016160597, b = 5.230088917287389, s/âb = 0.16696430059925058 => -164.62216663900503\n",
      "============================================================\n",
      "New configuration: [0.004189431485953751, 0.043796275117514875, 0.0036185980205554512]\n",
      "s = 0.5098719313017432, b = 14.098598681969854, s/âb = 0.1349852843159189 => -133.8720325932134\n",
      "============================================================\n",
      "New configuration: [0.005604966778541675, 0.03459067420639589, 0.0021219307130231914]\n",
      "s = 0.386093954107001, b = 5.598219363120106, s/âb = 0.16135666429636483 => -159.90199321528186\n",
      "============================================================\n",
      "New configuration: [0.002752432587442118, 0.05923253971123231, 0.01945028891515434]\n",
      "s = 0.4398986759094233, b = 7.887861931504398, s/âb = 0.15520627571059126 => -153.43166812683114\n",
      "============================================================\n",
      "New configuration: [0.008656710221317757, 0.08994701043870945, 0.0023198189612068515]\n",
      "s = 0.40890218160836006, b = 6.274070393143014, s/âb = 0.16152008328007364 => -159.83729667634523\n",
      "============================================================\n",
      "New configuration: [0.06738513928069592, 0.020613100681411447, 0.004186357983740227]\n",
      "s = 0.5770011122154433, b = 18.69834422701255, s/âb = 0.132759035485835 => -131.65893421023142\n",
      "============================================================\n",
      "New configuration: [0.006872371745776923, 0.0022388263548524224, 0.005054312229953388]\n",
      "s = 0.3794003922909063, b = 5.101515314641964, s/âb = 0.16595627693791745 => -163.6842145039488\n",
      "============================================================\n",
      "New configuration: [0.038026868122758795, 0.003207188247760609, 0.056875883706710206]\n",
      "s = 0.46880775959850357, b = 8.126128536754699, s/âb = 0.16291276730566445 => -160.67920621438535\n",
      "============================================================\n",
      "New configuration: [0.0022630082437879854, 0.049616622541371495, 0.002702582742056015]\n",
      "s = 0.3816063233737778, b = 5.92728066256244, s/âb = 0.155104565086462 => -153.42714956823207\n",
      "============================================================\n",
      "New configuration: [0.13553725821185683, 0.055101806313933265, 0.004838777469260812]\n",
      "s = 0.6232762814955912, b = 26.603701193568035, s/âb = 0.12037238575931146 => -119.4958925774683\n",
      "============================================================\n",
      "New configuration: [0.1795564607564894, 0.0020994664146141463, 0.12378487160529285]\n",
      "s = 0.36436950227217335, b = 4.902409605405378, s/âb = 0.16258701977154993 => -160.4488188458164\n",
      "============================================================\n",
      "New configuration: [0.015581107444438589, 0.05453526860601758, 0.004668585895775063]\n",
      "s = 0.6122813791258338, b = 25.476236392955784, s/âb = 0.12082521773186616 => -119.96940575890524\n",
      "============================================================\n",
      "New configuration: [0.13829128350028866, 0.030276509478842275, 0.14094750711413417]\n",
      "s = 1.142120836843274, b = 219.9608146953532, s/âb = 0.07694213033025332 => -76.3483509869007\n",
      "============================================================\n",
      "New configuration: [0.08393958052650123, 0.015549271387384732, 0.0023885296944224916]\n",
      "s = 0.4158691416254408, b = 6.511684076728289, s/âb = 0.1612807912964055 => -159.61858353034322\n",
      "============================================================\n",
      "New configuration: [0.021772232183892376, 0.0016621326988656249, 0.005007497260784905]\n",
      "s = 0.30911553780019985, b = 3.7873685927127143, s/âb = 0.15674681119667605 => -154.94473194397398\n",
      "============================================================\n",
      "New configuration: [0.025994247198377538, 0.00258248562446364, 0.014686497651596405]\n",
      "s = 0.4132839385789693, b = 5.943319825076009, s/âb = 0.16761518898361857 => -165.3167031771111\n",
      "============================================================\n",
      "New configuration: [0.028230903244033333, 0.002568714483983687, 0.017657549757289333]\n",
      "s = 0.41205164321011306, b = 5.85343029937008, s/âb = 0.16837069706839114 => -166.04232947518588\n",
      "============================================================\n",
      "New configuration: [0.006132891579136079, 0.0030477319472372757, 0.006392859043407592]\n",
      "s = 0.45510778036703553, b = 7.339204884667632, s/âb = 0.16629960924301246 => -163.96907411945458\n",
      "============================================================\n",
      "New configuration: [0.010206690767195499, 0.0014008994880069065, 0.10158054638850111]\n",
      "s = 0.2697935023889837, b = 3.117290047462677, s/âb = 0.15067857317142572 => -149.10599330652445\n",
      "============================================================\n",
      "New configuration: [0.17523428510667743, 0.004633059126375644, 0.017196213839443336]\n",
      "s = 0.5735759632736466, b = 16.997812337994507, s/âb = 0.1383499342814715 => -136.71266802783677\n",
      "============================================================\n",
      "New configuration: [0.14005131940318905, 0.002526197630583329, 0.03202380877388392]\n",
      "s = 0.4079589803244708, b = 5.621874531786732, s/âb = 0.1700379791693703 => -167.62554641248198\n",
      "============================================================\n",
      "New configuration: [0.0024615073994791632, 0.05515872797696294, 0.004486662914006922]\n",
      "s = 0.4097439525792506, b = 6.738047905887285, s/âb = 0.1562897309183806 => -154.43605142870123\n",
      "============================================================\n",
      "New configuration: [0.0015841386577988303, 0.1526190631507291, 0.12442899143348965]\n",
      "s = 0.30423453996080385, b = 4.0320761662576015, s/âb = 0.14966317101570994 => -148.10325088730184\n",
      "============================================================\n",
      "New configuration: [0.07892400062895373, 0.002411496211668233, 0.1069820756680242]\n",
      "s = 0.39690580513615925, b = 5.390627724188458, s/âb = 0.16891352896758108 => -166.53886800269316\n",
      "============================================================\n",
      "New configuration: [0.03218825094141082, 0.002629220363660052, 0.03735175870093549]\n",
      "s = 0.4177028158773706, b = 6.107114713901903, s/âb = 0.1671505350644606 => -164.85916406504907\n",
      "============================================================\n",
      "New configuration: [0.1784504283631911, 0.002436216868601478, 0.09845504228692663]\n",
      "s = 0.3993679748504336, b = 5.481597385527369, s/âb = 0.16856587906288234 => -166.21485131567704\n",
      "============================================================\n",
      "New configuration: [0.12429834643433467, 0.002309638123819873, 0.010247214133605596]\n",
      "s = 0.3870133101097137, b = 5.229947375967044, s/âb = 0.1672046385549724 => -164.86338401730833\n",
      "============================================================\n",
      "New configuration: [0.006250792560478759, 0.0012352624847269897, 0.007007576152524688]\n",
      "too little sig (0.241854250165638) at this hyperplane => 0.0\n",
      "============================================================\n",
      "New configuration: [0.007105092957466141, 0.002664946559424471, 0.004733350154104785]\n",
      "s = 0.42094888518220613, b = 6.224745462999725, s/âb = 0.16687081039649648 => -164.63088863732006\n",
      "============================================================\n",
      "Best parameters: [0.14005131940318905, 0.002526197630583329, 0.03202380877388392]\n",
      "Best s/âb = 0.16762554641248198\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Optimal parameters not found: Number of calls to function has reached maxfev = 600.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 107\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[1;32m    106\u001b[0m     warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 107\u001b[0m     clf_dict \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_optimize_cut_boundaries\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mflat_preds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_truths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_categories\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\n\u001b[1;32m    109\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;66;03m# plot_s_over_root_b(\u001b[39;00m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;66;03m#     sigs_and_bkgs['sig'], sigs_and_bkgs['bkg'], f\"{sample_name} vs. {sample_name_ if sample_name_ != sample_name else 'all'}\", \u001b[39;00m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;66;03m#     f\"BDT_{sample_name}_vs_{sample_name_ if sample_name_ != sample_name else 'all'}_sOverRootb_withCuts_testData_sum\", plot_dirpath, \u001b[39;00m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;66;03m#     weights=score_weights,\u001b[39;00m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;66;03m#     lines=lines, lines_labels=line_labels, line_colors=line_colors\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[1;32m    118\u001b[0m flat_mass \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([data_test_aux_dict[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfold_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmass\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m fold_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(data_test_aux_dict))], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "Cell \u001b[0;32mIn[11], line 402\u001b[0m, in \u001b[0;36mmulti_optimize_cut_boundaries\u001b[0;34m(preds, labels, weights, num_categories, min_sig, n_steps)\u001b[0m\n\u001b[1;32m    399\u001b[0m     sliced_labels \u001b[38;5;241m=\u001b[39m labels[slice_array]\n\u001b[1;32m    400\u001b[0m     sliced_weights \u001b[38;5;241m=\u001b[39m weights[slice_array]\n\u001b[0;32m--> 402\u001b[0m     opt_cuts, opt_params \u001b[38;5;241m=\u001b[39m \u001b[43moptimize_cuts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m        \u001b[49m\u001b[43msliced_preds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msliced_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msliced_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_sig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_sig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrng_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_funcs_per_param\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlevy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlevy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlevy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    408\u001b[0m clf_dict[cat] \u001b[38;5;241m=\u001b[39m opt_cuts\n\u001b[1;32m    409\u001b[0m param_clf_dict[cat] \u001b[38;5;241m=\u001b[39m opt_params\n",
      "Cell \u001b[0;32mIn[11], line 233\u001b[0m, in \u001b[0;36moptimize_cuts\u001b[0;34m(preds, labels, weights, param_names, param_range, n_steps, verbose, min_sig, prefactor, rng_seed, fit_funcs_per_param)\u001b[0m\n\u001b[1;32m    231\u001b[0m sig_to_ttH_popt_func, sig_to_ttH_popt_cov \u001b[38;5;241m=\u001b[39m fit_funcs[\u001b[38;5;241m0\u001b[39m](sig_to_ttH_bin_centers, sig_to_ttH_counts, sigma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39mnp\u001b[38;5;241m.\u001b[39mpower(sig_to_ttH_counts, \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m    232\u001b[0m sig_to_VH_popt_func, sig_to_VH_popt_cov \u001b[38;5;241m=\u001b[39m fit_funcs[\u001b[38;5;241m1\u001b[39m](sig_to_VH_bin_centers, sig_to_VH_counts, sigma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39mnp\u001b[38;5;241m.\u001b[39mpower(sig_to_VH_counts, \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m--> 233\u001b[0m sig_to_nonRes_popt_func, sig_to_nonRes_popt_cov \u001b[38;5;241m=\u001b[39m \u001b[43mfit_funcs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43msig_to_nonRes_bin_centers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msig_to_nonRes_counts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpower\u001b[49m\u001b[43m(\u001b[49m\u001b[43msig_to_nonRes_counts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    234\u001b[0m sig_to_ttH_transform \u001b[38;5;241m=\u001b[39m transform_funcs[\u001b[38;5;241m0\u001b[39m](\u001b[38;5;241m*\u001b[39msig_to_ttH_popt_func)\n\u001b[1;32m    235\u001b[0m sig_to_VH_transform \u001b[38;5;241m=\u001b[39m transform_funcs[\u001b[38;5;241m1\u001b[39m](\u001b[38;5;241m*\u001b[39msig_to_VH_popt_func)\n",
      "Cell \u001b[0;32mIn[11], line 215\u001b[0m, in \u001b[0;36moptimize_cuts.<locals>.fit_levy\u001b[0;34m(x, y, sigma)\u001b[0m\n\u001b[1;32m    212\u001b[0m c_init \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.01\u001b[39m  \u001b[38;5;66;03m# success of fit withint 600 tries (kwarg of curve_fit) HIGHLY\u001b[39;00m\n\u001b[1;32m    213\u001b[0m mu_init \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.\u001b[39m   \u001b[38;5;66;03m#  sensitive to these initial choices of parameters. maybe rescale them by 1,000?\u001b[39;00m\n\u001b[0;32m--> 215\u001b[0m opt_params, opt_cov \u001b[38;5;241m=\u001b[39m \u001b[43mcurve_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mp0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mc_init\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmu_init\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[43msigma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msigma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m opt_params, opt_cov\n",
      "File \u001b[0;32m~/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/scipy/optimize/_minpack_py.py:1012\u001b[0m, in \u001b[0;36mcurve_fit\u001b[0;34m(f, xdata, ydata, p0, sigma, absolute_sigma, check_finite, bounds, method, jac, full_output, nan_policy, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m     cost \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(infodict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfvec\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m   1011\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ier \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m]:\n\u001b[0;32m-> 1012\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimal parameters not found: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m errmsg)\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1014\u001b[0m     \u001b[38;5;66;03m# Rename maxfev (leastsq) to max_nfev (least_squares), if specified.\u001b[39;00m\n\u001b[1;32m   1015\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_nfev\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Optimal parameters not found: Number of calls to function has reached maxfev = 600."
     ]
    }
   ],
   "source": [
    "## NEED TO CHECK SERGO'S SUGGESTION: fix one axis (VH?) and try 2D optimization to see if it converges well to performance similar to Yibo's / 1D\n",
    "\n",
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"s_over_rootb_multiOptim\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "if 'BDT_perf' not in globals():\n",
    "    with open(os.path.join(OUTPUT_DIRPATH, CURRENT_TIME+\"_BDT_perf.json\"), 'r') as f:\n",
    "        BDT_perf = json.load(f)\n",
    "\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(projection='3d')\n",
    "# # x_preds, y_preds, z_preds = p_to_xyz(np.concatenate([BDT_perf['ggF HH']['preds'][fold_idx] for fold_idx in range(len(bdt_test_dict))], axis=0))\n",
    "# for i, sample_name in enumerate(order):\n",
    "#     if i == 0:\n",
    "#         downsample = 100\n",
    "#     elif i == 1:\n",
    "#         downsample = 200\n",
    "#     elif i == 2:\n",
    "#         downsample = 400\n",
    "#     elif i == 3:\n",
    "#         downsample = 500\n",
    "\n",
    "#     x_preds, y_preds, z_preds = p_to_xyz(\n",
    "#         np.array(BDT_perf['ggF HH']['preds'][0])[bdt_test_dict[f\"fold_0\"].get_label() == i][::downsample],\n",
    "#         split=True\n",
    "#     )\n",
    "#     ax.scatter(x_preds, y_preds, z_preds, marker='.', label=sample_name)\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# # plot s/âb curves\n",
    "# for fold_idx in range(len(bdt_train_dict)):\n",
    "\n",
    "#     with warnings.catch_warnings():\n",
    "#         warnings.simplefilter(\"ignore\")\n",
    "#         clf_dict = multi_optimize_cut_boundaries(\n",
    "#             BDT_perf['ggF HH']['preds'][fold_idx], \n",
    "#             bdt_test_dict[f\"fold_{fold_idx}\"].get_label() == 0, \n",
    "#             weights_plot_test[f\"fold_{fold_idx}\"],\n",
    "#             min_sig=0.07\n",
    "#         )\n",
    "\n",
    "#     cat_dict = {}\n",
    "#     for cat in range(len(clf_dict)):\n",
    "#         prev_cat_slice = np.ones_like(weights_plot_test[f\"fold_{fold_idx}\"], dtype=bool)\n",
    "#         if cat > 0:\n",
    "#             for prev_cat in range(cat):\n",
    "#                 prev_cat_slice = np.logical_and(\n",
    "#                     prev_cat_slice,\n",
    "#                     np.logical_not(\n",
    "#                         np.all(\n",
    "#                             p_to_xyz(np.array(BDT_perf['ggF HH']['preds'][fold_idx]), split=False) < clf_dict[prev_cat], \n",
    "#                             axis=1\n",
    "#                         )\n",
    "#                     )\n",
    "#                 )\n",
    "#         cat_dict[cat] = np.logical_and(\n",
    "#             prev_cat_slice,\n",
    "#             np.all(\n",
    "#                 p_to_xyz(np.array(BDT_perf['ggF HH']['preds'][fold_idx]), split=False) < clf_dict[cat],\n",
    "#                 axis=1\n",
    "#             )\n",
    "#         )\n",
    "\n",
    "#     masses = data_test_aux_dict[f\"fold_{fold_idx}\"]['mass']\n",
    "#     cat_num_samples = {}\n",
    "#     for cat in range(len(clf_dict)):\n",
    "#         cat_num_samples[cat] = {}\n",
    "#         print('='*60)\n",
    "#         print('='*60)\n",
    "#         print(f\"Fold {fold_idx}: Category {cat} (SVM) AND 120 GeV < m_HH < 130 GeV\")\n",
    "#         print('-'*60)\n",
    "#         for m, sample_name in enumerate(order):\n",
    "#             cat_num_samples[cat][sample_name] = np.sum(\n",
    "#                 weights_plot_test[f\"fold_{fold_idx}\"][\n",
    "#                     np.logical_and(  # event passes conditions and is the right type (i.e. sample)\n",
    "#                         np.logical_and(  # event passes category and mass conditions\n",
    "#                             cat_dict[cat],  # event passes category selections\n",
    "#                             np.logical_and(  # diphoton mass is within 120-130 window\n",
    "#                                 masses < 130,\n",
    "#                                 masses > 120\n",
    "#                             ),\n",
    "#                         ),\n",
    "#                         bdt_test_dict[f\"fold_{fold_idx}\"].get_label() == m\n",
    "#                     )\n",
    "#                 ]\n",
    "#             )\n",
    "#             print(f\"{cat}: Num {sample_name} = {cat_num_samples[cat][sample_name]:.4f}\")\n",
    "#             print('-'*60)\n",
    "#         print(f\"{cat}: S = {cat_num_samples[cat][order[0]]:.4f}, B = {np.sum([cat_num_samples[cat][order[v]] for v in range(1, len(order))]):.4f}, S/âB = {(cat_num_samples[cat][order[0]] / np.sqrt(np.sum([cat_num_samples[cat][order[v]] for v in range(1, len(order))]))):.4f}\")\n",
    "\n",
    "# print('='*60)\n",
    "# print('='*60)\n",
    "# print('='*60)\n",
    "# print('='*60)\n",
    "\n",
    "flat_preds = np.concatenate(BDT_perf['ggF HH']['preds'], axis=0)\n",
    "flat_truths = np.concatenate([bdt_test_dict[f\"fold_{fold_idx}\"].get_label() for fold_idx in range(len(bdt_test_dict))], axis=0)\n",
    "flat_weights = np.concatenate([weights_plot_test[f\"fold_{fold_idx}\"] for fold_idx in range(len(bdt_test_dict))], axis=0)\n",
    "# flat_weights = np.concatenate([weight_test_dict[f\"fold_{fold_idx}\"] for fold_idx in range(len(bdt_test_dict))], axis=0)\n",
    "flat_sample_names = np.concatenate([data_test_aux_dict[f\"fold_{fold_idx}\"]['sample_name'] for fold_idx in range(len(bdt_test_dict))], axis=0)\n",
    "\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    clf_dict = multi_optimize_cut_boundaries(\n",
    "        flat_preds, flat_truths, flat_weights, num_categories=3\n",
    "    )\n",
    "\n",
    "    # plot_s_over_root_b(\n",
    "    #     sigs_and_bkgs['sig'], sigs_and_bkgs['bkg'], f\"{sample_name} vs. {sample_name_ if sample_name_ != sample_name else 'all'}\", \n",
    "    #     f\"BDT_{sample_name}_vs_{sample_name_ if sample_name_ != sample_name else 'all'}_sOverRootb_withCuts_testData_sum\", plot_dirpath, \n",
    "    #     weights=score_weights,\n",
    "    #     lines=lines, lines_labels=line_labels, line_colors=line_colors\n",
    "    # )\n",
    "\n",
    "flat_mass = np.concatenate([data_test_aux_dict[f\"fold_{fold_idx}\"]['mass'] for fold_idx in range(len(data_test_aux_dict))], axis=0)\n",
    "cat_dict = {}\n",
    "for cat in range(len(clf_dict)):\n",
    "    prev_cat_slice = np.ones_like(flat_weights, dtype=bool)\n",
    "    if cat > 0:\n",
    "        for prev_cat in range(cat):\n",
    "            prev_cat_slice = np.logical_and(\n",
    "                prev_cat_slice,\n",
    "                np.logical_not(\n",
    "                    np.all(\n",
    "                        output_to_3d_thresholds(flat_preds, split=False) < clf_dict[prev_cat], \n",
    "                        axis=1\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "    cat_dict[cat] = np.logical_and(\n",
    "        prev_cat_slice,\n",
    "        np.all(\n",
    "            output_to_3d_thresholds(flat_preds, split=False) < clf_dict[cat],\n",
    "            axis=1\n",
    "        )\n",
    "    )\n",
    "\n",
    "cat_num_samples = {}\n",
    "for cat in range(len(clf_dict)):\n",
    "    cat_num_samples[cat] = {}\n",
    "    print('='*60)\n",
    "    print('='*60)\n",
    "    print(f\"Category {cat+1} {f'3D outputs NOT< {clf_dict[cat-1]} AND ' if cat > 0 else ''}3D outputs < {clf_dict[cat]} AND 120 GeV < m_HH < 130 GeV\")\n",
    "    # print(f\"Category {cat}: 3D outputs < {clf_dict[cat]:.4f} AND 120 GeV < m_HH < 130 GeV\")\n",
    "    print('-'*60)\n",
    "    for m, sample_name in enumerate(order):\n",
    "        sample_bool = np.logical_and(  # event passes conditions and is the right type (i.e. sample)\n",
    "            np.logical_and(  # event passes category and mass conditions\n",
    "                cat_dict[cat],  # event passes category selections\n",
    "                np.logical_and(  # diphoton mass is within 120-130 window\n",
    "                    flat_mass < 130,\n",
    "                    flat_mass > 120\n",
    "                ),\n",
    "            ),\n",
    "            flat_truths == m\n",
    "        )\n",
    "        cat_num_samples[cat][sample_name] = np.sum(\n",
    "            flat_weights[sample_bool]\n",
    "        )\n",
    "        print(f\"{cat+1}: Num {sample_name} = {cat_num_samples[cat][sample_name]:.4f}\")\n",
    "        print('-'*60)\n",
    "\n",
    "        if sample_name == order[-1]:\n",
    "            for smpl in [\n",
    "                ['GluGluHToGG', 'GluGlutoHHto2B2G_kl_1p00_kt_1p00_c2_0p00'],\n",
    "                ['VBFHToGG', 'VBFHToGG_M_125'],\n",
    "                ['GGJets'], ['GJetPt20To40'], ['GJetPt40']\n",
    "            ]:\n",
    "                smpl_num = 0\n",
    "                for smpl_ in smpl:\n",
    "                    smpl_num += np.sum(\n",
    "                        flat_weights[\n",
    "                            np.logical_and(\n",
    "                                sample_bool,\n",
    "                                flat_sample_names == smpl_\n",
    "                            )\n",
    "                        ]\n",
    "                    )\n",
    "                print(f\"{cat+1}: Num {smpl[0]} = {smpl_num:.4f}\")\n",
    "                print('-'*60)\n",
    "        elif sample_name == order[-2]:\n",
    "            smpl_num = np.sum(\n",
    "                flat_weights[\n",
    "                    np.logical_and(\n",
    "                        sample_bool,\n",
    "                        np.logical_or(\n",
    "                            flat_sample_names == 'VHToGG',\n",
    "                            flat_sample_names == 'VHtoGG_M_125'\n",
    "                        )\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "            print(f\"{cat+1}: Num VH, no ZH or WH = {smpl_num:.4f}\")\n",
    "            print('-'*60)\n",
    "\n",
    "        \n",
    "    print(f\"{cat+1}: S = {cat_num_samples[cat][order[0]]:.4f}, B = {np.sum([cat_num_samples[cat][order[v]] for v in range(1, len(order))]):.4f}, S/âB = {(cat_num_samples[cat][order[0]] / np.sqrt(np.sum([cat_num_samples[cat][order[v]] for v in range(1, len(order))]))):.4f}\")\n",
    "\n",
    "cat_num_samples = {}\n",
    "for cat in range(len(clf_dict)):\n",
    "    cat_num_samples[cat] = {}\n",
    "    print('='*60)\n",
    "    print('='*60)\n",
    "    print(f\"Category {cat+1} {f'3D outputs NOT< {clf_dict[cat-1]} AND ' if cat > 0 else ''}3D outputs < {clf_dict[cat]}\")\n",
    "    # print(f\"Category {cat}: 3D outputs < {clf_dict[cat]:.4f} AND 120 GeV < m_HH < 130 GeV\")\n",
    "    print('-'*60)\n",
    "    for m, sample_name in enumerate(order):\n",
    "        sample_bool = np.logical_and(  # event passes conditions and is the right type (i.e. sample)\n",
    "            cat_dict[cat],  # event passes category selections\n",
    "            flat_truths == m\n",
    "        )\n",
    "        cat_num_samples[cat][sample_name] = np.sum(\n",
    "            flat_weights[sample_bool]\n",
    "        )\n",
    "        print(f\"{cat+1}: Num {sample_name} = {cat_num_samples[cat][sample_name]:.4f}\")\n",
    "        print('-'*60)\n",
    "\n",
    "        if sample_name == order[-1]:\n",
    "            for smpl in [\n",
    "                ['GluGluHToGG', 'GluGlutoHHto2B2G_kl_1p00_kt_1p00_c2_0p00'],\n",
    "                ['VBFHToGG', 'VBFHToGG_M_125'],\n",
    "                ['GGJets'], ['GJetPt20To40'], ['GJetPt40']\n",
    "            ]:\n",
    "                smpl_num = 0\n",
    "                for smpl_ in smpl:\n",
    "                    smpl_num += np.sum(\n",
    "                        flat_weights[\n",
    "                            np.logical_and(\n",
    "                                sample_bool,\n",
    "                                flat_sample_names == smpl_\n",
    "                            )\n",
    "                        ]\n",
    "                    )\n",
    "                print(f\"{cat+1}: Num {smpl[0]} = {smpl_num:.4f}\")\n",
    "                print('-'*60)\n",
    "        elif sample_name == order[-2]:\n",
    "            smpl_num = np.sum(\n",
    "                flat_weights[\n",
    "                    np.logical_and(\n",
    "                        sample_bool,\n",
    "                        np.logical_or(\n",
    "                            flat_sample_names == 'VHToGG',\n",
    "                            flat_sample_names == 'VHtoGG_M_125'\n",
    "                        )\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "            print(f\"{cat+1}: Num VH, no ZH or WH = {smpl_num:.4f}\")\n",
    "            print('-'*60)\n",
    "    print(f\"{cat+1}: S = {cat_num_samples[cat][order[0]]:.4f}, B = {np.sum([cat_num_samples[cat][order[v]] for v in range(1, len(order))]):.4f}, S/âB = {(cat_num_samples[cat][order[0]] / np.sqrt(np.sum([cat_num_samples[cat][order[v]] for v in range(1, len(order))]))):.4f}\")\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0: FÎ² (Î²=1) score = \n",
      "[5.63017852e-04 8.50899670e-02 3.39366843e-02 9.76663535e-01]\n",
      "fold 1: FÎ² (Î²=1) score = \n",
      "[5.45515677e-04 7.84164171e-02 2.92184618e-02 9.75528539e-01]\n",
      "fold 2: FÎ² (Î²=1) score = \n",
      "[5.78744768e-04 8.87600804e-02 3.18369060e-02 9.76978655e-01]\n",
      "fold 3: FÎ² (Î²=1) score = \n",
      "[5.81067262e-04 1.02518702e-01 3.48552705e-02 9.77430251e-01]\n",
      "fold 4: FÎ² (Î²=1) score = \n",
      "[5.37796537e-04 9.25276621e-02 3.58576954e-02 9.75887042e-01]\n",
      "Sum over folds: FÎ² (Î²=1) score = \n",
      "[5.60730378e-04 8.87795435e-02 3.30116361e-02 9.76498160e-01]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 900x700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 900x700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 900x700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 900x700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 900x700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 900x700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"confusion_matrix\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "if 'BDT_perf' not in globals():\n",
    "    with open(os.path.join(OUTPUT_DIRPATH, CURRENT_TIME+\"_BDT_perf.json\"), 'r') as f:\n",
    "        BDT_perf = json.load(f)\n",
    "\n",
    "beta = 1\n",
    "normalize = 'true'  # 'true' for normalize over rows, None for absoulte yields\n",
    "\n",
    "for fold_idx in range(len(BDT_perf['ggF HH']['preds'])):\n",
    "\n",
    "    pred_classes = np.argmax(BDT_perf['ggF HH']['preds'][fold_idx], axis=1)\n",
    "\n",
    "    conf_matrix = confusion_matrix(\n",
    "        bdt_test_dict[f\"fold_{fold_idx}\"].get_label(), \n",
    "        pred_classes,\n",
    "        sample_weight=weights_plot_test[f\"fold_{fold_idx}\"],\n",
    "        normalize=normalize\n",
    "    )\n",
    "\n",
    "    plot_confusion_matrix(\n",
    "        conf_matrix, order, f\"confusion_matrix_fold{fold_idx}{'_norm_'+normalize if normalize is not None else ''}\", plot_dirpath\n",
    "    )\n",
    "\n",
    "    f1_scores = fbeta_score(\n",
    "        bdt_test_dict[f\"fold_{fold_idx}\"].get_label(), \n",
    "        pred_classes,\n",
    "        beta=beta,\n",
    "        sample_weight=weights_plot_test[f\"fold_{fold_idx}\"], average=None\n",
    "    )\n",
    "    print(f\"fold {fold_idx}: FÎ² (Î²={beta}) score = \\n{f1_scores}\")\n",
    "\n",
    "full_pred_classes = np.argmax(\n",
    "    np.concatenate(\n",
    "        [\n",
    "            BDT_perf['ggF HH']['preds'][fold_idx] for fold_idx in range(len(BDT_perf['ggF HH']['preds']))\n",
    "        ]\n",
    "    ), axis=1\n",
    ")\n",
    "full_labels = np.concatenate(\n",
    "    [\n",
    "        bdt_test_dict[f\"fold_{fold_idx}\"].get_label() for fold_idx in range(len(BDT_perf['ggF HH']['preds']))\n",
    "    ]\n",
    ")\n",
    "full_weights = np.concatenate(\n",
    "    [\n",
    "        weights_plot_test[f\"fold_{fold_idx}\"] for fold_idx in range(len(BDT_perf['ggF HH']['preds']))\n",
    "    ]\n",
    ")\n",
    "\n",
    "conf_matrix = confusion_matrix(\n",
    "    full_labels, \n",
    "    full_pred_classes,\n",
    "    sample_weight=full_weights,\n",
    "    normalize=normalize\n",
    ")\n",
    "\n",
    "plot_confusion_matrix(\n",
    "    conf_matrix, order, f\"confusion_matrix_sum{'_norm_'+normalize if normalize is not None else ''}\", plot_dirpath\n",
    ")\n",
    "\n",
    "f1_scores = fbeta_score(\n",
    "    full_labels, \n",
    "    full_pred_classes,\n",
    "    beta=beta,\n",
    "    sample_weight=full_weights, average=None\n",
    ")\n",
    "print(f\"Sum over folds: FÎ² (Î²={beta}) score = \\n{f1_scores}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:58] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:54:00] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:54:02] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:54:04] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:54:06] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"variable_importance\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "full_score_dict = {}\n",
    "for fold_idx in range(len(bdt_train_dict)):\n",
    "    booster = xgb.Booster(param, model_file=os.path.join(OUTPUT_DIRPATH, f'{CURRENT_TIME}_BDT_fold{fold_idx}.model'))\n",
    "\n",
    "    labels = copy.deepcopy([key for key in hlf_vars_columns_dict[f'fold_{fold_idx}'].keys()])\n",
    "    labels.sort()\n",
    "    \n",
    "    booster.feature_names = labels\n",
    "    score_dict = booster.get_score(importance_type='total_gain')\n",
    "    if fold_idx == 0:\n",
    "        full_score_dict = copy.deepcopy(score_dict)\n",
    "    else:\n",
    "        for key in full_score_dict.keys():\n",
    "            full_score_dict[key] += score_dict[key]\n",
    "\n",
    "    sorted_scores, sorted_labels = [], []\n",
    "    for label, score in score_dict.items():\n",
    "        sorted_scores.append(score)\n",
    "        sorted_labels.append(label)\n",
    "\n",
    "    sorted_labels = np.array(sorted_labels)[np.argsort(sorted_scores)]\n",
    "    sorted_scores = np.sort(sorted_scores)\n",
    "\n",
    "    plot_feature_importance(\n",
    "        sorted_scores, sorted_labels, f'xgb_importance_fold{fold_idx}', plot_dirpath\n",
    "    )\n",
    "\n",
    "full_sorted_scores, full_sorted_labels = [], []\n",
    "for label, score in full_score_dict.items():\n",
    "    full_sorted_scores.append(score / len(bdt_train_dict))\n",
    "    full_sorted_labels.append(label)\n",
    "\n",
    "full_sorted_labels = np.array(full_sorted_labels)[np.argsort(full_sorted_scores)]\n",
    "full_sorted_scores = np.sort(full_sorted_scores)\n",
    "\n",
    "plot_feature_importance(\n",
    "    full_sorted_scores, full_sorted_labels, f'xgb_importance_sum', plot_dirpath\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Variable Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "averaged correlation\n",
      "------------------------------------------------------------\n",
      "mass: 1.0000\n",
      "DeltaEta_jj: -0.0079\n",
      "DeltaPhi_isr_jet_z: -0.0004\n",
      "DeltaPhi_jj: 0.0013\n",
      "leadBjet_leadLepton: -0.0239\n",
      "HHbbggCandidate_eta: 0.0056\n",
      "HHbbggCandidate_pt: 0.0108\n",
      "pt_balance: -0.0126\n",
      "dijet_mass: 0.0019\n",
      "dijet_pt: 0.0227\n",
      "eta: 0.0091\n",
      "isr_jet_pt: 0.0006\n",
      "lead_bjet_pt: 0.0207\n",
      "lead_bjet_pt_over_Mjj: 0.0187\n",
      "lead_bjet_sigmapT_over_pT: -0.0144\n",
      "lead_mvaID: 0.0378\n",
      "lead_sigmaE_over_E: -0.1574\n",
      "lepton1_mvaID: -0.0239\n",
      "lepton1_pfIsoId: -0.0239\n",
      "lepton1_pt: -0.0255\n",
      "n_jets: 0.0033\n",
      "CosThetaStar_CS: 0.0043\n",
      "CosThetaStar_gg: -0.0012\n",
      "CosThetaStar_jj: 0.0052\n",
      "DeltaPhi_j1MET: -0.0001\n",
      "DeltaPhi_j2MET: -0.0011\n",
      "DeltaR_jg_min: 0.0047\n",
      "chi_t0: -0.0003\n",
      "chi_t1: -0.0006\n",
      "lead_bjet_btagPNetB: 0.0013\n",
      "lead_bjet_eta: 0.0044\n",
      "sublead_bjet_btagPNetB: 0.0041\n",
      "sublead_bjet_eta: -0.0002\n",
      "pt: 0.0546\n",
      "puppiMET_pt: -0.0110\n",
      "puppiMET_sumEt: 0.0390\n",
      "sublead_bjet_pt: 0.0119\n",
      "sublead_bjet_pt_over_Mjj: 0.0107\n",
      "sublead_bjet_sigmapT_over_pT: -0.0060\n",
      "sublead_mvaID: 0.0707\n",
      "sublead_sigmaE_over_E: -0.2375\n"
     ]
    }
   ],
   "source": [
    "data_corr_dict = {}\n",
    "for fold_idx in range(len(data_aux_dict)):\n",
    "    merged_pd = copy.deepcopy(data_df_dict[f\"fold_{fold_idx}\"])\n",
    "    for i, var_name in enumerate(['mass']):\n",
    "        merged_pd.insert(i, var_name, data_aux_dict[f\"fold_{fold_idx}\"].loc[:, var_name])\n",
    "    signal_merged_pd = merged_pd.loc[data_aux_dict[f\"fold_{fold_idx}\"].loc[:, 'sample_name'] == 'GluGluToHH']\n",
    "    data_corr_dict[f\"fold_{fold_idx}\"] = signal_merged_pd.corr()\n",
    "\n",
    "    # print(f\"fold {fold_idx}\")\n",
    "    # print('-'*60)\n",
    "    # print(data_corr_dict[f\"fold_{fold_idx}\"].iloc[0, :])\n",
    "    # print(f\"{'='*60}\\n{'='*60}\\n{'='*60}\\n\")\n",
    "\n",
    "print('averaged correlation')\n",
    "print('-'*60)\n",
    "corr_cols = data_corr_dict[f\"fold_0\"].columns\n",
    "avg_cols = data_corr_dict[f\"fold_0\"].iloc[0, :].to_numpy(copy=True)\n",
    "for fold_idx in range(1, len(data_corr_dict)):\n",
    "    avg_cols += data_corr_dict[f\"fold_{fold_idx}\"].iloc[0, :].to_numpy(copy=True)\n",
    "avg_cols /= len(data_corr_dict)\n",
    "avg_cols /= avg_cols[0]\n",
    "for i, col in enumerate(corr_cols):\n",
    "    print(f\"{col}: {avg_cols[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mass Sculpting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"mass_sculpting\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "if 'BDT_perf' not in globals():\n",
    "    with open(os.path.join(OUTPUT_DIRPATH, CURRENT_TIME+f\"_BDT_perf.json\"), 'r') as f:\n",
    "        BDT_perf = json.load(f)\n",
    "\n",
    "score_cuts = [0.0, 0.7, 0.99, 0.9963]\n",
    "label_arr = [f'score above {score_cut}' for score_cut in score_cuts]\n",
    "plot_vars = ['mass', 'dijet_mass', 'HHbbggCandidate_mass']\n",
    "\n",
    "# Loop over and plot the per-fold variables\n",
    "for fold_idx in range(len(hlf_vars_columns_dict)):\n",
    "\n",
    "    nonres_bool = (data_test_aux_dict[f\"fold_{fold_idx}\"].loc[:, 'sample_name'] == \"GGJets\") | (data_test_aux_dict[f\"fold_{fold_idx}\"].loc[:, 'sample_name'] == \"GJetPt20To40\") | (data_test_aux_dict[f\"fold_{fold_idx}\"].loc[:, 'sample_name'] == \"GJetPt40\")\n",
    "\n",
    "    pass_cut_bools = [\n",
    "        np.array(BDT_perf['ggF HH']['preds'][fold_idx])[:, 0] > score_cut for score_cut in score_cuts\n",
    "    ]\n",
    "\n",
    "    masks = [\n",
    "        np.logical_and(nonres_bool, pass_cut_bool) for pass_cut_bool in pass_cut_bools\n",
    "    ]\n",
    "\n",
    "    for var_idx, var_name in enumerate(plot_vars):\n",
    "\n",
    "        plot_dirpath_ = os.path.join(plot_dirpath, var_name)\n",
    "        if not os.path.exists(plot_dirpath_):\n",
    "            os.makedirs(plot_dirpath_)\n",
    "\n",
    "        nonres_sculpting_hists = [\n",
    "            hist.Hist(VARIABLES[var_name]).fill(\n",
    "                var=data_test_aux_dict[f\"fold_{fold_idx}\"].loc[mask, var_name]\n",
    "            ) for mask in masks\n",
    "        ]\n",
    "    \n",
    "        make_input_plot(\n",
    "            plot_dirpath_, var_name,\n",
    "            nonres_sculpting_hists, \n",
    "            fold_idx=fold_idx, labels=label_arr, \n",
    "            plot_prefix='test_non-res_scoreCut_', linestyle=False\n",
    "        )\n",
    "\n",
    "# flattened sculpting check\n",
    "flat_nonres_bool = np.concatenate([\n",
    "    (data_test_aux_dict[f\"fold_{fold_idx}\"].loc[:, 'sample_name'].to_numpy(copy=True) == \"GGJets\") \n",
    "    | (data_test_aux_dict[f\"fold_{fold_idx}\"].loc[:, 'sample_name'].to_numpy(copy=True) == \"GJetPt20To40\") \n",
    "    | (data_test_aux_dict[f\"fold_{fold_idx}\"].loc[:, 'sample_name'].to_numpy(copy=True) == \"GJetPt40\")\n",
    "    for fold_idx in range(len(data_test_aux_dict))\n",
    "])\n",
    "flat_pass_cut_bools = [\n",
    "    np.concatenate(BDT_perf['ggF HH']['preds'], axis=0)[:, 0] > score_cut for score_cut in score_cuts\n",
    "]\n",
    "flat_masks = [\n",
    "    np.logical_and(flat_nonres_bool, flat_pass_cut_bool) for flat_pass_cut_bool in flat_pass_cut_bools\n",
    "]\n",
    "\n",
    "for var_idx, var_name in enumerate(plot_vars):\n",
    "    flat_var = np.concatenate([\n",
    "        data_test_aux_dict[f\"fold_{fold_idx}\"].loc[:, var_name].to_numpy(copy=True) for fold_idx in range(len(data_test_aux_dict))\n",
    "    ])\n",
    "\n",
    "    plot_dirpath_ = os.path.join(plot_dirpath, var_name)\n",
    "    if not os.path.exists(plot_dirpath_):\n",
    "        os.makedirs(plot_dirpath_)\n",
    "\n",
    "    flat_nonres_sculpting_hists = [\n",
    "        hist.Hist(VARIABLES[var_name]).fill(var=flat_var[mask]) for mask in flat_masks\n",
    "    ]\n",
    "\n",
    "    make_input_plot(\n",
    "        plot_dirpath_, var_name,\n",
    "        flat_nonres_sculpting_hists, \n",
    "        fold_idx=None, labels=label_arr, \n",
    "        plot_prefix='test_non-res_scoreCut_', linestyle=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling for Mass Sculpting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def resample_from_var(\n",
    "    sample_var, sample_weight, n_events, \n",
    "    min_value=None,\n",
    "    n_samples_per_event=1, bins=100, seed=None\n",
    "):\n",
    "    resample_rng = np.random.default_rng(seed=seed)\n",
    "\n",
    "    np_hist, bin_edges = np.histogram(sample_var, bins=bins, weights=sample_weight, density=True)\n",
    "    np_hist /= np.sum(np_hist)\n",
    "\n",
    "    bin_choices = resample_rng.choice(np.arange(len(np_hist)), size=n_events*n_samples_per_event, p=np_hist)\n",
    "\n",
    "    value_choices = (bin_edges[bin_choices+1] - bin_edges[bin_choices]) * resample_rng.random(size=n_events*n_samples_per_event) + bin_edges[bin_choices]\n",
    "\n",
    "    if min_value is None or np.all(value_choices > min_value):\n",
    "        return value_choices\n",
    "    else:  # this is not really correct, just an approximation to make the code work faster\n",
    "        bad_choices_bool = value_choices <= min_value\n",
    "\n",
    "        largest_min_value = np.max(min_value[bad_choices_bool])\n",
    "\n",
    "        np_hist, bin_edges = np.histogram(sample_var[sample_var > largest_min_value], bins=bins, weights=sample_weight[sample_var > largest_min_value], density=True)\n",
    "        np_hist /= np.sum(np_hist)\n",
    "\n",
    "        bin_choices = resample_rng.choice(np.arange(len(np_hist)), size=np.sum(bad_choices_bool), p=np_hist)\n",
    "        \n",
    "        value_choices[bad_choices_bool] = (bin_edges[bin_choices+1] - bin_edges[bin_choices]) * resample_rng.random(size=np.sum(bad_choices_bool)) + bin_edges[bin_choices]\n",
    "        \n",
    "        return value_choices\n",
    "\n",
    "def resample_grow_np(var, bool_arr, n_duplicates_per_event):\n",
    "    new_rows_shape = tuple([n_duplicates_per_event]+[1 for _ in range(1, len(np.shape(var)))])\n",
    "    new_rows = np.tile(\n",
    "        var[bool_arr],\n",
    "        new_rows_shape\n",
    "    )\n",
    "    return np.concatenate([var, new_rows])\n",
    "def resample_grow_pd(var, bool_arr, n_duplicates_per_event):\n",
    "    new_rows = pd.DataFrame(\n",
    "        np.tile(\n",
    "            ( var.loc[bool_arr] ).to_numpy(),\n",
    "            (n_duplicates_per_event, 1)\n",
    "        ),\n",
    "        columns=var.columns\n",
    "    )\n",
    "    return pd.concat([var, new_rows], ignore_index=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:54:42] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:12:20] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:29:34] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:46:31] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:05:08] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resample_ = 10\n",
    "RESAMPLE = (resample_) * 10  # Set to False for no resampling, otherwise sets the number of times to duplicate gjet data for resampling\n",
    "\n",
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"mass_sculpting_resample_single\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "score_cuts = [0.0, 0.7, 0.99, 0.9983]\n",
    "label_arr = [f'score above {score_cut}' for score_cut in score_cuts]\n",
    "plot_vars = ['mass', 'dijet_mass', 'HHbbggCandidate_mass']\n",
    "\n",
    "BDT_perf_resample = [\n",
    "    {\n",
    "        f'preds{score_cut}': copy.deepcopy({plot_var: list() for plot_var in plot_vars+['event']}) for score_cut in score_cuts\n",
    "    } for fold_idx in range(len(bdt_train_dict))\n",
    "]\n",
    "\n",
    "for fold_idx in range(len(bdt_train_dict)):\n",
    "    booster = xgb.Booster(param)\n",
    "    booster.load_model(os.path.join(OUTPUT_DIRPATH, f'{CURRENT_TIME}_BDT_fold{fold_idx}.model'))\n",
    "\n",
    "    nonres_bool = (data_test_aux_dict[f\"fold_{fold_idx}\"].loc[:, 'sample_name'] == \"GGJets\") | (data_test_aux_dict[f\"fold_{fold_idx}\"].loc[:, 'sample_name'] == \"GJetPt20To40\") | (data_test_aux_dict[f\"fold_{fold_idx}\"].loc[:, 'sample_name'] == \"GJetPt40\")\n",
    "\n",
    "    data_hlf_test = resample_grow_np(data_hlf_test_dict[f\"fold_{fold_idx}\"], nonres_bool, resample_)\n",
    "    data_test_aux = resample_grow_pd(data_test_aux_dict[f\"fold_{fold_idx}\"], nonres_bool, resample_)\n",
    "    weight_test = resample_grow_np(weight_test_dict[f\"fold_{fold_idx}\"], nonres_bool, resample_)\n",
    "    weights_plot = resample_grow_np(weights_plot_test[f\"fold_{fold_idx}\"], nonres_bool, resample_)\n",
    "    xgb_label_test = resample_grow_np(xgb_label_test_dict[f\"fold_{fold_idx}\"], nonres_bool, resample_)\n",
    "\n",
    "    gg_bool = (data_test_aux.loc[:, 'sample_name'] == \"GGJets\")\n",
    "    tth_bool = (data_test_aux.loc[:, 'sample_name'] == \"ttHToGG\")\n",
    "    gj_bool = (data_test_aux.loc[:, 'sample_name'] == \"GJetPt20To40\") | (data_test_aux.loc[:, 'sample_name'] == \"GJetPt40\")\n",
    "    nonres_bool = (data_test_aux.loc[:, 'sample_name'] == \"GGJets\") | (data_test_aux.loc[:, 'sample_name'] == \"GJetPt20To40\") | (data_test_aux.loc[:, 'sample_name'] == \"GJetPt40\")\n",
    "\n",
    "\n",
    "    for _ in range(RESAMPLE // resample_):\n",
    "\n",
    "        for particle_type in ['lead', 'sublead']:\n",
    "\n",
    "            gg_mvaID = data_hlf_test[\n",
    "                gg_bool, \n",
    "                hlf_vars_columns_dict[f\"fold_{fold_idx}\"][f\"{particle_type}_mvaID\"]\n",
    "            ]\n",
    "            data_hlf_test[\n",
    "                gj_bool, \n",
    "                hlf_vars_columns_dict[f\"fold_{fold_idx}\"][f\"{particle_type}_mvaID\"]\n",
    "            ] = resample_from_var(\n",
    "                gg_mvaID, \n",
    "                weights_plot[gg_bool],\n",
    "                np.sum(gj_bool),\n",
    "                bins=190\n",
    "            )\n",
    "\n",
    "            tth_pNetB = data_hlf_test[\n",
    "                tth_bool, \n",
    "                hlf_vars_columns_dict[f\"fold_{fold_idx}\"][f\"{particle_type}_bjet_btagPNetB\"]\n",
    "            ]\n",
    "            data_hlf_test[\n",
    "                nonres_bool, \n",
    "                hlf_vars_columns_dict[f\"fold_{fold_idx}\"][f\"{particle_type}_bjet_btagPNetB\"]\n",
    "            ] = resample_from_var(\n",
    "                tth_pNetB, \n",
    "                np.abs(weights_plot[tth_bool]),\n",
    "                np.sum(nonres_bool),\n",
    "                bins=100,\n",
    "                min_value=data_test_aux.loc[nonres_bool, \"max_nonbjet_btag\"].to_numpy()\n",
    "            )\n",
    "\n",
    "        nonres_ggf_preds = booster.predict(\n",
    "            xgb.DMatrix(\n",
    "                data=data_hlf_test[nonres_bool], label=xgb_label_test[nonres_bool], \n",
    "                weight=np.abs(weight_test)[nonres_bool],\n",
    "                missing=-999.0, feature_names=list(hlf_vars_columns_dict[f\"fold_{fold_idx}\"])\n",
    "            ), \n",
    "            iteration_range=(0, booster.best_iteration+1)\n",
    "        )[:, 0]\n",
    "        \n",
    "        for score_cut in score_cuts:\n",
    "            if (\n",
    "                len(BDT_perf_resample[fold_idx][f'preds{score_cut}'][plot_vars[0]]) > 0 \n",
    "                and len(np.concatenate(BDT_perf_resample[fold_idx][f'preds{score_cut}'][plot_vars[0]])) >= 1000\n",
    "            ):\n",
    "                continue\n",
    "\n",
    "            new_unique_eventNumber = np.setdiff1d(\n",
    "                data_test_aux.loc[nonres_bool, \"event\"].to_numpy()[nonres_ggf_preds > score_cut],\n",
    "                BDT_perf_resample[fold_idx][f'preds{score_cut}'][\"event\"]\n",
    "            )\n",
    "            \n",
    "            if len(new_unique_eventNumber) > 0:\n",
    "                BDT_perf_resample[fold_idx][f'preds{score_cut}'][\"event\"].extend(new_unique_eventNumber.tolist())\n",
    "\n",
    "                intersect, comm1, comm2 = np.intersect1d(\n",
    "                    data_test_aux.loc[nonres_bool, \"event\"].to_numpy()[nonres_ggf_preds > score_cut],\n",
    "                    new_unique_eventNumber,\n",
    "                    return_indices=True\n",
    "                )\n",
    "\n",
    "                intersect_bool = np.zeros_like(\n",
    "                    data_test_aux.loc[nonres_bool, \"event\"].to_numpy()[nonres_ggf_preds > score_cut], \n",
    "                    dtype=bool\n",
    "                )\n",
    "                for index in comm1:\n",
    "                    intersect_bool[index] = True\n",
    "                \n",
    "                for var_idx, plot_var in enumerate(plot_vars):\n",
    "                    BDT_perf_resample[fold_idx][f'preds{score_cut}'][plot_var].append(\n",
    "                        data_test_aux.loc[nonres_bool, plot_var].to_numpy()[nonres_ggf_preds > score_cut][intersect_bool]\n",
    "                    )\n",
    "                \n",
    "    for var_idx, plot_var in enumerate(plot_vars):\n",
    "\n",
    "        plot_dirpath_ = os.path.join(plot_dirpath, plot_var)\n",
    "        if not os.path.exists(plot_dirpath_):\n",
    "            os.makedirs(plot_dirpath_)\n",
    "        \n",
    "        test_hists = [hist.Hist(VARIABLES[plot_var]).fill(var=np.concatenate(BDT_perf_resample[fold_idx][f'preds{score_cut}'][plot_var])) for score_cut in score_cuts]\n",
    "        make_input_plot(\n",
    "            plot_dirpath_, plot_var,\n",
    "            test_hists, \n",
    "            fold_idx=fold_idx, labels=label_arr, \n",
    "            plot_prefix='test_non-res_scoreCut_', linestyle=False\n",
    "        )\n",
    "\n",
    "for var_idx, plot_var in enumerate(plot_vars):\n",
    "\n",
    "    plot_dirpath_ = os.path.join(plot_dirpath, plot_var)\n",
    "    if not os.path.exists(plot_dirpath_):\n",
    "        os.makedirs(plot_dirpath_)\n",
    "\n",
    "    test_hists = [hist.Hist(VARIABLES[plot_var]).fill(\n",
    "        var=np.concatenate(\n",
    "            [np.concatenate(BDT_perf_resample[fold_idx][f'preds{score_cut}'][plot_var]) for fold_idx in range(len(BDT_perf_resample))]\n",
    "        )\n",
    "    ) for score_cut in score_cuts]\n",
    "    make_input_plot(\n",
    "        plot_dirpath_, plot_var,\n",
    "        test_hists, \n",
    "        fold_idx=None, labels=label_arr, \n",
    "        plot_prefix='test_non-res_scoreCut_', linestyle=False\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n"
     ]
    }
   ],
   "source": [
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"pre_std\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "label_arr_fold = [\n",
    "    MC_NAMES_PRETTY[\"GluGluToHH\"]+\" train\", MC_NAMES_PRETTY[\"GluGluToHH\"]+\" val\", MC_NAMES_PRETTY[\"GluGluToHH\"]+\" test\",\n",
    "    MC_NAMES_PRETTY[\"ttH + bbH\"]+\" train\", MC_NAMES_PRETTY[\"ttH + bbH\"]+\" val\", MC_NAMES_PRETTY[\"ttH + bbH\"]+\" test\",\n",
    "    # MC_NAMES_PRETTY[\"single-H\"]+\" train\", MC_NAMES_PRETTY[\"single-H\"]+\" val\", MC_NAMES_PRETTY[\"single-H\"]+\" test\",\n",
    "    # MC_NAMES_PRETTY[\"non-res\"]+\" train\", MC_NAMES_PRETTY[\"non-res\"]+\" val\", MC_NAMES_PRETTY[\"non-res\"]+\" test\",\n",
    "    MC_NAMES_PRETTY[\"VH\"]+\" train\", MC_NAMES_PRETTY[\"VH\"]+\" val\", MC_NAMES_PRETTY[\"VH\"]+\" test\",\n",
    "    MC_NAMES_PRETTY[\"non-res + ggFH + VBFH\"]+\" train\", MC_NAMES_PRETTY[\"non-res + ggFH + VBFH\"]+\" val\", MC_NAMES_PRETTY[\"non-res + ggFH + VBFH\"]+\" test\",\n",
    "]\n",
    "# Loop over and plot the per-fold variables\n",
    "for fold_idx in range(len(hlf_vars_columns_dict)):\n",
    "\n",
    "    for var_name in hlf_vars_columns_dict['fold_0']:\n",
    "        if var_name in {'puppiMET_eta'}:\n",
    "            continue\n",
    "\n",
    "        plot_dirpath_ = os.path.join(plot_dirpath, var_name)\n",
    "        if not os.path.exists(plot_dirpath_):\n",
    "            os.makedirs(plot_dirpath_)\n",
    "\n",
    "        train_hists, val_hists, test_hists = {}, {}, {}\n",
    "        for i, sample_name in enumerate(order):\n",
    "            train_mask = xgb_label_train_dict[f'fold_{fold_idx}'] == i\n",
    "            val_mask = xgb_label_val_dict[f'fold_{fold_idx}'] == i\n",
    "            test_mask = xgb_label_test_dict[f'fold_{fold_idx}'] == i\n",
    "\n",
    "            train_np = (\n",
    "                data_df_dict[f'fold_{fold_idx}'].iloc[train_idxs_dict[f'fold_{fold_idx}']]\n",
    "            ).loc[train_mask, var_name].to_numpy(dtype=int)\n",
    "            val_np = (\n",
    "                data_df_dict[f'fold_{fold_idx}'].iloc[val_idxs_dict[f'fold_{fold_idx}']]\n",
    "            ).loc[val_mask, var_name].to_numpy(dtype=int)\n",
    "            test_np = data_test_df_dict[f'fold_{fold_idx}'].loc[test_mask, var_name].to_numpy(dtype=int)\n",
    "\n",
    "            train_hists[sample_name] = hist.Hist(VARIABLES[var_name]).fill(var=train_np)\n",
    "            val_hists[sample_name] = hist.Hist(VARIABLES[var_name]).fill(var=val_np)\n",
    "            test_hists[sample_name] = hist.Hist(VARIABLES[var_name]).fill(var=test_np)\n",
    "    \n",
    "            make_input_plot(\n",
    "                plot_dirpath_, var_name,\n",
    "                [train_hists[sample_name], val_hists[sample_name], test_hists[sample_name]], \n",
    "                fold_idx=fold_idx, labels=label_arr_fold[3*i : 3*(i+1)], plot_prefix=f'train_val_test_{sample_name}_'\n",
    "            )\n",
    "        for j, (plot_type, histdict) in enumerate([('train_', train_hists), ('val_', val_hists), ('test_', test_hists)]):\n",
    "            if re.search('epton', var_name) is not None:\n",
    "                reduced_order = order[1:]\n",
    "                reduced_label_arr = label_arr_fold[j+3::3]\n",
    "            else:\n",
    "                reduced_order = order\n",
    "                reduced_label_arr = label_arr_fold[j::3]\n",
    "            make_input_plot(\n",
    "                plot_dirpath_, var_name,\n",
    "                [histdict[sample_name] for sample_name in reduced_order], \n",
    "                fold_idx=fold_idx, labels=reduced_label_arr, plot_prefix=plot_type\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n"
     ]
    }
   ],
   "source": [
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"post_std\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "label_arr_fold = [\n",
    "    MC_NAMES_PRETTY[\"GluGluToHH\"]+\" train\", MC_NAMES_PRETTY[\"GluGluToHH\"]+\" val\", MC_NAMES_PRETTY[\"GluGluToHH\"]+\" test\",\n",
    "    MC_NAMES_PRETTY[\"ttHToGG\"]+\" train\", MC_NAMES_PRETTY[\"ttHToGG\"]+\" val\", MC_NAMES_PRETTY[\"ttHToGG\"]+\" test\",\n",
    "    # MC_NAMES_PRETTY[\"single-H\"]+\" train\", MC_NAMES_PRETTY[\"single-H\"]+\" val\", MC_NAMES_PRETTY[\"single-H\"]+\" test\",\n",
    "    # MC_NAMES_PRETTY[\"non-res\"]+\" train\", MC_NAMES_PRETTY[\"non-res\"]+\" val\", MC_NAMES_PRETTY[\"non-res\"]+\" test\",\n",
    "    MC_NAMES_PRETTY[\"VH\"]+\" train\", MC_NAMES_PRETTY[\"VH\"]+\" val\", MC_NAMES_PRETTY[\"VH\"]+\" test\",\n",
    "    MC_NAMES_PRETTY[\"non-res + ggFH + VBFH\"]+\" train\", MC_NAMES_PRETTY[\"non-res + ggFH + VBFH\"]+\" val\", MC_NAMES_PRETTY[\"non-res + ggFH + VBFH\"]+\" test\",\n",
    "]\n",
    "# Loop over and plot the per-fold variables\n",
    "for fold_idx in range(len(hlf_vars_columns_dict)):\n",
    "\n",
    "    for var_idx, var_name in enumerate(hlf_vars_columns_dict['fold_0']):\n",
    "        if var_name in {'puppiMET_eta'}:\n",
    "            continue\n",
    "\n",
    "        plot_dirpath_ = os.path.join(plot_dirpath, var_name)\n",
    "        if not os.path.exists(plot_dirpath_):\n",
    "            os.makedirs(plot_dirpath_)\n",
    "\n",
    "        train_hists, val_hists, test_hists = {}, {}, {}\n",
    "        for i, sample_name in enumerate(order):\n",
    "            train_mask = xgb_label_train_dict[f'fold_{fold_idx}'] == i\n",
    "            val_mask = xgb_label_val_dict[f'fold_{fold_idx}'] == i\n",
    "            test_mask = xgb_label_test_dict[f'fold_{fold_idx}'] == i\n",
    "\n",
    "            train_np = train_data_dict[f'fold_{fold_idx}'][train_mask, var_idx]\n",
    "            val_np = val_data_dict[f'fold_{fold_idx}'][val_mask, var_idx]\n",
    "            test_np = data_hlf_test_dict[f'fold_{fold_idx}'][test_mask, var_idx]\n",
    "\n",
    "            train_hists[sample_name] = hist.Hist(VARIABLES_STD[var_name]).fill(var=train_np)\n",
    "            val_hists[sample_name] = hist.Hist(VARIABLES_STD[var_name]).fill(var=val_np)\n",
    "            test_hists[sample_name] = hist.Hist(VARIABLES_STD[var_name]).fill(var=test_np)\n",
    "    \n",
    "            make_input_plot(\n",
    "                plot_dirpath_, var_name,\n",
    "                [train_hists[sample_name], val_hists[sample_name], test_hists[sample_name]], \n",
    "                fold_idx=fold_idx, labels=label_arr_fold[3*i : 3*(i+1)], plot_prefix=f'train_val_test_{sample_name}_'\n",
    "            )\n",
    "        for j, (plot_type, histdict) in enumerate([('train_', train_hists), ('val_', val_hists), ('test_', test_hists)]):\n",
    "            make_input_plot(\n",
    "                plot_dirpath_, var_name,\n",
    "                [histdict[sample_name] for sample_name in order], \n",
    "                fold_idx=fold_idx, labels=label_arr_fold[j::3], plot_prefix=plot_type\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save out new parquets for Yibo to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lead_seediEtaOriX\n",
      "------------------------------------------------------------\n",
      "lead_cutBased\n",
      "------------------------------------------------------------\n",
      "lead_electronVeto\n",
      "------------------------------------------------------------\n",
      "lead_hasConversionTracks\n",
      "------------------------------------------------------------\n",
      "lead_isScEtaEB\n",
      "------------------------------------------------------------\n",
      "lead_isScEtaEE\n",
      "------------------------------------------------------------\n",
      "lead_mvaID_WP80\n",
      "------------------------------------------------------------\n",
      "lead_mvaID_WP90\n",
      "------------------------------------------------------------\n",
      "lead_pixelSeed\n",
      "------------------------------------------------------------\n",
      "lead_seedGain\n",
      "------------------------------------------------------------\n",
      "lead_electronIdx\n",
      "------------------------------------------------------------\n",
      "lead_jetIdx\n",
      "------------------------------------------------------------\n",
      "lead_seediPhiOriY\n",
      "------------------------------------------------------------\n",
      "lead_vidNestedWPBitmap\n",
      "------------------------------------------------------------\n",
      "lead_ecalPFClusterIso\n",
      "------------------------------------------------------------\n",
      "lead_energyErr\n",
      "------------------------------------------------------------\n",
      "lead_energyRaw\n",
      "------------------------------------------------------------\n",
      "lead_esEffSigmaRR\n",
      "------------------------------------------------------------\n",
      "lead_esEnergyOverRawE\n",
      "------------------------------------------------------------\n",
      "lead_eta\n",
      "------------------------------------------------------------\n",
      "lead_etaWidth\n",
      "------------------------------------------------------------\n",
      "lead_haloTaggerMVAVal\n",
      "------------------------------------------------------------\n",
      "lead_hcalPFClusterIso\n",
      "------------------------------------------------------------\n",
      "lead_hoe\n",
      "------------------------------------------------------------\n",
      "lead_hoe_PUcorr\n",
      "------------------------------------------------------------\n",
      "lead_mvaID\n",
      "------------------------------------------------------------\n",
      "lead_pfChargedIso\n",
      "------------------------------------------------------------\n",
      "lead_pfChargedIsoPFPV\n",
      "------------------------------------------------------------\n",
      "lead_pfChargedIsoWorstVtx\n",
      "------------------------------------------------------------\n",
      "lead_pfPhoIso03\n",
      "------------------------------------------------------------\n",
      "lead_pfRelIso03_all_quadratic\n",
      "------------------------------------------------------------\n",
      "lead_pfRelIso03_chg_quadratic\n",
      "------------------------------------------------------------\n",
      "lead_phi\n",
      "------------------------------------------------------------\n",
      "lead_phiWidth\n",
      "------------------------------------------------------------\n",
      "lead_r9\n",
      "------------------------------------------------------------\n",
      "lead_s4\n",
      "------------------------------------------------------------\n",
      "lead_sieie\n",
      "------------------------------------------------------------\n",
      "lead_sieip\n",
      "------------------------------------------------------------\n",
      "lead_sipip\n",
      "------------------------------------------------------------\n",
      "lead_trkSumPtHollowConeDR03\n",
      "------------------------------------------------------------\n",
      "lead_trkSumPtSolidConeDR04\n",
      "------------------------------------------------------------\n",
      "lead_x_calo\n",
      "------------------------------------------------------------\n",
      "lead_y_calo\n",
      "------------------------------------------------------------\n",
      "lead_z_calo\n",
      "------------------------------------------------------------\n",
      "lead_electronIdxG\n",
      "------------------------------------------------------------\n",
      "lead_jetIdxG\n",
      "------------------------------------------------------------\n",
      "lead_ScEta\n",
      "------------------------------------------------------------\n",
      "lead_rho_smear\n",
      "------------------------------------------------------------\n",
      "lead_pt\n",
      "------------------------------------------------------------\n",
      "lead_charge\n",
      "------------------------------------------------------------\n",
      "sublead_seediEtaOriX\n",
      "------------------------------------------------------------\n",
      "sublead_cutBased\n",
      "------------------------------------------------------------\n",
      "sublead_electronVeto\n",
      "------------------------------------------------------------\n",
      "sublead_hasConversionTracks\n",
      "------------------------------------------------------------\n",
      "sublead_isScEtaEB\n",
      "------------------------------------------------------------\n",
      "sublead_isScEtaEE\n",
      "------------------------------------------------------------\n",
      "sublead_mvaID_WP80\n",
      "------------------------------------------------------------\n",
      "sublead_mvaID_WP90\n",
      "------------------------------------------------------------\n",
      "sublead_pixelSeed\n",
      "------------------------------------------------------------\n",
      "sublead_seedGain\n",
      "------------------------------------------------------------\n",
      "sublead_electronIdx\n",
      "------------------------------------------------------------\n",
      "sublead_jetIdx\n",
      "------------------------------------------------------------\n",
      "sublead_seediPhiOriY\n",
      "------------------------------------------------------------\n",
      "sublead_vidNestedWPBitmap\n",
      "------------------------------------------------------------\n",
      "sublead_ecalPFClusterIso\n",
      "------------------------------------------------------------\n",
      "sublead_energyErr\n",
      "------------------------------------------------------------\n",
      "sublead_energyRaw\n",
      "------------------------------------------------------------\n",
      "sublead_esEffSigmaRR\n",
      "------------------------------------------------------------\n",
      "sublead_esEnergyOverRawE\n",
      "------------------------------------------------------------\n",
      "sublead_eta\n",
      "------------------------------------------------------------\n",
      "sublead_etaWidth\n",
      "------------------------------------------------------------\n",
      "sublead_haloTaggerMVAVal\n",
      "------------------------------------------------------------\n",
      "sublead_hcalPFClusterIso\n",
      "------------------------------------------------------------\n",
      "sublead_hoe\n",
      "------------------------------------------------------------\n",
      "sublead_hoe_PUcorr\n",
      "------------------------------------------------------------\n",
      "sublead_mvaID\n",
      "------------------------------------------------------------\n",
      "sublead_pfChargedIso\n",
      "------------------------------------------------------------\n",
      "sublead_pfChargedIsoPFPV\n",
      "------------------------------------------------------------\n",
      "sublead_pfChargedIsoWorstVtx\n",
      "------------------------------------------------------------\n",
      "sublead_pfPhoIso03\n",
      "------------------------------------------------------------\n",
      "sublead_pfRelIso03_all_quadratic\n",
      "------------------------------------------------------------\n",
      "sublead_pfRelIso03_chg_quadratic\n",
      "------------------------------------------------------------\n",
      "sublead_phi\n",
      "------------------------------------------------------------\n",
      "sublead_phiWidth\n",
      "------------------------------------------------------------\n",
      "sublead_r9\n",
      "------------------------------------------------------------\n",
      "sublead_s4\n",
      "------------------------------------------------------------\n",
      "sublead_sieie\n",
      "------------------------------------------------------------\n",
      "sublead_sieip\n",
      "------------------------------------------------------------\n",
      "sublead_sipip\n",
      "------------------------------------------------------------\n",
      "sublead_trkSumPtHollowConeDR03\n",
      "------------------------------------------------------------\n",
      "sublead_trkSumPtSolidConeDR04\n",
      "------------------------------------------------------------\n",
      "sublead_x_calo\n",
      "------------------------------------------------------------\n",
      "sublead_y_calo\n",
      "------------------------------------------------------------\n",
      "sublead_z_calo\n",
      "------------------------------------------------------------\n",
      "sublead_electronIdxG\n",
      "------------------------------------------------------------\n",
      "sublead_jetIdxG\n",
      "------------------------------------------------------------\n",
      "sublead_ScEta\n",
      "------------------------------------------------------------\n",
      "sublead_rho_smear\n",
      "------------------------------------------------------------\n",
      "sublead_pt\n",
      "------------------------------------------------------------\n",
      "sublead_charge\n",
      "------------------------------------------------------------\n",
      "pt\n",
      "------------------------------------------------------------\n",
      "eta\n",
      "------------------------------------------------------------\n",
      "phi\n",
      "------------------------------------------------------------\n",
      "mass\n",
      "------------------------------------------------------------\n",
      "charge\n",
      "------------------------------------------------------------\n",
      "rapidity\n",
      "------------------------------------------------------------\n",
      "pass_fiducial_classical\n",
      "------------------------------------------------------------\n",
      "pass_fiducial_geometric\n",
      "------------------------------------------------------------\n",
      "n_electrons\n",
      "------------------------------------------------------------\n",
      "n_muons\n",
      "------------------------------------------------------------\n",
      "n_electrons_after_dxy_dz_cuts\n",
      "------------------------------------------------------------\n",
      "n_muons_after_dxy_dz_cuts\n",
      "------------------------------------------------------------\n",
      "n_jets\n",
      "------------------------------------------------------------\n",
      "Njets2p5\n",
      "------------------------------------------------------------\n",
      "jet1_pt\n",
      "------------------------------------------------------------\n",
      "jet1_eta\n",
      "------------------------------------------------------------\n",
      "jet1_phi\n",
      "------------------------------------------------------------\n",
      "jet1_mass\n",
      "------------------------------------------------------------\n",
      "jet1_charge\n",
      "------------------------------------------------------------\n",
      "jet1_btagDeepFlav_B\n",
      "------------------------------------------------------------\n",
      "jet1_btagPNetB\n",
      "------------------------------------------------------------\n",
      "jet1_PNetRegPtRawCorr\n",
      "------------------------------------------------------------\n",
      "jet1_PNetRegPtRawCorrNeutrino\n",
      "------------------------------------------------------------\n",
      "jet1_PNetRegPtRawRes\n",
      "------------------------------------------------------------\n",
      "jet1_btagRobustParTAK4B\n",
      "------------------------------------------------------------\n",
      "jet1_index\n",
      "------------------------------------------------------------\n",
      "jet2_pt\n",
      "------------------------------------------------------------\n",
      "jet2_eta\n",
      "------------------------------------------------------------\n",
      "jet2_phi\n",
      "------------------------------------------------------------\n",
      "jet2_mass\n",
      "------------------------------------------------------------\n",
      "jet2_charge\n",
      "------------------------------------------------------------\n",
      "jet2_btagDeepFlav_B\n",
      "------------------------------------------------------------\n",
      "jet2_btagPNetB\n",
      "------------------------------------------------------------\n",
      "jet2_PNetRegPtRawCorr\n",
      "------------------------------------------------------------\n",
      "jet2_PNetRegPtRawCorrNeutrino\n",
      "------------------------------------------------------------\n",
      "jet2_PNetRegPtRawRes\n",
      "------------------------------------------------------------\n",
      "jet2_btagRobustParTAK4B\n",
      "------------------------------------------------------------\n",
      "jet2_index\n",
      "------------------------------------------------------------\n",
      "jet3_pt\n",
      "------------------------------------------------------------\n",
      "jet3_eta\n",
      "------------------------------------------------------------\n",
      "jet3_phi\n",
      "------------------------------------------------------------\n",
      "jet3_mass\n",
      "------------------------------------------------------------\n",
      "jet3_charge\n",
      "------------------------------------------------------------\n",
      "jet3_btagDeepFlav_B\n",
      "------------------------------------------------------------\n",
      "jet3_btagPNetB\n",
      "------------------------------------------------------------\n",
      "jet3_PNetRegPtRawCorr\n",
      "------------------------------------------------------------\n",
      "jet3_PNetRegPtRawCorrNeutrino\n",
      "------------------------------------------------------------\n",
      "jet3_PNetRegPtRawRes\n",
      "------------------------------------------------------------\n",
      "jet3_btagRobustParTAK4B\n",
      "------------------------------------------------------------\n",
      "jet3_index\n",
      "------------------------------------------------------------\n",
      "jet4_pt\n",
      "------------------------------------------------------------\n",
      "jet4_eta\n",
      "------------------------------------------------------------\n",
      "jet4_phi\n",
      "------------------------------------------------------------\n",
      "jet4_mass\n",
      "------------------------------------------------------------\n",
      "jet4_charge\n",
      "------------------------------------------------------------\n",
      "jet4_btagDeepFlav_B\n",
      "------------------------------------------------------------\n",
      "jet4_btagPNetB\n",
      "------------------------------------------------------------\n",
      "jet4_PNetRegPtRawCorr\n",
      "------------------------------------------------------------\n",
      "jet4_PNetRegPtRawCorrNeutrino\n",
      "------------------------------------------------------------\n",
      "jet4_PNetRegPtRawRes\n",
      "------------------------------------------------------------\n",
      "jet4_btagRobustParTAK4B\n",
      "------------------------------------------------------------\n",
      "jet4_index\n",
      "------------------------------------------------------------\n",
      "jet5_pt\n",
      "------------------------------------------------------------\n",
      "jet5_eta\n",
      "------------------------------------------------------------\n",
      "jet5_phi\n",
      "------------------------------------------------------------\n",
      "jet5_mass\n",
      "------------------------------------------------------------\n",
      "jet5_charge\n",
      "------------------------------------------------------------\n",
      "jet5_btagDeepFlav_B\n",
      "------------------------------------------------------------\n",
      "jet5_btagPNetB\n",
      "------------------------------------------------------------\n",
      "jet5_PNetRegPtRawCorr\n",
      "------------------------------------------------------------\n",
      "jet5_PNetRegPtRawCorrNeutrino\n",
      "------------------------------------------------------------\n",
      "jet5_PNetRegPtRawRes\n",
      "------------------------------------------------------------\n",
      "jet5_btagRobustParTAK4B\n",
      "------------------------------------------------------------\n",
      "jet5_index\n",
      "------------------------------------------------------------\n",
      "jet6_pt\n",
      "------------------------------------------------------------\n",
      "jet6_eta\n",
      "------------------------------------------------------------\n",
      "jet6_phi\n",
      "------------------------------------------------------------\n",
      "jet6_mass\n",
      "------------------------------------------------------------\n",
      "jet6_charge\n",
      "------------------------------------------------------------\n",
      "jet6_btagDeepFlav_B\n",
      "------------------------------------------------------------\n",
      "jet6_btagPNetB\n",
      "------------------------------------------------------------\n",
      "jet6_PNetRegPtRawCorr\n",
      "------------------------------------------------------------\n",
      "jet6_PNetRegPtRawCorrNeutrino\n",
      "------------------------------------------------------------\n",
      "jet6_PNetRegPtRawRes\n",
      "------------------------------------------------------------\n",
      "jet6_btagRobustParTAK4B\n",
      "------------------------------------------------------------\n",
      "jet6_index\n",
      "------------------------------------------------------------\n",
      "jet7_pt\n",
      "------------------------------------------------------------\n",
      "jet7_eta\n",
      "------------------------------------------------------------\n",
      "jet7_phi\n",
      "------------------------------------------------------------\n",
      "jet7_mass\n",
      "------------------------------------------------------------\n",
      "jet7_charge\n",
      "------------------------------------------------------------\n",
      "jet7_btagDeepFlav_B\n",
      "------------------------------------------------------------\n",
      "jet7_btagPNetB\n",
      "------------------------------------------------------------\n",
      "jet7_PNetRegPtRawCorr\n",
      "------------------------------------------------------------\n",
      "jet7_PNetRegPtRawCorrNeutrino\n",
      "------------------------------------------------------------\n",
      "jet7_PNetRegPtRawRes\n",
      "------------------------------------------------------------\n",
      "jet7_btagRobustParTAK4B\n",
      "------------------------------------------------------------\n",
      "jet7_index\n",
      "------------------------------------------------------------\n",
      "jet8_pt\n",
      "------------------------------------------------------------\n",
      "jet8_eta\n",
      "------------------------------------------------------------\n",
      "jet8_phi\n",
      "------------------------------------------------------------\n",
      "jet8_mass\n",
      "------------------------------------------------------------\n",
      "jet8_charge\n",
      "------------------------------------------------------------\n",
      "jet8_btagDeepFlav_B\n",
      "------------------------------------------------------------\n",
      "jet8_btagPNetB\n",
      "------------------------------------------------------------\n",
      "jet8_PNetRegPtRawCorr\n",
      "------------------------------------------------------------\n",
      "jet8_PNetRegPtRawCorrNeutrino\n",
      "------------------------------------------------------------\n",
      "jet8_PNetRegPtRawRes\n",
      "------------------------------------------------------------\n",
      "jet8_btagRobustParTAK4B\n",
      "------------------------------------------------------------\n",
      "jet8_index\n",
      "------------------------------------------------------------\n",
      "jet9_pt\n",
      "------------------------------------------------------------\n",
      "jet9_eta\n",
      "------------------------------------------------------------\n",
      "jet9_phi\n",
      "------------------------------------------------------------\n",
      "jet9_mass\n",
      "------------------------------------------------------------\n",
      "jet9_charge\n",
      "------------------------------------------------------------\n",
      "jet9_btagDeepFlav_B\n",
      "------------------------------------------------------------\n",
      "jet9_btagPNetB\n",
      "------------------------------------------------------------\n",
      "jet9_PNetRegPtRawCorr\n",
      "------------------------------------------------------------\n",
      "jet9_PNetRegPtRawCorrNeutrino\n",
      "------------------------------------------------------------\n",
      "jet9_PNetRegPtRawRes\n",
      "------------------------------------------------------------\n",
      "jet9_btagRobustParTAK4B\n",
      "------------------------------------------------------------\n",
      "jet9_index\n",
      "------------------------------------------------------------\n",
      "jet10_pt\n",
      "------------------------------------------------------------\n",
      "jet10_eta\n",
      "------------------------------------------------------------\n",
      "jet10_phi\n",
      "------------------------------------------------------------\n",
      "jet10_mass\n",
      "------------------------------------------------------------\n",
      "jet10_charge\n",
      "------------------------------------------------------------\n",
      "jet10_btagDeepFlav_B\n",
      "------------------------------------------------------------\n",
      "jet10_btagPNetB\n",
      "------------------------------------------------------------\n",
      "jet10_PNetRegPtRawCorr\n",
      "------------------------------------------------------------\n",
      "jet10_PNetRegPtRawCorrNeutrino\n",
      "------------------------------------------------------------\n",
      "jet10_PNetRegPtRawRes\n",
      "------------------------------------------------------------\n",
      "jet10_btagRobustParTAK4B\n",
      "------------------------------------------------------------\n",
      "jet10_index\n",
      "------------------------------------------------------------\n",
      "n_fatjets\n",
      "------------------------------------------------------------\n",
      "nonRes_HHbbggCandidate_pt\n",
      "------------------------------------------------------------\n",
      "nonRes_HHbbggCandidate_eta\n",
      "------------------------------------------------------------\n",
      "nonRes_HHbbggCandidate_phi\n",
      "------------------------------------------------------------\n",
      "nonRes_HHbbggCandidate_mass\n",
      "------------------------------------------------------------\n",
      "nonRes_M_X\n",
      "------------------------------------------------------------\n",
      "nonRes_lead_bjet_pt\n",
      "------------------------------------------------------------\n",
      "nonRes_lead_bjet_eta\n",
      "------------------------------------------------------------\n",
      "nonRes_lead_bjet_phi\n",
      "------------------------------------------------------------\n",
      "nonRes_lead_bjet_mass\n",
      "------------------------------------------------------------\n",
      "nonRes_lead_bjet_charge\n",
      "------------------------------------------------------------\n",
      "nonRes_lead_bjet_btagPNetB\n",
      "------------------------------------------------------------\n",
      "nonRes_lead_bjet_PNetRegPtRawCorr\n",
      "------------------------------------------------------------\n",
      "nonRes_lead_bjet_PNetRegPtRawCorrNeutrino\n",
      "------------------------------------------------------------\n",
      "nonRes_lead_bjet_PNetRegPtRawRes\n",
      "------------------------------------------------------------\n",
      "nonRes_lead_bjet_jet_idx\n",
      "------------------------------------------------------------\n",
      "nonRes_sublead_bjet_pt\n",
      "------------------------------------------------------------\n",
      "nonRes_sublead_bjet_eta\n",
      "------------------------------------------------------------\n",
      "nonRes_sublead_bjet_phi\n",
      "------------------------------------------------------------\n",
      "nonRes_sublead_bjet_mass\n",
      "------------------------------------------------------------\n",
      "nonRes_sublead_bjet_charge\n",
      "------------------------------------------------------------\n",
      "nonRes_sublead_bjet_btagPNetB\n",
      "------------------------------------------------------------\n",
      "nonRes_sublead_bjet_PNetRegPtRawCorr\n",
      "------------------------------------------------------------\n",
      "nonRes_sublead_bjet_PNetRegPtRawCorrNeutrino\n",
      "------------------------------------------------------------\n",
      "nonRes_sublead_bjet_PNetRegPtRawRes\n",
      "------------------------------------------------------------\n",
      "nonRes_sublead_bjet_jet_idx\n",
      "------------------------------------------------------------\n",
      "nonRes_dijet_pt\n",
      "------------------------------------------------------------\n",
      "nonRes_dijet_eta\n",
      "------------------------------------------------------------\n",
      "nonRes_dijet_phi\n",
      "------------------------------------------------------------\n",
      "nonRes_dijet_mass\n",
      "------------------------------------------------------------\n",
      "nonRes_dijet_charge\n",
      "------------------------------------------------------------\n",
      "nonRes_pholead_PtOverM\n",
      "------------------------------------------------------------\n",
      "nonRes_phosublead_PtOverM\n",
      "------------------------------------------------------------\n",
      "nonRes_FirstJet_PtOverM\n",
      "------------------------------------------------------------\n",
      "nonRes_SecondJet_PtOverM\n",
      "------------------------------------------------------------\n",
      "nonRes_DeltaR_j1g1\n",
      "------------------------------------------------------------\n",
      "nonRes_DeltaR_j2g1\n",
      "------------------------------------------------------------\n",
      "nonRes_DeltaR_j1g2\n",
      "------------------------------------------------------------\n",
      "nonRes_DeltaR_j2g2\n",
      "------------------------------------------------------------\n",
      "nonRes_DeltaR_jg_min\n",
      "------------------------------------------------------------\n",
      "nonRes_chi_t0\n",
      "------------------------------------------------------------\n",
      "nonRes_chi_t1\n",
      "------------------------------------------------------------\n",
      "nonRes_DeltaPhi_j1MET\n",
      "------------------------------------------------------------\n",
      "nonRes_DeltaPhi_j2MET\n",
      "------------------------------------------------------------\n",
      "nonRes_CosThetaStar_CS\n",
      "------------------------------------------------------------\n",
      "nonRes_CosThetaStar_gg\n",
      "------------------------------------------------------------\n",
      "nonRes_CosThetaStar_jj\n",
      "------------------------------------------------------------\n",
      "VBF_first_jet_pt\n",
      "------------------------------------------------------------\n",
      "VBF_first_jet_eta\n",
      "------------------------------------------------------------\n",
      "VBF_first_jet_phi\n",
      "------------------------------------------------------------\n",
      "VBF_first_jet_mass\n",
      "------------------------------------------------------------\n",
      "VBF_first_jet_charge\n",
      "------------------------------------------------------------\n",
      "VBF_first_jet_btagPNetB\n",
      "------------------------------------------------------------\n",
      "VBF_first_jet_PNetRegPtRawCorr\n",
      "------------------------------------------------------------\n",
      "VBF_first_jet_PNetRegPtRawCorrNeutrino\n",
      "------------------------------------------------------------\n",
      "VBF_first_jet_PNetRegPtRawRes\n",
      "------------------------------------------------------------\n",
      "VBF_first_jet_btagPNetQvG\n",
      "------------------------------------------------------------\n",
      "VBF_first_jet_btagDeepFlav_QG\n",
      "------------------------------------------------------------\n",
      "VBF_second_jet_pt\n",
      "------------------------------------------------------------\n",
      "VBF_second_jet_eta\n",
      "------------------------------------------------------------\n",
      "VBF_second_jet_phi\n",
      "------------------------------------------------------------\n",
      "VBF_second_jet_mass\n",
      "------------------------------------------------------------\n",
      "VBF_second_jet_charge\n",
      "------------------------------------------------------------\n",
      "VBF_second_jet_btagPNetB\n",
      "------------------------------------------------------------\n",
      "VBF_second_jet_PNetRegPtRawCorr\n",
      "------------------------------------------------------------\n",
      "VBF_second_jet_PNetRegPtRawCorrNeutrino\n",
      "------------------------------------------------------------\n",
      "VBF_second_jet_PNetRegPtRawRes\n",
      "------------------------------------------------------------\n",
      "VBF_second_jet_btagPNetQvG\n",
      "------------------------------------------------------------\n",
      "VBF_second_jet_btagDeepFlav_QG\n",
      "------------------------------------------------------------\n",
      "VBF_dijet_pt\n",
      "------------------------------------------------------------\n",
      "VBF_dijet_eta\n",
      "------------------------------------------------------------\n",
      "VBF_dijet_phi\n",
      "------------------------------------------------------------\n",
      "VBF_dijet_mass\n",
      "------------------------------------------------------------\n",
      "VBF_dijet_charge\n",
      "------------------------------------------------------------\n",
      "VBF_first_jet_PtOverM\n",
      "------------------------------------------------------------\n",
      "VBF_second_jet_PtOverM\n",
      "------------------------------------------------------------\n",
      "VBF_first_jet_index\n",
      "------------------------------------------------------------\n",
      "VBF_second_jet_index\n",
      "------------------------------------------------------------\n",
      "VBF_jet_eta_prod\n",
      "------------------------------------------------------------\n",
      "VBF_jet_eta_diff\n",
      "------------------------------------------------------------\n",
      "VBF_jet_eta_sum\n",
      "------------------------------------------------------------\n",
      "VBF_DeltaR_j1b1\n",
      "------------------------------------------------------------\n",
      "VBF_DeltaR_j1b2\n",
      "------------------------------------------------------------\n",
      "VBF_DeltaR_j2b1\n",
      "------------------------------------------------------------\n",
      "VBF_DeltaR_j2b2\n",
      "------------------------------------------------------------\n",
      "VBF_DeltaR_j1g1\n",
      "------------------------------------------------------------\n",
      "VBF_DeltaR_j1g2\n",
      "------------------------------------------------------------\n",
      "VBF_DeltaR_j2g1\n",
      "------------------------------------------------------------\n",
      "VBF_DeltaR_j2g2\n",
      "------------------------------------------------------------\n",
      "VBF_DeltaR_jb_min\n",
      "------------------------------------------------------------\n",
      "VBF_DeltaR_jg_min\n",
      "------------------------------------------------------------\n",
      "VBF_Cgg\n",
      "------------------------------------------------------------\n",
      "VBF_Cbb\n",
      "------------------------------------------------------------\n",
      "nonRes_has_two_btagged_jets\n",
      "------------------------------------------------------------\n",
      "nonRes_has_atleast_one_fatjet\n",
      "------------------------------------------------------------\n",
      "is_nonRes\n",
      "------------------------------------------------------------\n",
      "Res_HHbbggCandidate_pt\n",
      "------------------------------------------------------------\n",
      "Res_HHbbggCandidate_eta\n",
      "------------------------------------------------------------\n",
      "Res_HHbbggCandidate_phi\n",
      "------------------------------------------------------------\n",
      "Res_HHbbggCandidate_mass\n",
      "------------------------------------------------------------\n",
      "Res_M_X\n",
      "------------------------------------------------------------\n",
      "Res_lead_bjet_pt\n",
      "------------------------------------------------------------\n",
      "Res_lead_bjet_eta\n",
      "------------------------------------------------------------\n",
      "Res_lead_bjet_phi\n",
      "------------------------------------------------------------\n",
      "Res_lead_bjet_mass\n",
      "------------------------------------------------------------\n",
      "Res_lead_bjet_charge\n",
      "------------------------------------------------------------\n",
      "Res_lead_bjet_btagPNetB\n",
      "------------------------------------------------------------\n",
      "Res_lead_bjet_PNetRegPtRawCorr\n",
      "------------------------------------------------------------\n",
      "Res_lead_bjet_PNetRegPtRawCorrNeutrino\n",
      "------------------------------------------------------------\n",
      "Res_lead_bjet_PNetRegPtRawRes\n",
      "------------------------------------------------------------\n",
      "Res_lead_bjet_jet_idx\n",
      "------------------------------------------------------------\n",
      "Res_sublead_bjet_pt\n",
      "------------------------------------------------------------\n",
      "Res_sublead_bjet_eta\n",
      "------------------------------------------------------------\n",
      "Res_sublead_bjet_phi\n",
      "------------------------------------------------------------\n",
      "Res_sublead_bjet_mass\n",
      "------------------------------------------------------------\n",
      "Res_sublead_bjet_charge\n",
      "------------------------------------------------------------\n",
      "Res_sublead_bjet_btagPNetB\n",
      "------------------------------------------------------------\n",
      "Res_sublead_bjet_PNetRegPtRawCorr\n",
      "------------------------------------------------------------\n",
      "Res_sublead_bjet_PNetRegPtRawCorrNeutrino\n",
      "------------------------------------------------------------\n",
      "Res_sublead_bjet_PNetRegPtRawRes\n",
      "------------------------------------------------------------\n",
      "Res_sublead_bjet_jet_idx\n",
      "------------------------------------------------------------\n",
      "Res_dijet_pt\n",
      "------------------------------------------------------------\n",
      "Res_dijet_eta\n",
      "------------------------------------------------------------\n",
      "Res_dijet_phi\n",
      "------------------------------------------------------------\n",
      "Res_dijet_mass\n",
      "------------------------------------------------------------\n",
      "Res_dijet_charge\n",
      "------------------------------------------------------------\n",
      "Res_pholead_PtOverM\n",
      "------------------------------------------------------------\n",
      "Res_phosublead_PtOverM\n",
      "------------------------------------------------------------\n",
      "Res_FirstJet_PtOverM\n",
      "------------------------------------------------------------\n",
      "Res_SecondJet_PtOverM\n",
      "------------------------------------------------------------\n",
      "Res_DeltaR_j1g1\n",
      "------------------------------------------------------------\n",
      "Res_DeltaR_j2g1\n",
      "------------------------------------------------------------\n",
      "Res_DeltaR_j1g2\n",
      "------------------------------------------------------------\n",
      "Res_DeltaR_j2g2\n",
      "------------------------------------------------------------\n",
      "Res_DeltaR_jg_min\n",
      "------------------------------------------------------------\n",
      "Res_chi_t0\n",
      "------------------------------------------------------------\n",
      "Res_chi_t1\n",
      "------------------------------------------------------------\n",
      "Res_DeltaPhi_j1MET\n",
      "------------------------------------------------------------\n",
      "Res_DeltaPhi_j2MET\n",
      "------------------------------------------------------------\n",
      "Res_CosThetaStar_CS\n",
      "------------------------------------------------------------\n",
      "Res_CosThetaStar_gg\n",
      "------------------------------------------------------------\n",
      "Res_CosThetaStar_jj\n",
      "------------------------------------------------------------\n",
      "Res_has_two_btagged_jets\n",
      "------------------------------------------------------------\n",
      "Res_has_atleast_one_fatjet\n",
      "------------------------------------------------------------\n",
      "is_Res\n",
      "------------------------------------------------------------\n",
      "nBTight\n",
      "------------------------------------------------------------\n",
      "nBMedium\n",
      "------------------------------------------------------------\n",
      "nBLoose\n",
      "------------------------------------------------------------\n",
      "n_leptons\n",
      "------------------------------------------------------------\n",
      "lepton1_pt\n",
      "------------------------------------------------------------\n",
      "lepton1_eta\n",
      "------------------------------------------------------------\n",
      "lepton1_phi\n",
      "------------------------------------------------------------\n",
      "lepton1_mass\n",
      "------------------------------------------------------------\n",
      "lepton1_charge\n",
      "------------------------------------------------------------\n",
      "lepton1_generation\n",
      "------------------------------------------------------------\n",
      "lepton1_mvaID\n",
      "------------------------------------------------------------\n",
      "lepton1_pfRelIso03_all\n",
      "------------------------------------------------------------\n",
      "lepton1_pfRelIso04_all\n",
      "------------------------------------------------------------\n",
      "lepton1_pfIsoId\n",
      "------------------------------------------------------------\n",
      "lepton1_dxy\n",
      "------------------------------------------------------------\n",
      "lepton1_dz\n",
      "------------------------------------------------------------\n",
      "lepton2_pt\n",
      "------------------------------------------------------------\n",
      "lepton2_eta\n",
      "------------------------------------------------------------\n",
      "lepton2_phi\n",
      "------------------------------------------------------------\n",
      "lepton2_mass\n",
      "------------------------------------------------------------\n",
      "lepton2_charge\n",
      "------------------------------------------------------------\n",
      "lepton2_generation\n",
      "------------------------------------------------------------\n",
      "lepton2_mvaID\n",
      "------------------------------------------------------------\n",
      "lepton2_pfRelIso03_all\n",
      "------------------------------------------------------------\n",
      "lepton2_pfRelIso04_all\n",
      "------------------------------------------------------------\n",
      "lepton2_pfIsoId\n",
      "------------------------------------------------------------\n",
      "lepton2_dxy\n",
      "------------------------------------------------------------\n",
      "lepton2_dz\n",
      "------------------------------------------------------------\n",
      "lepton3_pt\n",
      "------------------------------------------------------------\n",
      "lepton3_eta\n",
      "------------------------------------------------------------\n",
      "lepton3_phi\n",
      "------------------------------------------------------------\n",
      "lepton3_mass\n",
      "------------------------------------------------------------\n",
      "lepton3_charge\n",
      "------------------------------------------------------------\n",
      "lepton3_generation\n",
      "------------------------------------------------------------\n",
      "lepton3_mvaID\n",
      "------------------------------------------------------------\n",
      "lepton3_pfRelIso03_all\n",
      "------------------------------------------------------------\n",
      "lepton3_pfRelIso04_all\n",
      "------------------------------------------------------------\n",
      "lepton3_pfIsoId\n",
      "------------------------------------------------------------\n",
      "lepton3_dxy\n",
      "------------------------------------------------------------\n",
      "lepton3_dz\n",
      "------------------------------------------------------------\n",
      "lepton4_pt\n",
      "------------------------------------------------------------\n",
      "lepton4_eta\n",
      "------------------------------------------------------------\n",
      "lepton4_phi\n",
      "------------------------------------------------------------\n",
      "lepton4_mass\n",
      "------------------------------------------------------------\n",
      "lepton4_charge\n",
      "------------------------------------------------------------\n",
      "lepton4_generation\n",
      "------------------------------------------------------------\n",
      "lepton4_mvaID\n",
      "------------------------------------------------------------\n",
      "lepton4_pfRelIso03_all\n",
      "------------------------------------------------------------\n",
      "lepton4_pfRelIso04_all\n",
      "------------------------------------------------------------\n",
      "lepton4_pfIsoId\n",
      "------------------------------------------------------------\n",
      "lepton4_dxy\n",
      "------------------------------------------------------------\n",
      "lepton4_dz\n",
      "------------------------------------------------------------\n",
      "DeltaR_j1l1\n",
      "------------------------------------------------------------\n",
      "DeltaR_j1l2\n",
      "------------------------------------------------------------\n",
      "DeltaR_j1l3\n",
      "------------------------------------------------------------\n",
      "DeltaR_j1l4\n",
      "------------------------------------------------------------\n",
      "DeltaR_j2l1\n",
      "------------------------------------------------------------\n",
      "DeltaR_j2l2\n",
      "------------------------------------------------------------\n",
      "DeltaR_j2l3\n",
      "------------------------------------------------------------\n",
      "DeltaR_j2l4\n",
      "------------------------------------------------------------\n",
      "DeltaR_j3l1\n",
      "------------------------------------------------------------\n",
      "DeltaR_j3l2\n",
      "------------------------------------------------------------\n",
      "DeltaR_j3l3\n",
      "------------------------------------------------------------\n",
      "DeltaR_j3l4\n",
      "------------------------------------------------------------\n",
      "DeltaR_j4l1\n",
      "------------------------------------------------------------\n",
      "DeltaR_j4l2\n",
      "------------------------------------------------------------\n",
      "DeltaR_j4l3\n",
      "------------------------------------------------------------\n",
      "DeltaR_j4l4\n",
      "------------------------------------------------------------\n",
      "DeltaR_j5l1\n",
      "------------------------------------------------------------\n",
      "DeltaR_j5l2\n",
      "------------------------------------------------------------\n",
      "DeltaR_j5l3\n",
      "------------------------------------------------------------\n",
      "DeltaR_j5l4\n",
      "------------------------------------------------------------\n",
      "DeltaR_j6l1\n",
      "------------------------------------------------------------\n",
      "DeltaR_j6l2\n",
      "------------------------------------------------------------\n",
      "DeltaR_j6l3\n",
      "------------------------------------------------------------\n",
      "DeltaR_j6l4\n",
      "------------------------------------------------------------\n",
      "DeltaR_j7l1\n",
      "------------------------------------------------------------\n",
      "DeltaR_j7l2\n",
      "------------------------------------------------------------\n",
      "DeltaR_j7l3\n",
      "------------------------------------------------------------\n",
      "DeltaR_j7l4\n",
      "------------------------------------------------------------\n",
      "DeltaR_j8l1\n",
      "------------------------------------------------------------\n",
      "DeltaR_j8l2\n",
      "------------------------------------------------------------\n",
      "DeltaR_j8l3\n",
      "------------------------------------------------------------\n",
      "DeltaR_j8l4\n",
      "------------------------------------------------------------\n",
      "DeltaR_j9l1\n",
      "------------------------------------------------------------\n",
      "DeltaR_j9l2\n",
      "------------------------------------------------------------\n",
      "DeltaR_j9l3\n",
      "------------------------------------------------------------\n",
      "DeltaR_j9l4\n",
      "------------------------------------------------------------\n",
      "DeltaR_j10l1\n",
      "------------------------------------------------------------\n",
      "DeltaR_j10l2\n",
      "------------------------------------------------------------\n",
      "DeltaR_j10l3\n",
      "------------------------------------------------------------\n",
      "DeltaR_j10l4\n",
      "------------------------------------------------------------\n",
      "DeltaR_b1l1\n",
      "------------------------------------------------------------\n",
      "DeltaR_b2l1\n",
      "------------------------------------------------------------\n",
      "DeltaR_b1l2\n",
      "------------------------------------------------------------\n",
      "DeltaR_b2l2\n",
      "------------------------------------------------------------\n",
      "fatjet1_jetId\n",
      "------------------------------------------------------------\n",
      "fatjet1_nConstituents\n",
      "------------------------------------------------------------\n",
      "fatjet1_subjet1_btagDeepB\n",
      "------------------------------------------------------------\n",
      "fatjet1_subjet1_eta\n",
      "------------------------------------------------------------\n",
      "fatjet1_subjet1_mass\n",
      "------------------------------------------------------------\n",
      "fatjet1_subjet1_phi\n",
      "------------------------------------------------------------\n",
      "fatjet1_subjet1_pt\n",
      "------------------------------------------------------------\n",
      "fatjet1_subjet1_rawFactor\n",
      "------------------------------------------------------------\n",
      "fatjet1_subjet2_btagDeepB\n",
      "------------------------------------------------------------\n",
      "fatjet1_subjet2_eta\n",
      "------------------------------------------------------------\n",
      "fatjet1_subjet2_mass\n",
      "------------------------------------------------------------\n",
      "fatjet1_subjet2_phi\n",
      "------------------------------------------------------------\n",
      "fatjet1_subjet2_pt\n",
      "------------------------------------------------------------\n",
      "fatjet1_subjet2_rawFactor\n",
      "------------------------------------------------------------\n",
      "fatjet1_area\n",
      "------------------------------------------------------------\n",
      "fatjet1_btagDDBvLV2\n",
      "------------------------------------------------------------\n",
      "fatjet1_btagDDCvBV2\n",
      "------------------------------------------------------------\n",
      "fatjet1_btagDDCvLV2\n",
      "------------------------------------------------------------\n",
      "fatjet1_btagDeepB\n",
      "------------------------------------------------------------\n",
      "fatjet1_btagHbb\n",
      "------------------------------------------------------------\n",
      "fatjet1_eta\n",
      "------------------------------------------------------------\n",
      "fatjet1_mass\n",
      "------------------------------------------------------------\n",
      "fatjet1_msoftdrop\n",
      "------------------------------------------------------------\n",
      "fatjet1_n2b1\n",
      "------------------------------------------------------------\n",
      "fatjet1_n3b1\n",
      "------------------------------------------------------------\n",
      "fatjet1_particleNetWithMass_HbbvsQCD\n",
      "------------------------------------------------------------\n",
      "fatjet1_particleNetWithMass_QCD\n",
      "------------------------------------------------------------\n",
      "fatjet1_particleNet_QCD\n",
      "------------------------------------------------------------\n",
      "fatjet1_particleNet_QCD0HF\n",
      "------------------------------------------------------------\n",
      "fatjet1_particleNet_QCD1HF\n",
      "------------------------------------------------------------\n",
      "fatjet1_particleNet_QCD2HF\n",
      "------------------------------------------------------------\n",
      "fatjet1_particleNet_XbbVsQCD\n",
      "------------------------------------------------------------\n",
      "fatjet1_particleNet_XccVsQCD\n",
      "------------------------------------------------------------\n",
      "fatjet1_particleNet_XggVsQCD\n",
      "------------------------------------------------------------\n",
      "fatjet1_particleNet_XqqVsQCD\n",
      "------------------------------------------------------------\n",
      "fatjet1_particleNet_massCorr\n",
      "------------------------------------------------------------\n",
      "fatjet1_phi\n",
      "------------------------------------------------------------\n",
      "fatjet1_pt\n",
      "------------------------------------------------------------\n",
      "fatjet1_rawFactor\n",
      "------------------------------------------------------------\n",
      "fatjet1_tau1\n",
      "------------------------------------------------------------\n",
      "fatjet1_tau2\n",
      "------------------------------------------------------------\n",
      "fatjet1_tau3\n",
      "------------------------------------------------------------\n",
      "fatjet1_tau4\n",
      "------------------------------------------------------------\n",
      "fatjet2_jetId\n",
      "------------------------------------------------------------\n",
      "fatjet2_nConstituents\n",
      "------------------------------------------------------------\n",
      "fatjet2_subjet1_btagDeepB\n",
      "------------------------------------------------------------\n",
      "fatjet2_subjet1_eta\n",
      "------------------------------------------------------------\n",
      "fatjet2_subjet1_mass\n",
      "------------------------------------------------------------\n",
      "fatjet2_subjet1_phi\n",
      "------------------------------------------------------------\n",
      "fatjet2_subjet1_pt\n",
      "------------------------------------------------------------\n",
      "fatjet2_subjet1_rawFactor\n",
      "------------------------------------------------------------\n",
      "fatjet2_subjet2_btagDeepB\n",
      "------------------------------------------------------------\n",
      "fatjet2_subjet2_eta\n",
      "------------------------------------------------------------\n",
      "fatjet2_subjet2_mass\n",
      "------------------------------------------------------------\n",
      "fatjet2_subjet2_phi\n",
      "------------------------------------------------------------\n",
      "fatjet2_subjet2_pt\n",
      "------------------------------------------------------------\n",
      "fatjet2_subjet2_rawFactor\n",
      "------------------------------------------------------------\n",
      "fatjet2_area\n",
      "------------------------------------------------------------\n",
      "fatjet2_btagDDBvLV2\n",
      "------------------------------------------------------------\n",
      "fatjet2_btagDDCvBV2\n",
      "------------------------------------------------------------\n",
      "fatjet2_btagDDCvLV2\n",
      "------------------------------------------------------------\n",
      "fatjet2_btagDeepB\n",
      "------------------------------------------------------------\n",
      "fatjet2_btagHbb\n",
      "------------------------------------------------------------\n",
      "fatjet2_eta\n",
      "------------------------------------------------------------\n",
      "fatjet2_mass\n",
      "------------------------------------------------------------\n",
      "fatjet2_msoftdrop\n",
      "------------------------------------------------------------\n",
      "fatjet2_n2b1\n",
      "------------------------------------------------------------\n",
      "fatjet2_n3b1\n",
      "------------------------------------------------------------\n",
      "fatjet2_particleNetWithMass_HbbvsQCD\n",
      "------------------------------------------------------------\n",
      "fatjet2_particleNetWithMass_QCD\n",
      "------------------------------------------------------------\n",
      "fatjet2_particleNet_QCD\n",
      "------------------------------------------------------------\n",
      "fatjet2_particleNet_QCD0HF\n",
      "------------------------------------------------------------\n",
      "fatjet2_particleNet_QCD1HF\n",
      "------------------------------------------------------------\n",
      "fatjet2_particleNet_QCD2HF\n",
      "------------------------------------------------------------\n",
      "fatjet2_particleNet_XbbVsQCD\n",
      "------------------------------------------------------------\n",
      "fatjet2_particleNet_XccVsQCD\n",
      "------------------------------------------------------------\n",
      "fatjet2_particleNet_XggVsQCD\n",
      "------------------------------------------------------------\n",
      "fatjet2_particleNet_XqqVsQCD\n",
      "------------------------------------------------------------\n",
      "fatjet2_particleNet_massCorr\n",
      "------------------------------------------------------------\n",
      "fatjet2_phi\n",
      "------------------------------------------------------------\n",
      "fatjet2_pt\n",
      "------------------------------------------------------------\n",
      "fatjet2_rawFactor\n",
      "------------------------------------------------------------\n",
      "fatjet2_tau1\n",
      "------------------------------------------------------------\n",
      "fatjet2_tau2\n",
      "------------------------------------------------------------\n",
      "fatjet2_tau3\n",
      "------------------------------------------------------------\n",
      "fatjet2_tau4\n",
      "------------------------------------------------------------\n",
      "fatjet3_jetId\n",
      "------------------------------------------------------------\n",
      "fatjet3_nConstituents\n",
      "------------------------------------------------------------\n",
      "fatjet3_subjet1_btagDeepB\n",
      "------------------------------------------------------------\n",
      "fatjet3_subjet1_eta\n",
      "------------------------------------------------------------\n",
      "fatjet3_subjet1_mass\n",
      "------------------------------------------------------------\n",
      "fatjet3_subjet1_phi\n",
      "------------------------------------------------------------\n",
      "fatjet3_subjet1_pt\n",
      "------------------------------------------------------------\n",
      "fatjet3_subjet1_rawFactor\n",
      "------------------------------------------------------------\n",
      "fatjet3_subjet2_btagDeepB\n",
      "------------------------------------------------------------\n",
      "fatjet3_subjet2_eta\n",
      "------------------------------------------------------------\n",
      "fatjet3_subjet2_mass\n",
      "------------------------------------------------------------\n",
      "fatjet3_subjet2_phi\n",
      "------------------------------------------------------------\n",
      "fatjet3_subjet2_pt\n",
      "------------------------------------------------------------\n",
      "fatjet3_subjet2_rawFactor\n",
      "------------------------------------------------------------\n",
      "fatjet3_area\n",
      "------------------------------------------------------------\n",
      "fatjet3_btagDDBvLV2\n",
      "------------------------------------------------------------\n",
      "fatjet3_btagDDCvBV2\n",
      "------------------------------------------------------------\n",
      "fatjet3_btagDDCvLV2\n",
      "------------------------------------------------------------\n",
      "fatjet3_btagDeepB\n",
      "------------------------------------------------------------\n",
      "fatjet3_btagHbb\n",
      "------------------------------------------------------------\n",
      "fatjet3_eta\n",
      "------------------------------------------------------------\n",
      "fatjet3_mass\n",
      "------------------------------------------------------------\n",
      "fatjet3_msoftdrop\n",
      "------------------------------------------------------------\n",
      "fatjet3_n2b1\n",
      "------------------------------------------------------------\n",
      "fatjet3_n3b1\n",
      "------------------------------------------------------------\n",
      "fatjet3_particleNetWithMass_HbbvsQCD\n",
      "------------------------------------------------------------\n",
      "fatjet3_particleNetWithMass_QCD\n",
      "------------------------------------------------------------\n",
      "fatjet3_particleNet_QCD\n",
      "------------------------------------------------------------\n",
      "fatjet3_particleNet_QCD0HF\n",
      "------------------------------------------------------------\n",
      "fatjet3_particleNet_QCD1HF\n",
      "------------------------------------------------------------\n",
      "fatjet3_particleNet_QCD2HF\n",
      "------------------------------------------------------------\n",
      "fatjet3_particleNet_XbbVsQCD\n",
      "------------------------------------------------------------\n",
      "fatjet3_particleNet_XccVsQCD\n",
      "------------------------------------------------------------\n",
      "fatjet3_particleNet_XggVsQCD\n",
      "------------------------------------------------------------\n",
      "fatjet3_particleNet_XqqVsQCD\n",
      "------------------------------------------------------------\n",
      "fatjet3_particleNet_massCorr\n",
      "------------------------------------------------------------\n",
      "fatjet3_phi\n",
      "------------------------------------------------------------\n",
      "fatjet3_pt\n",
      "------------------------------------------------------------\n",
      "fatjet3_rawFactor\n",
      "------------------------------------------------------------\n",
      "fatjet3_tau1\n",
      "------------------------------------------------------------\n",
      "fatjet3_tau2\n",
      "------------------------------------------------------------\n",
      "fatjet3_tau3\n",
      "------------------------------------------------------------\n",
      "fatjet3_tau4\n",
      "------------------------------------------------------------\n",
      "fatjet4_jetId\n",
      "------------------------------------------------------------\n",
      "fatjet4_nConstituents\n",
      "------------------------------------------------------------\n",
      "fatjet4_subjet1_btagDeepB\n",
      "------------------------------------------------------------\n",
      "fatjet4_subjet1_eta\n",
      "------------------------------------------------------------\n",
      "fatjet4_subjet1_mass\n",
      "------------------------------------------------------------\n",
      "fatjet4_subjet1_phi\n",
      "------------------------------------------------------------\n",
      "fatjet4_subjet1_pt\n",
      "------------------------------------------------------------\n",
      "fatjet4_subjet1_rawFactor\n",
      "------------------------------------------------------------\n",
      "fatjet4_subjet2_btagDeepB\n",
      "------------------------------------------------------------\n",
      "fatjet4_subjet2_eta\n",
      "------------------------------------------------------------\n",
      "fatjet4_subjet2_mass\n",
      "------------------------------------------------------------\n",
      "fatjet4_subjet2_phi\n",
      "------------------------------------------------------------\n",
      "fatjet4_subjet2_pt\n",
      "------------------------------------------------------------\n",
      "fatjet4_subjet2_rawFactor\n",
      "------------------------------------------------------------\n",
      "fatjet4_area\n",
      "------------------------------------------------------------\n",
      "fatjet4_btagDDBvLV2\n",
      "------------------------------------------------------------\n",
      "fatjet4_btagDDCvBV2\n",
      "------------------------------------------------------------\n",
      "fatjet4_btagDDCvLV2\n",
      "------------------------------------------------------------\n",
      "fatjet4_btagDeepB\n",
      "------------------------------------------------------------\n",
      "fatjet4_btagHbb\n",
      "------------------------------------------------------------\n",
      "fatjet4_eta\n",
      "------------------------------------------------------------\n",
      "fatjet4_mass\n",
      "------------------------------------------------------------\n",
      "fatjet4_msoftdrop\n",
      "------------------------------------------------------------\n",
      "fatjet4_n2b1\n",
      "------------------------------------------------------------\n",
      "fatjet4_n3b1\n",
      "------------------------------------------------------------\n",
      "fatjet4_particleNetWithMass_HbbvsQCD\n",
      "------------------------------------------------------------\n",
      "fatjet4_particleNetWithMass_QCD\n",
      "------------------------------------------------------------\n",
      "fatjet4_particleNet_QCD\n",
      "------------------------------------------------------------\n",
      "fatjet4_particleNet_QCD0HF\n",
      "------------------------------------------------------------\n",
      "fatjet4_particleNet_QCD1HF\n",
      "------------------------------------------------------------\n",
      "fatjet4_particleNet_QCD2HF\n",
      "------------------------------------------------------------\n",
      "fatjet4_particleNet_XbbVsQCD\n",
      "------------------------------------------------------------\n",
      "fatjet4_particleNet_XccVsQCD\n",
      "------------------------------------------------------------\n",
      "fatjet4_particleNet_XggVsQCD\n",
      "------------------------------------------------------------\n",
      "fatjet4_particleNet_XqqVsQCD\n",
      "------------------------------------------------------------\n",
      "fatjet4_particleNet_massCorr\n",
      "------------------------------------------------------------\n",
      "fatjet4_phi\n",
      "------------------------------------------------------------\n",
      "fatjet4_pt\n",
      "------------------------------------------------------------\n",
      "fatjet4_rawFactor\n",
      "------------------------------------------------------------\n",
      "fatjet4_tau1\n",
      "------------------------------------------------------------\n",
      "fatjet4_tau2\n",
      "------------------------------------------------------------\n",
      "fatjet4_tau3\n",
      "------------------------------------------------------------\n",
      "fatjet4_tau4\n",
      "------------------------------------------------------------\n",
      "puppiMET_phi\n",
      "------------------------------------------------------------\n",
      "puppiMET_phiJERDown\n",
      "------------------------------------------------------------\n",
      "puppiMET_phiJERUp\n",
      "------------------------------------------------------------\n",
      "puppiMET_phiJESDown\n",
      "------------------------------------------------------------\n",
      "puppiMET_phiJESUp\n",
      "------------------------------------------------------------\n",
      "puppiMET_phiUnclusteredDown\n",
      "------------------------------------------------------------\n",
      "puppiMET_phiUnclusteredUp\n",
      "------------------------------------------------------------\n",
      "puppiMET_pt\n",
      "------------------------------------------------------------\n",
      "puppiMET_ptJERDown\n",
      "------------------------------------------------------------\n",
      "puppiMET_ptJERUp\n",
      "------------------------------------------------------------\n",
      "puppiMET_ptJESDown\n",
      "------------------------------------------------------------\n",
      "puppiMET_ptJESUp\n",
      "------------------------------------------------------------\n",
      "puppiMET_ptUnclusteredDown\n",
      "------------------------------------------------------------\n",
      "puppiMET_ptUnclusteredUp\n",
      "------------------------------------------------------------\n",
      "puppiMET_sumEt\n",
      "------------------------------------------------------------\n",
      "event\n",
      "------------------------------------------------------------\n",
      "lumi\n",
      "------------------------------------------------------------\n",
      "run\n",
      "------------------------------------------------------------\n",
      "nPV\n",
      "------------------------------------------------------------\n",
      "fixedGridRhoAll\n",
      "------------------------------------------------------------\n",
      "dZ\n",
      "------------------------------------------------------------\n",
      "weight_central\n",
      "------------------------------------------------------------\n",
      "weight\n",
      "------------------------------------------------------------\n",
      "sigma_m_over_m\n",
      "------------------------------------------------------------\n",
      "sigma_m_over_m_Smeared\n",
      "------------------------------------------------------------\n",
      "sigma_m_over_m_nominal_decorr\n",
      "------------------------------------------------------------\n",
      "sigma_m_over_m_decorr\n",
      "------------------------------------------------------------\n",
      "sigma_m_over_m_smeared_decorr\n",
      "------------------------------------------------------------\n",
      "sample_name\n",
      "------------------------------------------------------------\n",
      "lead_bjet_btagRobustParTAK4B\n",
      "------------------------------------------------------------\n",
      "lead_bjet_PNetRegPt\n",
      "------------------------------------------------------------\n",
      "lead_bjet_sigmapT_over_pT\n",
      "------------------------------------------------------------\n",
      "lead_bjet_sigmapT_over_RegPt\n",
      "------------------------------------------------------------\n",
      "sublead_bjet_btagRobustParTAK4B\n",
      "------------------------------------------------------------\n",
      "sublead_bjet_PNetRegPt\n",
      "------------------------------------------------------------\n",
      "sublead_bjet_sigmapT_over_pT\n",
      "------------------------------------------------------------\n",
      "sublead_bjet_sigmapT_over_RegPt\n",
      "------------------------------------------------------------\n",
      "dijet_PNetRegPt\n",
      "------------------------------------------------------------\n",
      "dijet_PNetRegEta\n",
      "------------------------------------------------------------\n",
      "dijet_PNetRegPhi\n",
      "------------------------------------------------------------\n",
      "dijet_PNetRegMass\n",
      "------------------------------------------------------------\n",
      "HH_PNetRegPt\n",
      "------------------------------------------------------------\n",
      "HH_PNetRegEta\n",
      "------------------------------------------------------------\n",
      "HH_PNetRegPhi\n",
      "------------------------------------------------------------\n",
      "HH_PNetRegMass\n",
      "------------------------------------------------------------\n",
      "lead_sigmaE_over_E\n",
      "------------------------------------------------------------\n",
      "lead_bjet_pt_over_Mjj\n",
      "------------------------------------------------------------\n",
      "lead_bjet_RegPt_over_Mjj\n",
      "------------------------------------------------------------\n",
      "sublead_sigmaE_over_E\n",
      "------------------------------------------------------------\n",
      "sublead_bjet_pt_over_Mjj\n",
      "------------------------------------------------------------\n",
      "sublead_bjet_RegPt_over_Mjj\n",
      "------------------------------------------------------------\n",
      "RegPt_balance\n",
      "------------------------------------------------------------\n",
      "pt_balance\n",
      "------------------------------------------------------------\n",
      "DeltaPhi_jj\n",
      "------------------------------------------------------------\n",
      "DeltaEta_jj\n",
      "------------------------------------------------------------\n",
      "isr_jet_RegPt\n",
      "------------------------------------------------------------\n",
      "DeltaPhi_isr_jet_z\n",
      "------------------------------------------------------------\n",
      "hash\n",
      "------------------------------------------------------------\n",
      "lead_mvaID_run3\n",
      "------------------------------------------------------------\n",
      "sublead_mvaID_run3\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "EVAL_DATA_ON_ALL_FOLDS = True\n",
    "\n",
    "# load and pre-process the data\n",
    "# DATA_FILEPATHS_DICT = {\n",
    "#     'Data': [\n",
    "#         lpc_fileprefix[:-4]+f\"/data/DataC_2022/*.parquet\",\n",
    "#         lpc_fileprefix[:-4]+f\"/data/DataD_2022/*.parquet\",\n",
    "#         lpc_fileprefix[:-4]+f\"/data/Data_EraE/*.parquet\",\n",
    "#         lpc_fileprefix[:-4]+f\"/data/Data_EraF/*.parquet\",\n",
    "#         lpc_fileprefix[:-4]+f\"/data/Data_EraG/*.parquet\",\n",
    "#     ],\n",
    "# }\n",
    "DATA_FILEPATHS_DICT = {\n",
    "    'Data': [\n",
    "        lpc_fileprefix+Run3_2023[:-4]+\"/data/Data_EraCv1/*merged.parquet\",\n",
    "        lpc_fileprefix+Run3_2023[:-4]+\"/data/Data_EraCv2/*merged.parquet\",\n",
    "        lpc_fileprefix+Run3_2023[:-4]+\"/data/Data_EraCv3/*merged.parquet\",\n",
    "        lpc_fileprefix+Run3_2023[:-4]+\"/data/Data_EraCv4/*merged.parquet\",\n",
    "        lpc_fileprefix+Run3_2023[:-4]+\"/data/Data_EraDv1/*merged.parquet\",\n",
    "        lpc_fileprefix+Run3_2023[:-4]+\"/data/Data_EraDv2/*merged.parquet\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "(\n",
    "    NOTHING_IGNORE,\n",
    "    DATA_data_df_dict, DATA_data_test_df_dict, \n",
    "    DATA_data_hlf_dict, DATA_label_dict,\n",
    "    DATA_data_hlf_test_dict, DATA_label_test_dict, \n",
    "    DATA_hlf_vars_columns_dict,\n",
    "    DATA_data_aux_dict, DATA_data_test_aux_dict\n",
    ") = process_data(\n",
    "    DATA_FILEPATHS_DICT, OUTPUT_DIRPATH, order=['Data'], mod_vals=MOD_VALS, k_fold_test=True,\n",
    "    save=False, std_json_dirpath=OUTPUT_DIRPATH\n",
    ")\n",
    "\n",
    "BDT_DATA_preds = []\n",
    "\n",
    "if EVAL_DATA_ON_ALL_FOLDS:\n",
    "\n",
    "    bdt_train_data_dict = xgb.DMatrix(\n",
    "        data=DATA_data_hlf_dict[f\"fold_0\"], label=DATA_label_dict[f\"fold_0\"], \n",
    "        missing=-999.0, feature_names=list(DATA_hlf_vars_columns_dict[f\"fold_0\"])\n",
    "    )\n",
    "    bdt_test_data_dict = xgb.DMatrix(\n",
    "        data=DATA_data_hlf_test_dict[f\"fold_0\"], label=DATA_label_test_dict[f\"fold_0\"], \n",
    "        missing=-999.0, feature_names=list(DATA_hlf_vars_columns_dict[f\"fold_0\"])\n",
    "    )\n",
    "\n",
    "    for fold_idx in range(len(DATA_label_test_dict)):\n",
    "        booster = xgb.Booster(param)\n",
    "        booster.load_model(os.path.join(OUTPUT_DIRPATH, f'{CURRENT_TIME}_BDT_fold{fold_idx}.model'))\n",
    "\n",
    "        BDT_train_preds = booster.predict(\n",
    "            bdt_train_data_dict, \n",
    "            iteration_range=(0, booster.best_iteration+1)\n",
    "        )\n",
    "        BDT_test_preds = booster.predict(\n",
    "            bdt_test_data_dict, \n",
    "            iteration_range=(0, booster.best_iteration+1)\n",
    "        )\n",
    "\n",
    "        BDT_all_preds = np.concatenate([BDT_train_preds, BDT_test_preds])\n",
    "        BDT_all_preds = BDT_all_preds[\n",
    "            np.argsort(\n",
    "                np.concatenate([DATA_data_aux_dict[f\"fold_0\"].loc[:, 'hash'].to_numpy(), DATA_data_test_aux_dict[f\"fold_0\"].loc[:, 'hash'].to_numpy()])\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        if fold_idx == 0:\n",
    "            BDT_DATA_preds = copy.deepcopy(BDT_all_preds)\n",
    "        else:\n",
    "            BDT_DATA_preds += BDT_all_preds\n",
    "\n",
    "            if fold_idx == len(DATA_label_test_dict) - 1:\n",
    "                BDT_DATA_preds = BDT_DATA_preds / len(DATA_label_test_dict)\n",
    "else:\n",
    "\n",
    "    bdt_train_data_dict, bdt_test_data_dict = {}, {}\n",
    "    for fold_idx in range(len(DATA_label_test_dict)):\n",
    "        \n",
    "        bdt_train_data_dict[f\"fold_{fold_idx}\"] = xgb.DMatrix(\n",
    "            data=DATA_data_hlf_dict[f\"fold_{fold_idx}\"], label=DATA_label_dict[f\"fold_{fold_idx}\"], \n",
    "            missing=-999.0, feature_names=list(DATA_hlf_vars_columns_dict[f\"fold_{fold_idx}\"])\n",
    "        )\n",
    "        bdt_test_data_dict[f\"fold_{fold_idx}\"] = xgb.DMatrix(\n",
    "            data=DATA_data_hlf_test_dict[f\"fold_{fold_idx}\"], label=DATA_label_test_dict[f\"fold_{fold_idx}\"], \n",
    "            missing=-999.0, feature_names=list(DATA_hlf_vars_columns_dict[f\"fold_{fold_idx}\"])\n",
    "        )\n",
    "\n",
    "        booster = xgb.Booster(param)\n",
    "        booster.load_model(os.path.join(OUTPUT_DIRPATH, f'{CURRENT_TIME}_BDT_fold{fold_idx}.model'))\n",
    "\n",
    "        BDT_DATA_preds.append(\n",
    "            booster.predict(\n",
    "                bdt_test_data_dict[f\"fold_{fold_idx}\"], \n",
    "                iteration_range=(0, booster.best_iteration+1)\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Plot to show data labels look ok\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "hist_axis = hist.axis.Regular(100, 0., 1., name='var', growth=False, underflow=False, overflow=False)\n",
    "\n",
    "data_hists, data_plot_labels = [], []\n",
    "if not EVAL_DATA_ON_ALL_FOLDS:\n",
    "    \n",
    "    for fold_idx in range(len(BDT_DATA_preds)):\n",
    "\n",
    "        data_hists.append(\n",
    "            hist.Hist(hist_axis, storage='weight').fill(\n",
    "                var=np.array(BDT_DATA_preds[fold_idx])[:, 0],\n",
    "            )\n",
    "        )\n",
    "        data_plot_labels.append(f\"fold {fold_idx}\")\n",
    "else:\n",
    "\n",
    "    data_hists.append(\n",
    "        hist.Hist(hist_axis, storage='weight').fill(\n",
    "            var=np.array(BDT_DATA_preds)[:, 0],\n",
    "        )\n",
    "    )\n",
    "    data_plot_labels.append(f\"sum over folds\")\n",
    "\n",
    "hep.histplot(\n",
    "    data_hists,\n",
    "    alpha=0.5, density=False, histtype='step',\n",
    "    label=data_plot_labels\n",
    ")\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:48:52] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:48:56] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:48:57] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:48:57] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:48:58] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v2/Run3_2022_merged_MultiBDT_output_mvaIDCorr_22_23/data/DataC_2022/DataC_2022_merged_MultiBDT_output.parquet\n",
      "============================================================\n",
      "[11:49:02] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:49:02] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:49:03] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:49:03] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:49:03] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v2/Run3_2022_merged_MultiBDT_output_mvaIDCorr_22_23/data/DataD_2022/DataD_2022_merged_MultiBDT_output.parquet\n",
      "============================================================\n",
      "[11:49:08] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:49:08] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:49:09] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:49:09] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:49:10] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v2/Run3_2022_merged_MultiBDT_output_mvaIDCorr_22_23/data/Data_EraE/Data_EraE_merged_MultiBDT_output.parquet\n",
      "============================================================\n",
      "[11:49:17] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:49:18] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:49:18] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:49:19] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:49:20] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v2/Run3_2022_merged_MultiBDT_output_mvaIDCorr_22_23/data/Data_EraF/Data_EraF_merged_MultiBDT_output.parquet\n",
      "============================================================\n",
      "[11:49:25] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:49:25] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:49:25] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:49:26] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:49:26] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v2/Run3_2022_merged_MultiBDT_output_mvaIDCorr_22_23/data/Data_EraG/Data_EraG_merged_MultiBDT_output.parquet\n",
      "============================================================\n",
      "[11:49:29] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:49:29] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:49:29] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:49:30] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:49:30] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v2/Run3_2023_merged_MultiBDT_output_mvaIDCorr_22_23/data/Data_EraCv1/Data_EraCv1_merged_MultiBDT_output.parquet\n",
      "============================================================\n",
      "[11:49:32] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:49:32] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:49:32] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:49:32] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:49:33] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v2/Run3_2023_merged_MultiBDT_output_mvaIDCorr_22_23/data/Data_EraCv2/Data_EraCv2_merged_MultiBDT_output.parquet\n",
      "============================================================\n",
      "[11:49:34] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:49:34] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:49:35] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:49:35] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:49:35] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v2/Run3_2023_merged_MultiBDT_output_mvaIDCorr_22_23/data/Data_EraCv3/Data_EraCv3_merged_MultiBDT_output.parquet\n",
      "============================================================\n",
      "[11:49:39] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:49:40] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:49:40] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:49:41] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:49:42] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v2/Run3_2023_merged_MultiBDT_output_mvaIDCorr_22_23/data/Data_EraCv4/Data_EraCv4_merged_MultiBDT_output.parquet\n",
      "============================================================\n",
      "[11:49:49] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:49:50] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:49:50] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:49:51] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:49:52] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v2/Run3_2023_merged_MultiBDT_output_mvaIDCorr_22_23/data/Data_EraDv1/Data_EraDv1_merged_MultiBDT_output.parquet\n",
      "============================================================\n",
      "[11:49:57] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:49:57] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:49:57] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:49:58] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:49:58] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v2/Run3_2023_merged_MultiBDT_output_mvaIDCorr_22_23/data/Data_EraDv2/Data_EraDv2_merged_MultiBDT_output.parquet\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# load and pre-process the data\n",
    "VARIATIONS_FILEPATHS_DICT = {\n",
    "    syst_name: get_filepath_dict(syst_name=syst_name) for syst_name in [\n",
    "        'nominal',\n",
    "        'Et_dependent_ScaleEB_up', 'Et_dependent_ScaleEB_down', 'Et_dependent_ScaleEE_up', 'Et_dependent_ScaleEE_down', \n",
    "        'Et_dependent_Smearing_up', 'Et_dependent_Smearing_down', \n",
    "        'jec_syst_Total_up', 'jec_syst_Total_down', 'jer_syst_up', 'jer_syst_down'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# load and pre-process the data\n",
    "DATA_FILEPATHS_DICT = {\n",
    "    'Data': [\n",
    "        # 2022\n",
    "        lpc_fileprefix+Run3_2022[:-4]+f\"/data/DataC_2022/*merged.parquet\",\n",
    "        lpc_fileprefix+Run3_2022[:-4]+f\"/data/DataD_2022/*merged.parquet\",\n",
    "        lpc_fileprefix+Run3_2022[:-4]+f\"/data/Data_EraE/*merged.parquet\",\n",
    "        lpc_fileprefix+Run3_2022[:-4]+f\"/data/Data_EraF/*merged.parquet\",\n",
    "        lpc_fileprefix+Run3_2022[:-4]+f\"/data/Data_EraG/*merged.parquet\",\n",
    "        # 2023\n",
    "        lpc_fileprefix+Run3_2023[:-4]+\"/data/Data_EraCv1/*merged.parquet\",\n",
    "        lpc_fileprefix+Run3_2023[:-4]+\"/data/Data_EraCv2/*merged.parquet\",\n",
    "        lpc_fileprefix+Run3_2023[:-4]+\"/data/Data_EraCv3/*merged.parquet\",\n",
    "        lpc_fileprefix+Run3_2023[:-4]+\"/data/Data_EraCv4/*merged.parquet\",\n",
    "        lpc_fileprefix+Run3_2023[:-4]+\"/data/Data_EraDv1/*merged.parquet\",\n",
    "        lpc_fileprefix+Run3_2023[:-4]+\"/data/Data_EraDv2/*merged.parquet\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Sorts the predictions to map the output to the correct event\n",
    "def sorted_preds(preds, data_aux, sample, sorted_preds=False):\n",
    "    if not sorted_preds:\n",
    "        flat_preds = np.concatenate([preds[fold_idx] for fold_idx in range(len(data_aux))])\n",
    "        preds_sort = np.argsort(\n",
    "            np.concatenate([data_aux[f\"fold_{fold_idx}\"].loc[:, 'hash'].to_numpy() for fold_idx in range(len(data_aux))])\n",
    "        )\n",
    "    else:\n",
    "        flat_preds = preds\n",
    "        preds_sort = np.arange(len(flat_preds))\n",
    "\n",
    "    sample_sort = np.argsort(np.argsort(\n",
    "        ak.to_numpy(sample['hash'], allow_missing=False)\n",
    "    ))\n",
    "\n",
    "    return flat_preds[preds_sort][sample_sort]\n",
    "\n",
    "def get_file_sample_name(dirpath: str, variation: str):\n",
    "    end_idx = dirpath.find(variation) - 1\n",
    "    start_idx = dirpath[:end_idx].rfind('/') + 1\n",
    "\n",
    "    if end_idx == -2 or start_idx == 0: return ''\n",
    "\n",
    "    return dirpath[start_idx:end_idx]\n",
    "\n",
    "dirpath_addition = '_MultiBDT_output_mvaIDCorr_22_23'\n",
    "filename_addition = '_MultiBDT_output'\n",
    "\n",
    "## MC SAMPLES ##\n",
    "# Load parquet files #\n",
    "for i, sample_name in enumerate(order):\n",
    "    for variation, variation_filepath_dict in VARIATIONS_FILEPATHS_DICT.items():\n",
    "        if variation != 'nominal': continue\n",
    "        for dirpath in variation_filepath_dict[sample_name]:\n",
    "            if variation != 'nominal' and re.search('H', get_file_sample_name(dirpath, variation).upper()) is None: continue\n",
    "            parquet_filepath = glob.glob(dirpath)[0]\n",
    "            sample = ak.from_parquet(parquet_filepath)\n",
    "            sample = sample[\n",
    "                sample['nonRes_has_two_btagged_jets'] \n",
    "                & sample['is_nonRes']\n",
    "                & sample['fiducialGeometricFlag']\n",
    "            ]\n",
    "\n",
    "            (\n",
    "                NOTHING_IGNORE,\n",
    "                IGNORE_data_df_dict, SAMPLE_data_test_df_dict, \n",
    "                IGNORE_data_hlf_dict, IGNORE_label_dict,\n",
    "                SAMPLE_data_hlf_test_dict, SAMPLE_label_test_dict, \n",
    "                SAMPLE_hlf_vars_columns_dict,\n",
    "                IGNORE_data_aux_dict, SAMPLE_data_test_aux_dict\n",
    "            ) = process_data(\n",
    "                {\"sample\": [parquet_filepath]}, OUTPUT_DIRPATH, order=['sample'], mod_vals=MOD_VALS, k_fold_test=True,\n",
    "                save=False, std_json_dirpath=OUTPUT_DIRPATH\n",
    "            )\n",
    "\n",
    "            sample_preds = []\n",
    "            for fold_idx in range(len(SAMPLE_data_test_df_dict)):\n",
    "                booster = xgb.Booster(param)\n",
    "                booster.load_model(os.path.join(OUTPUT_DIRPATH, f'{CURRENT_TIME}_BDT_fold{fold_idx}.model'))\n",
    "\n",
    "                bdt_test_sample_dict = xgb.DMatrix(\n",
    "                    data=SAMPLE_data_hlf_test_dict[f\"fold_{fold_idx}\"], label=SAMPLE_label_test_dict[f\"fold_{fold_idx}\"], \n",
    "                    missing=-999.0, feature_names=list(SAMPLE_hlf_vars_columns_dict[f\"fold_{fold_idx}\"])\n",
    "                )\n",
    "\n",
    "                sample_preds.append(\n",
    "                    booster.predict(\n",
    "                        bdt_test_sample_dict, \n",
    "                        iteration_range=(0, booster.best_iteration+1)\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            sample['MultiBDT_output'] = sorted_preds(\n",
    "                sample_preds, SAMPLE_data_test_aux_dict, sample\n",
    "            )\n",
    "\n",
    "            dest_filepath = parquet_filepath[:parquet_filepath.find('Run3_202')+len('Run3_202x_merged')] + dirpath_addition + parquet_filepath[parquet_filepath.find('Run3_202')+len('Run3_202x_merged'):parquet_filepath.rfind('.')] + filename_addition + parquet_filepath[parquet_filepath.rfind('.'):]\n",
    "            if not os.path.exists(dest_filepath[:dest_filepath.rfind('/')]):\n",
    "                os.makedirs(dest_filepath[:dest_filepath.rfind('/')])\n",
    "            print(dest_filepath)\n",
    "            print('='*60)\n",
    "            merged_parquet = ak.to_parquet(sample, dest_filepath)\n",
    "\n",
    "## DATA ##\n",
    "for dirpath in DATA_FILEPATHS_DICT['Data']:\n",
    "    parquet_filepath = glob.glob(dirpath)[0]\n",
    "    data_sample = ak.from_parquet(parquet_filepath)\n",
    "    data_sample = data_sample[\n",
    "        data_sample['nonRes_has_two_btagged_jets'] \n",
    "        & data_sample['is_nonRes']\n",
    "        & data_sample['pass_fiducial_geometric']\n",
    "    ]\n",
    "\n",
    "    (\n",
    "        NOTHING_IGNORE,\n",
    "        DATA_data_df_dict, DATA_data_test_df_dict, \n",
    "        DATA_data_hlf_dict, DATA_label_dict,\n",
    "        DATA_data_hlf_test_dict, DATA_label_test_dict, \n",
    "        DATA_hlf_vars_columns_dict,\n",
    "        DATA_data_aux_dict, DATA_data_test_aux_dict\n",
    "    ) = process_data(\n",
    "        {\"sample\": [parquet_filepath]}, OUTPUT_DIRPATH, order=['sample'], mod_vals=MOD_VALS, k_fold_test=True,\n",
    "        save=False, std_json_dirpath=OUTPUT_DIRPATH\n",
    "    )\n",
    "\n",
    "    bdt_train_data_dict = xgb.DMatrix(\n",
    "        data=DATA_data_hlf_dict[f\"fold_0\"], label=DATA_label_dict[f\"fold_0\"], \n",
    "        missing=-999.0, feature_names=list(DATA_hlf_vars_columns_dict[f\"fold_0\"])\n",
    "    )\n",
    "    bdt_test_data_dict = xgb.DMatrix(\n",
    "        data=DATA_data_hlf_test_dict[f\"fold_0\"], label=DATA_label_test_dict[f\"fold_0\"], \n",
    "        missing=-999.0, feature_names=list(DATA_hlf_vars_columns_dict[f\"fold_0\"])\n",
    "    )\n",
    "\n",
    "    test_preds = []\n",
    "    for fold_idx in range(len(DATA_label_test_dict)):\n",
    "        booster = xgb.Booster(param)\n",
    "        booster.load_model(os.path.join(OUTPUT_DIRPATH, f'{CURRENT_TIME}_BDT_fold{fold_idx}.model'))\n",
    "\n",
    "        # all-fold eval\n",
    "        BDT_train_preds = booster.predict(\n",
    "            bdt_train_data_dict, \n",
    "            iteration_range=(0, booster.best_iteration+1)\n",
    "        )\n",
    "        BDT_test_preds = booster.predict(\n",
    "            bdt_test_data_dict, \n",
    "            iteration_range=(0, booster.best_iteration+1)\n",
    "        )\n",
    "\n",
    "        BDT_all_preds = np.concatenate([BDT_train_preds, BDT_test_preds])\n",
    "        BDT_all_preds = BDT_all_preds[\n",
    "            np.argsort(\n",
    "                np.concatenate([DATA_data_aux_dict[f\"fold_0\"].loc[:, 'hash'].to_numpy(), DATA_data_test_aux_dict[f\"fold_0\"].loc[:, 'hash'].to_numpy()])\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        if fold_idx == 0:\n",
    "            data_preds = copy.deepcopy(BDT_all_preds)\n",
    "        else:\n",
    "            data_preds += BDT_all_preds\n",
    "\n",
    "            if fold_idx == len(DATA_label_test_dict) - 1:\n",
    "                data_preds = data_preds / len(DATA_label_test_dict)\n",
    "\n",
    "\n",
    "        # single-fold eval\n",
    "        bdt_test_data_fold = xgb.DMatrix(\n",
    "            data=DATA_data_hlf_test_dict[f\"fold_{fold_idx}\"], label=DATA_label_test_dict[f\"fold_{fold_idx}\"], \n",
    "            missing=-999.0, feature_names=list(DATA_hlf_vars_columns_dict[f\"fold_{fold_idx}\"])\n",
    "        )\n",
    "\n",
    "        test_preds.append(\n",
    "            booster.predict(\n",
    "                bdt_test_data_fold,\n",
    "                iteration_range=(0, booster.best_iteration+1)\n",
    "            )\n",
    "        )\n",
    "\n",
    "    data_sample['MultiBDT_output'] = sorted_preds(\n",
    "        data_preds, DATA_data_test_aux_dict, data_sample,\n",
    "        sorted_preds=True\n",
    "    )\n",
    "    data_sample['MultiBDT_output_mod5'] = sorted_preds(\n",
    "        test_preds, DATA_data_test_aux_dict, data_sample\n",
    "    )\n",
    "\n",
    "    dest_filepath = parquet_filepath[:parquet_filepath.find('Run3_202')+len('Run3_202x_merged')] + dirpath_addition + parquet_filepath[parquet_filepath.find('Run3_202')+len('Run3_202x_merged'):parquet_filepath.rfind('.')] + filename_addition + parquet_filepath[parquet_filepath.rfind('.'):]\n",
    "    if not os.path.exists(dest_filepath[:dest_filepath.rfind('/')]):\n",
    "        os.makedirs(dest_filepath[:dest_filepath.rfind('/')])\n",
    "    print(dest_filepath)\n",
    "    print('='*60)\n",
    "    merged_parquet = ak.to_parquet(data_sample, dest_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
