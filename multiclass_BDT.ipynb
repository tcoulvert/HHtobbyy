{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmslpcgpu3.fnal.gov      Thu Jul  3 13:28:54 2025  555.42.06\n",
      "[0] Tesla P100-PCIE-12GB | 42Â°C,   1 % |     0 / 12288 MB |\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib widget\n",
    "# Stdlib packages\n",
    "import copy\n",
    "import datetime\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "# Common Py packages\n",
    "import awkward as ak\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from prettytable import PrettyTable\n",
    "from scipy.special import logit as inverse_sigmoid\n",
    "\n",
    "# HEP packages\n",
    "import gpustat\n",
    "import h5py\n",
    "import hist\n",
    "import mplhep as hep\n",
    "import xgboost as xgb\n",
    "from cycler import cycler\n",
    "\n",
    "# ML packages\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, fbeta_score\n",
    "from sklearn.metrics import log_loss\n",
    "from scipy.integrate import trapezoid\n",
    "from scipy.optimize import curve_fit\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Integer\n",
    "from skopt.utils import use_named_args\n",
    "\n",
    "# Module packages\n",
    "from data_processing_BDT import process_data\n",
    "\n",
    "gpustat.print_gpustat()\n",
    "\n",
    "plt.style.use(hep.style.CMS)\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "cmap_petroff10 = [\"#3f90da\", \"#ffa90e\", \"#bd1f01\", \"#94a4a2\", \"#832db6\", \"#a96b59\", \"#e76300\", \"#b9ac70\", \"#717581\", \"#92dadd\"]\n",
    "plt.rcParams.update({\"axes.prop_cycle\": cycler(\"color\", cmap_petroff10)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Locations and Model Naming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "lpc_fileprefix = \"/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v3/\"\n",
    "# Run3_2022 = 'Run3_2022_mergedResolved/sim'\n",
    "# Run3_2023 = 'Run3_2023_mergedResolved/sim'\n",
    "# Run3_2024 = 'Run3_2024_mergedResolved/sim'\n",
    "Run3_2022 = 'Run3_2022_mergedFullResolved/sim'\n",
    "Run3_2023 = 'Run3_2023_mergedFullResolved/sim'\n",
    "Run3_2024 = 'Run3_2024_mergedFullResolved/sim'\n",
    "\n",
    "def get_filepath_dict(syst_name: str='nominal'):\n",
    "    # return {\n",
    "    #     'ggF HH': [\n",
    "    #         lpc_fileprefix+Run3_2022+f\"/preEE/GluGlutoHHto2B2G_kl_1p00_kt_1p00_c2_0p00/{syst_name}/*merged.parquet\", \n",
    "    #         lpc_fileprefix+Run3_2022+f\"/postEE/GluGluToHH/{syst_name}/*merged.parquet\",\n",
    "    #         lpc_fileprefix+Run3_2023+f\"/preBPix/GluGlutoHHto2B2G_kl-1p00_kt-1p00_c2-0p00/{syst_name}/*merged.parquet\", \n",
    "    #         lpc_fileprefix+Run3_2023+f\"/postBPix/GluGlutoHHto2B2G_kl-1p00_kt-1p00_c2-0p00/{syst_name}/*merged.parquet\",\n",
    "\n",
    "    #         lpc_fileprefix+Run3_2022+f\"/preEE/VBFHHto2B2G_CV_1_C2V_1_C3_1/{syst_name}/*merged.parquet\", \n",
    "    #         # lpc_fileprefix+Run3_2022+f\"/postEE/VBFHHto2B2G_CV_1_C2V_1_C3_1/{syst_name}/*merged.parquet\",\n",
    "    #         lpc_fileprefix+Run3_2023+f\"/preBPix/VBFHHto2B2G_CV_1_C2V_1_C3_1/{syst_name}/*merged.parquet\", \n",
    "    #         lpc_fileprefix+Run3_2023+f\"/postBPix/VBFHHto2B2G_CV_1_C2V_1_C3_1/{syst_name}/*merged.parquet\",\n",
    "\n",
    "    #         # # kappa lambda scan #\n",
    "    #         # lpc_fileprefix+Run3_2022+f\"/preEE/GluGlutoHHto2B2G_kl_0p00_kt_1p00_c2_0p00/{syst_name}/*merged.parquet\", \n",
    "    #         # lpc_fileprefix+Run3_2022+f\"/postEE/GluGlutoHHto2B2G_kl_0p00_kt_1p00_c2_0p00/{syst_name}/*merged.parquet\",\n",
    "    #         # lpc_fileprefix+Run3_2022+f\"/preEE/GluGlutoHHto2B2G_kl_5p00_kt_1p00_c2_0p00/{syst_name}/*merged.parquet\", \n",
    "    #         # lpc_fileprefix+Run3_2022+f\"/postEE/GluGlutoHHto2B2G_kl_5p00_kt_1p00_c2_0p00/{syst_name}/*merged.parquet\",\n",
    "    #         # lpc_fileprefix+Run3_2023+f\"/preBPix/GluGlutoHHto2B2G_kl-0p00_kt-1p00_c2-0p00/{syst_name}/*merged.parquet\", \n",
    "    #         # lpc_fileprefix+Run3_2023+f\"/postBPix/GluGlutoHHto2B2G_kl-0p00_kt-1p00_c2-0p00/{syst_name}/*merged.parquet\",\n",
    "    #         # lpc_fileprefix+Run3_2023+f\"/preBPix/GluGlutoHHto2B2G_kl-2p45_kt-1p00_c2-0p00/{syst_name}/*merged.parquet\", \n",
    "    #         # lpc_fileprefix+Run3_2023+f\"/postBPix/GluGlutoHHto2B2G_kl-2p45_kt-1p00_c2-0p00/{syst_name}/*merged.parquet\",\n",
    "    #         # lpc_fileprefix+Run3_2023+f\"/preBPix/GluGlutoHHto2B2G_kl-5p00_kt-1p00_c2-0p00/{syst_name}/*merged.parquet\", \n",
    "    #         # lpc_fileprefix+Run3_2023+f\"/postBPix/GluGlutoHHto2B2G_kl-5p00_kt-1p00_c2-0p00/{syst_name}/*merged.parquet\",\n",
    "    #     ],\n",
    "    #     'ttH + bbH': [\n",
    "    #         # ttH\n",
    "    #         lpc_fileprefix+Run3_2022+f\"/preEE/ttHtoGG_M_125/{syst_name}/*merged.parquet\", \n",
    "    #         lpc_fileprefix+Run3_2022+f\"/postEE/ttHToGG/{syst_name}/*merged.parquet\",\n",
    "    #         lpc_fileprefix+Run3_2023+f\"/preBPix/ttHtoGG/{syst_name}/*merged.parquet\", \n",
    "    #         lpc_fileprefix+Run3_2023+f\"/postBPix/ttHtoGG/{syst_name}/*merged.parquet\",\n",
    "    #         # bbH\n",
    "    #         lpc_fileprefix+Run3_2022+f\"/preEE/BBHto2G_M_125/{syst_name}/*merged.parquet\", \n",
    "    #         lpc_fileprefix+Run3_2022+f\"/postEE/BBHto2G_M_125/{syst_name}/*merged.parquet\",\n",
    "    #         lpc_fileprefix+Run3_2023+f\"/preBPix/bbHtoGG/{syst_name}/*merged.parquet\", \n",
    "    #         lpc_fileprefix+Run3_2023+f\"/postBPix/bbHtoGG/{syst_name}/*merged.parquet\",\n",
    "    #     ],\n",
    "    #     'VH': [\n",
    "    #         # VH\n",
    "    #         lpc_fileprefix+Run3_2022+f\"/preEE/VHtoGG_M_125/{syst_name}/*merged.parquet\", \n",
    "    #         lpc_fileprefix+Run3_2022+f\"/postEE/VHtoGG_M-125/{syst_name}/*merged.parquet\",\n",
    "    #         lpc_fileprefix+Run3_2023+f\"/preBPix/VHtoGG/{syst_name}/*merged.parquet\", \n",
    "    #         lpc_fileprefix+Run3_2023+f\"/postBPix/VHtoGG/{syst_name}/*merged.parquet\",\n",
    "    #         # # # ZH\n",
    "    #         # lpc_fileprefix+Run3_2022+f\"/preEE/ZH_Hto2G_Zto2Q_M-125/{syst_name}/*merged.parquet\", \n",
    "    #         # lpc_fileprefix+Run3_2022+f\"/postEE/ZH_Hto2G_Zto2Q_M-125/{syst_name}/*merged.parquet\",\n",
    "    #         # # # W-H\n",
    "    #         # lpc_fileprefix+Run3_2022+f\"/preEE/WminusH_Hto2G_Wto2Q_M-125/{syst_name}/*merged.parquet\", \n",
    "    #         # lpc_fileprefix+Run3_2022+f\"/postEE/WminusH_Hto2G_Wto2Q_M-125/{syst_name}/*merged.parquet\",\n",
    "    #         # # # W+H\n",
    "    #         # lpc_fileprefix+Run3_2022+f\"/preEE/WplusH_Hto2G_Wto2Q_M-125/{syst_name}/*merged.parquet\", \n",
    "    #         # lpc_fileprefix+Run3_2022+f\"/postEE/WplusH_Hto2G_Wto2Q_M-125/{syst_name}/*merged.parquet\",\n",
    "    #     ],\n",
    "    #     'non-res + ggFH + VBFH': [\n",
    "    #         # GG + 3Jets\n",
    "    #         lpc_fileprefix+Run3_2022+f\"/preEE/GGJets/{syst_name}/*merged.parquet\", \n",
    "    #         lpc_fileprefix+Run3_2022+f\"/postEE/GGJets/{syst_name}/*merged.parquet\",\n",
    "    #         lpc_fileprefix+Run3_2023+f\"/preBPix/GGJets/{syst_name}/*merged.parquet\", \n",
    "    #         lpc_fileprefix+Run3_2023+f\"/postBPix/GGJets/{syst_name}/*merged.parquet\",\n",
    "    #         # GJet pT 20-40\n",
    "    #         lpc_fileprefix+Run3_2022+f\"/preEE/GJetPt20To40/{syst_name}/*merged.parquet\", \n",
    "    #         lpc_fileprefix+Run3_2022+f\"/postEE/GJetPt20To40/{syst_name}/*merged.parquet\",\n",
    "    #         lpc_fileprefix+Run3_2023+f\"/preBPix/GJetPt20To40/{syst_name}/*merged.parquet\", \n",
    "    #         lpc_fileprefix+Run3_2023+f\"/postBPix/GJetPt20To40/{syst_name}/*merged.parquet\",\n",
    "    #         # GJet pT 40-inf\n",
    "    #         lpc_fileprefix+Run3_2022+f\"/preEE/GJetPt40/{syst_name}/*merged.parquet\", \n",
    "    #         lpc_fileprefix+Run3_2022+f\"/postEE/GJetPt40/{syst_name}/*merged.parquet\",\n",
    "    #         lpc_fileprefix+Run3_2023+f\"/preBPix/GJetPt40/{syst_name}/*merged.parquet\", \n",
    "    #         lpc_fileprefix+Run3_2023+f\"/postBPix/GJetPt40/{syst_name}/*merged.parquet\",\n",
    "    #         # ggF H\n",
    "    #         lpc_fileprefix+Run3_2022+f\"/preEE/GluGluHToGG_M_125/{syst_name}/*merged.parquet\", \n",
    "    #         lpc_fileprefix+Run3_2022+f\"/postEE/GluGluHToGG/{syst_name}/*merged.parquet\",\n",
    "    #         lpc_fileprefix+Run3_2023+f\"/preBPix/GluGluHtoGG/{syst_name}/*merged.parquet\", \n",
    "    #         lpc_fileprefix+Run3_2023+f\"/postBPix/GluGluHtoGG/{syst_name}/*merged.parquet\",\n",
    "    #         # VBF H\n",
    "    #         lpc_fileprefix+Run3_2022+f\"/preEE/VBFHToGG_M_125/{syst_name}/*merged.parquet\", \n",
    "    #         lpc_fileprefix+Run3_2022+f\"/postEE/VBFHToGG/{syst_name}/*merged.parquet\",\n",
    "    #         lpc_fileprefix+Run3_2023+f\"/preBPix/VBFHtoGG/{syst_name}/*merged.parquet\", \n",
    "    #         lpc_fileprefix+Run3_2023+f\"/postBPix/VBFHtoGG/{syst_name}/*merged.parquet\",\n",
    "    #     ],\n",
    "    # }\n",
    "    return {\n",
    "        'ggF HH': [\n",
    "            lpc_fileprefix+Run3_2022+f\"/preEE/GluGlutoHH_kl-1p00_kt-1p00_c2-0p00/{syst_name}/*merged.parquet\", # central v2 preEE name\n",
    "            lpc_fileprefix+Run3_2022+f\"/postEE/GluGlutoHHto2B2G_kl_1p00_kt_1p00_c2_0p00/{syst_name}/*merged.parquet\",  # central v2 postEE name\n",
    "            lpc_fileprefix+Run3_2023+f\"/preBPix/GluGlutoHH_kl-1p00_kt-1p00_c2-0p00/{syst_name}/*merged.parquet\",  # thomas name\n",
    "            lpc_fileprefix+Run3_2023+f\"/postBPix/GluGlutoHH_kl-1p00_kt-1p00_c2-0p00/{syst_name}/*merged.parquet\",\n",
    "\n",
    "            # lpc_fileprefix+Run3_2022+f\"/preEE/VBFHHto2B2G_CV_1_C2V_1_C3_1/{syst_name}/*merged.parquet\", \n",
    "            # lpc_fileprefix+Run3_2022+f\"/postEE/VBFHHto2B2G_CV_1_C2V_1_C3_1/{syst_name}/*merged.parquet\",\n",
    "            # lpc_fileprefix+Run3_2023+f\"/preBPix/VBFHHto2B2G_CV_1_C2V_1_C3_1/{syst_name}/*merged.parquet\", \n",
    "            # lpc_fileprefix+Run3_2023+f\"/postBPix/VBFHHto2B2G_CV_1_C2V_1_C3_1/{syst_name}/*merged.parquet\",\n",
    "\n",
    "            # # kappa lambda scan #\n",
    "            # lpc_fileprefix+Run3_2022+f\"/preEE/GluGlutoHHto2B2G_kl_0p00_kt_1p00_c2_0p00/{syst_name}/*merged.parquet\", \n",
    "            # lpc_fileprefix+Run3_2022+f\"/postEE/GluGlutoHHto2B2G_kl_0p00_kt_1p00_c2_0p00/{syst_name}/*merged.parquet\",\n",
    "            # lpc_fileprefix+Run3_2022+f\"/preEE/GluGlutoHHto2B2G_kl_5p00_kt_1p00_c2_0p00/{syst_name}/*merged.parquet\", \n",
    "            # lpc_fileprefix+Run3_2022+f\"/postEE/GluGlutoHHto2B2G_kl_5p00_kt_1p00_c2_0p00/{syst_name}/*merged.parquet\",\n",
    "            # lpc_fileprefix+Run3_2023+f\"/preBPix/GluGlutoHHto2B2G_kl-0p00_kt-1p00_c2-0p00/{syst_name}/*merged.parquet\", \n",
    "            # lpc_fileprefix+Run3_2023+f\"/postBPix/GluGlutoHHto2B2G_kl-0p00_kt-1p00_c2-0p00/{syst_name}/*merged.parquet\",\n",
    "            # lpc_fileprefix+Run3_2023+f\"/preBPix/GluGlutoHHto2B2G_kl-2p45_kt-1p00_c2-0p00/{syst_name}/*merged.parquet\", \n",
    "            # lpc_fileprefix+Run3_2023+f\"/postBPix/GluGlutoHHto2B2G_kl-2p45_kt-1p00_c2-0p00/{syst_name}/*merged.parquet\",\n",
    "            # lpc_fileprefix+Run3_2023+f\"/preBPix/GluGlutoHHto2B2G_kl-5p00_kt-1p00_c2-0p00/{syst_name}/*merged.parquet\", \n",
    "            # lpc_fileprefix+Run3_2023+f\"/postBPix/GluGlutoHHto2B2G_kl-5p00_kt-1p00_c2-0p00/{syst_name}/*merged.parquet\",\n",
    "        ],\n",
    "        'ttH + bbH': [\n",
    "            # ttH\n",
    "            lpc_fileprefix+Run3_2022+f\"/preEE/ttHtoGG/{syst_name}/*merged.parquet\", \n",
    "            lpc_fileprefix+Run3_2022+f\"/postEE/ttHToGG/{syst_name}/*merged.parquet\",\n",
    "            lpc_fileprefix+Run3_2023+f\"/preBPix/ttHtoGG/{syst_name}/*merged.parquet\", \n",
    "            lpc_fileprefix+Run3_2023+f\"/postBPix/ttHtoGG/{syst_name}/*merged.parquet\",\n",
    "            # bbH\n",
    "            lpc_fileprefix+Run3_2022+f\"/preEE/bbHtoGG/{syst_name}/*merged.parquet\", \n",
    "            lpc_fileprefix+Run3_2022+f\"/postEE/bbHtoGG/{syst_name}/*merged.parquet\",\n",
    "            lpc_fileprefix+Run3_2023+f\"/preBPix/bbHtoGG/{syst_name}/*merged.parquet\", \n",
    "            lpc_fileprefix+Run3_2023+f\"/postBPix/bbHtoGG/{syst_name}/*merged.parquet\",\n",
    "        ],\n",
    "        'VH': [\n",
    "            # VH\n",
    "            lpc_fileprefix+Run3_2022+f\"/preEE/VHtoGG/{syst_name}/*merged.parquet\", \n",
    "            lpc_fileprefix+Run3_2022+f\"/postEE/VHtoGG/{syst_name}/*merged.parquet\",\n",
    "            lpc_fileprefix+Run3_2023+f\"/preBPix/VHtoGG/{syst_name}/*merged.parquet\", \n",
    "            lpc_fileprefix+Run3_2023+f\"/postBPix/VHtoGG/{syst_name}/*merged.parquet\",\n",
    "            # ZH\n",
    "            lpc_fileprefix+Run3_2022+f\"/preEE/ZH_Hto2G_Zto2Q_M-125/{syst_name}/*merged.parquet\", \n",
    "            lpc_fileprefix+Run3_2022+f\"/postEE/ZH_Hto2G_Zto2Q_M-125/{syst_name}/*merged.parquet\",\n",
    "            lpc_fileprefix+Run3_2023+f\"/preBPix/ZH_Hto2G_Zto2Q_M-125/{syst_name}/*merged.parquet\", \n",
    "            lpc_fileprefix+Run3_2023+f\"/postBPix/ZH_Hto2G_Zto2Q_M-125/{syst_name}/*merged.parquet\",\n",
    "            # W-H\n",
    "            lpc_fileprefix+Run3_2022+f\"/preEE/WminusH_Hto2G_Wto2Q_M-125/{syst_name}/*merged.parquet\", \n",
    "            lpc_fileprefix+Run3_2022+f\"/postEE/WminusH_Hto2G_Wto2Q_M-125/{syst_name}/*merged.parquet\",\n",
    "            lpc_fileprefix+Run3_2023+f\"/preBPix/WminusH_Hto2G_Wto2Q_M-125/{syst_name}/*merged.parquet\", \n",
    "            lpc_fileprefix+Run3_2023+f\"/postBPix/WminusH_Hto2G_Wto2Q_M-125/{syst_name}/*merged.parquet\",\n",
    "            # W+H\n",
    "            lpc_fileprefix+Run3_2022+f\"/preEE/WplusH_Hto2G_Wto2Q_M-125/{syst_name}/*merged.parquet\", \n",
    "            lpc_fileprefix+Run3_2022+f\"/postEE/WplusH_Hto2G_Wto2Q_M-125/{syst_name}/*merged.parquet\",\n",
    "            lpc_fileprefix+Run3_2023+f\"/preBPix/WplusH_Hto2G_Wto2Q_M-125/{syst_name}/*merged.parquet\", \n",
    "            lpc_fileprefix+Run3_2023+f\"/postBPix/WplusH_Hto2G_Wto2Q_M-125/{syst_name}/*merged.parquet\",\n",
    "        ],\n",
    "        'non-res + ggFH + VBFH': [\n",
    "            # GG + 3Jets 40-80\n",
    "            lpc_fileprefix+Run3_2022+f\"/preEE/GGJets_MGG-40to80/{syst_name}/*merged.parquet\", \n",
    "            lpc_fileprefix+Run3_2022+f\"/postEE/GGJets_MGG-40to80/{syst_name}/*merged.parquet\",\n",
    "            lpc_fileprefix+Run3_2023+f\"/preBPix/GGJets_MGG-40to80/{syst_name}/*merged.parquet\", \n",
    "            lpc_fileprefix+Run3_2023+f\"/postBPix/GGJets_MGG-40to80/{syst_name}/*merged.parquet\",\n",
    "            # GG + 3Jets 80-\n",
    "            lpc_fileprefix+Run3_2022+f\"/preEE/GGJets_MGG-80/{syst_name}/*merged.parquet\", \n",
    "            lpc_fileprefix+Run3_2022+f\"/postEE/GGJets_MGG-80/{syst_name}/*merged.parquet\",\n",
    "            lpc_fileprefix+Run3_2023+f\"/preBPix/GGJets_MGG-80/{syst_name}/*merged.parquet\", \n",
    "            lpc_fileprefix+Run3_2023+f\"/postBPix/GGJets_MGG-80/{syst_name}/*merged.parquet\",\n",
    "            # GJet pT 20-40\n",
    "            lpc_fileprefix+Run3_2022+f\"/preEE/GJet_PT-20to40_DoubleEMEnriched_MGG-80/{syst_name}/*merged.parquet\", \n",
    "            lpc_fileprefix+Run3_2022+f\"/postEE/GJet_PT-20to40_DoubleEMEnriched_MGG-80/{syst_name}/*merged.parquet\",\n",
    "            lpc_fileprefix+Run3_2023+f\"/preBPix/GJet_PT-20to40_DoubleEMEnriched_MGG-80/{syst_name}/*merged.parquet\", \n",
    "            lpc_fileprefix+Run3_2023+f\"/postBPix/GJet_PT-20to40_DoubleEMEnriched_MGG-80/{syst_name}/*merged.parquet\",\n",
    "            # GJet pT 40-inf\n",
    "            lpc_fileprefix+Run3_2022+f\"/preEE/GJet_PT-40_DoubleEMEnriched_MGG-80/{syst_name}/*merged.parquet\", \n",
    "            lpc_fileprefix+Run3_2022+f\"/postEE/GJet_PT-40_DoubleEMEnriched_MGG-80/{syst_name}/*merged.parquet\",\n",
    "            lpc_fileprefix+Run3_2023+f\"/preBPix/GJet_PT-40_DoubleEMEnriched_MGG-80/{syst_name}/*merged.parquet\", \n",
    "            lpc_fileprefix+Run3_2023+f\"/postBPix/GJet_PT-40_DoubleEMEnriched_MGG-80/{syst_name}/*merged.parquet\",\n",
    "            # ggF H\n",
    "            lpc_fileprefix+Run3_2022+f\"/preEE/GluGluHtoGG/{syst_name}/*merged.parquet\", \n",
    "            lpc_fileprefix+Run3_2022+f\"/postEE/GluGluHtoGG/{syst_name}/*merged.parquet\",\n",
    "            lpc_fileprefix+Run3_2023+f\"/preBPix/GluGluHtoGG/{syst_name}/*merged.parquet\", \n",
    "            lpc_fileprefix+Run3_2023+f\"/postBPix/GluGluHtoGG/{syst_name}/*merged.parquet\",\n",
    "            # VBF H\n",
    "            lpc_fileprefix+Run3_2022+f\"/preEE/VBFHtoGG/{syst_name}/*merged.parquet\", \n",
    "            lpc_fileprefix+Run3_2022+f\"/postEE/VBFHToGG/{syst_name}/*merged.parquet\",\n",
    "            lpc_fileprefix+Run3_2023+f\"/preBPix/VBFHtoGG/{syst_name}/*merged.parquet\", \n",
    "            lpc_fileprefix+Run3_2023+f\"/postBPix/VBFHtoGG/{syst_name}/*merged.parquet\",\n",
    "        ],\n",
    "    }\n",
    "    # return {\n",
    "    #     'ggF HH': [\n",
    "    #         lpc_fileprefix+f\"Run3_2022_mergedResolved_SMEFTSignal/2022postEE/GluGluToHH/{syst_name}/*merged.parquet\",\n",
    "    #         lpc_fileprefix+f\"Run3_2022_mergedResolved_SMEFTSignal/2022postEE/ggHH-CH-20-CHD10-t1/{syst_name}/*merged.parquet\",\n",
    "    #         lpc_fileprefix+f\"Run3_2022_mergedResolved_SMEFTSignal/2022postEE/ggHH-CH-20-CHG0.1-t1/{syst_name}/*merged.parquet\",\n",
    "    #         lpc_fileprefix+f\"Run3_2022_mergedResolved_SMEFTSignal/2022postEE/ggHH-CH-20-CHbox20-t1/{syst_name}/*merged.parquet\",\n",
    "    #         lpc_fileprefix+f\"Run3_2022_mergedResolved_SMEFTSignal/2022postEE/ggHH-CH-20-CuH40-t1/{syst_name}/*merged.parquet\",\n",
    "    #         lpc_fileprefix+f\"Run3_2022_mergedResolved_SMEFTSignal/2022postEE/ggHH-CH-20-t1/{syst_name}/*merged.parquet\",\n",
    "    #         lpc_fileprefix+f\"Run3_2022_mergedResolved_SMEFTSignal/2022postEE/ggHH-CH-6-t1/{syst_name}/*merged.parquet\",\n",
    "    #         lpc_fileprefix+f\"Run3_2022_mergedResolved_SMEFTSignal/2022postEE/ggHH-CH10-t1/{syst_name}/*merged.parquet\",\n",
    "    #         lpc_fileprefix+f\"Run3_2022_mergedResolved_SMEFTSignal/2022postEE/ggHH-CHD-5-t1/{syst_name}/*merged.parquet\",\n",
    "    #         lpc_fileprefix+f\"Run3_2022_mergedResolved_SMEFTSignal/2022postEE/ggHH-CHD10-CHG0.1-t1/{syst_name}/*merged.parquet\",\n",
    "    #         lpc_fileprefix+f\"Run3_2022_mergedResolved_SMEFTSignal/2022postEE/ggHH-CHD10-CuH40-t1/{syst_name}/*merged.parquet\",\n",
    "    #         lpc_fileprefix+f\"Run3_2022_mergedResolved_SMEFTSignal/2022postEE/ggHH-CHD10-t1/{syst_name}/*merged.parquet\",\n",
    "    #         lpc_fileprefix+f\"Run3_2022_mergedResolved_SMEFTSignal/2022postEE/ggHH-CHG-0.05-t1/{syst_name}/*merged.parquet\",\n",
    "    #         lpc_fileprefix+f\"Run3_2022_mergedResolved_SMEFTSignal/2022postEE/ggHH-CHG0.1-t1/{syst_name}/*merged.parquet\",\n",
    "    #         lpc_fileprefix+f\"Run3_2022_mergedResolved_SMEFTSignal/2022postEE/ggHH-CHbox-10-t1/{syst_name}/*merged.parquet\",\n",
    "    #         lpc_fileprefix+f\"Run3_2022_mergedResolved_SMEFTSignal/2022postEE/ggHH-CHbox20-CHD10-t1/{syst_name}/*merged.parquet\",\n",
    "    #         lpc_fileprefix+f\"Run3_2022_mergedResolved_SMEFTSignal/2022postEE/ggHH-CHbox20-CHG0.1-t1/{syst_name}/*merged.parquet\",\n",
    "    #         lpc_fileprefix+f\"Run3_2022_mergedResolved_SMEFTSignal/2022postEE/ggHH-CHbox20-CuH40-t1/{syst_name}/*merged.parquet\",\n",
    "    #         lpc_fileprefix+f\"Run3_2022_mergedResolved_SMEFTSignal/2022postEE/ggHH-CHbox20-t1/{syst_name}/*merged.parquet\",\n",
    "    #         lpc_fileprefix+f\"Run3_2022_mergedResolved_SMEFTSignal/2022postEE/ggHH-CuH-20-t1/{syst_name}/*merged.parquet\",\n",
    "    #         lpc_fileprefix+f\"Run3_2022_mergedResolved_SMEFTSignal/2022postEE/ggHH-CuH40-CHG0.1-t1/{syst_name}/*merged.parquet\",\n",
    "    #         lpc_fileprefix+f\"Run3_2022_mergedResolved_SMEFTSignal/2022postEE/ggHH-CuH40-t1/{syst_name}/*merged.parquet\",\n",
    "    #         lpc_fileprefix+f\"Run3_2022_mergedResolved_SMEFTSignal/2022postEE/ggHH_BM1/{syst_name}/*merged.parquet\",\n",
    "    #         lpc_fileprefix+f\"Run3_2022_mergedResolved_SMEFTSignal/2022postEE/ggHH_BM3/{syst_name}/*merged.parquet\",\n",
    "    #         lpc_fileprefix+f\"Run3_2022_mergedResolved_SMEFTSignal/2022postEE/ggHH_kl_0p00/{syst_name}/*merged.parquet\",\n",
    "    #         lpc_fileprefix+f\"Run3_2022_mergedResolved_SMEFTSignal/2022postEE/ggHH_kl_2p45/{syst_name}/*merged.parquet\",\n",
    "    #         lpc_fileprefix+f\"Run3_2022_mergedResolved_SMEFTSignal/2022postEE/ggHH_kl_5p00/{syst_name}/*merged.parquet\",\n",
    "    #     ],\n",
    "    #     'ttH + bbH': [\n",
    "    #         # ttH\n",
    "    #         lpc_fileprefix+f\"Run3_2022_mergedResolved_SMEFTSingleH/2022postEE/tth/{syst_name}/*merged.parquet\",\n",
    "    #         # bbH\n",
    "    #         lpc_fileprefix+f\"Run3_2022_mergedResolved_SMEFTSingleH/2022postEE/bbh/{syst_name}/*merged.parquet\",\n",
    "    #     ],\n",
    "    #     'VH': [\n",
    "    #         # VH\n",
    "    #         lpc_fileprefix+f\"Run3_2022_mergedResolved_SMEFTSingleH/2022postEE/vh/{syst_name}/*merged.parquet\",\n",
    "    #     ],\n",
    "    #     'non-res + ggFH + VBFH': [\n",
    "    #         # ggF H\n",
    "    #         lpc_fileprefix+f\"Run3_2022_mergedResolved_SMEFTSingleH/2022postEE/GluGluToHH/{syst_name}/*merged.parquet\",\n",
    "    #         # VBF H\n",
    "    #         lpc_fileprefix+f\"Run3_2022_mergedResolved_SMEFTSingleH/2022postEE/vbf/{syst_name}/*merged.parquet\",\n",
    "    #     ],\n",
    "    # }\n",
    "    # return {\n",
    "    #     'ggF HH': [\n",
    "    #         lpc_fileprefix+f\"Run3_2022_mergedResolved_ggHH_smeft/2022postEE/GluGluToHH/{syst_name}/*merged.parquet\",\n",
    "    #     ],\n",
    "    #     'ttH + bbH': [\n",
    "    #     ],\n",
    "    #     'VH': [\n",
    "    #     ],\n",
    "    #     'non-res + ggFH + VBFH': [\n",
    "    #         # ggF H\n",
    "    #         lpc_fileprefix+f\"Run3_2022_mergedResolved_ggH_smeft/2022postEE/GluGluHToGG/{syst_name}/*merged.parquet\",\n",
    "    #     ],\n",
    "    # }\n",
    "\n",
    "FILEPATHS_DICT = get_filepath_dict()\n",
    "\n",
    "CURRENT_DIRPATH = str(Path().absolute())\n",
    "MOD_VALS = (5, 5)\n",
    "# VERSION = 'v12'\n",
    "# VARS = 'v2_vars_mvaIDCorr_22_23'\n",
    "# CURRENT_TIME = '2025-04-05_12-04-41'\n",
    "# VARS = 'v2_vars_float32_22_23'\n",
    "# CURRENT_TIME = '2025-04-16_14-16-12'\n",
    "# VARS = 'HEFT_vars'\n",
    "# CURRENT_TIME = '2025-04-24_09-55-39'\n",
    "VERSION = 'v13'\n",
    "# VARS = 'v3_vars_DijetMass_22_23'\n",
    "# CURRENT_TIME = '2025-06-19_12-16-44'\n",
    "# VARS = 'v3_vars_MbbRegDijetMass_22_23'\n",
    "# VARS = 'v3_vars_MbbRegDNNPairDijetMass_22_23'\n",
    "# CURRENT_TIME = '2025-06-20_00-51-43'\n",
    "VARS = 'v3_vars_EFT_DijetMass_22_23'\n",
    "if 'CURRENT_TIME' in globals():\n",
    "    OUTPUT_DIRPATH = os.path.join(CURRENT_DIRPATH, f\"MultiClassBDT_model_outputs/{VERSION}/{VARS}\", CURRENT_TIME)\n",
    "else:\n",
    "    OUTPUT_DIRPATH = os.path.join(CURRENT_DIRPATH, f\"MultiClassBDT_model_outputs/{VERSION}/{VARS}\")\n",
    "\n",
    "if not os.path.exists(OUTPUT_DIRPATH):\n",
    "    os.makedirs(OUTPUT_DIRPATH)\n",
    "\n",
    "OTHER_BKG_RESCALE = 100\n",
    "OPTIMIZE_SPACE = False\n",
    "FORCE_RERUN = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "order = ['ggF HH', 'ttH + bbH', 'VH', 'non-res + ggFH + VBFH']\n",
    "\n",
    "def training_weights(event_weights, labels, order=None, weighttype='rescaled_and_shifted', sig_rescale_factor=None):\n",
    "    if weighttype == 'abs':\n",
    "        return np.abs(event_weights)\n",
    "    \n",
    "    if order is not None:\n",
    "        sig_idx, big_bkg_idx = -1, -1\n",
    "        for i, sample_name in enumerate(order):\n",
    "            if re.search('ggF HH', sample_name) is not None:\n",
    "                sig_idx = i\n",
    "                continue\n",
    "            if re.search('non-res', sample_name) is not None:\n",
    "                big_bkg_idx = i\n",
    "                continue\n",
    "    else:\n",
    "        sig_idx, big_bkg_idx = 0, len(order)-1\n",
    "    \n",
    "    if sig_rescale_factor is None:\n",
    "        sig_sum = np.sum(event_weights[labels[:, sig_idx] == 1])\n",
    "        bkg_sum = np.sum(event_weights[labels[:, sig_idx] == 0])\n",
    "        \n",
    "        sig_rescale_factor = bkg_sum / sig_sum\n",
    "\n",
    "    scaled_weights = np.where(\n",
    "        labels[:, sig_idx] == 0, \n",
    "        np.where(\n",
    "            np.argmax(labels, axis=1) != big_bkg_idx,  \n",
    "            event_weights * OTHER_BKG_RESCALE,  # if not big bkg, rescale\n",
    "            event_weights  # otherwise do nothing\n",
    "        ),\n",
    "        event_weights * sig_rescale_factor  # if sig, rescale to equal sum of all bkgs\n",
    "    )\n",
    "\n",
    "    abs_weights = np.abs(scaled_weights)\n",
    "\n",
    "    if weighttype == 'rescaled':\n",
    "        return abs_weights\n",
    "    elif weighttype == 'rescaled_and_shifted':\n",
    "        mean_weights = np.mean(scaled_weights)\n",
    "        rescaled_weights = abs_weights / mean_weights\n",
    "        return rescaled_weights\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"The only options for weighttype are 'abs', 'rescaled', and 'rescaled_and_shifted'. You provided {weighttype}\"\n",
    "        )\n",
    "\n",
    "# def training_weights(event_weights, labels, order=None, sig_rescale_factor=None):\n",
    "#     if order is None:\n",
    "#         order = [i for v in range(np.shape(labels)[0])]\n",
    "#     sum_dict, max_sum, max_i = {}, 0, 0\n",
    "#     for i, sample_name in enumerate(order):\n",
    "#         sum_dict[i] = np.sum(event_weights[labels[:, i] == 1])\n",
    "#         if np.sum(event_weights[labels[:, i] == 1]) > max_sum:\n",
    "#             max_sum, max_i = np.sum(event_weights[labels[:, i] == 1]), i\n",
    "\n",
    "#     label_i = np.sum(\n",
    "#         np.tile([i for i in range(np.shape(labels)[1])], (np.shape(labels)[0], 1)) * labels,\n",
    "#         axis=1\n",
    "#     )\n",
    "\n",
    "#     weight_factors = []\n",
    "#     for i in range(len(label_i)):\n",
    "#         weight_factors.append(\n",
    "#             max_sum / sum_dict[label_i[i]] if label_i[i] != max_i else 1\n",
    "#         )\n",
    "#     weights = event_weights * np.array(weight_factors)\n",
    "\n",
    "#     mean_weight = np.mean(weights)\n",
    "#     abs_weights = np.abs(weights)\n",
    "#     scaled_weights = abs_weights / mean_weight\n",
    "\n",
    "#     return scaled_weights\n",
    "\n",
    "\n",
    "def xgb_labels(labels):\n",
    "    label_i = np.sum(\n",
    "        np.tile([i for i in range(np.shape(labels)[1])], (np.shape(labels)[0], 1)) * labels,\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    return label_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading and Input Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# order = ['ggF HH', 'ttH', 'single-H', 'non-res']\n",
    "# order = ['ggF HH', 'ttH', 'VH', 'non-res + ggFH + VBFH']\n",
    "# order = ['ggF HH', 'ttH + bbH', 'VH', 'non-res + ggFH + VBFH']\n",
    "\n",
    "(\n",
    "    sig_rescale_factor,\n",
    "    data_df_dict, data_test_df_dict, \n",
    "    data_hlf_dict, label_dict,\n",
    "    data_hlf_test_dict, label_test_dict, \n",
    "    hlf_vars_columns_dict,\n",
    "    data_aux_dict, data_test_aux_dict\n",
    ") = process_data(\n",
    "    FILEPATHS_DICT, OUTPUT_DIRPATH, order=order, mod_vals=MOD_VALS,\n",
    "    save=False if 'CURRENT_TIME' in globals() else True,\n",
    "    std_json_dirpath=OUTPUT_DIRPATH if 'CURRENT_TIME' in globals() else None,\n",
    "    other_bkg_rescale=OTHER_BKG_RESCALE, \n",
    "    jet_prefix='nonResReg_DNNpair' if re.search('MbbRegDNNPair', VARS) is not None else (\n",
    "        'nonResReg' if re.search('MbbReg', VARS) is not None else 'nonRes'\n",
    "    )\n",
    ")\n",
    "\n",
    "# Make xgb-like labels (NOT one-hot encoded, but integer encoded for each class)\n",
    "xgb_label_dict = {\n",
    "    f\"fold_{fold_idx}\": copy.deepcopy(xgb_labels(label_dict[f\"fold_{fold_idx}\"])) for fold_idx in range(len(data_test_aux_dict))\n",
    "}\n",
    "xgb_label_test_dict = {\n",
    "    f\"fold_{fold_idx}\": copy.deepcopy(xgb_labels(label_test_dict[f\"fold_{fold_idx}\"])) for fold_idx in range(len(data_test_aux_dict))\n",
    "}\n",
    "\n",
    "# Make weight dicts:\n",
    "#   - the top two are with the training rescale (i.e. rescale sig eventWeight to match bkg and then shift for gradients)\n",
    "#   - the bottom two are the standard eventWeights (i.e. xs * lumi * genWeight) for proper plotting\n",
    "weight_train_dict = {\n",
    "    f\"fold_{fold_idx}\": copy.deepcopy(training_weights(data_aux_dict[f'fold_{fold_idx}'].loc[:, \"eventWeight\"].to_numpy(), label_dict[f'fold_{fold_idx}'], order=order, sig_rescale_factor=sig_rescale_factor)) for fold_idx in range(len(data_aux_dict))\n",
    "}\n",
    "weight_test_dict = {\n",
    "    f'fold_{fold_idx}': copy.deepcopy(training_weights(data_test_aux_dict[f'fold_{fold_idx}'].loc[:, \"eventWeight\"].to_numpy(), label_test_dict[f'fold_{fold_idx}'], order=order, sig_rescale_factor=sig_rescale_factor)) for fold_idx in range(len(data_test_aux_dict))\n",
    "}\n",
    "weights_plot_train_dict = {\n",
    "    f\"fold_{fold_idx}\": copy.deepcopy(data_aux_dict[f'fold_{fold_idx}'].loc[:, \"eventWeight\"].to_numpy()) for fold_idx in range(len(data_aux_dict))\n",
    "}\n",
    "weights_plot_test = {\n",
    "    f'fold_{fold_idx}': copy.deepcopy(data_test_aux_dict[f'fold_{fold_idx}'].loc[:, \"eventWeight\"].to_numpy()) for fold_idx in range(len(data_test_aux_dict))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "Num train: 4301906 -> 190743 sig & 311778 ttH bkg & 99086 single-H bkg & 3700299 non-res bkg\n",
      "Num val: 1075477 -> 47498 sig & 78331 ttH bkg & 24692 single-H bkg & 924956 non-res bkg\n",
      "Num test: 1345956 -> 59582 sig & 97562 ttH bkg & 30973 single-H bkg & & 1157839 non-res bkg\n",
      "============================================================\n",
      "fold 1\n",
      "Num train: 4303872 -> 190609 sig & 312117 ttH bkg & 99171 single-H bkg & 3701975 non-res bkg\n",
      "Num val: 1075968 -> 47677 sig & 78297 ttH bkg & 24734 single-H bkg & 925260 non-res bkg\n",
      "Num test: 1343499 -> 59537 sig & 97257 ttH bkg & 30846 single-H bkg & & 1155859 non-res bkg\n",
      "============================================================\n",
      "fold 2\n",
      "Num train: 4303004 -> 190580 sig & 311984 ttH bkg & 98871 single-H bkg & 3701569 non-res bkg\n",
      "Num val: 1075752 -> 47646 sig & 77656 ttH bkg & 24874 single-H bkg & 925576 non-res bkg\n",
      "Num test: 1344583 -> 59597 sig & 98031 ttH bkg & 31006 single-H bkg & & 1155949 non-res bkg\n",
      "============================================================\n",
      "fold 3\n",
      "Num train: 4304405 -> 190334 sig & 312735 ttH bkg & 98912 single-H bkg & 3702424 non-res bkg\n",
      "Num val: 1076102 -> 47876 sig & 77497 ttH bkg & 24832 single-H bkg & 925897 non-res bkg\n",
      "Num test: 1342832 -> 59613 sig & 97439 ttH bkg & 31007 single-H bkg & & 1154773 non-res bkg\n",
      "============================================================\n",
      "fold 4\n",
      "Num train: 4301496 -> 190552 sig & 312073 ttH bkg & 99290 single-H bkg & 3699581 non-res bkg\n",
      "Num val: 1075374 -> 47777 sig & 78216 ttH bkg & 24542 single-H bkg & 924839 non-res bkg\n",
      "Num test: 1346469 -> 59494 sig & 97382 ttH bkg & 30919 single-H bkg & & 1158674 non-res bkg\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "bdt_train_dict, bdt_val_dict, bdt_test_dict = {}, {}, {}\n",
    "\n",
    "train_data_dict, val_data_dict = {}, {}\n",
    "xgb_label_train_dict, xgb_label_val_dict = {}, {}\n",
    "weights_plot_train, weights_plot_val= {}, {}\n",
    "train_idxs_dict, val_idxs_dict = {}, {}\n",
    "for fold_idx in range(len(data_df_dict)):\n",
    "    if re.search('no_std', VARS) is not None:\n",
    "        print('no standardization')\n",
    "        train_val_data_dict = {key: value.to_numpy() for key, value in data_df_dict.items()}\n",
    "        test_data_dict = {key: value.to_numpy() for key, value in data_test_df_dict.items()}\n",
    "    else:\n",
    "        train_val_data_dict = data_hlf_dict\n",
    "        test_data_dict = data_hlf_test_dict\n",
    "    (\n",
    "        X_train, X_val, \n",
    "        y_train, y_val, \n",
    "        weight_train, weight_val, \n",
    "        weight_plot_train, weight_plot_val,\n",
    "        train_idxs, val_idxs\n",
    "    ) = train_test_split(\n",
    "        train_val_data_dict[f\"fold_{fold_idx}\"], xgb_label_dict[f\"fold_{fold_idx}\"], \n",
    "        weight_train_dict[f\"fold_{fold_idx}\"], weights_plot_train_dict[f\"fold_{fold_idx}\"],\n",
    "        range(len(train_val_data_dict[f\"fold_{fold_idx}\"])),\n",
    "        test_size=0.2, random_state=21\n",
    "    )\n",
    "\n",
    "    train_data_dict[f\"fold_{fold_idx}\"] = copy.deepcopy(X_train)\n",
    "    val_data_dict[f\"fold_{fold_idx}\"] = copy.deepcopy(X_val)\n",
    "\n",
    "    xgb_label_train_dict[f\"fold_{fold_idx}\"] = copy.deepcopy(y_train)\n",
    "    xgb_label_val_dict[f\"fold_{fold_idx}\"] = copy.deepcopy(y_val)\n",
    "\n",
    "    weights_plot_train[f\"fold_{fold_idx}\"] = copy.deepcopy(weight_plot_train)\n",
    "    weights_plot_val[f\"fold_{fold_idx}\"] = copy.deepcopy(weight_plot_val)\n",
    "\n",
    "    train_idxs_dict[f\"fold_{fold_idx}\"] = copy.deepcopy(train_idxs)\n",
    "    val_idxs_dict[f\"fold_{fold_idx}\"] = copy.deepcopy(val_idxs)\n",
    "\n",
    "    bdt_train_dict[f\"fold_{fold_idx}\"] = xgb.DMatrix(\n",
    "        data=X_train, label=y_train, \n",
    "        weight=weight_train,\n",
    "        missing=-999.0, feature_names=list(hlf_vars_columns_dict[f\"fold_{fold_idx}\"])\n",
    "    )\n",
    "    bdt_val_dict[f\"fold_{fold_idx}\"] = xgb.DMatrix(\n",
    "        data=X_val, label=y_val, \n",
    "        weight=weight_val,\n",
    "        missing=-999.0, feature_names=list(hlf_vars_columns_dict[f\"fold_{fold_idx}\"])\n",
    "    )\n",
    "    \n",
    "    bdt_test_dict[f\"fold_{fold_idx}\"] = xgb.DMatrix(\n",
    "        data=test_data_dict[f\"fold_{fold_idx}\"], label=xgb_label_test_dict[f\"fold_{fold_idx}\"], \n",
    "        weight=np.abs(weight_test_dict[f\"fold_{fold_idx}\"]),\n",
    "        missing=-999.0, feature_names=list(hlf_vars_columns_dict[f\"fold_{fold_idx}\"])\n",
    "    )\n",
    "\n",
    "    print(f\"fold {fold_idx}\")\n",
    "    print(f\"Num train: {len(y_train)} -> {sum(y_train == 0)} sig & {sum(y_train == 1)} ttH bkg & {sum(y_train == 2)} single-H bkg & {sum(y_train == 3)} non-res bkg\")\n",
    "    print(f\"Num val: {len(y_val)} -> {sum(y_val == 0)} sig & {sum(y_val == 1)} ttH bkg & {sum(y_val == 2)} single-H bkg & {sum(y_val == 3)} non-res bkg\")\n",
    "    print(f\"Num test: {len(label_test_dict[f'fold_{fold_idx}'])} -> {sum(label_test_dict[f'fold_{fold_idx}'] == np.array([1, 0, 0, 0]))[0]} sig & {sum(label_test_dict[f'fold_{fold_idx}'] == np.array([0, 1, 0, 0]))[1]} ttH bkg & {sum(label_test_dict[f'fold_{fold_idx}'] == np.array([0, 0, 1, 0]))[2]} single-H bkg & & {sum(label_test_dict[f'fold_{fold_idx}'] == np.array([0, 0, 0, 1]))[3]} non-res bkg\")\n",
    "    print('='*60)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Parameterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/57986259/multiclass-classification-with-xgboost-classifier\n",
    "# https://forecastegy.com/posts/xgboost-multiclass-classification-python/\n",
    "# https://indico.cern.ch/event/915265/contributions/3848138/attachments/2048174/3432202/kunlinRan_bbyy_20200531.pdf\n",
    "\n",
    "# https://xgboost.readthedocs.io/en/stable/tutorials/intercept.html - for looking at logits level BDT output\n",
    "# https://indico.cern.ch/event/915265/contributions/3848138/attachments/2048174/3432202/kunlinRan_bbyy_20200531.pdf - ATLAS HHbbgg BDT\n",
    "\n",
    "param = {}\n",
    "\n",
    "# Booster parameters #\n",
    "\n",
    "# v11 #\n",
    "# param['eta']              = 0.05 # learning rate\n",
    "# num_trees = round(25 / param['eta'])  # number of trees to make\n",
    "# param['max_depth']        = 10  # maximum depth of a tree\n",
    "# param['subsample']        = 0.6 # fraction of events to train tree on\n",
    "# param['colsample_bytree'] = 0.6 # fraction of features to train tree on\n",
    "# param['num_class']        = len(order) # num classes for multi-class training\n",
    "\n",
    "# v12 #\n",
    "param['eta']              = 0.05 # learning rate\n",
    "num_trees = round(25 / param['eta'])  # number of trees to make\n",
    "param['max_depth']        = 10  # maximum depth of a tree\n",
    "param['subsample']        = 0.2 # fraction of events to train tree on\n",
    "param['colsample_bytree'] = 0.6 # fraction of features to train tree on\n",
    "param['num_class']        = len(order) # num classes for multi-class training\n",
    "param['device']           = 'cuda'\n",
    "param['tree_method']      = 'gpu_hist'\n",
    "param['max_bin']          = 512\n",
    "param['grow_policy']      = 'lossguide'\n",
    "param['sampling_method']  = 'gradient_based'\n",
    "param['min_child_weight'] = 0.25\n",
    "\n",
    "\n",
    "# Learning task parameters\n",
    "param['objective']   = 'multi:softprob'   # objective function\n",
    "param['eval_metric'] = 'merror'\n",
    "param = list(param.items()) + [('eval_metric', 'mlogloss')]  # evaluation metric for cross validation\n",
    "\n",
    "# custom eval_metrics\n",
    "def one_hot_encoding(cat_labels: np.ndarray):\n",
    "    one_hot = np.zeros((np.shape(cat_labels)[0], np.max(cat_labels)+1))\n",
    "    for i in range(np.max(cat_labels)):\n",
    "        one_hot[:, i] = (cat_labels == i)\n",
    "    return one_hot\n",
    "\n",
    "def mlogloss_binlogloss(\n",
    "    predt: np.ndarray, dtrain: xgb.DMatrix, mLL=True, **kwargs\n",
    "):\n",
    "    assert (len(kwargs) == 0 and mLL) or len(kwargs) == (len(order) - 1)\n",
    "\n",
    "    mweight = dtrain.get_weight()\n",
    "    monehot = one_hot_encoding(dtrain.get_label())\n",
    "    mlogloss = log_loss(monehot, predt, sample_weight=mweight, normalize=False)\n",
    "\n",
    "    bkgloglosses = {}\n",
    "    for i, (key, value) in enumerate(kwargs.items(), start=1):\n",
    "        bkgbool = np.logical_or(mweight == 0, mweight == i)\n",
    "        bkgloglosses[key] = value * log_loss(\n",
    "            monehot[bkgbool], predt[bkgbool, 0] / (predt[bkgbool, 0] + predt[bkgbool, i]),\n",
    "            sample_weight=mweight[bkgbool], normalize=False\n",
    "        )\n",
    "\n",
    "    if len(bkgloglosses) > 0 and mLL:\n",
    "        return f'mLL+binLL@{bkgloglosses.keys()}', float(np.sum([mlogloss]+list(bkgloglosses.values())))\n",
    "    elif len(bkgloglosses) > 0:\n",
    "        return f'binLL@{bkgloglosses.keys()}', float(np.sum(bkgloglosses.values()))\n",
    "    else:\n",
    "        return 'mLL', float(mlogloss)\n",
    "\n",
    "def thresholded_weighted_merror(predt: np.ndarray, dtrain: xgb.DMatrix, threshold=0.95):\n",
    "    \"\"\"Used when there's no custom objective.\"\"\"\n",
    "    # No need to do transform, XGBoost handles it internally.\n",
    "    weights = dtrain.get_weight()\n",
    "    thresh_weight_merror = np.where(\n",
    "        np.logical_and(\n",
    "            np.max(predt, axis=1) >= threshold,\n",
    "            np.argmax(predt, axis=1) == dtrain.get_label()\n",
    "        ),\n",
    "        0,\n",
    "        weights\n",
    "    )\n",
    "    return f'WeightedMError@{threshold:.2f}', np.sum(thresh_weight_merror)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def init_param_dict(static_params_dict):\n",
    "    param = {}\n",
    "    # Booster parameters\n",
    "    param['eta']              = 0.1 # learning rate\n",
    "    param['subsample']        = 0.5 # fraction of events to train tree on\n",
    "    param['colsample_bytree'] = 0.8 # fraction of features to train tree on\n",
    "    param['num_class']        = len(order) # num classes for multi-class training\n",
    "    param['min_child_weight'] = 0.25\n",
    "    param['tree_method']      = 'hist'\n",
    "    param['max_bin']          = 512\n",
    "    param['grow_policy']      = 'lossguide'\n",
    "    # Learning task parameters\n",
    "    param['objective']   = 'multi:softprob'   # objective function\n",
    "    param['eval_metric'] = 'mlogloss'         # evaluation metric for cross validation\n",
    "\n",
    "    if static_params_dict is not None:\n",
    "        for key, value in static_params_dict.items():\n",
    "            param[key] = value\n",
    "\n",
    "    return param, round(25 / param['eta'])  # number of trees to make\n",
    "\n",
    "def optimize_hyperparams(\n",
    "    dtrain_dict: dict, dval_dict: dict, param_filepath: str, verbose: bool=False, verbose_eval: bool=False, start_point: int=0,\n",
    "    static_params_dict: dict=None\n",
    "):\n",
    "    # order and grouping of optimization taken from: \n",
    "    #   https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/#:~:text=min_child_weight%20%3D%201%3A%20A%20smaller%20value,%2C%20anyways%2C%20be%20tuned%20later.\n",
    "    rng = np.random.default_rng()\n",
    "    param, num_trees = init_param_dict(static_params_dict)\n",
    "    print(\"Baseline parameters: {}\".format(param))\n",
    "\n",
    "    score_arrs = {\n",
    "        'max_depth_and_min_child_weight': list(),\n",
    "        'min_split_loss': list(),\n",
    "        'subsample_and_colsample_bytree': list(),\n",
    "        'reg_lambda': list(),\n",
    "        'eta': list()\n",
    "    }\n",
    "\n",
    "## max_depth and min_child_weight ##\n",
    "    max_depth_range = (2, 6)\n",
    "    min_child_weight_range = (0.01, 2.)\n",
    "    max_depth_and_min_child_weight_space  = [\n",
    "        Integer(max_depth_range[0], max_depth_range[1], \"uniform\", name='max_depth'),\n",
    "        Real(min_child_weight_range[0], min_child_weight_range[1], \"log-uniform\", name='min_child_weight'),\n",
    "    ]\n",
    "    if 'max_depth' in static_params_dict.keys() and 'min_child_weight' in static_params_dict.keys():\n",
    "        max_depth_and_min_child_weight_space = []\n",
    "    elif 'max_depth' in static_params_dict.keys():\n",
    "        max_depth_and_min_child_weight_space  = [\n",
    "            Real(min_child_weight_range[0], min_child_weight_range[1], \"log-uniform\", name='min_child_weight'),\n",
    "        ]\n",
    "    elif 'min_child_weight' in static_params_dict.keys():\n",
    "        max_depth_and_min_child_weight_space  = [\n",
    "            Integer(max_depth_range[0], max_depth_range[1], \"uniform\", name='max_depth'),\n",
    "        ]\n",
    "    @use_named_args(max_depth_and_min_child_weight_space)\n",
    "    def max_depth_and_min_child_weight_objective(**X):\n",
    "        if verbose:\n",
    "            print(\"New configuration: {}\".format(X))\n",
    "\n",
    "        for key, val in X.items():\n",
    "            param[key] = val\n",
    "\n",
    "        # randomly sample a fold to evaluate\n",
    "        fold_idx = rng.integers(0, 4)\n",
    "\n",
    "        evallist = [(dtrain_dict[f\"fold_{fold_idx}\"], 'train'), (dval_dict[f\"fold_{fold_idx}\"], 'val')]\n",
    "        booster = xgb.train(\n",
    "            param, dtrain_dict[f\"fold_{fold_idx}\"], num_boost_round=num_trees, \n",
    "            evals=evallist, early_stopping_rounds=10, verbose_eval=verbose_eval,\n",
    "        )\n",
    "\n",
    "        eval_str = booster.eval(dval_dict[f\"fold_{fold_idx}\"], name='val', iteration=booster.best_iteration)\n",
    "\n",
    "        best_mlogloss = float(eval_str[eval_str.find('val-mlogloss:')+len('val-mlogloss:'):])\n",
    "        score_arrs['max_depth_and_min_child_weight'].append(best_mlogloss)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Best val. mlogloss on fold{fold_idx} = {best_mlogloss}\")\n",
    "\n",
    "        return -best_mlogloss\n",
    "    \n",
    "    if start_point == 0 and len(max_depth_and_min_child_weight_space) > 0:\n",
    "        print(\"Optimizing max_depth (max depth of tree) and min_child_weight (min sum of weights in final nodes)\")\n",
    "        result_max_depth_and_min_child_weight = gp_minimize(\n",
    "            max_depth_and_min_child_weight_objective, max_depth_and_min_child_weight_space,\n",
    "            n_calls=10, n_points=1\n",
    "        )\n",
    "\n",
    "        if len(max_depth_and_min_child_weight_space) == 2:\n",
    "            param['max_depth'] = int(result_max_depth_and_min_child_weight.x[0])\n",
    "            param['min_child_weight'] = float(result_max_depth_and_min_child_weight.x[1])\n",
    "        elif 'max_depth' not in static_params_dict.keys():\n",
    "            param['max_depth'] = int(result_max_depth_and_min_child_weight.x[0])\n",
    "        elif 'min_child_weight' not in static_params_dict.keys():\n",
    "            param['min_child_weight'] = int(result_max_depth_and_min_child_weight.x[0])\n",
    "\n",
    "        print(f\"Best max_depth = {param['max_depth']} and min_child_weight = {param['min_child_weight']}\")\n",
    "\n",
    "        with open(param_filepath, 'w') as f:\n",
    "            json.dump(param, f)\n",
    "\n",
    "## min_split_loss ##\n",
    "    min_split_loss_range = (0., 0.5)\n",
    "    min_split_loss_space  = [\n",
    "        Real(min_split_loss_range[0], min_split_loss_range[1], \"uniform\", name='min_split_loss'),\n",
    "    ]\n",
    "    @use_named_args(min_split_loss_space)\n",
    "    def min_split_loss_objective(**X):\n",
    "        if verbose:\n",
    "            print(\"New configuration: {}\".format(X))\n",
    "\n",
    "        for key, val in X.items():\n",
    "            param[key] = val\n",
    "\n",
    "        # randomly sample a fold to evaluate\n",
    "        fold_idx = rng.integers(0, 4)\n",
    "\n",
    "        evallist = [(dtrain_dict[f\"fold_{fold_idx}\"], 'train'), (dval_dict[f\"fold_{fold_idx}\"], 'val')]\n",
    "        booster = xgb.train(\n",
    "            param, dtrain_dict[f\"fold_{fold_idx}\"], num_boost_round=num_trees, \n",
    "            evals=evallist, early_stopping_rounds=10, verbose_eval=verbose_eval,\n",
    "        )\n",
    "\n",
    "        eval_str = booster.eval(dval_dict[f\"fold_{fold_idx}\"], name='val', iteration=booster.best_iteration)\n",
    "\n",
    "        best_mlogloss = float(eval_str[eval_str.find('val-mlogloss:')+len('val-mlogloss:'):])\n",
    "        score_arrs['min_split_loss'].append(best_mlogloss)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Best val. mlogloss on fold{fold_idx} = {best_mlogloss}\")\n",
    "\n",
    "        return -best_mlogloss\n",
    "\n",
    "    if start_point <= 1 and 'min_split_loss' not in static_params_dict.keys():\n",
    "        if start_point > 0:\n",
    "            with open(param_filepath, 'r') as f:\n",
    "                param = json.load(f)\n",
    "            \n",
    "        print(\"Optimizing min_split_loss (min loss change to add leaf)\")\n",
    "        result_min_split_loss = gp_minimize(min_split_loss_objective, min_split_loss_space)\n",
    "        param['min_split_loss'] = float(result_min_split_loss.x[0])\n",
    "        print(f\"Best min_split_loss = {param['min_split_loss']}\")\n",
    "\n",
    "        with open(param_filepath, 'w') as f:\n",
    "            json.dump(param, f)\n",
    "\n",
    "## subsample and colsample_by_tree ##\n",
    "    subsample_range = (0.3, 0.6)\n",
    "    colsample_by_tree_range = (0.3, 0.9)\n",
    "    subsample_and_colsample_bytree_space  = [\n",
    "        Real(subsample_range[0], subsample_range[1], \"log-uniform\", name='subsample'),\n",
    "        Real(colsample_by_tree_range[0], colsample_by_tree_range[1], \"uniform\", name='colsample_bytree'),\n",
    "    ]\n",
    "    @use_named_args(subsample_and_colsample_bytree_space)\n",
    "    def subsample_and_colsample_bytree_objective(**X):\n",
    "        if verbose:\n",
    "            print(\"New configuration: {}\".format(X))\n",
    "\n",
    "        for key, val in X.items():\n",
    "            param[key] = val\n",
    "\n",
    "        # randomly sample a fold to evaluate\n",
    "        fold_idx = rng.integers(0, 4)\n",
    "\n",
    "        evallist = [(dtrain_dict[f\"fold_{fold_idx}\"], 'train'), (dval_dict[f\"fold_{fold_idx}\"], 'val')]\n",
    "        booster = xgb.train(\n",
    "            param, dtrain_dict[f\"fold_{fold_idx}\"], num_boost_round=num_trees, \n",
    "            evals=evallist, early_stopping_rounds=10, verbose_eval=verbose_eval,\n",
    "        )\n",
    "\n",
    "        eval_str = booster.eval(dval_dict[f\"fold_{fold_idx}\"], name='val', iteration=booster.best_iteration)\n",
    "\n",
    "        best_mlogloss = float(eval_str[eval_str.find('val-mlogloss:')+len('val-mlogloss:'):])\n",
    "        score_arrs['subsample_and_colsample_bytree'].append(best_mlogloss)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Best val. mlogloss on fold{fold_idx} = {best_mlogloss}\")\n",
    "\n",
    "        return -best_mlogloss\n",
    "\n",
    "    if start_point <= 2:\n",
    "        if start_point > 0:\n",
    "            with open(param_filepath, 'r') as f:\n",
    "                param = json.load(f)\n",
    "                \n",
    "        print(\"Optimizing subsample (fraction of training events) and colsample_bytree (fraction of training features per tree)\")\n",
    "        result_subsample_and_colsample_bytree = gp_minimize(subsample_and_colsample_bytree_objective, subsample_and_colsample_bytree_space)\n",
    "        param['subsample'] = float(result_subsample_and_colsample_bytree.x[0])\n",
    "        param['colsample_bytree'] = float(result_subsample_and_colsample_bytree.x[1])\n",
    "        print(f\"Best subsample = {param['subsample']} and colsample_bytree = {param['colsample_bytree']}\")\n",
    "\n",
    "        with open(param_filepath, 'w') as f:\n",
    "            json.dump(param, f)\n",
    "        \n",
    "\n",
    "## reg_lambda ##\n",
    "    lambda_range = (0.001, 0.1)\n",
    "    reg_lambda_space  = [\n",
    "        Real(lambda_range[0], lambda_range[1], \"log-uniform\", name='reg_lambda'),\n",
    "    ]\n",
    "    @use_named_args(reg_lambda_space)\n",
    "    def reg_lambda_objective(**X):\n",
    "        if verbose:\n",
    "            print(\"New configuration: {}\".format(X))\n",
    "\n",
    "        for key, val in X.items():\n",
    "            param[key] = val\n",
    "\n",
    "        # randomly sample a fold to evaluate\n",
    "        fold_idx = rng.integers(0, 4)\n",
    "\n",
    "        evallist = [(dtrain_dict[f\"fold_{fold_idx}\"], 'train'), (dval_dict[f\"fold_{fold_idx}\"], 'val')]\n",
    "        booster = xgb.train(\n",
    "            param, dtrain_dict[f\"fold_{fold_idx}\"], num_boost_round=num_trees, \n",
    "            evals=evallist, early_stopping_rounds=10, verbose_eval=verbose_eval,\n",
    "        )\n",
    "\n",
    "        eval_str = booster.eval(dval_dict[f\"fold_{fold_idx}\"], name='val', iteration=booster.best_iteration)\n",
    "\n",
    "        best_mlogloss = float(eval_str[eval_str.find('val-mlogloss:')+len('val-mlogloss:'):])\n",
    "        score_arrs['reg_lambda'].append(best_mlogloss)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Best val. mlogloss on fold{fold_idx} = {best_mlogloss}\")\n",
    "\n",
    "        return -best_mlogloss\n",
    "\n",
    "    if start_point <= 3:\n",
    "        if start_point > 0:\n",
    "            with open(param_filepath, 'r') as f:\n",
    "                param = json.load(f)\n",
    "\n",
    "        print(\"Optimizing reg_lambda (L2 reg)\")\n",
    "        result_reg_lambda = gp_minimize(reg_lambda_objective, reg_lambda_space)\n",
    "        param['reg_lambda'] = float(result_reg_lambda.x[0])\n",
    "        print(f\"Best reg_lambda = {param['reg_lambda']}\")\n",
    "\n",
    "        with open(param_filepath, 'w') as f:\n",
    "            json.dump(param, f)\n",
    "\n",
    "## eta ##\n",
    "    eta_range = (0.01, 0.3)\n",
    "    eta_space  = [\n",
    "        Real(eta_range[0], eta_range[1], \"log-uniform\", name='eta'),\n",
    "    ]\n",
    "    @use_named_args(eta_space)\n",
    "    def eta_objective(**X):\n",
    "        if verbose:\n",
    "            print(\"New configuration: {}\".format(X))\n",
    "\n",
    "        for key, val in X.items():\n",
    "            param[key] = val\n",
    "        num_trees = round(25 / X['eta'])  # number of trees to make\n",
    "\n",
    "        # randomly sample a fold to evaluate\n",
    "        fold_idx = rng.integers(0, 4)\n",
    "\n",
    "        evallist = [(dtrain_dict[f\"fold_{fold_idx}\"], 'train'), (dval_dict[f\"fold_{fold_idx}\"], 'val')]\n",
    "        booster = xgb.train(\n",
    "            param, dtrain_dict[f\"fold_{fold_idx}\"], num_boost_round=num_trees, \n",
    "            evals=evallist, early_stopping_rounds=10, verbose_eval=verbose_eval,\n",
    "        )\n",
    "\n",
    "        eval_str = booster.eval(dval_dict[f\"fold_{fold_idx}\"], name='val', iteration=booster.best_iteration)\n",
    "\n",
    "        best_mlogloss = float(eval_str[eval_str.find('val-mlogloss:')+len('val-mlogloss:'):])\n",
    "        score_arrs['eta'].append(best_mlogloss)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Best val. mlogloss on fold{fold_idx} = {best_mlogloss}\")\n",
    "\n",
    "        return -best_mlogloss\n",
    "\n",
    "    if start_point <= 4:\n",
    "        if start_point > 0:\n",
    "            with open(param_filepath, 'r') as f:\n",
    "                param = json.load(f)\n",
    "                \n",
    "        print(\"Optimizing eta (step size)\")\n",
    "        result_eta = gp_minimize(eta_objective, eta_space)\n",
    "        param['eta'] = float(result_eta.x[0])\n",
    "        print(f\"Best eta = {param['eta']}\")\n",
    "\n",
    "        with open(param_filepath, 'w') as f:\n",
    "            json.dump(param, f)\n",
    "\n",
    "    print(\"Best parameters: {}\".format(param))\n",
    "    \n",
    "    return param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "[13:43:25] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-merror:0.10020\ttrain-mlogloss:1.31020\ttest-merror:0.11036\ttest-mlogloss:1.31104\tval-merror:0.11012\tval-mlogloss:1.31114\n",
      "[25]\ttrain-merror:0.08498\ttrain-mlogloss:0.53340\ttest-merror:0.09633\ttest-mlogloss:0.54805\tval-merror:0.09565\tval-mlogloss:0.54855\n",
      "[50]\ttrain-merror:0.08105\ttrain-mlogloss:0.33586\ttest-merror:0.09442\ttest-mlogloss:0.35956\tval-merror:0.09378\tval-mlogloss:0.36046\n",
      "[75]\ttrain-merror:0.07724\ttrain-mlogloss:0.27204\ttest-merror:0.09277\ttest-mlogloss:0.30456\tval-merror:0.09206\tval-mlogloss:0.30533\n",
      "[100]\ttrain-merror:0.07381\ttrain-mlogloss:0.24327\ttest-merror:0.09148\ttest-mlogloss:0.28431\tval-merror:0.09101\tval-mlogloss:0.28479\n",
      "[125]\ttrain-merror:0.07087\ttrain-mlogloss:0.22785\ttest-merror:0.09125\ttest-mlogloss:0.27664\tval-merror:0.09045\tval-mlogloss:0.27685\n",
      "[150]\ttrain-merror:0.06809\ttrain-mlogloss:0.21690\ttest-merror:0.09094\ttest-mlogloss:0.27270\tval-merror:0.08986\tval-mlogloss:0.27285\n",
      "[175]\ttrain-merror:0.06578\ttrain-mlogloss:0.20853\ttest-merror:0.09033\ttest-mlogloss:0.27044\tval-merror:0.08956\tval-mlogloss:0.27057\n",
      "[200]\ttrain-merror:0.06377\ttrain-mlogloss:0.20196\ttest-merror:0.08983\ttest-mlogloss:0.26874\tval-merror:0.08941\tval-mlogloss:0.26902\n",
      "[225]\ttrain-merror:0.06180\ttrain-mlogloss:0.19611\ttest-merror:0.08972\ttest-mlogloss:0.26761\tval-merror:0.08908\tval-mlogloss:0.26787\n",
      "[250]\ttrain-merror:0.05979\ttrain-mlogloss:0.19063\ttest-merror:0.08969\ttest-mlogloss:0.26693\tval-merror:0.08896\tval-mlogloss:0.26718\n",
      "[275]\ttrain-merror:0.05809\ttrain-mlogloss:0.18609\ttest-merror:0.08987\ttest-mlogloss:0.26657\tval-merror:0.08890\tval-mlogloss:0.26682\n",
      "[300]\ttrain-merror:0.05648\ttrain-mlogloss:0.18144\ttest-merror:0.08972\ttest-mlogloss:0.26644\tval-merror:0.08885\tval-mlogloss:0.26669\n",
      "[304]\ttrain-merror:0.05626\ttrain-mlogloss:0.18081\ttest-merror:0.08966\ttest-mlogloss:0.26644\tval-merror:0.08886\tval-mlogloss:0.26671\n",
      "[295]\ttest-merror:0.089698\ttest-mlogloss:0.266433\n",
      "====================================================================================================\n",
      "fold 1\n",
      "[13:46:55] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-merror:0.10061\ttrain-mlogloss:1.31016\ttest-merror:0.11056\ttest-mlogloss:1.31103\tval-merror:0.10985\tval-mlogloss:1.31099\n",
      "[25]\ttrain-merror:0.08494\ttrain-mlogloss:0.53323\ttest-merror:0.09598\ttest-mlogloss:0.54739\tval-merror:0.09585\tval-mlogloss:0.54839\n",
      "[50]\ttrain-merror:0.08098\ttrain-mlogloss:0.33582\ttest-merror:0.09393\ttest-mlogloss:0.35914\tval-merror:0.09338\tval-mlogloss:0.36012\n",
      "[75]\ttrain-merror:0.07717\ttrain-mlogloss:0.27182\ttest-merror:0.09240\ttest-mlogloss:0.30410\tval-merror:0.09229\tval-mlogloss:0.30497\n",
      "[100]\ttrain-merror:0.07388\ttrain-mlogloss:0.24312\ttest-merror:0.09122\ttest-mlogloss:0.28379\tval-merror:0.09121\tval-mlogloss:0.28470\n",
      "[125]\ttrain-merror:0.07098\ttrain-mlogloss:0.22762\ttest-merror:0.09079\ttest-mlogloss:0.27575\tval-merror:0.09090\tval-mlogloss:0.27676\n",
      "[150]\ttrain-merror:0.06801\ttrain-mlogloss:0.21642\ttest-merror:0.09043\ttest-mlogloss:0.27171\tval-merror:0.09034\tval-mlogloss:0.27286\n",
      "[175]\ttrain-merror:0.06566\ttrain-mlogloss:0.20836\ttest-merror:0.09013\ttest-mlogloss:0.26932\tval-merror:0.09017\tval-mlogloss:0.27066\n",
      "[200]\ttrain-merror:0.06370\ttrain-mlogloss:0.20186\ttest-merror:0.08970\ttest-mlogloss:0.26765\tval-merror:0.08998\tval-mlogloss:0.26900\n",
      "[225]\ttrain-merror:0.06195\ttrain-mlogloss:0.19631\ttest-merror:0.08934\ttest-mlogloss:0.26653\tval-merror:0.08961\tval-mlogloss:0.26792\n",
      "[250]\ttrain-merror:0.05966\ttrain-mlogloss:0.19038\ttest-merror:0.08931\ttest-mlogloss:0.26567\tval-merror:0.08950\tval-mlogloss:0.26694\n",
      "[275]\ttrain-merror:0.05817\ttrain-mlogloss:0.18607\ttest-merror:0.08923\ttest-mlogloss:0.26537\tval-merror:0.08970\tval-mlogloss:0.26671\n",
      "[300]\ttrain-merror:0.05651\ttrain-mlogloss:0.18158\ttest-merror:0.08894\ttest-mlogloss:0.26506\tval-merror:0.08973\tval-mlogloss:0.26646\n",
      "[325]\ttrain-merror:0.05454\ttrain-mlogloss:0.17677\ttest-merror:0.08893\ttest-mlogloss:0.26486\tval-merror:0.08982\tval-mlogloss:0.26635\n",
      "[336]\ttrain-merror:0.05364\ttrain-mlogloss:0.17469\ttest-merror:0.08887\ttest-mlogloss:0.26480\tval-merror:0.08995\tval-mlogloss:0.26634\n",
      "[326]\ttest-merror:0.088868\ttest-mlogloss:0.264802\n",
      "====================================================================================================\n",
      "fold 2\n",
      "[13:50:45] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-merror:0.10010\ttrain-mlogloss:1.31012\ttest-merror:0.11069\ttest-mlogloss:1.31104\tval-merror:0.11119\tval-mlogloss:1.31113\n",
      "[25]\ttrain-merror:0.08463\ttrain-mlogloss:0.53238\ttest-merror:0.09589\ttest-mlogloss:0.54821\tval-merror:0.09629\tval-mlogloss:0.54891\n",
      "[50]\ttrain-merror:0.08080\ttrain-mlogloss:0.33496\ttest-merror:0.09398\ttest-mlogloss:0.36024\tval-merror:0.09459\tval-mlogloss:0.36105\n",
      "[75]\ttrain-merror:0.07708\ttrain-mlogloss:0.27124\ttest-merror:0.09251\ttest-mlogloss:0.30539\tval-merror:0.09299\tval-mlogloss:0.30610\n",
      "[100]\ttrain-merror:0.07362\ttrain-mlogloss:0.24249\ttest-merror:0.09106\ttest-mlogloss:0.28496\tval-merror:0.09210\tval-mlogloss:0.28564\n",
      "[125]\ttrain-merror:0.07061\ttrain-mlogloss:0.22703\ttest-merror:0.09054\ttest-mlogloss:0.27695\tval-merror:0.09138\tval-mlogloss:0.27743\n",
      "[150]\ttrain-merror:0.06787\ttrain-mlogloss:0.21609\ttest-merror:0.09008\ttest-mlogloss:0.27292\tval-merror:0.09072\tval-mlogloss:0.27323\n",
      "[175]\ttrain-merror:0.06548\ttrain-mlogloss:0.20786\ttest-merror:0.08932\ttest-mlogloss:0.27069\tval-merror:0.09024\tval-mlogloss:0.27101\n",
      "[200]\ttrain-merror:0.06331\ttrain-mlogloss:0.20092\ttest-merror:0.08931\ttest-mlogloss:0.26907\tval-merror:0.08972\tval-mlogloss:0.26926\n",
      "[225]\ttrain-merror:0.06134\ttrain-mlogloss:0.19492\ttest-merror:0.08933\ttest-mlogloss:0.26794\tval-merror:0.08923\tval-mlogloss:0.26803\n",
      "[250]\ttrain-merror:0.05958\ttrain-mlogloss:0.18982\ttest-merror:0.08929\ttest-mlogloss:0.26731\tval-merror:0.08929\tval-mlogloss:0.26722\n",
      "[275]\ttrain-merror:0.05794\ttrain-mlogloss:0.18530\ttest-merror:0.08909\ttest-mlogloss:0.26702\tval-merror:0.08923\tval-mlogloss:0.26686\n",
      "[300]\ttrain-merror:0.05602\ttrain-mlogloss:0.18052\ttest-merror:0.08917\ttest-mlogloss:0.26681\tval-merror:0.08921\tval-mlogloss:0.26658\n",
      "[317]\ttrain-merror:0.05485\ttrain-mlogloss:0.17776\ttest-merror:0.08921\ttest-mlogloss:0.26679\tval-merror:0.08915\tval-mlogloss:0.26660\n",
      "[308]\ttest-merror:0.089200\ttest-mlogloss:0.266795\n",
      "====================================================================================================\n",
      "fold 3\n",
      "[13:54:22] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-merror:0.10006\ttrain-mlogloss:1.31019\ttest-merror:0.11027\ttest-mlogloss:1.31115\tval-merror:0.10889\tval-mlogloss:1.31094\n",
      "[25]\ttrain-merror:0.08513\ttrain-mlogloss:0.53317\ttest-merror:0.09599\ttest-mlogloss:0.54862\tval-merror:0.09403\tval-mlogloss:0.54664\n",
      "[50]\ttrain-merror:0.08148\ttrain-mlogloss:0.33589\ttest-merror:0.09437\ttest-mlogloss:0.36110\tval-merror:0.09231\tval-mlogloss:0.35790\n",
      "[75]\ttrain-merror:0.07757\ttrain-mlogloss:0.27224\ttest-merror:0.09353\ttest-mlogloss:0.30653\tval-merror:0.09117\tval-mlogloss:0.30278\n",
      "[100]\ttrain-merror:0.07415\ttrain-mlogloss:0.24352\ttest-merror:0.09200\ttest-mlogloss:0.28617\tval-merror:0.09037\tval-mlogloss:0.28234\n",
      "[125]\ttrain-merror:0.07124\ttrain-mlogloss:0.22833\ttest-merror:0.09173\ttest-mlogloss:0.27854\tval-merror:0.08964\tval-mlogloss:0.27468\n",
      "[150]\ttrain-merror:0.06843\ttrain-mlogloss:0.21733\ttest-merror:0.09131\ttest-mlogloss:0.27446\tval-merror:0.08947\tval-mlogloss:0.27064\n",
      "[175]\ttrain-merror:0.06600\ttrain-mlogloss:0.20901\ttest-merror:0.09056\ttest-mlogloss:0.27208\tval-merror:0.08896\tval-mlogloss:0.26828\n",
      "[200]\ttrain-merror:0.06397\ttrain-mlogloss:0.20260\ttest-merror:0.09012\ttest-mlogloss:0.27035\tval-merror:0.08870\tval-mlogloss:0.26657\n",
      "[225]\ttrain-merror:0.06194\ttrain-mlogloss:0.19681\ttest-merror:0.08952\ttest-mlogloss:0.26905\tval-merror:0.08822\tval-mlogloss:0.26525\n",
      "[250]\ttrain-merror:0.05990\ttrain-mlogloss:0.19123\ttest-merror:0.08958\ttest-mlogloss:0.26830\tval-merror:0.08804\tval-mlogloss:0.26450\n",
      "[275]\ttrain-merror:0.05823\ttrain-mlogloss:0.18655\ttest-merror:0.08971\ttest-mlogloss:0.26791\tval-merror:0.08808\tval-mlogloss:0.26415\n",
      "[300]\ttrain-merror:0.05638\ttrain-mlogloss:0.18193\ttest-merror:0.08955\ttest-mlogloss:0.26775\tval-merror:0.08801\tval-mlogloss:0.26394\n",
      "[325]\ttrain-merror:0.05454\ttrain-mlogloss:0.17722\ttest-merror:0.08950\ttest-mlogloss:0.26757\tval-merror:0.08800\tval-mlogloss:0.26370\n",
      "[350]\ttrain-merror:0.05287\ttrain-mlogloss:0.17296\ttest-merror:0.08972\ttest-mlogloss:0.26765\tval-merror:0.08796\tval-mlogloss:0.26369\n",
      "[353]\ttrain-merror:0.05272\ttrain-mlogloss:0.17252\ttest-merror:0.08963\ttest-mlogloss:0.26764\tval-merror:0.08810\tval-mlogloss:0.26369\n",
      "[343]\ttest-merror:0.089634\ttest-mlogloss:0.267641\n",
      "====================================================================================================\n",
      "fold 4\n",
      "[13:58:29] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-merror:0.10052\ttrain-mlogloss:1.31015\ttest-merror:0.11158\ttest-mlogloss:1.31112\tval-merror:0.11219\tval-mlogloss:1.31113\n",
      "[25]\ttrain-merror:0.08463\ttrain-mlogloss:0.53280\ttest-merror:0.09598\ttest-mlogloss:0.54846\tval-merror:0.09643\tval-mlogloss:0.54848\n",
      "[50]\ttrain-merror:0.08096\ttrain-mlogloss:0.33550\ttest-merror:0.09380\ttest-mlogloss:0.36040\tval-merror:0.09478\tval-mlogloss:0.36057\n",
      "[75]\ttrain-merror:0.07716\ttrain-mlogloss:0.27168\ttest-merror:0.09275\ttest-mlogloss:0.30545\tval-merror:0.09338\tval-mlogloss:0.30586\n",
      "[100]\ttrain-merror:0.07376\ttrain-mlogloss:0.24295\ttest-merror:0.09176\ttest-mlogloss:0.28500\tval-merror:0.09238\tval-mlogloss:0.28577\n",
      "[125]\ttrain-merror:0.07075\ttrain-mlogloss:0.22746\ttest-merror:0.09114\ttest-mlogloss:0.27712\tval-merror:0.09199\tval-mlogloss:0.27813\n",
      "[150]\ttrain-merror:0.06793\ttrain-mlogloss:0.21628\ttest-merror:0.09071\ttest-mlogloss:0.27299\tval-merror:0.09181\tval-mlogloss:0.27434\n",
      "[175]\ttrain-merror:0.06566\ttrain-mlogloss:0.20833\ttest-merror:0.09026\ttest-mlogloss:0.27070\tval-merror:0.09163\tval-mlogloss:0.27228\n",
      "[200]\ttrain-merror:0.06366\ttrain-mlogloss:0.20188\ttest-merror:0.09012\ttest-mlogloss:0.26898\tval-merror:0.09126\tval-mlogloss:0.27081\n",
      "[225]\ttrain-merror:0.06172\ttrain-mlogloss:0.19598\ttest-merror:0.09004\ttest-mlogloss:0.26775\tval-merror:0.09096\tval-mlogloss:0.26967\n",
      "[250]\ttrain-merror:0.05975\ttrain-mlogloss:0.19035\ttest-merror:0.08996\ttest-mlogloss:0.26692\tval-merror:0.09108\tval-mlogloss:0.26896\n",
      "[275]\ttrain-merror:0.05819\ttrain-mlogloss:0.18596\ttest-merror:0.08996\ttest-mlogloss:0.26657\tval-merror:0.09111\tval-mlogloss:0.26868\n",
      "[300]\ttrain-merror:0.05663\ttrain-mlogloss:0.18157\ttest-merror:0.08993\ttest-mlogloss:0.26630\tval-merror:0.09094\tval-mlogloss:0.26850\n",
      "[303]\ttrain-merror:0.05642\ttrain-mlogloss:0.18114\ttest-merror:0.08991\ttest-mlogloss:0.26630\tval-merror:0.09094\tval-mlogloss:0.26852\n",
      "[294]\ttest-merror:0.089961\ttest-mlogloss:0.266279\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "if 'CURRENT_TIME' in globals() and not (\n",
    "    len(glob.glob(OUTPUT_DIRPATH+'/*.model')) < MOD_VALS[0]\n",
    "    and not FORCE_RERUN\n",
    "):\n",
    "    OUTPUT_DIRPATH, OLD_TIME = os.path.split(OUTPUT_DIRPATH)\n",
    "fold_start = 0\n",
    "if 'CURRENT_TIME' not in globals() or not (\n",
    "    len(glob.glob(OUTPUT_DIRPATH+'/*.model')) < MOD_VALS[0]\n",
    "    and not FORCE_RERUN\n",
    "):\n",
    "    CURRENT_TIME = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "    OUTPUT_DIRPATH = os.path.join(OUTPUT_DIRPATH, CURRENT_TIME)\n",
    "    if not os.path.exists(OUTPUT_DIRPATH):\n",
    "        os.makedirs(OUTPUT_DIRPATH)\n",
    "else:\n",
    "    for model_file in glob.glob(OUTPUT_DIRPATH+'/*.model'):\n",
    "        print(f\"Finished model fold {model_file[-7]}\")\n",
    "        fold_start += 1\n",
    "    print(f\"Starting from fold {fold_start}\")\n",
    "\n",
    "if OPTIMIZE_SPACE:\n",
    "    print('OPTIMIZING SPACE')\n",
    "        \n",
    "    param_filepath = os.path.join(OUTPUT_DIRPATH, f'{CURRENT_TIME}_best_params.json')\n",
    "    param = optimize_hyperparams(\n",
    "        bdt_train_dict, bdt_val_dict, param_filepath, \n",
    "        start_point=3, static_params_dict={'min_child_weight': 0.2, 'max_depth': 4}\n",
    "    )\n",
    "\n",
    "    param['eval_metric'] = 'merror'\n",
    "    param = list(param.items()) + [('eval_metric', 'mlogloss')]\n",
    "# else:\n",
    "#     # with open('/uscms/home/tsievert/nobackup/XHYbbgg/HHtobbyy/MultiClassBDT_model_outputs/v10/v2_vars/2025-02-19_12-45-38/2025-02-19_12-45-38_best_params.json', 'r') as f:\n",
    "#     with open('/uscms/home/tsievert/nobackup/XHYbbgg/HHtobbyy/MultiClassBDT_model_outputs/v11/v2_vars/2025-03-04_15-04-16/2025-03-04_15-04-16_best_params.json', 'r') as f:\n",
    "#         param = json.load(f)\n",
    "#     param['eval_metric'] = 'merror'\n",
    "#     param = list(param.items()) + [('eval_metric', 'mlogloss')]\n",
    "\n",
    "evals_result_dict = {f\"fold_{fold_idx}\": dict() for fold_idx in range(len(bdt_train_dict))}\n",
    "for fold_idx in range(fold_start, len(bdt_train_dict)):\n",
    "    print(f\"fold {fold_idx}\")\n",
    "    # Train bdt\n",
    "    evallist = [(bdt_train_dict[f\"fold_{fold_idx}\"], 'train'), (bdt_test_dict[f\"fold_{fold_idx}\"], 'test'), (bdt_val_dict[f\"fold_{fold_idx}\"], 'val')]\n",
    "    booster = xgb.train(\n",
    "        param, bdt_train_dict[f\"fold_{fold_idx}\"], num_boost_round=num_trees, \n",
    "        evals=evallist, early_stopping_rounds=10, verbose_eval=25, evals_result=evals_result_dict[f\"fold_{fold_idx}\"],\n",
    "        # custom_metric=thresholded_weighted_merror\n",
    "    )\n",
    "\n",
    "    booster.save_model(os.path.join(OUTPUT_DIRPATH, f'{CURRENT_TIME}_BDT_fold{fold_idx}.model'))\n",
    "    \n",
    "    # Print perf on test dataset\n",
    "    print(booster.eval(bdt_test_dict[f\"fold_{fold_idx}\"], name='test', iteration=booster.best_iteration))\n",
    "    print('='*100)\n",
    "\n",
    "    with open(os.path.join(OUTPUT_DIRPATH, f'{CURRENT_TIME}_BDT_eval_result.json'), 'w') as f:\n",
    "        json.dump(evals_result_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance (ROC) Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:20:49] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:22:20] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:23:49] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:25:15] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:26:45] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:29:16] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:30:40] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:32:09] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:33:36] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:35:12] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:37:41] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:39:10] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:40:35] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:42:05] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:43:32] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:45:59] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:47:26] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:49:07] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:50:35] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:52:08] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_tpr = np.linspace(0, 1, 5000)  # copied from IN evaluate.py file\n",
    "roc_baseline = np.zeros(\n",
    "    (len(bdt_train_dict), len(base_tpr), len(order)), \n",
    "    dtype=float\n",
    ")\n",
    "area_baseline = np.zeros(\n",
    "    (len(bdt_train_dict), len(order)), \n",
    "    dtype=float\n",
    ")\n",
    "\n",
    "BDT_perf = {\n",
    "    sample_name: copy.deepcopy({\n",
    "        'base_tpr': base_tpr,\n",
    "        'class_order': copy.deepcopy(order),\n",
    "        # test data #\n",
    "        'preds': [],\n",
    "        'fprs_density': copy.deepcopy(roc_baseline), 'thresholds_density': copy.deepcopy(roc_baseline), 'areas_density': copy.deepcopy(area_baseline),\n",
    "        'fprs_weighted': copy.deepcopy(roc_baseline), 'thresholds_weighted': copy.deepcopy(roc_baseline), 'areas_weighted': copy.deepcopy(area_baseline),\n",
    "        'fprs_sum_density': copy.deepcopy(roc_baseline[0, ...]), 'thresholds_sum_density': copy.deepcopy(roc_baseline[0, ...]), 'areas_sum_density': copy.deepcopy(area_baseline[0, ...]),\n",
    "        'fprs_sum_weighted': copy.deepcopy(roc_baseline[0, ...]), 'thresholds_sum_weighted': copy.deepcopy(roc_baseline[0, ...]), 'areas_sum_weighted': copy.deepcopy(area_baseline[0, ...]),\n",
    "        # train data #\n",
    "        'train_preds': [], \n",
    "        'train_fprs_density': copy.deepcopy(roc_baseline), 'train_thresholds_density': copy.deepcopy(roc_baseline), 'train_areas_density': copy.deepcopy(area_baseline),\n",
    "        'train_fprs_weighted': copy.deepcopy(roc_baseline), 'train_thresholds_weighted': copy.deepcopy(roc_baseline), 'train_areas_weighted': copy.deepcopy(area_baseline),\n",
    "        'train_fprs_sum_density': copy.deepcopy(roc_baseline[0, ...]), 'train_thresholds_sum_density': copy.deepcopy(roc_baseline[0, ...]), 'train_areas_sum_density': copy.deepcopy(area_baseline[0, ...]),\n",
    "        'train_fprs_sum_weighted': copy.deepcopy(roc_baseline[0, ...]), 'train_thresholds_sum_weighted': copy.deepcopy(roc_baseline[0, ...]), 'train_areas_sum_weighted': copy.deepcopy(area_baseline[0, ...]),\n",
    "        # val data #\n",
    "        'val_preds': [],\n",
    "        'val_fprs_density': copy.deepcopy(roc_baseline), 'val_thresholds_density': copy.deepcopy(roc_baseline), 'val_areas_density': copy.deepcopy(area_baseline),\n",
    "        'val_fprs_weighted': copy.deepcopy(roc_baseline), 'val_thresholds_weighted': copy.deepcopy(roc_baseline), 'val_areas_weighted': copy.deepcopy(area_baseline),\n",
    "        'val_fprs_sum_density': copy.deepcopy(roc_baseline[0, ...]), 'val_thresholds_sum_density': copy.deepcopy(roc_baseline[0, ...]), 'val_areas_sum_density': copy.deepcopy(area_baseline[0, ...]),\n",
    "        'val_fprs_sum_weighted': copy.deepcopy(roc_baseline[0, ...]), 'val_thresholds_sum_weighted': copy.deepcopy(roc_baseline[0, ...]), 'val_areas_sum_weighted': copy.deepcopy(area_baseline[0, ...]),\n",
    "    }) for sample_name in order\n",
    "}\n",
    "\n",
    "for j, sample_name in enumerate(order):\n",
    "\n",
    "    for fold_idx in range(len(bdt_train_dict)):\n",
    "        booster = xgb.Booster(param)\n",
    "\n",
    "        try:\n",
    "            booster.load_model(os.path.join(OUTPUT_DIRPATH, f'{CURRENT_TIME}_BDT_fold{fold_idx}.model'))\n",
    "        except:\n",
    "            raise FileNotFoundError(f\"No model file at fold {fold_idx}.\")\n",
    "    \n",
    "        for pred_type, dataset in [\n",
    "            ('train_', bdt_train_dict[f\"fold_{fold_idx}\"]),\n",
    "            ('val_', bdt_val_dict[f\"fold_{fold_idx}\"]),\n",
    "            ('', bdt_test_dict[f\"fold_{fold_idx}\"])\n",
    "        ]:\n",
    "            \n",
    "            BDT_perf[sample_name][pred_type + 'preds'].append(\n",
    "                booster.predict(\n",
    "                    dataset, \n",
    "                    iteration_range=(0, booster.best_iteration+1)\n",
    "                ).tolist()\n",
    "            )\n",
    "\n",
    "            for i, sample_name_ in enumerate(order):\n",
    "                \n",
    "                if sample_name_ == sample_name:\n",
    "                    event_mask = dataset.get_label() > -1\n",
    "                    pred_rescale = np.ones_like(event_mask)\n",
    "                else:\n",
    "                    event_mask = np.logical_or(dataset.get_label() == j, dataset.get_label() == i)\n",
    "                    pred_rescale = np.array(BDT_perf[sample_name][pred_type + 'preds'][-1])[:, j][event_mask] + np.array(BDT_perf[sample_name][pred_type + 'preds'][-1])[:, i][event_mask]\n",
    "                class_preds = np.array(BDT_perf[sample_name][pred_type + 'preds'][-1])[:, j][event_mask] / pred_rescale\n",
    "                class_truths = np.where(dataset.get_label() == j, 1, 0)[event_mask]\n",
    "                \n",
    "                for roc_type in ['density', 'weighted']:\n",
    "\n",
    "                    if roc_type == 'weighted':\n",
    "                        if re.search('train', pred_type) is not None:\n",
    "                            roc_weights = weights_plot_train[f\"fold_{fold_idx}\"][event_mask]\n",
    "                        elif re.search('val', pred_type) is not None:\n",
    "                            roc_weights = weights_plot_val[f\"fold_{fold_idx}\"][event_mask]\n",
    "                        else:\n",
    "                            roc_weights = weights_plot_test[f\"fold_{fold_idx}\"][event_mask]\n",
    "                    else:\n",
    "                        roc_weights = None\n",
    "\n",
    "                    fpr_bdt, tpr_bdt, threshold_bdt = roc_curve(class_truths, class_preds, sample_weight=roc_weights)\n",
    "                    fpr_bdt = np.interp(base_tpr, tpr_bdt, fpr_bdt)\n",
    "                    threshold_bdt = np.interp(base_tpr, tpr_bdt, threshold_bdt)\n",
    "\n",
    "                    BDT_perf[sample_name][pred_type + 'fprs_' + roc_type][fold_idx][:, i] = fpr_bdt\n",
    "                    BDT_perf[sample_name][pred_type + 'thresholds_' + roc_type][fold_idx][:, i] = threshold_bdt\n",
    "                    BDT_perf[sample_name][pred_type + 'areas_' + roc_type][fold_idx][i] = float(trapezoid(base_tpr, fpr_bdt))\n",
    "    \n",
    "    for pred_type, dataset_dict in [\n",
    "        ('train_', bdt_train_dict),\n",
    "        ('val_', bdt_val_dict),\n",
    "        ('', bdt_test_dict)\n",
    "    ]:\n",
    "\n",
    "        flat_preds = np.concatenate(BDT_perf[sample_name][f'{pred_type}preds'], axis=0)\n",
    "        flat_truths = np.concatenate([dataset_dict[f\"fold_{fold_idx}\"].get_label() for fold_idx in range(len(dataset_dict))], axis=0)\n",
    "\n",
    "        for i, sample_name_ in enumerate(order):\n",
    "            \n",
    "            if sample_name_ == sample_name:\n",
    "                event_mask = flat_truths > -1\n",
    "                pred_rescale = np.ones_like(event_mask)\n",
    "            else:\n",
    "                event_mask = np.logical_or(flat_truths == j, flat_truths == i)\n",
    "                pred_rescale = flat_preds[:, j][event_mask] + flat_preds[:, i][event_mask]\n",
    "            class_preds = flat_preds[:, j][event_mask] / pred_rescale\n",
    "            class_truths = np.where(flat_truths == j, 1, 0)[event_mask]\n",
    "            \n",
    "            for roc_type in ['density', 'weighted']:\n",
    "\n",
    "                if roc_type == 'weighted':\n",
    "                    if re.search('train', pred_type) is not None:\n",
    "                        roc_weights = np.concatenate([weights_plot_train[f\"fold_{fold_idx}\"] for fold_idx in range(len(weights_plot_train))], axis=0)[event_mask]\n",
    "                    elif re.search('val', pred_type) is not None:\n",
    "                        roc_weights = np.concatenate([weights_plot_val[f\"fold_{fold_idx}\"] for fold_idx in range(len(weights_plot_val))], axis=0)[event_mask]\n",
    "                    else:\n",
    "                        roc_weights = np.concatenate([weights_plot_test[f\"fold_{fold_idx}\"] for fold_idx in range(len(weights_plot_test))], axis=0)[event_mask]\n",
    "                else:\n",
    "                    roc_weights = None\n",
    "\n",
    "                fpr_bdt, tpr_bdt, threshold_bdt = roc_curve(class_truths, class_preds, sample_weight=roc_weights)\n",
    "                fpr_bdt = np.interp(base_tpr, tpr_bdt, fpr_bdt)\n",
    "                threshold_bdt = np.interp(base_tpr, tpr_bdt, threshold_bdt)\n",
    "\n",
    "                BDT_perf[sample_name][pred_type + 'fprs_sum_' + roc_type][:, i] = fpr_bdt\n",
    "                BDT_perf[sample_name][pred_type + 'thresholds_sum_' + roc_type][:, i] = threshold_bdt\n",
    "                BDT_perf[sample_name][pred_type + 'areas_sum_' + roc_type][i] = float(trapezoid(base_tpr, fpr_bdt))\n",
    "    \n",
    "    for key in BDT_perf[sample_name].keys():\n",
    "        if type(BDT_perf[sample_name][key]) is list:\n",
    "            continue\n",
    "        BDT_perf[sample_name][key] = BDT_perf[sample_name][key].tolist()\n",
    "\n",
    "\n",
    "with open(os.path.join(OUTPUT_DIRPATH, CURRENT_TIME+f\"_BDT_perf.json\"), 'w') as f:\n",
    "    json.dump(BDT_perf, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 122] Disk quota exceeded",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(OUTPUT_DIRPATH, CURRENT_TIME\u001b[38;5;241m+\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_BDT_perf.json\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBDT_perf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/json/__init__.py:180\u001b[0m, in \u001b[0;36mdump\u001b[0;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m# could accelerate with writelines in some versions of Python, at\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# a debuggability cost\u001b[39;00m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m--> 180\u001b[0m     \u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 122] Disk quota exceeded"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(OUTPUT_DIRPATH, CURRENT_TIME+f\"_BDT_perf.json\"), 'w') as f:\n",
    "    json.dump(BDT_perf, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def pad_list(list_of_lists):\n",
    "    max_length = np.max([len(list_i) for list_i in list_of_lists])\n",
    "    for list_i in list_of_lists:\n",
    "        while len(list_i) < max_length:\n",
    "            list_i.append(list_i[-1])\n",
    "\n",
    "    return list_of_lists\n",
    "\n",
    "def plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix, format='png'):\n",
    "    plot_prefix = plot_prefix + ('_' if plot_prefix != '' else '')\n",
    "    plot_postfix = plot_postfix + ('_' if plot_postfix != '' else '')\n",
    "    plot_name = plot_prefix + plot_name + plot_postfix + f'.{format}'\n",
    "\n",
    "    plot_filepath = os.path.join(plot_dirpath, plot_name)\n",
    "    return plot_filepath\n",
    "\n",
    "def plot_train_val_losses(\n",
    "    losses_arrs, labels, plot_name, plot_dirpath, \n",
    "    plot_prefix='', plot_postfix='', linestyles=None,\n",
    "    losses_std_arrs=None\n",
    "):\n",
    "    plt.figure(figsize=(9,7))\n",
    "    \n",
    "    if type(losses_arrs[0]) is float:\n",
    "        losses_arrs = [losses_arrs]\n",
    "    if linestyles is None:\n",
    "        linestyles = ['solid'] * len(losses_arrs)\n",
    "    if labels is None:\n",
    "        labels = [i for i in range(len(losses_arrs))]\n",
    "\n",
    "    if losses_std_arrs is not None:\n",
    "        for i in range(len(losses_std_arrs)):\n",
    "            plt.fill_between(\n",
    "                range(len(losses_std_arrs[i])), \n",
    "                losses_arrs[i]+losses_std_arrs[i], losses_arrs[i]-losses_std_arrs[i],\n",
    "                alpha=0.7\n",
    "            )\n",
    "\n",
    "    for i in range(len(losses_arrs)):\n",
    "        plt.plot(\n",
    "            range(len(losses_arrs[i])), \n",
    "            losses_arrs[i], \n",
    "            label=f\"{labels[i]} losses\", linestyle=linestyles[i],\n",
    "            alpha=0.7\n",
    "        )\n",
    "        \n",
    "    plt.legend(bbox_to_anchor=(1, 1))\n",
    "    plt.xlabel('EPOCH')\n",
    "    plt.ylabel('Data Loss')\n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix, format='pdf'), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.close()\n",
    "\n",
    "def get_ttH_score(multibdt_output):\n",
    "    return multibdt_output[:, 0] / (multibdt_output[:, 0] + multibdt_output[:, 1])\n",
    "\n",
    "def get_QCD_score(multibdt_output):\n",
    "    return multibdt_output[:, 0] / (multibdt_output[:, 0] + multibdt_output[:, 2] + multibdt_output[:, 3])\n",
    "\n",
    "OPTIMIZED_CUTS = {\n",
    "    '1D': [0.9977, 0.9946, 0.9874],\n",
    "    '2D': [\n",
    "        [0.987, 0.9982],\n",
    "        [0.92, 0.994],\n",
    "        [0.92, 0.9864],\n",
    "    ]\n",
    "}\n",
    "def cat_mask(score, index: int, EVAL_METHOD='2D'):\n",
    "\n",
    "    if EVAL_METHOD == '1D':\n",
    "\n",
    "        lower_cut_value = OPTIMIZED_CUTS[EVAL_METHOD][index]\n",
    "        if index > 0:\n",
    "            upper_cut_value = OPTIMIZED_CUTS[EVAL_METHOD][index - 1]\n",
    "        else:\n",
    "            upper_cut_value = 1.0\n",
    "        \n",
    "        mask = (\n",
    "            score > lower_cut_value\n",
    "        ) & (\n",
    "            score <= upper_cut_value\n",
    "        )\n",
    "\n",
    "        return mask\n",
    "    \n",
    "    elif EVAL_METHOD == '2D':\n",
    "\n",
    "        lower_ttH_cut_value = OPTIMIZED_CUTS[EVAL_METHOD][index][0]\n",
    "        lower_QCD_cut_value = OPTIMIZED_CUTS[EVAL_METHOD][index][1]\n",
    "        if index > 0:\n",
    "            upper_QCD_cut_value = OPTIMIZED_CUTS[EVAL_METHOD][index - 1][1]\n",
    "        else:\n",
    "            upper_QCD_cut_value = 1.\n",
    "        \n",
    "        mask = (\n",
    "            get_ttH_score(score) > lower_ttH_cut_value\n",
    "        ) & (\n",
    "            get_QCD_score(score) > lower_QCD_cut_value\n",
    "        ) & (\n",
    "            get_QCD_score(score) <= upper_QCD_cut_value\n",
    "        )\n",
    "\n",
    "        return mask\n",
    "\n",
    "def plot_rocs(\n",
    "    fprs, tprs, labels, plot_name, plot_dirpath,\n",
    "    plot_prefix='', plot_postfix='', close=True, log=None\n",
    "):\n",
    "    plt.figure(figsize=(9,7))\n",
    "    \n",
    "    for fpr, tpr, label in zip(fprs, tprs, labels):\n",
    "        plt.plot(fpr, tpr, label=label, linestyle='solid')\n",
    "\n",
    "    plt.legend(bbox_to_anchor=(1, 1))\n",
    "    plt.xlabel('Background contamination')\n",
    "    plt.ylabel('Signal efficiency')\n",
    "    plt.xlim((0., 1.))\n",
    "    plt.ylim((0., 1.))\n",
    "    if log is not None and re.search('x', log) is not None:\n",
    "        plt.xscale('log')\n",
    "        plt.xlim((1e-4, 1))\n",
    "    if log is not None and re.search('y', log) is not None:\n",
    "        plt.yscale('log')\n",
    "        plt.ylim((1e-3, 1))\n",
    "    \n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix, format='pdf'), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    if close:\n",
    "        plt.close()\n",
    "\n",
    "def plot_output_scores(\n",
    "    sigs_and_bkgs, order, plot_name, plot_dirpath,\n",
    "    plot_prefix='', plot_postfix='', bins=1000, weights=None, log=False, arctanh=False\n",
    "):\n",
    "    plt.figure(figsize=(9,7))\n",
    "\n",
    "    if arctanh:\n",
    "        end_point = 6.\n",
    "    else:\n",
    "        end_point = 1.\n",
    "    hist_axis = hist.axis.Regular(bins, 0., end_point, name='var', growth=False, underflow=False, overflow=False)\n",
    "    hists, labels = [], []\n",
    "    for sample_name in order:\n",
    "        if sample_name not in sigs_and_bkgs:\n",
    "            continue\n",
    "        hists.append(\n",
    "            hist.Hist(hist_axis, storage='weight').fill(\n",
    "                var=sigs_and_bkgs[sample_name], \n",
    "                weight=weights[sample_name] if weights is not None else np.ones_like(sigs_and_bkgs[sample_name])\n",
    "            )\n",
    "        )\n",
    "        labels.append(sample_name)\n",
    "    hep.histplot(\n",
    "        hists,\n",
    "        yerr=(True if weights is not None else False),\n",
    "        alpha=0.8, density=(False if weights is not None else True), histtype='step',\n",
    "        label=labels\n",
    "    )\n",
    "\n",
    "    plt.legend(bbox_to_anchor=(1, 1))\n",
    "    plt.xlabel('Output score')\n",
    "    if log:\n",
    "        plt.yscale('log')\n",
    "    \n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix, format='pdf'), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.close()\n",
    "\n",
    "def plot_s_over_root_b(\n",
    "    sig, bkg, label, plot_name, plot_dirpath,\n",
    "    plot_prefix='', plot_postfix='', bins=1000, weights={'sig': None, 'bkg': None},\n",
    "    lines=None, lines_labels=None, line_colors=None, arctanh=False\n",
    "):\n",
    "    plt.figure(figsize=(9,7))\n",
    "\n",
    "    if arctanh:\n",
    "        end_point = 6.\n",
    "        hist_axis = hist.axis.Regular(bins, 0., end_point, name='var', growth=False, underflow=False, overflow=False)\n",
    "    else:\n",
    "        end_point = 1.\n",
    "        hist_axis = hist.axis.Regular(bins, 0., end_point, name='var', growth=False, underflow=False, overflow=False)\n",
    "    sig_hist = hist.Hist(hist_axis, storage='weight').fill(var=sig, weight=weights['sig'] if weights['sig'] is not None else np.ones_like(sig))\n",
    "    bkg_hist = hist.Hist(hist_axis, storage='weight').fill(var=bkg, weight=weights['bkg'] if weights['bkg'] is not None else np.ones_like(bkg))\n",
    "    s_over_root_b_points = sig_hist.values().flatten() / np.sqrt(bkg_hist.values().flatten())\n",
    "    plt.plot(\n",
    "        np.arange(0., end_point, end_point*(1/bins)), s_over_root_b_points, \n",
    "        label=f'{label} - s/âb', alpha=0.8\n",
    "    )\n",
    "\n",
    "    if lines is not None:\n",
    "        for i in range(len(lines)):\n",
    "            plt.vlines(\n",
    "                lines[i], 0, np.max(s_over_root_b_points), \n",
    "                label='s/âb'+(' - '+lines_labels[i] if lines_labels is not None else ''), \n",
    "                alpha=0.5, colors=line_colors[i]\n",
    "            )\n",
    "    \n",
    "    plt.legend(bbox_to_anchor=(1, 1))\n",
    "    plt.xlabel('Output score')\n",
    "    plt.ylabel('s/âb')\n",
    "    \n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix, format='pdf'), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.close()\n",
    "\n",
    "def plot_confusion_matrix(\n",
    "    conf_matrix, class_labels, plot_name, plot_dirpath, \n",
    "    plot_prefix='', plot_postfix=''\n",
    "):\n",
    "    plt.figure(figsize=(9,7))\n",
    "\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=class_labels)\n",
    "    disp.plot(im_kw={'norm': 'log'})\n",
    "    \n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix, format='pdf'), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.close()\n",
    "\n",
    "def plot_feature_importance(\n",
    "    feature_scores, feature_labels, plot_name, plot_dirpath, \n",
    "    plot_prefix='', plot_postfix='', fscore_method='total_gain', log=True\n",
    "):\n",
    "    plt.figure(figsize=(18,14))\n",
    "\n",
    "    plt.barh(\n",
    "        np.arange(len(feature_scores)), feature_scores, align='center'\n",
    "    )\n",
    "    plt.yticks(np.arange(len(feature_scores)), feature_labels, fontsize=8)\n",
    "    plt.ylabel('Features')\n",
    "    plt.xlabel(f'F score ({fscore_method})')\n",
    "    if log:\n",
    "        plt.xscale('log')\n",
    "    \n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix, format='pdf'), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def optimize_cut_boundaries(sigs, bkgs, weights, bins=10000, arctanh=False):\n",
    "    hist_list_fold = []\n",
    "    cut_boundaries_fold = []\n",
    "    cut_s_over_root_bs_fold = []\n",
    "    sig_weights_fold = []\n",
    "    bkg_weights_fold = []\n",
    "    if len(np.shape(sigs)) == 1:\n",
    "        sigs, bkgs = [sigs], [bkgs] \n",
    "    if arctanh:\n",
    "        end_point = 6.\n",
    "    else:\n",
    "        end_point = 1.\n",
    "    for sig, bkg in zip(sigs, bkgs):\n",
    "        hist_axis = hist.axis.Regular(bins, 0., end_point, name='var', growth=False, underflow=False, overflow=False)\n",
    "        sig_hist = hist.Hist(hist_axis, storage='weight').fill(var=sig, weight=weights['sig'])\n",
    "        bkg_hist = hist.Hist(hist_axis, storage='weight').fill(var=bkg, weight=weights['bkg'])\n",
    "        hist_list_fold.append({'sig': copy.deepcopy(sig_hist), 'bkg': copy.deepcopy(bkg_hist)})\n",
    "\n",
    "        fold_idx_cuts_bins_inclusive = []\n",
    "        fold_idx_sig_weights = []\n",
    "        fold_idx_bkg_weights = []\n",
    "        fold_idx_prev_s_over_root_b = []\n",
    "        prev_s_over_root_b = 0\n",
    "        for i in range(bins):\n",
    "            s = np.sum(sig_hist.values().flatten()[\n",
    "                (bins-1) - i : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "            ])\n",
    "            sqrt_b = np.sqrt(np.sum(bkg_hist.values().flatten()[\n",
    "                (bins-1) - i : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "            ]))\n",
    "            if prev_s_over_root_b < (s / sqrt_b) or s < 0.25:\n",
    "                prev_s_over_root_b = s / sqrt_b\n",
    "                continue\n",
    "            else:\n",
    "                fold_idx_sig_weights.append(\n",
    "                    {\n",
    "                        'value': np.sum(sig_hist.values().flatten()[\n",
    "                            (bins) - i : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                        ]),\n",
    "                        'w2': np.sqrt(np.sum(sig_hist.variances().flatten()[\n",
    "                            (bins) - i : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                        ])),\n",
    "                    }\n",
    "                )\n",
    "                fold_idx_bkg_weights.append(\n",
    "                    {\n",
    "                        'value': np.sum(bkg_hist.values().flatten()[\n",
    "                            (bins) - i : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                        ]),\n",
    "                        'w2': np.sqrt(np.sum(bkg_hist.variances().flatten()[\n",
    "                            (bins) - i : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                        ])),\n",
    "                    }\n",
    "                )\n",
    "                fold_idx_cuts_bins_inclusive.append(bins - i)\n",
    "                fold_idx_prev_s_over_root_b.append(prev_s_over_root_b)\n",
    "                prev_s_over_root_b = 0\n",
    "        fold_idx_sig_weights.append(\n",
    "            {\n",
    "                'value': np.sum(sig_hist.values().flatten()[\n",
    "                    0 : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                ]),\n",
    "                'w2': np.sqrt(np.sum(sig_hist.variances().flatten()[\n",
    "                    0 : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                ])),\n",
    "            }\n",
    "        )\n",
    "        fold_idx_bkg_weights.append(\n",
    "            {\n",
    "                'value': np.sum(bkg_hist.values().flatten()[\n",
    "                    0 : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                ]),\n",
    "                'w2': np.sqrt(np.sum(bkg_hist.variances().flatten()[\n",
    "                    0 : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                ])),\n",
    "            }\n",
    "        )\n",
    "        fold_idx_cuts_bins_inclusive.append(0)\n",
    "        fold_idx_prev_s_over_root_b.append(prev_s_over_root_b)\n",
    "        fold_idx_score_cuts = [end_point * (bin_i / bins) for bin_i in fold_idx_cuts_bins_inclusive]\n",
    "        cut_boundaries_fold.append(fold_idx_score_cuts)\n",
    "        cut_s_over_root_bs_fold.append(fold_idx_prev_s_over_root_b)\n",
    "        sig_weights_fold.append(fold_idx_sig_weights)\n",
    "        bkg_weights_fold.append(fold_idx_bkg_weights)\n",
    "    return cut_boundaries_fold, cut_s_over_root_bs_fold, sig_weights_fold, bkg_weights_fold\n",
    "\n",
    "def p_to_xyz(p, split=True):  # makes a tetrahedron with height 1 and vertices {(0, 0, 0),  (â3/2, 0, â3/2),  (0, â3/2, â3/2),  (â3/2, â3/2, 0)}\n",
    "    rt3o2 = np.sqrt(3) / 2\n",
    "\n",
    "    x = rt3o2 * (0*p[:, 0] + p[:, 1] + p[:, 2] + 0*p[:, 3])\n",
    "    y = rt3o2 * (0*p[:, 0] + 0*p[:, 1] + p[:, 2] + p[:, 3])\n",
    "    z = rt3o2 * (0*p[:, 0] + p[:, 1] + 0*p[:, 2] + p[:, 3])\n",
    "\n",
    "    if split:\n",
    "        return x, y, z\n",
    "    else:\n",
    "        return np.column_stack((x, y, z))\n",
    "    \n",
    "def tetrahedron_lines(split=True):\n",
    "    sig_to_ttH_like    = np.array([np.sqrt(3)/2,         0,            np.sqrt(3)/2])\n",
    "    sig_to_VH_like     = np.array([0,                np.sqrt(3)/2,     np.sqrt(3)/2])\n",
    "    sig_to_nonRes_like = np.array([np.sqrt(3)/2,     np.sqrt(3)/2,                0])\n",
    "\n",
    "    if split:\n",
    "        return sig_to_ttH_like, sig_to_VH_like, sig_to_nonRes_like\n",
    "    else:\n",
    "        return np.column_stack((sig_to_ttH_like, sig_to_VH_like, sig_to_nonRes_like))\n",
    "\n",
    "def output_to_3d_thresholds(p, split=True):\n",
    "    data = p_to_xyz(p, split=False)\n",
    "    tetrahedron_matrix = tetrahedron_lines(split=False)\n",
    "\n",
    "    thresholds = np.einsum('ij,jk', data, tetrahedron_matrix)\n",
    "\n",
    "    if split:\n",
    "        return thresholds[:, 0], thresholds[:, 1], thresholds[:, 2]\n",
    "    else:\n",
    "        return thresholds\n",
    "\n",
    "def optimize_cuts(\n",
    "    preds: np.ndarray, labels: np.ndarray, weights: np.ndarray,\n",
    "    param_names=['r1', 'r2', 'r3'], param_range=[(0., 1.), (0., 1.), (0., 1.)], \n",
    "    n_steps=int(5e2), verbose: bool=False, min_sig: float=0.25, prefactor: float=1e3, rng_seed: int=21,\n",
    "    fit_funcs_per_param: list=['power_law', 'power_law', 'power_law']\n",
    "):\n",
    "    # tetrahedron bkg vectors\n",
    "    sig_to_ttH_like, sig_to_VH_like, sig_to_nonRes_like = tetrahedron_lines()\n",
    "    tetrahedron_matrix = tetrahedron_lines(split=False)\n",
    "\n",
    "    # 3D outputs\n",
    "    xyz_preds = p_to_xyz(preds, split=False)\n",
    "    xyz_thresholds = np.einsum('ij,jk', xyz_preds, tetrahedron_matrix)\n",
    "\n",
    "    sig_to_ttH_preds = np.einsum('ij,j', xyz_preds, sig_to_ttH_like)\n",
    "    sig_to_VH_preds = np.einsum('ij,j', xyz_preds, sig_to_VH_like)\n",
    "    sig_to_nonRes_preds = np.einsum('ij,j', xyz_preds, sig_to_nonRes_like)\n",
    "\n",
    "    # histogramed counts\n",
    "    sig_to_ttH_counts, sig_to_ttH_bins = np.histogram(sig_to_ttH_preds[labels == 0], bins=1000, range=(0., 0.8), density=True)\n",
    "    sig_to_VH_counts, sig_to_VH_bins = np.histogram(sig_to_VH_preds[labels == 0], bins=1000, range=(0., 0.8), density=True)\n",
    "    sig_to_nonRes_counts, sig_to_nonRes_bins = np.histogram(sig_to_nonRes_preds[labels == 0], bins=1000, range=(0., 0.8), density=True)\n",
    "\n",
    "    # shift to center of bins\n",
    "    def bin_centers(bins_array):\n",
    "        return np.array([np.mean([bins_array[bin_i], bins_array[bin_i+1]]) for bin_i in range(len(bins_array)-1)])\n",
    "    \n",
    "    sig_to_ttH_bin_centers = bin_centers(sig_to_ttH_bins)\n",
    "    sig_to_VH_bin_centers = bin_centers(sig_to_VH_bins)\n",
    "    sig_to_nonRes_bin_centers = bin_centers(sig_to_nonRes_bins)\n",
    "\n",
    "    # fit data\n",
    "    def get_fit_funcs_per_param():\n",
    "        func_list, fit_func_list, transform_func_list = [], [], []\n",
    "        for func_name in fit_funcs_per_param:\n",
    "            if func_name == 'power_law':\n",
    "                func_list.append(power_law)\n",
    "                fit_func_list.append(fit_power_law)\n",
    "                transform_func_list.append(power_law_transform)\n",
    "            elif func_name == 'exponential':\n",
    "                func_list.append(exponential)\n",
    "                fit_func_list.append(fit_exponential)\n",
    "                transform_func_list.append(exponential_transform)\n",
    "            elif func_name == 'levy':\n",
    "                func_list.append(levy)\n",
    "                fit_func_list.append(fit_levy)\n",
    "                transform_func_list.append(levy_transform)\n",
    "            else:\n",
    "                raise Exception(f\"Fit function requested is not implemented. You asked for {func_name}, the implemented functions are power_law, exponential, and levy.\")\n",
    "        return func_list, fit_func_list, transform_func_list\n",
    "    \n",
    "    power_law = lambda x, a, k: a * np.power(x, -k)\n",
    "    def fit_power_law(x, y, sigma=None):\n",
    "        a_init = 1.\n",
    "        k_init = 5.\n",
    "\n",
    "        opt_params, opt_cov  = curve_fit(\n",
    "            power_law, \n",
    "            x,\n",
    "            y,\n",
    "            p0=[a_init, k_init],\n",
    "            sigma=sigma\n",
    "        )\n",
    "        return opt_params, opt_cov\n",
    "    power_law_transform = lambda a, k: (\n",
    "        lambda x: ((-k + 1) / a) * (x ** (1 / (-k + 1)))\n",
    "    )\n",
    "\n",
    "    exponential = lambda x, a, k: a * np.exp(-x * k)\n",
    "    def fit_exponential(x, y, sigma=None):\n",
    "        a_init = y[0]\n",
    "        k_init = 1 / np.mean([\n",
    "            x[y > (y[0] / np.exp(1))][-1],\n",
    "            x[y < (y[0] / np.exp(1))][0],\n",
    "        ])\n",
    "\n",
    "        opt_params, opt_cov = curve_fit(\n",
    "            exponential, \n",
    "            x,\n",
    "            y,\n",
    "            p0=[a_init, k_init],\n",
    "            sigma=sigma\n",
    "        )\n",
    "        return opt_params, opt_cov\n",
    "    exponential_transform = lambda a, k: (\n",
    "        lambda x: (-1 / k) * np.log(-k * x / a)\n",
    "    )\n",
    "\n",
    "    levy = lambda x, c, mu: (\n",
    "        np.sqrt(c / (2 * np.pi)) * np.exp(-c / (2 * (x - mu))) / np.power(x - mu, 3/2)\n",
    "    )\n",
    "    def fit_levy(x, y, sigma=None):\n",
    "        c_init = 0.01  # success of fit withint 600 tries (kwarg of curve_fit) HIGHLY\n",
    "        mu_init = 0.   #  sensitive to these initial choices of parameters. maybe rescale them by 1,000?\n",
    "\n",
    "        opt_params, opt_cov = curve_fit(\n",
    "            levy, \n",
    "            x,\n",
    "            y,\n",
    "            p0=[c_init, mu_init],\n",
    "            sigma=sigma,\n",
    "        )\n",
    "        return opt_params, opt_cov\n",
    "    gaussian_transfrom = lambda x: (10 / np.log(41)) * np.log(\n",
    "        1 - (np.log(-np.log2(x)) / np.log(22))\n",
    "    )  # approximation taken from https://dmi.units.it/~soranzo/epureAMS85-88-2014%202.pdf\n",
    "    levy_transform = lambda c, mu: (\n",
    "        lambda x: (c / np.power(gaussian_transfrom(1 - x/2), 2)) + mu\n",
    "    )\n",
    "    \n",
    "    funcs, fit_funcs, transform_funcs = get_fit_funcs_per_param()\n",
    "    sig_to_ttH_popt_func, sig_to_ttH_popt_cov = fit_funcs[0](sig_to_ttH_bin_centers, sig_to_ttH_counts, sigma=1/np.power(sig_to_ttH_counts, 1/2))\n",
    "    sig_to_VH_popt_func, sig_to_VH_popt_cov = fit_funcs[1](sig_to_VH_bin_centers, sig_to_VH_counts, sigma=1/np.power(sig_to_VH_counts, 1/2))\n",
    "    sig_to_nonRes_popt_func, sig_to_nonRes_popt_cov = fit_funcs[2](sig_to_nonRes_bin_centers, sig_to_nonRes_counts, sigma=1/np.power(sig_to_nonRes_counts, 1/2))\n",
    "    sig_to_ttH_transform = transform_funcs[0](*sig_to_ttH_popt_func)\n",
    "    sig_to_VH_transform = transform_funcs[1](*sig_to_VH_popt_func)\n",
    "    sig_to_nonRes_transform = transform_funcs[2](*sig_to_nonRes_popt_func)\n",
    "\n",
    "    sig_to_ttH_func = funcs[0](sig_to_ttH_bin_centers, *sig_to_ttH_popt_func)\n",
    "    sig_to_VH_func = funcs[1](sig_to_ttH_bin_centers, *sig_to_VH_popt_func)\n",
    "    sig_to_nonRes_func = funcs[2](sig_to_ttH_bin_centers, *sig_to_nonRes_popt_func)\n",
    "    plt.figure()\n",
    "    plt.plot(sig_to_ttH_bin_centers, sig_to_ttH_counts, alpha=0.7, color='r', linestyle='-', label='Sig to ttH-like')\n",
    "    plt.plot(sig_to_VH_bin_centers, sig_to_VH_counts, alpha=0.7, color='b', linestyle='-', label='Sig to VH-like')\n",
    "    plt.plot(sig_to_nonRes_bin_centers, sig_to_nonRes_counts, alpha=0.7, color='g', linestyle='-', label='Sig to nonRes-like')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    if np.all(np.array(fit_funcs_per_param) == 'levy'):\n",
    "        print(f\"opt ttH levy values: c = {sig_to_ttH_popt_func[0]}, $\\mu$ = {sig_to_ttH_popt_func[1]}\")\n",
    "        print(f\"opt VH levy values: c = {sig_to_VH_popt_func[0]}, $\\mu$ = {sig_to_VH_popt_func[1]}\")\n",
    "        print(f\"opt nonRes levy values: c = {sig_to_nonRes_popt_func[0]}, $\\mu$ = {sig_to_nonRes_popt_func[1]}\")\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(sig_to_ttH_bin_centers, sig_to_ttH_counts, alpha=0.7, color='r', linestyle='-', label='Sig to ttH-like')\n",
    "    plt.plot(sig_to_VH_bin_centers, sig_to_VH_counts, alpha=0.7, color='b', linestyle='-', label='Sig to VH-like')\n",
    "    plt.plot(sig_to_nonRes_bin_centers, sig_to_nonRes_counts, alpha=0.7, color='g', linestyle='-', label='Sig to nonRes-like')\n",
    "    plt.plot(sig_to_ttH_bin_centers, sig_to_ttH_func, alpha=0.7, color='r', linestyle='--', label='Sig to ttH-like - Fit exp')\n",
    "    plt.plot(sig_to_VH_bin_centers, sig_to_VH_func, alpha=0.7, color='b', linestyle='--', label='Sig to VH-like - Fit exp')\n",
    "    plt.plot(sig_to_nonRes_bin_centers, sig_to_nonRes_func, alpha=0.7, color='g', linestyle='--', label='Sig to nonRes-like - Fit exp')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    space  = [Real(float(param_range[i][0]), float(param_range[i][1]), \"uniform\", name=param_name) for i, param_name in enumerate(param_names)]\n",
    "    def space_transform(X):\n",
    "        return [\n",
    "            sig_to_ttH_transform(X[param_names[0]]),\n",
    "            sig_to_VH_transform(X[param_names[1]]),\n",
    "            sig_to_nonRes_transform(X[param_names[2]]),\n",
    "        ]\n",
    "\n",
    "    @use_named_args(space)\n",
    "    def objective(**X):\n",
    "        thresholds = space_transform(X)\n",
    "        if verbose:\n",
    "            print(\"New configuration: {}\".format(thresholds))\n",
    "        sample_mask = np.all(xyz_thresholds < thresholds, axis=1)\n",
    "\n",
    "        num_sig = np.abs(\n",
    "            np.sum(\n",
    "                weights[\n",
    "                    np.logical_and(\n",
    "                        labels == 0,\n",
    "                        sample_mask\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "        num_singleH_bkg = np.abs(\n",
    "            np.sum(\n",
    "                weights[\n",
    "                    np.logical_and(\n",
    "                        np.logical_or(\n",
    "                            labels == 1,\n",
    "                            labels == 2\n",
    "                        ),\n",
    "                        sample_mask\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "        num_nonRes_bkg = np.abs(\n",
    "            np.sum(\n",
    "                weights[\n",
    "                    np.logical_and(\n",
    "                        labels == 3,\n",
    "                        sample_mask\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "        singleH_to_nonRes_factor = 3.\n",
    "        num_rescale_bkg = (\n",
    "            singleH_to_nonRes_factor * num_singleH_bkg\n",
    "        ) + num_nonRes_bkg\n",
    "        num_bkg = num_singleH_bkg + num_nonRes_bkg\n",
    "\n",
    "        def s_over_b(s, b, case='realistic'):\n",
    "            if case == 'simplistic':\n",
    "                return s / np.sqrt(b)\n",
    "            elif case == 'realistic':\n",
    "                return np.sqrt(\n",
    "                    2 * (\n",
    "                        (s + b) * np.log(1 + (s / b)) - s\n",
    "                    )\n",
    "                )\n",
    "        s_over_root_b = s_over_b(num_sig, num_bkg)\n",
    "        opt_criteria = s_over_b(num_sig, num_rescale_bkg)\n",
    "\n",
    "        if num_sig == 0 and num_bkg == 0:\n",
    "            both_0 = prefactor*1e1\n",
    "            if verbose:\n",
    "                print(f\"both sig and bkg 0 at this hyperplane => {both_0}\")\n",
    "                print('='*60)\n",
    "            return both_0\n",
    "        elif num_sig < min_sig:\n",
    "            small_sig = prefactor*0\n",
    "            if verbose:\n",
    "                print(f\"too little sig ({num_sig}) at this hyperplane => {small_sig}\")\n",
    "                print('='*60)\n",
    "            return small_sig\n",
    "        elif num_bkg == 0:\n",
    "            zero_bkg = -prefactor*num_sig\n",
    "            if verbose:\n",
    "                print(f\"zero bkg at this hyperplane (likely due to finite data rather than real bkg-free zone) => {zero_bkg}\")\n",
    "                print('='*60)\n",
    "            return zero_bkg\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"s = {num_sig}, b = {num_bkg}, s/âb = {s_over_root_b} => {-prefactor*opt_criteria}\")\n",
    "            print('='*60)\n",
    "\n",
    "        return -prefactor*opt_criteria\n",
    "    \n",
    "    res_gp = gp_minimize(\n",
    "        objective, space, random_state=rng_seed, \n",
    "        n_calls=n_steps, n_initial_points=n_steps-100,\n",
    "        n_restarts_optimizer=5\n",
    "    )\n",
    "\n",
    "    opt_params = [float(res_gp.x[i]) for i in range(len(space))]\n",
    "    opt_cuts = [float(opt_cut) for opt_cut in space_transform({param_names[i]: res_gp.x[i] for i in range(len(param_names))})]\n",
    "    if verbose:\n",
    "        print(\"Best parameters: {}\".format(opt_cuts))\n",
    "        print(f\"Best s/âb = {-res_gp.fun / prefactor}\")\n",
    "\n",
    "    return opt_cuts, opt_params\n",
    "\n",
    "\n",
    "def multi_optimize_cut_boundaries(preds: list, labels: np.ndarray, weights: np.ndarray, num_categories: int=3, min_sig: float=0.25, n_steps: int=200):\n",
    "    clf_dict = {}\n",
    "    param_clf_dict = {}\n",
    "    # clf_dict[0] = [0.008485205139697272, 0.03976034437493922, 0.06505303760998234]\n",
    "    # for cat in range(1, num_categories):\n",
    "    for cat in range(num_categories):\n",
    "\n",
    "        clf_dict[cat] = []\n",
    "        param_clf_dict[cat] = []\n",
    "\n",
    "        if cat == 0:\n",
    "            opt_cuts, opt_params = optimize_cuts(\n",
    "                np.array(preds), labels, weights, verbose=True,\n",
    "                n_steps=n_steps, min_sig=min_sig, rng_seed=None,\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            slice_array = np.ones_like(labels, dtype=bool)\n",
    "            for prev_cat in range(cat):\n",
    "                slice_array = np.logical_and(\n",
    "                    slice_array,\n",
    "                    np.logical_not(\n",
    "                        np.all(\n",
    "                            output_to_3d_thresholds(np.array(preds), split=False) < clf_dict[prev_cat], \n",
    "                            axis=1\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            sliced_preds = np.array(preds)[slice_array]\n",
    "            sliced_labels = labels[slice_array]\n",
    "            sliced_weights = weights[slice_array]\n",
    "            \n",
    "            opt_cuts, opt_params = optimize_cuts(\n",
    "                sliced_preds, sliced_labels, sliced_weights, verbose=True,\n",
    "                n_steps=n_steps, min_sig=min_sig, rng_seed=None,\n",
    "                fit_funcs_per_param=['levy', 'levy', 'levy']\n",
    "            )\n",
    "\n",
    "        clf_dict[cat] = opt_cuts\n",
    "        param_clf_dict[cat] = opt_params\n",
    "\n",
    "    return clf_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "MC_NAMES_PRETTY = {\n",
    "    \"GGJets\": r\"$\\gamma\\gamma+3j$\",\n",
    "    \"GJetPt20To40\": r\"$\\gamma+j$, 20<$p_T$<40GeV\",\n",
    "    \"GJetPt40\": r\"$\\gamma+j$, 40GeV<$p_T$\",\n",
    "    \"GluGluHToGG\": r\"ggF $H\\rightarrow \\gamma\\gamma$\",\n",
    "    \"VBFHToGG\": r\"VBF $H\\rightarrow \\gamma\\gamma$\",\n",
    "    \"VHToGG\": r\"V$H\\rightarrow\\gamma\\gamma$\",\n",
    "    \"ttHToGG\": r\"$t\\bar{t}H\\rightarrow\\gamma\\gamma$\",\n",
    "    \"GluGluToHH\": r\"ggF $HH\\rightarrow bb\\gamma\\gamma$\",\n",
    "    # \"VBFHHto2B2G_CV_1_C2V_1_C3_1\": r\"VBF $HH\\rightarrow bb\\gamma\\gamma$\",\n",
    "    \"signal\": r\"ggF $HH\\rightarrow bb\\gamma\\gamma$ + VBF $HH\\rightarrow bb\\gamma\\gamma$\",\n",
    "    # Names for order #\n",
    "    \"ggF HH\": r\"ggF $H\\rightarrow \\gamma\\gamma$\",\n",
    "    \"ttH\": r\"$t\\bar{t}H\\rightarrow\\gamma\\gamma$\",\n",
    "    \"single-H\": r\"ggF $H\\rightarrow \\gamma\\gamma$ + VBF $H\\rightarrow \\gamma\\gamma$ + V$H\\rightarrow\\gamma\\gamma$\",\n",
    "    \"non-res\": r\"$\\gamma\\gamma+3j$ + $\\gamma+j$, 20GeV<$p_T$\",\n",
    "    \"VH\": r\"V$H\\rightarrow\\gamma\\gamma$\",\n",
    "    \"non-res + ggFH + VBFH\": r\"$\\gamma\\gamma+3j$ + $\\gamma+j$, 20GeV<$p_T$ + ggF $H\\rightarrow \\gamma\\gamma$ + VBF $H\\rightarrow \\gamma\\gamma$\",\n",
    "    \"ttH + bbH\": r\"$t\\bar{t}H\\rightarrow\\gamma\\gamma$ + $b\\bar{b}H\\rightarrow\\gamma\\gamma$\",\n",
    "    # Need to fill in pretty print for BSM samples #\n",
    "}\n",
    "LUMINOSITIES = {\n",
    "    '2022preEE': 7.9804, \n",
    "    '2022postEE': 26.6717,\n",
    "    # Need to fill in lumis for other eras #\n",
    "}\n",
    "LUMINOSITIES['total_lumi'] = sum(LUMINOSITIES.values())\n",
    "\n",
    "# Dictionary of variables\n",
    "VARIABLES = {\n",
    "    # key: hist.axis axes for plotting #\n",
    "    # MET variables\n",
    "    'puppiMET_sumEt': hist.axis.Regular(40, 150., 2000, name='var', label=r'puppiMET $\\Sigma E_T$ [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'puppiMET_pt': hist.axis.Regular(40, 20., 250, name='var', label=r'puppiMET $p_T$ [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'puppiMET_phi': hist.axis.Regular(20,-3.2, 3.2, name='var', label=r'puppiMET $\\phi$', growth=False, underflow=False, overflow=False), \n",
    "    # jet-MET variables\n",
    "    'DeltaPhi_j1MET': hist.axis.Regular(20,-3.2, 3.2, name='var', label=r'$\\Delta\\phi (j_1,E_T^{miss})$', growth=False, underflow=False, overflow=False), \n",
    "    'DeltaPhi_j2MET': hist.axis.Regular(20, -3.2, 3.2, name='var', label=r'$\\Delta\\phi (j_2,E_T^{miss})$', growth=False, underflow=False, overflow=False), \n",
    "    # jet-photon variables\n",
    "    'DeltaR_jg_min': hist.axis.Regular(30, 0, 5, name='var', label=r'min$(\\Delta R(jet, \\gamma))$', growth=False, underflow=False, overflow=False), \n",
    "    # jet variables\n",
    "    # 'jet1_pt': hist.axis.Regular(40, 20., 250, name='var', label=r'lead jet $p_T$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    # 'jet2_pt': hist.axis.Regular(40, 20., 250, name='var', label=r'sublead jet $p_T$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    'lead_bjet_pt': hist.axis.Regular(40, 20., 250, name='var', label=r'lead bjet $p_T$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    'lead_bjet_eta': hist.axis.Regular(20, -5., 5., name='var', label=r'lead bjet $\\eta$', growth=False, underflow=False, overflow=False),\n",
    "    'nonRes_lead_bjet_btagPNetB': hist.axis.Regular(50, 0., 1., name='var', label=r'$j_{lead}$ PNet btag score', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_bjet_pt': hist.axis.Regular(40, 20., 250, name='var', label=r'lead bjet $p_T$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    'sublead_bjet_eta': hist.axis.Regular(20, -5., 5., name='var', label=r'lead bjet $\\eta$', growth=False, underflow=False, overflow=False),\n",
    "    'nonRes_sublead_bjet_btagPNetB': hist.axis.Regular(50, 0., 1., name='var', label=r'$j_{sublead}$ PNet btag score', growth=False, underflow=False, overflow=False),\n",
    "    'n_jets': hist.axis.Integer(0, 10, name='var', label=r'$n_{jets}$', growth=False, underflow=False, overflow=False), \n",
    "    'chi_t0': hist.axis.Regular(40, 0., 150, name='var', label=r'$\\chi_{t0}^2$', growth=False, underflow=False, overflow=False), \n",
    "    'chi_t1': hist.axis.Regular(30, 0., 500, name='var', label=r'$\\chi_{t1}^2$', growth=False, underflow=False, overflow=False), \n",
    "    # lepton variables\n",
    "    'n_leptons': hist.axis.Integer(0, 10, name='var', label=r'$n_{leptons}$', growth=False, underflow=False, overflow=False),\n",
    "    'lepton1_pt': hist.axis.Regular(40, 0., 200., name='var', label=r'lead lepton $p_T$ [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'lepton2_pt': hist.axis.Regular(40, 0., 200., name='var', label=r'sublead lepton $p_T$ [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'lepton1_eta': hist.axis.Regular(30, -5., 5., name='var', label=r'lead lepton $\\eta$', growth=False, underflow=False, overflow=False), \n",
    "    'lepton2_eta': hist.axis.Regular(30, -5., 5., name='var', label=r'sublead lepton $\\eta$', growth=False, underflow=False, overflow=False),\n",
    "    'lepton1_phi': hist.axis.Regular(20, -3.2, 3.2, name='var', label=r'lead lepton $\\phi$', growth=False, underflow=False, overflow=False), \n",
    "    'lepton2_phi': hist.axis.Regular(20, -3.2, 3.2, name='var', label=r'sublead lepton $\\phi$', growth=False, underflow=False, overflow=False),\n",
    "    # diphoton variables\n",
    "    'pt': hist.axis.Regular(40, 20., 2000, name='var', label=r' $\\gamma\\gamma p_{T}$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    'eta': hist.axis.Regular(20, -5., 5., name='var', label=r'$\\gamma\\gamma \\eta$', growth=False, underflow=False, overflow=False), \n",
    "    'phi': hist.axis.Regular(20, -3.2, 3.2, name='var', label=r'$\\gamma \\gamma \\phi$', growth=False, underflow=False, overflow=False),\n",
    "    # angular (cos) variables\n",
    "    'nonRes_CosThetaStar_CS': hist.axis.Regular(20, -1, 1, name='var', label=r'cos$(\\theta_{CS})$', growth=False, underflow=False, overflow=False), \n",
    "    'nonRes_CosThetaStar_jj': hist.axis.Regular(20, -1, 1, name='var', label=r'cos$(\\theta_{jj})$', growth=False, underflow=False, overflow=False), \n",
    "    'nonRes_CosThetaStar_gg': hist.axis.Regular(50, -1., 1., name='var', label=r'cos$(\\theta_{gg})$', growth=False, underflow=False, overflow=False),\n",
    "    # jet-lepton variables\n",
    "    'leadBjet_leadLepton': hist.axis.Regular(30, 0, 5, name='var', label=r'$\\Delta R(bjet_{lead}, l_{lead})$', growth=False, underflow=False, overflow=False), \n",
    "    'leadBjet_subleadLepton': hist.axis.Regular(30, 0, 5, name='var', label=r'$\\Delta R(bjet_{lead}, l_{sublead})$', growth=False, underflow=False, overflow=False), \n",
    "    'subleadBjet_leadLepton': hist.axis.Regular(30, 0, 5, name='var', label=r'$\\Delta R(bjet_{sublead}, l_{lead})$', growth=False, underflow=False, overflow=False), \n",
    "    'subleadBjet_subleadLepton': hist.axis.Regular(30, 0, 5, name='var', label=r'$\\Delta R(bjet_{sublead}, l_{sublead})$', growth=False, underflow=False, overflow=False),\n",
    "    # Yibo's BDT variables\n",
    "    'lead_mvaID': hist.axis.Regular(50, -1., 1., name='var', label=r'$\\gamma_{lead}$ MVA ID', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_mvaID': hist.axis.Regular(50, -1., 1., name='var', label=r'$\\gamma_{sublead}$ MVA ID', growth=False, underflow=False, overflow=False),\n",
    "    'lead_sigmaE_over_E': hist.axis.Regular(50, 0., 0.06, name='var', label=r'$\\gamma_1 \\sigma {E} / E$', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_sigmaE_over_E': hist.axis.Regular(50, 0., 0.06, name='var', label=r'$\\gamma_2 \\sigma {E} / E$', growth=False, underflow=False, overflow=False),\n",
    "    'lead_bjet_pt_over_Mjj': hist.axis.Regular(50, 0., 4., name='var', label=r'$j1 p_{T} / M_{jj}$', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_bjet_pt_over_Mjj': hist.axis.Regular(50, 0., 2., name='var', label=r'$j2 p_{T} / M_{jj}$', growth=False, underflow=False, overflow=False),\n",
    "    'lead_bjet_sigmapT_over_pT': hist.axis.Regular(50, 0., 0.02, name='var', label=r'$j1 \\sigma p_{T} / p_{T}$', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_bjet_sigmapT_over_pT': hist.axis.Regular(50, 0., 0.02, name='var', label=r'$j2 \\sigma p_{T} / p_{T}$', growth=False, underflow=False, overflow=False),\n",
    "    'dipho_mass_over_Mggjj': hist.axis.Regular(50, 0., 1., name='var', label=r'$M_{\\gamma\\gamma} / M_{\\gamma\\gamma jj}$', growth=False, underflow=False, overflow=False), \n",
    "    'dijet_mass_over_Mggjj': hist.axis.Regular(50, 0., 1., name='var', label=r'$M_{jj} / M_{\\gamma\\gamma jj}$', growth=False, underflow=False, overflow=False),\n",
    "    # My variables for non-reso reduction #\n",
    "    'lead_pfRelIso03_all_quadratic': hist.axis.Regular(50, -1., 1., name='var', label=r'$\\gamma_{lead}$ PF RelIso03 all quad.', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_pfRelIso03_all_quadratic': hist.axis.Regular(50, -1., 1., name='var', label=r'$\\gamma_{sublead}$ PF RelIso03 all quad.', growth=False, underflow=False, overflow=False),\n",
    "    # Michael's DNN variables #\n",
    "    'DeltaR_j1g1': hist.axis.Regular(50, 0., 5., name='var', label=r'$\\Delta R(bjet_{lead}, \\gamma_{lead})$', growth=False, underflow=False, overflow=False), \n",
    "    'DeltaR_j1g2': hist.axis.Regular(50, 0., 5., name='var', label=r'$\\Delta R(bjet_{lead}, \\gamma_{sublead})$', growth=False, underflow=False, overflow=False), \n",
    "    'DeltaR_j2g1': hist.axis.Regular(50, 0., 5., name='var', label=r'$\\Delta R(bjet_{sublead}, \\gamma_{lead})$', growth=False, underflow=False, overflow=False), \n",
    "    'DeltaR_j2g2': hist.axis.Regular(50, 0., 5., name='var', label=r'$\\Delta R(bjet_{sublead}, \\gamma_{sublead})$', growth=False, underflow=False, overflow=False),\n",
    "    'HHbbggCandidate_pt': hist.axis.Regular(100, 0., 700., name='var', label=r'HH $p_T$ [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'HHbbggCandidate_eta': hist.axis.Regular(50, -5., 5., name='var', label=r'HH $\\eta$', growth=False, underflow=False, overflow=False), \n",
    "    'HHbbggCandidate_phi': hist.axis.Regular(50, -3.2, 3.2, name='var', label=r'HH $\\phi$', growth=False, underflow=False, overflow=False),\n",
    "    'HHbbggCandidate_mass': hist.axis.Regular(25, 0., 700., name='var', label=r'$M_{HH}$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    # ATLAS variables #\n",
    "    'pt_balance': hist.axis.Regular(100, 0., 2., name='var', label=r'$p_{T,HH} / (p_{T,\\gamma1} + p_{T,\\gamma2} + p_{T,j1} + p_{T,j2})$', growth=False, underflow=False, overflow=False), \n",
    "    # VH variables #\n",
    "    'DeltaPhi_jj': hist.axis.Regular(20, -3.2, 3.2, name='var', label=r'$\\Delta\\phi (j_1,j_2)$', growth=False, underflow=False, overflow=False),\n",
    "    'DeltaEta_jj': hist.axis.Regular(20, 0., 10., name='var', label=r'$\\Delta\\eta (j_1,j_2)$', growth=False, underflow=False, overflow=False),\n",
    "    'isr_jet_pt': hist.axis.Regular(100, 0., 200., name='var', label=r'ISR jet $p_T$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    'DeltaPhi_isr_jet_z': hist.axis.Regular(20, -3.2, 3.2, name='var', label=r'$\\Delta\\phi (j_{ISR},jj)$', growth=False, underflow=False, overflow=False),\n",
    "    'dijet_pt': hist.axis.Regular(100, 0., 500., name='var', label=r'jj $p_T$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    'lepton1_pfIsoId': hist.axis.Integer(0, 12, name='var', label=r'$l_{lead}$ PF IsoId', growth=False, underflow=False, overflow=False), \n",
    "    'lepton1_mvaID': hist.axis.Regular(50, -1., 1., name='var', label=r'$\\l_{lead}$ MVA ID', growth=False, underflow=False, overflow=False), \n",
    "\n",
    "    # aux variables #\n",
    "    'dijet_mass': hist.axis.Regular(55, 70., 180., name='var', label=r'$M_{jj}$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    'mass': hist.axis.Regular(55, 70., 180., name='var', label=r'$M_{\\gamma\\gamma}$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "}\n",
    "# Dictionary of variables to do MC/Data comparison\n",
    "VARIABLES_STD = {\n",
    "    # key: hist.axis axes for plotting #\n",
    "    # MET variables\n",
    "    'puppiMET_sumEt': hist.axis.Regular(40, -4., 4., name='var', label=r'puppiMET ln($\\Sigma E_T$) [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'puppiMET_pt': hist.axis.Regular(40, -4., 4., name='var', label=r'puppiMET ln($p_T$) [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'puppiMET_phi': hist.axis.Regular(40, -4., 4., name='var', label=r'puppiMET $\\phi$', growth=False, underflow=False, overflow=False), \n",
    "    # jet-MET variables\n",
    "    'DeltaPhi_j1MET': hist.axis.Regular(40, -4., 4., name='var', label=r'$\\Delta\\phi (j_1,E_T^{miss})$', growth=False, underflow=False, overflow=False), \n",
    "    'DeltaPhi_j2MET': hist.axis.Regular(40, -4., 4., name='var', label=r'$\\Delta\\phi (j_2,E_T^{miss})$', growth=False, underflow=False, overflow=False), \n",
    "    # jet-photon variables\n",
    "    'DeltaR_jg_min': hist.axis.Regular(40, -4., 4., name='var', label=r'min$(\\Delta R(jet, \\gamma))$', growth=False, underflow=False, overflow=False), \n",
    "    # jet variables\n",
    "    'lead_bjet_pt': hist.axis.Regular(40, -4., 4., name='var', label=r'lead bjet ln($p_T$) [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_bjet_pt': hist.axis.Regular(40, -4., 4., name='var', label=r'sublead bjet ln($p_T$) [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'lead_bjet_eta': hist.axis.Regular(40, -4., 4., name='var', label=r'lead bjet $\\eta$', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_bjet_eta': hist.axis.Regular(40, -4., 4., name='var', label=r'sublead bjet $\\eta$', growth=False, underflow=False, overflow=False),\n",
    "    'lead_bjet_phi': hist.axis.Regular(40, -4., 4., name='var', label=r'lead bjet $\\phi$', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_bjet_phi': hist.axis.Regular(40, -4., 4., name='var', label=r'sublead bjet $\\phi$', growth=False, underflow=False, overflow=False),\n",
    "    'n_jets': hist.axis.Regular(12, -4., 4., name='var', label=r'$n_{jets}$', growth=False, underflow=False, overflow=False), \n",
    "    'chi_t0': hist.axis.Regular(40, -4., 10., name='var', label=r'ln($\\chi_{t0}^2$)', growth=False, underflow=False, overflow=False), \n",
    "    'chi_t1': hist.axis.Regular(40, -4., 10., name='var', label=r'ln($\\chi_{t1}^2$)', growth=False, underflow=False, overflow=False), \n",
    "    # lepton variables\n",
    "    'n_leptons': hist.axis.Regular(12, -4., 4., name='var', label=r'$n_{leptons}$', growth=False, underflow=False, overflow=False),\n",
    "    'lepton1_pt': hist.axis.Regular(40, -4., 4., name='var', label=r'lead lepton ln($p_T$) [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'lepton2_pt': hist.axis.Regular(40, -4., 4., name='var', label=r'sublead lepton ln($p_T$) [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'lepton1_eta': hist.axis.Regular(40, -4., 4., name='var', label=r'lead lepton $\\eta$', growth=False, underflow=False, overflow=False), \n",
    "    'lepton2_eta': hist.axis.Regular(40, -4., 4., name='var', label=r'sublead lepton $\\eta$', growth=False, underflow=False, overflow=False),\n",
    "    'lepton1_phi': hist.axis.Regular(40, -4., 4., name='var', label=r'lead lepton $\\phi$', growth=False, underflow=False, overflow=False), \n",
    "    'lepton2_phi': hist.axis.Regular(40, -4., 4., name='var', label=r'sublead lepton $\\phi$', growth=False, underflow=False, overflow=False),\n",
    "    # diphoton variables\n",
    "    'pt': hist.axis.Regular(40, -4., 4., name='var', label=r' $\\gamma\\gamma$ ln($p_{T}$) [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    'eta': hist.axis.Regular(40, -4., 4., name='var', label=r'$\\gamma\\gamma \\eta$', growth=False, underflow=False, overflow=False), \n",
    "    'phi': hist.axis.Regular(40, -4., 4., name='var', label=r'$\\gamma \\gamma \\phi$', growth=False, underflow=False, overflow=False),\n",
    "    # angular (cos) variables\n",
    "    'abs_CosThetaStar_CS': hist.axis.Regular(40, -4., 4., name='var', label=r'|cos$(\\theta_{CS})$|', growth=False, underflow=False, overflow=False), \n",
    "    'abs_CosThetaStar_jj': hist.axis.Regular(40, -4., 4., name='var', label=r'|cos$(\\theta_{jj})$|', growth=False, underflow=False, overflow=False), \n",
    "    'CosThetaStar_CS': hist.axis.Regular(40, -1., 1., name='var', label=r'cos$(\\theta_{CS})$', growth=False, underflow=False, overflow=False), \n",
    "    'CosThetaStar_jj': hist.axis.Regular(40, -1., 1., name='var', label=r'cos$(\\theta_{jj})$', growth=False, underflow=False, overflow=False), \n",
    "    # jet-lepton variables\n",
    "    'leadBjet_leadLepton': hist.axis.Regular(40, -4., 4., name='var', label=r'$\\Delta R(bjet_{lead}, l_{lead})$', growth=False, underflow=False, overflow=False), \n",
    "    'leadBjet_subleadLepton': hist.axis.Regular(40, -4., 4., name='var', label=r'$\\Delta R(bjet_{lead}, l_{sublead})$', growth=False, underflow=False, overflow=False), \n",
    "    'subleadBjet_leadLepton': hist.axis.Regular(40, -4., 4., name='var', label=r'$\\Delta R(bjet_{sublead}, l_{lead})$', growth=False, underflow=False, overflow=False), \n",
    "    'subleadBjet_subleadLepton': hist.axis.Regular(40, -4., 4., name='var', label=r'$\\Delta R(bjet_{sublead}, l_{sublead})$', growth=False, underflow=False, overflow=False),\n",
    "    # dijet variables (must be blinded on data)\n",
    "    'dijet_mass': hist.axis.Regular(40, -4., 4., name='var', label=r'ln($M_{jj}$) [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    # diphoton variables (must be blinded on data)\n",
    "    'mass': hist.axis.Regular(40, -4., 4., name='var', label=r'$M_{\\gamma\\gamma}$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    # Yibo's BDT variables\n",
    "    'lead_mvaID': hist.axis.Regular(50, -4., 4., name='var', label=r'$\\gamma_{lead}$ MVA ID', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_mvaID': hist.axis.Regular(50, -4., 4., name='var', label=r'$\\gamma_{sublead}$ MVA ID', growth=False, underflow=False, overflow=False),\n",
    "    'CosThetaStar_gg': hist.axis.Regular(50, -1., 1., name='var', label=r'cos$(\\theta_{gg})$', growth=False, underflow=False, overflow=False),\n",
    "    'lead_pt_over_Mgg': hist.axis.Regular(50, -4., 4., name='var', label=r'$p_{T,\\gamma_1} / M_{\\gamma\\gamma}$', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_pt_over_Mgg': hist.axis.Regular(50, -4., 4., name='var', label=r'$p_{T,\\gamma_2} / M_{\\gamma\\gamma}$', growth=False, underflow=False, overflow=False),\n",
    "    'lead_sigmaE_over_E': hist.axis.Regular(50, -4., 4., name='var', label=r'$\\gamma_1 \\sigma {E} / E$', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_sigmaE_over_E': hist.axis.Regular(50, -4., 4., name='var', label=r'$\\gamma_2 \\sigma {E} / E$', growth=False, underflow=False, overflow=False),\n",
    "    'lead_bjet_pt_over_Mjj': hist.axis.Regular(50, -4., 4., name='var', label=r'$p_{T,j1} / M_{jj}$', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_bjet_pt_over_Mjj': hist.axis.Regular(50, -4., 4., name='var', label=r'$p_{T,j2} / M_{jj}$', growth=False, underflow=False, overflow=False),\n",
    "    'lead_bjet_btagPNetB': hist.axis.Regular(50, -4., 4., name='var', label=r'$j_{lead}$ PNet btag score', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_bjet_btagPNetB': hist.axis.Regular(50, -4., 4., name='var', label=r'$j_{sublead}$ PNet btag score', growth=False, underflow=False, overflow=False),\n",
    "    'lead_bjet_sigmapT_over_pT': hist.axis.Regular(50, -4., 4., name='var', label=r'$j1 \\sigma p_{T} / p_{T}$', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_bjet_sigmapT_over_pT': hist.axis.Regular(50, -4., 4., name='var', label=r'$j2 \\sigma p_{T} / p_{T}$', growth=False, underflow=False, overflow=False),\n",
    "    'dipho_mass_over_Mggjj': hist.axis.Regular(50, -4., 4., name='var', label=r'$M_{\\gamma\\gamma} / M_{\\gamma\\gamma jj}$', growth=False, underflow=False, overflow=False), \n",
    "    'dijet_mass_over_Mggjj': hist.axis.Regular(50, -4., 4., name='var', label=r'$M_{jj} / M_{\\gamma\\gamma jj}$', growth=False, underflow=False, overflow=False),\n",
    "    # My variables for non-reso reduction #\n",
    "    'lead_pfRelIso03_all_quadratic': hist.axis.Regular(50, -4., 4., name='var', label=r'$\\gamma_{lead}$ PF RelIso03 all quad.', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_pfRelIso03_all_quadratic': hist.axis.Regular(50, -4., 4., name='var', label=r'$\\gamma_{sublead}$ PF RelIso03 all quad.', growth=False, underflow=False, overflow=False),\n",
    "    # Michael's DNN variables #\n",
    "    'DeltaR_j1g1': hist.axis.Regular(50, -4., 4., name='var', label=r'$\\Delta R(bjet_{lead}, \\gamma_{lead})$', growth=False, underflow=False, overflow=False), \n",
    "    'DeltaR_j1g2': hist.axis.Regular(50, -4., 4., name='var', label=r'$\\Delta R(bjet_{lead}, \\gamma_{sublead})$', growth=False, underflow=False, overflow=False), \n",
    "    'DeltaR_j2g1': hist.axis.Regular(50, -4., 4., name='var', label=r'$\\Delta R(bjet_{sublead}, \\gamma_{lead})$', growth=False, underflow=False, overflow=False), \n",
    "    'DeltaR_j2g2': hist.axis.Regular(50, -4., 4., name='var', label=r'$\\Delta R(bjet_{sublead}, \\gamma_{sublead})$', growth=False, underflow=False, overflow=False),\n",
    "    'HHbbggCandidate_pt': hist.axis.Regular(100, -4., 4., name='var', label=r'HH ln($p_T$) [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'HHbbggCandidate_eta': hist.axis.Regular(50, -4., 4., name='var', label=r'HH $\\eta$', growth=False, underflow=False, overflow=False), \n",
    "    'HHbbggCandidate_phi': hist.axis.Regular(50, -4., 4., name='var', label=r'HH $\\phi$', growth=False, underflow=False, overflow=False),\n",
    "    'HHbbggCandidate_mass': hist.axis.Regular(50, -4., 4., name='var', label=r'ln($M_{HH}$) [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    # ATLAS variables #\n",
    "    'pt_balance': hist.axis.Regular(100, -4., 4., name='var', label=r'ln($p_{T,HH} / (p_{T,\\gamma1} + p_{T,\\gamma2} + p_{T,j1} + p_{T,j2})$)', growth=False, underflow=False, overflow=False), \n",
    "    # VH variables #\n",
    "    'DeltaPhi_jj': hist.axis.Regular(20, -4., 4., name='var', label=r'$\\Delta\\phi (j_1,j_2)$', growth=False, underflow=False, overflow=False),\n",
    "    'DeltaEta_jj': hist.axis.Regular(20, -4., 4., name='var', label=r'$\\Delta\\eta (j_1,j_2)$', growth=False, underflow=False, overflow=False),\n",
    "    'isr_jet_pt': hist.axis.Regular(100, -4., 4., name='var', label=r'ISR jet ln($p_T$) [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    'DeltaPhi_isr_jet_z': hist.axis.Regular(20, -4., 4., name='var', label=r'$\\Delta\\phi (j_{ISR},jj)$', growth=False, underflow=False, overflow=False),\n",
    "    'dijet_pt': hist.axis.Regular(100, -4., 4., name='var', label=r'jj ln($p_T$) [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    'lepton1_pfIsoId': hist.axis.Regular(50, -4., 4., name='var', label=r'$l_{lead}$ PF IsoId', growth=False, underflow=False, overflow=False), \n",
    "    'lepton1_mvaID': hist.axis.Regular(50, -4., 4., name='var', label=r'$l_{lead}$ MVA ID', growth=False, underflow=False, overflow=False), \n",
    "}\n",
    "\n",
    "\n",
    "def make_input_plot(\n",
    "    output_dir, var_name, hist_list, fold_idx=None, labels=None, density=True, \n",
    "    plot_prefix='', plot_postfix='', alpha=0.7, num_compare=1, log=False\n",
    "):\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    if num_compare > 1:\n",
    "        unique_linestyles = [\"solid\", \"dashed\", \"dotted\", \"dashdot\"]\n",
    "        linestyles = unique_linestyles[:num_compare]\n",
    "        linestyles = linestyles * ((len(hist_list) // len(linestyles)) + 1)\n",
    "        linestyles = linestyles[:len(hist_list)]\n",
    "        \n",
    "        colors = [cmap for cmap in cmap_petroff10 for _ in range(0, num_compare)]\n",
    "        colors = colors[:len(hist_list)]\n",
    "        hep.histplot(\n",
    "            hist_list, ax=ax, linewidth=3, histtype=\"step\", yerr=True, density=density,\n",
    "            linestyle=linestyles, label=labels, alpha=alpha, color=colors\n",
    "        )\n",
    "    else:\n",
    "        hep.histplot(\n",
    "            hist_list, ax=ax, linewidth=3, histtype=\"step\", yerr=True, density=density,\n",
    "            label=labels, alpha=alpha\n",
    "        )\n",
    "\n",
    "    # Plotting niceties #\n",
    "    hep.cms.lumitext(f\"{LUMINOSITIES['total_lumi']:.2f}\" + r\"fb$^{-1}$ (13.6 TeV)\", ax=ax)\n",
    "    hep.cms.text(\"Work in Progress\", ax=ax)\n",
    "    # Plot legend properly\n",
    "    ax.legend(bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "    if log:\n",
    "        ax.set_yscale('log')\n",
    "\n",
    "    if fold_idx is not None:\n",
    "        plt.savefig(f'{output_dir}/{plot_prefix}1dhist_{var_name}{plot_postfix}_fold{fold_idx}.pdf', bbox_inches='tight')\n",
    "        plt.savefig(f'{output_dir}/{plot_prefix}1dhist_{var_name}{plot_postfix}_fold{fold_idx}.png', bbox_inches='tight')\n",
    "    else:\n",
    "        plt.savefig(f'{output_dir}/{plot_prefix}1dhist_{var_name}{plot_postfix}.pdf', bbox_inches='tight')\n",
    "        plt.savefig(f'{output_dir}/{plot_prefix}1dhist_{var_name}{plot_postfix}.png', bbox_inches='tight')\n",
    "\n",
    "    plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss per Epoch Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"losses\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "if 'BDT_perf' not in globals():\n",
    "    with open(os.path.join(OUTPUT_DIRPATH, CURRENT_TIME+\"_BDT_perf.json\"), 'r') as f:\n",
    "        BDT_perf = json.load(f)\n",
    "\n",
    "if 'evals_result_dict' not in globals():\n",
    "    with open(os.path.join(OUTPUT_DIRPATH, CURRENT_TIME+\"_BDT_eval_result.json\"), 'r') as f:\n",
    "        evals_result_dict = json.load(f)\n",
    "\n",
    "# plot train/val/test losses\n",
    "all_train, all_val, all_test = [], [], []\n",
    "for fold_idx in range(len(evals_result_dict)):\n",
    "    all_train.append(evals_result_dict[f\"fold_{fold_idx}\"]['train']['mlogloss'])\n",
    "    all_val.append(evals_result_dict[f\"fold_{fold_idx}\"]['val']['mlogloss'])\n",
    "    all_test.append(evals_result_dict[f\"fold_{fold_idx}\"]['test']['mlogloss'])\n",
    "\n",
    "plot_train_val_losses(\n",
    "    all_train + all_val, [f'train fold {i}' for i in range(len(all_train))]+[f'val fold {i}' for i in range(len(all_val))],\n",
    "    'train_val_losses_vs_epoch', plot_dirpath, \n",
    "    linestyles=['solid']*len(all_train) + ['dashed']*len(all_val),\n",
    ")\n",
    "plot_train_val_losses(\n",
    "    all_train + all_test, [f'train fold {i}' for i in range(len(all_train))]+[f'test fold {i}' for i in range(len(all_test))],\n",
    "    'train_test_losses_vs_epoch', plot_dirpath,\n",
    "    linestyles=['solid']*len(all_train) + ['dotted']*len(all_test),\n",
    ")\n",
    "avg_train, avg_val, avg_test = np.mean(pad_list(all_train), axis=0), np.mean(pad_list(all_val), axis=0), np.mean(pad_list(all_test), axis=0)\n",
    "std_train, std_val, std_test = np.std(pad_list(all_train), axis=0), np.std(pad_list(all_val), axis=0), np.std(pad_list(all_test), axis=0)\n",
    "plot_train_val_losses(\n",
    "    [avg_train, avg_val, avg_test], ['train avg', 'val avg', 'test avg'],\n",
    "    'train_val_test_avg_vs_epoch', plot_dirpath,\n",
    "    losses_std_arrs=[std_train, std_val, std_test],\n",
    "    linestyles=['solid', 'dashed', 'dotted'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"ROCs\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "if 'BDT_perf' not in globals():\n",
    "    with open(os.path.join(OUTPUT_DIRPATH, CURRENT_TIME+\"_BDT_perf.json\"), 'r') as f:\n",
    "        BDT_perf = json.load(f)\n",
    "\n",
    "base_tpr = np.array(BDT_perf['ggF HH']['base_tpr'])\n",
    "\n",
    "# plot ROCs\n",
    "for j, sample_name in enumerate(order):\n",
    "\n",
    "    for fold_idx in range(len(bdt_train_dict)):\n",
    "\n",
    "        for roc_type in ['density', 'weighted']:\n",
    "\n",
    "            fprs = [np.array(BDT_perf[sample_name][f'fprs_{roc_type}'][fold_idx])[:, i] for i in range(len(order))]\n",
    "            tprs = [base_tpr for _ in range(len(order))]\n",
    "            labels = [\n",
    "                f\"{sample_name} vs. {'all' if i == j else sample_name_}, AUC = {BDT_perf[sample_name][f'areas_{roc_type}'][fold_idx][i]:.4f}\" \n",
    "                for i, sample_name_ in enumerate(order)\n",
    "            ]\n",
    "\n",
    "            # plot_rocs(fprs, tprs, labels, f\"BDT_roc_{sample_name}_{roc_type}_testData_fold{fold_idx}\", plot_dirpath)\n",
    "            plot_rocs(fprs, tprs, labels, f\"BDT_logroc_{sample_name}_{roc_type}_testData_fold{fold_idx}\", plot_dirpath, log='x')\n",
    "\n",
    "\n",
    "    for roc_type in ['sum_density', 'sum_weighted']:\n",
    "\n",
    "        fprs = [np.array(BDT_perf[sample_name][f'fprs_{roc_type}'])[:, i] for i in range(len(order))]\n",
    "        tprs = [base_tpr for _ in range(len(order))]\n",
    "        labels = [\n",
    "            f\"{sample_name} vs. {'all' if i == j else sample_name_}, AUC = {BDT_perf[sample_name][f'areas_{roc_type}'][i]:.4f}\" \n",
    "            for i, sample_name_ in enumerate(order)\n",
    "        ]\n",
    "\n",
    "        # plot_rocs(fprs, tprs, labels, f\"BDT_roc_{sample_name}_{roc_type}_testData_sum\", plot_dirpath)\n",
    "        plot_rocs(fprs, tprs, labels, f\"BDT_logroc_{sample_name}_{roc_type}_testData_sum\", plot_dirpath, log='x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:16:25] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:16:31] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:16:37] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:16:42] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:16:51] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"2D_ROCs\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "\n",
    "base_tpr = np.linspace(0, 1, 5000)\n",
    "\n",
    "preds, truths, weights = {sample_name: list() for sample_name in order}, {sample_name: list() for sample_name in order}, {sample_name: list() for sample_name in order}\n",
    "\n",
    "# plot ROCs\n",
    "for fold_idx in range(len(bdt_train_dict)):\n",
    "    booster = xgb.Booster(param)\n",
    "    booster.load_model(os.path.join(OUTPUT_DIRPATH, f'{CURRENT_TIME}_BDT_fold{fold_idx}.model'))\n",
    "\n",
    "    fold_fprs_tth, fold_tprs_tth, fold_thresholds_tth, fold_auc_tth = [], [], [], []\n",
    "    fold_fprs_qcd, fold_tprs_qcd, fold_thresholds_qcd, fold_auc_qcd = [], [], [], []\n",
    "\n",
    "    for j, sample_name in enumerate(order):\n",
    "\n",
    "        if j == 0:\n",
    "            event_mask = (bdt_test_dict[f\"fold_{fold_idx}\"].get_label() > -1)\n",
    "        else:\n",
    "            event_mask = np.logical_or(\n",
    "                bdt_test_dict[f\"fold_{fold_idx}\"].get_label() == 0,\n",
    "                bdt_test_dict[f\"fold_{fold_idx}\"].get_label() == j\n",
    "            )\n",
    "\n",
    "        full_preds = booster.predict(\n",
    "            bdt_test_dict[f\"fold_{fold_idx}\"], iteration_range=(0, booster.best_iteration+1)\n",
    "        )[event_mask]\n",
    "        preds[sample_name].extend(full_preds.tolist())\n",
    "\n",
    "        tth_preds = get_ttH_score(full_preds)\n",
    "        qcd_preds = get_QCD_score(full_preds)\n",
    "\n",
    "        signal_truths = (bdt_test_dict[f\"fold_{fold_idx}\"].get_label() == 0)[event_mask]\n",
    "        truths[sample_name].extend(bdt_test_dict[f\"fold_{fold_idx}\"].get_label()[event_mask].tolist())\n",
    "\n",
    "        weights[sample_name].extend(weights_plot_test[f\"fold_{fold_idx}\"][event_mask].tolist())\n",
    "\n",
    "        fpr_tth, tpr_tth, threshold_tth = roc_curve(signal_truths, tth_preds, sample_weight=weights_plot_test[f\"fold_{fold_idx}\"][event_mask])\n",
    "        fpr_qcd, tpr_qcd, threshold_qcd = roc_curve(signal_truths, qcd_preds, sample_weight=weights_plot_test[f\"fold_{fold_idx}\"][event_mask])\n",
    "\n",
    "        fpr_tth = np.interp(base_tpr, tpr_tth, fpr_tth)\n",
    "        threshold_tth = np.interp(base_tpr, tpr_tth, threshold_tth)\n",
    "        auc_tth = float(trapezoid(base_tpr, fpr_tth))\n",
    "\n",
    "        fpr_qcd = np.interp(base_tpr, tpr_qcd, fpr_qcd)\n",
    "        threshold_qcd = np.interp(base_tpr, tpr_qcd, threshold_qcd)\n",
    "        auc_qcd = float(trapezoid(base_tpr, fpr_qcd))\n",
    "\n",
    "        fold_fprs_tth.append(fpr_tth)\n",
    "        fold_tprs_tth.append(base_tpr)\n",
    "        fold_thresholds_tth.append(threshold_tth)\n",
    "        fold_auc_tth.append(auc_tth)\n",
    "\n",
    "        fold_fprs_qcd.append(fpr_qcd)\n",
    "        fold_tprs_qcd.append(base_tpr)\n",
    "        fold_thresholds_qcd.append(threshold_qcd)\n",
    "        fold_auc_qcd.append(auc_qcd)\n",
    "\n",
    "    labels_tth = [\n",
    "        f\"{sample_name} DttH, AUC = {fold_auc_tth[i]:.4f}\" \n",
    "        for i, sample_name in enumerate(order)\n",
    "    ]\n",
    "    labels_qcd = [\n",
    "        f\"{sample_name} DQCD, AUC = {fold_auc_qcd[i]:.4f}\" \n",
    "        for i, sample_name in enumerate(order)\n",
    "    ]\n",
    "\n",
    "    plot_rocs(fold_fprs_tth, fold_tprs_tth, labels_tth, f\"DttH_logroc_weighted_fold{fold_idx}\", plot_dirpath, log='x')\n",
    "    plot_rocs(fold_fprs_qcd, fold_tprs_qcd, labels_qcd, f\"DQCD_logroc_weighted_fold{fold_idx}\", plot_dirpath, log='x')\n",
    "\n",
    "fprs_tth, tprs_tth, thresholds_tth, aucs_tth = [], [], [], []\n",
    "fprs_qcd, tprs_qcd, thresholds_qcd, aucs_qcd = [], [], [], []\n",
    "for j, sample_name in enumerate(order):\n",
    "\n",
    "    tth_preds = get_ttH_score(np.array(preds[sample_name]))\n",
    "    qcd_preds = get_QCD_score(np.array(preds[sample_name]))\n",
    "\n",
    "    signal_truths = (np.array(truths[sample_name]) == 0)\n",
    "\n",
    "    fpr_tth, tpr_tth, threshold_tth = roc_curve(signal_truths, tth_preds, sample_weight=np.array(weights[sample_name]))\n",
    "    fpr_qcd, tpr_qcd, threshold_qcd = roc_curve(signal_truths, qcd_preds, sample_weight=np.array(weights[sample_name]))\n",
    "\n",
    "    fpr_tth = np.interp(base_tpr, tpr_tth, fpr_tth)\n",
    "    threshold_tth = np.interp(base_tpr, tpr_tth, threshold_tth)\n",
    "    auc_tth = float(trapezoid(base_tpr, fpr_tth))\n",
    "\n",
    "    fpr_qcd = np.interp(base_tpr, tpr_qcd, fpr_qcd)\n",
    "    threshold_qcd = np.interp(base_tpr, tpr_qcd, threshold_qcd)\n",
    "    auc_qcd = float(trapezoid(base_tpr, fpr_qcd))\n",
    "\n",
    "    fprs_tth.append(fpr_tth)\n",
    "    tprs_tth.append(base_tpr)\n",
    "    thresholds_tth.append(threshold_tth)\n",
    "    aucs_tth.append(auc_tth)\n",
    "\n",
    "    fprs_qcd.append(fpr_qcd)\n",
    "    tprs_qcd.append(base_tpr)\n",
    "    thresholds_qcd.append(threshold_qcd)\n",
    "    aucs_qcd.append(auc_qcd)\n",
    "\n",
    "labels_tth = [\n",
    "    f\"{sample_name} DttH, AUC = {fold_auc_tth[i]:.4f}\" \n",
    "    for i, sample_name in enumerate(order)\n",
    "]\n",
    "labels_qcd = [\n",
    "    f\"{sample_name} DQCD, AUC = {fold_auc_qcd[i]:.4f}\" \n",
    "    for i, sample_name in enumerate(order)\n",
    "]\n",
    "\n",
    "plot_rocs(fprs_tth, tprs_tth, labels_tth, f\"DttH_logroc_weighted_sum\", plot_dirpath, log='x')\n",
    "plot_rocs(fprs_qcd, tprs_qcd, labels_qcd, f\"DQCD_logroc_weighted_sum\", plot_dirpath, log='x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Score Dist Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"output_scores\")\n",
    "# plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"output_scores_arctanh\")\n",
    "# plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"output_scores_resample\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "if 'BDT_perf' not in globals():\n",
    "    with open(os.path.join(OUTPUT_DIRPATH, CURRENT_TIME+\"_BDT_perf.json\"), 'r') as f:\n",
    "        BDT_perf = json.load(f)\n",
    "\n",
    "# plot Output scores\n",
    "for j, sample_name in enumerate(order):\n",
    "\n",
    "    for i, sample_name_ in enumerate(order):\n",
    "\n",
    "        for fold_idx in range(len(bdt_train_dict)):\n",
    "            \n",
    "            sigs_and_bkgs = {\n",
    "                sample_name__: np.array(BDT_perf[sample_name]['preds'][fold_idx])[:, j][bdt_test_dict[f\"fold_{fold_idx}\"].get_label() == k]\n",
    "                for k, sample_name__ in enumerate(order)\n",
    "            }\n",
    "            score_weights = {\n",
    "                sample_name__: weights_plot_test[f\"fold_{fold_idx}\"][bdt_test_dict[f\"fold_{fold_idx}\"].get_label() == k]\n",
    "                for k, sample_name__ in enumerate(order)\n",
    "            }\n",
    "\n",
    "            if sample_name_ != sample_name:\n",
    "                event_j_mask = bdt_test_dict[f\"fold_{fold_idx}\"].get_label() == j\n",
    "                pred_j_rescale = np.array(BDT_perf[sample_name]['preds'][fold_idx])[:, j][event_j_mask] + np.array(BDT_perf[sample_name]['preds'][fold_idx])[:, i][event_j_mask]\n",
    "                event_i_mask = bdt_test_dict[f\"fold_{fold_idx}\"].get_label() == i\n",
    "                pred_i_rescale = np.array(BDT_perf[sample_name]['preds'][fold_idx])[:, j][event_i_mask] + np.array(BDT_perf[sample_name]['preds'][fold_idx])[:, i][event_i_mask]\n",
    "\n",
    "                for sample_name__ in order:\n",
    "                    if sample_name__ == sample_name:\n",
    "                        sigs_and_bkgs[sample_name__] = sigs_and_bkgs[sample_name__] / pred_j_rescale\n",
    "                    elif sample_name__ == sample_name_:\n",
    "                        sigs_and_bkgs[sample_name__] = sigs_and_bkgs[sample_name__] / pred_i_rescale\n",
    "                    else:\n",
    "                        del sigs_and_bkgs[sample_name__]\n",
    "                        del score_weights[sample_name__]\n",
    "\n",
    "            if re.search('arctanh', plot_dirpath) is not None:\n",
    "                for key, value in sigs_and_bkgs.items():\n",
    "                    sigs_and_bkgs[key] = np.arctanh(value)\n",
    "\n",
    "            plot_output_scores(\n",
    "                sigs_and_bkgs, order, \n",
    "                f\"BDT_{sample_name}_vs_{sample_name_ if sample_name_ != sample_name else 'all'}_outputScoreWeighted_testData_fold{fold_idx}\", \n",
    "                plot_dirpath, weights=score_weights, log=True,\n",
    "                arctanh=True if re.search('arctanh', plot_dirpath) is not None else False\n",
    "            )\n",
    "            plot_output_scores(\n",
    "                sigs_and_bkgs, order, \n",
    "                f\"BDT_{sample_name}_vs_{sample_name_ if sample_name_ != sample_name else 'all'}_outputScoreDensity_testData_fold{fold_idx}\", \n",
    "                plot_dirpath, log=True,\n",
    "                arctanh=True if re.search('arctanh', plot_dirpath) is not None else False\n",
    "            )\n",
    "\n",
    "        flat_preds = np.concatenate([BDT_perf[sample_name]['preds'][fold_idx] for fold_idx in range(len(bdt_test_dict))], axis=0)\n",
    "        if re.search('arctanh', plot_dirpath) is not None:\n",
    "            flat_preds = np.arctanh(flat_preds)\n",
    "        flat_truths = np.concatenate([bdt_test_dict[f\"fold_{fold_idx}\"].get_label() for fold_idx in range(len(bdt_test_dict))], axis=0)\n",
    "        flat_weights = np.concatenate([weights_plot_test[f\"fold_{fold_idx}\"] for fold_idx in range(len(bdt_test_dict))], axis=0)\n",
    "\n",
    "        sigs_and_bkgs = {\n",
    "            sample_name__: flat_preds[:, j][flat_truths == k]\n",
    "            for k, sample_name__ in enumerate(order)\n",
    "        }\n",
    "        score_weights = {\n",
    "            sample_name__: flat_weights[flat_truths == k]\n",
    "            for k, sample_name__ in enumerate(order)\n",
    "        }\n",
    "        \n",
    "        if sample_name_ != sample_name:\n",
    "            event_j_mask = flat_truths == j\n",
    "            pred_j_rescale = (flat_preds[:, j] + flat_preds[:, i])[event_j_mask]\n",
    "            event_i_mask = flat_truths == i\n",
    "            pred_i_rescale = (flat_preds[:, j] + flat_preds[:, i])[event_i_mask]\n",
    "\n",
    "            for sample_name__ in order:\n",
    "                if sample_name__ == sample_name:\n",
    "                    sigs_and_bkgs[sample_name__] = sigs_and_bkgs[sample_name__] / pred_j_rescale\n",
    "                elif sample_name__ == sample_name_:\n",
    "                    sigs_and_bkgs[sample_name__] = sigs_and_bkgs[sample_name__] / pred_i_rescale\n",
    "                else:\n",
    "                    del sigs_and_bkgs[sample_name__]\n",
    "                    del score_weights[sample_name__]\n",
    "        \n",
    "        plot_output_scores(\n",
    "            sigs_and_bkgs, order, \n",
    "            f\"BDT_{sample_name}_vs_{sample_name_ if sample_name_ != sample_name else 'all'}_outputScoreWeighted_testData_sum\", \n",
    "            plot_dirpath, weights=score_weights, log=True,\n",
    "            arctanh=True if re.search('arctanh', plot_dirpath) is not None else False\n",
    "        )\n",
    "        plot_output_scores(\n",
    "            sigs_and_bkgs, order, \n",
    "            f\"BDT_{sample_name}_vs_{sample_name_ if sample_name_ != sample_name else 'all'}_outputScoreDensity_testData_sum\", \n",
    "            plot_dirpath, log=True,\n",
    "            arctanh=True if re.search('arctanh', plot_dirpath) is not None else False\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:31:40] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:31:50] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:31:59] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:32:09] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:32:19] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"2D_output_scores\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "\n",
    "tth_preds, qcd_preds, weights = {sample_name: list() for sample_name in order}, {sample_name: list() for sample_name in order}, {sample_name: list() for sample_name in order}\n",
    "\n",
    "# plot ROCs\n",
    "for fold_idx in range(len(bdt_train_dict)):\n",
    "    booster = xgb.Booster(param)\n",
    "    booster.load_model(os.path.join(OUTPUT_DIRPATH, f'{CURRENT_TIME}_BDT_fold{fold_idx}.model'))\n",
    "\n",
    "    fold_tth_preds, fold_qcd_preds, fold_weights = {}, {}, {}\n",
    "\n",
    "    for j, sample_name in enumerate(order):\n",
    "\n",
    "        event_mask = (bdt_test_dict[f\"fold_{fold_idx}\"].get_label() == j)\n",
    "\n",
    "        full_preds = booster.predict(\n",
    "            bdt_test_dict[f\"fold_{fold_idx}\"], iteration_range=(0, booster.best_iteration+1)\n",
    "        )[event_mask]\n",
    "\n",
    "        tth_preds_sample = get_ttH_score(full_preds)\n",
    "        qcd_preds_sample = get_QCD_score(full_preds)\n",
    "\n",
    "        fold_tth_preds[sample_name] = tth_preds_sample\n",
    "        fold_qcd_preds[sample_name] = qcd_preds_sample\n",
    "        tth_preds[sample_name].extend(tth_preds_sample.tolist())\n",
    "        qcd_preds[sample_name].extend(qcd_preds_sample.tolist())\n",
    "\n",
    "        fold_weights[sample_name] = weights_plot_test[f\"fold_{fold_idx}\"][event_mask]\n",
    "        weights[sample_name].extend(weights_plot_test[f\"fold_{fold_idx}\"][event_mask].tolist())\n",
    "\n",
    "    plot_output_scores(\n",
    "        fold_tth_preds, order, \n",
    "        f\"DttH_outputScoreDensity_testData_fold{fold_idx}\", \n",
    "        plot_dirpath, log=True,\n",
    "        arctanh=True if re.search('arctanh', plot_dirpath) is not None else False\n",
    "    )\n",
    "    plot_output_scores(\n",
    "        fold_tth_preds, order, \n",
    "        f\"DttH_outputScoreWeighted_testData_fold{fold_idx}\", \n",
    "        plot_dirpath, weights=fold_weights, log=True,\n",
    "        arctanh=True if re.search('arctanh', plot_dirpath) is not None else False\n",
    "    )\n",
    "    plot_output_scores(\n",
    "        fold_qcd_preds, order, \n",
    "        f\"DQCD_outputScoreDensity_testData_fold{fold_idx}\", \n",
    "        plot_dirpath, log=True,\n",
    "        arctanh=True if re.search('arctanh', plot_dirpath) is not None else False\n",
    "    )\n",
    "    plot_output_scores(\n",
    "        fold_qcd_preds, order, \n",
    "        f\"DQCD_outputScoreWeighted_testData_fold{fold_idx}\", \n",
    "        plot_dirpath, weights=fold_weights, log=True,\n",
    "        arctanh=True if re.search('arctanh', plot_dirpath) is not None else False\n",
    "    )\n",
    "    \n",
    "np_tth_preds = {key: np.array(value) for key, value in tth_preds.items()}\n",
    "np_qcd_preds = {key: np.array(value) for key, value in qcd_preds.items()}\n",
    "np_weights = {key: np.array(value) for key, value in weights.items()}\n",
    "\n",
    "plot_output_scores(\n",
    "    np_tth_preds, order, \n",
    "    f\"DttH_outputScoreDensity_testData_sum\", \n",
    "    plot_dirpath, log=True,\n",
    "    arctanh=True if re.search('arctanh', plot_dirpath) is not None else False\n",
    ")\n",
    "plot_output_scores(\n",
    "    np_tth_preds, order, \n",
    "    f\"DttH_outputScoreWeighted_testData_sum\", \n",
    "    plot_dirpath, weights=np_weights, log=True,\n",
    "    arctanh=True if re.search('arctanh', plot_dirpath) is not None else False\n",
    ")\n",
    "plot_output_scores(\n",
    "    np_qcd_preds, order, \n",
    "    f\"DQCD_outputScoreDensity_testData_sum\", \n",
    "    plot_dirpath, log=True,\n",
    "    arctanh=True if re.search('arctanh', plot_dirpath) is not None else False\n",
    ")\n",
    "plot_output_scores(\n",
    "    np_qcd_preds, order, \n",
    "    f\"DQCD_outputScoreWeighted_testData_sum\", \n",
    "    plot_dirpath, weights=np_weights, log=True,\n",
    "    arctanh=True if re.search('arctanh', plot_dirpath) is not None else False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### s/âb Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "============================================================\n",
      "Cat1: 0.9966 < ggF HH score â¤ 1.0000 AND 120 GeV < m_HH < 130 GeV\n",
      "------------------------------------------------------------\n",
      "Cat1: Num ggF HH = 0.2444\n",
      "------------------------------------------------------------\n",
      "Cat1: Num ttH + bbH = 0.0303\n",
      "------------------------------------------------------------\n",
      "Cat1: Num VH = 0.2686\n",
      "------------------------------------------------------------\n",
      "Cat1: Num VH, no ZH or WH = 0.1594\n",
      "------------------------------------------------------------\n",
      "Cat1: Num non-res + ggFH + VBFH = 0.7287\n",
      "------------------------------------------------------------\n",
      "Cat1: Num GluGluHToGG = 0.0934\n",
      "------------------------------------------------------------\n",
      "Cat1: Num VBFHToGG = 0.0112\n",
      "------------------------------------------------------------\n",
      "Cat1: Num GGJets = 0.6241\n",
      "------------------------------------------------------------\n",
      "Cat1: Num GJetPt20To40 = 0.0000\n",
      "------------------------------------------------------------\n",
      "Cat1: Num GJetPt40 = 0.0000\n",
      "------------------------------------------------------------\n",
      "Cat1: S = 0.2444, B = 1.0276, S/âB = 0.2411\n",
      "============================================================\n",
      "============================================================\n",
      "Cat2: 0.9920 < ggF HH score â¤ 0.9966 AND 120 GeV < m_HH < 130 GeV\n",
      "------------------------------------------------------------\n",
      "Cat2: Num ggF HH = 0.3077\n",
      "------------------------------------------------------------\n",
      "Cat2: Num ttH + bbH = 0.1338\n",
      "------------------------------------------------------------\n",
      "Cat2: Num VH = 0.5143\n",
      "------------------------------------------------------------\n",
      "Cat2: Num VH, no ZH or WH = 0.2898\n",
      "------------------------------------------------------------\n",
      "Cat2: Num non-res + ggFH + VBFH = 2.7751\n",
      "------------------------------------------------------------\n",
      "Cat2: Num GluGluHToGG = 0.2720\n",
      "------------------------------------------------------------\n",
      "Cat2: Num VBFHToGG = 0.0339\n",
      "------------------------------------------------------------\n",
      "Cat2: Num GGJets = 2.4692\n",
      "------------------------------------------------------------\n",
      "Cat2: Num GJetPt20To40 = 0.0000\n",
      "------------------------------------------------------------\n",
      "Cat2: Num GJetPt40 = 0.0000\n",
      "------------------------------------------------------------\n",
      "Cat2: S = 0.3077, B = 3.4232, S/âB = 0.1663\n",
      "============================================================\n",
      "============================================================\n",
      "Cat3: 0.9819 < ggF HH score â¤ 0.9920 AND 120 GeV < m_HH < 130 GeV\n",
      "------------------------------------------------------------\n",
      "Cat3: Num ggF HH = 0.2605\n",
      "------------------------------------------------------------\n",
      "Cat3: Num ttH + bbH = 0.3252\n",
      "------------------------------------------------------------\n",
      "Cat3: Num VH = 0.4896\n",
      "------------------------------------------------------------\n",
      "Cat3: Num VH, no ZH or WH = 0.3421\n",
      "------------------------------------------------------------\n",
      "Cat3: Num non-res + ggFH + VBFH = 7.3385\n",
      "------------------------------------------------------------\n",
      "Cat3: Num GluGluHToGG = 0.4545\n",
      "------------------------------------------------------------\n",
      "Cat3: Num VBFHToGG = 0.0552\n",
      "------------------------------------------------------------\n",
      "Cat3: Num GGJets = 6.8288\n",
      "------------------------------------------------------------\n",
      "Cat3: Num GJetPt20To40 = 0.0000\n",
      "------------------------------------------------------------\n",
      "Cat3: Num GJetPt40 = 0.0000\n",
      "------------------------------------------------------------\n",
      "Cat3: S = 0.2605, B = 8.1533, S/âB = 0.0912\n",
      "============================================================\n",
      "============================================================\n",
      "Cat1: 0.9966 < ggF HH score â¤ 1.0000\n",
      "------------------------------------------------------------\n",
      "Cat1: Num ggF HH = 0.2537\n",
      "------------------------------------------------------------\n",
      "Cat1: Num ttH + bbH = 0.0321\n",
      "------------------------------------------------------------\n",
      "Cat1: Num VH = 0.2761\n",
      "------------------------------------------------------------\n",
      "Cat1: Num VH, no ZH or WH = 0.1632\n",
      "------------------------------------------------------------\n",
      "Cat1: Num non-res + ggFH + VBFH = 12.5027\n",
      "------------------------------------------------------------\n",
      "Cat1: Num GluGluHToGG = 0.0958\n",
      "------------------------------------------------------------\n",
      "Cat1: Num VBFHToGG = 0.0115\n",
      "------------------------------------------------------------\n",
      "Cat1: Num GGJets = 11.5208\n",
      "------------------------------------------------------------\n",
      "Cat1: Num GJetPt20To40 = 0.0000\n",
      "------------------------------------------------------------\n",
      "Cat1: Num GJetPt40 = 0.8746\n",
      "------------------------------------------------------------\n",
      "Cat1: S = 0.2537, B = 12.8108, S/âB = 0.0709\n",
      "============================================================\n",
      "============================================================\n",
      "Cat2: 0.9920 < ggF HH score â¤ 0.9966\n",
      "------------------------------------------------------------\n",
      "Cat2: Num ggF HH = 0.3236\n",
      "------------------------------------------------------------\n",
      "Cat2: Num ttH + bbH = 0.1420\n",
      "------------------------------------------------------------\n",
      "Cat2: Num VH = 0.5429\n",
      "------------------------------------------------------------\n",
      "Cat2: Num VH, no ZH or WH = 0.3049\n",
      "------------------------------------------------------------\n",
      "Cat2: Num non-res + ggFH + VBFH = 48.3101\n",
      "------------------------------------------------------------\n",
      "Cat2: Num GluGluHToGG = 0.2812\n",
      "------------------------------------------------------------\n",
      "Cat2: Num VBFHToGG = 0.0364\n",
      "------------------------------------------------------------\n",
      "Cat2: Num GGJets = 39.1502\n",
      "------------------------------------------------------------\n",
      "Cat2: Num GJetPt20To40 = 0.0000\n",
      "------------------------------------------------------------\n",
      "Cat2: Num GJetPt40 = 8.8423\n",
      "------------------------------------------------------------\n",
      "Cat2: S = 0.3236, B = 48.9950, S/âB = 0.0462\n",
      "============================================================\n",
      "============================================================\n",
      "Cat3: 0.9819 < ggF HH score â¤ 0.9920\n",
      "------------------------------------------------------------\n",
      "Cat3: Num ggF HH = 0.2750\n",
      "------------------------------------------------------------\n",
      "Cat3: Num ttH + bbH = 0.3479\n",
      "------------------------------------------------------------\n",
      "Cat3: Num VH = 0.5234\n",
      "------------------------------------------------------------\n",
      "Cat3: Num VH, no ZH or WH = 0.3651\n",
      "------------------------------------------------------------\n",
      "Cat3: Num non-res + ggFH + VBFH = 148.3475\n",
      "------------------------------------------------------------\n",
      "Cat3: Num GluGluHToGG = 0.4783\n",
      "------------------------------------------------------------\n",
      "Cat3: Num VBFHToGG = 0.0598\n",
      "------------------------------------------------------------\n",
      "Cat3: Num GGJets = 101.9997\n",
      "------------------------------------------------------------\n",
      "Cat3: Num GJetPt20To40 = 0.0000\n",
      "------------------------------------------------------------\n",
      "Cat3: Num GJetPt40 = 45.8096\n",
      "------------------------------------------------------------\n",
      "Cat3: S = 0.2750, B = 149.2188, S/âB = 0.0225\n"
     ]
    }
   ],
   "source": [
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"s_over_rootb\")\n",
    "# plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"s_over_rootb_arctanh\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "if 'BDT_perf' not in globals():\n",
    "    with open(os.path.join(OUTPUT_DIRPATH, CURRENT_TIME+\"_BDT_perf.json\"), 'r') as f:\n",
    "        BDT_perf = json.load(f)\n",
    "\n",
    "# plot s/âb curves\n",
    "for j, sample_name in enumerate(order):\n",
    "\n",
    "    for i, sample_name_ in enumerate(order):\n",
    "\n",
    "        for fold_idx in range(len(BDT_perf['ggF HH']['preds'])):\n",
    "\n",
    "            if sample_name_ == sample_name:\n",
    "                sig_mask = bdt_test_dict[f\"fold_{fold_idx}\"].get_label() == j\n",
    "                bkg_mask = bdt_test_dict[f\"fold_{fold_idx}\"].get_label() != j\n",
    "\n",
    "                sig_rescale = np.ones_like(sig_mask)\n",
    "                bkg_rescale = np.ones_like(bkg_mask)\n",
    "            else:\n",
    "                sig_mask = bdt_test_dict[f\"fold_{fold_idx}\"].get_label() == j\n",
    "                bkg_mask = bdt_test_dict[f\"fold_{fold_idx}\"].get_label() == i\n",
    "\n",
    "                sig_rescale = (\n",
    "                    np.array(BDT_perf[sample_name]['preds'][fold_idx])[:, j] \n",
    "                    + np.array(BDT_perf[sample_name]['preds'][fold_idx])[:, i]\n",
    "                )\n",
    "                bkg_rescale = (\n",
    "                    np.array(BDT_perf[sample_name]['preds'][fold_idx])[:, j] \n",
    "                    + np.array(BDT_perf[sample_name]['preds'][fold_idx])[:, i]\n",
    "                )\n",
    "\n",
    "            sigs_and_bkgs = {\n",
    "                'sig': (np.array(BDT_perf[sample_name]['preds'][fold_idx])[:, j] / sig_rescale)[sig_mask],\n",
    "                'bkg': (np.array(BDT_perf[sample_name]['preds'][fold_idx])[:, j] / bkg_rescale)[bkg_mask]\n",
    "            }\n",
    "            if re.search('arctanh', plot_dirpath) is not None:\n",
    "                sigs_and_bkgs['sig'] = np.arctanh(sigs_and_bkgs['sig'])\n",
    "                sigs_and_bkgs['bkg'] = np.arctanh(sigs_and_bkgs['bkg'])\n",
    "            score_weights = {\n",
    "                'sig': weights_plot_test[f\"fold_{fold_idx}\"][sig_mask],\n",
    "                'bkg': weights_plot_test[f\"fold_{fold_idx}\"][bkg_mask]\n",
    "            }\n",
    "\n",
    "\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\")\n",
    "                plot_s_over_root_b(\n",
    "                    sigs_and_bkgs['sig'], sigs_and_bkgs['bkg'], f\"{sample_name} vs. {sample_name_ if sample_name_ != sample_name else 'all'}\", \n",
    "                    f\"BDT_{sample_name}_vs_{sample_name_ if sample_name_ != sample_name else 'all'}_sOverRootb_testData_fold{fold_idx}\", \n",
    "                    plot_dirpath, weights=score_weights,\n",
    "                    arctanh=True if re.search('arctanh', plot_dirpath) is not None else False  \n",
    "                )\n",
    "\n",
    "                (\n",
    "                    cut_boundaries_fold, cut_s_over_root_bs_fold, sig_weights_fold, bkg_weights_fold\n",
    "                ) = optimize_cut_boundaries(\n",
    "                    sigs_and_bkgs['sig'], sigs_and_bkgs['bkg'], score_weights,\n",
    "                    arctanh=True if re.search('arctanh', plot_dirpath) is not None else False\n",
    "                )\n",
    "\n",
    "                BDT_cut_labels = [\n",
    "                    f\"cut={cut_boundaries_fold[0][cut_idx]:.4f}: s/âb={cut_s_over_root_bs_fold[0][cut_idx]:.5f}, s={sig_weights_fold[0][cut_idx]['value']:.5f}Â±{sig_weights_fold[0][cut_idx]['w2']:.5f}, b={bkg_weights_fold[0][cut_idx]['value']:.5f}Â±{bkg_weights_fold[0][cut_idx]['w2']:.5f}\" for cut_idx in range(len(cut_s_over_root_bs_fold[0]))\n",
    "                ]\n",
    "                line_labels = BDT_cut_labels[:10]\n",
    "                lines = cut_boundaries_fold[0][:10]\n",
    "                line_colors = cmap_petroff10\n",
    "\n",
    "                plot_s_over_root_b(\n",
    "                    sigs_and_bkgs['sig'], sigs_and_bkgs['bkg'], f\"{sample_name} vs. {sample_name_ if sample_name_ != sample_name else 'all'}\", \n",
    "                    f\"BDT_{sample_name}_vs_{sample_name_ if sample_name_ != sample_name else 'all'}_sOverRootb_withCuts_testData_fold{fold_idx}_{sample_name}\", plot_dirpath, \n",
    "                    weights=score_weights,\n",
    "                    lines=lines, lines_labels=line_labels, line_colors=line_colors,\n",
    "                    arctanh=True if re.search('arctanh', plot_dirpath) is not None else False\n",
    "                )\n",
    "            \n",
    "        flat_preds = np.concatenate([BDT_perf[sample_name]['preds'][fold_idx] for fold_idx in range(len(BDT_perf['ggF HH']['preds']))], axis=0)\n",
    "        if re.search('arctanh', plot_dirpath) is not None:\n",
    "            flat_preds = np.arctanh(flat_preds)\n",
    "        flat_truths = np.concatenate([bdt_test_dict[f\"fold_{fold_idx}\"].get_label() for fold_idx in range(len(BDT_perf['ggF HH']['preds']))], axis=0)\n",
    "        flat_weights = np.concatenate([weights_plot_test[f\"fold_{fold_idx}\"] for fold_idx in range(len(BDT_perf['ggF HH']['preds']))], axis=0)\n",
    "        flat_sample_names = np.concatenate([data_test_aux_dict[f\"fold_{fold_idx}\"]['sample_name'] for fold_idx in range(len(BDT_perf['ggF HH']['preds']))], axis=0)\n",
    "\n",
    "        if sample_name_ == sample_name:\n",
    "            sig_mask = flat_truths == j\n",
    "            bkg_mask = flat_truths != j\n",
    "\n",
    "            sig_rescale = np.ones_like(sig_mask)\n",
    "            bkg_rescale = np.ones_like(bkg_mask)\n",
    "        else:\n",
    "            sig_mask = flat_truths == j\n",
    "            bkg_mask = flat_truths == i\n",
    "\n",
    "            sig_rescale = flat_preds[:, j] + flat_preds[:, i]\n",
    "            bkg_rescale = flat_preds[:, j] + flat_preds[:, i]\n",
    "\n",
    "        sigs_and_bkgs = {\n",
    "            'sig': (flat_preds[:, j] / sig_rescale)[sig_mask],\n",
    "            'bkg': (flat_preds[:, j] / bkg_rescale)[bkg_mask]\n",
    "        }\n",
    "        score_weights = {\n",
    "            'sig': flat_weights[sig_mask],\n",
    "            'bkg': flat_weights[bkg_mask]\n",
    "        }\n",
    "\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            plot_s_over_root_b(\n",
    "                sigs_and_bkgs['sig'], sigs_and_bkgs['bkg'], f\"{sample_name} vs. {sample_name_ if sample_name_ != sample_name else 'all'}\", \n",
    "                f\"BDT_{sample_name}_vs_{sample_name_ if sample_name_ != sample_name else 'all'}_sOverRootb_testData_sum\", \n",
    "                plot_dirpath, weights=score_weights,\n",
    "                arctanh=True if re.search('arctanh', plot_dirpath) is not None else False\n",
    "            )\n",
    "\n",
    "            (\n",
    "                cut_boundaries_fold, cut_s_over_root_bs_fold, sig_weights_fold, bkg_weights_fold\n",
    "            ) = optimize_cut_boundaries(\n",
    "                sigs_and_bkgs['sig'], sigs_and_bkgs['bkg'], score_weights,\n",
    "                arctanh=True if re.search('arctanh', plot_dirpath) is not None else False\n",
    "            )\n",
    "\n",
    "            BDT_cut_labels = [\n",
    "                f\"cut={cut_boundaries_fold[0][cut_idx]:.4f}: s/âb={cut_s_over_root_bs_fold[0][cut_idx]:.5f}, s={sig_weights_fold[0][cut_idx]['value']:.5f}Â±{sig_weights_fold[0][cut_idx]['w2']:.5f}, b={bkg_weights_fold[0][cut_idx]['value']:.5f}Â±{bkg_weights_fold[0][cut_idx]['w2']:.5f}\" for cut_idx in range(len(cut_s_over_root_bs_fold[0]))\n",
    "            ]\n",
    "            line_labels = BDT_cut_labels[:10]\n",
    "            lines = cut_boundaries_fold[0][:10]\n",
    "            line_colors = cmap_petroff10\n",
    "\n",
    "            plot_s_over_root_b(\n",
    "                sigs_and_bkgs['sig'], sigs_and_bkgs['bkg'], f\"{sample_name} vs. {sample_name_ if sample_name_ != sample_name else 'all'}\", \n",
    "                f\"BDT_{sample_name}_vs_{sample_name_ if sample_name_ != sample_name else 'all'}_sOverRootb_withCuts_testData_sum\", plot_dirpath, \n",
    "                weights=score_weights,\n",
    "                lines=lines, lines_labels=line_labels, line_colors=line_colors,\n",
    "                arctanh=True if re.search('arctanh', plot_dirpath) is not None else False\n",
    "            )\n",
    "\n",
    "        if j == 0 and i == 0:\n",
    "            flat_mass = np.concatenate([data_test_aux_dict[f\"fold_{fold_idx}\"]['mass'] for fold_idx in range(len(BDT_perf['ggF HH']['preds']))], axis=0)\n",
    "            if re.search('arctanh', plot_dirpath) is not None:\n",
    "                cat_lines = [6.0] + lines[:3]\n",
    "            else:\n",
    "                cat_lines = [1.0] + lines[:3]\n",
    "            cat_num_samples = {}\n",
    "            for k, cat in enumerate(['Cat1', 'Cat2', 'Cat3']):\n",
    "                cat_num_samples[cat] = {}\n",
    "                print('='*60)\n",
    "                print('='*60)\n",
    "                print(f\"{cat}: {cat_lines[k+1]:.4f} < ggF HH score â¤ {cat_lines[k]:.4f} AND 120 GeV < m_HH < 130 GeV\")\n",
    "                print('-'*60)\n",
    "                for m, sample_name in enumerate(order):\n",
    "                    sample_bool = np.logical_and(  # event passes conditions and is the right type (i.e. sample)\n",
    "                        np.logical_and(  # event passes category and mass conditions\n",
    "                            np.logical_and(  # prediction is within category bounds\n",
    "                                flat_preds[:, 0] <= cat_lines[k],\n",
    "                                flat_preds[:, 0] > cat_lines[k+1]\n",
    "                            ),\n",
    "                            np.logical_and(  # diphoton mass is within 120-130 window\n",
    "                                flat_mass < 130,\n",
    "                                flat_mass > 120\n",
    "                            ),\n",
    "                        ),\n",
    "                        flat_truths == m\n",
    "                    )\n",
    "                    cat_num_samples[cat][sample_name] = np.sum(\n",
    "                        flat_weights[sample_bool]\n",
    "                    )\n",
    "                    print(f\"{cat}: Num {sample_name} = {cat_num_samples[cat][sample_name]:.4f}\")\n",
    "                    print('-'*60)\n",
    "                    if sample_name == order[-1]:\n",
    "                        for smpl in [\n",
    "                            ['GluGluHToGG', 'GluGlutoHHto2B2G_kl_1p00_kt_1p00_c2_0p00'],\n",
    "                            ['VBFHToGG', 'VBFHToGG_M_125'],\n",
    "                            ['GGJets'], ['GJetPt20To40'], ['GJetPt40']\n",
    "                        ]:\n",
    "                            smpl_num = 0\n",
    "                            for smpl_ in smpl:\n",
    "                                smpl_num += np.sum(\n",
    "                                    flat_weights[\n",
    "                                        np.logical_and(\n",
    "                                            sample_bool,\n",
    "                                            flat_sample_names == smpl_\n",
    "                                        )\n",
    "                                    ]\n",
    "                                )\n",
    "                            print(f\"{cat}: Num {smpl[0]} = {smpl_num:.4f}\")\n",
    "                            print('-'*60)\n",
    "                    elif sample_name == order[-2]:\n",
    "                        smpl_num = np.sum(\n",
    "                            flat_weights[\n",
    "                                np.logical_and(\n",
    "                                    sample_bool,\n",
    "                                    np.logical_or(\n",
    "                                        flat_sample_names == 'VHToGG',\n",
    "                                        flat_sample_names == 'VHtoGG_M_125'\n",
    "                                    )\n",
    "                                )\n",
    "                            ]\n",
    "                        )\n",
    "                        print(f\"{cat}: Num VH, no ZH or WH = {smpl_num:.4f}\")\n",
    "                        print('-'*60)\n",
    "\n",
    "                print(f\"{cat}: S = {cat_num_samples[cat][order[0]]:.4f}, B = {np.sum([cat_num_samples[cat][order[v]] for v in range(1, len(order))]):.4f}, S/âB = {(cat_num_samples[cat][order[0]] / np.sqrt(np.sum([cat_num_samples[cat][order[v]] for v in range(1, len(order))]))):.4f}\")\n",
    "\n",
    "            for k, cat in enumerate(['Cat1', 'Cat2', 'Cat3']):\n",
    "                cat_num_samples[cat] = {}\n",
    "                print('='*60)\n",
    "                print('='*60)\n",
    "                print(f\"{cat}: {cat_lines[k+1]:.4f} < ggF HH score â¤ {cat_lines[k]:.4f}\")\n",
    "                print('-'*60)\n",
    "                for m, sample_name in enumerate(order):\n",
    "                    sample_bool = np.logical_and(  # event passes conditions and is the right type (i.e. sample)\n",
    "                        np.logical_and(  # prediction is within category bounds\n",
    "                            flat_preds[:, 0] <= cat_lines[k],\n",
    "                            flat_preds[:, 0] > cat_lines[k+1]\n",
    "                        ),\n",
    "                        flat_truths == m\n",
    "                    )\n",
    "                    cat_num_samples[cat][sample_name] = np.sum(\n",
    "                        flat_weights[sample_bool]\n",
    "                    )\n",
    "                    print(f\"{cat}: Num {sample_name} = {cat_num_samples[cat][sample_name]:.4f}\")\n",
    "                    print('-'*60)\n",
    "                    if sample_name == order[-1]:\n",
    "                        for smpl in [\n",
    "                            ['GluGluHToGG', 'GluGluHToGG_M_125'],\n",
    "                            ['VBFHToGG', 'VBFHToGG_M_125'],\n",
    "                            ['GGJets'], ['GJetPt20To40'], ['GJetPt40']\n",
    "                        ]:\n",
    "                            smpl_num = 0\n",
    "                            for smpl_ in smpl:\n",
    "                                smpl_num += np.sum(\n",
    "                                    flat_weights[\n",
    "                                        np.logical_and(\n",
    "                                            sample_bool,\n",
    "                                            flat_sample_names == smpl_\n",
    "                                        )\n",
    "                                    ]\n",
    "                                )\n",
    "                            print(f\"{cat}: Num {smpl[0]} = {smpl_num:.4f}\")\n",
    "                            print('-'*60)\n",
    "                    elif sample_name == order[-2]:\n",
    "                        smpl_num = np.sum(\n",
    "                            flat_weights[\n",
    "                                np.logical_and(\n",
    "                                    sample_bool,\n",
    "                                    np.logical_or(\n",
    "                                        flat_sample_names == 'VHToGG',\n",
    "                                        flat_sample_names == 'VHtoGG_M_125'\n",
    "                                    )\n",
    "                                )\n",
    "                            ]\n",
    "                        )\n",
    "                        print(f\"{cat}: Num VH, no ZH or WH = {smpl_num:.4f}\")\n",
    "                        print('-'*60)\n",
    "\n",
    "                print(f\"{cat}: S = {cat_num_samples[cat][order[0]]:.4f}, B = {np.sum([cat_num_samples[cat][order[v]] for v in range(1, len(order))]):.4f}, S/âB = {(cat_num_samples[cat][order[0]] / np.sqrt(np.sum([cat_num_samples[cat][order[v]] for v in range(1, len(order))]))):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0YAAAM1CAYAAABUkuF3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzdeVxU5f4H8M8ZGIZFZAdZTFBMQA13Ky0101Qy01wiLUHsqplp3TLUDDDTbDEz6VpmYmq2aFq4pZZg2a/QFJcUwQVUUGRV9m2e3x80kyMzMCDDjPB539e8yvM85znfcwZv58uzSUIIASIiIiIiohZMZuwAiIiIiIiIjI2JERERERERtXhMjIiIiIiIqMVjYkRERERERC0eEyMiIiIiImrxmBgREREREVGLx8SIiIiIiIhaPCZGRERERETU4pkbO4DGZmNjg9LSUpiZmcHV1dXY4RARERERkZFcv34dVVVVsLS0RFFRUa11JSGEaKK4moSZmRmUSqWxwyAiIiIiIhMhk8lQVVVVa51m12OkSoxkMhnc3d3vqK3MzEy4ubk1+HwhBDIyMuDh4QFJkowaS2O2Y0qxNNYzNqV7MqVYmuPzbax2+HwN244pPd/GiseUnm9jtMPna9h2TO35NlY7phILn6/h2zGV/8ZdvXoVSqUSZmZmdVcWzYynp6cAIDw9Pe+4LX9//zs6/8aNGwKAuHHjhtFjacx2TCmWxnrGpnRPphRLc3y+jdUOn69h2zGl59tY8ZjS822Mdvh8DduOqT3fxmrHVGLh8zV8O6by37j65AZcfIGIiIiIiFo8JkZERERERNTiMTEiIiIiIqIWj4kRERERERG1eEyMiIiIiIioxWNiVIuZM2caOwS1xoqlMdoxpVgaiyndkynF0lhM7Z5M6XtqDKb0XBqrHVN6voBp3ZOptdMY+HwNy5TuyZRiaSymdE+mFEtjacpYmt0Gr15eXkhPT4enpyeuXLli1Fhu3rwJOzs73LhxA61btzZqLM0Vn7Fh8fkaFp+vYfH5Ghafr2Hx+RoWn6/hmcozrk9uwB4jIiIiIiJq8ZgYERERERFRi8fEiIiIiIiIWjwmRkRERERE1OIxMSIiIiIiohaPiREREREREbV4TIyIiIiIiKjFMzd2AIaSmZmJgIAArWUzZ85sks2iFAoFIiIioFAoDH6tlorP2LD4fA2Lz9ew+HwNi8/XsPh8DYvP1/Ca8hlHR0cjOjpaa1lmZqbe7XCDVyIiIiIiapa4wSsREREREVE9MDEiIiIiIqIWj4kRERERERG1eEyMiIiIiIioxWNiRERERHds9+7dGDNmDLp06QIbGxv4+PhgyJAhWLZsGUpKSowdnsnx8fGBJEmIj4+vs64kSZAkCWlpaXq3P2jQIL3O0bceUUvAxIiIiIgarLy8HEFBQRgxYgS2bduGpKQk2NvbIyMjA/v370d4eDh8fX2RkJCgcV5aWpr6hV+f5KAh0tLSEBUVhR9++MEg7avEx8cjKioKx48f1zh+48YNREVFYf369Qa9vr5UyVhUVJSxQyEySUyMiIiIqMHCw8Oxa9cuuLu7Y/PmzSguLkZ6ejpKSkpw5MgRPPbYY8jIyEBwcDAKCgqaNLbU1FRERkZi+/btBr1OXFwcIiMjkZiYqHE8Pz8fkZGRiImJMej1iahxMDEiIiKiBikoKMCKFSsgSRJiY2Px9NNPw8LCAgAgk8nQs2dPxMbGok+fPrhw4QK+/PJL9blyuRx+fn7w8/ODtbW1sW6hRenQoQP8/Pzg7Oxs7FCITJK5sQMgIiKiu1NiYiKEEPD390fPnj211pHL5QgJCUFCQoLGUDMPDw+cOXOmqUIlAPv37zd2CEQmjT1GRERE1CDXr18HAJSVldVab9SoUdi4cSMmTJigcVw15+V2hYWFePXVV9G7d2/Y2NggMDBQPU/HwcEBbdu2rTM2Hx8fDBw4EAAQExMDSZIQGhqqUSctLQ1Tp05F9+7dYWtrix49eiAsLAypqal1tq86X5IkREZGAgBCQkIgSRLWr1+PQYMGwdvbG0D1UDtJkjBo0CC92jWU0NBQved0/frrr7C2toaFhQV2796tUVZZWYlly5bh0UcfhaOjIzw8PBAUFIS9e/caKnSiJsEeIyIiImqQgIAAAMCFCxcQHh6Ot956C3K5vEY9Dw8PTJw4Ua82L1++jKCgIJw8eRIA4OzsjJMnTyIkJAQXL17UO7Z27dqhoqIC6enpsLW1hZubG1xdXdXlu3btwsSJE5Gfnw8AcHV1xbFjx3Ds2DFs3boVGzduxOOPP17rNczNzeHr64vc3Fzk5ubC1dUVrVu3hq2tLTw9PdGuXTukpaXBysoKnp6e8PT01Dt+Yzp27Bgef/xxlJWVYfPmzRg+fLi6LDMzE2PGjMHvv/8OAHBxcUF2djZ27dqFXbt2YcGCBVi8eLGxQie6I+wxIiIiogbx9/fH6NGjAQDLli2Dp6cnpk+fjh9++AE3b95sUJtz5szByZMn0b9/f6SmpiIrKwtZWVkIDg7GokWL9G43Li4OmzZtAgA89dRTSElJwbJlywBU90iFhIQgPz8fkydPRlZWFjIzM5GdnY0pU6bgxo0bmDJlCgoLC2u9hqenJ1JSUvDSSy8BAN59912kpKRgzJgx2Lhxo7pnpm/fvkhJScHGjRsb9Eya0tmzZ/HYY4/h5s2b+PTTTzF+/HiN8tdeew2///47Hn/8caSmpuL69esoKCjAmjVrYGNjg7fffhu7du0yUvREd4aJERERkaEIAZSWmt5HiEa7xa+++grTpk2DQqFAVlYWPv30Uzz55JNwcnJC//79sWjRIr2Hpp04cQLbtm2Do6Mj9uzZg3bt2gEAnJycsGnTJnTp0gVKpfKOY/7oo4+QlZWFAQMGICYmRr0YgZOTE9auXYuBAwciKysLH3/88R1fqy4DBw5UL1uu69NULl26hCFDhiArKwvvvfcepk6dqlF+8uRJbNq0CV27dsXWrVvV349CocDUqVPx0UcfAQCWLl3aZDETNSYOpSMiIjKUsjJg3DhjR1HTd98BlpaN0pSlpSVWr16Nt99+Gzt27MC+ffuwb98+XL9+HYcOHcKhQ4cQFRWFqVOnYtWqVVqH2qns2bMHQgiEhobCxsZGo0ySJEyfPh0zZ86845hVPTkvv/yy1vLZs2cjLi4O8fHxmDdv3h1frzaenp6wsrKqtc65c+cMGgNQPURu0qRJuHz5MoYNG4ZXX321Rp2ffvoJSqUSoaGh6tUHbzVp0iTMmDEDCQkJKCsrg0KhMHjcRI2JiRERERHdMScnJ0yePBmTJ0+GEAInTpxAbGwsNmzYgOTkZHz22WeoqqrC559/rrON8+fPAwA6d+6stVzX8fpSXadr165ay7t06QKgeu6UoW3atAkDBgyotY62XqOOHTvWOPbSSy9h1qxZDYpj7NixuHz5MgDgl19+QUpKSo1rpKSkAADee+89fPLJJ1rbUSqVqKqqQnZ29l0zp4pIhYmRAWUXZyMpOwmtFa1xn9t9xg6HiIiamkJR3Ttjagz8m3xJkhAYGIjAwECEh4dj3rx5eP/997Fu3TosXLhQPQTrdqoX81sXSbhVmzZtGiW+jIwMAICbm1ut17ly5UqjXM8QtPUi5ebmNri9y5cv4+2338bhw4exfft2vPLKK4iNjdWoc+nSJQDA1atX62yvqTfzJWoMnGNkQGezz2LZoWXYfHKzsUMhIiJjkKTqIWum9mmkeSuDBw+Gg4MDjhw5orOOubk53n33XXh5eUGpVCIxMVFnXVWikpWVpbVc1/H68vDwAFA9fEwb1fHGSsQMQQhR4xMREdHg9l577TXMnz8fH3zwARQKBXbs2IE9e/Zo1HF3dwcAfPvtt1qvf+vHz8/vju6PyBiYGDUBgcab5EpERGQqvL29kZ+fX2tiBFT3INnZ2QGo3odIF19fXwDA6dOntZYnJSU1MFJN7du3BwCcOnVKa7nquCqelkA1d6t9+/b473//C6B6hcCKigp1HdXzOHv2rNY2lEolzp492yRzoogMgYmRAanGBItGXP2HiIjIVPTp0wcAsHjxYuTl5emsl5SUhDNnzkAmk6FHjx4666k2ZF23bh2Ki4trlK9evfrOAv7Hww8/DABYsWKF1vIPP/wQAPDQQw81yvXuNvPnz4eHhwfOnj2rsTKf6rmtXbsWpaWlNc7bunUr/Pz88MorrzRZrESNiYmRIRUXA4VFQEHD9nIgIiIyZWFhYbj//vuRnp6OPn36YMuWLRpzS0pLS/H1119j+PDhUCqVmDt3Llq1aqWzvX79+mHo0KHIzs5GUFCQes5Rfn4+pkyZgsTERJiZmdU7ztvnxMyZMwfOzs44cOAAwsLCkJOTAwDIzs5GSEgI4uPj4erqijlz5tzRdeo6bqpsbGzUez4tWrQI169fBwD0798fI0aMQGpqKkaPHq2xDPtPP/2E6dOnA4D6n0R3GyZGhnTuHHD6b4hjx4wdCRERUaMzNzfH5s2bERgYiHPnzmHcuHFo3bo1XF1d4erqCmtrawQHByMtLQ0TJ07E4sWL62xz1apVaN++PeLi4nDPPffA1dUVjo6OWL9+PT777DNYW1vXuby1imqO0N69e9G5c2e88cYbAABbW1vExMTAzs4OX3zxBZydneHm5gYXFxesX78e9vb2iImJga2tbb2uExERgR49emD79u0AAGdnZ5iZmeHs2bPo2LEjwsLC9GrPFEycOBEPPPAAbty4gfnz56uPf/zxx+jcuTP27NkDHx8fuLq6wt7eHsOGDUNubi4WLlyIESNGGDFyooZrtolRZmYmAgICtH6io6ObJAYJ/0xu5VA6IiJqpry9vXHs2DFs3rwZI0eOROfOnVFUVASZTIa+ffsiJCQER48excaNG/Xq7enYsSMOHz6MGTNmwN/fH0VFRXjwwQexd+9eBAcHo6CgQO+EpVOnTnjzzTfh6OiIS5cuoby8XF0WFBSExMREhIaGIjAwEEVFRejWrRvCwsJw/PhxDB8+XO9n8Oyzz2L06NGQy+W4dOmSegi9jY0NVq1aBXd3d6Snp2sdHmiqJEnCypUrIUkS1q1bh7/++gtA9Rykw4cPY8GCBejfvz/Kyspga2uL4cOH45dffsGiRYuMHDm1RNHR0Trf+3UtsqKNJJrZBBgvLy+kp6fD09PT6Mts/rHrM7y9byH8bbzx7uI/jRoLERHR3S4pKQn+/v4YN24cvv32W2OHQ0R3gfrkBs22x8gUdLD2xJzM9hhf1cnYoRAREZm8hIQE+Pj44Omnn9ZavmHDBgBA7969mzIsImohmBgZkIuFAwYXOKNXlenug0BERGQqAgMDkZOTgy1btmDr1q0aZbGxsVi5ciXkcjnGjRtnpAiJqDkzN3YAzVojbaBHRETUEigUCnzxxRcYP348xo4di4CAALRt2xYXL15EcnIyzM3NsXz5cnh7exs7VCJqhthjZED5lYU4bJ2PM1KOsUMhIiK6K4wdOxYJCQkYM2YMSkpKcPDgQUiShJEjRyI+Ph6zZs0ydohE1Eyxx8iAkluV4q3eRehkdxPvGzsYIiKiu0SvXr1qDKUjIjI0JkaG5OoGeHpCON5j7EiIiIiIiKgWHEpnQKp9jASa1YroRERERETNDhMjQyorBUpKgKIiY0dCRERERES1YGJkSOfOAydPAv/sFk1ERERERKaJiVETEIJD6YiIiIiITBkTIwOSuI8REREREdFdgavSGdA9Vm0wI6sdWrv7GDsUIiIiIiKqBRMjA3JVOGLEDTfA1dPYoRARERERUS04lI6IiIiIiFo89hgZUEFVMS5a3YSVLA8djR0MERERERHpxB4jA0qxLMaCnjewqn2OsUMhIiIiIqJaMDEyJDc34J62ED7exo6EiIjIoHbv3o0xY8agS5cusLGxgY+PD4YMGYJly5ahpKTE2OEZzMSJEyFJEsaOHVtn3YKCAigUCkiShAMHDgAA4uPjIUkSfHzqXqhp/fr1kCQJgwYN0ju+tLQ0vc7Rtx5Rc8bEyIAkcLluIiJq3srLyxEUFIQRI0Zg27ZtSEpKgr29PTIyMrB//36Eh4fD19cXCQkJGuepXsQlSUJ8fLxBYktLS0NUVBR++OEHg7QPABMmTABQnRgWFxfXWnf37t0oLy+Hs7MzHn74YYPFVBdVMiZJEtLS0owWB5GpYWJkQFJlJVBWBlHafH9TRkRELVt4eDh27doFd3d3bN68GcXFxUhPT0dJSQmOHDmCxx57DBkZGQgODkZBQUGTxpaamorIyEhs377dYNd47LHH0Lp1axQXF2PPnj211v3xxx8BAKNHj4aZmZnBYiKihmFiZEjnzgHHjwO3/ZaMiIioOSgoKMCKFSsgSRJiY2Px9NNPw8LCAgAgk8nQs2dPxMbGok+fPrhw4QK+/PJL9blyuRx+fn7w8/ODtbW1sW7hjikUCowaNQoAsHXrVp31KisrsWvXLgDAU0891SSx6WJtba1+9nK53KixEJkSrkpHREREDZKYmAghBPz9/dGzZ0+tdeRyOUJCQpCQkIDjx4+rj3t4eODMmTNNFapBjR8/Hhs2bMCOHTtQVlYGhUJRo86vv/6KvLw82Nvb45FHHjFClP/q3bt3s3n2RI2p2fYYZWZmIiAgQOsnOjq6SWKQpH8er2iSyxERETWp69evAwDKyspqrTdq1Chs3LhRPR9HxcfHB5JUcz5uYWEhXn31VfTu3Rs2NjYIDAzE+vXrAQAODg5o27ZtnbH5+Phg4MCBAICYmBhIkoTQ0FCNOmlpaZg6dSq6d+8OW1tb9OjRA2FhYUhNTa2z/VsNHToU9vb2uHnzJvbv36+1jmqe06hRo0yil0bfBR8AYNasWZAkCffddx/y8vI0yi5evIjnn38e3bt3h42NDTp16oQ5c+bg8uXLhgibSKvo6Gid7/2ZmZl6t9Nse4zc3Nxw+vRpo8bgbuWC0Oy2aO3qZdQ4iIiIDCEgIAAAcOHCBYSHh+Ott97S+tLv4eGBiRMn6tXm5cuXERQUhJMnTwIAnJ2dcfLkSYSEhODixYt6x9auXTtUVFQgPT0dtra2cHNzg6urq7p8165dmDhxIvLz8wEArq6uOHbsGI4dO4atW7di48aNePzxx/W6loWFBZ588knExMRg69atCAoKqlFHNb/I2MPo6mvhwoVYtWoVfH19sXfvXjg4OKjLduzYgWeffRb5+fkwMzODs7MzkpOTkZycjI0bN2Lnzp3o27evEaOnlmLmzJmYOXOm1jIvLy+kp6fr1U6z7TEyBa4KR4zJd8ej5XX/ZouIiJofIYDSUtP7iEYayeDv74/Ro0cDAJYtWwZPT09Mnz4dP/zwA27evNmgNufMmYOTJ0+if//+SE1NRVZWFrKyshAcHIxFixbp3W5cXBw2bdoEoDoZSUlJwbJlywBU90iFhIQgPz8fkydPRlZWFjIzM5GdnY0pU6bgxo0bmDJlCgoLC/WOe/z48QCqe4YqKys1yk6ePImLFy/C1tYWQ4cO1btNY1u+fDkWL14MT09P7Nu3D23atFGX5ebmYtKkSSguLsaHH36IwsJCXLt2Tb3QRk5ODsaPH9+sl2qn5qfZ9hgREREZW1kZMG6csaOo6bvvAEvLxmnrq6++wpw5cxATE4OsrCx8+umn+PTTT2Fubo6+ffti6NCheO655+Dt7V1nWydOnMC2bdvg6OiIPXv2wMbGBgDg5OSETZs24dSpU+qepDvx0UcfISsrCwMGDEBMTIz6uJOTE9auXYsLFy4gLi4OH3/8MebNm6dXm48++igcHByQm5uLuLg4PProo+oyVW/R448/rnX+EVC9gp62YYXG8sUXX+DVV1+Fs7Mz9u3bV+P7W7p0KW7cuIGlS5dizpw56uPu7u7YtGkT0tPTcfDgQXz11VcICwtr2uCJGog9RgZUXFmCZEUhUmUN+60ZERGRqbO0tMTq1auRnp6OmJgYTJw4Ea6urqisrMShQ4cQERGBDh06YNq0aaioqKi1rT179kAIgdDQUHVSpCJJEqZPn94oMav2TXr55Ze1ls+ePVujnj7kcrm69+z21elU84tqG0Znbm4OX1/fWj+3DgU0pC1btuA///kPhBBYtWoV/P39a9TZvXs3JEnC888/X6NMkiSEhIQAAA4ePGjocIkaDXuMDOi8ogjze2ajrbUcnxg7GCIianIKRXXvjKnR0WlxR5ycnDB58mRMnjwZQgicOHECsbGx2LBhA5KTk/HZZ5+hqqoKn3/+uc42zp8/DwDo3Lmz1nJdx+tLdZ2uXbtqLe/SpQuA6rlT9TFhwgR88cUX2LZtG6KjoyGTyXD16lUcOXIEVlZWGD58uM5zvby8kJKSUmv769evVyccKt9//z1ef/31GnXj4uLg6elZr/gB4MyZM5g4cSKqqqoAAJ9++mmNRTOEEDh//jwkScL999+vtR3VZrcZGRn1joHIWJgYGZKrG+DtDbTmHCMiopZIkhpvyNrdRJIkBAYGIjAwEOHh4Zg3bx7ef/99rFu3DgsXLkS7du20nqdayUxXz8itc1zuhOpl3c3NrdbrXLlypV7tPvLII3ByckJmZiYOHTqEhx56CD/++COEEBgxYoRB9msqKCjAuXPnahy/fZ6TvjIzM+Hg4IAffvgBY8eOxYEDB7B161aN3q7r16+jtLQUALRe+/b4iO4WHEpnQKqxwqKxZrkSERGZkMGDB8PBwQFHjhzRWcfc3BzvvvsuvLy8oFQqkZiYqLOuKlHJysrSWq7reH15eHgAgM5lfFXH65uImZubY8yYMQD+HU5n6NXoVD10t390JZ91adWqFfbs2YNhw4Zh/vz5AIBXX31VnQgB1SsFyuVy2NjYaL32rZ8//vijUe6TqCkwMTKkykqgoqL6Q0RE1Mx4e3sjPz+/1sQIqP5FoZ2dHQBoLPd8O19fXwDQud1GUlJSAyPV1L59ewDAqVOntJarjqviqQ/V6nTff/89CgoK8PPPP0OhUGhdwtsU9erVC3369AEA/Pe//0X79u2RmpqK9957T13HzMwM3t7eKCoq0tmrlpeXh7NnzzZaMkvUFJgYGVBK3BWc/TULZ/bov+8CERHR3UL1Ar148eIaG3/eKikpCWfOnIFMJkOPHj101lNtyLpu3Tr1HJVbrV69+s4C/sfDDz8MAFixYoXW8g8//BAA8NBDD9W77UGDBsHFxQWXL1/G4sWLUVZWhqFDh6J169YNjtdYFAoFPvjgAwDAO++8o7Fpq+oZrlq1Suu5kyZNgp+fH3799VfDB0rUSJgYGVBhsRluVFrjRlkLHGBORETNXlhYGO6//36kp6ejT58+2LJli8acktLSUnz99dcYPnw4lEol5s6di1atWulsr1+/fhg6dCiys7MRFBSkfhHPz8/HlClTkJiYCDMzs3rHefXqVY0/z5kzB87Ozjhw4ADCwsKQk5MDAMjOzkZISAji4+Ph6uqqsQy1vszMzNTD5pYvXw7g7tvU9VZPPvkkBg8ejOLiYsydO1d9PCIiApaWlli+fDnef/999VC7wsJChIeHY9euXWjbtu1d01NGBDAxMiiJT5eIiJoxc3NzbN68GYGBgTh37hzGjRuH1q1bw9XVFa6urrC2tkZwcDDS0tIwceJELF68uM42V61ahfbt2yMuLg733HMPXF1d4ejoiPXr1+Ozzz6DtbU1rKys9IpPNUdo79696Ny5M9544w0AgK2tLWJiYmBnZ4cvvvgCzs7OcHNzg4uLC9avXw97e3vExMTA1ta2Qc9FNZyusrIS5ubmeOKJJxrUjqn46KOPYG5ujq+//lrdA9S2bVusXr0aZmZmeO2119CqVSt4eXnB0dERy5Ytg62tLX788Ued+zYRmSK+uhuQg8wJnilD0f5aX2OHQkREZBDe3t44duwYNm/ejJEjR6Jz584oKiqCTCZD3759ERISgqNHj2Ljxo169fZ07NgRhw8fxowZM+Dv74+ioiI8+OCD2Lt3L4KDg1FQUKB3wtKpUye8+eabcHR0xKVLl1BeXq4uCwoKQmJiIkJDQxEYGIiioiJ069YNYWFhOH78eK1La9dlwIAB6oUkHnnkkVrnVd0NOnfujBkzZgCo3uNJqVQCqF74ISEhAc888ww6deqEvLw83HvvvXjxxReRnJyMbt26GTFqovqTRDNbMs3Lywvp6enw9PSs9zKbje33jeex9L858HfPx7uJQ40aCxER0d0uKSkJ/v7+GDduHL799ltjh0NEd4H65AbsMTIgydgBEBER3UUSEhLg4+ODp59+Wmv5hg0bAAC9e/duyrCIqIW448Ro6dKlkCRJvUOyPnbt2gVJkrBw4UKddRISEjBy5Eg4OzujVatW6Nu3LzZt2nSn4TapcpSjpNU1FFrmGDsUIiIikxcYGIicnBxs2bJFvQ+QSmxsLFauXAm5XI5x48YZKUIias7M7+RkIUS9u7ILCwvV41R12blzJ0aPHo2KigqYm5vD0tISCQkJmDRpEv7++28sWbLkTsJuMlctcnBqyApkmzkCCDZ2OERERCZNoVDgiy++wPjx4zF27FgEBASgbdu2uHjxIpKTk2Fubo7ly5fD29vb2KESUTPU4B6jqqoqLFq0qNYdrLWZP38+Ll26pLP85s2beO6551BRUYHw8HBkZ2cjNzcXX3/9NczNzbF06VL89ttvDQ27SQUOckLvATbo/djdPemSiIioqYwdOxYJCQkYM2YMSkpKcPDgQUiShJEjRyI+Ph6zZs0ydohE1EzVu8dox44d2Lp1K+Li4pCamlqvc//v//4P0dHRtdZZu3YtcnNzMWzYMCxZsgSSVD1TZ8KECbhw4QLmz5+P5cuXo3///vUNvcmpYiciIiL99erVq8ZQOiIiQ6t3j9HWrVsRExNT76SovLwcU6dOhVwuR3Cw7mFlsbGxAICQkJAaiUVISAgA4KefftJYctNUSUoBVCkhqiqNHQoREREREdWi3onR4sWLcerUKfVHX0uXLsXp06excOFCdOrUSWsdIQT+/PNPSJKEIUOG1Ch3d3fHfffdh+LiYpw4caK+oTe51N8uI+VgBpL3XDB2KEREREREVIt6J0aenp7o3Lmz+qOP06dPY8mSJejSpQvmzp2rs15GRgaKi4vh6OgIR0dHrXU6dOgAADh//nx9Q29yNwvNkFfRCrll+u3QTURERERExnFHq9LpQ6lU4vnnn0dlZSXWrFkDuVyus25WVhYAwN7eXmcdVcKUmZlZ63WFELh582b9A/6HQqGAQqFo8PkAIHGXKCIiIiKiBisrK0NZWVmDzxdC6F3X4InRJ598gt9//x2zZs3C/fffX2vd4uJiAICDg+5V3FRlqrq6ZGRkwM7Orp7R/isiIgKRkZENPh8A7Mwc4H5hILys9P9CiIiIiIio2tKlSxEVFdUk1zJoYnT58mXMnz8fbdu2xdtvv11nfVVGV1tmZ2ZmBgB1bijr4eGBM2fO1CNaTXfaWwQA9nIntE0aCV+XG3fcFhERERFRSzNv3jy88sorDT7f398fGRkZetU1aGI0Y8YMFBQU4KuvvoKtrW2d9W1sbAAAeXl5OuuoeopUdXWRJAmtW7euR7SNT4IqwWOPERERERFRfd3p9Jb6bJ9jsMToxx9/xM6dOzF+/Hg8/vjjep3j7OwMAMjPz9dZ5/r16xp1TVmlqECZVQ6KLAqNHQoREREREdXCYMsDXLx4EQDw7bffQpIkjY9q7s7ixYshSZJ63pCnpyesra2Rl5eH7Oxsre3+/fffAICOHTsaKvRGc80iF8eHvoff+m40dihERERERFQLg/UY2dnZwdfXV2tZbm4ucnNz4eDgACcnJ/UwO0mS0LdvXxw4cAD79u2rsRFsRkYGTp06BSsrKwQGBhoq9EbTub8TehfawMla+9LjRERERERkGgzWYxQSEoKUlBStn5deegkAMHPmTKSkpODo0aPq80aOHAkAiImJqbEIQ0xMDABg6NChsLS0NFTojUYmSZBkgCRxjhERETVvu3fvxpgxY9ClSxfY2NjAx8cHQ4YMwbJly1BSUmLs8Fqs0NDQGiN3bv3Y2dmhZ8+eePnll5GTk2PscGtYv349JEmqc1UyfesR1cbkdtqZOnUqnJycsHfvXsyfPx83b95EeXk5vvnmG0RERECSpFo3iTUl9ZnsRUREdDcqLy9HUFAQRowYgW3btiEpKQn29vbIyMjA/v37ER4eDl9fXyQkJGicl5aWpn45j4+PN0hsaWlpiIqKwg8//GCQ9u8mjo6O8PX11fi0b98eFRUVOHr0KFasWIGOHTvi3Llzxg61TlFRUZAkCT4+PsYOhZoZk0uMbG1tsX79esjlcrzzzjtwdnaGo6Mjnn76aVRWVmLBggV48MEHjR2mXq78cQXnD1zGud3Jxg6FiIjIIMLDw7Fr1y64u7tj8+bNKC4uRnp6OkpKSnDkyBE89thjyMjIQHBwMAoKCpo0ttTUVERGRmL79u1Nel1T9NJLL9UYwXP+/HkUFRXh119/hY+PD/Ly8vD8888bO1QiozG5xAgAgoKC8NtvvyEoKAitWrUCAPTp0wdfffUV3nrrLSNHp78bBTLkVNgiu6yVsUMhIiJqdAUFBVixYgUkSUJsbCyefvppWFhYAABkMhl69uyJ2NhY9OnTBxcuXMCXX36pPlcul8PPzw9+fn6wtrY21i20eJIkoX///li5ciUAID4+HoWFpr2arrOzM/z8/NChQwdjh0LNzB0vvlDbZqy6REREICIiotY6ffr0wY4dOxoalkmQTDLtJCIiahyJiYkQQsDf3x89e/bUWkculyMkJAQJCQk4fvy4+vidbsROjatfv34Aqt/rzp49q/P7NAUzZ87EzJkzjR0GNUN8dTcgm4IquF7oA68rAcYOhYiIqNGp9hYsKyurtd6oUaOwceNGTJgwQeO4j4+P1vm4hYWFePXVV9G7d2/Y2NggMDAQ69evBwA4ODigbdu2dcbm4+ODgQMHAqhevEmSJISGhmrUSUtLw9SpU9G9e3fY2tqiR48eCAsLQ2pqap3t334t1TYiP/30Ex566CHY2trC3d0dTzzxBBITE7WeV1xcjAULFuChhx6CnZ0d7r33XowbNw6//PKL1vqSJGHIkCEAgK+++go9e/aEjY0N7rnnHjzzzDO4cOFCveLWxcrKqsaxY8eO4dlnn0VAQABatWqFLl264M0339S5vcqhQ4cwatQo+Pj4wNraGn5+fpg2bRouX758x/HFx8dr/T61KSoqwgMPPABJkvDcc8/V+IX+L7/8ggkTJsDX1xetW7dGjx498MEHH6CoqOiO46S7kGhmPD09BQDh6elp7FDEsWU/icctfhIzHb8ydihERESN7vTp0wKAACBef/11UV5eXq/zvb29xe2vIpcuXRJdu3ZVt+vs7Cyk6uVdRUREhLC3txdeXl51tj1gwAD1O4Gtra3w9fUVc+fOVZfv3LlT2Nvbq6/j6uqq/nc7OzsRGxtbr/vw9fUVX331lZDJZEImkwk3Nzd1ezY2NiI5OVnjnJSUFOHv76+u4+joKMzNzQUAIZPJRGRkZI3rABCPPvqoWLZsmQAgzM3NhYuLi7oNd3d3kZ2drXFOSEiIAKC1vVvt3LlTABAuLi6irKxMo2zNmjVCoVAIAMLCwkI4Ozurr+nt7V3j3tavX68ut7KyEp6ensLMzEwAEG3atBHXr1/X+9nGxMTUiD8uLk4AECEhIbXWKy0tFY8++qgAIEaNGiUqKio02o6KihIymUwdp4ODgzru7t27i8zMTL3jJNNVn9yAPUYGxEXpiIioOfP398fo0aMBAMuWLYOnpyemT5+OH374ATdv3mxQm3PmzMHJkyfRv39/pKamIisrC1lZWQgODsaiRYv0bjcuLg6bNm0CADz11FNISUnBsmXLAFT3SIWEhCA/Px+TJ09GVlYWMjMzkZ2djSlTpuDGjRuYMmVKveba5OTkYNq0aZg9ezby8vJw7do1nDt3Dl26dEFRURGio6M16s+aNQtnzpxBz549cebMGeTk5ODmzZv4+OOPIZPJEBkZiT///LPGdU6fPo2FCxfi3Xffxc2bN3H9+nX89ddf8PDwwNWrV7Fhwwa9Y1b5/fffMWvWLADAW2+9pZ4nBgDJycmYMWMGLC0t8eWXX6KwsBBZWVlISUnBo48+itTUVEyaNEndE1NRUYEXXngBkiQhOjoaBQUFuHLlCq5evYqBAwfi2rVrWLFiRb1jrK+qqioEBwdj//79GDx4ML755huYm/87g+SXX35BREQE2rRpgx07dqCwsBC5ubk4evQoevTogWPHjuHFF180eJxkYgyfpzUtU+oxOvrebvGY7fcizO1zY4dCRERGoFQqRUlFicl9lEplo91jSUmJmDZtmrpHQfUxNzcX/fr1E1FRUeLixYtaz729x+j48eNCkiTh6OgoCgsLazxLVU+SPj1GQmjvWRBCiMWLFwsAYsCAAVrPGzhwoAAglixZotd1VPcxevToGmWqnpghQ4aoj/3222/qnqm8vLwa50RGRgoAYujQoRrHVc/25ZdfrnFOdHS0ACCef/55jeOqHiNHR0fh6+ur8Wnfvr2wsbFR96p9/nnN95WxY8cKAGLz5s01yoqLi0XHjh0FALF//34hhBCJiYkCgAgICKhR/+effxa9evUSr7zySo0yXRrSY6RUKtX33bdvX1FQUFCj3V69eglJksShQ4dqlF27dk04OTkJACIlJUXvWMk01Sc3uOPFF0i3TIsCHBu1HBeEBYAwY4dDRERNrKyqDOO+G2fsMGr4btx3sDRvnI3SLS0tsXr1arz99tvYsWMH9u3bh3379uH69es4dOgQDh06hKioKEydOhWrVq2CXC7X2daePXsghEBoaChsbGw0yiRJwvTp0xtl0r1q36SXX35Za/ns2bMRFxeH+Ph4zJs3T+92Z8+eXeOYn58fgOqelNuvHxoaCnt7+xrnvPjii1i0aBEOHjwIIUSNeVj6XudWubm5yM3N1Rl7aWkpLl26VOP4nj17YG9vj/Hjx9cos7KyUvfkHTx4EIMHD0br1q0BVM/fOnXqFLp06aKu/8gjj+Dw4cM6Y2gMQgi8/PLLiImJgZmZGb7//nv1Cscq2dnZOHLkCO677z6tW8C4ubkhKCgIX375JX799Vf4+voaNGYyHUyMDMi8fQ6crpyBg7y1sUMhIiIyKCcnJ0yePBmTJ0+GEAInTpxAbGwsNmzYgOTkZHz22WeoqqrC559/rrON8+fPAwA6d+6stVzX8fpSXadr165ay1Uv8/VdzEBbfGZmZvW+vpOTE9zd3ZGeno6rV6/Cw8NDXWZjY4N27drpdZ1bRUZGal0ROC8vDzt37sQLL7yARYsWwdfXF88++ywA4OrVqygsLIRCoUCnTp20tnvjxg0AQEZGBoDqhSiGDx+O3bt3o0ePHhg2bBiGDh2KAQMGaL3f119/Hd9//73GMU9PT8TFxdV6P7p88cUX6gUeVD9vb775pkadlJQUANXfg2rRjNvl5ORo3Be1DEyMDOiGMh85FiWQZLX/nxURETVPCjMFvhv3nbHDqEFhpjBo+5IkITAwEIGBgQgPD8e8efPw/vvvY926dVi4cKHWF3sA6hdaV1dXreVt2rRplPhUL7tubm61XufKlSv1atfZ2blRrq+KIT09HVeuXNFIjPS9hr4cHBwwadIkpKWl4Y033sDWrVvViZGqB6msrAznzp2rtZ1bN+/dunUrli5dik8//RSxsbGIjY0FALRr1w6hoaEIDw+HQlH9M3j9+vUabVdWVjb4fi5fvoyePXvipZdewuTJk7Fs2TKEhoZqrGSouq+ioqJ63Rc1f1x8wYBkZtV5Z/13eiIiouZAkiRYmlua3EfbEtkNMXjwYDg4OODIkSM665ibm+Pdd9+Fl5cXlEqlzqWrgX8ThaysLK3luo7XlyrRyMzM1FquOt5YiVh9r19bDI313d1uwIABAKqHwKm4u7sDAAICAiCEqPXz9ddfq8+zsrLCokWLcPXqVfz6669YtGgRBg4ciCtXriAyMhJPPvmkuu66detqtHXx4sUG34e/vz/27NmD5557DkOGDEFxcTFee+01jTqq+xoxYkSd9/XOO+80OBa6+zAxMqCi85WwueIJs4uOxg6FiIio0Xl7eyM/P7/WxAiofpm3s7MDUN1DoYtqLsfp06e1liclJTUwUk3t27cHAJw6dUprueq4oeaW1HX93NxcZGRkQKFQwMvLyyAx3E6VlN7aQ+Ll5QWFQoHz58+jqqpK63nXr1/H2bNnkZ+fD6B6aF1aWhry8/Mhk8nQv39/LFy4EAcOHMCxY8dgZmaGPXv2qIezNbYJEyaoe9VWrFgBc3NzfPPNNzh48KC6jup7PXv2rM520tPTcfbsWe5n1MIwMTKgomIr5Fc5I7/KydihEBERNbo+ffoAABYvXoy8vDyd9ZKSknDmzBnIZDL06NFDZz3Vhqzr1q1DcXFxjfLVq1ffWcD/ePjhhwFA57LRH374IQDgoYceapTr3U7VO7Nu3Tqty49/9NFHUCqV6NevH2SypnlVU12ntLRU41j//v1RVlaGNWvW1DhHCIHBgwfDz89PPR/rm2++gbe3N6ZPn16jfteuXdVzleqzFHpDBQQEqBfrmD17NpRKJYDqHiNfX1+cP38ee/bsqXFecXExunfvrl5qnVoOJkYGJJnx8RIRUfMVFhaG+++/H+np6ejTpw+2bNmi0eNQWlqKr7/+GsOHD4dSqcTcuXNrrBB2q379+mHo0KHIzs5GUFCQes5Rfn4+pkyZgsTExDoXGdDm6tWrGn+eM2cOnJ2dceDAAYSFhakn2mdnZyMkJATx8fFwdXXFnDlz6n0tffTv3x+PPfYY8vPzMWTIECQnJwMASkpKsHLlSixZsgQA1P9sClZWVgCg7vlRUcUwd+5cxMTEqFe9y8nJQUhICE6dOoU+ffqoE17VAgvbtm3D999/r97fqKysDCtXrsSZM2dga2urc+GJxhYZGQlnZ2ckJiaqkztJktT3FRoaih07dqiTpsuXL+Opp55CVlYWxowZo3O+GzVTjbZIuIkwpX2MNnywRvg89Lzo9tCzxg6FiIjIIC5evCgCAwM19jBycXERLi4uQpIkAUBIkiQmTpwoKisrNc69fR8jIYRITk4W7du312hLkiQhk8nE2rVrha2trejYsaNesSUlJamvHxAQIBYsWKAu27Fjh7Czs1Nfx9XVVf3v9vb2YteuXXo/A233oZKamioAiIEDB2ocT0lJEX5+fuprOjk5CXNzcwFAyGQy8dZbb9VoC4Dw9vbWeh1dezap9vO5dR8gbUpLS9Xf1759+zTKlixZIszMzAQAIZfLhaenp/rPHh4e4tKlSxr1n3rqKfV9tW7dWrRt21a9z5UkSeK7776rNZZbNWQfo9utXr1aABDOzs4a+0bNmDFDHaeVlZVwd3cXMplMABBdunQR+fn5esdJpqs+uQG7NAzIzswWnkdGwefkQGOHQkREZBDe3t44duwYNm/ejJEjR6Jz584oKiqCTCZD3759ERISgqNHj2Ljxo169fZ07NgRhw8fxowZM+Dv74+ioiI8+OCD2Lt3L4KDg1FQUABbW1u9YuvUqRPefPNNODo64tKlSygvL1eXBQUFITExEaGhoQgMDERRURG6deuGsLAwHD9+HMOHD2/wM9GHr68v/vrrL4SHh6Nfv36oqKiAt7c3xo4diwMHDuCNN94w6PVvp1AoEBAQAKB6H6VbzZs3D7/88gvGjh2Ldu3a4caNG+jatSvmz5+P06dPa6z4BgCbNm3Cxx9/jN69e8PS0hLZ2dnw9vbGxIkTcfToUYwdO7bJ7gsAnn/+eXTr1g3Z2dkaS5Z/8skn+P777/HEE0/AxcUFxcXF6NmzJ959910cPnxYPS+OWg5JCNGsFk3z8vJCeno6zM3Nda5NP3PmzEbZIK4uOz/egndet4KL4jq+zws1+PWIiIias6SkJPj7+2PcuHH49ttvjR0OEZmI6OhoREdHay1LSUlBZWUlPD0961yCv9nuY+Tm5qZzVZumIgFQmpWjwqzh6/ETERG1FAkJCZgwYQL69u2rsfyzyoYNGwAAvXv3burQiMiE1dbpoeo00QeH0hlQjrwIp8a8g8PD1ho7FCIiIpMXGBiInJwcbNmyBVu3btUoi42NxcqVKyGXyzFu3DgjRUhEzVmz7TEyBV5+clik/Q2FJDd2KERERCZPoVDgiy++wPjx4zF27FgEBASgbdu2uHjxIpKTk2Fubo7ly5fD29vb2KESUTPEHiMDUliYQWZWAZmMQ+mIiIj0MXbsWCQkJGDMmDEoKSnBwYMHIUkSRo4cifj4eMyaNcvYIRJRM8UeIwOSyapX3xFoVutbEBERGVSvXr1qDKUjIjI0JkYGVHCxBK3S3aFQSsYOhYiIiIiIasHEyIAKixXIq3SFpZI9RkREREREpoxzjAxIkvHxEhERERHdDdhjZEBWZpawu9IZ1ig1dihERERERFQLJkYGZG/hAK8/x8Jenm3sUIiIiIiIqBYc62VAqqF0SnDxBSIiIiIiU8bEyIBkkhnEP/8jIiIiIiLTxaF0BnRDVohTY9+CHEoI8RwkiT1HRERERESmiImRAXn6tYL88BnIIEFAQOKQOiIiIiIik8TEyIAsLc0gMy+DDBKUQgmZxJGLRERERESmiG/qBiSTman/XSmURoyEiIiIiIhqw8TIgG5eLkarDDe0znBhYkRERM3a7t27MWbMGHTp0gU2Njbw8fHBkCFDsGzZMpSUlBg7PJPj4+MDSZIQHx9fZ11JkiBJEtLS0vRuf9CgQXqdo289UxIfH69+Jvp8bty4YeyQ6S7BxMiACgtkyKtog/xyN1Qpq4wdDhERUaMrLy9HUFAQRowYgW3btiEpKQn29vbIyMjA/v37ER4eDl9fXyQkJGicl5aWpn5x1Sc5aIi0tDRERUXhhx9+MEj7KvHx8YiKisLx48c1jt+4cQNRUVFYv369Qa+vL1UyFhUVZexQGoW5uTl8fX3r/Mj+2T5F2/2b2ndExsXEyIAks3+ncLHHiIiImqPw8HDs2rUL7u7u2Lx5M4qLi5Geno6SkhIcOXIEjz32GDIyMhAcHIyCgoImjS01NRWRkZHYvn27Qa8TFxeHyMhIJCYmahzPz89HZGQkYmJiDHr9lsrLywspKSl1fmxtbXW2we+IbsXFFwzIytwKttc6wgLlULLHiIiImpmCggKsWLECkiQhNjYWPXv2VJfJZDL07NkTsbGx6N+/PxISEvDll19i5syZAAC5XA4/Pz8AgLW1tVHib2k6dOgAS0tLODs7GzsUo2jp9091Y2JkQK0t7XDPoWdgY5bPxIiIiJqdxMRECCHg7++vkRTdSi6XIyQkBAkJCRpDzTw8PHDmzJmmCpUA7N+/39ghGFVLv3+qG4fSNQEBCcqqSmOHQURE1KiuX78OACgrK6u13qhRo7Bx40ZMmDBB47hqzsftCgsL8eqrr6J3796wsbFBYGCgeg6Ig4MD2rZtW2dsPj4+GDhwIAAgJiYGkiQhNDRUo05aWhqmTp2K7t27w9bWFj169EBYWBhSU1PrbF91viRJiIyMBACEhIRAkiSsX78egwYNgre3N4DqoXaSJGHQoEF6tWsooaGhes/p+vXXX2FtbQ0LCwvs3r1bo6yyshLLli3Do48+CkdHR3h4eCAoKAh79+41VOiN4vb7v9Pv6LvvvsPo0aPRtm1bODg44IEHHsCaNWtQUVGhUW/MmDGQJAkRERE12vjpp58gSRL8/PxQWlqqjsvKygoA8OOPP6J///6wtbVF+/btMWHCBPzf//1fQ26f9NBse4wyMzMREBCgtWzmzJnqrnyDuuX/7JVKJkZERNS8qP47e+HCBYSHh+Ott96CXC6vUc/DwwMTJ07Uq83Lly8jKCgIJ0+eBAA4Ozvj5MmTCAkJwcWLF/WOrV27dqioqEB6ejpsbW3h5uYGV1dXdfmuXbswceJE5OfnAwBcXV1x7NgxHDt2DFu3bsXGjRvx+OOP13oN1eT/3Nxc5ObmwtXVFa1bt4atrS08PT3Rrl07pKWlwcrKCp6envD09NQ7fmM6duwYHn/8cZSVlWHz5s0YPny4uiwzMxNjxozB77//DgBwcXFBdnY2du3ahV27dmHBggVYvHixsUKvl4Z+R1VVVXjhhRfw2WefAYB6DtMff/yBP/74A1u2bMG2bdvUQ0Q//vhj/Pzzz3jnnXfwzDPPoFOnTgCA0tJSzJw5E5Ik4fPPP4elpaXGdT788EO88sorAKr/Hly8eBEXL17Etm3b8Mknn2Dq1KmN9izudtHR0YiOjtZalpmZqX9Dopnx9PQUAISnp6exQxHHD50VDs88KJyf6SOuZqcaOxwiIjKWkhLdn7KypqlbWlp9vJGNHj1aABAAhIuLi5g2bZrYvn27uHHjRp3nent7i9tfRcaMGSMAiP79+4vU1Or/dmZnZ4vg4GAhSZKQyWTCy8tLr9ji4uIEABESEqJxvKCgQLi4uAgAYvLkySIrK0t9nSlTpqjvpaCgQK/rREZGCgAiJiZG43hqaqoAIAYOHKjz3uPi4upsX/V8Vc9DHwMHDqxxTkhISI1r3l4vKSlJ/WzWrFlTo91nn31WABCPP/64+pzS0lKxZs0aYWNjIwCInTt36h1nQ6i+V29v73qdp+3+a/uOdFm7dq0AIPz8/MShQ4eEUqkUSqVSHDhwQLRv314AEK+99prGOZ988okAIB555BH1sQULFggA4sUXX9SoO3DgQCFJkjAzMxODBg0SaWlpQojqn8/p06cLAMLCwkJcunSpXvffUtUnN2i2PUamwO1eO8i9TkMJwTlGREQt2bhxust69QJuHWIzaRKga2haly7A0qX//jksDLh5U3vdjh2B5cv//fMLLwDXrwOxsfrHrYevvvoKc+bMQUxMDLKysvDpp5/i008/hbm5Ofr27YuhQ4fiueeeUw9Zqs2JEyewbds2ODo6Ys+ePbCxsQEAODk5YdOmTTh16pS6J+lOfPTRR8jKysKAAQM0ViNzcnLC2rVrceHCBcTFxeHjjz/GvHnz7vh6tVEN9zMFly5dwpAhQ5CVlYX33nuvRo/EyZMnsWnTJnTt2hVbt26FhYUFAEChUGDq1KmQJAlTp07F0qVLMWLECIPHm5qaqnUopoq9vT3y8vIa9ZplZWWIiIiAtbU1duzYgQ4dOqjLBg4ciNjYWHTv3h0fffQRIiMj1b1G06dPx8aNG/HLL79g06ZN6NGjB9577z3cc889WHrr3+l/CCHg6emJ3bt3Q6FQAKj++fzf//6Ha9euYfv27Vi6dCk++eSTRr2/lo5zjAxIoZDB3LwEZvISJkZERNQsWVpaYvXq1UhPT0dMTAwmTpwIV1dXVFZW4tChQ4iIiECHDh0wbdq0GnMvbrdnzx4IIRAaGqpOilQkScL06dMbJWbVHJOXX35Za/ns2bM16hmSp6dnnfvwNIXMzEw8+uijuHz5MoYNG4ZXX321Rp2ffvoJSqUSoaGh6qToVpMmTYJcLkdCQkKd884aQ137GPn4+DT6NU+ePIkrV67g0Ucf1UiKVAICAnD//fejvLwcf/75p/q4JElYs2YNLCws8N///hdTp05FeXk5Pv30U7Rq1UrrtWbNmqVOim71+uuvAwB++eWXRrorUmGPkSH981sMATAxIiJqyb77TneZ7LbfUW7cqH/dtWv1r/vJJ4AQuuvfIScnJ0yePBmTJ0+GEAInTpxAbGwsNmzYgOTkZHz22WeoqqrC559/rrON8+fPAwA6d+6stVzX8fpSXadr165ay7t06QKgeu6UoW3atAkDBgyotY62XpGOHTvWOPbSSy9h1qxZDYpj7NixuHz5MoDqF+6UlJQa10hJSQEAvPfeezp7KpRKJaqqqpCdnV3rfJ3vv/9e/YJ/q7i4OL3nYqn2MWpKqusdPHhQ63cAANeuXQMAZGRkaBwPCAjA66+/jrfeeguZmZmYPHkyhg0bpvNaulZ67NatGyRJQmpqKoQQtfaaUf0wMTKggqtFsLnmDAElV6UjImrJbptUbZS6Wn7zbCiSJCEwMBCBgYEIDw/HvHnz8P7772PdunVYuHAh2rVrp/U81Yv5rYsk3KpNmzaNEp/qhdXNza3W61y5cqVRrmcI586dq3EsNze3we1dvnwZb7/9Ng4fPozt27fjlVdeQextwy4vXboEALh69Wqd7dW1mW9BQYHWe6isNO33JdUzyM/PVy/coYu2ZzBlyhS89dZbAIDRo0fXer6Hh4fW45aWlnB0dEROTg6ysrJ0/n2h+uNQOgMqKAByyj2QX+7OHiMiImp2Bg8eDAcHBxw5ckRnHXNzc7z77rvw8vKCUqlEYmKizrqqRCUrK0trua7j9aV64dS1WpXqeGMlYoYghKjx0bYctL5ee+01zJ8/Hx988AEUCgV27NiBPXv2aNRxd3cHAHz77bdar3/rR7V5ry6qnsXbP7qSZlOhegYvvPBCnc9A29BP1SpzQPUzr23Ioa6f97KyMuTl5cHc3ByOjo53eEd0KyZGhnRLz2Yle4yIiKiZ8fb2Rn5+fq2JEVDdg2RnZwegeh8iXVTzaU6fPq21PCkpqYGRamrfvj0A4NSpU1rLVceban6PKVBtY9K+fXv897//BQDMmTNHY16Y6nmcPXtWaxtKpRJnz57V2hPUXNT1DIDqRSHOnj2L8vJyjeNbt27Ftm3bMGjQIIwfPx4pKSlYsmSJznb+/vtvrcePHz8OpVIJHx8fmJtz8FdjYmJkQHKZOWyy2qFV9j3cx4iIiJqdPn36AAAWL15c6+pfSUlJOHPmDGQyGXr06KGznmqFtnXr1qG4uLhG+erVq+8s4H88/PDDAIAVK1ZoLf/www8BAA899FCjXO9uM3/+fHh4eODs2bP4+OOP1cdVz23t2rXqzUhvtXXrVvj5+Wn0ijQ3Xbt2hYODA+Li4rQm1unp6ejUqRP69eunMfcnLy8PL774IiwsLPC///0PH374IWxtbfHOO+/oTLJWrlwJpVJZ4/iyZcsA/Pt9UONhYmRA1vJW8DkYCt9fgyFEzR9sIiKiu1lYWBjuv/9+pKeno0+fPtiyZYvGvIrS0lJ8/fXXGD58OJRKJebOnatzBS4A6NevH4YOHYrs7GwEBQWp5xzl5+djypQpSExMhJmZWb3jvH1OzJw5c+Ds7IwDBw4gLCwMOTk5AIDs7GyEhIQgPj4erq6umDNnzh1dp67jpsrGxkb98r1o0SJcv34dANC/f3+MGDECqampGD16NFJTU9Xn/PTTT+qhY421emBT0vc7srW1xbx581BVVYUxY8bgt99+g/hnUZOkpCSMGjUK5eXlCAsL09js+L///S+uXbuG119/HZ06dYKHhweioqJQXl6OadOmab3W6dOn8dRTT6mHdubm5uKFF17A999/DwsLC7zxxht3eNdUQ2NsnGRKTGmD1yunb4iHrXaKR22+ESeTDho7HCIiokZ38eJFERgYqN6EFP9sjuri4iIkSRIAhCRJYuLEiaKyslLjXG0bvCYnJ6s3yVS1pdrYde3atcLW1lZ07NhRr9iSkpLU1w8ICBALFixQl+3YsUPY2dmpr+Pq6qr+d3t7e7Fr1y69n8Hq1avVm252795dbNu2TQghRGFhoTAzMxMAhK+vr5gyZUqNeze1DV5VlEqleOCBBwQAERYWpj5+/vx50blzZ43v59bnuHDhQr1jbKjG3OC1tu9Il5KSEvHkk0+q77lVq1YaPz+DBw8W5eXl6vr79u0TAESHDh1EyS2bLFdUVIj77ruvxubAqu/kmWee0frzKZfLxWeffVave2/J6pMbsMfIgP7tQZW4+AIRETVL3t7eOHbsGDZv3oyRI0eic+fOKCoqgkwmQ9++fRESEoKjR49i48aNevX2dOzYEYcPH8aMGTPg7++PoqIiPPjgg9i7dy+Cg4NRUFAAW1tbvWLr1KkT3nzzTTg6OuLSpUsacz6CgoKQmJiI0NBQBAYGoqioCN26dUNYWBiOHz+O4cOH6/0Mnn32WYwePRpyuRyXLl1S9yDY2Nhg1apVcHd3R3p6utbhgaZKkiSsXLkSkiRh3bp1+OuvvwBUz0E6fPgwFixYgP79+6OsrAy2trYYPnw4fvnlFyxatMjIkddPQ74jS0tLbNu2DWvWrMGwYcPQqlUrVFVVoV+/flizZg1++ukndW9RcXEx/vOf/wAAoqOjYXnLSpLm5ub45JNPIEkSXn31VXXPpcrbb7+NzZs3IygoSL0wxdixY3Hw4EE8//zzjfgUSEUSqr+9zYSXlxfS09Ph6elp9GU2z52+hgeigiFJldj9xkL07DLUqPEQERHdzZKSkuDv749x48bh22+/NXY4RAYxaNAgxMXFITU11eRX6bsb1Cc3YI+RATm0tYHinr+hvOdv9hgRERHVISEhAT4+Pnj66ae1lm/YsAEA0Lt376YMi4haCCZGBqRQSLCwKIaZRRGqtKwqQkRERP8KDAxETk4OtmzZgq1bt2qUxcbGYuXKlZDL5Rg3bpyRIiSi5oyLnxuYapqRkvsYERER1UqhUOCLL77A+PHjMXbsWAQEBKBt27a4ePEikpOTYW5ujuXLl8Pb29vYoRJRM8QeIwMqziqGPNMOra85MjEiIiLSw9ixY5GQkIAxY8agpKQEBw8ehCRJGDlyJOLj4zFr1ixjh0hEzRR7jAyosFAgq8wLEqqgrKqo+wQiIiJCr169agylI2opDhw4YOwQWiz2GBlU9UA6AQn5NznHiIiIiIjIVDExMiBzMzNY5LSFZZ4ntu+1MnY4RERERESkA4fSGZClmSW8f54OM7MS5Liwx4iIiIiIyFSxx6iJKBTcx4iIiIiIyFQxMTIgSbVWtwAs5Vx8gYiIiIjIVDXboXSZmZkICAjQWjZz5kzMnDnT4DGUowLnHv8AQCU6KiYZ/HpERERERC1NdHQ0oqOjtZZlZmbq3U6zTYzc3Nxw+vRpo8Zg62qJIvdUVFoUwsyKc4yIiIiIiBpbbZ0eXl5eSE9P16sdDqUzIJkMkMnLIMmLoJBzg1ciIiIiIlPFxMiAioskSKL63+Xm7DEiIiIiIjJVzXYonSnIuVYB5xsCwswakk2ZscMhIiIiIiId2GNkQHk5StyoaIObZR4Q4FA6IiJqvnbv3o0xY8agS5cusLGxgY+PD4YMGYJly5ahpKTE2OEZzMSJEyFJEsaOHVtn3YKCAigUCkiShAMHDgAA4uPjIUkSfHx86jx//fr1kCQJgwYN0ju+tLQ0vc7Rt56pCQ0NhSRJen1Gjx5t7HDJxDExMqDioup/CkiA4FA6IiJqfsrLyxEUFIQRI0Zg27ZtSEpKgr29PTIyMrB//36Eh4fD19cXCQkJGuepXsQlSUJ8fLxBYktLS0NUVBR++OEHg7QPABMmTABQnRgWFxfXWnf37t0oLy+Hs7MzHn74YYPFVBdVMiZJEtLS0owWR2NydHSEr69vrZ82bdoA0H3/8fHxiIqKwvHjx411G2RkTIwMqKRUBoubrlDcdIEQwtjhEBERNbrw8HDs2rUL7u7u2Lx5M4qLi5Geno6SkhIcOXIEjz32GDIyMhAcHIyCgoImjS01NRWRkZHYvn27wa7x2GOPoXXr1iguLsaePXtqrfvjjz8CAEaPHg0zMzODxdQSvfTSS0hJSan187///a/WNuLi4hAZGYnExMSmCZpMDhMjA2rvLUf7n2bDZ+9MmCvlxg6HiIioURUUFGDFihWQJAmxsbF4+umnYWFhAQCQyWTo2bMnYmNj0adPH1y4cAFffvml+ly5XA4/Pz/4+fnB2traWLdwxxQKBUaNGgUA2Lp1q856lZWV2LVrFwDgqaeeapLYdLG2tlY/e7m85b2ftPT7J924+IIBeXhIMJdVoQIA+4uIiKi5SUxMhBAC/v7+6Nmzp9Y6crkcISEhSEhI0Bii5OHhgTNnzjRVqAY1fvx4bNiwATt27EBZWRkUCkWNOr/++ivy8vJgb2+PRx55xAhR/qt3797N5tk3REu/f9KNPUYGJEnV/6yeY8TFF4iIqHm5fv06AKCsrPaVV0eNGoWNGzeq5+Oo+Pj4QFL9x/IWhYWFePXVV9G7d2/Y2NggMDAQ69evBwA4ODigbdu2dcbm4+ODgQMHAgBiYmIgSRJCQ0M16qSlpWHq1Kno3r07bG1t0aNHD4SFhSE1NbXO9m81dOhQ2Nvb4+bNm9i/f7/WOqp5TqNGjTKJXgp9F3wAgFmzZkGSJNx3333Iy8vTKLt48SKef/55dO/eHTY2NujUqRPmzJmDy5cvGyLsRnPr/avmu0VGRgIAQkJCIEmS+meuLkVFRViwYAEefvhhtG7dGu3atcP48ePx559/atS7cuUKWrduDYVCgaSkpBrtBAcHQ5IkREVFacQ1Y8YMlJSU4I033kCHDh1gY2ODPn364JVXXsHNmzfv4ClQDaKZ8fT0FACEp6ensUMR2deKRJsnRgqXJx4XLy5429jhEBERNarTp08LVA+KEK+//rooLy+v1/ne3t7i9leRS5cuia5du6rbdXZ2FpIkCQAiIiJC2NvbCy8vrzrbHjBggPqdwNbWVvj6+oq5c+eqy3fu3Cns7e3V13F1dVX/u52dnYiNja3XvYSEhAgAIjQ0VGu5j4+PACB+/PFHjeNxcXECgPD29q7zGjExMQKAGDhwoN5xpaamaj3n9mvqqvfGG28IAMLX11dcvXpVoyw2Nlb9DM3MzISbm5v6GTo5OYk//vhD7zgbSvXcIyMj63Xerfd/5coV4evrKxwdHdU/C76+vmLr1q11tnP27Fnh7++vvm83Nzchk8kEACGTycTq1as16n/88cdan/NPP/0kAIjOnTuLsrIyIcS/38nkyZNF3759BQAhl8s1fm7vvfdekZKSUq97b2nqkxswMTKg4tIK4Ty7k5DPuUf8J+JdY4dDRETU6EaPHq1+SXNxcRHTpk0T27dvFzdu3KjzXG2J0ZgxYwQA0b9/f5GamiqEECI7O1sEBwcLSZKETCbTKzES4t+kIyQkRON4QUGBcHFxUb90ZmVlqa8zZcoU9b0UFBTodR0hhNi1a5cAIBwdHUVFRYVG2YkTJ9QJWmlpqdYYTTEx+uCDD9TvVBcvXtQ4PycnR9jZ2QkLCwvx4YcfipKSEiGEEBkZGSI4OFgAEPfcc48oLi7WO9aGaIzESCUyMlIAEDExMXq389BDD6kT4uvXrwshhCgqKhJLliwR5ubmwszMTBw/flxdv6qqStx///0CgPjyyy+FEEKUlJSIDh06CJlMppFMqr4TuVwuZDKZeP/990VRUZFQKpXir7/+Ep06dRIAxPDhw+t17y0NEyMTSYwqqyqFx2tthcVcBzH1zaXGDoeIiIykpET3559fDhu8bmlp9fHGv7cSMW3aNKFQKNQJEgBhbm4u+vXrJ6Kiomq8VKvcnhgdP35cSJIkHB0dRWFhoUZdpVKp7km608Ro8eLFAoAYMGCA1vMGDhwoAIglS5bodR0hhCgvLxcODg4CgNi3b5/W6wUHB+uMsT6fpkiM1q5dKyRJEs7OzuL06dM12n311VcFALF0ac33G6VSKR5++GEBQHz++ed6x9oQqsSors+cOXM0zmuMxGjHjh0CgBg2bJjWclVv26RJkzSOnzx5UsjlcuHi4iJyc3PV9V555RWNeqrvRNUje7urV68KKysrAUD8+eefesXcEtUnN7jjOUZLly6FJEmoqqrSWef48eMYN24c/P390apVK/Ts2ROzZs1Cdna2znMSEhIwcuRIODs7o1WrVujbty82bdp0p+EaEZdfICJqqcaN0/1ZulSz7qRJuutGRGjWDQvTXTc8XLPuCy9UH29slpaWWL16NdLT0xETE4OJEyfC1dUVlZWVOHToECIiItChQwdMmzYNFRUVtba1Z88eCCEQGhoKGxsbjTJJkjB9+vRGiVm1b9LLL7+stXz27Nka9fQhl8vVG4jevjqdan5RbavRmZub17kPj6urq97x3IktW7bgP//5D4QQWLVqFfz9/WvU2b17NyRJwvPPP1+jTJIkhISEAAAOHjxo6HAB1L2PkbOzc6Nfc/fu3QCA//znP1rLp0yZAqDmM+jSpQvmzp2LrKwsPPvss3j33XfRvn17vPXWW1rbkclkWn9W27Rpg+eeew4A8MsvvzT4Puhfd7QqnRAC3377ba11vvjiC0yfPh0VFRUwMzODk5MTjh49iqNHj+Lbb7/F9u3b8cADD2ics3PnTowePRoVFRUwNzeHpaUlEhISMGnSJPz9999YsmTJnYTdZCrLlGiVB5jDEmZOtf/HgIiI6G7m5OSEyZMnY/LkyRBC4MSJE4iNjcWGDRuQnJyMzz77DFVVVfj88891tnH+/HkAQOfOnbWW6zpeX6rrdO3aVWt5ly5dAAAXLlyoV7sTJkzAF198gW3btiE6OhoymQxXr17FkSNHYGVlheHDh+s818vLCykpKbW2v379enXCofL999/j9ddfr1E3Li4Onp6e9YofAM6cOYOJEyeqf+H96aef1lg0QwiB8+fPQ5Ik3H///VrbUW12m5GRUec1J02aVGOhgr59+2Ljxo16x/3SSy8h4vbfHBiY6vuaPXs25s6dW6Nc/LOHpbZn8MYbb+Dbb7/Fzp07AQBr1qzRuWy9l5cX3NzctJZ1794dQPUiGHTnGpwYVVVVYfHixbVugpWbm4tXXnkFlZWViIiIwOuvvw4rKytcu3YNr7zyCjZv3ozJkyfjxIkTsLS0BADcvHkTzz33HCoqKhAeHo7w8HBYW1vj+++/x6RJk7B06VKMGDEC/fv3b2joTaasBMgu9YQSSkDJVemIiFqq777TXSa7bexGbe+Ct9ddu1b/up98AjTVXuOSJCEwMBCBgYEIDw/HvHnz8P7772PdunVYuHAh2rVrp/U81UpmunpG2rRp0yjxqV5Udb1sqq5z5cqVerX7yCOPwMnJCZmZmTh06BAeeugh/PjjjxBCYMSIEQbZr6mgoADnzp2rcbyysmHvHZmZmXBwcMAPP/yAsWPH4sCBA9i6datGb9f169dRWloKAFqvfXt8dUlPT6/RjpeXVwOib1qXLl0CgDpX4KusrERpaan6XReo7mmdOHEiIiMj0aZNG/Tr10/n+R4eHjrLVMmvqa8CeLeo91C6HTt2IDQ0FL6+vuplDXX55JNPcOPGDQwfPhyRkZGwsrICUP1/OBs3bsQDDzyAlJQUjd8IrF27Frm5uRg2bBiWLFkCOzs7yOVyTJgwAYsWLQIALF++vL5hG8etS5Aqay5HSkRELYOlpe7PP/uhGryuQlF9vDENHjwYDg4OOHLkiM465ubmePfdd+Hl5QWlUlnrL1RViUpWVpbWcl3H60v1opmZmam1XHW8vomYubk5xowZA+Df4XQ//vgjAMNt6qrqobv9oyv5rEurVq2wZ88eDBs2DPPnzwcAvPrqq+pECACcnZ0hl8thY2Oj9dq3fv744486r3ngwIEa5x04cKBB8Tcld3d3ANXTP+p6Dpa3/eW7cuWK+n322rVrtY6Gqu3n/urVqwAa75cGLV29E6OtW7ciJiZGrzX+T58+DQB49tlna15YJlOPizx27Jj6eGxsLIB/15C/lar7+KeffkJ5eXl9QzcKebEd5EX2EEqlsUMhIiJqVN7e3sjPz681MQKqe5Ds7OwAVO9DpIuvry+Af98fbqdt75eGaN++PQDg1KlTWstVx1Xx1Mf48eMBVA9xKygowM8//wyFQoGgoKAGRtu0evXqhT59+gAA/vvf/6J9+/ZITU3Fe++9p65jZmYGb29vFBUV6exVy8vLw9mzZxstmTVFqp+Ps2fPai0vKyvD2bNnkZaWVqNsxowZuHnzJt555x3Y2dnhnXfe0fnzfenSJZ09b6p36Ib8rFJN9U6MFi9ejFOnTqk/tVElT97e3lrLVZm2qp4QAn/++SckScKQIUO01r/vvvtQXFyMEydO1Df0Jiczk+HeXa+i/e6XIRc1d8EmIiK6m6leoBcvXlxj489bJSUl4cyZM5DJZOjRo4fOeqoNWdetW6eeo3Kr1atX31nA/3j44YcBACtWrNBa/uGHHwIAHnrooXq3PWjQILi4uODy5ctYvHgxysrKMHToULRu3brB8RqLQqHABx98AAB45513NIZrqZ7hqlWrtJ47adIk+Pn54ddffzV8oEaiegbR0dHq+US3WrlyJfz8/NTPUGXz5s3YsWMHBgwYgNdffx1vvfUWysvLdS4uUlFRgejo6BrHMzMz1ZvQNuRnlWqqd2Lk6emJzp07qz+1WbZsGfbs2aNzcuPhw4cBQL2DdUZGBoqLi+Ho6AhHR0et53To0AHAvxMnTdqtPV5clI6IiJqZsLAw3H///UhPT0efPn2wZcsWjd9sl5aW4uuvv8bw4cOhVCoxd+5ctGrVSmd7/fr1w9ChQ5GdnY2goCD1i3h+fj6mTJmCxMREmJmZ1TtO1XAjlTlz5sDZ2RkHDhxAWFgYcnJyAADZ2dkICQlBfHw8XF1dMWfOnHpfy8zMTD1sTjVUylDD6JrCk08+icGDB6O4uFhjgYGIiAhYWlpi+fLleP/999VD7QoLCxEeHo5du3ahbdu2d01P2a1u/3nR5ZlnnkHXrl3xxx9/YPLkyereMaVSia+++gpvvvkm5HI5pk6dqj4nOzsbs2fPhoWFBf73v/8BAF544QV0794d8fHxiImJ0XqtiIgIrFmzBmVlZRBC4NixYxg0aBCKi4sxdOhQJkaN5U7XBsc/66tXVlbW67yLFy+q1/vftm2bEEKIY8eOCQCiQ4cOOs8LCwsTAMRHH32ktdyU9jEqLFCKhyz3ib6Wu8ULs6KMHQ4REVGju3jxoggMDNTYM8bFxUW4uLgISZIEACFJkpg4cWKNdwVtG7wmJyeL9u3ba7Sl2th17dq1wtbWVnTs2FGv2JKSktTXDwgIEAsWLFCX7dixQ9jZ2amv4+rqqv53e3t7sWvXrgY/k19++UVjP6fc3FyddU15g1eVU6dOCXNzcwFAHDx4UCMeS0tLAUCYmZkJT09PIZfL1ZvZHjt2TO84G6oxN3hdvXq1ACAsLCxE9+7d1e+ntTly5Ijw8vJSf99t2rQRNjY26p+7NWvWaNSfOHGiAKDxsyiEEH/88YeQJEk4OTmpNxxWfSf33Xef6Ny5szo2e3t79fU6duwokpOT63XvLU2T7mPUEMeOHcMjjzyCvLw8BAYG4oknngDw79KOtY0/VpVp62K/lRACN2/ebPCnrKysUe71wiOrkfbIZyhH47RHRERkSry9vXHs2DFs3rwZI0eOROfOnVFUVASZTIa+ffsiJCQER48excaNG/Xq7enYsSMOHz6MGTNmwN/fH0VFRXjwwQexd+9eBAcHo6CgALa2tnrF1qlTJ7z55ptwdHTEpUuXNOYnBwUFITExEaGhoQgMDERRURG6deuGsLAwHD9+vNaltesyYMAA9UISjzzySK3vNXeDzp07Y8aMGQCql6ZW/jNvevLkyUhISMAzzzyDTp06IS8vD/feey9efPFFJCcno1u3bkaMuv6effZZjB49GnK5HJcuXdI6PO52PXv2xPHjx/HSSy+hT58+KCwshKurK5566in89ddfGr1Fu3fvxqZNm9C+fXssWLBAo52+ffvi+eefR05ODl577TWNMkdHR/z+++8IDw9H9+7dUVVVhZ49e+Lll1/GkSNH0LFjx8Z5ACaqrKzsjt7p9fke1e40C0M9eowKCwvFa6+9pv6tg6urq8Zu2L/99psAIHr27Kmzjddff10AEIsXL9ZarsoK7/QTERFR30dRQ0W5UrjM7izMZ3uLia8tvOP2iIiIWrIzZ84IAGLcuHHGDoXI4GrrxWtJIiIiGuXdXp8eozva4LU+fv/9dzzzzDPqlTn69++PzZs3a6xTr9rlurYJnKqeott3xL6dh4cHzpw50+B4FYo7XyzBXC5BYVkEmbgBqak2jyAiIrpLJSQkYMKECejbty++/vrrGuUbNmwAAPTu3bupQyMiI5k3bx5eeeWVBp/v7++v10bDwB1s8FofS5cuxcKFC1FVVQVHR0csXrwY06ZNg+y23eecnZ0BVE+y1OX69esadXWRJMkkVoBRLb8gBJfrJiIiqk1gYCBycnKwZcuWGpuKxsbGYuXKlZDL5Rg3bpwRoySipqRQKO6ow+L27X9qY/DEaPny5eoNwsaPH4/o6GidSY2npyesra2Rl5eH7OxsrfX+/vtvALgrxlNWVQE2uQJtoIDMsmE7UBMREbUUCoUCX3zxBcaPH4+xY8ciICAAbdu2xcWLF5GcnAxzc3MsX75c5zYgRER3wqCLLyQkJKgnkL3//vv45ptvau3pkSQJffv2hRAC+/btq1GekZGBU6dOwcrKCoGBgQaLu7FUVABZRZ64WXIPzCqrjB0OERGRyRs7diwSEhIwZswYlJSU4ODBg5AkCSNHjkR8fDxmzZpl7BCJqJkyaI/RJ598AqVSiRdffBH//e9/9Tpn5MiROHDgAGJiYvD0009rdH+p1nYfOnQoLC0tDRGywSiVnGNERESkj169emHr1q3GDoPIqNq1a1e/FdXojhmsx0ipVOK7774DgBrLDtZm6tSpcHJywt69ezF//nzcvHkT5eXl+OabbxAREQFJkjQ2GDNlkgSYldnArNSGG7wSEREREZkwg/UYZWRkoLi4GJIkYfDgwbXWHTVqFN5//30AgK2tLdavX4/Ro0fjnXfewQcffAALCwsUFRUBAN544w08+OCDhgq7UUkS4LfrdZSJCiie/dXY4RARERERkQ4GS4xSU1MBVG+0eu7cuVrrZmZmavw5KCgIv/32GxYtWoTff/8d5eXl6NOnD+bMmYPg4GBDhWxY7DEiIiIiIjJZd5wY6Rr72L9//zsaF9mnTx/s2LGjweebGqHkct1ERERERKaqyTZ4bYkkCUjtH4MKWTnulTyNHQ4REREREenAxMiAzMyAcv9TyBE3UCi8jB0OERERERHpwMTIgGQywMq6EJIyH7IyTjIiIiIiIjJVBt3glYiIiIiI6G7AHiMDEgKwzq2EG+QwlyqMHQ4REREREenAxMiAlEogs6AtKs3KIMk5lI6IiIiIyFRxKJ2BqdIhpeBy3UREREREpoqJkQFJEiCrtIBUKQcgGTscIiIig9m9ezfGjBmDLl26wMbGBj4+PhgyZAiWLVuGkpISY4fXYoWGhkKSJJ0fOzs79OzZEy+//DJycnKMHW4N69evhyRJiIqKapR6psbHx6fW7+fWz0cffWTscJs9JkYGJEmA/875uHf7G7CusjF2OERERI2uvLwcQUFBGDFiBLZt24akpCTY29sjIyMD+/fvR3h4OHx9fZGQkKBxXlpamvqFLz4+3iCxpaWlISoqCj/88INB2r+bODo6wtfXV+PTvn17VFRU4OjRo1ixYgU6duyIc+fOGTvUOkVFRUGSJPj4+Bg7lEbj6elZ4/u5/WNnZwdA9/2vX78eUVFRuHHjhjFuoVlgYtREOJKOiIiao/DwcOzatQvu7u7YvHkziouLkZ6ejpKSEhw5cgSPPfYYMjIyEBwcjIKCgiaNLTU1FZGRkdi+fXuTXtcUvfTSS0hJSdH4nD9/HkVFRfj111/h4+ODvLw8PP/888YOtUXatGlTje/n9k9ISEitbcTExCAyMhL5+flNEnNzxMTIwMRt/yQiImouCgoKsGLFCkiShNjYWDz99NOwsLAAAMhkMvTs2ROxsbHo06cPLly4gC+//FJ9rlwuh5+fH/z8/GBtbW2sW2jxJElC//79sXLlSgBAfHw8CgsLjRxV7ZydneHn54cOHToYOxSjaOn3b0hclc6AJAm43HczKsxK0E5mb+xwiIiIGlViYiKEEPD390fPnj211pHL5QgJCUFCQgKOHz+uPu7h4YEzZ840VahUh379+gEAhBA4e/aszu/TFMycORMzZ840dhhG09Lv35DYY2RgFZ0Tke33Bwo4xYiIiJqZ69evAwDKyspqrTdq1Chs3LgREyZM0Diumnh+u8LCQrz66qvo3bs3bGxsEBgYiPXr1wMAHBwc0LZt2zpj8/HxwcCBAwFUDzGSJAmhoaEaddLS0jB16lR0794dtra26NGjB8LCwpCamlpn+7dfq2PHjgCAn376CQ899BBsbW3h7u6OJ554AomJiVrPKy4uxoIFC/DQQw/Bzs4O9957L8aNG4dffvlFa31JkjBkyBAAwFdffYWePXvCxsYG99xzD5555hlcuHChXnHrYmVlVePYsWPH8OyzzyIgIACtWrVCly5d8OabbyI7O1trG4cOHcKoUaPg4+MDa2tr+Pn5Ydq0abh8+fIdxxcfH6/1+9SmqKgIDzzwACRJwnPPPQchNMfw/PLLL5gwYQJ8fX3RunVr9OjRAx988AGKioruOE5Duf3+VQtPxMXFAQC8vb0hSRLS0tL0au/ixYt4/vnn0b17d9jY2KBTp06YM2dOje/qhx9+gCRJuPfee2v8nS8pKUH79u0hk8lw4MABjbi++eYbXLp0CZMnT0abNm3g4OCAwYMH48MPP6zxfRidaGY8PT0FAGFubi78/f21flatWtVk8dw7319YzHUQQS/OaLJrEhERNYXTp08LVI8WF6+//rooLy+v1/ne3t7i9leRS5cuia5du6rbdXZ2FpIkCQAiIiJC2NvbCy8vrzrbHjBggPqdwNbWVvj6+oq5c+eqy3fu3Cns7e3V13F1dVX/u52dnYiNja3Xffj6+oqvvvpKyGQyIZPJhJubm7o9GxsbkZycrHFOSkqK8Pf3V9dxdHQU5ubmAoCQyWQiMjKyxnUAiEcffVQsW7ZM/a7j4uKibsPd3V1kZ2drnBMSEiIAaG3vVjt37hQAhIuLiygrK9MoW7NmjVAoFAKAsLCwEM7Ozuprent717i39evXq8utrKyEp6enMDMzEwBEmzZtxPXr1/V+tjExMTXij4uLEwBESEhIrfVKS0vFo48+KgCIUaNGiYqKCo22o6KihEwmU8fp4OCgjrt79+4iMzNT7zgbSvV3IC4uTu9zbr//rVu3Cl9fX2FlZSUAiHbt2glfX19x5cqVOtuKjY1V/z0wMzPT+Ll1cnISf/zxh0b9p556SuvP07x58wQA8Z///Ed9TPWdvPXWW8LJyUn9d9HS0lJ9jccff1wUFRXpfe+6rFq1Sud7v+rvlaenZ53tNNvESJ+bbwqqxGjETCZGRETU/IwePVr9kuPi4iKmTZsmtm/fLm7cuFHnudoSozFjxggAon///iI1NVUIIUR2drYIDg4WkiQJmUymV2IkhPYXaCGEKCgoUCcUkydPFllZWerrTJkyRX0vBQUFel3H29tbODg4CFtbW/Hyyy+r7/3cuXOiS5cuAoCYPXu2xjnDhg0TAETPnj3FmTNnhBBCFBcXi48//lj9Inf7SykA4eHhISwsLMS7774riouLhRBC/PXXX8LDw0MAEB9++KHGOfokRocOHRLt27cXAMTq1as1ys6ePSvMzc2FnZ2d+PLLL9XJb0pKijrp6NOnj1AqlUIIIcrLy4WNjY2QJElER0eLyspKIYQQ169fFwMHDhQAxPz58/V6rkI0PDGqrKxU/2wOHjxYlJaWarT7888/q5/njh07RFVVlRBCiKNHj4oePXoIAGLcuHF6x9lQjZEYqaier+rvTV1ycnKEnZ2dsLCwEB9++KEoKSkRQgiRkZEhgoODBQBxzz33qH/OVGV2dnZCoVCoE+K///5byOVy4eHhIfLz89V1Vd+JXC4X9vb2YufOnaKyslKUl5eLLVu2CFtbWwFALFu2TO97b4j65AZMjAys27QOou00ZzE6bKqxQyEiIiMpqSjR+SmrLGuSuqUVpaKkoqTx762kREybNk3do6D6mJubi379+omoqChx8eJFrefenhgdP35cSJIkHB0dRWFhoUZdpVKp7km608Ro8eLFAoAYMGCA1vNUL5hLlizR6zqq+xg9enSNMlVPzJAhQ9THfvvtN3XPVF5eXo1zIiMjBQAxdOhQjeOqZ/vyyy/XOCc6OloAEM8//7zGcVVi5OjoKHx9fTU+7du3FzY2Nurf5H/++ec12h07dqwAIDZv3lyjrLi4WHTs2FEAEPv37xdCCJGYmCgAiICAgBr1f/75Z9GrVy/xyiuv1CjTpSGJkVKpVN933759tSa4vXr1EpIkiUOHDtUou3btmrqHIyUlRe9YG0L1s1PXZ/v27epzGisxevXVVwUAsXTp0hplSqVSPPzwwwJAjZ+L1atXq3svb633ww8/aNRTfScAxO7du2tcY/v27epe4cboNdKlPrkBF18wsPT8e1AhL4IkuMErEVFLNe67cTrLern3QsTACPWfJ30/CWVV2ufsdHHpgqWPLlX/OezHMNwsu6m1bkfHjlj+2HL1n1/Y+QKuF19HbHBsfcOvlaWlJVavXo23334bO3bswL59+7Bv3z5cv34dhw4dwqFDhxAVFYWpU6di1apVkMvlOtvas2cPhBAIDQ2FjY3m5FxJkjB9+vRGmXSu2jfp5Zdf1lo+e/ZsxMXFIT4+HvPmzdO73dmzZ9c45ufnBwCoqKiocf3Q0FDY29vXOOfFF1/EokWLcPDgQQghaszD0vc6t8rNzUVubq7O2EtLS3Hp0qUax/fs2QN7e3uMHz++RpmVlRWCg4PVsQ4ePBitW7cGUD1/69SpU+jSpYu6/iOPPILDhw/rjKExCCHw8ssvIyYmBmZmZvj+++/RqlUrjTrZ2dk4cuQI7rvvPjz44IM12nBzc0NQUBC+/PJL/Prrr/D19TVozED1Pkba5nap3P73oTHs3r0bkiRpXaJdkiSEhITg4MGDOHjwIMLCwtRl//nPf7Bx40bs378fTz31FA4ePIinn34aTzzxhNbrdO7cGcOGDatx/IknnoCfnx+SkpJw4sQJ3H///Y13cw3ExKiJmNrcMiIiosbk5OSEyZMnY/LkyRBC4MSJE4iNjcWGDRuQnJyMzz77DFVVVfj88891tnH+/HkA1S9S2ug6Xl+q63Tt2lVrueplvr6LGWiLz8zMrN7Xd3Jygru7O9LT03H16lV4eHioy2xsbNCuXTu9rnOryMhIRERE1Diel5eHnTt34oUXXsCiRYvg6+uLZ599FgBw9epVFBYWQqFQoFOnTlrbVW0mmpGRAaB6IYrhw4dj9+7d6NGjB4YNG4ahQ4diwIABWu/39ddfx/fff69xzNPTU72QQH198cUX6kUDVD9vb775pkadlJQUANXfg2rRjNvl5ORo3FdttLXx0ksvYdasWXrHvWnTJgwYMEDv+ndKCIHz589DkiSdCUlxcTGAms9AkiR89tln6NatG7Zt2wZnZ2f1cu/a6FrhUJIkdOvWDUlJSbh48SITo5ZA3VPEzIiIqMX6btx3OstkkuYCsRvHbNS77ton1upd95OgTyCaaFc9SZIQGBiIwMBAhIeHY968eXj//fexbt06LFy4UOuLPQD1C62rq6vW8jZt2jRKfKoXPTc3t1qvc+XKlXq16+zs3CjXV8WQnp6OK1euaCRG+l5DXw4ODpg0aRLS0tLwxhtvYOvWrerESNWDVFZWhnPnztXazq2b927duhVLly7Fp59+itjYWMTGVvdStmvXDqGhoQgPD4dCoQBQvbLh7W1XVlY2+H4uX76Mnj174qWXXsLkyZOxbNkyhIaGaqxkqLqvoqKiet2XLtraqK13zhRcv34dpaWlALTHfyttz8Df3x8PPvgg4uLi0L9/f7i4uOg8/9af39t5enoCQKOsVtgYuFy3gfnvnIdOW6JgVWVr7FCIiMhILM0tdX4szCyapK7CXAFLc8tGva/BgwfDwcEBR44c0VnH3Nwc7777Lry8vKBUKnUuXQ38myhkZWVpLdd1vL5UL2qZmZlay1XHGysRq+/1a4tB2/LmjUHVW3HrEs/u7u4AgICAAIjqeek6P19//bX6PCsrKyxatAhXr17Fr7/+ikWLFmHgwIG4cuUKIiMj8eSTT6rrrlu3rkZbFy9ebPB9+Pv7Y8+ePXjuuecwZMgQFBcX47XXXtOoo7qvESNG1Hlf77zzTp3X1Haett45U+Ls7Ay5XA4bG5s6n8Eff/xR4/zY2Fh1r9727dt1LjEP1P739urVqwAM93etvpgYGZjq/8CE0siBEBERNTJvb2/k5+fXmhgB1f8ttLOzA1DdQ6GLai7H6dOntZYnJSU1MFJN7du3BwCcOnVKa7nquKHmltR1/dzcXGRkZEChUMDLy8sgMdxOlZTe2jvg5eUFhUKB8+fPo6qqSut5169fx9mzZ5Gfnw+gemhdWloa8vPzIZPJ0L9/fyxcuBAHDhzAsWPHYGZmhj179qiHszW2CRMmqHvVVqxYAXNzc3zzzTc4ePCguo7qez179qzOdtLT03H27FmT3s/oTpiZmcHb2xtFRUU6e0bz8vJw9uzZGonNzZs3MWPGDCgUCqxYsQIAMGPGDJ37mf39998641D9oqQp5nHpg4mRgUn/DFuQOJKOiIiamT59+gAAFi9ejLy8PJ31kpKScObMGchkMvTo0UNnPdWGrOvWrVPPb7jV6tWr7yzgfzz88MMAoH6pu92HH34IAHjooYca5Xq3U/XOrFu3Djdv1lw846OPPoJSqUS/fv0gkzXNq5rqOqrhVapj/fv3R1lZGdasWVPjHCEEBg8eDD8/P/V8rG+++Qbe3t6YPn16jfpdu3ZVz1UqLCw0xG1oCAgIUC/WMXv2bCiV1b+ldnd3h6+vL86fP489e/bUOK+4uBjdu3dHly5dmm1iBPz792DVqlVayydNmgQ/Pz/8+uuvGsdfe+01pKenIzw8HLNnz8aYMWOQnJyMpUuXam3njz/+0NnrdPr0adjb2+ucb9fUmBgZ2JXu25Fx/7coNav5f/BERER3s7CwMNx///1IT09Hnz59sGXLFo0eh9LSUnz99dcYPnw4lEol5s6dW2OFsFv169cPQ4cORXZ2NoKCgtTzDvLz8zFlyhQkJibWuciANqrhOipz5syBs7MzDhw4gLCwMPVE++zsbISEhCA+Ph6urq6YM2dOva+lj/79++Oxxx5Dfn4+hgwZguTkZABASUkJVq5ciSVLlgCA+p9NQbUimqrnR0UVw9y5cxETE6Ne9S4nJwchISE4deoU+vTpo054VS+427Ztw/fffw/xzxzrsrIyrFy5EmfOnIGtrW2TvQhHRkbC2dkZiYmJ6uROkiT1fYWGhmLHjh3qpOny5ct46qmnkJWVhTFjxuic72bKbv951yUiIgKWlpZYvnw53n//fXVSXFhYiPDwcOzatQtt27ZFUFCQ+pz4+HisWbMGvr6+CA8PB1D9CwYbGxssXbpUZy/cU089hfj4eCiVSlRUVGDr1q2YNGkSgOqfLVtbE5lycgfLgpskU9vH6J6ZDwjLF3zFI2H/qbsyERHRXebixYsiMDBQY88VFxcX4eLiIiRJEgCEJEli4sSJ6s0+VbRt8JqcnKzebFTVlmpj17Vr1wpbW1vRsWNHvWJLSkpSXz8gIEAsWLBAXbZjxw5hZ2envo6rq6v63+3t7cWuXbv0fgba7kMlNTVVABADBw7UOJ6SkiL8/PzU13RyclJv7CqTycRbb71Voy0AwtvbW+t1dO1to88Gr0IIUVpaqv6+9u3bp1G2ZMkSYWZmpt6s09PTU/1nDw8PcenSJY36Tz31lPq+WrduLdq2bave50qSJPHdd9/VGsutGrrB661U++44Oztr7Bs1Y8YMdZxWVlbC3d1dyGQyAUB06dJFY7NSQ2nMDV6ffvpp9f5YPXr0EFeuXKmzrZiYGGFpaSkACDMzM+Hp6Snkcrl6b6tjx46p6xYXFwtfX18BQOzdu1ejnXfffbfGz7nqO3n88cfVm7m2bt1afT0AYsSIEQbdw0iI+uUG7DEysFb2BVC2yoGkaPgKK0RERKbK29sbx44dw+bNmzFy5Eh07twZRUVFkMlk6Nu3L0JCQnD06FFs3LhRr96ejh074vDhw5gxYwb8/f1RVFSEBx98EHv37kVwcDAKCgr0/u1yp06d8Oabb8LR0RGXLl1CeXm5uiwoKAiJiYkIDQ1FYGAgioqK0K1bN4SFheH48eMYPnx4g5+JPnx9ffHXX38hPDwc/fr1Q0VFBby9vTF27FgcOHAAb7zxhkGvfzuFQoGAgAAA1fso3WrevHn45ZdfMHbsWLRr1w43btxA165dMX/+fJw+fVpjxTegeunpjz/+GL1794alpSWys7Ph7e2NiRMn4ujRoxg7dmyT3RcAPP/88+jWrRuys7M1FkX45JNP8P333+OJJ56Ai4sLiouL0bNnT7z77rs4fPiwel7c3SIiIgK9e/dGaWkprl27ptdCHZMnT0ZCQgKeeeYZdOrUCXl5ebj33nvx4osvIjk5Gd26dVPXjYyMxLlz5xAcHIwhQ4ZotDNnzhx07twZcXFxWL9+vUZZr1698Ndff2HKlCnw9PSEQqHAoEGD8OGHH2LHjh2wtrZulPtvDJIQzWsdaS8vL6Snp8PT07Pey2waQpc37kNKxRX0L3gSP3/yhbHDISIiumslJSXB398f48aNw7fffmvscIioFuvXr0dISIjOPbSaSn1yA/YYGZhVbilcb8qgKNW+EzURERFVS0hIgI+PD55++mmt5Rs2bAAA9O7duynDIqIWgomRgV3JbofCwg4wK+ZeukRERLUJDAxETk4OtmzZgq1bt2qUxcbGYuXKlZDL5Rg3bpyRIiSi5oxv601E2bxGLBIRETU6hUKBL774AuPHj8fYsWMREBCAtm3b4uLFi0hOToa5uTmWL18Ob29vY4dKRM0Qe4yaCvMiIiKiOo0dOxYJCQkYM2YMSkpKcPDgQUiShJEjRyI+Ph6zZs0ydohE1Exx8QUDG+ywAwUVSng/uh/fbl9p7HCIiIiIiFqM+uQGHEpnYDKlArKqKgB1L5lIRERERETGwaF0TaSZdcwRERERETUr7DEysPQuu1BkVgwX8ypjh0JERERERDowMTKwsm5/4bq4hvzSfsYOhYiIiIiIdOBQOgNr7VQEpW02YMENXomIiIiITFWz7THKzMxEQECA1rKZM2di5syZTRqPUuIcIyIiIiKixhYdHY3o6GitZZmZmXq302wTIzc3N5w+fdrYYcAqtxguSsC6hD1GRERERESNrbZOD9Vy3fpotomRqbiU2RZFlq0hK1EYOxQiIiIiItKBc4yaCJfrJiIiIiIyXUyMDI4buxIRERERmToOpTMw//hpyCsXsOn3s7FDISIiIiIiHZgYGZi8whrmZYBMsOeIiIiIiMhUcSidoTEfIiIiIiIyeewxMrD0Tr/gplQMR3mxsUMhIiIiIiIdmBgZWEm3v5CJdLgU9TJ2KEREREREpAOH0hmYQ5siVLW+DliWGzsUIiIiIiLSgYlRExHgPkZERERERKaKQ+kMzCq3CM5VAtZlFcYOhYiIiIiIdGBiZGAXMzxRbGkN80IrY4dCREREREQ6cCidoan2L+JIOiIiIiIik8XEyMCkfzYyEoKZERERERGRqeJQOgPz++M5ZJUANr0PGDsUIiIiIiLSgYmRgVmUtoa8WAaZ0szYoRARERERkQ4cSmdgEicXERERERGZPPYYGdjV9v+HbKkIdvJCY4dCREREREQ6MDEysMIeR5CJNNgXBBo7FCIiIiIi0oFD6QzMybMIlXaZqLIpNXYoRERERESkAxMjQ/tnGyNwuW4iIiIiIpPFoXQGZplfAKcyJWxKy40dChERERER6dBsE6PMzEwEBARoLZs5cyZmzpzZJHGcT/VEiZUC8hu2TXI9IiIiIqKWJDo6GtHR0VrLMjMz9W6n2SZGbm5uOH36tLHDwC1j6YwaBRERERFRc1Rbp4eXlxfS09P1aodzjAxMUuVDzIuIiIiIiExWs+0xMhWd/pqAq8VAq64HjR0KERERERHpwMTIwKxKHKAoMIek5KMmIiIiIjJVHEpnYFLdVYiIiIiIyMjYjWFgV9sdQXZVMWwsiowdChERERER6cDEyMBu9jiCa8qLsL6pfelwIiIiIiIyPg6lMzDXdiWocLiKSlv2GBERERERmSomRgYmcZYREREREZHJY2JkYJY3b8KxtAo2ZeXGDoWIiIiIiHTgHCMDS05pg1IrCYo8O2OHQkREREREOrDHqIkIDqkjIiIiIjJZTIwMTVQnRJIQRg6EiIiIiIh0uePEaOnSpZAkCVVVVTrrnD17FsHBwWjTpg2sra0RGBiIjz/+GKKWZCEhIQEjR46Es7MzWrVqhb59+2LTpk13Gm6T63RyFNr9/B9YF3MoHRERERGRqbqjOUZCCHz77be11vnrr78waNAgFBQUQJIktG7dGidOnMBLL72EP/74Q2uys3PnTowePRoVFRUwNzeHpaUlEhISMGnSJPz9999YsmTJnYTdpFoVOcMyzwLmlRbGDoWIiIiIiHRocI9RVVUVFi1ahMTERJ11lEolJk6ciIKCAjz33HO4du0acnNzsX//ftja2uKrr76qkRjdvHkTzz33HCoqKhAeHo7s7Gzk5ubi66+/hrm5OZYuXYrffvutoWEbgWpuEYfSERERERGZqnonRjt27EBoaCh8fX0RGRlZa90ffvgBZ8+exX333Yc1a9bA1dUVMpkMgwcPxqeffgoA+OCDDzTOWbt2LXJzczFs2DAsWbIEdnZ2kMvlmDBhAhYtWgQAWL58eX3DNppMjxPI7fQbSiyKjR0KERERERHpUO/EaOvWrYiJiUFqamqddWNjYwEAzzzzDCwsNIeSjR07Fq1atcKxY8dw5cqVGueEhIRAkjRXcgsJCQEA/PTTTygvvzv2BcrrcQQZvbcj07nQ2KEQEREREZEO9U6MFi9ejFOnTqk/tfm///s/AMBjjz1Wo0wul+ORRx4BAPzxxx8Aqucs/fnnn5AkCUOGDKlxjru7O+677z4UFxfjxIkT9Q3dKNx9S1HhmIHK1kXGDoWIiIiIiHSo9+ILnp6e8PT0rLOeUqnEhQsXAAC+vr5a63To0AEAcP78eQBARkYGiouL4eTkBEdHR53nnDhxAufPn0evXr3qG36Tk/0zx0hwjhERERERkcky2D5GN2/eRHl5OczNzdGqVSutdVTJT2ZmJgAgKysLAGBvb6+z3dvPMXWWhQWwL6uEdUWZsUMhIiIiIiId7mi57toUF1cvNlBbkuPg4KBRV/VP1XF9ztFFCIGbN2/qHe/tFAoFFApFg89XOfO3Eyqs/GCV43THbRERERERtSRlZWUoK2t4B0Nt+6bezmCJkSqI2oIxMzMDAPXmsA05R5eMjAzY2TV8U9WIiIg6V93ThxASBCRA4lA6IiIiIqL6WLp0KaKioprkWgZLjGxsbAAA+fn5EELUWGEO+LfXR1VX9c+8vDyd7d5+ji4eHh44c+ZM/QP/R2P0FgGApNrHiHkREREREVG9zJs3D6+88kqDz/f390dGRoZedQ2WGLVu3RoWFhYoLy9HYWEhbG1ta9S5fv06AMDZ2Vnjn/n5+Trbvf0cXSRJQuvWrRsSeqO69+wwmN1QopXPn8YOhYiIiIjornKn01u0dc7oYrDFF2QyGdq3bw8ASE5O1lrn77//BgB07NgRQPWKd9bW1sjLy0N2drZe55g624I2sM72hlmlRd2ViYiIiIjIKAyWGAHAAw88AADYu3dvjbLy8nLExcUBAO6//34A1Rld3759IYTAvn37apyTkZGBU6dOwcrKCoGBgYYLnIiIiIiIWhSDJkYjR44EAHz11Vc1VpPYsmULCgsLERgYiHbt2tU4JyYmpsYiDDExMQCAoUOHwtLS0oCRN54s1yTkdUhAqUXtq+gREREREZHxGDQxGjVqFPz8/HDq1ClMmzYNWVlZqKqqws8//4zp06cDAF5//XWNc6ZOnQonJyfs3bsX8+fPV++H9M033yAiIgKSJGHu3LmGDLtRZfU4gvT7t+CaS8OXDiciIiIiIsMyaGIkk8mwadMm2NraYv369WjTpg0cHR3x6KOPoqCgAJMmTUJwcLDGOaq6crkc77zzDpydneHo6Iinn34alZWVWLBgAR588EFDht2o2vmXo8LpCsrsbxg7FCIiIiIi0sGgiREA9OjRA4cPH8aECRPg5OSE8vJydO3aFatWrcKXX36p9ZygoCD89ttvCAoKQqtWrQAAffr0wVdffYW33nrL0CE3Kkn65xFzHyMiIiIiIpN1x8t167ObbKdOnfD111/Xq90+ffpgx44dDQ3LZFgUFqB1eRVsyiuNHQoREREREelgsH2MqFpSYisoLe+FTY6jsUMhIiIiIiIdDD6UrqWrFGZQQgYB/TeXIiIiIiKipsXEyMAkJkRERERERCaPQ+kMrOP5QajKr0Qrr7+MHQoREREREenAHiMDsy/wQqtr90JefndsSEtERERE1BIxMWoqHFFHRERERGSyOJTOwLKdzuOGeSkUimJjh0JERERERDowMTKwzG5HcLnyb1TmtzV2KEREREREpAOH0hmYz31VqHC+hGKnXGOHQkREREREOjAxMjCZxMlFRERERESmjomRgZkXFcK2ogrWFRXGDoWIiIiIiHTgHCMDO3tEDsmiA+xynI0dChERERER6cAeIwMrr5KjEnIIYWbsUIiIiIiISIdm22OUmZmJgIAArWUzZ87EzJkzmyQOiRsYEREREREZTHR0NKKjo7WWZWZm6t1Os02M3NzccPr0aWOHgQ5X+qEkpxdauZ4wdihERERERM1ObZ0eXl5eSE9P16sdDqUzMKcb7WB7pQssyq2MHQoREREREenAxMjAuFo3EREREZHpa7ZD6UxFbuvLKPAqgdyi2NihEBERERGRDkyMDOxy4BFcqkhESb6nsUMhIiIiIiIdOJTOwPx6C5S7pKHYJcvYoRARERERkQ5MjAxNNclICOPGQUREREREOjExMjDz4mJYVyhhVVVp7FCIiIiIiEgHzjEysLO/V0Fu7g3HHBdjh0JERERERDqwx8jASqsUqIACVUrmoEREREREpoqJkYFJ4EZGRERERESmjt0YBuaT0Qd52Z3RyvG0sUMhIiIiIiIdmBgZmEuBN+zSLGBpnWrsUIiIiIiISAcOpTMwGUfSERERERGZPPYYGVh+q6sobFMKc4tSY4dCREREREQ6MDEysItd/kJax79QlO9m7FCIiIiIiEgHDqUzsC79ZCh3vYgCt2vGDoWIiIiIiHRgYmRgMkn1iIVR4yAiIiIiIt2YGBmYrKQElpVKKKqUxg6FiIiIiIh04BwjAzt7sBhWuAdtcp2NHQoREREREenAHiMDK6xQoAxWqKiyMHYoRERERESkAxMjA5Ok6o2MuJ0REREREZHparZD6TIzMxEQEKC1bObMmZg5c2aTxOGd1R2ZVzvA2v5sk1yPiIiIiKgliY6ORnR0tNayzMxMvdtptomRm5sbTp8+beww4F7gC/sL5rDudNXYoRARERERNTu1dXp4eXkhPT1dr3Y4lM7A/h1Cx+W6iYiIiIhMVbPtMTIVN6yyUOxSCjOLUmOHQkREREREOjAxMrCUgCO44J0A53wu101EREREZKo4lM7Aug+yQIXbedxw129sIxERERERNT0mRgYmk/55xBIgOM2IiIiIiMgkMTEyMKm8DBZVAhaVVcYOhYiIiIiIdOAcIwNL2pcL2ypPtMlxghCAxJ1eiYiIiIhMDnuMDKygzAolwgYVVdbGDoWIiIiIiHRgYmRgkrqLSHCOERERERGRieJQOgNrl98VaVfc0crmHBMjIiIiIiITxR4jA/Ms6AjH5H6wKrI3dihERERERKQDEyMDU42kk8DluomIiIiITBWH0hlYoSIXJQ6lsJCXGTsUIiIiIiLSgYmRgZ3u+BfOexyCU54ze4yIiIiIiEwUh9IZWN/hNqhwO4d8r4vGDoWIiIiIiHRgYmRgMtm/j1ipZJcREREREZEpYmJkYFJFJcyVAuZKJYfSERERERGZKM4xMrCzO9NhX+oO1zwHY4dCREREREQ6sMfIwPJLbFAsbFFe+f/s3Xd4HOW99vHvzHZJq94sy70bjOk9hWpIIEAgoUMgBYgSQiCNkBzghBM4ySEhASfhJc0kJvSE0HsHgw0G44LciySrt11J22bm/WNUbZkYsHaFfX+ua65d7Tw7+9uVMXv7adk4qMtIRERERGQ0UjAaYUbvRkYGmmMkIiIiIjJaaSjdCKuMzqRoY5js4CbNMRIRERERGaV222DU0NDA7Nmzhz1XVVVFVVVVWuoY1zWD4lXTyJ7yKLZtA560vK6IiIiIyJ5g/vz5zJ8/f9hzDQ0NO32d3TYYlZWVsXLlykyXgdmbg4zMliEiIiIislv6oE6PyspKamtrd+o6u20wGi26PVHiuRGCvh4c2850OSIiIiIiMgwFoxG2YsI7rCl8iqKOvN6hdCIiIiIiMtpoVboRdvSZRSTLV9M2boMWXxARERERGaUUjEaYafTNLnJQMhIRERERGZ0UjEaYBzAdMB0HW8FIRERERGRU0hyjEbb8vrUUt5VS0pGnxRdEREREREYp9RiNsJbubKJOHvFUDo6tHiMRERERkdFIwWiEGb0fsSKRiIiIiMjopaF0I6wiOYHC6iPI9W7Vct0iIiIiIqOUeoxG2PjkDEreO5785goFIxERERGRUUrBaIT1L9ftGDhalU5EREREZFRSMBphSW+MZFY7KV9Ciy+IiIiIiIxSmmM0wpaXrqD6pHsp7AhnuhQREREREdmBtPYYbd26la9//evsvffehMNhDjnkEK677jri8fiw7aurqzn77LMpLy8nKyuLuXPncuutt36ihqQdfXYZybLVtI5fqzlGIiIiIiKjVNp6jBYvXsy8efNoa2vD4/FQVFTEm2++yZtvvsl9993Hq6++Sn5+fn/7t956i6OOOopIJIJhGOTm5rJs2TIuv/xyFi1axMKFC9NV+sfi83jAcDAMtMGriIiIiMgolZYeo2QyycUXX0xbWxuXXXYZHR0dNDQ0sGnTJo488khWrlzJD3/4w/72tm1z7rnnEolEuOCCC6ivr6e1tZVnnnmGcDjMXXfd9YkJRobZ+xF/gnq5RERERET2NGkJRq+99hrLly9nzpw53HbbbWRnZwMwfvx4/vGPf+D3+/nrX/9KMpkE4KGHHqK6upp99tmHO+64g9LSUkzT5JhjjuH2228H4Oabb05H6R/b+/etpKy+mKmbC9VjJCIiIiIySqUlGC1btgyAz372s5jm0JesrKxk+vTpJBIJqqurAXj44YcBOOecc/D7/UPan3HGGeTk5LB06VJqamrSUP3H09QZImIX0JPKV6eRiIiIiMgolZZg1NXVBYBlWcOeT6VSAHR3dwPw+uuvAzBv3rzt2vp8Po4++mgAFi1atMtr3dUM093HyAFsJSMRERERkVEpLYsv7LfffgA8+eSTxONxAoFA/7n333+fNWvWEAgEmDFjBrZts379egCmTp067PWmTJkCwLp160a48o+v3BlL/rqDyKVd84xEREREREaptASj4447jk996lO8/PLLnHHGGdx0001MmDCBxYsX881vfhPLsvjBD35AXl4e7e3tJBIJvF4vOTk5w16vsLAQgIaGhh2+puM4dHZ2fuSaA4HAkAD3UU0wplC2tJCC0te1XLeIiIiIyIcQj8d3uLXPzvgw2/ykJRiZpslDDz3EKaecwiOPPMIjjzwy5PwVV1zBDTfcAAwMpxu8dPe2CgoKhrQdTl1dHXl5eR+55muvvZbrrrvuIz+/T99QOhwDB/UYiYiIiIjsrBtvvJHrr78+La+Vtn2M/v3vf/cvwuDz+SgqKqKhoQHHcXj88cc555xzOOigg/pT3QelO4/HA+x4zhJARUUFq1at+sj17oreIgDLTJIKdJHyJjSSTkRERETkQ7j66qu58sorP/LzZ82aRV1d3U61TUswuvvuu/nKV75CcXExd999N6effjper5dIJMItt9zCtddey3HHHcebb75JaWkpAO3t7TiOg2EY212vr6eob9nv4fRtCptpq3JXU/2F/0deJBvb+kamyxERERER+cT4uNNbhssSO5KWVemuueYaAP70pz9x5pln4vW6eSwcDvPTn/6U73znO3R0dPCLX/yC3Nxc/H4/lmURjUaHvV5jYyMAxcXF6Sj/YznsjHEky9bSNn6dFl8QERERERmlRjwYtbW1sX79egKBAJ/73OeGbXP66acDsGTJEkzTZPLkyQCsXr162PYrVqwAYNq0aSNQ8a7l9xlgWmBaWnxBRERERGSUGvFgFAqF8Hq9H9iN1TefqG/o22GHHQbAU089tV3bRCLBCy+8AMChhx66i6vd9UzDxKDvvavHSERERERkNBrxYBQMBpk1axaxWIzHHnts2DYPPvggAPvvvz8AJ598MgB33XXXdsvz3X///USjUebOncuECRNGsPJdY/0jqyitL2DylgKNpBMRERERGaXSMsfoqquuAuCrX/0q9913H6lUCoBIJMLPfvYzfvOb35CVlcWll14KwCmnnMLMmTNZvnw5l1xyCU1NTViWxbPPPtvf5oc//GE6Sv/Ymtv8dNpFdCcLNcdIRERERGSUSsuqdBdeeCGLFi3iD3/4A1/+8pfx+/0UFRVRX1+P4zgEg0H+8Ic/MHPmTMDd92jhwoV89rOfZcGCBfztb38jJyenf8PW8847j7PPPjsdpX9s/fsYYWArGImIiIiIjEpp6TEC+P3vf89zzz3HKaecwvjx4+no6GDOnDlcdNFFrFixgvPPP39I+/3335/Fixdz5plnUlRURCKRYM6cOdx2223ceeed6Sr7Yys0i8jduC/h5gotviAiIiIiMkqlbYNXgKOOOoqjjjpqp9vPmDGDu+++ewQrGnnjPBMZs+Q08vPf01A6EREREZFRKm09Rnsq06R3TTpDuUhEREREZJRSMBphjuFgexLYhqU5RiIiIiIio1Rah9LtidYEN7Dqi78kuyuEY38+0+WIiIiIiMgwFIxG2NzPjyO5aT3tySCWlelqRERERERkOApGIywYMDDMFJgpHA2lExEREREZlTTHaIQZGIABhoNW6xYRERERGZ3UYzTC6l5cR2lDHlk9Ae1jJCIiIiIySikYjbCWVg8dVgl2KqChdCIiIiIio5SG0o0w0/QA4KChdCIiIiIio5V6jEZYrjdMeMtehO24htKJiIiIiIxSCkYjbIy/grFvfJlw1gb1GImIiIiIjFIaSjfCTI/7ETsYmmMkIiIiIjJK7bY9Rg0NDcyePXvYc1VVVVRVVaWlDsNw5xc5jqOhdCIiIiIiu9j8+fOZP3/+sOcaGhp2+jq7bTAqKytj5cqVmS6DTWYdq750PYG4D8vaP9PliIiIiIjsVj6o06OyspLa2tqdus5uG4xGi+mfGUvqrU3ELQ846jESERERERmNFIxGWDBgYHiSGFikUqlMlyMiIiIiIsPQ4gsjzDRMjN77mmMkIiIiIjI6qcdohLW8U0NxYw7epA/LUjASERERERmNFIxGWHurQUeqjEDSg21bmS5HRERERESGoaF0I6x/HyMDbFv7GImIiIiIjEbqMRphWd4Q2VunE7CTWJYWXxARERERGY0UjEZYUbCEca+eR8DXjH2ueoxEREREREYjDaUbYWb/J2xo8QURERERkVFKwWiEmd7eOUaAo+W6RURERERGJQ2lG2EtTjurvvgzTNvBsr+f6XJERERERGQYCkYjrGJuKVb5ZrqdFJaW6xYRERERGZUUjEZYwG/g8SYwnCSOlusWERERERmVNMdohBmGAYCDQ0o9RiIiIiIio5J6jEZY16ZWCpuC5Dl+7HItviAiIiIiMhopGI2waIdDW7IMA0ur0omIiIiIjFIaSjfCvD43ezqA5SgYiYiIiIiMRuoxGmE+j4fsxklgpLBSmmMkIiIiIjIaKRiNsJxAmAkvXYxjxOAzrZkuR0REREREhqGhdCPM9Bi99wxsrUonIiIiIjIqKRiNMMMcCEaWFl8QERERERmVNJRuhMWNJO9/4X+xsTje/nKmyxERERERkWHstsGooaGB2bNnD3uuqqqKqqqqtNSROzYXu3IjUaeHFBpKJyIiIiKyK82fP5/58+cPe66hoWGnr7PbBqOysjJWrlyZ6TLw+0y8vjiG04NtpTJdjoiIiIjIbuWDOj0qKyupra3dqetojtEIMzD679tojpGIiIiIyGi02/YYjRapaJzcJi9ZTg52mXqMRERERERGIwWjEZZKGLQmynGwsZKaYyQiIiIiMhppKN0I83gGPmIt1y0iIiIiMjqpx2iEeXweQq1jsXFwCp1MlyMiIiIiIsNQMBphhmkw+blLSZLCO2VZpssREREREZFhaCjdCDM9g1al09oLIiIiIiKjkoLRCDM8Jn0rdtuaYyQiIiIiMippKN0IMz0Ga+b9hpQnzhwOznQ5IiIiIiIyDAWjkWYYOJM20kk7KeegTFcjIiIiIiLD0FC6EWYYEAjEMHxdgCYZiYiIiIiMRgpGaWD0TjKyHC3XLSIiIiIyGmkoXRqE68EwszA88UyXIiIiIiIiw1AwSoOm7rEk/N2kTHXQiYiIiIiMRvqmngb9OxnZGkonIiIiIjIaqccoDQKREvDGcMKZrkRERERERIajYJQG01/+CpGUSdZJr2a6FBERERERGYaG0qWB0TuWzrHtzBYiIiIiIiLDUjBKAwM3EDlarltEREREZFTSULo0WHfY3XSG2hjjG5fpUkREREREZBgKRumw12banU1Ee8ZkuhIRERERERnGbhuMGhoamD179rDnqqqqqKqqSlst2VkxjGQEI5FI22uKiIiIiOwJ5s+fz/z584c919DQsNPX2W2DUVlZGStXrsx0GQCYvVO5bMfKcCUiIiIiIruXD+r0qKyspLa2dqeus9sGo9EkZ0uCcl+IYE8y06WIiIiIiMgwFIzSoL69ks5cH8nuYKZLERERERGRYWi57jQwnb6hdNrHSERERERkNFIwSoNAPBtfVwFmypPpUkREREREZBgaSpcGs989mayOfAoOejHTpYiIiIiIyDDUY5QGhum4dzSSTkRERERkVFIwSgNPbzDSFCMRERERkdFJQ+nSYP30F9iU1UhWKpzpUkREREREZBgKRmlgH9BOc/JdmiL7ZboUEREREREZhobSpUF+bgwz0IHHH810KSIiIiIiMgwFozQwDXeZbkerL4iIiIiIjEoaSpcGoY0Rys0AeZ1WpksREREREZFhpK3HyHEc7rjjDg4++GDC4TATJkzg7LPPZuPGjTt8TnV1NWeffTbl5eVkZWUxd+5cbr31VhzHSVfZu0R9QxmdPeOJdxZmuhQRERERERlGWoKR4ziceeaZfOMb32Dx4sV4vV62bt3K3XffzZw5c1i2bNl2z3nrrbc46KCDuPvuu2lsbMTv97Ns2TIuv/xyzjvvvHSUvct4ej9mh09WoBMRERER2VOkJRjdfPPN3HfffVRWVvLqq6/S0tJCW1sbF110EdFolK985StDeoFs2+bcc88lEolwwQUXUF9fT2trK8888wzhcJi77rqLhQsXpqP0XcJn+/HEcjBTGrkoIiIiIjIajXgw6urq4sYbb8Tv9/Poo49y+OGHY5om2dnZ3H777UybNo2lS5eydOnS/uc89NBDVFdXs88++3DHHXdQWlqKaZocc8wx3H777YAbtj4pZm/6FFMf+T5j6mZmuhQRERERERnGiAejxx9/nNbWVo477jj22WefIed8Ph9XXHEFn/3sZ1m/fn3/4w8//DAA55xzDn6/f8hzzjjjDHJycli6dCk1NTUjXf4u4en7lG0tAigiIiIiMhqN+Df1p556CoAvfvGLw57/5je/yfPPP88ZZ5zR/9jrr78OwLx587Zr7/P5OProowFYtGjRri53RJjuat04Wq1bRERERGRUGvFJLytXrgTYrrdoR2zb7u89mjp16rBtpkyZAsC6det2QYUjb3PZe2wufxQnpjlGIiIiIiKj0Yj3GPWFnJKSEhYuXMhJJ51EcXExU6ZM4YwzzuDtt98e0r6zs5NEIoHX6yUnJ2fYaxYWusteNzQ0jGzxu4hzsEXztLeom/TJqFdEREREZE8z4l0YnZ2dgLtYwq233gpAWVkZmzZtYv369Tz00EPMnz+fb3zjGwB0d3cDkJ+fv8NrFhQUDGk7HMdx+l/7owgEAgQCgY/8/MEKCy2MeDum1bFLriciIiIisieIx+PE4/GP/PwPs//piPcYxWIxAG699Va+853v0NraSn19PZFIhP/5n//BsiyuuOIKNmzYAAwU/0FvwuNxJ+1YlrXDNnV1deTl5X3k48Ybb9xVHwFej5s/tY+RiIiIiMjOu/HGGz/Wd/q6urqdfq0R7zEqKCigubmZs846i1tuuaX/8VAoxI9//GNWr17NggULuO2227j55pvJzs4GoL29HcdxMAxju2v29RT1tR1ORUUFq1at+sh176reIgD/xjbKoj5KIgpGIiIiIiI76+qrr+bKK6/8yM+fNWvWToejEQ9G5eXlNDc3c9FFFw17/swzz2TBggW89957AOTm5uL3+0kkEkSjUcLh8HbPaWxsBKC4uHiHr2sYBrm5ubvgHXx89ZvDRIITyenYcb0iIiIiIjLUx53eMlwny46M+FC6srIyAMaOHTvs+b7Ht27d6hZkmkyePBmA1atXD/ucFStWADBt2rRdWutI8fT+QtRfJCIiIiIyOo14MJoxYwaw45DTN7do1qxZ/Y8ddthhwMAeSIMlEgleeOEFAA499NBdWeqI8Rk+zJQfQxu8ioiIiIiMSiP+Tf2kk04C4Lbbbhv2/B//+EcADjjggP7HTj75ZADuuuuu7VahuP/++4lGo8ydO5cJEyaMRMm73KzoXKb96xomLv9MpksREREREZFhjHgwOuGEE5gzZw7PPfccX/nKV2hubgago6ODb3/72zzyyCOMGzeOqqqq/ueccsopzJw5k+XLl3PJJZfQ1NSEZVk8++yzXHrppQD88Ic/HOnSd5neRfRwnJ0f4ygiIiIiIukz4sHIMAwWLlxIXl4eCxYsoKSkhPLycgoKCrjtttsoKirizjvvHLKZq2maLFy4kHA4zIIFCygvL6ewsJBjjz2WSCTCeeedx9lnnz3Spe8yprf3Y1YwEhEREREZldIy6WXOnDm8++67XHTRRYwdO5aOjg722WcfLrnkElasWMFnP/vZ7Z6z//77s3jxYs4880yKiopIJBLMmTOH2267jTvvvDMdZe8yjTlbqDny79ROW5LpUkREREREZBgjvlx3nwkTJvDnP//5Qz1nxowZ3H333SNUUfoYB2bTtOZ1unsKM12KiIiIiIgMI23BaE9WXOaB2jYMU0PpRERERERGI60fnQYerw8ABzvDlYiIiIiIyHDUY5QG3rp2yjq8ZPWox0hEREREZDRSMEqD5vUmka5JEA1nuhQRERERERmGhtKlgT/g5k/H0FA6EREREZHRSMEoDfze3o45xwTHyWwxIiIiIiKyHQ2lS4Op/hlMv/86srK2gmWBVx+7iIiIiMhooh6jNPCH/BgY4BhgazidiIiIiMhoo2CUBj6/BwAb0+0xEhERERGRUUVjutKgy9dJ7aH34SeFk/oiWrRbRERERGR0UTBKg6wDxtK88mUMy0cqmcCX6YJERERERGQIBaM0GFuZg53dimF7SMaTCkYiIiIiIqOM5hilQcDXG4UMh0QykdliRERERERkO7ttj1FDQwOzZ88e9lxVVRVVVVVpq8XXEqW008TBQyKRStvrioiIiIjs7ubPn8/8+fOHPdfQ0LDT19ltg1FZWRkrV67MdBkA9DQkiUanAA6JeDLT5YiIiIiI7DY+qNOjsrKS2tranbqOhtKlQVa2HwAHg1i8J8PViIiIiIjItnbbHqPRJBTyQ+8i3d3xWGaLERERERGR7SgYpUF2KItp/7wGx/GQuliddCIiIiIio42CURr4Qj5My4+DQzJhZ7ocERERERHZhoJRGnhDvt6BdNDTrcUXRERERERGGwWjNDB9Hhr2/zcpb5zGyMmZLkdERERERLahYJQOWVk07fUKKV8PceOoTFcjIiIiIiLbUDBKB9PECLdie7swvfFMVyMiIiIiItvQEmlpYvR+1D1JLdctIiIiIjLaqMcoTSraLaIBg1hHd6ZLERERERGRbSgYpUlX60yiOREa6jNdiYiIiIiIbEtD6dLEtN0FuxOJRIYrERERERGRbSkYpYnpuB91PKnFF0RERERERhsNpUuTWa9/gcb4WMrObMl0KSIiIiIisg31GKWJP+XHkwxix41MlyIiIiIiIttQMEoT07QASCasDFciIiIiIiLb0lC6NGmYuIz60LvUmaWZLkVERERERLahYJQmW2atoym8kUj2CZkuRUREREREtqFglCbeog6sYBPBnEimSxERERERkW1ojlGaePAAkLCTGa5ERERERES2pR6jNClrj9GdA2YsmulSRERERERkG7ttMGpoaGD27NnDnquqqqKqqiqt9SS2TqCrzEtDd35aX1dEREREZHc2f/585s+fP+y5hoaGnb7ObhuMysrKWLlyZabL6OfB3b8oadsZrkREREREZPfxQZ0elZWV1NbW7tR1NMcoTUzHDUYptI+RiIiIiMhos9v2GI02UzbPoeetLzFxUn2mSxERERERkW2oxyhNAo4fX08eRsKf6VJERERERGQbCkZp4vG4c4tSlpHhSkREREREZFsaSpcmnfkNNO7zBIGAsqiIiIiIyGijYJQmdVNjNGS/TDA1MdOliIiIiIjINhSM0iSr1CLlbcDn5GS6FBERERER2YbGdaWJz3AXXUiRynAlIiIiIiKyLfUYpUlRV4Jir00oFct0KSIiIiIisg0FozQxawN0582gsbsg06WIiIiIiMg2NJQuTXweHwCWaWW4EhERERER2ZaCUZoE/W4wsg07w5WIiIiIiMi2NJQuTYopYuKT38KvT1xEREREZNTR1/Q0yQoECURKMPzqMRIRERERGW00lC5N/FluBrVsZVERERERkdFG39LTJejQvNdzWF6bVOo4vF4j0xWJiIiIiEgv9RiliT2mhPoDHqF13ydIWMlMlyMiIiIiIoOoxyhNsvLzSebX48GLbSQAf6ZLEhERERGRXuoxSpNgIAQYODgkrESmyxERERERkUHUY5QmQRNKui1MwyaWSEIo0xWJiIiIiEgf9RilScg0SDXuRaRtBhs3xzJdjoiIiIiIDLLb9hg1NDQwe/bsYc9VVVVRVVWV1nr8Wdl4LBNI0R3tTutri4iIiIjsrubPn8/8+fOHPdfQ0LDT19ltg1FZWRkrV67MdBn9fKEQHtvtoOvu7slwNSIiIiIiu4cP6vSorKyktrZ2p66z2waj0caflcWMN+bRkhpLyQVjM12OiIiIiIgMomCUJoGgn3A0h0iiDKtbm7uKiIiIiIwmWnwhTbJCQTymu0x3V7sWXxARERERGU3UY5Qm/kCAtoo1NAebWNNmMo/xmS5JRERERER6KRilSSAUYMWc5URy24mWzsp0OSIiIiIiMoiCUZr4gl6ipQ2kQq2UT9Ry3SIiIiIio4nmGKWJ12dg2h4coDvRlelyRERERERkEPUYpYnXCxVRi3ZPikj9zm80JSIiIiIiI089Rmni9ULJpgnEWmfx4vNOpssREREREZFBFIzSxOsFw/EAEEtquW4RERERkdFEwShNvF7w4G7s2pNKZLgaEREREREZTHOM0sQwoKStmPFrvsTkyQWZLkdERERERAZRMEojv+Ul1FqJWRLIdCkiIiIiIjJIRofSvfvuu/h8Ps4///xhz1dXV3P22WdTXl5OVlYWc+fO5dZbb8VxPqGLF3hsAOJxI8OFiIiIiIjIYBnrMbIsi6997WukUqlhz7/11lscddRRRCIRDMMgNzeXZcuWcfnll7No0SIWLlyY5oo/vkSom9bpr+LkhYHPZrocERERERHplbEeo9/85jcsWbJk2HO2bXPuuecSiUS44IILqK+vp7W1lWeeeYZwOMxdd931iQxGG8oM6g7+F+1zn8t0KSIiIiIiMkhGgtGGDRv46U9/usPzDz30ENXV1eyzzz7ccccdlJaWYpomxxxzDLfffjsAN998c7rK3WW6cnwkC2spHNea6VJERERERGSQjASjSy65hJ6eHi688MJhzz/88MMAnHPOOfj9/iHnzjjjDHJycli6dCk1NTUjXuuu5MN9Lwlby3WLiIiIiIwmaQ9GCxYs4Omnn+arX/0qRx111LBtXn/9dQDmzZu33Tmfz8fRRx8NwKJFi0au0BGQm4T8eAqinaQsK9PliIiIiIhIr7QGo8bGRq688krKy8v55S9/OWwb27ZZv349AFOnTh22zZQpUwBYt27dyBQ6QsZ2J7FbprJxyxg21sQyXY6IiIiIiPRK66p0l19+Oa2trdx7773k5+cP26azs5NEIoHX6yUnJ2fYNoWFhQA0NDTs8LUcx6Gzs/Mj1xoIBAgEdu1+Q4YniGF7wHBoiXQzlexden0RERERkd1JPB4nHo9/5Od/mG1+0haMHnnkEe655x5OPvlkvvSlL+2wXXd3N8AOgxNAQUHBkLbDqaurIy8v76MVC1x77bVcd911H/n5w7F9Afwpkx4PtEd7dum1RURERER2NzfeeCPXX399Wl4rLcEoEolw2WWXEQ6H+d3vfveBbftS3QelO4/HA7h7Ie1IRUUFq1at+gjVunZ1bxGA4/cx+/WjabdmELqkdJdfX0RERERkd3L11Vdz5ZVXfuTnz5o1i7q6up1qm5ZgdPXVV1NTU8Ott95KZWXlB7bNznaHl7W3t+M4DoZhbNemr6eor+1w+jaFHVV8QUpbCkhY40lFPZmuRkRERERkVPu401uGyxI7MuKLL7zzzjv87ne/49BDD+Wb3/zmf2yfm5uL3+/Hsiyi0eiwbRobGwEoLi7epbWOOH+QgNmDg0N320cfKykiIiIiIrvWiAejTZs24TgOixYtwuPxYBhG//GVr3wFgL///e/9j0UiESZPngzA6tWrh73mihUrAJg2bdpIl79L+X1e2so20zzlVTa0rMl0OSIiIiIi0mvEh9JlZ2fvcNntzs5OGhsbycnJoby8HADTNDnssMN4//33eeqppzjggAOGPCeRSPDCCy8AcOihh45o7bua3+Plpbmr6Mp/h0jhLGC/TJckIiIiIiKkocfo2GOPZc2aNcMev/jFLwA49dRT+x8Lh8OcfPLJANx1113bLc93//33E41GmTt3LhMmTBjp8nepgM9La3kDgaJmJs/RBq8iIiIiIqNFWjd43VmnnHIKM2fOZPny5VxyySU0NTVhWRbPPvssl156KQA//OEPM1zlh+f3+jAcExuHnqSW6xYRERERGS1GZTAyTZOFCxcSDodZsGAB5eXlFBYWcuyxxxKJRDjvvPM4++yzM13mhxbweynptsiKxelqqc90OSIiIiIi0mtUBiOA/fffn8WLF3PmmWdSVFREIpFgzpw53Hbbbdx5552ZLu8jCfi8TN9YREfzBO6/vyPT5YiIiIiISK+07GO0IxdeeCEXXnjhDs/PmDGDu+++O40VjayA34fhGNiYdGkonYiIiIjIqDFqe4x2R0F/AI/hLrrQbSsYiYiIiIiMFhntMdrTBANewnGTcS+fT/nYOZkuR0REREREeqnHKI2CAT8+M0VOwzT87ZUkEpmuSEREREREQMEorYJBPwl/AgMbLItIJNMViYiIiIgIKBilVSDgp8tn0j3xderHPEV7ZyrTJYmIiIiICApGaZWVFWB9bogNRzxI56H/Iu5EM12SiIiIiIigYJRWgVCQpqwAqbwWpu8TJLdYwUhEREREZDRQMEqjrOyAe8dxP/ZoQsFIRERERGQ0UDBKo2AogGk7FPRY0NpGNKbVF0RERERERgMFozTKyg5gAOM2l/HWEof7H2jLdEkiIiIiIoKCUVqFskNYpoHX8mI5Bs3tCkYiIiIiIqOBglEaZedkARBK2QC0RhSMRERERERGA2+mC9iTZAdDGMCU+jDR2q9QfNAhmS5JRERERETYjYNRQ0MDs2fPHvZcVVUVVVVVaa4IAl4/pgGFCZtw80ySzUVpr0FEREREZHcyf/585s+fP+y5hoaGnb7ObhuMysrKWLlyZabLGMIwDLy2DyfQjoNNe7uD44BhZLoyEREREZFPpg/q9KisrKS2tnanrqM5Rmnmc7xEc6I0Vy5ma+5zdHdnuiIREREREdlte4xGK5/j542xfhrK7qMgfwyp1DmZLklEREREZI+nYJRmfsfH2tww4ycmqKiMkxO2AE+myxIRERER2aNpKF2a+R0fhuPBttwluzvjnRmuSEREREREFIzSzG/4CKYcsrpT0NFBe6wj0yWJiIiIiOzxFIzSzI+fsp4E9vtelix2uPchBSMRERERkUxTMEqzoOGj0+8hGPdj29DU2Z7pkkRERERE9ngKRmnmN/xEfF5ykw4ATW3NGa5IRERERES0Kl2aBU0fFgYH1ZTTuvk0CrIPyHRJIiIiIiJ7PAWjNAuZAbBhbMJLftssehrCmS5JRERERGSPp6F0aRY0fQB4QlEAmpscHCeTFYmIiIiIiIJRmoW8AQAi4Taaxy5ma/BlIpEMFyUiIiIisofTULo0C3n8ALwxMYeWsgfIC4wnkTgtw1WJiIiIiOzZFIzSLOj3Qxdszithxv5d+MxOioocwMh0aSIiIiIieywNpUuzkNedY+RYBgYGSTtJZ7wzw1WJiIiIiOzZFIzSLMvvzjHyJOIUxICOTmrbmzJblIiIiIjIHk7BKM2yAm6PUVFnJ9EXG1myxOF3f23JcFUiIiIiIns2BaM0ywq6iy80BUxKUn5sy6GurTHDVYmIiIiI7NkUjNIsnBUEoCkAlba74EJjZ0MmSxIRERER2eNpVbo0y8kOAdBj2JzkGcdTbx5PqPIzWBZ4PBkuTkRERERkD6UeozTLyckCIEWSuSVlFLVMw9+VS2trhgsTEREREdmD7bY9Rg0NDcyePXvYc1VVVVRVVaW5IldfMLKwcYoLKfZ3Up+I09AAJSUZKUlERERE5BNr/vz5zJ8/f9hzDQ07P2Vltw1GZWVlrFy5MtNlbCc3PxsAyzaIFeYSm/AydbnrqKu7jL331iavIiIiIiIfxgd1elRWVlJbW7tT19ltg9FolZOXA4DjQM8BB7Jq64/oskL4wmcDBZktTkRERERkD6VglGahvACm5cX2pOicMIW995tES08LY6c3oWAkIiIiIpIZWnwhzTzZQTy2u8lrtDtGeU45APXR+kyWJSIiIiKyR1MwSjMjFMRrux97tLWTiqgBzc2srqvBcTJcnIiIiIjIHkpD6dLN58PveOkBIh0Ryv/5DG97fKx/q4ZTpmplOhERERGRTFCPUboZBj7HzaNdPTHGZpXhNSxi3hrq6jJcm4iIiIjIHkrBKAP8hgeA7mg3FUUTCXqSxDy1CkYiIiIiIhmioXQZ4O/92KPRLsaOmc6XXw6xKHEmNQc6gPYyEhERERFJN/UYZUDAdFel6+ruwT92PEfGQgTb86mpUSgSEREREckEBaMMCBh9c4x6oKKCiVmNEIuxcWNm6xIRERER2VMpGGVAlqdvH6M4VFQQL1hHXeW/WRdfREdHhosTEREREdkDaY5RBmR5vWBDpCcG5eWs/uJBxKqfZ2qRD9s+NNPliYiIiIjscRSMMiDs90EMIrEYeL2MP+pUJnveozRvMwUFma5ORERERGTPo6F0GZDj6x1Kl0gAMDF/IgA1kRpSdipTZYmIiIiI7LEUjDIgHPQD0N0bjEo6LUKtEWJNrbzyrjYzEhERERFJNwWjDMgLucGoK+UGI2PJEorfbeTtZR7+61cbSanTSEREREQkrRSMMiAvOwhAj+0GIyZNYnbKg9dOEjE3sXlzBosTEREREdkDKRhlQF5WAICY1ds1NGECExMhso1uenwbqa7OYHEiIiIiInsgBaMMyM8NARCzkzgOEA7zKf80qlZ8jqnrvq1gJCIiIiKSZgpGGVDYG4wsM0Ys5j6WN2E6h3u6MLrjrF6dweJERERERPZACkYZkBPOxsDBMuNEo70PTpzI9Oxa6O5hyxbo6spoiSIiIiIie5TddoPXhoYGZs+ePey5qqoqqqqq0lzRgFBWGK9hYRtuMCopASZOZF3eVpqyf40T/Bxr1sxj330zVqKIiIiIyCfC/PnzmT9//rDnGhoadvo6u20wKisrY+XKlZkuY1jBUC5ewybmiQ30GM2dy5bzT4Hqp5mZX8L48fMyWqOIiIiIyCfBB3V6VFZWUltbu1PX0VC6DAhm5+IxLBwjRUfEch/Mz2f6IZ+jpMKHXVhNQYGT2SJFRERERPYgCkYZEAiF8Zo2OA6tnbH+x6cUTsE0TNpj7bT0tGSwQhERERGRPYuCUQb4ssJ4cXuE2iM9/Y/76xqYWB+jZ0szf3qomo0bM1SgiIiIiMgeRsEoA4xQiGzLnd7V0t46cGLjRmYuq6Nuc4q7nlrFq69mqEARERERkT2MglEmBAKEe4NRa0fHwOMzZrB3T5hcp5PO4DLefTdD9YmIiIiI7GEUjDLBNMklAEBbR9vA4yUl7O2vJM/bhZG0WVWd0n5GIiIiIiJpoGCUIXkeNxi1RwcFI8OgYNo+/HPjPpxQcyXYXpYuzVCBIiIiIiJ7EAWjDMn3ZwHQ0dM59MRee5FlezgwuByAxYvTXZmIiIiIyJ5HwShDioJuMIrEOoaemDMHgIN6XsKih7feAkdbGomIiIiIjCgFowwpzM4BIJqMDD0xeTKp7BB3TXuCZVPPpCPRytatGShQRERERGQPomCUIcXhMABddnRoj5Bp4v3NrSROPp5psx0uvf4tKioyU6OIiIiIyJ5CwShDSvPzAEgYURKJbU6WlXFgxUHk5MCy5iXpL05EREREZA+T1mC0ceNGLrzwQubOnUtOTg5z5szh4osvZtOmTcO2r66u5uyzz6a8vJysrCzmzp3LrbfeirMbTLopKijAwCHl6SQa3f78gRUHggNL65eSslOkUumvUURERERkT5G2YPT4448zZ84c7rzzTt577z1ycnJYsWIFf/nLX5gzZw4PPfTQkPZvvfUWBx10EHfffTeNjY34/X6WLVvG5ZdfznnnnZeuskdMbl4JHsMm5YkMG4ymPv4GeUtXUre+ifO+u4K//jXtJYqIiIiI7DHSEoySySTf+ta3iEajfP3rX6e9vZ36+nra2tq44ooriEQiXHzxxTQ2NgJg2zbnnnsukUiECy64gPr6elpbW3nmmWcIh8PcddddLFy4MB2lj5jcgnK8hoXliRKJbN8DZnR2cnBrCKMrworIa7zwAuo1EhEREREZIWkJRvfccw/r169nr7324vbbbyc3NxeAvLw8fv3rX/PlL3+Z1tZWfvvb3wLw0EMPUV1dzT777MMdd9xBaWkppmlyzDHHcPvttwNw8803p6P0EZObV4rXsHFwaOro2r7BQQdxZLSQvHgjXYWv0d5h8+ab6a9TRERERGRPkJZgtHLlSgDOO+88DMPY7vxFF10EwNKlSwF4+OGHATjnnHPw+/1D2p5xxhnk5OSwdOlSampqRrLsEeUN5xGwTXAcmjoj2zfYZx/2SRVxeGsWXyw5CcewePrp9NcpIiIiIrInSEsw2rhxIwATJ04c9vyYMWOGtHv99dcBmDdv3nZtfT4fRx99NACLFi3atYWmU3Y2OZYfHIfm9vbtzwcCePfdnx/XT+PKbB+m4+Ott6C5Oe2VioiIiIjs9tISjK688kqeeOIJjj322GHPL168GIBx48Zh2zbr168HYOrUqcO2nzJlCgDr1q0bgWrTJDubHMsHQHN7y/BtjjwSgIrlT7H3Xg6OA88+m64CRURERET2HN50vMiBBx64w3NtbW3ceOONAJxwwgl0dnaSSCTwer3k5OQM+5zCwkIAGhoadn2x6eL1Enb8QJL2zrbh2xxyCPh8dNRvJPuABXRs2Icnntif008Hb1p+cyIiIiIie4aMfr1ev349Z5xxBuvXr6eiooKvfvWrRCLufJv8/PwdPq+goACA7u7uHbZxHIfOzs6PXFsgECAQCHzk5++MPDMAdNEeaR++QVYWHHccj6SW8rrnLvxz13Hlyfvj8YxoWSIiIiIio0I8Hicej3/k53+Y/U8zEoySySS//vWvuf766+nu7iY7O5uHHnqIcDjcH2Y+6E14epOBZVk7bFNXV0deXt5HrvHaa6/luuuu+8jP3xn5viA40NHdvuNGl13GsdEG7n74a4QmvUPZ5EYMo3RE6xIRERERGQ1uvPFGrr/++rS8VtqD0apVqzjrrLNYtmwZAHvttRf33nsvs2fPBiA7OxuA9vZ2HMcZdhW7vp6ivrbDqaioYNWqVR+5zpHuLQIo8IcgDp3xYValG6Qsp4y5ZXN5t+Fdnln/DOfMOWfEaxMRERERybSrr76aK6+88iM/f9asWdTV1e1U27QGo7/+9a9UVVXR3d1NKBTixz/+Md///veHhJDc3Fz8fj+JRIJoNEo4HN7uOn0bwRYXF+/wtQzD6N8vabQqCmZBHKKJDw5G2DbH25N4t+EpHvY8SdebX6a50cvVV6enThERERGRTPi401uG62TZkbSsSgfwwAMPcPHFF9Pd3c1RRx3FqlWr+MlPfrLdGzVNk8mTJwOwevXqYa+1YsUKAKZNmzayRY+w4t4ery7rPwSjDRs4/DcPUrihnpbORv76/Iu89hosX56GIkVERERE9gBpCUabN2/mggsuwHEcrrjiCp555hkmTJiww/aHHXYYAE899dR25xKJBC+88AIAhx566IjUmy4lYTcYddtdH9xw8mS8U6ZxclsJgY5GfPv8EweHBQvgQ8wnExERERGRHUhLMPrzn/9Md3c3J510Er/+9a8xzQ9+2ZNPPhmAu+66a7tVKO6//36i0Shz5879wHD1SVBa5C47HidCIvEBDQ0DTjmFEztKyalv5Zh9J+AJ9PD++/Dmm+mpVURERERkd5aWYHTPPfcA8P3vf3+n2p9yyinMnDmT5cuXc8kll9DU1IRlWTz77LNceumlAPzwhz8csXrTpay8DAOHlKeTrv/QacSnPkV2fil/qZ7FT/0H8cWTswC48074gMX5RERERERkJ4x4MLJtm3Xr1gFw4YUXMm3atB0eZ511lluUabJw4ULC4TALFiygvLycwsJCjj32WCKRCOeddx5nn332SJc+4nJLKvAYNraRoLXjg7qMcHd0/fznCToeeOghTv+iQ04ObN4Mjz2WnnpFRERERHZXIx6M6urqSCaTAGzcuJG1a9fu8Kitre1/3v7778/ixYs588wzKSoqIpFIMGfOHG677TbuvPPOkS47LUIlFfgAbJu6lp3YjPaEE8Dvh7VraV/xNGM/dycODg8+CKnUSFcrIiIiIrL7GvHluisrKz/UjrODzZgxg7vvvnsXVzR6GIWFhC0vPaZDTX07sOPlxwHIzYV584i9/SZXvvd/dGcHOPCUGVz+xUPwZmSrXhERERGR3UPaluuWYeTlkWd7AKitadq551xwAcH5t3PSwedhGNA4ZgF5+ZpkJCIiIiLycSgYZZJpUuD1A1C3tXnnnhMMgsfD6bNOJ+wPs6VzC4+ueRSAN96AyH/YEklERERERLanYJRhRX43GDW2dnyo52Xj44Ke6dDWxt+X/Z0/LGjlhhvg9ttHokoRERERkd2bglGGlQYDADRFoh/uiY8+yvH3LGHa2jZ64l2sz/8zhgEvvgjPPz8ChYqIiIiI7MYUjDKsPBwCoLX7Q46B+/znMUvLuGxzKcbWrazqfpEjv7gcgPnz3WW8RURERERk5ygYZdiYPDcYdVtd/3mT18H8fvj615kWz+H0VQYXjjuZK8+fzb77QjwOP/859PSMSMkiIiIiIrsdBaMMK84twGtYpMxOmnZyYbp+hxwC++/PhU0VnPHoBrymwfe+B0VFUFsL//u/YGnBOhERERGR/0jBKMPC4SL8ZoqU5yMEI8OAb37TXalu+XJ4+GGC2XG+XLUCvx/eftt9WEREREREPpi2Bc2wcLiYgJmk56MEI4CyMrj4Yvjd7+i4ZwE/MR6nrqeR8751M+XBicydu8tLFhERERHZ7ajHKMPy88vwmymSvg4aG52PdpETToBTTyX3plsozCklYSV4Inoj+xwwMGkpldpFBYuIiIiI7IYUjDKsvHgS2dhYZoy1DXUf7SKGAV/9Ksa4cVx1+FUUZxVTF63jplduImWnaG6Gb39by3iLiIiIiOyIglGGecrKmRTLAdtmbcOKj3293EAuPyn7MsH2KO80vMPvFv+Op55yqKmBX//a3edIRERERESGUjDKtMJCZuWOBWBzwzsf/3orVjDlxj/wg1fAiHbx9PqnMfe5l+OPB8eBm2+Gxx//+C8jIiIiIrI72W0XX2hoaGD27NnDnquqqqKqqirNFe3YXrP3gTeepSWxhVQKvB/ntzJrFhx0EAe98QaXvhnh94fHeHrdU9x26SmYZpAnnoDf/Q7a2uDss91ReCIiIiIin1Tz589n/vz5w55raGjY6esYjuN8xBn/o1NlZSW1tbWMHTuWmpqaTJezU9557K+ceN8fCcQrWfSruykv/5gXjMXg6qth7Vr+OTnBET/+PaVlk3EcuOsuuPtut9nxx8Nll33MICYiIiIiMkp9mGygoXSjQHn5JPxmkri/mYaGXZBTg0H46U+hpITT1vspvelW6OrCMGDeac1cdpnbU1RdrdXqRERERERAwWhUKC6fQtCwsI046+tad81FCwvh+ushNxfWroX/+i/eWP8SX3/460Qn3MtPf+rwk5+4GUpEREREZE+nYDQKeItLKUwFAFi3Zcuuu/C4cXDDDRAOw4QJrI5sJGWn+Nuyv7GEP1BaZvc3vfdeeOABd4EGEREREZE9jWaXjAZ+P+VONuuNHjbUbQT23XXXnjQJbrkFSko43zDIC+bzx7f/yGNrH6Olp4WrDruKpq0h/v53NxS98w5897tuh5OIiIiIyJ5CPUajxARfHgCbWzfv+ouXlvYvP/eFKZ/jBw1T8caTvFH7Blc9dRWe/Dq+9S3w+91g9O1vu/sdqfdIRERERPYUCkajxLScIgDqu0d4Jb1//IMjn13DTc97Kewx2NK5haueupKDPtXGLbe4HUydnfB//wf//d/Q3Dyy5YiIiIiIjAYKRqPErPIxADRbW7GsEXyhL3wBpk9nRqvBLY8kmdXu5fDKwygIFTBuHPzqV3Duue4S3kuWwFVXQTI5gvWIiIiIiIwCCkajxN6TJuI1LHq89Sx9dwTX0M7LgxtvhKOPpiDp5eePJbjk5R7o7gagM9nKwfPW89vfunvFnnkm+HzuUx1Hw+tEREREZPekYDRKlIybRqmnB8dJ8tgLIzx+ze+HK66Ar38dr+kl8NKrcPnlOGvXcsuiW7jqqat4qW0hP/t5ghNPHHja4sXwX/8FmzaNbHkiIiIiIummYDRKGBUVTHFssG3er6lPwwsa7rC6m25yF2fo6CAe8BDwBEjZKe5ecTffeeJyVjQtB9yeojvvHFic4Ze/hP+webCIiIiIyCeGgtFoUV7OeMsDjkNdyy7cy+g/mTULfvtbuPZaguMm8eNP/ZgfHfEjCghRG6nl6mev5pZFt9Da08I118ARR7gh6aWX4JvfdOck1damr1wRERERkZGgYDRaBINMznc3D2rv3kxPTxpfOzsb9t4bAMMwOKI9zO/v7eKEhlywbJ7d8CyXPHIJHb73+dGP4De/gUMOcQPS88/DZZfB3XensV4RERERkV1MwWgUGTduCl7DIm5syewy2UuXkp0yqXq2k5tfDDCrO5vCUAFTC6cCMHky/OQn8Otfw0EHuQFpypSBp8fjYNsZql1ERERE5CNQMBpFxk7dD7+Zose7kcbGDBZy4YVw3XVQWsr0+iT/+68oN73gw1u9BoCUneKaZ69hvfEUP/5Jit//Hg48cODp998PX/863HsvtLZm5i2IiIiIiHwYCkajyLR9j3GDUaCWjRvbM1vMAQfA738PF1yAEQxRuHoL/OAH8Mc/8uLGF1nWuIxb37yVSx6+hOWxJ0jaCcDtPXrlFWhshL/9DS66CH7+c3jrLS31LSIiIiKjl4LRKJI3biqVRgiA+x55J/NBwu+HL30J7rgD5s1zV7KbMYMjxx/J1/b7GvmBfBq7G5m/eD4XPXQRC5ctpD3Wxi23wHe/667rYNvw+utuB9TFF7u9SSIiIiIio42C0WhiGBxVUYDHsFnTXM369ZkuqFd+PnzrW3D77XDEEQS8AU6ZeQp/9JzG11eHKY176Yx1cveKu7n43xcTsZo5+mj4xS9g/nx3VfDsbGhuZsjcKcchs3OpRERERER6eTNdgAw1s2Ia4ZoX6fFtYNWqoYsaZNyYMQP3LYvAP//NF1oifH6Jw6LpIR6a7cE3fhLFWcX9zZq8b3HOhTO58MJsliyBysqBS6xcCT/6EcyYAYceCocdBmPHpvH9iIiIiIj0UjAaZSaMnU2O90laAptYtQpOOinTFe2Ax+NOHnroITzPPMMRq2McsRpiRVug/m8wbx4duQFuePkGTMPkyHFHcuyUYxlXujdgALB6tXup6mr3WLAAxo1zA9Khh8LUqe7oPRERERGRkaZgNMpMnLQfOZ4eaoNbWbkqCfgyXdKOVVS4mxiddx48/jg88gjBljZ3ObqWFpouOIkxOWPY0rmF5zY+x3Mbn6MoVMSnxn+KT0/4NKeeOpXPfMZg0SJYtAiWLYMtW9zj3nvh1lth4kT3pRxHIUlERERERo7hOBmf4r9LVVZWUltby9ixY6mpqcl0OR+aE4vx5e/P4KXoeKZFbuLJBUeQnZ3pqnZSKgVvvAFPPAHnngszZ+I4DqvffoonX/gTrxVE6Qp6+jqMuOKQKzhm8jH9T+/qgiVL3JC0fj384Q8DYejXv4bNm2H//WG//WDmTPAq1ouIiIjIB/gw2WC3/WrZ0NDA7Nmzhz1XVVVFVVVVmivaOUYwyOeNCbxhJqjPvZ8NG45g770zXdVO8nrhiCPco5dhGMxYspEZL/RwmWHw9lh4cVYWb+V1cdDYg/rbPbv+Wda0ruGQ6Ydw1afm4DG8/aHIceDtt6G9HdaudXuTAgF31bu994Y5c2AHv2oRERER2c3Nnz+f+fPnD3uuoaFhp6+jHqNRqO66qzi67jk6PBX84cSHOeULn/DFA5cvh6efhtdeg1gMgKRh46sY504mOuccrn7pWpY3LQcg5A1xwJgDOHjswcwtn0thqJDWVli61A1I77wDnZ0Dl582DX71q4Gfq6thwgQIBtP4HkVERERk1FGP0Sdc+dgZ5G19ijYnzotv1XPKFyoyXdLHs/fe7lFVBW++CS++iG/JEqithRdfhAsv5PTZpzO2ZixvVD9Lu9XFK1te4ZUtrwAwo2gGvzzulxxzjMExx7g9SJs2wYoVbuaaNGngpWIx+OEP3f2Txo+H6dPdVe+mT3d/9ngy9BmIiIiIyKimYDQKmePGM2dJio22xeLVm2loqKCsLNNV7QJ+Pxx5pHt0d7vdP/E4GAYHVhzIgWX7UXXLq6y2I7wxLYu3y2zWh2KEx+RgDFp54deLfkVFuIK9DtyLY+dNJ+AN9J9raoLCQvd20yb3ePpp91wgAGecAWed5f7c11eqRR1ERERERMFoNKqsZLZl8pInSrd3A3feeSjf/36mi9rFsrLcgDRYYyNGKIsZjSFmvONwAQadppdo4XJY+mv4zGdomjGO5zc+3/8Ur+llSsEUZpfMZq+SvZhdOps//zlMayusWTOwFPiaNdDT475sn02b4Ac/cHucJk8eOMaPB98oXgxQRERERHY9BaPRaOZMpvvHMM67mvWJ53np5bP46lcNCgszXdgIGzMG/vhHqKtze5OWLiV32TJym+Pw3HNQVkZo7+lcduBlLN/yFitWvUhryKDaqqa6pZp/vv9PPjf1c1x20GUUFsJ+ByYonLqJc86bhImX2loIhwdebsMGNyytXOkefTwedz+l886DQw5xH0ul3MfVuyQiIiKye1IwGo28Xj7zqfP58xs/wpO9kq7Iel5+eQqnnJLpwtLAMGDsWPc4+WRIJmHVKnflhYMPJsefw+emfY7PNRfgPPEGjd4EK0tirKwMsiI/wV5lQTfthEKsaVnDj579EV7Ty6T8SUwvms605DSmG9MZmzuWT3/aZPJkd2nwDRvc2/XrIRKBjRvBHLTmxZtvws03u4Fp/PiB2/HjoaxsaFsRERER+eRRMBqlwvsezL7P51ITaCMSeo/Fi/eQYLQtnw/22cc9BvP7MfaeQ1l1NWVbkxy1FcCP8/QDcMs/4ZpraB+TIsefQ7SnkzXNq1nTuqb/6UFvkO8e+l0On3A4EybAYZ+KYTs2IW8WLS1uUJo5c+DlNm+GRALWrXOPbUv8r/+Cffd1f25ocOc4VVRAQYF6mUREREQ+CRSMRqspU5iZzOPFYD11PYtYvfpUbFs9E/0OOMA9ksmByUSrV2NUV7upZPx4jhgzhsPHHU793X9kzWN/Y01FgDWFsC7UQyzoo8AYmHD08qaX+e2bv6U0q5RJBZOYlD+JZPskxtnjGBMew5e+5OXTn4YtW9y5SVu2uGGppsYNTIOHOb78MixY4N4PBt2ANPg4+OChQ/pEREREJPMUjEYrv5+ZlfsSiv6bHv8yutsS1NT4GT8+04WNMj6fu7vr4B1eW1vdrhrcDWbH1EcZ057Hp9vd0zYBan0xyh79CZSPhZ/9jPpoPQCNka00djXwRu0b/ZfzGB5uOvYmZlbMpKICxs/eSiQRoTK3kqAni8ZGKC4eWtKYMVBf7y4f3jdEr89ttw0EoyefdINUWdnQo7RUvU0iIiIi6aRgNIpN/8H/kvWTR/BlN9DR+jLLlx+jYLQztl2l4oor3DW6N2yAdeswN2xg3Pr10NLijnsrKOD80vM5deapbPzd/7Dh3RfZWOpnY57DllCCWMBLWacFBRZ4PDy57kkeWPWA+1KhQsbljmNseCwV4QrKc8qZ9/m5nHJKkFTKvXxd3dBj8NLra9fCu+8O/zb8fvjtb93pVuDu21RX54awviMU2vUfn4iIiMieSMFoFAuGCzh+yvGsX/UGNcULeOX1T/G5z/kzXdYnj2G4XThjxsDhhw883tHhJo3etbnDgTBzGmBOSzG0uE0cHFq8SfKf+CH4/HD33XgMDwXBAtqaNtPa2UlrRz3v+t6F3t6dv5zyF4LeIF4vrIg9xfv2+4yZOoY5+43h+JwxWGY5kA3A5z8Ps2a5AWrw0dy8/RC9F16AJ54Y+taysgZC0hVX9HeUUV/vjjIsKIDsbPU8iYiIiPwnCkaj3BmHfZXHq19iS2Ajz298lrq6E6moyHRVu4m8PPcY7Oc/d5NJ7yQiY8sWivsmFOXlgd/P+XPP5/y559N19VXUrHmbLf4O6rIsthb6aAp7KLr3Ebeb59hjeXvr27y65dXtXjrbl01JVgk3HnsjEyfmALCxfSMJK0FpdinZnjxaW40hPULjx7vTqpqb3aOry90nd/Nm9wgGB9o+8MBAiPL53IDUdxQWwvnnQ477srS2DnwcHs+u+nBFREREPlkUjEa5/LmHcHZPKe95umiNP80vf3kiN9449Euw7EKmOdC7dPDBA487DnR2DmmaXTKWGS0RZjQ0QMSGht4Tbz4ARUVw3HEcN/k4JuZPpO7fC6mPNVMXStLhc+gK+IkHm8ju6IGiLDBN7ll+D69seQUAv8dPSVYJJVkllGaXUpJdwumfO52TT3Z7txJWglTcR2urQXOzOypwcIgyTTf4RKNuz1Fjo3v0+cpXBu7fdZc718kwIDfXDU6FhZCf74alM88c2Bi3pQUsy308ENg1H7mIiIjIaKBgNNr5/Rw48XAmttzLquRbrF7RyV//msull2a6sD2MYWzfu3Tlle5tKuWmjr5JRFu3uhOEgAMqDuCAigPg5ieh2W0eMyyavAnavEmMf1/srrTwpz+R5cuiMFRI2+ZqEo5Drb+RWp8f/H68/iBn7nVm/0vf/NrNLNm6hKJQEUWhIgpDhWxa6t4vyiriG5ccxmWXeUgkoL0d2trcnqG2NvfnwSEqkXDfnuO4ows7OtzpWH3OPnvg/sKF8PTT7v1g0A1SfQEqLw++9jV36B5Aba3bo5WX54a0UEhD+kRERGT0UjD6BJhQdQ1jr7uPeM5mOlnEY48dz2mnDZ3ELxnk9Q6sxb0jP/iBO/GnsZFgQwPjGhsZ19gIySa3dwn49iHfBiB18Vdobqul0ZegydtNo6+NmNfAePYbMG0a/OAHtPS0kLASbK2rZqtpukHM6wPTwGt6efDLDwLuw3etv4XVLavJD+ZTkFdAflk+968scH8OFvDd7+7PFVcYdHYOhKe+ABWJDO0Zsm13aF4y6a64F4sN7Ym65JKB+/ffD888M/Czx+MGpNxcd1W+n/xkYHW+ZcvcTBkODz1yc/szpoiIiMiIUjD6BDCKijhw1jE0r3mcVTP+m1SLh7ffPpoTT9Q/v39izJrlHtuybbdbZRDvoYdT3tBAeUuLO5motaP3TH3/6go/P+bntHS30PK9b9La2UCLN0KLN0lLtoEdDGIs+wlMngxf/Sq1nbVs6dzClrpV7hg7n88NUQb4TB8PfPkBTNPt+fnr+26IKggWkD8mn4LJBdy3MpfcgHt85zuH8Z3vGPT0QHu7QyRi0N7ujjLs6Bg6xDMUcofkRSJukLKsgR4pGBp4nn9+aIgazO+HO+4YWIjimWdg+XI3ZGVnDxx9P0+frjAlIiIiH56C0SfEYQecyhNrHic31cr6wl/yxJJKTjxxRqbLko+rbzLQYN/4xtCfk0m3C6elpf8hv8fPmJxyxhTOhGSB29VjWf3D9WCZ+zzgu4d9l+buZtqv/QFtXS20e5K0eVO053ggGMRYdb0boi64gJrOGjdE1awAwwSf1w1RHg9+r5/7v3Q/huHOOfrVkv9hZdPK/tCUW5rLb9/IJS+QR24gl69//VS+8Q03vDd2dNDdZWLFsumKmkSjQ8PL5MlwyCFuwIpGB24tyx3q1zc8D9xly599dscf6YIFAyHqz392h/5tG576ji99aWCEZE2N+zGGQu77y8py7wcCGgIoIiKyJ1Aw+oTY7+BTuOatN7nhvQep7enh5bVLeOKJGZxwQqYrkxHn87nzkEpLhz5uGHDjje59x3G7ZvomFLW19U8kqghXUJEzBoIzIdoMLb1dNn2LRfAW9PQA8N1DB4Wo7lbaPUk6PSk6vRZGIIjx0rdh6lS44go6Yh1EEhEiWzdSC26A8nrB68EfyOK0maf2l/qHd37D4rrFgLsiX44/h3ufzCHHn0PYH+b7J32fk082AXiv4T0iiQjZvhy8dg5OIoeUkYPfCWEYBp/6lLvoX1eXG566ugaOaHRgoQhwP5Jo1D2Gc9ppA/efeAIeemj7Nn1B8OabB/aUeuEFeOONgRA1OExlZcH++w+Eue5uN+CFQu7HIyIiIqOT/jf9CWEYBodeeA2Xf+tVvuntosX/NM+8cDonnKDl6YSBJeVycxl2F2DDgFtuce+nUm6XTF+Aamvr/xY/NncsY3PHQsF+YLe44956Q5NrU3/b//rMf9Eea6fzqm/RGW2hwxNzQ5QnhY0D95wGM2fCTTcRT8Xdp2/ZQpdt0+X10uBxQ1TAn4VZfIrbdTNmDP98/5/9IWow0zDJ8eew4NQF7L+/+1fXw9UPs6ljE8W+LLJ92WT5sni1Lotsv3v/wq/sxemne+jqgkjEobvbGBKk+uY4gfvRjRvnvt3ubvfWcdyjq2voXKt16+CVV3b86/jd7waC0UMPuSv/gdtLFgwOHKEQfOc77usCvPMOLFniPt53fnD76dMHOhgTCXckpnq0REREdg0Fo0+S7GwO/MxZzHjrJpZE1/H0e7+iq+kKskuy/vNzRfp4vQNrcu/ITTcN3E8k3K6Xjg43UA3aEDccCMOMI90xaH3j3zp6JxVhuakC+J9j/oeUnaLr4vOJdDYR9VhEzRQRT4qU0QWPfN8NdPPnMy53HNFElOgrz7m3Xpuk18D2eIh7g3j/thBKSuBzn2Np/VI3RHV3AwZ4Pe4qD6YHDPjnmf8kv3eo3P+9djOv179Oli+L7GA2WeEs1r7iBqgsXxaXfPESvvxl9x8a3m9+n6auZjxOCFIhSIaIeYN0xLII+UIcdpiP0lJ3rlVfkOo7enqGjo6Mx4d+lInE0JXfbXvg/vvvD99r1ecXvxiYqvb44/DHP7qhKBDYPkR9/evuWh0AK1fCa6+5jwcC2x+zZrlzzMB9D9Ho0PMKXiIisidQMPqEKfziuXznqQVcHEzRnr2YM0/q5G9PZPXNyRfZ9fx+d+W83tXztvP972//WF+Ysqz+h7yml7zTzyGvb7m7wePcQhE37AAX7XeR+4S/X9i/+2zCsImYKXpMC5L3w4QJ8LnPcezkY5leNJ3uP99OV0cT3aZFt2nRZVok/R68z1zijn/77/+mO9lNwkqQqNlMeyoFHtMNUB73qPIdDrn5MG0aj65+lBc2veAGu75U8M7A21v4xYXMnp0LwD3L72FZ7ZsEvUFCvhDFvizuXhvq//lL55zMeedl09MD65tqaYy0YaSyIBXESYbILQzhOAEMw2DmTDj9dDdcxePubSw2cDu4hysWc28dZ2CFwMF6p5gBbg/XBwWu665zNw8GN0D95jdDz/v9AyHpW98aaLt8OfzrXwPntg1eBx440BvW3g4bN7rX8vnc84NvNdRQREQyTf8b+qTJzeWIz19C8cv/x9ZsL+/O+hb/8/N/8N/X+4bMrRDJqL4wta2TT975a/z0p/2TiPzd3RQNHgPX271x+LjDOXzc4eB9G2K9GyelUoMu0ti/VN73Dv8e0USUrh9eSVfDFro9boDqNi16zATeJ/4biovhL39hbO5Y9irZi57nn6Kns5Uen0HMBzEvYHoIrfpfKCyBK66gNlLL6tbV0NIKqeRAj5XHAx6TE/2zyc4rI1xWxmvv/5vH1j429H1u6f3IPH5+//nfs+++7lyyR1c/yiubXyHoDVLkDRLwBnh4a4BgU5CgN8iJX/gcp56aRywG65pqqO1owEkG3CMVJFQUJBJ3nzd5so8zzjCIx90AFY8PPQZv0WXb7q8vkRh4rK+nKxIZ2sPV0ODOtdqRoqKBYLRy5cCUuOF8+9tw/PHu/WXL3DldPp9bS9/RF6JOPBEOOmighscfH9pu8DFp0sDcsHjcbT/4vM/nHqa549pERGTPoGD0CZR99oUcX7OQt2urWRm1WfTmI5x55mn4/fDjHw/8a67IJ9rUqTvf9he/cG8dx+0qiUbdkNTV1d/j0zdkjmNOd5dB7xsH1zcWLq+nfzn0s/Y+i7P2Pgse7IQtW/pfxsYhZtp47XehqBiA02edzpHjj6TntzfTU7ORHjNJjxknZlj0mDZZD18NoRy45x5yA7mMDY+l5+036OloIeYFx2OCaZIwTXyrfgWhQvjBD6jprGF503K31yye6O3h6u3lMk0+Ey8nv2A8gcmTWbHxee5dfe/QHq76gY/nlnm3cOGFUwB4fM3jPLrmUYLeIAFPgGyPn/u2+gk0BfB7/Jx+2Ok8cPwYHAdW1a9jWf1KPHYQLD9Oyk+80M/yRrfthKnjqKoKEY9DdyxFLG6TivtIJNwQNmbMQA2BAEycOBCyBh99+2P16enp7ywcVl8oAjfoPPDAjttedBF88Yvu/U2b4Kqrhm/n8cA558CXv+z+XFsLN9wwEJy2PQ4/HD7zGbdtJAIPPuj2ePWdHxy6xo0b+OOcSsHatQPn+54zuL16zkREMmO3/eu3oaGB2bNnD3uuqqqKqqqqNFe0C5km3z3rFr538zyS2XWsnfJLumpXM7brUv70pzwFI9lzGYb7DfOD5lANXoruP/nlLwcmDvX0YPb0kNX3s8cDwIT8CUzInwBzTob8LUMDV08P5Mb7Vwg8d59zOXefc+GlH8DqVTg4xA2buGkTM2zyUssh6LY9fsrxzC6ZTewv/4/42mpiZoq4YRMzbeKGTfiJX4DthYceIj+Yz5SCKcSWLCLeWEfMCzEPpDyAaRJcfBP4CuFnP6Olp4VNHZugqckNjqYHTKM3dJnMqw1C3mSMI49kZdtSFr6/wO1qSVlum9Vmf9v/OfbnnHDCXAAeW/MUdy35PYbPwOfxEfAEWLbCT+B9N0RdeuCl3HrrXgAsb1zOU+uewu/x4/f48RoB6jx+7l/pw2f62HvSwfzmN2NIJqGhs4WNHRt6g5kPx/JRMNHP1ogPv8dPOD/MKaf4SSbdMgffJhJDF3N0HHeRjUTCbdM7BQ5wR30O7jXq6XGXcN+RysqB+52d7obGO/KFLwwEo46O4Uef9jnuOLj8cvd+d7e7ev+2oawvTO2330CQs213fRWvd+jR1378eDjiiIHXefZZ949w3/nBbXNzh76/lha37eDrejyaeyYio8f8+fOZP3/+sOcaGhqGfXw4u20wKisrY+XKlZkuY8SMmbA3vzn8Z3x90Y+Znl3HyopHMNZZmBu+RzzuH7KCloh8RH0bHu2M887b+ev+6EcQjWLEYgRjMYLxOHl9E4V6v61PKpjEpIJJMLcZwusHxsD13fpi7rdh0+TkGSdz8oyT4Y3rYcOS/pexcIibNkF7K1APHg/HTzmevUv3Jv7XPxFf9haJ3mCWMGzihkXJi/eD5YNDDqEyt5Ijxx1J/LUXSazbQKI3lCUM97pZ//ouWHlwxx39Kw86W7eSaG0h0RueMEwwDZIrAxCaBOeeS01nDc9vfB46I73hzBjS9sfTLuaw0gNgxgzqG5Zz39r/c7tabNv9Nv6WCW+bYBhcediVfO1rRwHwZu2b/OLVX+DzuKHJZ/q4q8PPfY/78Hl8fGn2l1i48BAANrVv4r4VD+I1/Bi2D9Px0Rn0c+8KN5zNyJ/LjTdOJpmE9p4I69rfx7a8YHlxLB9lE7xsavfhNb04vnxOOSW7N4w5xJMWVtJDKmWQSAwMJwT311tW5ga3wUffdLzBPWfJ5MCGyMMZHPqSSXej5B05/PCBYOQ4A4tUDmf//eH66wd+vvTS7eewgRuQ9t4bfvazgcd+8AP3Vzo4aPUdlZXwta8NtP3b39zO3b6gNfi2oGBgaCXAokUD/x6xbftQCGYM2tavocH9PAe32/a+iOxePqjTo7Kyktra2p26jv56+AQrPutivjN3DDc/8zPmbqljlfM4eSsP4Pe/P55zzjG22/ZGREaJ/7Qq4GAfpofr+993uxl6x6h54nGy4vGBMWseD6XZpZRml8Knz4Zxhw6c65tw1PdzIMChlYdyaOWh8H4RrHh5oM2QeVwp8Pv5wowvcPyU40n8v9+TWPHUkMCVMGymxFeAXQ1f+hIzi2dy8b4XE3/2CRLL3iRh2CSNvrYOpc8vhPi/4LbbyPJlMbVgKon3V5BcWz2kXcqw8T1+HSRvhxtuIOFPELfixBtqobHRDVGDAlf03S4ILYbTTqPJaOLFzc+53+I7Ot1w1tsOw+Ablady8pjPwMyZLE/U8Ktn/9t934mEe933TFjhtr1w7/P42gVfBp+PtW3r+O6T3wXcBUe8ppd1XT7+8S8fXsPLF2Z8gT/+8RQAmrqa+PWiX+MzfXhML6bjpcPj45ZFXnymjzml+3HrrYeTTEJnTzfP1zyG4fgwbC84Xgrzfby0yX2NkmAFF1880S0xaVEf24Sd8oLlw7Y8TJ7opTPuxWN48Bp+DjjARyrFsMe20wN31DPUl1UHq6lxhxYOZ9v9xJ57zh3VOpzx44cGowULdtyDV1oKf/rTwM833eQOVxxOXh78/e8DP193HaxePXzgyspyO437/O1v7kIm2watvtvLLhv4rF5+2R2O2Xd+2+Poo/s7nVm71h06Olw703Q3wO5r29nphtS+1zTN7Z+jnjyRj07B6BPus7NO5DMzT+D6f11B29NPsnKvG6hZ+iTPPHszP/tvg/32y3SFIpI2fTvM7ozDD3ePnfG1rw39p37bHghTiQSEw3gMg2x/NtmnnAmHfGbgXN+Ytr7bnBwmZpUyMX8iNBVBYsZAGOvrPsntvR8KcVDpQRw09iBo+we8eO82oQwcHKALTJODKg7iT1/4E4l/PUDihftIGo4bpEz3dlJ8HaRq4OijGTtuLBftexGJN18juezZIe2ShsO4lx+FnlfguusITMxleuF0khvXkVq2iqRhkzIckoZDynAIPPVb6LgHrr6a1PTewNvaRmrTRlKGQWxQ4Op5vQGMRfDlL9M1qYD3Gt9zw1l9Q38bN8wZZIcP4dNFNXDggdRPzuLFFQsgkXS/HZsG1Bj94exzYz7NZTPPhbIy2rNMzv/nd9zfUzIJhsErrQZ33ute95jJR3PdtVeCYRBLxTj/n+e7gak3yL1reLj0ER8ew8OBFQdy770X4ThgWQ7/9fy1mHgx8YLjwe/x8ZtF7nMnF0zm2mtP7M/OT2653+0Jsz1ge8nO8vL0Ovc1irKKOPXUfYhG3babYyuwUoDtxbY8FOZ7qel0g1zQG2T27AKKi92eoEQqhW15sFIGlrX9vzH07QFmWduHt76A0cfd42z4P/bb/qe0erW719hwTBO++c2Bn196ye3l2pHPfnaglocecjeN3pG77hpYkfJvf3M3o96Rv/zFXUMG3DD5+OPDhyePB669FsrL3bZPPun2OPaFscGBzjThK19xezoB3n4b3nxzaDDra2+abujrq2HjRqiu3j7E9d2fMWNg8Ze2Nti6dej5wbdFRf1r6ZBIuD2IfR3T27ZVOJSPSsFoN2AYBpefcC3Wxs3cv2oDrcnFLB5zDKf/YQ5/vfB/+fTh2gRWRHYh0xzYMGlb48YNHTv2QT79affYGWef7R59C2z0Bi2j735JCQGvn1JvKRx9Kkw7YGggSyQGenxKSxkTLuaLs74IsUnQVumeSyYHbkt7b3NzmVY0jZvn3ex+c3z1L0PbDg5qXi/Ti6Zz9+l3k3zhWVLPzHdDFE5/mCq0kpBaDieeSEnWdH5w+A9IvfcOyecXkuoNZX3PmRV7H3rqID+fwJiDOHbSsSS3bCD1ypO9wczuv6149Ulofxe+/nXs446kMFRIqq2F5DvLsQyHFA624Q7T9D63CW58AS68kOTJ84ilYtDd436D7Qtnvcck6z34xyqMY4+FY4/mvealbjjbvGlQO/eb6CGByZxYUO+OrzvoIH62ZiGpZByamnsDn8Fz693bfXOn87MZl7nftidO5Kz7f0ZXIgpd3WAAlsGz97vXn1Ewjf8752fun7fsbL7yr6/R0t2CAXg9PhpMD2fd78FjepiYN5Ebb/yf/l/J9S9cT1N3Mx7Di+F4MDD58bNu4CrJLuGHP7ycnh7313j/mr/R2tMCjgfD8eAxvfzxbROv6SXHn8Ppp5/BZz7jtn23/SU6E+1ge3FsExMvz29wawh4Auy//yHk57ttG5MbiFndOJYHx/bgWB5qIh78Xi+mYVJePoYZM9y2cSuGZYFjm9iWB9sy8fkGvuWbpjuN0rKG7IYw5HyfeNwNfjsyeI5dfT2sWLHjtn1z2QDWrIFHH91x2zlzBoLRu++6+63tyM9+Bvvu695/4w3YwRQRAK65Bg491L3/6qvwq1/tuO1VV7nhE2DxYneVyx0FrvPPhyOPdNtWV8Mddww9P/j+CSfAwQe7bWtr4Z57hr+mx+NuVzDXnYJJWxs8/fSOrztlysC+cz098NZbO75ucfHAwjapFGzevP11+45QaGBfPcdxBxRs267vP2NxKRjtJgpDhfys6h4q//sLPBBZzrLOiXT53uM7t9/D/9V9gaPn+TDCOf/5QiIio1nfAht+/47nf40ZM3RJvA+y337sdNf6UUe5x2COMxCU/H5MwyTbnw1HHAPT9xkatgbfTp9Otj+bT034FHgnQ2Ls9u367o8bR0GogO8c+h0oqIZl4YFQ1tctEk5BKAXhMIWhQhacusDdaOqRa/u/RTu4PVz9TLfWO06+A2vtGpKPXdcfolK9vWF5lhcSq2DffTEw+O6h38Wq30rqqd/2trH7n1ORbITog+5ncpAb5FKdbVgv/INUb9hLGQ6W4TA53g333eCuvf7Nb1IRrqC7q53Ua8/0v3bKcLBwCMY2wp+2uJ/9lVeSslPg2DhLlpAEkoYBuN/uulI58JdN7rfXyy+nprOG+q56eG+5G7gGhb6x5FJMs9ttce65bFr1Bpu6N8GGDf0rPL6z0m1b7Anzl5IoVFTACcfzzFP/prql2h2yabtt3/232zbHG+Ife18HR+bB3Llc8+wfWd24zB1LaDtgGlz+gNvW6/Hyz+P+xLnH+aG0lBte+j/eqH1jIHAbBmc96IY0j+nlrm/cxWWXuRPRbl/y/3iz9k0MPHgMDzgm173hwWt6MA2TH5xxAyedFMSy4PEND7Gi5Z3ecOi2/esak8BGt+28I77O1KnZWBa82/oam7pWgePBsU1wPLzQ7GFxt4lpmEycfgJnnZWDZUFNrJqmxCawPf1hbnXMpG2LicfwkF8yh0MOycKyoNNqJGI149gesE0c20ObY7Klw63BFyyhosLvdkhbcVJOAtty21kpE8Nj4jgeDMMYEuqGM7hnMJH44IDY0zNwPxp1w9GODP6roq3tg+f15eUNBKOWFre3b0fOPHMgGDU3w//+747bnnLKQAd+Wxt85zs7bnvCCdA37SYadVfeHI5huD19V1zh/pxMwoUXbh+0DMP9bA84AC65ZOD5V1450Nk9+Lj4Yjf0fZIoGO1O/H7OvOYfPHrH55iyup6aniLq+Sv/c3UO/+/nQfIPOpG5c80h46BFRORjMIyB5eIG+zALd4wdO7Cm+H8yY8bQ1Q4+yN57D6xl7jgYloVv8GSiYNDtscgph5n58Ms7tp9w1Be8KivxmB6OnnQ0FEfg7Lzt2/Td33tvAKoOrnJ39l0aGHq+b7WJ4lT/WK5fzfuVu9LEo1cOtBt8eKz+VRP+38n/j1RXhNR9F2Ab7iIjKcPGBjwYkOzo/7Z71eFXEUv2kPrX5Vi9QcvqDV1B2wNdS/uve9rM02iLtWE/9QssO9Xfy5YyHLLsHmh9APbZB44/nv3K96Msu4zUq3/HSsT7r2sZDkHbhMd/6X7T/dWvKMkuYWx4LNZbz2HFYwNtcdx6H7zMnVQ1fz6W3dsNtHIVxNz3YPUeAJ6/nQZjKuD//T/aY200djfA+++7PX6GMRD+MMh9sJ1gfjHcdBPdtRtYH1vijm3r6QEM1vaHRLjIbGZWKB++9z1WLH6X6rWPud1IPTEwYPVWo/+6dxTXckigCC44j78sfY3X33/Q/YYej4Np8McXB+q4dcq3+cwRFfDpT3P3qudY+N5Ct1cw6c7V+9WbBrzpXvv/9vsBt39vKkyezD9XP8af3/lz758Vd9GVG1YCKw0M0+CGI/6Lf/9jH+xgFk+te5YFy/6C4ZiYhtsr+NcWDwsfcQPXxXO+yR/+sDe2DUsblvDwhnswHBMwMRyTJ5Mmr77gwcDg+HFn8JOf7IVtw4bOal5u+jeG4wZJMFnqM9my2A2I++YdxcUXz8CyoDley3vR53Acs7/9phyTB1e5bcd65zJv3iQsCyJWK5uTb4FtYtsmOCZtYZNXN7tts5IT2HvvCiwL4nY3Lc5acMzekGjSk2WyttVt6yQKKSzMd/8TtFPEjBY3oNpu26RpEom7beNJP+D+PeUOQQYDo++vh+1W6dzREFNwf919HMftRRzOBwXS0UrBaDeTHyrg5nPv5LXn/sqy1//Ns91RVh35a1ZgUNq9hrrHr6Cnx91MsafHXbH3w2wXIyIin0CG8cFLsgWD7iz/nREOw0kn7Vzb/PwPXp98sLy8oaso7ECWLwvyQvD3B4aGp74JRalU/xL5M4tnut/crpm/fZu+5/VOUjpm8jHuC5zqGwhv2x69PZHn7nOu23ZpyB2ftG0dJXb/mudXHHqF2/a1H0O0dfu2OXZ/iP7Jp3+C5VhYL1xGqr7ODWaDQlffF1mAC+ZewKkzT8V682dYtVuwoT9w2YaDv6seut2dmvtWo7SX3Y61eTOW4WAPDnPtb0PQHVWy35j9CPlC2KsewNqyCas3fFqGjY1D1muPAwE47zzG543n4IqDsde+gFXTOOSaNhB6fgGkAnDkkWT7st2AuP4drPq6/jrdW/A9+UtIZMNdd2E5vVGwphaaGof8/h3A/PePMGK5eP7yFywjRleq0x1TVl+P23vIwL8A37OasYli+NWveL+gjfo178PWemjsXcK5v8cRjulZxmF2JXzve6TsRmpaX4LmFvfLkgFb1g+0nWa+wWne6XDeeSw263n0pXvdhVxaW8CAzW8bvLDUvf5lOUfxray5MG8ey7wtXPPcb93U0N4BBjy11uCpdW7brxQdw41HHAkHHshqXydXPXWNGzojEcDgqVZ46h9uHWdXHM+Cb50Ikyez2dtF1WNV7p+pnh4MDJ414Nk73eB56vh5PHjLWdj5hdQ73Vz2+FfBdjAtBwOTlzweFv3DDZfHTTyG3/3qK9iml06rh/9+8wpM3NBpYPK+3+Tyx93AdfDYQ7j22rOxbYinEtyx5jrAwHBM7LyLgJ38e2WUUDDaDU0rmsa0L/0Prcd/m+zbzmNJ0wqiqRA1qXuoazK581WLNe+fRbRnDB0d7go+s2erF0lERD4hDGNg8sTOtN1nn52/9imn7Hzbb31r59v+/Of/sYnH9ODBA3/4oxvgbHsgRPX93GtMeAxjwmPgh//nfnHetp1l9Y8pm10ym9kls+Hccrdnbri2vROU+lej7JzsrobQ127wc3odM/kYN1C27wNZa7dvWzZQR/+2Au1/h+a3hra1bSiw+tueMfsMTp91Otbtv8d+51msVBLLsbBtC8twyLF7v76aJp+d+Fnmls3FWvg3rMXP9IYz+nvmJsV9YLtdF/uW78s1n7oG+7FHsRc/1x/kbMA2HKZ1RyC1HpJJJhdP5qv7fRX7lZexN77gtukNcTYOk6KbINEMp55K6ZhSTp5+MtY7b2OvexXbcLCx+9tWdC6FnvWw336EJ+ZzUMVB2GtWY6+pGXJN23Aobn8JoiuguBj/zHLG547Hrq3Brq522/TWagNZix6G9sVw5ZU4+00m4Algt0ewq9/HNgZ6hgC8r7Tga3kZqqrwHzEXjxfoiED1+wCkeg+A5JPVjGt+FL72NdqO/zSxtxohEoVVK8EwiAItvV8aJ3W9yDntD8GZZ9J90jx+sek991/eq6sxZxwAEz5ZwchwnP80UvOTpW+t8rFjx1LzQbvz7SFsx+a5u2/kwVfuYK03xXudE7AxCXYVU9xzIiXml/DZBWRnu2NcP/OZnV9FWERERCStHGcg0Hm9A/+q27fH2+DAN/goLx/oMW1udif+9J0bfE3LglmzBpYl3LLFHYK47fX6Xueww9yNt8AdU/buu9u36TvmzXPnqYG72sULL+y43tNPH5h49O677rDY4drZtruP3v77u23feQf+8AewbRwrhW1b2LaNYdt4beBrX8P+7GeIxCNY7y7F/uUv3DbOQJDLtj0UWH74xjdIff5E1rWuw15Tjf2rX/WHsr4gV5TyMzGRBRdcQOr001hUswi7ZgvWbb9l3yt/ScGBR474H4n/5MNkAwWjPYFtE33nTa5660bq2jfTVJuguStIyvaSihUybd13MQvGksqxmBLei+uu8/QvKqVeJBEREZHdXF8c6AtqjjOwFju4Q/Si0aGBbHCgzM0dWFc+HneHNo4du/NbSIwgBSMFo2HZjo2BwUsrH+OZ332Pd/yt1MWKqIkN7OaX2zadSdEfE0gUYeaGOfMcD2edNXQJUBERERGRTwIFIwWj/yyV4s2vnciDwQ286UuyrrucmO0HwLA9FNcchBMw8edPp8I4mim+AHP2y+eUs7N47bWBHuHVq93lKBWcRERERGS0UTBSMNo5778Pa9ey8qCJrH3nJUoTQeY//1s2JzuojRXiMyw6UtlYhhdsm9LaIyjsOZacuhLMQA5MnAAeDxd8oYPTzg7iyQ5q6J2IiIiIjBq7TTDaunUr1157LY899hgtLS2MHz+ec889lx/96Ef4/f5hn6Ng9PFY3V088vwfqDW7KHh9KSvqV/KCP0WXFaA5kUeidyWYcOtkAj1FRAs3YaQM8tpnQ1ERY70TuHj//WiaEOGQvSrYb0YBhqm0JCIiIiLpt1sEo82bN3PIIYdQX18PQH5+Pu3t7QB8+tOf5plnnsG37YZ6KBjtcvX1bF30DDe0/Yv1jRuIR5NkeZO0NyVoT2bTlMjb7imhaBk9Oe7+AONWncyB0QMo228ikW4vBaEu/OEQhftNYMLUBD4jSGUljBvnLtCyfr27qurUqUN3rhYRERER+bB2i2B03HHH8cwzz3D88cfzxz/+kXHjxrFkyRJOPfVUamtrueGGG7jmmmu2e56C0cjqTnbz/Ibn6X7vLdpWLeXlnBhbuorxr/eSiG+hLdxARzKLuOXDHrQRXbCrhJSvm5S/C39PHolQByYBKmq/QFa0gsaxr5JXM5lS7zl0FzSQlZrCzNkBDjwQcv0xVqxwOOGUIDNmGvg9llKTiIiIiPxHn/hgtHTpUvbff3/Ky8tZuXIlBX3rwwOvv/46hx9+OCUlJdTV1eHdZhdvBaPMady6llvevZ1QNEbty4/zdtJDxAljOik6Eu4u5LneHmK2jy4riIlDlidOtxXoD1HeZIiUrwdfIgfD8YFt44/lk90xjlhOI6FoOcXtY3GyHfIm+IjY0B7rIV76DMWpcRxQO5XQpCgTJx1CwdhPU1aYZPLsIHGzhTdf38oxkwwSY/Zh1WutHH58mGB+kEgE+jofg8HeN9P3n4UmTYmIiIh8Yn2YbOD9wLMZ8vDDDwNw6qmnDglFAIcddhgzZsygurqaN954gyOOOCITJcowSsdM5edjfun+8IUESRNe2fIqkUSEnIY2yoJFrMjq4pVljxBNdpHV1kXQyqY22c7mmhYMHDyGTdz2EQu04TNSdKaySOQ00lCwCYCO4tXUb/vCQSABjbSzcsx7EANWPU3WGxU4ho3H8tOVtwXHcDBxyGucTTBaRuAPCXweh7asAJ6Ej4Anh+IxG0htDWG2FJPrn8yMT0Ftx3o8RX4mZk+j9L0QbxsrOP7g8ZRm70Wer5sUXqoTcfY7ci9Sns10NfjZ19tGbXAK+ZU5GEZvB1dHBzmFfiy/GxK9o/K/PhEREZE906j8avb6668DMG/evGHPz5s3j+rqal5//XUFo9HK78cHHDXpKPfnGe7NXsCX9z5z+/aJBFuitXTUbSAVzubVLa9Rlgqwl1VITU8DTxgbeXfzCpobbSqy8hhT00qrkaLR6aA+nsWMVB5ZbWHeCXVg5HbSFfPhK1xL3PbSZftwMDBsD7Zp0Va6CkpXDVv25hRQ0nsAL9X2noi6Nz4rh6Q/yj+XQChaiu1JYtheYtlNGC8ZODgYtkmwqwTLF8Pj5JDMimImTbw9QUxvgpTXIdhTRDhgkDKD0NNFia+IKZFsWpNZdJdG8YY3kdVTxpr2MIncBmZ5iwnVHUBw+jvkRB0KnTnsZUdZ52ujLncsYwu7Kc7qpHprBfVrEuw9pouGrGJSToqUlcAX6sQMtpAdK8bOm8xMTwEVY1K0tlRjd2SRqF1HTWkR+TMOY0xpiIrOduqdJMsa/FRWxMhqXU2ZNZbwoZ+lvTFB0YQQweJaXnmwmbIpDhOyyvHmFzOhpJvu2jZaHAfyYzSt9bHvoRPwbVlPzPaTKCqnLeonJ9VOd2eK8OQSskIO/g3Vbi/djBl02zZJJ0bYn9e/sTnxOESj2PmFGKbR35GXSsTw+gI4joMxeM34ke7xU4+iiIh8BI7jYPT9v8Nx/uP/RxzHoaazhnVt67Bsi7KcMvYq2WvgGrJLjcpgtHbtWgCmTp067PkpU6YAsG7durTVJCPM72dc4STGFU4CYN8Jh/SfmgUcB1i2hcccOrfIsi3qInVU5la6g/EMg7aeNh5dei8FXRZdHY20vltN+fQTOfzgI/n2YwsI+eCwAyrZ8notS5d1kWjt5OiJ9Wwyy9naYWCHPfgCm2no3kAiUYGV1UOkp8fd4DlokYx5wICenEYATGyyPQm6rQBg4Jg2PeGG3go7wAG8kAgP1B3ztdLe94MPtrKOZaFBbywGGBuht8O03gHGPA+RvgbPgglYQFvv0acA/h3rvUafzkH3+0rbNhvWArV3sp233RvDMfC/8FsSgQgYNpiOmw9eA188jCcVIOWP4k2E3aDoxkQKfjeGsAPtpkMkuwkDE28iC8MxcUwLB5tcTwLTEyNqQo/pw8DBm8rH1x0iHEhS0lqMZZk0emxSBbWMDxXT2QON/mrKUn5afRZOyMbTVUxePJdAqpts/GSb2Xh9Fk4oSGuyC48TJLsrQZ7joydgs6EjTJ5VSkGom4LcTdT5G+mM5+LNcsBIkrBMvF3ZZMVt2gIG3hw/yUgRHmsLWVmb8BAi7BlHyFdBrNuhMFXBVidGT6iBglgQ02yjzUlBdiWVuR5ivkbybZPs7ghBE+rbZtLQESJc0E1FQYpsAnT44vR0byXXdAh7yola0+hqiRIObaIrECOvu42JuZWkinOoabXpqItRUhbB8niosSNkGQ6l4f1Yvy5Emb+VcEkz3U4bzXHY4tiMs8uotLLoyYlAUQ90QJffIEmSCoqwyMObC8loPcXtPsoLAjh5QTZGsnFSFkX+KFs6umnt8TGhpAtvyENRNAur1aA6L5ukaWP415Jv5pBK5BAqMDA6vKSyc0iZYcymGJ5CizklBWzu3IyDQ1fIoLDbi9cG2+fFSSaxOttoiiewfDCuKIduu5DCoAfDaqCsaDyvNfbgLc4mP9FDoTdJ0F9CdiqfuMfk3bYtjM/y4HeCdBtepoc7WF9Ti5EFxXmz8XcnaYhvwvSahIvm4Iv3UGFGcbxFLK1tpjaYoLIwQHvTZjZFs8m1SpkdLmFKcRutLV4aOrvJK8ylw+f+Bxn15FLqzcdjJenObyEa7WR2fikNDT5q7Trycwo5sCiP9+pX02NPxBNoodDMIZxTRHdXB+vqwpSXlRD2LcFsjuHtysaMJ2guiWEW5NHd041DK6FQHp2OzeyGbOJWKzV5JeSFfVh2nOb2BLmhMIWFlQR82bQ0rsPICtEQXUNJfgHZTiHenAIitsk0r0kgp5it9VvZ4mnBMS1Kt9ZR4vOTN35vthCkubYbT0k3EX8XWW1hxpVlY5vZRFrXstLTyAF5UynIG8fWxS0UhG1KJoRpMw3sms1klxaTivfQkYiS8OUQ93RTHi7HjCVYE40woaKclk3dbIyupigvQL4/m2InSG5OIQ12D47HIRyJk2xqoNhbSHMyi6SnEd+mzXhDPqxxleQ7QTpDXrL9WdQH4kQ7m0nFbCJtPYQ94/CVREgUZjO5dDo9Xe0k7CTdtZsxjSBmlpdYpJvyonJyy8bRU19DyrHIDeRSE2ukMLuYQHcCI5yHaVt4HZOGWDNrInWM8eaTlYizMtTN5OwKjK3ttPq6SAX9tDY3MLl4PP7uIHnBLDylxSRr19LU2Ug0FsAMJcjKzWFsdjmJrk4SrS3kj53NivXdhNveIC8UxMopoD3Hoq0wm3IjmzHxAOQU4gQcWtasxbKjGJMnkt8WA3+AJrsT20oxNh6gun453YaH3ORUxu9XjhEO09xRRziaZGwHvJ+bwAkVEGo1iMRWYxZPxEshU3wptm5cRqqlFa/hJVqRT0F2KeQX0JzoIBYCb0+ckCdIPBalYm0jG+INxMNlZOWWYMe7CCcixANeeqIWFQE/wdxC1hvtmMEQvu4YY1fWYPu9dIwpJNpYh5NfyPRZh9Le0cDqWC1xD4SaI+TGbIIeH6GiMrLzKqhbv5L6tmrC5eMpyCunrWkLMb9BMhHD295J0aTZhArL6GlroqN2HalYN3g8FDR3UZhfTpMVoS3eTn7CQzIrQEdZHu2168glQDiUR9xnsjnWwFhfERhQ70Qo8xaQ48uirbWOii6TaFkBS3vWU1TbxhRfKdExRXQaSWLRNrJaIngsm+aCAF09nfgTFk7AT6o7So4ZpDJ/PJucNrLbu+hMdZPwwuJwhNwemxwzyPQmm/xwKU/6NpHKyeJAzzji3RFa/CniyR4iXpvOgEPS5wGvD8I5EAqR7ctmSsEUPKaHpJVkr9K9mFE0gzllc1hSt4QpBVMYEx6z/f/Ph7ET2WyPMirnGOXn59PR0cGWLVuorKzc7vzf//53zj//fE477TQefPDBIec0x0g+tJ35WyGVYkv7JjZ1b2VqcDpvvOuQ47yBN8+DnR9kfMzk+bfewxveh89OCbLccijLStD53lKyuiMESsfxdHwVvkQhk6yxdBOnc3MT7Z1b8IZy2NQFy1LNNCR7mJaYwDh/iC4ilBW0Y9eFedm/mnqiFFklFGYF6PDW0J4ycKIhilMO3alC8DqkEkl6kjb+7DjeUCfdlonTVU6uaZDjs4h52uimBQeTpOnHGyvE9kfwGj780XxafU0YZgLH9JByPJi2RcBMEiOAjyQmNl7DdkOg5XODjeEOgQSwnIFeG08qiOXtTWeD/3UMMHBvnb4FOrY5L7K72e7P/C6+9se9roGDaThD/hv+ICYODgPvZ3ANHsPGa1ikHE//9TyGjYFDyvFsV6+JzcAnRP/fJwBGKkjKsHFMCwOHgJkk5XiwHQMbE6P3Sh7DIukM/bdej2HjOO51PYaNg4HlmHgMG8sxCZhJbMd9zGu6NfuMFCnHQ9z2YTkmIU+CmOXH7H0OQMBMErd9eAyblOPBa1j99fjNVP+2Fn3Dw23H7J9Ha+LgMSy8vcPGBx53PwN70OfpNSxsTGzHwGdaJGxv/+N97yVgJrEcE6f3k7Ad97bvvRuG295yTGzH7P+d9T3mYGBiD/ndm4bTfx2g//Vsx+g/t+2flcF/HkJmArP3s0nY3v4/D6bhkLC9/a/b93jfe7Ec9/PzGSksxyRuu5N/Q2YCG4Ok48V23OeZhtP/JyZpezF7H+s7D+DBJoWn/z0AOP+/vbuPkqq+Dz/+vk/zsDs7+8iyy4IPsAIiik1qBWMUE4QkTX6YeKo5VkPtUY7WkMba1KTHnqpQc+JJeo6nNdWqzUk4Fnva2tDWEyS0xngUwYfYRFAEDE/Lsgv7MLM7szN35t7P749hJyBLWODOMrPzeZ0zh2G+d777+X7mzr33c59GDDxM8r5ZnCdGpx8ds33088kfnVegsG5zfQfb9I727QEGrthHP2ODkJlHBHJHXzMR8mLi85t5zTE98r5V7Ns2fFwpfK6OkS9+D0bz7YlJjeUiXoiGoTbyuShDbYfI2hCyfHzDJOMa2IaPaUAkcvRbJJDPG9imjWWY4DkYqanYpiCSw8/XEDZCmGaOdLqORrOOeDjN4EgNgkFT2CBamyaR93HcOOFQBDFy9A+ZGIYQsvM4oRHCfg3DLtQ6NtlsGB8hGirkbyjZQPv0Ib5+02e5fOHcky5LJkLFX2OUTqcBTri+aNTo66PTjUVESCaTJ20/lXA4TDgcPuP3qwoynl0lts2MllnMoHC0cvn1AP/vuElmLbiu+PyC0SeXXFt87WNnEWImn2Fn307mTZmHZVqICIlsgvpw/YmH048Wer74eL6HYx1/W/uurvfY1PM6n+68nunx6YzuGzEMAz8zwsjhbhLxCCMDLdj1Pbzft525LRdT6xnsHymlCgAAH1ZJREFU2f0WHTVtDB1JkR6cxqyrz2NwwKXLeg95/3281vmYLTDDmoHXZZCp7eZn27dhNUwD22PW4SjTWoX8Ra2AS2QwQf+QsKXbx5Q4dakkc6MDDKcbeHHbLoYNodY5SKjexWubyXBvjhnSxqFDu0n5Pnk7xqC5B+xBZtdMY3Z8FsO2xxAw5GbIjOTIjXgkkweJNAj11DGcq+WI0U+NNFNXZ5PM7MHwTIZSU2nyZtBScwCj32K4xqKr9h1mmBeQ6s5SY+fIOBa96TCN0XYG8+fhxH8NI7uI+B7UwWE3yXlhBz/ZyodZobXFw3eHIHEE041hZZs4HBnCHwmTtnzMhhShaI6GbJyhrIEbGiCSrcUemUYyPwLxPqzQfuy0j5GqIxSdzpHaHBk3ge1FiJkGdswnl2nC8vNM8WIMGZAwtpMxLHyzljq/Dl9C2G43s40Y++M+Q0YO2w2RSUQI2RY2HqFMlFS4F8NIk8rXErLqGalNMJwaQjwhVj+CWB4jmXri+am0hA16k1HEzzJSvw/fMIgkWoj7WdzcDFz7CBHLxM+75OuGydtJIp6HKWHyqQi98SNEjCjx4WmYOZNUvB/bq8H0TAyfwvfSDDPsu5h5mxpnmCM1+8gZFmYugpOJYbk2ptSA44OdJFfTj0ee2lwU320i7wzjuxEwDMLShJ/L44UHyDtZ7FwTZj6MZx9GTMg7efLGMDXZFuoyMVKkyMRSRHwLsVNkBSCK6WSIeA4uecy8Db5DrWcz6GTwDZ+aoRZsIgzFujHDKeoGZpKO9jDipKkZ7sAPH0FM8E0fnwyOW0/ezJO30mCa2PlaxElhWGAOxbAkimGC4dVieCa+kWWk/iDgEMmGyTgpnEycUKYRz0mTjfSB4RLJN+KGBhEvTCQ1FTcygJgZsEbIGzb4ggVEhtsx8iFytRnc6AD4eaychWMC6UZMzyIT78HMh/HNHI7bQDZyBB8DQwws++gGpQimZ2Hg4JtZXM/B8qKYZpZwuplsbR++KURTTbjhBOJkEMPEycQxPId8eBjfyoIIvhcGwwbLwA/nMITC3zeyZPwQmCYYYIqNb+SxMlE828XEJOxOwQ33Y7tRfCNL3klh5WowfQvf9jDtHFamBscPkwsN4llZDLHJ+eAaHqFMHTknhRzdAE57YTBA/DA1Q21ka/pwLQ8xXHwvjJOPYOdqyET7wPQw0q3YTqawU8gXxIsQysQRS/CcLIZvkndS+F4Iw/DBzGDmbRy3jlw4hUEex41huzE8Z4R8TQLBJ+c72FKLlYuClycXGsIAjFQblgnZ2j4wLOxslFw4iZ8vnD7uZBrJRZN4Th4zb+G4EdzoML4fxXZt8qFhfNNGsLEljhg5rFwI10lg+DmsfBQrF8HyI3h2FkNMMrF+fN/CyRfuVmR5UfLhNIYrONkG3NoEvpkjOjQFR0x8K08m1odJGDtbQ8SP4RlpRiIHwYsRTjcRS7XihbJ40Ry+kcM3BiCUxPJqIDeVUCaEhHqx/DpMr1CQ5WpSSD6HjWAQAsMn5MUIu00MN+7DwyOSasNxa3DDSexcGDsTw86EyNQnMAwbCmULInly4SGi6WnknAQ5O0lNfipuJAG5LM39l5CL58lEDmJk8hhGiKg7Az/k4VlZPEngRpM4XpzG5AzsVIRMtItsbIBwvg2DMI40k7P6sEdqqMnNBC/PYOOvsEKHqR+8nEiynmTTThy/hVCmDkwT33Bx0lHqD8/ByHqQTOJZWdLxLtLxLqx8hEztYUbqDpGq389g5KPbvfljnicKZ5kUtxUo/D8MRwD8wnOADwFSx0ybPfrvsZsT7tF/R89eGa0oRvdr1MI7A3Dl5vazLoyy2SzZbPbUE57E6RwDKssjRqFQiFwux9DQELFY7IT2DRs28NnPfpYlS5bw05/+9Li20arwbP31X/81Dz744Fn3o5RSlUz8o4VzwD/U7IuPaZz66IR/dCVrmpD381iGTSpVuPZseBiamwvtvznoKMftLBgZgWQSWlsLl6rZdmHa0QPFo4+BAXDCOepqj675PQ8xreMOZo6MQDQqJz23/9i16fCwEI7mCdkOeT/PoSNZ6sK11B/96becl8Pz80ScKCJCV9/RjapGA9uWQox5H8O2jvZXuHtmKASp3BCSD1NXE6K/v/BHm5oKMWVzeWwbbNNmJDdCeijMkcMmF10EHD2ucGCwjzoD4rF6fAp3/0xlLPqTGWIxaI6HMS2DfB5yw1nCdQ5DQwZh28MzbGR4mK70CHVWA81tJqm0z8gINNQV9ugn+/MMDEK8wWJKs082Z5IaEdIjPm2tNpneBNFmwQo3kMlAJlP4bBLDOerjPhYhMAw83+NA+kNmtEUIZaaTy7v0D1jEag0MO0drU4TDRzzyrsmI69HW7hNxQvg+5HKQOTSAZfiE25pID7ocSYaYPsMgmYSGBuju8rDygzS2N5EcFg71pckNhKgZ6aJlQRuGYbJnX56mZqE2EiFWYxMKQdcBIZYbwIzX0twWIjlkIG6SWH0t3T0WbW0QCgnZEZ+RrIUjLq0dDpmsQToNR45AOg3t7YLhjNCQSXEo10I4AgN9eQb7oKPdp28oRFOLYBguiQGTGec5iBgkD2exog5+zuNQr4Vpm7RM8QmFwPcMamNC/74ktfEwnhPlSJ/PUG6A6a1x6mocojGXnoMOfs6nrSPPvu48tmXTFA8zNFT4rsViYBt5BJPUYA67NoxtFz4rJ+STThnE48boV4XeXqitEeL1Bh98ULjhUF1h257Rfdj9/YXfKIzFYNeuwg6/1qYwpmlQX1+Yt3fvLvTV1gZDwz5NjSb5fGHeb2go3Dl2zx6oqSm85rqFZYDnFWIzzcJrhgF9fUJzs4FtF77fllVoS6cLcXheYbp0ujD/xeOF5UNXV+H1eByGhgrPQyGIRile9zr6HssqxBGPw759hWlaWwvLnIEBmDq18HcGBgoxJxKFccTjhT6Gh3/Tp+8X4h992HZhmdLbW5h+eBiiyR5CO7dRO3SI/kwNIT9TyJXE6E8a7O4ZpNkMkZUcdc15sq5H1s3jmVn8WC+St/BDtVhGPynfIO2beMYgg55POhemKTKCafp0pyMYuTC1Rp4RJ0HGzWISpjFkMJQLE7UFxGHAd4nZHiPiEbJy2GIwknfIiYkfStLX28DqVTcz7+O/2XF8Jh588EEeeuihs+oDqNzbdY+eSrdv3z5mzJhxQvvzzz/PjTfeyPLly/nxj398XNtoYTRt2jTee2/sC+zHQ48YKaWUUkopdW6d7RGjiy++mIMHD1buqXQtLS0kEgkGBwfHLIx6e3uL052MYRjE4/GSxaiUUkoppZQqrbM9WHE6d/Ab31WWE+yiwjF/PvjggzHbt23bdtx0SimllFJKKXU2yrIwWrRoEQAbN24cs/3FF18EYOHChRMWk1JKKaWUUmryKsvC6Atf+AIA69evp7+//7i21157jZ07d9LS0sJVV111LsJTSimllFJKTTJlWRj9zu/8Dtdffz09PT3ccsstHDhwABHhrbfe4qabbgLgz/7sz3Ac5xQ9KaWUUkoppdSpleXNFwCefvpprrzySl588UVmzJhBQ0MDg4ODAFx33XV84xvfOLcBKqWUUkoppSaNsjxiBHDeeefx9ttvc8cdd9De3s7IyAizZ8/m4YcfZsOGDdh22dZ0SimllFJKqQpT1tVFe3s7Tz311LkOQymllFJKKTXJle0RI6WUUkoppZSaKFoYKaWUUkoppaqeFkZKKaWUUkqpqqeFkVJKKaWUUqrqaWGklFJKKaWUqnpaGCmllFJKKaWqnhZGSimllFJKqaqnhZFSSimllFKq6mlhVELZbJYHH3yQbDZ7rkOZtDTHpaX5LS3Nb2lpfktL81tamt/S0vyWXiXm2BAROddBBGn69Ol0dXXR0dHBgQMHzmksyWSS+vp6EokE8Xj8nMYyWWmOS0vzW1qa39LS/JaW5re0NL+lpfktvXLJ8enUBnrESCmllFJKKVX1tDBSSimllFJKVT0tjJRSSimllFJVzz7XAZRKT08P8+bNG7Ptnnvu4Z577pngiJRSSimllFJBe/zxx3n88cfHbOvp6Rl3P5O2MJo6dSrbt28/12EopZRSSimlSui3HfQYvfnCeOipdEoppZRSSqmqp4WRUkoppZRSquppYfRbnOxcxXMhqFiC6KecYglKOY2pnGIJSrmNqZw+pyCUU16C6qec8gvlNaZy6ycImt/SKqcxlVMsQSmnMZVTLEGZ0Fhkkuno6BBAOjo6zrqviy+++Kzen0gkBJBEInHOYwmyn3KKJagcl9OYyimWyZjfoPrR/Ja2n3LKb1DxlFN+g+hH81vafsotv0H1Uy6xaH5L30+5rONOpzbQI0ZKKaWUUkqpqqeFkVJKKaWUUqrqaWGklFJKKaWUqnpaGCmllFJKKaWqnhZGSimllFJKqapniIic6yCCFAqFyOVymKZJe3v7WfXV09PD1KlTz/j9IsLBgweZNm0ahmGc01iC7KecYgkqx+U0pnKKZTLmN6h+NL+l7aec8htUPOWU3yD60fyWtp9yy29Q/ZRLLJrf0vdTLuu47u5ufN/HcRxc1/2t0066wsiyLHzfP9dhKKWUUkoppcqEaZp4nvdbp7EnKJYJE4lEyGQyWJZFa2vruQ5HKaWUUkopdY709vbieR6RSOSU0066I0ZKKaWUUkopdbr05gtKKaWUUkqpqqeFkVJKKaWUUqrqaWGklFJKKaWUqnpaGCmllFJKKaWqnhZGSimllFJKqaqnhdFp6O7uZuXKlUyfPp1oNMqcOXN4+OGHT/ljUWNxXZfVq1czd+5cotEoHR0d3HnnnRw8eLAEkVeGIPN7rM2bN2MYBv/zP/8TUKSVK8gcp1IpvvnNb7Jo0SIaGhq48MIL+eIXv8jLL79cgsgrQ5D5/fWvf82tt97K/PnzicViXHrppdx+++3s37+/BJFXhlItI6AwP1944YXMmDEjgEgrUynzq4LP7//+7//yuc99jilTptDc3MySJUt0+avzb0kFmeNsNstDDz3EwoULicfjXHLJJdxxxx10d3eXIPLTIGpc9u7dK21tbQIIIA0NDcXn11xzjbiuO+6+XNeVa6+9dsy+2traZO/evSUcSXkKMr8f9bWvfU0A2bRpU4ARV54gc7xnzx6ZOXNm8f0tLS3iOI4AYhiGPPDAAyUcSXkKMr+bNm2Surq6Yj7b2trENE0BJBaLyc9//vMSjqQ8lXIZISJy7733CiDTp08PKOLKEmR+169fX3zvyR7vvPNOCUdTfoKefx977DExDEMAiUajEovFisuLp59+ukSjKF9B5fcv/uIvpLOzc1yPf//3fy/xqMpLkPPw4OCgXHLJJcX3t7a2imVZAkhjY6Ns2bKlhCP57bQwGqclS5YIIEuXLpV9+/aJiMgbb7whHR0dAsiaNWvG3deaNWuKK+C33npLRAoz3PXXXy+ALFmypCRjKGdB5vdYGzZsKG6wV3thFGSOb731VgFk0aJFsnv3bhERyWaz8tRTT0ltba0A8tOf/rQk4yhXQeXX8zyZN2+eALJy5UpJJpMiIpJIJOSP/uiPBJC5c+dKNpst2VjKUamWESIiW7duLa6Uq7UwCjK/3/3udwWQKVOmnHSjcvv27aUaSlkKMr+bN28Wy7LEcRxZu3atpNNp8TxP/uEf/kEMw5BYLCb79+8v1VDKUlD5HV3Gjuexbt26Ug6p7AQ5D69cuVIAufrqq2XPnj0iIjI8PCx33323ADJ//vyz3tl1prQwGoe33367eDSnv7//uLbXXnutuALI5XKn7Mt1XWlpaRFANm/efFxbf39/sRqvpr1pQeZXROTdd9+Vr371q/K7v/u7xy3EqrkwCjLHe/fuFdM0xXEcOXDgwAnt3//+9wWQT3ziE4HFX+6CzO8LL7wggHR2dornece15XI56ezsFEBeeeWVQMdQzoJeRhzLdV257LLLisuJaiyMgs7vXXfdJYCsX7++FOFWnKDzu2zZMgHkiSeeOKFtxYoVAsj3vve9QGKvBKVcPnzU3r17pa6uTi6//PKq2jkV9Haw4zgSCoVO2IbwPE/mz58vgLz88suBjmG89Bqjcfiv//ovAG644QYaGxuPa1u0aBFz5szh8OHDbNmy5ZR9bd68mSNHjjB37lwWLlx4XFtjYyPLly8H4L//+78Dir78BZlfgDfffJO///u/58033ww81koVZI7ff/99fN/nU5/6FB0dHSe0f+UrX8E0Td555x1EJJgBlLkg87tjx45iX6Z5/CLatm0WL14MwPbt2wOIvDIEvYw41qOPPsovf/lLbr/99kBirURB53fnzp0AzJkzJ9hAK1SQ+e3t7WXjxo00NDTwx3/8xye0r1y5ksWLF9Pf3x9M8BWglMuHj7rzzjtxXZe1a9cSCoXOur9KEfQ2RC6XY86cOSdsQ5imWVzH/fKXvwwm+NOkhdE4bN68GYBly5aN2T76+uh0E9XXZBF0TpYvX867775bfFxxxRXBBFrBgszxnj17ALjgggvGbK+trSUej5NKpThy5MjpB1uBgsxvd3c3sVjspPmtqakBIJlMnkGklalUy80dO3awevVq5s2bxze/+c2zC7KCBZ3fXbt2Yds2M2fODCbAChdkfjdt2oSI8IUvfAHHcU5ov+qqq3jppZdYs2bNWURcWSZqu+rpp59m48aNPPLII8yfP/+s+qo0QeY4lUoB4HnemO35fB6AdDp92nEGwT4nf7XC7Nq1C4DOzs4x22fNmgXA7t27J7SvySLonDQ0NNDQ0FD8f21t7dkFOAkEmeMlS5awYcMGLrzwwpP+rcHBQSKRCC0tLWcYcWUJMr+PPvoojz766JhtIlLcI3fJJZecSagVqRTLTREp7v196qmnCIfDZx9ohQoyv9lslv3799PZ2cnrr7/O97//fXbs2MHUqVP52Mc+xle/+lXa29uDC74CBJnf0SPFl112WUDRVb6J2K7q7e3lvvvuY8GCBdx7771n3E+lCjLHF198MeFwmB07drBjx47jjixns1k2btwIwIIFC8427DOiR4zG4fDhwwDHbWwfq6mpCYCenp4J7Wuy0JyUXpA5njlzJsuWLWP27NkntIkI999/P1DYg2QYxhlGXFlKOQ97nlc8ReG2225jy5YtLFiwgKVLl55xvJWmFPl98skneeWVV7j77ru56qqrzjrGShZkfj/88EN832fPnj1cc801PPfcc/ziF79gw4YNxT3t1XSqOASfX4ApU6awdetWbrnlFi688EJaW1tZtmwZ//Iv/xJM0BVkIrYhvv3tb5NMJlmzZk3VrNeOFWSO6+vrue+++/A8jxtuuIGXXnqJ4eFhtm3bxo033siHH37I1VdfzZIlSwKL/3RoYTQOo4fzPnpe5ajR18dz2C/IviYLzUnpTUSOU6kUt912G88//zy2bfOtb33rjPuqNKXM71133UVraysLFy7k2Wef5brrruMnP/kJlmWdecAVJuj8dnV1cf/999PR0cG3v/3tYIKsYEHmd/T6Itd1WblyJVu3biWZTLJ161Y+97nP0d/fz6233kpvb29A0Ze/IPM7egrtK6+8wuLFi1m3bh3JZJLh4WE2btzIl7/8ZVasWBFQ5JWh1Ou3rq4unnjiCa688ko+//nPn1mQFS7oHK9evZqvfe1rvP/++3zqU5+irq6O+fPn88ILL3Dttdfyn//5n+dsHaeF0Wk42YXkox/eyc6XHKuPIPqabDQnpVeqHK9fv5558+bx7LPPAvDYY49x5ZVXnlmQFawU+Z0yZQrnn38+tl0483nLli2sXbv2zIOsYEHl95577iGZTPL4448Tj8cDi6/SBZHfcDjMl7/8ZR599FGefPJJrrjiCurq6rjiiit44YUXWLx4MYlEoqqugRkVRH4zmQwAzzzzDJ/4xCfYsWMHfX19DA0N8fzzz9PU1MSPfvSjqjxyVKr12+rVq8lkMlU5z35UUDl+88032bBhAwCGYdDW1la8Zu7//u//ijd7OBe0MBqH0YudBwYGxmwfrZDHcy3L6DRB9DVZBJlfNbZS5XhwcJCbbrqJG264gX379tHY2Mh//Md/8Cd/8idnF3CFKeU8/Mgjj7Bnzx4ymQzPPvsslmVx//33s27dujMPuMIEmd9/+7d/Y/369dx4443Fu4BWuyDzu2zZMtatW8c3vvGNMdv/8i//EoDXX3/9TEKtSEHmd3TP/MyZM1m/fn3xlGbLsvjiF7/I9773PYCTXqc4GZVy+Xv48GF+8IMfMGfOnHN2alc5CDLHH3zwAUuXLmXXrl08/PDDJJNJuru7SafTPPfcc1iWxYoVK3juueeCG8Bp0MJoHEYvIB8cHByzffSUgPFcaB5kX5OF5qT0SpHjN954g8svv5x//dd/BeC2225j+/bt3HDDDWcVayWaiHnYsixuueUWVq9eDcA//dM/nXFflSao/Lquy6pVq6ivr+fv/u7vAo2xkk3kMvjSSy8F4L333jvrvipFkPlta2sD4Oabby5urB7rpptuwjAMtm/fXjVnWZRy/l27di2u6/KVr3zljOObDILM8Xe+8x0SiQR/+qd/yl/91V8Ri8WAws9R3HzzzTzzzDMAPPDAAwFEfvq0MBqHiy66CChUuWPZtm3bcdNNVF+Theak9ILO8a5du/jMZz7D3r17ueCCC/j5z3/Oj370o+JKu9oEmd9nnnmGJ598kuHh4THbR3/jYe/evWcQaWUKKr8jIyMcOnSIRCLBtGnTMAyj+Bi9PfqBAweKr61fvz64QZSxiVwGj+5RHt0YqgZB5nfq1KkAY/6GHBT27Dc0NJDJZE66ETvZlHL+feaZZzAMgz/8wz888wAngSBzPPobk1/60pfGbP/93/99wuEwu3fvPifzsBZG47Bo0SKA4i0EP+rFF18EOOEHW0vd12ShOSm9IHMsInzpS1+iv7+fT37yk7zzzjt88pOfDC7YChRkfh977DHuuuuuk+5RTyQSAEybNu1MQq1IQeXXNE06OzvHfJx//vlA4cjc6GvVcvpukPPv8uXLufTSS/nVr341ZvvoDxjPmzfvTEKtSEHmd/TWxifbQE0kEgwMDNDS0kJzc/OZhFtxSrUNsXnzZrZv384111xTXD5UqyBzPHpd56nu7mfbNpFI5HTCDIaoU3r77bcFkKlTp0pfX99xba+++qoA0tLSIq7rnrIv13WlpaVFAHn11VePa+vr65O2tjYB5Be/+EWQQyhrQeZ3LIsXLxZANm3aFES4FSnIHL/00ksCyLRp0ySRSJQq5IoSZH5XrFghgKxevXrM9q9//esCyKpVqwKJvRKUehkhIrJnzx4BZPr06WcbbsUJMr9//ud/LoCsXLlyzPbbb79dAHnooYcCib0SBJnfgYEBCYVC0tLSckJfIiLf/e53BZDPfOYzgcVf7kq1fLjvvvsEkEceeSTIcCtSkDletWqVAHLvvfeO2f7jH/9YAFmwYEEQoZ82LYzG6frrrxdAli1bJvv37xff9+XNN9+Ujo6OMb84XV1dMnfuXJk7d65s3br1uLa/+Zu/Ka6A33rrLREprJSXLFkigCxdunTCxlUugszvR2lhVBBUju+6666q27AZj6Dy++qrr4phGFJbWytr166VfD4vIiLpdFq+853viGVZEo1G5YMPPpjQ8Z1rpVxGiFR3YSQSXH7fffddCYfDxfdks1kREUkkEvKtb31LDMOQ6dOny/Dw8ISO71wLcv695557BJDf+73fk23btomISDablX/8x3+UaDQqlmUVty2qRSmWDwsWLBBAfvazn03EEMpeUDnevn27RKNRMU1T1qxZU1wW5HI5WbdunTQ3NwsgP/zhDyd0fKO0MBqnvXv3Fo/mANLQ0FB8ft1110kulztu+tGV7FhfKtd15dprry22NzY2Fp+3t7fLvn37JnJoZSHI/H6UFkYFQeX405/+dHHPUWdn5299jG7UV4Mg5+HRPZWAOI4j06ZNE9M0BZBwOCw/+MEPJnBk5aGUy4hjp6/WwijI/D7xxBPHzb/t7e1iGIYA0tbWJi+//PJEDq0sBJnfZDJZ3GgHpLm5WUKhkABi27b87d/+7UQOrSwEvXzo6ekRwzDEtm1JpVITNYyyFmSOf/jDHxZ3oBiGIe3t7eI4TnH6u+++eyKHdhwtjE7DwYMH5Y477pD29nYJh8Mye/Zsefjhh4t7xI51qi9dNpuVhx56SC666CIJh8PS3t4ud955p3R3d0/EUMpSkPk9lhZGvxFEjmfNmlV8/VSPaiqMRIKdh3/yk5/I0qVL5fzzz5eamhq57LLLZMWKFbJz586JGEpZKtUy4tjpq7UwEgk2v6+99pp8/vOfl/PPP19qa2vliiuukFWrVsnhw4cnYihlKcj8plIpeeCBB2T27NkSiURk1qxZ8gd/8AfyxhtvTMRQylKQ+f3nf/5nAeTjH//4RIReMYLM8e7du+X222+Xyy67TGpqaqSzs1OWL18uL7300gSM5OQMkZP8WpNSSimllFJKVQm9K51SSimllFKq6mlhpJRSSimllKp6WhgppZRSSimlqp4WRkoppZRSSqmqp4WRUkoppZRSquppYaSUUkoppZSqeloYKaWUUkoppaqeFkZKKaWUUkqpqqeFkVJKKaWUUqrqaWGklFJKKaWUqnpaGCmllFJKKaWqnhZGSimllFJKqaqnhZFSSimllFKq6mlhpJRSSimllKp6/x/KQXPSrjXXXgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New configuration: [0.007633239344082646, 0.022078728328601412, 0.13985205459641628]\n",
      "s = 0.7594285607337952, b = 88.04608917236328, s/âb = 0.08081859082108686 => -80.36479030450393\n",
      "============================================================\n",
      "New configuration: [0.13928248353935993, 0.047491373708064964, 0.010655876140286078]\n",
      "s = 0.877084493637085, b = 132.7380828857422, s/âb = 0.07604467778445724 => -75.63275836128507\n",
      "============================================================\n",
      "New configuration: [0.014511048501835192, 0.06033635152905135, 0.16277005886274998]\n",
      "s = 0.9515194892883301, b = 189.45323181152344, s/âb = 0.0690719531816179 => -68.70497592260213\n",
      "============================================================\n",
      "New configuration: [0.004776249377395179, 0.03542590468521179, 0.00018949980392484532]\n",
      "both sig and bkg 0 at this hyperplane => 10000.0\n",
      "============================================================\n",
      "New configuration: [0.014000923208557146, 2.522841972429996e-05, 0.004372511353133884]\n",
      "both sig and bkg 0 at this hyperplane => 10000.0\n",
      "============================================================\n",
      "New configuration: [0.05178152214429777, 0.044251411052467646, 0.0632821611301762]\n",
      "s = 1.1743152141571045, b = 421.7465515136719, s/âb = 0.05715574297694043 => -56.84095067115059\n",
      "============================================================\n",
      "New configuration: [0.04082052944562943, 0.09022516994766577, 0.005459303536601326]\n",
      "s = 0.6622148156166077, b = 43.39800262451172, s/âb = 0.10026899606185317 => -99.63333820777017\n",
      "============================================================\n",
      "New configuration: [0.1005381913294477, 0.01947450511928783, 0.14705837866472699]\n",
      "s = 0.9888737201690674, b = 177.09292602539062, s/âb = 0.07424013046154611 => -73.6991051285601\n",
      "============================================================\n",
      "New configuration: [0.10863265873372163, 0.0009164141708686921, 0.04882385344064683]\n",
      "too little sig (0.16463935375213623) at this hyperplane => 0.0\n",
      "============================================================\n",
      "New configuration: [0.07608362217456735, 0.09806989259554089, 0.1128532675881185]\n",
      "s = 1.3073710203170776, b = 883.024169921875, s/âb = 0.04398537153410775 => -43.80811980473596\n",
      "============================================================\n",
      "New configuration: [0.004312005245109582, 0.15324872780585289, 0.017951446463679722]\n",
      "s = 0.5796083807945251, b = 33.10722732543945, s/âb = 0.10044193082770526 => -99.78876738484601\n",
      "============================================================\n",
      "New configuration: [0.03569830072811147, 0.15023442451269886, 0.0027716696797313476]\n",
      "s = 0.4592719078063965, b = 15.436023712158203, s/âb = 0.1163242673575449 => -115.57228764029756\n",
      "============================================================\n",
      "New configuration: [0.0008177446358818725, 0.012634633147053868, 0.14453966095953397]\n",
      "too little sig (0.16781018674373627) at this hyperplane => 0.0\n",
      "============================================================\n",
      "New configuration: [0.0052777957512544355, 0.05885843150783981, 0.11384039595698198]\n",
      "s = 0.6427544355392456, b = 42.57135009765625, s/âb = 0.09826507673868866 => -97.591817417488\n",
      "============================================================\n",
      "New configuration: [0.06383024141952591, 0.006572676940736414, 0.10699915555828364]\n",
      "s = 0.6656867861747742, b = 38.13597869873047, s/âb = 0.10748442548075997 => -106.44984897403691\n",
      "============================================================\n",
      "New configuration: [0.0019962232866249335, 0.00012570821471303257, 0.0010295341456646287]\n",
      "both sig and bkg 0 at this hyperplane => 10000.0\n",
      "============================================================\n",
      "New configuration: [0.1359959761091365, 0.00038715701127845105, 0.11942960413607477]\n",
      "too little sig (0.019424354657530785) at this hyperplane => 0.0\n",
      "============================================================\n",
      "New configuration: [7.967864738824507e-08, 0.0032702819681227377, 0.1627863970518735]\n",
      "both sig and bkg 0 at this hyperplane => 10000.0\n",
      "============================================================\n",
      "New configuration: [0.003828639698564433, 0.08126100323966108, 0.00676394431247403]\n",
      "s = 0.542519748210907, b = 27.613309860229492, s/âb = 0.10290669088093463 => -102.27725234355522\n",
      "============================================================\n",
      "New configuration: [0.1636896896018341, 0.07076342154846757, 0.023008820192091772]\n",
      "s = 1.096327781677246, b = 309.9886474609375, s/âb = 0.06223068153218006 => -61.915268053709184\n",
      "============================================================\n",
      "New configuration: [0.013397514632200026, 0.15441582243756266, 0.17326179770061775]\n",
      "s = 0.9286948442459106, b = 170.909423828125, s/âb = 0.07097339133089153 => -70.58486617810465\n",
      "============================================================\n",
      "New configuration: [0.13962919219744852, 0.001530200779151074, 0.08275565768453187]\n",
      "s = 0.27781233191490173, b = 5.740489959716797, s/âb = 0.11503492542986361 => -114.17425351179023\n",
      "============================================================\n",
      "New configuration: [0.0009534441223439954, 0.00787320395224895, 0.034117111604068155]\n",
      "too little sig (0.20058001577854156) at this hyperplane => 0.0\n",
      "============================================================\n",
      "New configuration: [0.04476073949961232, 0.0836504532533909, 0.016231291828951486]\n",
      "s = 1.0020486116409302, b = 207.4544677734375, s/âb = 0.06951518508698278 => -69.13494043873393\n",
      "============================================================\n",
      "New configuration: [0.017197840853029143, 0.14650324245381208, 0.106217278280734]\n",
      "s = 0.9983381628990173, b = 231.44554138183594, s/âb = 0.06557458697252382 => -65.23324738061976\n",
      "============================================================\n",
      "New configuration: [0.13774771789641105, 0.16036246484015623, 0.0003883983716635509]\n",
      "too little sig (0.02601224184036255) at this hyperplane => 0.0\n",
      "============================================================\n",
      "New configuration: [0.07993877847009948, 0.14310693049475107, 0.07063561737155502]\n",
      "s = 1.319851279258728, b = 1016.1741943359375, s/âb = 0.04139411473735767 => -41.25478197532557\n",
      "============================================================\n",
      "New configuration: [0.17707146752600078, 0.013677197225933524, 0.01655344091372483]\n",
      "s = 0.8840761780738831, b = 126.54068756103516, s/âb = 0.07850046390775854 => -77.97647956491274\n",
      "============================================================\n",
      "New configuration: [0.03605532210696444, 0.12508519105054472, 0.012143656974765613]\n",
      "s = 0.917121946811676, b = 152.59149169921875, s/âb = 0.07417021090994509 => -73.77250834528218\n",
      "============================================================\n",
      "New configuration: [0.010740552477837704, 0.03396953834093464, 0.024472603467767754]\n",
      "s = 0.8635058403015137, b = 138.69366455078125, s/âb = 0.07324690674782229 => -72.8587443167438\n",
      "============================================================\n",
      "New configuration: [0.17200179514136013, 0.08072259290235731, 0.14649415284319847]\n",
      "s = 1.310730218887329, b = 768.0185546875, s/âb = 0.04728258928420512 => -47.04318975859074\n",
      "============================================================\n",
      "New configuration: [0.00013431978106010774, 0.08509977512235806, 0.05568001767452157]\n",
      "both sig and bkg 0 at this hyperplane => 10000.0\n",
      "============================================================\n",
      "New configuration: [0.012980863211316331, 0.056333185632320495, 0.08439056373066815]\n",
      "s = 0.9194108843803406, b = 166.2212677001953, s/âb = 0.07124712646641716 => -70.85707916000113\n",
      "============================================================\n",
      "New configuration: [0.04789970945340786, 0.02985610655804986, 0.14885555723178542]\n",
      "s = 1.096967339515686, b = 280.9935607910156, s/âb = 0.065397536620257 => -64.96410763622555\n",
      "============================================================\n",
      "New configuration: [0.13669347049321065, 0.050756050075675734, 0.06207881176134262]\n",
      "s = 1.2185957431793213, b = 479.7669982910156, s/âb = 0.05561182086515227 => -55.29308076177134\n",
      "============================================================\n",
      "New configuration: [0.07100059673840092, 0.004271062808495391, 0.048641814626891856]\n",
      "s = 0.5363443493843079, b = 22.322385787963867, s/âb = 0.11307024082151892 => -112.08947538234754\n",
      "============================================================\n",
      "New configuration: [0.003190439914758602, 0.06890152209840668, 0.16305596981654036]\n",
      "s = 0.4902638792991638, b = 18.38953399658203, s/âb = 0.11382309654282172 => -113.02760752914831\n",
      "============================================================\n",
      "New configuration: [0.13176825324629457, 0.0560493601401197, 0.13868585550687815]\n",
      "s = 1.2411185503005981, b = 529.0987548828125, s/âb = 0.05393437408989168 => -53.624343074593426\n",
      "============================================================\n",
      "New configuration: [0.007618140280087157, 0.05396642506060349, 0.07506867759921772]\n",
      "s = 0.7588450312614441, b = 87.94426727294922, s/âb = 0.08080241833575479 => -80.34958316757404\n",
      "============================================================\n",
      "New configuration: [0.04962493058974874, 0.014045455014267426, 0.007450478252070269]\n",
      "s = 0.7634097337722778, b = 81.59300994873047, s/âb = 0.08438396347654409 => -83.94738372136409\n",
      "============================================================\n",
      "New configuration: [0.0417287711452159, 0.004186680534403397, 0.16218034957648966]\n",
      "s = 0.5305953621864319, b = 21.682205200195312, s/âb = 0.11348945921362379 => -112.49857643439825\n",
      "============================================================\n",
      "New configuration: [0.020189644856414137, 0.029338159145039632, 0.0021811376502827028]\n",
      "s = 0.3967759609222412, b = 11.967089653015137, s/âb = 0.11407164765712131 => -113.3672142491977\n",
      "============================================================\n",
      "New configuration: [0.13078370610596635, 0.029933083016860963, 0.07957554105795794]\n",
      "s = 1.0995503664016724, b = 281.69940185546875, s/âb = 0.06547001832712167 => -65.0309920363864\n",
      "============================================================\n",
      "New configuration: [0.04289960373047148, 0.023876001646411127, 0.05764829582215643]\n",
      "s = 1.0433018207550049, b = 223.4146728515625, s/âb = 0.06974580361704896 => -69.25811139400338\n",
      "============================================================\n",
      "New configuration: [0.1598652577262969, 0.10468591610679887, 0.038768958608379214]\n",
      "s = 1.2225565910339355, b = 543.3029174804688, s/âb = 0.05243019445496091 => -52.19206629506533\n",
      "============================================================\n",
      "New configuration: [0.11740800957840683, 0.001320058616238718, 0.03779827368212762]\n",
      "too little sig (0.2436365783214569) at this hyperplane => 0.0\n",
      "============================================================\n",
      "New configuration: [0.005403149532554133, 6.601727425735736e-07, 0.07489715687451455]\n",
      "both sig and bkg 0 at this hyperplane => 10000.0\n",
      "============================================================\n",
      "New configuration: [4.936520415842285e-05, 0.001188209314519949, 0.1109249374506815]\n",
      "both sig and bkg 0 at this hyperplane => 10000.0\n",
      "============================================================\n",
      "New configuration: [0.05315087532545141, 0.014548520163736879, 0.07166054021198798]\n",
      "s = 0.9055920243263245, b = 134.62939453125, s/âb = 0.07796119734462321 => -77.40864682985175\n",
      "============================================================\n",
      "New configuration: [6.603915245688945e-05, 0.029320054805988597, 0.07888844959071456]\n",
      "both sig and bkg 0 at this hyperplane => 10000.0\n",
      "============================================================\n",
      "New configuration: [0.08134387187273766, 0.00011611794054172197, 0.0774958106608823]\n",
      "both sig and bkg 0 at this hyperplane => 10000.0\n",
      "============================================================\n",
      "New configuration: [0.01675928348054357, 0.02335436550890311, 0.05323505539984184]\n",
      "s = 0.97346031665802, b = 196.62454223632812, s/âb = 0.06936552211520124 => -68.9637320749399\n",
      "============================================================\n",
      "New configuration: [0.00417585573485949, 0.12148720612627478, 0.1341060842145008]\n",
      "s = 0.5693168640136719, b = 31.91077423095703, s/âb = 0.100485023531161 => -99.86638444713651\n",
      "============================================================\n",
      "New configuration: [9.174637071147362e-06, 0.0013876383620191662, 0.08990155177753806]\n",
      "both sig and bkg 0 at this hyperplane => 10000.0\n",
      "============================================================\n",
      "New configuration: [9.576469566529517e-06, 0.0014049006578272921, 0.10239540225722242]\n",
      "both sig and bkg 0 at this hyperplane => 10000.0\n",
      "============================================================\n",
      "New configuration: [0.002156770919801247, 0.005238379312428125, 0.12279845477572718]\n",
      "s = 0.3850889205932617, b = 11.578949928283691, s/âb = 0.11254982671273948 => -111.8492838066077\n",
      "============================================================\n",
      "New configuration: [0.02612015261459991, 0.005187547897105428, 0.06662474452295379]\n",
      "s = 0.5929822325706482, b = 27.89417266845703, s/âb = 0.11188096077345953 => -110.83520898734656\n",
      "============================================================\n",
      "New configuration: [0.002051246214262655, 0.0024869408429528494, 0.12885881310392974]\n",
      "s = 0.354850709438324, b = 8.833778381347656, s/âb = 0.11860491301803995 => -117.76294560453509\n",
      "============================================================\n",
      "New configuration: [0.03226183565975797, 0.0017879660487330183, 0.06874373506969184]\n",
      "s = 0.31450745463371277, b = 6.972072601318359, s/âb = 0.11823143463911702 => -117.26178423534458\n",
      "============================================================\n",
      "New configuration: [0.0999394698971967, 7.781765039177405e-06, 0.0022997151774420375]\n",
      "both sig and bkg 0 at this hyperplane => 10000.0\n",
      "============================================================\n",
      "New configuration: [0.0034095851209225607, 0.11652770065472393, 0.14485569932943648]\n",
      "s = 0.5091888308525085, b = 20.43828010559082, s/âb = 0.11216809389410405 => -111.40322800337897\n",
      "============================================================\n",
      "New configuration: [0.00500295784276844, 0.03193229468527591, 0.06359339144323439]\n",
      "s = 0.6258628368377686, b = 39.76422882080078, s/âb = 0.0989914391215439 => -98.31354733478672\n",
      "============================================================\n",
      "New configuration: [0.09240665712866669, 0.0019811175881917172, 0.009555536343893483]\n",
      "s = 0.3385167717933655, b = 7.591548442840576, s/âb = 0.12196462987973054 => -120.97213126401749\n",
      "============================================================\n",
      "New configuration: [0.07797265657210604, 0.1593919727702603, 0.028476122431585444]\n",
      "s = 1.150869607925415, b = 398.7257385253906, s/âb = 0.05760744565965478 => -57.326381379845955\n",
      "============================================================\n",
      "New configuration: [0.13406244202952558, 0.022248732794476277, 0.0002249636247508284]\n",
      "too little sig (2.048552778433077e-05) at this hyperplane => 0.0\n",
      "============================================================\n",
      "New configuration: [0.003003565329666453, 0.10016725233310163, 0.018342191792231344]\n",
      "s = 0.4740367829799652, b = 17.038341522216797, s/âb = 0.11431506077429415 => -113.49769363207055\n",
      "============================================================\n",
      "New configuration: [0.09058384309358346, 0.007711443095973872, 0.0935175995792675]\n",
      "s = 0.714571475982666, b = 53.26713562011719, s/âb = 0.09768977570236288 => -96.83338065799263\n",
      "============================================================\n",
      "New configuration: [0.03651151577511112, 0.0005437183484414941, 0.03818709234908761]\n",
      "too little sig (0.06588125228881836) at this hyperplane => 0.0\n",
      "============================================================\n",
      "New configuration: [0.07084495731071042, 0.034346765070548804, 4.5501341562622834e-05]\n",
      "both sig and bkg 0 at this hyperplane => 10000.0\n",
      "============================================================\n",
      "New configuration: [0.004116171914190117, 0.010229922873067824, 0.11253755350167169]\n",
      "s = 0.5646425485610962, b = 31.065874099731445, s/âb = 0.10100029228533876 => -100.38540578349088\n",
      "============================================================\n",
      "New configuration: [0.11945046703393589, 0.006596321692043906, 0.1364044428950255]\n",
      "s = 0.6667884588241577, b = 38.221675872802734, s/âb = 0.10754209020641377 => -106.5014005541817\n",
      "============================================================\n",
      "New configuration: [0.0012344301576593625, 0.011611577387645858, 0.027518181445523475]\n",
      "s = 0.25554823875427246, b = 5.895586013793945, s/âb = 0.1045001314960543 => -103.80843794814751\n",
      "============================================================\n",
      "New configuration: [0.15607563548789546, 0.03250342541649786, 0.006671054449136443]\n",
      "s = 0.7277768850326538, b = 66.93741607666016, s/âb = 0.08879286296639277 => -88.30730821836889\n",
      "============================================================\n",
      "New configuration: [0.000653289630337536, 0.057212992692931876, 0.11265277289322466]\n",
      "too little sig (0.12338750064373016) at this hyperplane => 0.0\n",
      "============================================================\n",
      "New configuration: [0.08304708221643212, 0.03926490888256383, 0.07446638893073484]\n",
      "s = 1.1638574600219727, b = 375.5240783691406, s/âb = 0.060028287195092934 => -59.65666957447414\n",
      "============================================================\n",
      "New configuration: [0.00379788723856483, 0.14565498639196556, 0.11005069962353757]\n",
      "s = 0.5400938987731934, b = 27.302263259887695, s/âb = 0.1030263560368394 => -102.3902489609221\n",
      "============================================================\n",
      "New configuration: [0.008308631139067662, 0.05334304411032038, 0.0021677071450996997]\n",
      "s = 0.3951600193977356, b = 11.892992973327637, s/âb = 0.11395891390239328 => -113.25210650909942\n",
      "============================================================\n",
      "New configuration: [0.18291266989670663, 0.019890197258170185, 0.00017495505606500138]\n",
      "both sig and bkg 0 at this hyperplane => 10000.0\n",
      "============================================================\n",
      "New configuration: [0.13137391155045477, 0.052671244050778276, 0.14528562435173256]\n",
      "s = 1.2280306816101074, b = 501.2680969238281, s/âb = 0.0548264107747591 => -54.50680355979963\n",
      "============================================================\n",
      "New configuration: [0.15367713110596135, 0.06915283544799908, 0.12646980740061436]\n",
      "s = 1.2827805280685425, b = 652.4215087890625, s/âb = 0.0502058056545375 => -49.934432034593975\n",
      "============================================================\n",
      "New configuration: [0.17375425119411544, 0.15623090951475443, 0.09760119436518833]\n",
      "s = 1.391292691230774, b = 1323.325927734375, s/âb = 0.03823578607333194 => -38.10242207930729\n",
      "============================================================\n",
      "New configuration: [0.13864114603160488, 0.003065017865917104, 0.02871832998534695]\n",
      "s = 0.4459025263786316, b = 13.514012336730957, s/âb = 0.12063857267774382 => -119.5885230594521\n",
      "============================================================\n",
      "New configuration: [0.040785146411420815, 0.08024548896334391, 0.03566103395990949]\n",
      "s = 1.1799882650375366, b = 481.2549133300781, s/âb = 0.053765887305156745 => -53.5349555339116\n",
      "============================================================\n",
      "New configuration: [0.002921772490837129, 0.10752724388728414, 0.09351601120437891]\n",
      "s = 0.4658966660499573, b = 16.650663375854492, s/âb = 0.11364933885265815 => -112.85715821266525\n",
      "============================================================\n",
      "New configuration: [0.1598823004439851, 0.11359092128583187, 0.0065147375417016744]\n",
      "s = 0.7197409272193909, b = 57.88737106323242, s/âb = 0.09440336277348346 => -93.8311009435339\n",
      "============================================================\n",
      "New configuration: [0.0061200315948564685, 0.1415844852685427, 0.04272244494650436]\n",
      "s = 0.6898600459098816, b = 57.30908966064453, s/âb = 0.09094546223036004 => -90.37113213461785\n",
      "============================================================\n",
      "New configuration: [0.1250792311157842, 0.0403944051032429, 0.16155841084566505]\n",
      "s = 1.1703143119812012, b = 384.49029541015625, s/âb = 0.05965396503709812 => -59.28407754721723\n",
      "============================================================\n",
      "New configuration: [0.18323927621999359, 0.0819504447263967, 0.044863163151888555]\n",
      "s = 1.254273772239685, b = 624.4920654296875, s/âb = 0.05017365154768676 => -49.950559982702636\n",
      "============================================================\n",
      "New configuration: [0.17069465517355295, 0.06019194822687413, 0.0355451851022497]\n",
      "s = 1.2016823291778564, b = 489.08746337890625, s/âb = 0.05431577269978958 => -54.05864895222932\n",
      "============================================================\n",
      "New configuration: [0.08922839394847278, 0.0013058265739665461, 2.7560938025343225e-05]\n",
      "both sig and bkg 0 at this hyperplane => 10000.0\n",
      "============================================================\n",
      "New configuration: [0.016409419344042473, 0.0031103230650835066, 0.001461296744722232]\n",
      "s = 0.2992187440395355, b = 6.896499156951904, s/âb = 0.11313009451261637 => -112.39612899628301\n",
      "============================================================\n",
      "New configuration: [0.048831405795319235, 0.12484955099529747, 0.10805949870575805]\n",
      "s = 1.2474677562713623, b = 694.6730346679688, s/âb = 0.047317160742599826 => -47.12586612473355\n",
      "============================================================\n",
      "New configuration: [0.17875412712877808, 0.14654476454473472, 0.0025307075376372707]\n",
      "s = 0.4349684715270996, b = 13.806903839111328, s/âb = 0.11645353030145891 => -115.72075626083875\n",
      "============================================================\n",
      "New configuration: [0.05873565181152569, 0.12846511945031933, 0.004150591627165374]\n",
      "s = 0.5758700370788574, b = 29.576147079467773, s/âb = 0.10554878877587058 => -104.86836629635937\n",
      "============================================================\n",
      "New configuration: [0.15357009126255905, 0.1389897436642252, 0.039927937027529045]\n",
      "s = 1.2291789054870605, b = 559.9834594726562, s/âb = 0.051924695719748 => -51.689656129829764\n",
      "============================================================\n",
      "New configuration: [0.1010191886670963, 0.072682360077981, 0.0027285636715460647]\n",
      "s = 0.45510542392730713, b = 15.193696975708008, s/âb = 0.11618066769963001 => -115.43473820795383\n",
      "============================================================\n",
      "New configuration: [0.0012382406771291933, 0.07712865790346364, 0.0220590968102833]\n",
      "s = 0.25625285506248474, b = 5.974343299865723, s/âb = 0.10410276927317677 => -103.42230203995997\n",
      "============================================================\n",
      "New configuration: [0.09201138102065526, 0.08839255744568499, 0.028574871766761246]\n",
      "s = 1.151591420173645, b = 399.57403564453125, s/âb = 0.057582880936171046 => -57.30111729082203\n",
      "============================================================\n",
      "New configuration: [0.0019801580934697073, 0.023712832343760648, 0.07669049485661734]\n",
      "s = 0.364413321018219, b = 10.646349906921387, s/âb = 0.11105638405586364 => -110.3911930198541\n",
      "============================================================\n",
      "New configuration: [0.0677753650470368, 0.14559995657972705, 0.035850348522812804]\n",
      "s = 1.2053319215774536, b = 496.97918701171875, s/âb = 0.05404559132642781 => -53.79341287073856\n",
      "============================================================\n",
      "New configuration: [0.07929330206971165, 0.0021814299250160693, 0.061167270236053776]\n",
      "s = 0.3616677522659302, b = 8.475747108459473, s/âb = 0.12336010154632457 => -122.37245372098786\n",
      "============================================================\n",
      "New configuration: [0.16675616120417927, 0.03289555976959084, 0.1240244861739658]\n",
      "s = 1.122451901435852, b = 310.1130065917969, s/âb = 0.0637021908906988 => -63.28340498637092\n",
      "============================================================\n",
      "New configuration: [0.18500987041599637, 0.08421496812309551, 0.0]\n",
      "both sig and bkg 0 at this hyperplane => 10000.0\n",
      "============================================================\n",
      "New configuration: [0.03961157295597769, 0.03298186265776976, 0.050703933292372216]\n",
      "s = 1.1094982624053955, b = 306.8179626464844, s/âb = 0.0633032271201326 => -62.91597654270259\n",
      "============================================================\n",
      "New configuration: [0.1508579060856289, 0.030455696744025238, 0.1731373869265976]\n",
      "s = 1.1034612655639648, b = 285.88726806640625, s/âb = 0.0652191329965831 => -64.78437717103687\n",
      "============================================================\n",
      "New configuration: [0.18500987041599637, 0.03095226559464184, 0.01232729021344961]\n",
      "s = 0.9216747283935547, b = 155.23757934570312, s/âb = 0.07390151902033466 => -73.50921991130956\n",
      "============================================================\n",
      "New configuration: [0.10735719756219128, 0.004704293728844726, 0.1490605261901488]\n",
      "s = 0.5638684034347534, b = 24.991989135742188, s/âb = 0.11237133379340235 => -111.36497101211336\n",
      "============================================================\n",
      "New configuration: [0.1091420097434178, 0.023718648247515375, 0.00046685290560210266]\n",
      "too little sig (0.053173698484897614) at this hyperplane => 0.0\n",
      "============================================================\n",
      "New configuration: [0.0, 0.033713206985402915, 0.056388822154585856]\n",
      "both sig and bkg 0 at this hyperplane => 10000.0\n",
      "============================================================\n",
      "New configuration: [0.07923105387934581, 0.002320565399055138, 0.0607721948151249]\n",
      "s = 0.37635883688926697, b = 8.999955177307129, s/âb = 0.12459371010411942 => -123.54459983370063\n",
      "============================================================\n",
      "New configuration: [0.09163138101649118, 0.010090993189925897, 0.09524479257883217]\n",
      "s = 0.7974435687065125, b = 80.59031677246094, s/âb = 0.08868417978292302 => -87.97727407398531\n",
      "============================================================\n",
      "New configuration: [0.09293176670051893, 0.002149740486023773, 0.013430420341277017]\n",
      "s = 0.3580678105354309, b = 8.41010570526123, s/âb = 0.12260986009980988 => -121.63413857532775\n",
      "============================================================\n",
      "New configuration: [0.07891494643855762, 0.003382570637571845, 0.0586326337023435]\n",
      "s = 0.4715678095817566, b = 17.339759826660156, s/âb = 0.11273814023288603 => -111.87561551896187\n",
      "============================================================\n",
      "New configuration: [0.017307794403414126, 0.006936245594545025, 0.0010798648243701566]\n",
      "too little sig (0.22963891923427582) at this hyperplane => 0.0\n",
      "============================================================\n",
      "New configuration: [0.11510078979809002, 0.03600999599377997, 0.0004365248459650808]\n",
      "too little sig (0.04292679205536842) at this hyperplane => 0.0\n",
      "============================================================\n",
      "New configuration: [0.001528189180350232, 0.0179944243451719, 0.1402392731232661]\n",
      "s = 0.30309030413627625, b = 7.064329624176025, s/âb = 0.11323321388790114 => -112.46661722964319\n",
      "============================================================\n",
      "New configuration: [0.07868552324581189, 0.004355073496266231, 0.05723025161449459]\n",
      "s = 0.54171222448349, b = 22.833736419677734, s/âb = 0.11292129151603737 => -111.92758069803031\n",
      "============================================================\n",
      "New configuration: [0.08320334007048547, 0.04607876890459416, 0.07394547345996653]\n",
      "s = 1.198563814163208, b = 448.91656494140625, s/âb = 0.05654390959770179 => -56.21583475638782\n",
      "============================================================\n",
      "New configuration: [0.0020708891815712734, 0.026184468180828157, 0.07668916976086333]\n",
      "s = 0.3753078281879425, b = 11.197562217712402, s/âb = 0.11153882849200969 => -110.8708664564834\n",
      "============================================================\n",
      "New configuration: [0.09333813189405772, 0.002351080599676185, 0.01747053027508554]\n",
      "s = 0.3794982135295868, b = 9.130447387695312, s/âb = 0.12473727857100894 => -123.67361103462419\n",
      "============================================================\n",
      "New configuration: [0.005004763153498047, 0.035710230070823794, 0.06325017882123538]\n",
      "s = 0.6259834170341492, b = 39.79682159423828, s/âb = 0.09897088543514339 => -98.29292168248266\n",
      "============================================================\n",
      "New configuration: [0.000843782737614791, 0.0649270288132457, 0.11360050226059011]\n",
      "too little sig (0.17445863783359528) at this hyperplane => 0.0\n",
      "============================================================\n",
      "New configuration: [0.008438578684729131, 0.055500777385194544, 0.002229939107365462]\n",
      "s = 0.401966392993927, b = 12.141880989074707, s/âb = 0.11472974498332358 => -114.00405057692086\n",
      "============================================================\n",
      "New configuration: [0.07922908083245363, 0.0024093875585973843, 0.06066752066271885]\n",
      "s = 0.3854025602340698, b = 9.338409423828125, s/âb = 0.12526534237305884 => -124.16940723315668\n",
      "============================================================\n",
      "New configuration: [0.09234921408036732, 0.002109965188361213, 0.009766767066778346]\n",
      "s = 0.35334405303001404, b = 8.197792053222656, s/âb = 0.12253860102463199 => -121.5599591989953\n",
      "============================================================\n",
      "New configuration: [0.17837858873105797, 0.14907304409842256, 0.0026533660708507496]\n",
      "s = 0.44768625497817993, b = 14.757509231567383, s/âb = 0.11595593180314037 => -115.21024203848022\n",
      "============================================================\n",
      "New configuration: [0.00212896835947158, 0.002578712824872614, 0.12916505254685737]\n",
      "s = 0.36372944712638855, b = 9.140504837036133, s/âb = 0.11952262334418311 => -118.67634087414126\n",
      "============================================================\n",
      "New configuration: [0.0077085576774680075, 0.06174851405375957, 0.07477619317606855]\n",
      "s = 0.7623854279518127, b = 89.88751983642578, s/âb = 0.08029897932805931 => -79.85491222436758\n",
      "============================================================\n",
      "New configuration: [0.10141199350275502, 0.07657373055083593, 0.002731890906649015]\n",
      "s = 0.45540472865104675, b = 15.193564414978027, s/âb = 0.11625691045634974 => -115.51176558449998\n",
      "============================================================\n",
      "New configuration: [0.06367047965057339, 0.008682000218790413, 0.10816694109539877]\n",
      "s = 0.7516525387763977, b = 64.60686492919922, s/âb = 0.0933342893198984 => -92.55162103820439\n",
      "============================================================\n",
      "New configuration: [0.01654299557995538, 0.003566262362724316, 0.0013871780057179053]\n",
      "s = 0.28696537017822266, b = 6.597792625427246, s/âb = 0.11092438638704392 => -110.24125768192341\n",
      "============================================================\n",
      "New configuration: [0.02022820767285183, 0.029732165108263736, 0.0020364838739523]\n",
      "s = 0.3797290325164795, b = 11.17550277709961, s/âb = 0.11295568483436262 => -112.30727124977878\n",
      "============================================================\n",
      "New configuration: [0.07926268246891223, 0.0024179217587962654, 0.06090040212169345]\n",
      "s = 0.38612720370292664, b = 9.346383094787598, s/âb = 0.12544653129963784 => -124.33603074174744\n",
      "============================================================\n",
      "New configuration: [0.00111145486478908, 0.014860291460415002, 0.14249614791557358]\n",
      "too little sig (0.23262237012386322) at this hyperplane => 0.0\n",
      "============================================================\n",
      "New configuration: [0.001677205879951698, 0.019043066102158543, 0.13941182171795413]\n",
      "s = 0.32526353001594543, b = 7.862547874450684, s/âb = 0.11521275240286166 => -114.41429438872629\n",
      "============================================================\n",
      "New configuration: [0.002280371331755579, 0.005833567956713159, 0.12336764861586265]\n",
      "s = 0.39956793189048767, b = 12.357743263244629, s/âb = 0.11305915244658674 => -112.3340019636936\n",
      "============================================================\n",
      "New configuration: [0.09101076290043664, 0.008812937103457324, 0.09422765881020094]\n",
      "s = 0.7561955451965332, b = 65.67094421386719, s/âb = 0.09313573808898203 => -92.35264699188674\n",
      "============================================================\n",
      "New configuration: [0.09224475197406855, 0.005250190140698402, 0.09614098225092035]\n",
      "s = 0.5967662930488586, b = 28.255470275878906, s/âb = 0.11187527896293863 => -110.84489428776627\n",
      "============================================================\n",
      "New configuration: [0.0031240700630522813, 0.10305129358366405, 0.09483185184586798]\n",
      "s = 0.4846203029155731, b = 17.908184051513672, s/âb = 0.11400806203930312 => -113.21321547544116\n",
      "============================================================\n",
      "New configuration: [0.11121244260285829, 0.028980103303201003, 0.0004550972285792156]\n",
      "too little sig (0.0490448996424675) at this hyperplane => 0.0\n",
      "============================================================\n",
      "New configuration: [0.12772517639164693, 0.028177953035765164, 0.00029660565011620525]\n",
      "too little sig (0.003773507196456194) at this hyperplane => 0.0\n",
      "============================================================\n",
      "New configuration: [0.05204074201441934, 0.019338450521583103, 0.0702407723785048]\n",
      "s = 0.9869130849838257, b = 176.39395141601562, s/âb = 0.07423851608281495 => -73.69918040269229\n",
      "============================================================\n",
      "New configuration: [0.003394898984056517, 0.06987697276664388, 0.16011854851081858]\n",
      "s = 0.5077747106552124, b = 20.217592239379883, s/âb = 0.11246119467208407 => -111.68719063633337\n",
      "============================================================\n",
      "New configuration: [0.05787984240521699, 0.13004096147877645, 0.004554797103066064]\n",
      "s = 0.6049259305000305, b = 34.603057861328125, s/âb = 0.10253871084816668 => -101.89653124982696\n",
      "============================================================\n",
      "New configuration: [0.15643551476339257, 0.04956129808864827, 0.007294348459148695]\n",
      "s = 0.7570720911026001, b = 79.04557800292969, s/âb = 0.08501750430562721 => -84.5726084638292\n",
      "============================================================\n",
      "New configuration: [0.0012345483269560207, 0.008513603019474602, 0.03110276104288446]\n",
      "s = 0.2555575668811798, b = 5.925169944763184, s/âb = 0.10424618138140088 => -103.56126900842821\n",
      "============================================================\n",
      "New configuration: [0.0037941316594951777, 0.09183232654301098, 0.006970534447584484]\n",
      "s = 0.5397330522537231, b = 27.2990779876709, s/âb = 0.10296344093121203 => -102.33248586595593\n",
      "============================================================\n",
      "New configuration: [0.006671028581973926, 0.13296311081770765, 0.041276886430576414]\n",
      "s = 0.7168864607810974, b = 66.67617797851562, s/âb = 0.08763795874086738 => -87.09384746633621\n",
      "============================================================\n",
      "New configuration: [0.003877379113472589, 0.012896491530301464, 0.11373426391013018]\n",
      "s = 0.5466703772544861, b = 28.05962371826172, s/âb = 0.10286896998843226 => -102.23802541656019\n",
      "============================================================\n",
      "New configuration: [0.08595191467495272, 0.04881356015951914, 0.08314146513245689]\n",
      "s = 1.2110415697097778, b = 466.3899841308594, s/âb = 0.05605233005240652 => -55.72425051002587\n",
      "============================================================\n",
      "New configuration: [0.07965944299703566, 0.011505687487264092, 0.06173004460542389]\n",
      "s = 0.8372258543968201, b = 95.38626861572266, s/âb = 0.08559904014917877 => -84.92295690802854\n",
      "============================================================\n",
      "New configuration: [0.07750859865451469, 0.003161760103456005, 0.05478737149424022]\n",
      "s = 0.45375415682792664, b = 13.902117729187012, s/âb = 0.12104416760072849 => -119.98251150046364\n",
      "============================================================\n",
      "New configuration: [0.1335195648533677, 0.1475101300757186, 0.0006843885013420548]\n",
      "too little sig (0.12817682325839996) at this hyperplane => 0.0\n",
      "============================================================\n",
      "New configuration: [0.09327906367008139, 0.0020873832643355035, 0.014113707561969557]\n",
      "s = 0.35075753927230835, b = 7.948697090148926, s/âb = 0.12351248847062866 => -122.48746626154819\n",
      "============================================================\n",
      "New configuration: [0.027548902755757953, 0.006578498894991158, 0.06603039513560817]\n",
      "s = 0.6659722924232483, b = 38.15263366699219, s/âb = 0.10750741632198803 => -106.471876487461\n",
      "============================================================\n",
      "New configuration: [0.006443236113448663, 0.08264841202567297, 0.11364555345047421]\n",
      "s = 0.7058512568473816, b = 62.19070816040039, s/âb = 0.0893370271445602 => -88.77066000692669\n",
      "============================================================\n",
      "New configuration: [0.07591494036355893, 0.16168755541765384, 0.07041245586669592]\n",
      "s = 1.3154323101043701, b = 1006.5048828125, s/âb = 0.04145456114412995 => -41.314318659844886\n",
      "============================================================\n",
      "New configuration: [0.0016921170508855837, 0.020192862802217975, 0.1418339502580927]\n",
      "s = 0.3273217976093292, b = 9.298548698425293, s/âb = 0.1067207965253349 => -106.09435174356119\n",
      "============================================================\n",
      "New configuration: [0.04946533041647875, 0.02543165928029207, 0.008108983162563081]\n",
      "s = 0.7901881337165833, b = 91.45674896240234, s/âb = 0.08250918062157207 => -82.0729758369635\n",
      "============================================================\n",
      "New configuration: [0.035774020313337575, 0.14213253358021266, 0.0031691614353856787]\n",
      "s = 0.49645721912384033, b = 20.50795555114746, s/âb = 0.10919021395139097 => -108.53591731684989\n",
      "============================================================\n",
      "New configuration: [0.05716280822508094, 0.024682557254262237, 0.059136121695363864]\n",
      "s = 1.0519863367080688, b = 231.03492736816406, s/âb = 0.06915839396567565 => -68.67589545552839\n",
      "============================================================\n",
      "New configuration: [0.004744780202091856, 0.12903879819299674, 0.13770934427793963]\n",
      "s = 0.609367311000824, b = 37.18497848510742, s/âb = 0.09965876097953609 => -98.98125525294023\n",
      "============================================================\n",
      "New configuration: [0.13929124166520873, 0.004483097410017506, 0.08305093160880522]\n",
      "s = 0.5498000383377075, b = 23.685842514038086, s/âb = 0.11253649348755572 => -111.55404874512061\n",
      "============================================================\n",
      "New configuration: [0.013406530357855145, 0.07172267922168475, 0.08539647083569969]\n",
      "s = 0.928840160369873, b = 171.06246948242188, s/âb = 0.07095306483715434 => -70.5643712468416\n",
      "============================================================\n",
      "New configuration: [0.07922553640859574, 0.0024406596238478045, 0.060690198441777796]\n",
      "s = 0.3884238600730896, b = 9.404052734375, s/âb = 0.12580542329024003 => -124.69592228568399\n",
      "============================================================\n",
      "New configuration: [0.09941601012691335, 0.07778113078232118, 0.0030235574951557823]\n",
      "s = 0.4831412732601166, b = 19.420095443725586, s/âb = 0.10918494233217566 => -108.54688064033388\n",
      "============================================================\n",
      "New configuration: [0.07922658255517742, 0.0024475680559334755, 0.060603877457657156]\n",
      "s = 0.38927194476127625, b = 9.416223526000977, s/âb = 0.12599772999671663 => -124.88956769882518\n",
      "============================================================\n",
      "New configuration: [0.07924617590587209, 0.0024181409652860608, 0.060743875989672826]\n",
      "s = 0.38615480065345764, b = 9.346383094787598, s/âb = 0.1254555655822713 => -124.34485865715612\n",
      "============================================================\n",
      "New configuration: [0.017188392571596812, 0.00912801659160855, 0.0015034598024846275]\n",
      "s = 0.3060060143470764, b = 7.0483551025390625, s/âb = 0.11444262222257713 => -113.67695144766478\n",
      "============================================================\n",
      "New configuration: [0.009736927223146983, 0.044165078082881525, 0.02603649732741264]\n",
      "s = 0.833396315574646, b = 127.11470031738281, s/âb = 0.07383796887508894 => -73.44867390966525\n",
      "============================================================\n",
      "New configuration: [0.10993683731752162, 0.00946387231919558, 0.14652632046429614]\n",
      "s = 0.7780107259750366, b = 72.93009185791016, s/âb = 0.09094092850648912 => -90.19512857737615\n",
      "============================================================\n",
      "New configuration: [0.07928112240041546, 0.002364211635989368, 0.06067687634196556]\n",
      "s = 0.38083550333976746, b = 9.182692527770996, s/âb = 0.12482193649880587 => -123.74635046836885\n",
      "============================================================\n",
      "New configuration: [0.07922713210355334, 0.002398008568688374, 0.06062586269150811]\n",
      "s = 0.3841836750507355, b = 9.331990242004395, s/âb = 0.12491442829415912 => -123.8483193784535\n",
      "============================================================\n",
      "New configuration: [0.021208211124307062, 0.03592172003623233, 0.0022885370256511047]\n",
      "s = 0.4084624946117401, b = 12.473567962646484, s/âb = 0.11503032140372298 => -114.29750254755565\n",
      "============================================================\n",
      "New configuration: [0.003578322311778543, 0.07901250587818269, 0.16373899209308002]\n",
      "s = 0.5227899551391602, b = 24.351194381713867, s/âb = 0.10556624410445378 => -104.87254422033459\n",
      "============================================================\n",
      "New configuration: [0.07460344095686124, 0.003080056923975155, 0.0585992483954297]\n",
      "s = 0.4471047520637512, b = 13.576432228088379, s/âb = 0.12068641547707133 => -119.63484037664308\n",
      "============================================================\n",
      "New configuration: [0.09188921795383356, 0.003363873008254129, 0.009567782331796833]\n",
      "s = 0.4699707627296448, b = 17.318344116210938, s/âb = 0.11242719446149767 => -111.56829640020766\n",
      "============================================================\n",
      "New configuration: [0.09350983479096216, 0.0010115257047469749, 0.013395145816660122]\n",
      "too little sig (0.18567600846290588) at this hyperplane => 0.0\n",
      "============================================================\n",
      "New configuration: [0.09276435989335545, 0.0027475843826259166, 0.013595143286694282]\n",
      "s = 0.4179714024066925, b = 12.12453556060791, s/âb = 0.11935674680441996 => -118.37418222796808\n",
      "============================================================\n",
      "New configuration: [0.09324065487225452, 0.0024137278881362196, 0.014365316853730605]\n",
      "s = 0.3857492208480835, b = 9.341971397399902, s/âb = 0.12535353037068314 => -124.24682239534259\n",
      "============================================================\n",
      "New configuration: [0.13856004899185212, 0.006094453621256634, 0.02863914946031053]\n",
      "s = 0.6425409913063049, b = 35.12531661987305, s/âb = 0.10808689126005767 => -107.05843054479413\n",
      "============================================================\n",
      "New configuration: [0.005456100838973028, 0.03806602727474829, 0.06473668650165003]\n",
      "s = 0.6530970335006714, b = 44.486663818359375, s/âb = 0.09767972191743385 => -96.99838634052831\n",
      "============================================================\n",
      "New configuration: [0.009208315855973674, 0.03117584884142383, 0.14100844141279276]\n",
      "s = 0.816210150718689, b = 120.11743927001953, s/âb = 0.07438899134747141 => -74.00090470341281\n",
      "============================================================\n",
      "New configuration: [0.048769735890799325, 0.01920587785285719, 0.07750438091760854]\n",
      "s = 0.9849006533622742, b = 175.57907104492188, s/âb = 0.07425829523294057 => -73.72075830395488\n",
      "============================================================\n",
      "New configuration: [0.07625459553429154, 0.009134094777139688, 0.10733152572307324]\n",
      "s = 0.7670877575874329, b = 70.47122955322266, s/âb = 0.09121261258022927 => -90.46286124342691\n",
      "============================================================\n",
      "New configuration: [0.002110536445385079, 0.024266529713117845, 0.07664149213645281]\n",
      "s = 0.380092978477478, b = 11.36803913116455, s/âb = 0.11211238631106761 => -111.42905644069685\n",
      "============================================================\n",
      "New configuration: [0.004395482777697078, 0.15991202345469369, 0.11011184254312444]\n",
      "s = 0.5853045582771301, b = 34.0101432800293, s/âb = 0.10007778978347909 => -99.42317037036175\n",
      "============================================================\n",
      "New configuration: [0.17576346674686893, 0.1510127744809065, 0.0025029305923703823]\n",
      "s = 0.4322075843811035, b = 13.737940788269043, s/âb = 0.11600530932415798 => -115.2828835571073\n",
      "============================================================\n",
      "New configuration: [0.0018769311617526324, 0.07300875416299032, 0.02175943783135928]\n",
      "s = 0.3517400920391083, b = 10.170432090759277, s/âb = 0.10966735333726063 => -109.03220296203325\n",
      "============================================================\n",
      "New configuration: [0.08091140947224973, 0.10722363801832653, 0.03204570214635253]\n",
      "s = 1.1791449785232544, b = 449.4408874511719, s/âb = 0.05559449369065329 => -55.329960584956254\n",
      "============================================================\n",
      "New configuration: [0.005620734266257022, 0.04587824780150825, 0.11103008238703065]\n",
      "s = 0.6628907918930054, b = 46.13762664794922, s/âb = 0.09735976769460544 => -96.67778859787639\n",
      "============================================================\n",
      "New configuration: [0.04265172699024318, 0.008637367674564179, 0.15859119046709966]\n",
      "s = 0.7501725554466248, b = 64.19931030273438, s/âb = 0.09344501742829107 => -92.6568412098459\n",
      "============================================================\n",
      "New configuration: [0.06197672069898694, 0.047751978262757996, 0.06948026632939559]\n",
      "s = 1.1968060731887817, b = 452.716064453125, s/âb = 0.056223106011392875 => -55.90893940494759\n",
      "============================================================\n",
      "New configuration: [0.003499615363892673, 0.08660319361385731, 0.006613540430136012]\n",
      "s = 0.5164626836776733, b = 23.31067657470703, s/âb = 0.10657827808669966 => -105.8876240940133\n",
      "============================================================\n",
      "New configuration: [0.09361054914548064, 0.0020715913455854455, 0.01748459195191024]\n",
      "s = 0.34902793169021606, b = 7.862246036529541, s/âb = 0.12357198346341933 => -122.53694065998063\n",
      "============================================================\n",
      "New configuration: [0.007059943079167196, 0.1493589467287126, 0.04321369995286893]\n",
      "s = 0.734359622001648, b = 77.50211334228516, s/âb = 0.08328512666977492 => -82.80171972598005\n",
      "============================================================\n",
      "New configuration: [0.16858775467139464, 0.029680872950244862, 0.014494486675533946]\n",
      "s = 0.9695546627044678, b = 181.63296508789062, s/âb = 0.0718773940965918 => -71.48075452866402\n",
      "============================================================\n",
      "New configuration: [0.002326391346081028, 0.00312769936056999, 0.12432175719611753]\n",
      "s = 0.3955903947353363, b = 12.177492141723633, s/âb = 0.11275617842754154 => -112.01726117944668\n",
      "============================================================\n",
      "New configuration: [0.01180853879476327, 0.06279879065202429, 0.07911569166956996]\n",
      "s = 0.8912566900253296, b = 151.4339599609375, s/âb = 0.07235384227708463 => -71.96169458128593\n",
      "============================================================\n",
      "New configuration: [0.14284373441075549, 0.0014180057848090352, 0.08364391441667722]\n",
      "s = 0.259859174489975, b = 5.303465366363525, s/âb = 0.11193546272376877 => -111.06209320486523\n",
      "============================================================\n",
      "Best parameters: [0.07922658255517742, 0.0024475680559334755, 0.060603877457657156]\n",
      "Best s/âb = 0.12488956769882517\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Optimal parameters not found: Number of calls to function has reached maxfev = 600.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 107\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[1;32m    106\u001b[0m     warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 107\u001b[0m     clf_dict \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_optimize_cut_boundaries\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mflat_preds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_truths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_categories\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\n\u001b[1;32m    109\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;66;03m# plot_s_over_root_b(\u001b[39;00m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;66;03m#     sigs_and_bkgs['sig'], sigs_and_bkgs['bkg'], f\"{sample_name} vs. {sample_name_ if sample_name_ != sample_name else 'all'}\", \u001b[39;00m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;66;03m#     f\"BDT_{sample_name}_vs_{sample_name_ if sample_name_ != sample_name else 'all'}_sOverRootb_withCuts_testData_sum\", plot_dirpath, \u001b[39;00m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;66;03m#     weights=score_weights,\u001b[39;00m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;66;03m#     lines=lines, lines_labels=line_labels, line_colors=line_colors\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[1;32m    118\u001b[0m flat_mass \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([data_test_aux_dict[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfold_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmass\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m fold_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(data_test_aux_dict))], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "Cell \u001b[0;32mIn[11], line 402\u001b[0m, in \u001b[0;36mmulti_optimize_cut_boundaries\u001b[0;34m(preds, labels, weights, num_categories, min_sig, n_steps)\u001b[0m\n\u001b[1;32m    399\u001b[0m     sliced_labels \u001b[38;5;241m=\u001b[39m labels[slice_array]\n\u001b[1;32m    400\u001b[0m     sliced_weights \u001b[38;5;241m=\u001b[39m weights[slice_array]\n\u001b[0;32m--> 402\u001b[0m     opt_cuts, opt_params \u001b[38;5;241m=\u001b[39m \u001b[43moptimize_cuts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m        \u001b[49m\u001b[43msliced_preds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msliced_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msliced_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_sig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_sig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrng_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_funcs_per_param\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlevy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlevy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlevy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    408\u001b[0m clf_dict[cat] \u001b[38;5;241m=\u001b[39m opt_cuts\n\u001b[1;32m    409\u001b[0m param_clf_dict[cat] \u001b[38;5;241m=\u001b[39m opt_params\n",
      "Cell \u001b[0;32mIn[11], line 231\u001b[0m, in \u001b[0;36moptimize_cuts\u001b[0;34m(preds, labels, weights, param_names, param_range, n_steps, verbose, min_sig, prefactor, rng_seed, fit_funcs_per_param)\u001b[0m\n\u001b[1;32m    226\u001b[0m levy_transform \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m c, mu: (\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m x: (c \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39mpower(gaussian_transfrom(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m x\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m), \u001b[38;5;241m2\u001b[39m)) \u001b[38;5;241m+\u001b[39m mu\n\u001b[1;32m    228\u001b[0m )\n\u001b[1;32m    230\u001b[0m funcs, fit_funcs, transform_funcs \u001b[38;5;241m=\u001b[39m get_fit_funcs_per_param()\n\u001b[0;32m--> 231\u001b[0m sig_to_ttH_popt_func, sig_to_ttH_popt_cov \u001b[38;5;241m=\u001b[39m \u001b[43mfit_funcs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43msig_to_ttH_bin_centers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msig_to_ttH_counts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpower\u001b[49m\u001b[43m(\u001b[49m\u001b[43msig_to_ttH_counts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m sig_to_VH_popt_func, sig_to_VH_popt_cov \u001b[38;5;241m=\u001b[39m fit_funcs[\u001b[38;5;241m1\u001b[39m](sig_to_VH_bin_centers, sig_to_VH_counts, sigma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39mnp\u001b[38;5;241m.\u001b[39mpower(sig_to_VH_counts, \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m    233\u001b[0m sig_to_nonRes_popt_func, sig_to_nonRes_popt_cov \u001b[38;5;241m=\u001b[39m fit_funcs[\u001b[38;5;241m2\u001b[39m](sig_to_nonRes_bin_centers, sig_to_nonRes_counts, sigma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39mnp\u001b[38;5;241m.\u001b[39mpower(sig_to_nonRes_counts, \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m))\n",
      "Cell \u001b[0;32mIn[11], line 215\u001b[0m, in \u001b[0;36moptimize_cuts.<locals>.fit_levy\u001b[0;34m(x, y, sigma)\u001b[0m\n\u001b[1;32m    212\u001b[0m c_init \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.01\u001b[39m  \u001b[38;5;66;03m# success of fit withint 600 tries (kwarg of curve_fit) HIGHLY\u001b[39;00m\n\u001b[1;32m    213\u001b[0m mu_init \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.\u001b[39m   \u001b[38;5;66;03m#  sensitive to these initial choices of parameters. maybe rescale them by 1,000?\u001b[39;00m\n\u001b[0;32m--> 215\u001b[0m opt_params, opt_cov \u001b[38;5;241m=\u001b[39m \u001b[43mcurve_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mp0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mc_init\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmu_init\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[43msigma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msigma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m opt_params, opt_cov\n",
      "File \u001b[0;32m~/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/scipy/optimize/_minpack_py.py:1012\u001b[0m, in \u001b[0;36mcurve_fit\u001b[0;34m(f, xdata, ydata, p0, sigma, absolute_sigma, check_finite, bounds, method, jac, full_output, nan_policy, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m     cost \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(infodict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfvec\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m   1011\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ier \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m]:\n\u001b[0;32m-> 1012\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimal parameters not found: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m errmsg)\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1014\u001b[0m     \u001b[38;5;66;03m# Rename maxfev (leastsq) to max_nfev (least_squares), if specified.\u001b[39;00m\n\u001b[1;32m   1015\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_nfev\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Optimal parameters not found: Number of calls to function has reached maxfev = 600."
     ]
    }
   ],
   "source": [
    "## NEED TO CHECK SERGO'S SUGGESTION: fix one axis (VH?) and try 2D optimization to see if it converges well to performance similar to Yibo's / 1D\n",
    "\n",
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"s_over_rootb_multiOptim\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "if 'BDT_perf' not in globals():\n",
    "    with open(os.path.join(OUTPUT_DIRPATH, CURRENT_TIME+\"_BDT_perf.json\"), 'r') as f:\n",
    "        BDT_perf = json.load(f)\n",
    "\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(projection='3d')\n",
    "# # x_preds, y_preds, z_preds = p_to_xyz(np.concatenate([BDT_perf['ggF HH']['preds'][fold_idx] for fold_idx in range(len(bdt_test_dict))], axis=0))\n",
    "# for i, sample_name in enumerate(order):\n",
    "#     if i == 0:\n",
    "#         downsample = 100\n",
    "#     elif i == 1:\n",
    "#         downsample = 200\n",
    "#     elif i == 2:\n",
    "#         downsample = 400\n",
    "#     elif i == 3:\n",
    "#         downsample = 500\n",
    "\n",
    "#     x_preds, y_preds, z_preds = p_to_xyz(\n",
    "#         np.array(BDT_perf['ggF HH']['preds'][0])[bdt_test_dict[f\"fold_0\"].get_label() == i][::downsample],\n",
    "#         split=True\n",
    "#     )\n",
    "#     ax.scatter(x_preds, y_preds, z_preds, marker='.', label=sample_name)\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# # plot s/âb curves\n",
    "# for fold_idx in range(len(bdt_train_dict)):\n",
    "\n",
    "#     with warnings.catch_warnings():\n",
    "#         warnings.simplefilter(\"ignore\")\n",
    "#         clf_dict = multi_optimize_cut_boundaries(\n",
    "#             BDT_perf['ggF HH']['preds'][fold_idx], \n",
    "#             bdt_test_dict[f\"fold_{fold_idx}\"].get_label() == 0, \n",
    "#             weights_plot_test[f\"fold_{fold_idx}\"],\n",
    "#             min_sig=0.07\n",
    "#         )\n",
    "\n",
    "#     cat_dict = {}\n",
    "#     for cat in range(len(clf_dict)):\n",
    "#         prev_cat_slice = np.ones_like(weights_plot_test[f\"fold_{fold_idx}\"], dtype=bool)\n",
    "#         if cat > 0:\n",
    "#             for prev_cat in range(cat):\n",
    "#                 prev_cat_slice = np.logical_and(\n",
    "#                     prev_cat_slice,\n",
    "#                     np.logical_not(\n",
    "#                         np.all(\n",
    "#                             p_to_xyz(np.array(BDT_perf['ggF HH']['preds'][fold_idx]), split=False) < clf_dict[prev_cat], \n",
    "#                             axis=1\n",
    "#                         )\n",
    "#                     )\n",
    "#                 )\n",
    "#         cat_dict[cat] = np.logical_and(\n",
    "#             prev_cat_slice,\n",
    "#             np.all(\n",
    "#                 p_to_xyz(np.array(BDT_perf['ggF HH']['preds'][fold_idx]), split=False) < clf_dict[cat],\n",
    "#                 axis=1\n",
    "#             )\n",
    "#         )\n",
    "\n",
    "#     masses = data_test_aux_dict[f\"fold_{fold_idx}\"]['mass']\n",
    "#     cat_num_samples = {}\n",
    "#     for cat in range(len(clf_dict)):\n",
    "#         cat_num_samples[cat] = {}\n",
    "#         print('='*60)\n",
    "#         print('='*60)\n",
    "#         print(f\"Fold {fold_idx}: Category {cat} (SVM) AND 120 GeV < m_HH < 130 GeV\")\n",
    "#         print('-'*60)\n",
    "#         for m, sample_name in enumerate(order):\n",
    "#             cat_num_samples[cat][sample_name] = np.sum(\n",
    "#                 weights_plot_test[f\"fold_{fold_idx}\"][\n",
    "#                     np.logical_and(  # event passes conditions and is the right type (i.e. sample)\n",
    "#                         np.logical_and(  # event passes category and mass conditions\n",
    "#                             cat_dict[cat],  # event passes category selections\n",
    "#                             np.logical_and(  # diphoton mass is within 120-130 window\n",
    "#                                 masses < 130,\n",
    "#                                 masses > 120\n",
    "#                             ),\n",
    "#                         ),\n",
    "#                         bdt_test_dict[f\"fold_{fold_idx}\"].get_label() == m\n",
    "#                     )\n",
    "#                 ]\n",
    "#             )\n",
    "#             print(f\"{cat}: Num {sample_name} = {cat_num_samples[cat][sample_name]:.4f}\")\n",
    "#             print('-'*60)\n",
    "#         print(f\"{cat}: S = {cat_num_samples[cat][order[0]]:.4f}, B = {np.sum([cat_num_samples[cat][order[v]] for v in range(1, len(order))]):.4f}, S/âB = {(cat_num_samples[cat][order[0]] / np.sqrt(np.sum([cat_num_samples[cat][order[v]] for v in range(1, len(order))]))):.4f}\")\n",
    "\n",
    "# print('='*60)\n",
    "# print('='*60)\n",
    "# print('='*60)\n",
    "# print('='*60)\n",
    "\n",
    "flat_preds = np.concatenate(BDT_perf['ggF HH']['preds'], axis=0)\n",
    "flat_truths = np.concatenate([bdt_test_dict[f\"fold_{fold_idx}\"].get_label() for fold_idx in range(len(bdt_test_dict))], axis=0)\n",
    "flat_weights = np.concatenate([weights_plot_test[f\"fold_{fold_idx}\"] for fold_idx in range(len(bdt_test_dict))], axis=0)\n",
    "# flat_weights = np.concatenate([weight_test_dict[f\"fold_{fold_idx}\"] for fold_idx in range(len(bdt_test_dict))], axis=0)\n",
    "flat_sample_names = np.concatenate([data_test_aux_dict[f\"fold_{fold_idx}\"]['sample_name'] for fold_idx in range(len(bdt_test_dict))], axis=0)\n",
    "\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    clf_dict = multi_optimize_cut_boundaries(\n",
    "        flat_preds, flat_truths, flat_weights, num_categories=3\n",
    "    )\n",
    "\n",
    "    # plot_s_over_root_b(\n",
    "    #     sigs_and_bkgs['sig'], sigs_and_bkgs['bkg'], f\"{sample_name} vs. {sample_name_ if sample_name_ != sample_name else 'all'}\", \n",
    "    #     f\"BDT_{sample_name}_vs_{sample_name_ if sample_name_ != sample_name else 'all'}_sOverRootb_withCuts_testData_sum\", plot_dirpath, \n",
    "    #     weights=score_weights,\n",
    "    #     lines=lines, lines_labels=line_labels, line_colors=line_colors\n",
    "    # )\n",
    "\n",
    "flat_mass = np.concatenate([data_test_aux_dict[f\"fold_{fold_idx}\"]['mass'] for fold_idx in range(len(data_test_aux_dict))], axis=0)\n",
    "cat_dict = {}\n",
    "for cat in range(len(clf_dict)):\n",
    "    prev_cat_slice = np.ones_like(flat_weights, dtype=bool)\n",
    "    if cat > 0:\n",
    "        for prev_cat in range(cat):\n",
    "            prev_cat_slice = np.logical_and(\n",
    "                prev_cat_slice,\n",
    "                np.logical_not(\n",
    "                    np.all(\n",
    "                        output_to_3d_thresholds(flat_preds, split=False) < clf_dict[prev_cat], \n",
    "                        axis=1\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "    cat_dict[cat] = np.logical_and(\n",
    "        prev_cat_slice,\n",
    "        np.all(\n",
    "            output_to_3d_thresholds(flat_preds, split=False) < clf_dict[cat],\n",
    "            axis=1\n",
    "        )\n",
    "    )\n",
    "\n",
    "cat_num_samples = {}\n",
    "for cat in range(len(clf_dict)):\n",
    "    cat_num_samples[cat] = {}\n",
    "    print('='*60)\n",
    "    print('='*60)\n",
    "    print(f\"Category {cat+1} {f'3D outputs NOT< {clf_dict[cat-1]} AND ' if cat > 0 else ''}3D outputs < {clf_dict[cat]} AND 120 GeV < m_HH < 130 GeV\")\n",
    "    # print(f\"Category {cat}: 3D outputs < {clf_dict[cat]:.4f} AND 120 GeV < m_HH < 130 GeV\")\n",
    "    print('-'*60)\n",
    "    for m, sample_name in enumerate(order):\n",
    "        sample_bool = np.logical_and(  # event passes conditions and is the right type (i.e. sample)\n",
    "            np.logical_and(  # event passes category and mass conditions\n",
    "                cat_dict[cat],  # event passes category selections\n",
    "                np.logical_and(  # diphoton mass is within 120-130 window\n",
    "                    flat_mass < 130,\n",
    "                    flat_mass > 120\n",
    "                ),\n",
    "            ),\n",
    "            flat_truths == m\n",
    "        )\n",
    "        cat_num_samples[cat][sample_name] = np.sum(\n",
    "            flat_weights[sample_bool]\n",
    "        )\n",
    "        print(f\"{cat+1}: Num {sample_name} = {cat_num_samples[cat][sample_name]:.4f}\")\n",
    "        print('-'*60)\n",
    "\n",
    "        if sample_name == order[-1]:\n",
    "            for smpl in [\n",
    "                ['GluGluHToGG', 'GluGlutoHHto2B2G_kl_1p00_kt_1p00_c2_0p00'],\n",
    "                ['VBFHToGG', 'VBFHToGG_M_125'],\n",
    "                ['GGJets'], ['GJetPt20To40'], ['GJetPt40']\n",
    "            ]:\n",
    "                smpl_num = 0\n",
    "                for smpl_ in smpl:\n",
    "                    smpl_num += np.sum(\n",
    "                        flat_weights[\n",
    "                            np.logical_and(\n",
    "                                sample_bool,\n",
    "                                flat_sample_names == smpl_\n",
    "                            )\n",
    "                        ]\n",
    "                    )\n",
    "                print(f\"{cat+1}: Num {smpl[0]} = {smpl_num:.4f}\")\n",
    "                print('-'*60)\n",
    "        elif sample_name == order[-2]:\n",
    "            smpl_num = np.sum(\n",
    "                flat_weights[\n",
    "                    np.logical_and(\n",
    "                        sample_bool,\n",
    "                        np.logical_or(\n",
    "                            flat_sample_names == 'VHToGG',\n",
    "                            flat_sample_names == 'VHtoGG_M_125'\n",
    "                        )\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "            print(f\"{cat+1}: Num VH, no ZH or WH = {smpl_num:.4f}\")\n",
    "            print('-'*60)\n",
    "\n",
    "        \n",
    "    print(f\"{cat+1}: S = {cat_num_samples[cat][order[0]]:.4f}, B = {np.sum([cat_num_samples[cat][order[v]] for v in range(1, len(order))]):.4f}, S/âB = {(cat_num_samples[cat][order[0]] / np.sqrt(np.sum([cat_num_samples[cat][order[v]] for v in range(1, len(order))]))):.4f}\")\n",
    "\n",
    "cat_num_samples = {}\n",
    "for cat in range(len(clf_dict)):\n",
    "    cat_num_samples[cat] = {}\n",
    "    print('='*60)\n",
    "    print('='*60)\n",
    "    print(f\"Category {cat+1} {f'3D outputs NOT< {clf_dict[cat-1]} AND ' if cat > 0 else ''}3D outputs < {clf_dict[cat]}\")\n",
    "    # print(f\"Category {cat}: 3D outputs < {clf_dict[cat]:.4f} AND 120 GeV < m_HH < 130 GeV\")\n",
    "    print('-'*60)\n",
    "    for m, sample_name in enumerate(order):\n",
    "        sample_bool = np.logical_and(  # event passes conditions and is the right type (i.e. sample)\n",
    "            cat_dict[cat],  # event passes category selections\n",
    "            flat_truths == m\n",
    "        )\n",
    "        cat_num_samples[cat][sample_name] = np.sum(\n",
    "            flat_weights[sample_bool]\n",
    "        )\n",
    "        print(f\"{cat+1}: Num {sample_name} = {cat_num_samples[cat][sample_name]:.4f}\")\n",
    "        print('-'*60)\n",
    "\n",
    "        if sample_name == order[-1]:\n",
    "            for smpl in [\n",
    "                ['GluGluHToGG', 'GluGlutoHHto2B2G_kl_1p00_kt_1p00_c2_0p00'],\n",
    "                ['VBFHToGG', 'VBFHToGG_M_125'],\n",
    "                ['GGJets'], ['GJetPt20To40'], ['GJetPt40']\n",
    "            ]:\n",
    "                smpl_num = 0\n",
    "                for smpl_ in smpl:\n",
    "                    smpl_num += np.sum(\n",
    "                        flat_weights[\n",
    "                            np.logical_and(\n",
    "                                sample_bool,\n",
    "                                flat_sample_names == smpl_\n",
    "                            )\n",
    "                        ]\n",
    "                    )\n",
    "                print(f\"{cat+1}: Num {smpl[0]} = {smpl_num:.4f}\")\n",
    "                print('-'*60)\n",
    "        elif sample_name == order[-2]:\n",
    "            smpl_num = np.sum(\n",
    "                flat_weights[\n",
    "                    np.logical_and(\n",
    "                        sample_bool,\n",
    "                        np.logical_or(\n",
    "                            flat_sample_names == 'VHToGG',\n",
    "                            flat_sample_names == 'VHtoGG_M_125'\n",
    "                        )\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "            print(f\"{cat+1}: Num VH, no ZH or WH = {smpl_num:.4f}\")\n",
    "            print('-'*60)\n",
    "    print(f\"{cat+1}: S = {cat_num_samples[cat][order[0]]:.4f}, B = {np.sum([cat_num_samples[cat][order[v]] for v in range(1, len(order))]):.4f}, S/âB = {(cat_num_samples[cat][order[0]] / np.sqrt(np.sum([cat_num_samples[cat][order[v]] for v in range(1, len(order))]))):.4f}\")\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0: FÎ² (Î²=1) score = \n",
      "[3.75208065e-04 7.86065230e-02 2.71057559e-02 9.76089284e-01]\n",
      "fold 1: FÎ² (Î²=1) score = \n",
      "[3.90096819e-04 8.77577784e-02 2.32232785e-02 9.77219709e-01]\n",
      "fold 2: FÎ² (Î²=1) score = \n",
      "[4.04165781e-04 8.94709894e-02 2.59133580e-02 9.77692832e-01]\n",
      "fold 3: FÎ² (Î²=1) score = \n",
      "[3.96219145e-04 9.54856026e-02 2.10419437e-02 9.77305865e-01]\n",
      "fold 4: FÎ² (Î²=1) score = \n",
      "[3.76627497e-04 7.68373785e-02 3.20171702e-02 9.76306194e-01]\n",
      "Sum over folds: FÎ² (Î²=1) score = \n",
      "[3.88135975e-04 8.51683572e-02 2.55549991e-02 9.76921218e-01]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 900x700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 900x700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 900x700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 900x700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 900x700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 900x700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"confusion_matrix\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "if 'BDT_perf' not in globals():\n",
    "    with open(os.path.join(OUTPUT_DIRPATH, CURRENT_TIME+\"_BDT_perf.json\"), 'r') as f:\n",
    "        BDT_perf = json.load(f)\n",
    "\n",
    "beta = 1\n",
    "normalize = 'true'  # 'true' for normalize over rows, None for absoulte yields\n",
    "\n",
    "for fold_idx in range(len(BDT_perf['ggF HH']['preds'])):\n",
    "\n",
    "    pred_classes = np.argmax(BDT_perf['ggF HH']['preds'][fold_idx], axis=1)\n",
    "\n",
    "    conf_matrix = confusion_matrix(\n",
    "        bdt_test_dict[f\"fold_{fold_idx}\"].get_label(), \n",
    "        pred_classes,\n",
    "        sample_weight=weights_plot_test[f\"fold_{fold_idx}\"],\n",
    "        normalize=normalize\n",
    "    )\n",
    "\n",
    "    plot_confusion_matrix(\n",
    "        conf_matrix, order, f\"confusion_matrix_fold{fold_idx}{'_norm_'+normalize if normalize is not None else ''}\", plot_dirpath\n",
    "    )\n",
    "\n",
    "    f1_scores = fbeta_score(\n",
    "        bdt_test_dict[f\"fold_{fold_idx}\"].get_label(), \n",
    "        pred_classes,\n",
    "        beta=beta,\n",
    "        sample_weight=weights_plot_test[f\"fold_{fold_idx}\"], average=None\n",
    "    )\n",
    "    print(f\"fold {fold_idx}: FÎ² (Î²={beta}) score = \\n{f1_scores}\")\n",
    "\n",
    "full_pred_classes = np.argmax(\n",
    "    np.concatenate(\n",
    "        [\n",
    "            BDT_perf['ggF HH']['preds'][fold_idx] for fold_idx in range(len(BDT_perf['ggF HH']['preds']))\n",
    "        ]\n",
    "    ), axis=1\n",
    ")\n",
    "full_labels = np.concatenate(\n",
    "    [\n",
    "        bdt_test_dict[f\"fold_{fold_idx}\"].get_label() for fold_idx in range(len(BDT_perf['ggF HH']['preds']))\n",
    "    ]\n",
    ")\n",
    "full_weights = np.concatenate(\n",
    "    [\n",
    "        weights_plot_test[f\"fold_{fold_idx}\"] for fold_idx in range(len(BDT_perf['ggF HH']['preds']))\n",
    "    ]\n",
    ")\n",
    "\n",
    "conf_matrix = confusion_matrix(\n",
    "    full_labels, \n",
    "    full_pred_classes,\n",
    "    sample_weight=full_weights,\n",
    "    normalize=normalize\n",
    ")\n",
    "\n",
    "plot_confusion_matrix(\n",
    "    conf_matrix, order, f\"confusion_matrix_sum{'_norm_'+normalize if normalize is not None else ''}\", plot_dirpath\n",
    ")\n",
    "\n",
    "f1_scores = fbeta_score(\n",
    "    full_labels, \n",
    "    full_pred_classes,\n",
    "    beta=beta,\n",
    "    sample_weight=full_weights, average=None\n",
    ")\n",
    "print(f\"Sum over folds: FÎ² (Î²={beta}) score = \\n{f1_scores}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:39:57] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:39:59] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:40:01] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:40:02] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:40:04] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"variable_importance\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "score_arr = ['weight', 'gain', 'cover']\n",
    "\n",
    "full_score_dict = {}\n",
    "for fold_idx in range(len(bdt_train_dict)):\n",
    "    booster = xgb.Booster(param, model_file=os.path.join(OUTPUT_DIRPATH, f'{CURRENT_TIME}_BDT_fold{fold_idx}.model'))\n",
    "\n",
    "    labels = copy.deepcopy([key for key in hlf_vars_columns_dict[f'fold_{fold_idx}'].keys()])\n",
    "    labels.sort()\n",
    "    \n",
    "    booster.feature_names = labels\n",
    "    # score_dict = booster.get_score(importance_type='total_gain')\n",
    "    score_dict = booster.get_score()\n",
    "    if fold_idx == 0:\n",
    "        full_score_dict = copy.deepcopy(score_dict)\n",
    "    else:\n",
    "        for key in full_score_dict.keys():\n",
    "            full_score_dict[key] += score_dict[key]\n",
    "\n",
    "    sorted_scores, sorted_labels = [], []\n",
    "    for label, score in score_dict.items():\n",
    "        sorted_scores.append(score)\n",
    "        sorted_labels.append(label)\n",
    "\n",
    "    sorted_labels = np.array(sorted_labels)[np.argsort(sorted_scores)]\n",
    "    sorted_scores = np.sort(sorted_scores)\n",
    "\n",
    "    plot_feature_importance(\n",
    "        sorted_scores, sorted_labels, f'xgb_importance_fold{fold_idx}', plot_dirpath\n",
    "    )\n",
    "\n",
    "full_sorted_scores, full_sorted_labels = [], []\n",
    "for label, score in full_score_dict.items():\n",
    "    full_sorted_scores.append(score / len(bdt_train_dict))\n",
    "    full_sorted_labels.append(label)\n",
    "\n",
    "full_sorted_labels = np.array(full_sorted_labels)[np.argsort(full_sorted_scores)]\n",
    "full_sorted_scores = np.sort(full_sorted_scores)\n",
    "\n",
    "plot_feature_importance(\n",
    "    full_sorted_scores, full_sorted_labels, f'xgb_importance_sum', plot_dirpath\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Variable Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "averaged correlation\n",
      "------------------------------------------------------------\n",
      "HHbbggCandidate_mass: 1.0000\n",
      "pt_balance: -0.1798\n",
      "HHbbggCandidate_pt: 0.1444\n",
      "sublead_bjet_btagPNetB: 0.1235\n",
      "lead_sigmaE_over_E: -0.1131\n",
      "sublead_sigmaE_over_E: -0.0842\n",
      "lead_bjet_btagPNetB: 0.0810\n",
      "puppiMET_pt: 0.0751\n",
      "n_jets: 0.0549\n",
      "sublead_mvaID: 0.0353\n",
      "lead_mvaID: 0.0333\n",
      "chi_t0: 0.0265\n",
      "chi_t1: 0.0187\n",
      "lead_bjet_eta: 0.0046\n",
      "CosThetaStar_jj: 0.0046\n",
      "leadBjet_leadLepton: -0.0037\n",
      "lepton1_mvaID: -0.0037\n",
      "lepton1_pfIsoId: -0.0037\n",
      "lepton1_pt: -0.0036\n",
      "eta: 0.0030\n",
      "CosThetaStar_gg: 0.0030\n",
      "HHbbggCandidate_eta: 0.0024\n",
      "CosThetaStar_CS: -0.0018\n",
      "DeltaPhi_j1MET: -0.0016\n",
      "DeltaPhi_j2MET: 0.0015\n",
      "DeltaPhi_isr_jet_z: 0.0012\n",
      "DeltaPhi_jj: -0.0008\n",
      "sublead_bjet_eta: 0.0001\n"
     ]
    }
   ],
   "source": [
    "data_corr_dict = {}\n",
    "for fold_idx in range(len(data_aux_dict)):\n",
    "    merged_pd = copy.deepcopy(data_df_dict[f\"fold_{fold_idx}\"])\n",
    "    # for i, var_name in enumerate(['mass']):\n",
    "    for i, var_name in enumerate(['HHbbggCandidate_mass']):\n",
    "        merged_pd.insert(i, var_name, data_aux_dict[f\"fold_{fold_idx}\"].loc[:, var_name])\n",
    "    signal_merged_pd = merged_pd.loc[data_aux_dict[f\"fold_{fold_idx}\"].loc[:, 'sample_name'] == 'GluGluToHH']\n",
    "    data_corr_dict[f\"fold_{fold_idx}\"] = signal_merged_pd.corr()\n",
    "\n",
    "    # print(f\"fold {fold_idx}\")\n",
    "    # print('-'*60)\n",
    "    # print(data_corr_dict[f\"fold_{fold_idx}\"].iloc[0, :])\n",
    "    # print(f\"{'='*60}\\n{'='*60}\\n{'='*60}\\n\")\n",
    "\n",
    "print('averaged correlation')\n",
    "print('-'*60)\n",
    "corr_cols = data_corr_dict[f\"fold_0\"].columns\n",
    "avg_cols = data_corr_dict[f\"fold_0\"].iloc[0, :].to_numpy(copy=True)\n",
    "for fold_idx in range(1, len(data_corr_dict)):\n",
    "    avg_cols += data_corr_dict[f\"fold_{fold_idx}\"].iloc[0, :].to_numpy(copy=True)\n",
    "avg_cols /= len(data_corr_dict)\n",
    "avg_cols /= avg_cols[0]\n",
    "\n",
    "sorted_avg_corr = np.argsort(np.abs(avg_cols))[::-1]\n",
    "for i in sorted_avg_corr:\n",
    "    print(f\"{corr_cols[i]}: {avg_cols[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mass Sculpting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"mass_sculpting\")\n",
    "# plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"PNetBtag_sculpting\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "if 'BDT_perf' not in globals():\n",
    "    with open(os.path.join(OUTPUT_DIRPATH, CURRENT_TIME+f\"_BDT_perf.json\"), 'r') as f:\n",
    "        BDT_perf = json.load(f)\n",
    "\n",
    "score_cuts = [0.0, 0.7, 0.99, 0.9955]\n",
    "label_arr = [f'score above {score_cut}' for score_cut in score_cuts]\n",
    "plot_vars = ['mass', 'dijet_mass', 'HHbbggCandidate_mass']\n",
    "# plot_vars = ['lead_bjet_btagPNetB', 'sublead_bjet_btagPNetB']\n",
    "\n",
    "\n",
    "# for bool_arr in [nonres_bool]:\n",
    "for idx, sample_name_bool in enumerate([\"GluGluToHH\", \"GluGlutoHHto2B2G_kl_0p00_kt_1p00_c2_0p00\", \"GluGlutoHHto2B2G_kl_5p00_kt_1p00_c2_0p00\"]):\n",
    "\n",
    "    # nonres_bool = (data_test_aux_dict[f\"fold_{fold_idx}\"].loc[:, 'sample_name'] == \"GGJets\") | (data_test_aux_dict[f\"fold_{fold_idx}\"].loc[:, 'sample_name'] == \"GJetPt20To40\") | (data_test_aux_dict[f\"fold_{fold_idx}\"].loc[:, 'sample_name'] == \"GJetPt40\")\n",
    "\n",
    "    # Loop over and plot the per-fold variables\n",
    "    for fold_idx in range(len(hlf_vars_columns_dict)):\n",
    "\n",
    "        bool_arr = (data_test_aux_dict[f\"fold_{fold_idx}\"].loc[:, 'sample_name'] == sample_name_bool)\n",
    "\n",
    "        pass_cut_bools = [\n",
    "            np.array(BDT_perf['ggF HH']['preds'][fold_idx])[:, 0] > score_cut for score_cut in score_cuts\n",
    "        ]\n",
    "\n",
    "        masks = [\n",
    "            np.logical_and(bool_arr, pass_cut_bool) for pass_cut_bool in pass_cut_bools\n",
    "        ]\n",
    "        \n",
    "        for var_idx, var_name in enumerate(plot_vars):\n",
    "\n",
    "            plot_dirpath_ = os.path.join(plot_dirpath, var_name)\n",
    "            if not os.path.exists(plot_dirpath_):\n",
    "                os.makedirs(plot_dirpath_)\n",
    "\n",
    "            sculpting_hists = [\n",
    "                hist.Hist(VARIABLES[var_name]).fill(\n",
    "                    var=data_test_aux_dict[f\"fold_{fold_idx}\"].loc[mask, var_name]\n",
    "                    # var=data_test_df_dict[f\"fold_{fold_idx}\"].loc[mask, var_name]\n",
    "                ) for mask in masks\n",
    "            ]\n",
    "        \n",
    "            make_input_plot(\n",
    "                plot_dirpath_, var_name,\n",
    "                sculpting_hists, \n",
    "                fold_idx=fold_idx, labels=label_arr, \n",
    "                plot_prefix=f'test_signal{idx}_scoreCut_', num_compare=1\n",
    "            )\n",
    "\n",
    "    # flattened sculpting check\n",
    "    # flat_bool = np.concatenate([\n",
    "    #     (data_test_aux_dict[f\"fold_{fold_idx}\"].loc[:, 'sample_name'].to_numpy(copy=True) == \"GGJets\") \n",
    "    #     | (data_test_aux_dict[f\"fold_{fold_idx}\"].loc[:, 'sample_name'].to_numpy(copy=True) == \"GJetPt20To40\") \n",
    "    #     | (data_test_aux_dict[f\"fold_{fold_idx}\"].loc[:, 'sample_name'].to_numpy(copy=True) == \"GJetPt40\")\n",
    "    #     for fold_idx in range(len(data_test_aux_dict))\n",
    "    # ])\n",
    "    flat_bool = np.concatenate([\n",
    "        data_test_aux_dict[f\"fold_{fold_idx}\"].loc[:, 'sample_name'] == sample_name_bool\n",
    "        for fold_idx in range(len(data_test_aux_dict))\n",
    "    ])\n",
    "    \n",
    "    flat_pass_cut_bools = [\n",
    "        np.concatenate(BDT_perf['ggF HH']['preds'], axis=0)[:, 0] > score_cut for score_cut in score_cuts\n",
    "    ]\n",
    "    flat_masks = [\n",
    "        np.logical_and(flat_bool, flat_pass_cut_bool) for flat_pass_cut_bool in flat_pass_cut_bools\n",
    "    ]\n",
    "\n",
    "    for var_idx, var_name in enumerate(plot_vars):\n",
    "        flat_var = np.concatenate([\n",
    "            data_test_aux_dict[f\"fold_{fold_idx}\"].loc[:, var_name].to_numpy(copy=True) for fold_idx in range(len(data_test_aux_dict))\n",
    "            # data_test_df_dict[f\"fold_{fold_idx}\"].loc[:, var_name].to_numpy(copy=True) for fold_idx in range(len(data_test_df_dict))\n",
    "        ])\n",
    "\n",
    "        plot_dirpath_ = os.path.join(plot_dirpath, var_name)\n",
    "        if not os.path.exists(plot_dirpath_):\n",
    "            os.makedirs(plot_dirpath_)\n",
    "\n",
    "        flat_sculpting_hists = [\n",
    "            hist.Hist(VARIABLES[var_name]).fill(var=flat_var[mask]) for mask in flat_masks\n",
    "        ]\n",
    "\n",
    "        make_input_plot(\n",
    "            plot_dirpath_, var_name,\n",
    "            flat_sculpting_hists, \n",
    "            fold_idx=None, labels=label_arr, \n",
    "            plot_prefix=f'test_signal{idx}_scoreCut_', num_compare=1\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling for Mass Sculpting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def resample_from_var(\n",
    "    sample_var, sample_weight, n_events, \n",
    "    min_value=None,\n",
    "    n_samples_per_event=1, bins=100, seed=None\n",
    "):\n",
    "    resample_rng = np.random.default_rng(seed=seed)\n",
    "\n",
    "    np_hist, bin_edges = np.histogram(sample_var, bins=bins, weights=sample_weight, density=True)\n",
    "    np_hist /= np.sum(np_hist)\n",
    "\n",
    "    bin_choices = resample_rng.choice(np.arange(len(np_hist)), size=n_events*n_samples_per_event, p=np_hist)\n",
    "\n",
    "    value_choices = (bin_edges[bin_choices+1] - bin_edges[bin_choices]) * resample_rng.random(size=n_events*n_samples_per_event) + bin_edges[bin_choices]\n",
    "\n",
    "    if min_value is None or np.all(value_choices > min_value):\n",
    "        return value_choices\n",
    "    else:  # this is not really correct, just an approximation to make the code work faster\n",
    "        bad_choices_bool = value_choices <= min_value\n",
    "\n",
    "        largest_min_value = np.max(min_value[bad_choices_bool])\n",
    "\n",
    "        np_hist, bin_edges = np.histogram(sample_var[sample_var > largest_min_value], bins=bins, weights=sample_weight[sample_var > largest_min_value], density=True)\n",
    "        np_hist /= np.sum(np_hist)\n",
    "\n",
    "        bin_choices = resample_rng.choice(np.arange(len(np_hist)), size=np.sum(bad_choices_bool), p=np_hist)\n",
    "        \n",
    "        value_choices[bad_choices_bool] = (bin_edges[bin_choices+1] - bin_edges[bin_choices]) * resample_rng.random(size=np.sum(bad_choices_bool)) + bin_edges[bin_choices]\n",
    "        \n",
    "        return value_choices\n",
    "\n",
    "def resample_grow_np(var, bool_arr, n_duplicates_per_event):\n",
    "    new_rows_shape = tuple([n_duplicates_per_event]+[1 for _ in range(1, len(np.shape(var)))])\n",
    "    new_rows = np.tile(\n",
    "        var[bool_arr],\n",
    "        new_rows_shape\n",
    "    )\n",
    "    return np.concatenate([var, new_rows])\n",
    "def resample_grow_pd(var, bool_arr, n_duplicates_per_event):\n",
    "    new_rows = pd.DataFrame(\n",
    "        np.tile(\n",
    "            ( var.loc[bool_arr] ).to_numpy(),\n",
    "            (n_duplicates_per_event, 1)\n",
    "        ),\n",
    "        columns=var.columns\n",
    "    )\n",
    "    return pd.concat([var, new_rows], ignore_index=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1794697/241474733.py:46: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  return pd.concat([var, new_rows], ignore_index=True)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/numpy/lib/histograms.py:906: RuntimeWarning: invalid value encountered in divide\n",
      "  return n/db/n.sum(), bin_edges\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "probabilities contain NaN",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 47\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m particle_type \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlead\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msublead\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m     40\u001b[0m     gg_mvaID \u001b[38;5;241m=\u001b[39m data_hlf_test[\n\u001b[1;32m     41\u001b[0m         gg_bool, \n\u001b[1;32m     42\u001b[0m         hlf_vars_columns_dict[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfold_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparticle_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_mvaID\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     43\u001b[0m     ]\n\u001b[1;32m     44\u001b[0m     data_hlf_test[\n\u001b[1;32m     45\u001b[0m         gj_bool, \n\u001b[1;32m     46\u001b[0m         hlf_vars_columns_dict[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfold_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparticle_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_mvaID\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 47\u001b[0m     ] \u001b[38;5;241m=\u001b[39m \u001b[43mresample_from_var\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgg_mvaID\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweights_plot\u001b[49m\u001b[43m[\u001b[49m\u001b[43mgg_bool\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgj_bool\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbins\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m190\u001b[39;49m\n\u001b[1;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m     tth_pNetB \u001b[38;5;241m=\u001b[39m data_hlf_test[\n\u001b[1;32m     55\u001b[0m         tth_bool, \n\u001b[1;32m     56\u001b[0m         hlf_vars_columns_dict[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfold_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparticle_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_bjet_btagPNetB\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     57\u001b[0m     ]\n\u001b[1;32m     58\u001b[0m     data_hlf_test[\n\u001b[1;32m     59\u001b[0m         nonres_bool, \n\u001b[1;32m     60\u001b[0m         hlf_vars_columns_dict[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfold_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparticle_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_bjet_btagPNetB\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m         min_value\u001b[38;5;241m=\u001b[39mdata_test_aux\u001b[38;5;241m.\u001b[39mloc[nonres_bool, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_nonbjet_btag\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto_numpy()\n\u001b[1;32m     67\u001b[0m     )\n",
      "Cell \u001b[0;32mIn[12], line 11\u001b[0m, in \u001b[0;36mresample_from_var\u001b[0;34m(sample_var, sample_weight, n_events, min_value, n_samples_per_event, bins, seed)\u001b[0m\n\u001b[1;32m      8\u001b[0m np_hist, bin_edges \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhistogram(sample_var, bins\u001b[38;5;241m=\u001b[39mbins, weights\u001b[38;5;241m=\u001b[39msample_weight, density\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      9\u001b[0m np_hist \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(np_hist)\n\u001b[0;32m---> 11\u001b[0m bin_choices \u001b[38;5;241m=\u001b[39m \u001b[43mresample_rng\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnp_hist\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_events\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mn_samples_per_event\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp_hist\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m value_choices \u001b[38;5;241m=\u001b[39m (bin_edges[bin_choices\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m bin_edges[bin_choices]) \u001b[38;5;241m*\u001b[39m resample_rng\u001b[38;5;241m.\u001b[39mrandom(size\u001b[38;5;241m=\u001b[39mn_events\u001b[38;5;241m*\u001b[39mn_samples_per_event) \u001b[38;5;241m+\u001b[39m bin_edges[bin_choices]\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m min_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(value_choices \u001b[38;5;241m>\u001b[39m min_value):\n",
      "File \u001b[0;32m_generator.pyx:743\u001b[0m, in \u001b[0;36mnumpy.random._generator.Generator.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: probabilities contain NaN"
     ]
    }
   ],
   "source": [
    "resample_ = 10\n",
    "RESAMPLE = (resample_) * 10  # Set to False for no resampling, otherwise sets the number of times to duplicate gjet data for resampling\n",
    "\n",
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"mass_sculpting_resample_single\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "score_cuts = [0.0, 0.7, 0.99, 0.9955]\n",
    "label_arr = [f'score above {score_cut}' for score_cut in score_cuts]\n",
    "plot_vars = ['mass', 'dijet_mass', 'HHbbggCandidate_mass']\n",
    "\n",
    "BDT_perf_resample = [\n",
    "    {\n",
    "        f'preds{score_cut}': copy.deepcopy({plot_var: list() for plot_var in plot_vars+['event']}) for score_cut in score_cuts\n",
    "    } for fold_idx in range(len(bdt_train_dict))\n",
    "]\n",
    "\n",
    "for fold_idx in range(len(bdt_train_dict)):\n",
    "    booster = xgb.Booster(param)\n",
    "    booster.load_model(os.path.join(OUTPUT_DIRPATH, f'{CURRENT_TIME}_BDT_fold{fold_idx}.model'))\n",
    "\n",
    "    nonres_bool = (data_test_aux_dict[f\"fold_{fold_idx}\"].loc[:, 'sample_name'] == \"GGJets\") | (data_test_aux_dict[f\"fold_{fold_idx}\"].loc[:, 'sample_name'] == \"GJetPt20To40\") | (data_test_aux_dict[f\"fold_{fold_idx}\"].loc[:, 'sample_name'] == \"GJetPt40\")\n",
    "\n",
    "    data_hlf_test = resample_grow_np(data_hlf_test_dict[f\"fold_{fold_idx}\"], nonres_bool, resample_)\n",
    "    data_test_aux = resample_grow_pd(data_test_aux_dict[f\"fold_{fold_idx}\"], nonres_bool, resample_)\n",
    "    weight_test = resample_grow_np(weight_test_dict[f\"fold_{fold_idx}\"], nonres_bool, resample_)\n",
    "    weights_plot = resample_grow_np(weights_plot_test[f\"fold_{fold_idx}\"], nonres_bool, resample_)\n",
    "    xgb_label_test = resample_grow_np(xgb_label_test_dict[f\"fold_{fold_idx}\"], nonres_bool, resample_)\n",
    "\n",
    "    gg_bool = (data_test_aux.loc[:, 'sample_name'] == \"GGJets\")\n",
    "    tth_bool = (data_test_aux.loc[:, 'sample_name'] == \"ttHToGG\")\n",
    "    gj_bool = (data_test_aux.loc[:, 'sample_name'] == \"GJetPt20To40\") | (data_test_aux.loc[:, 'sample_name'] == \"GJetPt40\")\n",
    "    nonres_bool = (data_test_aux.loc[:, 'sample_name'] == \"GGJets\") | (data_test_aux.loc[:, 'sample_name'] == \"GJetPt20To40\") | (data_test_aux.loc[:, 'sample_name'] == \"GJetPt40\")\n",
    "\n",
    "\n",
    "    for _ in range(RESAMPLE // resample_):\n",
    "\n",
    "        for particle_type in ['lead', 'sublead']:\n",
    "\n",
    "            gg_mvaID = data_hlf_test[\n",
    "                gg_bool, \n",
    "                hlf_vars_columns_dict[f\"fold_{fold_idx}\"][f\"{particle_type}_mvaID\"]\n",
    "            ]\n",
    "            data_hlf_test[\n",
    "                gj_bool, \n",
    "                hlf_vars_columns_dict[f\"fold_{fold_idx}\"][f\"{particle_type}_mvaID\"]\n",
    "            ] = resample_from_var(\n",
    "                gg_mvaID, \n",
    "                weights_plot[gg_bool],\n",
    "                np.sum(gj_bool),\n",
    "                bins=190\n",
    "            )\n",
    "\n",
    "            tth_pNetB = data_hlf_test[\n",
    "                tth_bool, \n",
    "                hlf_vars_columns_dict[f\"fold_{fold_idx}\"][f\"{particle_type}_bjet_btagPNetB\"]\n",
    "            ]\n",
    "            data_hlf_test[\n",
    "                nonres_bool, \n",
    "                hlf_vars_columns_dict[f\"fold_{fold_idx}\"][f\"{particle_type}_bjet_btagPNetB\"]\n",
    "            ] = resample_from_var(\n",
    "                tth_pNetB, \n",
    "                np.abs(weights_plot[tth_bool]),\n",
    "                np.sum(nonres_bool),\n",
    "                bins=100,\n",
    "                min_value=data_test_aux.loc[nonres_bool, \"max_nonbjet_btag\"].to_numpy()\n",
    "            )\n",
    "\n",
    "        nonres_ggf_preds = booster.predict(\n",
    "            xgb.DMatrix(\n",
    "                data=data_hlf_test[nonres_bool], label=xgb_label_test[nonres_bool], \n",
    "                weight=np.abs(weight_test)[nonres_bool],\n",
    "                missing=-999.0, feature_names=list(hlf_vars_columns_dict[f\"fold_{fold_idx}\"])\n",
    "            ), \n",
    "            iteration_range=(0, booster.best_iteration+1)\n",
    "        )[:, 0]\n",
    "        \n",
    "        for score_cut in score_cuts:\n",
    "            if (\n",
    "                len(BDT_perf_resample[fold_idx][f'preds{score_cut}'][plot_vars[0]]) > 0 \n",
    "                and len(np.concatenate(BDT_perf_resample[fold_idx][f'preds{score_cut}'][plot_vars[0]])) >= 1000\n",
    "            ):\n",
    "                continue\n",
    "\n",
    "            new_unique_eventNumber = np.setdiff1d(\n",
    "                data_test_aux.loc[nonres_bool, \"event\"].to_numpy()[nonres_ggf_preds > score_cut],\n",
    "                BDT_perf_resample[fold_idx][f'preds{score_cut}'][\"event\"]\n",
    "            )\n",
    "            \n",
    "            if len(new_unique_eventNumber) > 0:\n",
    "                BDT_perf_resample[fold_idx][f'preds{score_cut}'][\"event\"].extend(new_unique_eventNumber.tolist())\n",
    "\n",
    "                intersect, comm1, comm2 = np.intersect1d(\n",
    "                    data_test_aux.loc[nonres_bool, \"event\"].to_numpy()[nonres_ggf_preds > score_cut],\n",
    "                    new_unique_eventNumber,\n",
    "                    return_indices=True\n",
    "                )\n",
    "\n",
    "                intersect_bool = np.zeros_like(\n",
    "                    data_test_aux.loc[nonres_bool, \"event\"].to_numpy()[nonres_ggf_preds > score_cut], \n",
    "                    dtype=bool\n",
    "                )\n",
    "                for index in comm1:\n",
    "                    intersect_bool[index] = True\n",
    "                \n",
    "                for var_idx, plot_var in enumerate(plot_vars):\n",
    "                    BDT_perf_resample[fold_idx][f'preds{score_cut}'][plot_var].append(\n",
    "                        data_test_aux.loc[nonres_bool, plot_var].to_numpy()[nonres_ggf_preds > score_cut][intersect_bool]\n",
    "                    )\n",
    "                \n",
    "    for var_idx, plot_var in enumerate(plot_vars):\n",
    "\n",
    "        plot_dirpath_ = os.path.join(plot_dirpath, plot_var)\n",
    "        if not os.path.exists(plot_dirpath_):\n",
    "            os.makedirs(plot_dirpath_)\n",
    "        \n",
    "        test_hists = [hist.Hist(VARIABLES[plot_var]).fill(var=np.concatenate(BDT_perf_resample[fold_idx][f'preds{score_cut}'][plot_var])) for score_cut in score_cuts]\n",
    "        make_input_plot(\n",
    "            plot_dirpath_, plot_var,\n",
    "            test_hists, \n",
    "            fold_idx=fold_idx, labels=label_arr, \n",
    "            plot_prefix='test_non-res_scoreCut_'\n",
    "        )\n",
    "\n",
    "for var_idx, plot_var in enumerate(plot_vars):\n",
    "\n",
    "    plot_dirpath_ = os.path.join(plot_dirpath, plot_var)\n",
    "    if not os.path.exists(plot_dirpath_):\n",
    "        os.makedirs(plot_dirpath_)\n",
    "\n",
    "    test_hists = [hist.Hist(VARIABLES[plot_var]).fill(\n",
    "        var=np.concatenate(\n",
    "            [np.concatenate(BDT_perf_resample[fold_idx][f'preds{score_cut}'][plot_var]) for fold_idx in range(len(BDT_perf_resample))]\n",
    "        )\n",
    "    ) for score_cut in score_cuts]\n",
    "    make_input_plot(\n",
    "        plot_dirpath_, plot_var,\n",
    "        test_hists, \n",
    "        fold_idx=None, labels=label_arr, \n",
    "        plot_prefix='test_non-res_scoreCut_'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'for' statement on line 26 (2427805608.py, line 28)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[22], line 28\u001b[0;36m\u001b[0m\n\u001b[0;31m    data_hlf_test = resample_grow_np(data_hlf_test_dict[f\"fold_{fold_idx}\"], nonres_bool, resample_)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'for' statement on line 26\n"
     ]
    }
   ],
   "source": [
    "resample_ = 10\n",
    "RESAMPLE = (resample_) * 10  # Set to False for no resampling, otherwise sets the number of times to duplicate gjet data for resampling\n",
    "\n",
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"kl_mass_sculpting_resample_single\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "score_cuts = [0.0, 0.7, 0.99, 0.9955]\n",
    "label_arr = [f'score above {score_cut}' for score_cut in score_cuts]\n",
    "plot_vars = ['mass', 'dijet_mass', 'HHbbggCandidate_mass']\n",
    "\n",
    "BDT_perf_resample = [\n",
    "    {\n",
    "        f'preds{score_cut}': copy.deepcopy({plot_var: list() for plot_var in plot_vars+['event']}) for score_cut in score_cuts\n",
    "    } for fold_idx in range(len(bdt_train_dict))\n",
    "]\n",
    "\n",
    "for fold_idx in range(len(bdt_train_dict)):\n",
    "    booster = xgb.Booster(param)\n",
    "    booster.load_model(os.path.join(OUTPUT_DIRPATH, f'{CURRENT_TIME}_BDT_fold{fold_idx}.model'))\n",
    "\n",
    "    # SM_bool = (data_test_aux_dict[f\"fold_{fold_idx}\"].loc[:, 'sample_name'] == \"GluGluToHH\")\n",
    "    # kl0_bool = (data_test_aux_dict[f\"fold_{fold_idx}\"].loc[:, 'sample_name'] == \"GluGlutoHHto2B2G_kl_0p00_kt_1p00_c2_0p00\")\n",
    "    # kl5_bool = (data_test_aux_dict[f\"fold_{fold_idx}\"].loc[:, 'sample_name'] == \"GluGlutoHHto2B2G_kl_5p00_kt_1p00_c2_0p00\")\n",
    "\n",
    "    # for bool_arr in [SM_bool, kl0_bool, kl5_bool]:\n",
    "\n",
    "    data_hlf_test = resample_grow_np(data_hlf_test_dict[f\"fold_{fold_idx}\"], nonres_bool, resample_)\n",
    "    data_test_aux = resample_grow_pd(data_test_aux_dict[f\"fold_{fold_idx}\"], nonres_bool, resample_)\n",
    "    weight_test = resample_grow_np(weight_test_dict[f\"fold_{fold_idx}\"], nonres_bool, resample_)\n",
    "    weights_plot = resample_grow_np(weights_plot_test[f\"fold_{fold_idx}\"], nonres_bool, resample_)\n",
    "    xgb_label_test = resample_grow_np(xgb_label_test_dict[f\"fold_{fold_idx}\"], nonres_bool, resample_)\n",
    "\n",
    "    gg_bool = (data_test_aux.loc[:, 'sample_name'] == \"GGJets\")\n",
    "    tth_bool = (data_test_aux.loc[:, 'sample_name'] == \"ttHToGG\")\n",
    "    gj_bool = (data_test_aux.loc[:, 'sample_name'] == \"GJetPt20To40\") | (data_test_aux.loc[:, 'sample_name'] == \"GJetPt40\")\n",
    "    nonres_bool = (data_test_aux.loc[:, 'sample_name'] == \"GGJets\") | (data_test_aux.loc[:, 'sample_name'] == \"GJetPt20To40\") | (data_test_aux.loc[:, 'sample_name'] == \"GJetPt40\")\n",
    "\n",
    "\n",
    "    for _ in range(RESAMPLE // resample_):\n",
    "\n",
    "        for particle_type in ['lead', 'sublead']:\n",
    "\n",
    "            gg_mvaID = data_hlf_test[\n",
    "                gg_bool, \n",
    "                hlf_vars_columns_dict[f\"fold_{fold_idx}\"][f\"{particle_type}_mvaID\"]\n",
    "            ]\n",
    "            data_hlf_test[\n",
    "                gj_bool, \n",
    "                hlf_vars_columns_dict[f\"fold_{fold_idx}\"][f\"{particle_type}_mvaID\"]\n",
    "            ] = resample_from_var(\n",
    "                gg_mvaID, \n",
    "                weights_plot[gg_bool],\n",
    "                np.sum(gj_bool),\n",
    "                bins=190\n",
    "            )\n",
    "\n",
    "            tth_pNetB = data_hlf_test[\n",
    "                tth_bool, \n",
    "                hlf_vars_columns_dict[f\"fold_{fold_idx}\"][f\"{particle_type}_bjet_btagPNetB\"]\n",
    "            ]\n",
    "            data_hlf_test[\n",
    "                nonres_bool, \n",
    "                hlf_vars_columns_dict[f\"fold_{fold_idx}\"][f\"{particle_type}_bjet_btagPNetB\"]\n",
    "            ] = resample_from_var(\n",
    "                tth_pNetB, \n",
    "                np.abs(weights_plot[tth_bool]),\n",
    "                np.sum(nonres_bool),\n",
    "                bins=100,\n",
    "                min_value=data_test_aux.loc[nonres_bool, \"max_nonbjet_btag\"].to_numpy()\n",
    "            )\n",
    "\n",
    "        nonres_ggf_preds = booster.predict(\n",
    "            xgb.DMatrix(\n",
    "                data=data_hlf_test[nonres_bool], label=xgb_label_test[nonres_bool], \n",
    "                weight=np.abs(weight_test)[nonres_bool],\n",
    "                missing=-999.0, feature_names=list(hlf_vars_columns_dict[f\"fold_{fold_idx}\"])\n",
    "            ), \n",
    "            iteration_range=(0, booster.best_iteration+1)\n",
    "        )[:, 0]\n",
    "        \n",
    "        for score_cut in score_cuts:\n",
    "            if (\n",
    "                len(BDT_perf_resample[fold_idx][f'preds{score_cut}'][plot_vars[0]]) > 0 \n",
    "                and len(np.concatenate(BDT_perf_resample[fold_idx][f'preds{score_cut}'][plot_vars[0]])) >= 1000\n",
    "            ):\n",
    "                continue\n",
    "\n",
    "            new_unique_eventNumber = np.setdiff1d(\n",
    "                data_test_aux.loc[nonres_bool, \"event\"].to_numpy()[nonres_ggf_preds > score_cut],\n",
    "                BDT_perf_resample[fold_idx][f'preds{score_cut}'][\"event\"]\n",
    "            )\n",
    "            \n",
    "            if len(new_unique_eventNumber) > 0:\n",
    "                BDT_perf_resample[fold_idx][f'preds{score_cut}'][\"event\"].extend(new_unique_eventNumber.tolist())\n",
    "\n",
    "                intersect, comm1, comm2 = np.intersect1d(\n",
    "                    data_test_aux.loc[nonres_bool, \"event\"].to_numpy()[nonres_ggf_preds > score_cut],\n",
    "                    new_unique_eventNumber,\n",
    "                    return_indices=True\n",
    "                )\n",
    "\n",
    "                intersect_bool = np.zeros_like(\n",
    "                    data_test_aux.loc[nonres_bool, \"event\"].to_numpy()[nonres_ggf_preds > score_cut], \n",
    "                    dtype=bool\n",
    "                )\n",
    "                for index in comm1:\n",
    "                    intersect_bool[index] = True\n",
    "                \n",
    "                for var_idx, plot_var in enumerate(plot_vars):\n",
    "                    BDT_perf_resample[fold_idx][f'preds{score_cut}'][plot_var].append(\n",
    "                        data_test_aux.loc[nonres_bool, plot_var].to_numpy()[nonres_ggf_preds > score_cut][intersect_bool]\n",
    "                    )\n",
    "                \n",
    "    for var_idx, plot_var in enumerate(plot_vars):\n",
    "\n",
    "        plot_dirpath_ = os.path.join(plot_dirpath, plot_var)\n",
    "        if not os.path.exists(plot_dirpath_):\n",
    "            os.makedirs(plot_dirpath_)\n",
    "        \n",
    "        test_hists = [hist.Hist(VARIABLES[plot_var]).fill(var=np.concatenate(BDT_perf_resample[fold_idx][f'preds{score_cut}'][plot_var])) for score_cut in score_cuts]\n",
    "        make_input_plot(\n",
    "            plot_dirpath_, plot_var,\n",
    "            test_hists, \n",
    "            fold_idx=fold_idx, labels=label_arr, \n",
    "            plot_prefix='test_non-res_scoreCut_'\n",
    "        )\n",
    "\n",
    "for var_idx, plot_var in enumerate(plot_vars):\n",
    "\n",
    "    plot_dirpath_ = os.path.join(plot_dirpath, plot_var)\n",
    "    if not os.path.exists(plot_dirpath_):\n",
    "        os.makedirs(plot_dirpath_)\n",
    "\n",
    "    test_hists = [hist.Hist(VARIABLES[plot_var]).fill(\n",
    "        var=np.concatenate(\n",
    "            [np.concatenate(BDT_perf_resample[fold_idx][f'preds{score_cut}'][plot_var]) for fold_idx in range(len(BDT_perf_resample))]\n",
    "        )\n",
    "    ) for score_cut in score_cuts]\n",
    "    make_input_plot(\n",
    "        plot_dirpath_, plot_var,\n",
    "        test_hists, \n",
    "        fold_idx=None, labels=label_arr, \n",
    "        plot_prefix='test_non-res_scoreCut_'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n"
     ]
    }
   ],
   "source": [
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"pre_std\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "label_arr_fold = [\n",
    "    MC_NAMES_PRETTY[\"GluGluToHH\"]+\" train\", MC_NAMES_PRETTY[\"GluGluToHH\"]+\" val\", MC_NAMES_PRETTY[\"GluGluToHH\"]+\" test\",\n",
    "    MC_NAMES_PRETTY[\"ttH + bbH\"]+\" train\", MC_NAMES_PRETTY[\"ttH + bbH\"]+\" val\", MC_NAMES_PRETTY[\"ttH + bbH\"]+\" test\",\n",
    "    # MC_NAMES_PRETTY[\"single-H\"]+\" train\", MC_NAMES_PRETTY[\"single-H\"]+\" val\", MC_NAMES_PRETTY[\"single-H\"]+\" test\",\n",
    "    # MC_NAMES_PRETTY[\"non-res\"]+\" train\", MC_NAMES_PRETTY[\"non-res\"]+\" val\", MC_NAMES_PRETTY[\"non-res\"]+\" test\",\n",
    "    MC_NAMES_PRETTY[\"VH\"]+\" train\", MC_NAMES_PRETTY[\"VH\"]+\" val\", MC_NAMES_PRETTY[\"VH\"]+\" test\",\n",
    "    MC_NAMES_PRETTY[\"non-res + ggFH + VBFH\"]+\" train\", MC_NAMES_PRETTY[\"non-res + ggFH + VBFH\"]+\" val\", MC_NAMES_PRETTY[\"non-res + ggFH + VBFH\"]+\" test\",\n",
    "]\n",
    "# Loop over and plot the per-fold variables\n",
    "for fold_idx in range(len(hlf_vars_columns_dict)):\n",
    "\n",
    "    for var_name in hlf_vars_columns_dict['fold_0']:\n",
    "        if var_name in {'puppiMET_eta'}:\n",
    "            continue\n",
    "\n",
    "        plot_dirpath_ = os.path.join(plot_dirpath, var_name)\n",
    "        if not os.path.exists(plot_dirpath_):\n",
    "            os.makedirs(plot_dirpath_)\n",
    "\n",
    "        train_hists, val_hists, test_hists = {}, {}, {}\n",
    "        for i, sample_name in enumerate(order):\n",
    "            train_mask = xgb_label_train_dict[f'fold_{fold_idx}'] == i\n",
    "            val_mask = xgb_label_val_dict[f'fold_{fold_idx}'] == i\n",
    "            test_mask = xgb_label_test_dict[f'fold_{fold_idx}'] == i\n",
    "\n",
    "            train_np = (\n",
    "                data_df_dict[f'fold_{fold_idx}'].iloc[train_idxs_dict[f'fold_{fold_idx}']]\n",
    "            ).loc[train_mask, var_name].to_numpy(dtype=int)\n",
    "            val_np = (\n",
    "                data_df_dict[f'fold_{fold_idx}'].iloc[val_idxs_dict[f'fold_{fold_idx}']]\n",
    "            ).loc[val_mask, var_name].to_numpy(dtype=int)\n",
    "            test_np = data_test_df_dict[f'fold_{fold_idx}'].loc[test_mask, var_name].to_numpy(dtype=int)\n",
    "\n",
    "            train_hists[sample_name] = hist.Hist(VARIABLES[var_name]).fill(var=train_np)\n",
    "            val_hists[sample_name] = hist.Hist(VARIABLES[var_name]).fill(var=val_np)\n",
    "            test_hists[sample_name] = hist.Hist(VARIABLES[var_name]).fill(var=test_np)\n",
    "    \n",
    "            make_input_plot(\n",
    "                plot_dirpath_, var_name,\n",
    "                [train_hists[sample_name], val_hists[sample_name], test_hists[sample_name]], \n",
    "                fold_idx=fold_idx, labels=label_arr_fold[3*i : 3*(i+1)], plot_prefix=f'train_val_test_{sample_name}_'\n",
    "            )\n",
    "        for j, (plot_type, histdict) in enumerate([('train_', train_hists), ('val_', val_hists), ('test_', test_hists)]):\n",
    "            if re.search('epton', var_name) is not None:\n",
    "                reduced_order = order[1:]\n",
    "                reduced_label_arr = label_arr_fold[j+3::3]\n",
    "            else:\n",
    "                reduced_order = order\n",
    "                reduced_label_arr = label_arr_fold[j::3]\n",
    "            make_input_plot(\n",
    "                plot_dirpath_, var_name,\n",
    "                [histdict[sample_name] for sample_name in reduced_order], \n",
    "                fold_idx=fold_idx, labels=reduced_label_arr, plot_prefix=plot_type\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n"
     ]
    }
   ],
   "source": [
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"post_std\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "label_arr_fold = [\n",
    "    MC_NAMES_PRETTY[\"GluGluToHH\"]+\" train\", MC_NAMES_PRETTY[\"GluGluToHH\"]+\" val\", MC_NAMES_PRETTY[\"GluGluToHH\"]+\" test\",\n",
    "    MC_NAMES_PRETTY[\"ttHToGG\"]+\" train\", MC_NAMES_PRETTY[\"ttHToGG\"]+\" val\", MC_NAMES_PRETTY[\"ttHToGG\"]+\" test\",\n",
    "    # MC_NAMES_PRETTY[\"single-H\"]+\" train\", MC_NAMES_PRETTY[\"single-H\"]+\" val\", MC_NAMES_PRETTY[\"single-H\"]+\" test\",\n",
    "    # MC_NAMES_PRETTY[\"non-res\"]+\" train\", MC_NAMES_PRETTY[\"non-res\"]+\" val\", MC_NAMES_PRETTY[\"non-res\"]+\" test\",\n",
    "    MC_NAMES_PRETTY[\"VH\"]+\" train\", MC_NAMES_PRETTY[\"VH\"]+\" val\", MC_NAMES_PRETTY[\"VH\"]+\" test\",\n",
    "    MC_NAMES_PRETTY[\"non-res + ggFH + VBFH\"]+\" train\", MC_NAMES_PRETTY[\"non-res + ggFH + VBFH\"]+\" val\", MC_NAMES_PRETTY[\"non-res + ggFH + VBFH\"]+\" test\",\n",
    "]\n",
    "# Loop over and plot the per-fold variables\n",
    "for fold_idx in range(len(hlf_vars_columns_dict)):\n",
    "\n",
    "    for var_idx, var_name in enumerate(hlf_vars_columns_dict['fold_0']):\n",
    "        if var_name in {'puppiMET_eta'}:\n",
    "            continue\n",
    "\n",
    "        plot_dirpath_ = os.path.join(plot_dirpath, var_name)\n",
    "        if not os.path.exists(plot_dirpath_):\n",
    "            os.makedirs(plot_dirpath_)\n",
    "\n",
    "        train_hists, val_hists, test_hists = {}, {}, {}\n",
    "        for i, sample_name in enumerate(order):\n",
    "            train_mask = xgb_label_train_dict[f'fold_{fold_idx}'] == i\n",
    "            val_mask = xgb_label_val_dict[f'fold_{fold_idx}'] == i\n",
    "            test_mask = xgb_label_test_dict[f'fold_{fold_idx}'] == i\n",
    "\n",
    "            train_np = train_data_dict[f'fold_{fold_idx}'][train_mask, var_idx]\n",
    "            val_np = val_data_dict[f'fold_{fold_idx}'][val_mask, var_idx]\n",
    "            test_np = data_hlf_test_dict[f'fold_{fold_idx}'][test_mask, var_idx]\n",
    "\n",
    "            train_hists[sample_name] = hist.Hist(VARIABLES_STD[var_name]).fill(var=train_np)\n",
    "            val_hists[sample_name] = hist.Hist(VARIABLES_STD[var_name]).fill(var=val_np)\n",
    "            test_hists[sample_name] = hist.Hist(VARIABLES_STD[var_name]).fill(var=test_np)\n",
    "    \n",
    "            make_input_plot(\n",
    "                plot_dirpath_, var_name,\n",
    "                [train_hists[sample_name], val_hists[sample_name], test_hists[sample_name]], \n",
    "                fold_idx=fold_idx, labels=label_arr_fold[3*i : 3*(i+1)], plot_prefix=f'train_val_test_{sample_name}_'\n",
    "            )\n",
    "        for j, (plot_type, histdict) in enumerate([('train_', train_hists), ('val_', val_hists), ('test_', test_hists)]):\n",
    "            make_input_plot(\n",
    "                plot_dirpath_, var_name,\n",
    "                [histdict[sample_name] for sample_name in order], \n",
    "                fold_idx=fold_idx, labels=label_arr_fold[j::3], plot_prefix=plot_type\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save out new parquets for Yibo to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:271: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  self.flat_scale(1 / np.sum(np.diff(self.edges) * self.values))\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:198: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  return np.abs(method_fcn(self.values, variances) - self.values)\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:242: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.values *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_lo *= scale\n",
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/mplhep/utils.py:244: RuntimeWarning: invalid value encountered in multiply\n",
      "  self.yerr_hi *= scale\n"
     ]
    }
   ],
   "source": [
    "# EVAL_DATA_ON_ALL_FOLDS = True\n",
    "NONRES_sideband = False\n",
    "\n",
    "PLOT_DATA = True\n",
    "PLOT_NONRES = True\n",
    "\n",
    "# load and pre-process the data\n",
    "if 'DATA_data_df_dict' not in globals() and PLOT_DATA:\n",
    "    DATA_FILEPATHS_DICT = {\n",
    "        'Data': [\n",
    "            # 2022\n",
    "            lpc_fileprefix+Run3_2022[:-len('/sim')]+\"_MultiBDT_output_mvaIDCorr_22_23/data/DataC_2022/*output.parquet\",\n",
    "            lpc_fileprefix+Run3_2022[:-len('/sim')]+\"_MultiBDT_output_mvaIDCorr_22_23/data/DataD_2022/*output.parquet\",\n",
    "            lpc_fileprefix+Run3_2022[:-len('/sim')]+\"_MultiBDT_output_mvaIDCorr_22_23/data/Data_EraE/*output.parquet\",\n",
    "            lpc_fileprefix+Run3_2022[:-len('/sim')]+\"_MultiBDT_output_mvaIDCorr_22_23/data/Data_EraF/*output.parquet\",\n",
    "            lpc_fileprefix+Run3_2022[:-len('/sim')]+\"_MultiBDT_output_mvaIDCorr_22_23/data/Data_EraG/*output.parquet\",\n",
    "            # 2023\n",
    "            lpc_fileprefix+Run3_2023[:-len('/sim')]+\"_MultiBDT_output_mvaIDCorr_22_23/data/Data_EraCv1/*output.parquet\",\n",
    "            lpc_fileprefix+Run3_2023[:-len('/sim')]+\"_MultiBDT_output_mvaIDCorr_22_23/data/Data_EraCv2/*output.parquet\",\n",
    "            lpc_fileprefix+Run3_2023[:-len('/sim')]+\"_MultiBDT_output_mvaIDCorr_22_23/data/Data_EraCv3/*output.parquet\",\n",
    "            lpc_fileprefix+Run3_2023[:-len('/sim')]+\"_MultiBDT_output_mvaIDCorr_22_23/data/Data_EraCv4/*output.parquet\",\n",
    "            lpc_fileprefix+Run3_2023[:-len('/sim')]+\"_MultiBDT_output_mvaIDCorr_22_23/data/Data_EraDv1/*output.parquet\",\n",
    "            lpc_fileprefix+Run3_2023[:-len('/sim')]+\"_MultiBDT_output_mvaIDCorr_22_23/data/Data_EraDv2/*output.parquet\",\n",
    "        ]\n",
    "    }\n",
    "    (\n",
    "        NOTHING_IGNORE,\n",
    "        DATA_data_df_dict, DATA_data_test_df_dict, \n",
    "        DATA_data_hlf_dict, DATA_label_dict,\n",
    "        DATA_data_hlf_test_dict, DATA_label_test_dict, \n",
    "        DATA_hlf_vars_columns_dict,\n",
    "        DATA_data_aux_dict, DATA_data_test_aux_dict\n",
    "    ) = process_data(\n",
    "        DATA_FILEPATHS_DICT, OUTPUT_DIRPATH, order=['Data'], mod_vals=MOD_VALS, k_fold_test=True,\n",
    "        save=False, std_json_dirpath=OUTPUT_DIRPATH\n",
    "    )\n",
    "\n",
    "if 'NONRES_data_df_dict' not in globals() and PLOT_NONRES:\n",
    "    NONRES_FILEPATHS_DICT = {\n",
    "        'non-res': [\n",
    "            # GG + 3Jets\n",
    "            lpc_fileprefix+Run3_2022[:-len('/sim')]+f\"_MultiBDT_output_mvaIDCorr_22_23/sim/preEE/GGJets/nominal/*output.parquet\", \n",
    "            lpc_fileprefix+Run3_2022[:-len('/sim')]+f\"_MultiBDT_output_mvaIDCorr_22_23/sim/postEE/GGJets/nominal/*output.parquet\",\n",
    "            lpc_fileprefix+Run3_2023[:-len('/sim')]+f\"_MultiBDT_output_mvaIDCorr_22_23/sim/preBPix/GGJets/nominal/*output.parquet\", \n",
    "            lpc_fileprefix+Run3_2023[:-len('/sim')]+f\"_MultiBDT_output_mvaIDCorr_22_23/sim/postBPix/GGJets/nominal/*output.parquet\",\n",
    "            # GJet pT 20-40\n",
    "            lpc_fileprefix+Run3_2022[:-len('/sim')]+f\"_MultiBDT_output_mvaIDCorr_22_23/sim/preEE/GJetPt20To40/nominal/*output.parquet\", \n",
    "            lpc_fileprefix+Run3_2022[:-len('/sim')]+f\"_MultiBDT_output_mvaIDCorr_22_23/sim/postEE/GJetPt20To40/nominal/*output.parquet\",\n",
    "            lpc_fileprefix+Run3_2023[:-len('/sim')]+f\"_MultiBDT_output_mvaIDCorr_22_23/sim/preBPix/GJetPt20To40/nominal/*output.parquet\", \n",
    "            lpc_fileprefix+Run3_2023[:-len('/sim')]+f\"_MultiBDT_output_mvaIDCorr_22_23/sim/postBPix/GJetPt20To40/nominal/*output.parquet\",\n",
    "            # GJet pT 40-inf\n",
    "            lpc_fileprefix+Run3_2022[:-len('/sim')]+f\"_MultiBDT_output_mvaIDCorr_22_23/sim/preEE/GJetPt40/nominal/*output.parquet\", \n",
    "            lpc_fileprefix+Run3_2022[:-len('/sim')]+f\"_MultiBDT_output_mvaIDCorr_22_23/sim/postEE/GJetPt40/nominal/*output.parquet\",\n",
    "            lpc_fileprefix+Run3_2023[:-len('/sim')]+f\"_MultiBDT_output_mvaIDCorr_22_23/sim/preBPix/GJetPt40/nominal/*output.parquet\", \n",
    "            lpc_fileprefix+Run3_2023[:-len('/sim')]+f\"_MultiBDT_output_mvaIDCorr_22_23/sim/postBPix/GJetPt40/nominal/*output.parquet\",\n",
    "        ],\n",
    "    }\n",
    "    (\n",
    "        NOTHING_IGNORE,\n",
    "        NONRES_data_df_dict, NONRES_data_test_df_dict, \n",
    "        NONRES_data_hlf_dict, NONRES_label_dict,\n",
    "        NONRES_data_hlf_test_dict, NONRES_label_test_dict, \n",
    "        NONRES_hlf_vars_columns_dict,\n",
    "        NONRES_data_aux_dict, NONRES_data_test_aux_dict\n",
    "    ) = process_data(\n",
    "        NONRES_FILEPATHS_DICT, OUTPUT_DIRPATH, order=['non-res'], mod_vals=MOD_VALS, k_fold_test=True,\n",
    "        save=False, std_json_dirpath=OUTPUT_DIRPATH\n",
    "    )\n",
    "\n",
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"sculpting_data\")\n",
    "# plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"PNetBtag_sculpting_data\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "score_cuts = [0.0, 0.7, 0.99, 0.998]\n",
    "# score_cuts = [0.998]\n",
    "label_arr = []\n",
    "for score_cut in score_cuts:\n",
    "    if PLOT_DATA:\n",
    "        label_arr.append(f'Data score above {score_cut}')\n",
    "    if PLOT_NONRES:\n",
    "        label_arr.append(f'NonRes score above {score_cut}')\n",
    "plot_vars = ['mass', 'dijet_mass', 'HHbbggCandidate_mass']\n",
    "# plot_vars = ['lead_bjet_btagPNetB', 'sublead_bjet_btagPNetB']\n",
    "\n",
    "# Loop over and plot the per-fold variables\n",
    "for fold_idx in range(len(DATA_hlf_vars_columns_dict)):\n",
    "\n",
    "    if PLOT_DATA:\n",
    "        DATA_sideband_bool = (DATA_data_test_aux_dict[f\"fold_{fold_idx}\"].loc[:, 'mass'] < 115) | (DATA_data_test_aux_dict[f\"fold_{fold_idx}\"].loc[:, 'mass'] > 135)\n",
    "        DATA_pass_cut_bools = [\n",
    "        DATA_data_test_aux_dict[f\"fold_{fold_idx}\"].loc[:, 'MultiBDT_output'].to_numpy() > score_cut for score_cut in score_cuts\n",
    "        ]\n",
    "        DATA_masks = [\n",
    "            np.logical_and(DATA_sideband_bool, DATA_pass_cut_bool) for DATA_pass_cut_bool in DATA_pass_cut_bools\n",
    "        ]\n",
    "\n",
    "    if PLOT_NONRES:\n",
    "        if NONRES_sideband:\n",
    "            NONRES_sideband_bool = (NONRES_data_test_aux_dict[f\"fold_{fold_idx}\"].loc[:, 'mass'] < 115) | (NONRES_data_test_aux_dict[f\"fold_{fold_idx}\"].loc[:, 'mass'] > 135)\n",
    "        else:\n",
    "            NONRES_sideband_bool = NONRES_data_test_aux_dict[f\"fold_{fold_idx}\"].loc[:, 'mass'] > 0\n",
    "        NONRES_pass_cut_bools = [\n",
    "        NONRES_data_test_aux_dict[f\"fold_{fold_idx}\"].loc[:, 'MultiBDT_output'].to_numpy() > score_cut for score_cut in score_cuts\n",
    "        ]\n",
    "        NONRES_masks = [\n",
    "            np.logical_and(NONRES_sideband_bool, NONRES_pass_cut_bool) for NONRES_pass_cut_bool in NONRES_pass_cut_bools\n",
    "        ]\n",
    "\n",
    "    for var_idx, var_name in enumerate(plot_vars):\n",
    "\n",
    "        plot_dirpath_ = os.path.join(plot_dirpath, var_name)\n",
    "        if not os.path.exists(plot_dirpath_):\n",
    "            os.makedirs(plot_dirpath_)\n",
    "\n",
    "        if PLOT_DATA:\n",
    "            if var_name in DATA_data_test_aux_dict[f\"fold_{fold_idx}\"].columns:\n",
    "                DATA_var_df = DATA_data_test_aux_dict[f\"fold_{fold_idx}\"]\n",
    "            elif var_name in DATA_data_test_df_dict[f\"fold_{fold_idx}\"].columns:\n",
    "                DATA_var_df = DATA_data_test_df_dict[f\"fold_{fold_idx}\"]\n",
    "            else:\n",
    "                raise Exception(f'Variable {var_name} does not exist in DF nor in auxiliary DF.')\n",
    "        if PLOT_NONRES:\n",
    "            if var_name in NONRES_data_test_aux_dict[f\"fold_{fold_idx}\"].columns:\n",
    "                NONRES_var_df = NONRES_data_test_aux_dict[f\"fold_{fold_idx}\"]\n",
    "            elif var_name in NONRES_data_test_df_dict[f\"fold_{fold_idx}\"].columns:\n",
    "                NONRES_var_df = NONRES_data_test_df_dict[f\"fold_{fold_idx}\"]\n",
    "            else:\n",
    "                raise Exception(f'Variable {var_name} does not exist in DF nor in auxiliary DF.')\n",
    "        \n",
    "        sculpting_hists = []\n",
    "        for mask_idx in range(len(score_cuts)):\n",
    "            if PLOT_DATA:\n",
    "                sculpting_hists.append(\n",
    "                    hist.Hist(VARIABLES[var_name]).fill(var=DATA_var_df.loc[DATA_masks[mask_idx], var_name])\n",
    "                )\n",
    "            if PLOT_NONRES:\n",
    "                sculpting_hists.append(\n",
    "                    hist.Hist(VARIABLES[var_name]).fill(\n",
    "                        var=NONRES_var_df.loc[NONRES_masks[mask_idx], var_name], \n",
    "                        weight=NONRES_data_test_aux_dict[f\"fold_{fold_idx}\"].loc[NONRES_masks[mask_idx], 'eventWeight']\n",
    "                    )\n",
    "                )\n",
    "    \n",
    "        make_input_plot(\n",
    "            plot_dirpath_, var_name,\n",
    "            sculpting_hists, \n",
    "            fold_idx=fold_idx, labels=label_arr, \n",
    "            plot_prefix='test_non-res_scoreCut_', \n",
    "            # log=True,\n",
    "            density=False if (PLOT_DATA ^ PLOT_NONRES) and len(score_cuts) == 1 else True,\n",
    "            num_compare=int(PLOT_DATA)+int(PLOT_NONRES),\n",
    "        )\n",
    "\n",
    "# flattened sculpting check\n",
    "if PLOT_DATA:\n",
    "    DATA_flat_sideband_bool = np.concatenate([\n",
    "        (DATA_data_test_aux_dict[f\"fold_{fold_idx}\"].loc[:, 'mass'] < 115) \n",
    "        | (DATA_data_test_aux_dict[f\"fold_{fold_idx}\"].loc[:, 'mass'] > 135)\n",
    "        for fold_idx in range(len(DATA_data_test_aux_dict))\n",
    "    ])\n",
    "    DATA_flat_pass_cut_bools = [\n",
    "        np.concatenate([\n",
    "            DATA_data_test_aux_dict[f\"fold_{fold_idx}\"].loc[:, 'MultiBDT_output'].to_numpy()\n",
    "            for fold_idx in range(len(DATA_data_test_aux_dict))\n",
    "        ]) > score_cut for score_cut in score_cuts\n",
    "    ]\n",
    "    DATA_flat_masks = [\n",
    "        np.logical_and(DATA_flat_sideband_bool, DATA_flat_pass_cut_bool) for DATA_flat_pass_cut_bool in DATA_flat_pass_cut_bools\n",
    "    ]\n",
    "\n",
    "if PLOT_NONRES:\n",
    "    NONRES_flat_sideband_bool = np.concatenate([\n",
    "        (NONRES_data_test_aux_dict[f\"fold_{fold_idx}\"].loc[:, 'mass'] < 115) \n",
    "        | (NONRES_data_test_aux_dict[f\"fold_{fold_idx}\"].loc[:, 'mass'] > 135)\n",
    "        for fold_idx in range(len(NONRES_data_test_aux_dict))\n",
    "    ])\n",
    "    NONRES_flat_pass_cut_bools = [\n",
    "        np.concatenate([\n",
    "            NONRES_data_test_aux_dict[f\"fold_{fold_idx}\"].loc[:, 'MultiBDT_output'].to_numpy()\n",
    "            for fold_idx in range(len(NONRES_data_test_aux_dict))\n",
    "        ]) > score_cut for score_cut in score_cuts\n",
    "    ]\n",
    "    NONRES_flat_masks = [\n",
    "        np.logical_and(NONRES_flat_sideband_bool, NONRES_flat_pass_cut_bool) for NONRES_flat_pass_cut_bool in NONRES_flat_pass_cut_bools\n",
    "    ]\n",
    "    NONRES_flat_weight = np.concatenate([\n",
    "        NONRES_data_test_aux_dict[f\"fold_{fold_idx}\"].loc[:, 'eventWeight'].to_numpy(copy=True) for fold_idx in range(len(NONRES_data_test_aux_dict))\n",
    "    ])\n",
    "\n",
    "for var_idx, var_name in enumerate(plot_vars):\n",
    "\n",
    "    if PLOT_DATA:\n",
    "        if var_name in DATA_data_test_aux_dict[f\"fold_0\"].columns:\n",
    "            DATA_flat_var = np.concatenate([\n",
    "                DATA_data_test_aux_dict[f\"fold_{fold_idx}\"].loc[:, var_name].to_numpy(copy=True) for fold_idx in range(len(DATA_data_test_aux_dict))\n",
    "            ])\n",
    "        elif var_name in DATA_data_test_df_dict[f\"fold_0\"].columns:\n",
    "            DATA_flat_var = np.concatenate([\n",
    "                DATA_data_test_df_dict[f\"fold_{fold_idx}\"].loc[:, var_name].to_numpy(copy=True) for fold_idx in range(len(DATA_data_test_aux_dict))\n",
    "            ])\n",
    "        else:\n",
    "            raise Exception(f'Variable {var_name} does not exist in DF nor in auxiliary DF.')\n",
    "    if PLOT_NONRES:\n",
    "        if var_name in NONRES_data_test_aux_dict[f\"fold_0\"].columns:\n",
    "            NONRES_flat_var = np.concatenate([\n",
    "                NONRES_data_test_aux_dict[f\"fold_{fold_idx}\"].loc[:, var_name].to_numpy(copy=True) for fold_idx in range(len(NONRES_data_test_aux_dict))\n",
    "            ])\n",
    "        elif var_name in NONRES_data_test_df_dict[f\"fold_0\"].columns:\n",
    "            NONRES_flat_var = np.concatenate([\n",
    "                NONRES_data_test_df_dict[f\"fold_{fold_idx}\"].loc[:, var_name].to_numpy(copy=True) for fold_idx in range(len(NONRES_data_test_aux_dict))\n",
    "            ])\n",
    "        else:\n",
    "            raise Exception(f'Variable {var_name} does not exist in DF nor in auxiliary DF.')\n",
    "\n",
    "    plot_dirpath_ = os.path.join(plot_dirpath, var_name)\n",
    "    if not os.path.exists(plot_dirpath_):\n",
    "        os.makedirs(plot_dirpath_)\n",
    "\n",
    "    flat_sculpting_hists = []\n",
    "    for mask_idx in range(len(DATA_flat_masks)):\n",
    "        if PLOT_DATA:\n",
    "            flat_sculpting_hists.append(\n",
    "                hist.Hist(VARIABLES[var_name]).fill(var=DATA_flat_var[DATA_flat_masks[mask_idx]])\n",
    "            )\n",
    "        if PLOT_NONRES:\n",
    "            flat_sculpting_hists.append(\n",
    "                hist.Hist(VARIABLES[var_name]).fill(\n",
    "                    var=NONRES_flat_var[NONRES_flat_masks[mask_idx]], \n",
    "                    weight=NONRES_flat_weight[NONRES_flat_masks[mask_idx]]\n",
    "                )\n",
    "            )\n",
    "\n",
    "    make_input_plot(\n",
    "        plot_dirpath_, var_name,\n",
    "        flat_sculpting_hists, \n",
    "        fold_idx=None, labels=label_arr, \n",
    "        plot_prefix='test_non-res_scoreCut_', \n",
    "        # log=True,\n",
    "        density=False if (PLOT_DATA ^ PLOT_NONRES) and len(score_cuts) == 1 else True,\n",
    "        num_compare=int(PLOT_DATA)+int(PLOT_NONRES),\n",
    "    )\n",
    "\n",
    "# BDT_DATA_preds = []\n",
    "\n",
    "# if EVAL_DATA_ON_ALL_FOLDS:\n",
    "\n",
    "#     bdt_train_data_dict = xgb.DMatrix(\n",
    "#         data=DATA_data_hlf_dict[f\"fold_0\"], label=DATA_label_dict[f\"fold_0\"], \n",
    "#         missing=-999.0, feature_names=list(DATA_hlf_vars_columns_dict[f\"fold_0\"])\n",
    "#     )\n",
    "#     bdt_test_data_dict = xgb.DMatrix(\n",
    "#         data=DATA_data_hlf_test_dict[f\"fold_0\"], label=DATA_label_test_dict[f\"fold_0\"], \n",
    "#         missing=-999.0, feature_names=list(DATA_hlf_vars_columns_dict[f\"fold_0\"])\n",
    "#     )\n",
    "\n",
    "#     for fold_idx in range(len(DATA_label_test_dict)):\n",
    "#         booster = xgb.Booster(param)\n",
    "#         booster.load_model(os.path.join(OUTPUT_DIRPATH, f'{CURRENT_TIME}_BDT_fold{fold_idx}.model'))\n",
    "\n",
    "#         BDT_train_preds = booster.predict(\n",
    "#             bdt_train_data_dict, \n",
    "#             iteration_range=(0, booster.best_iteration+1)\n",
    "#         )\n",
    "#         BDT_test_preds = booster.predict(\n",
    "#             bdt_test_data_dict, \n",
    "#             iteration_range=(0, booster.best_iteration+1)\n",
    "#         )\n",
    "\n",
    "#         BDT_all_preds = np.concatenate([BDT_train_preds, BDT_test_preds])\n",
    "#         BDT_all_preds = BDT_all_preds[\n",
    "#             np.argsort(\n",
    "#                 np.concatenate([DATA_data_aux_dict[f\"fold_0\"].loc[:, 'hash'].to_numpy(), DATA_data_test_aux_dict[f\"fold_0\"].loc[:, 'hash'].to_numpy()])\n",
    "#             )\n",
    "#         ]\n",
    "\n",
    "#         if fold_idx == 0:\n",
    "#             BDT_DATA_preds = copy.deepcopy(BDT_all_preds)\n",
    "#         else:\n",
    "#             BDT_DATA_preds += BDT_all_preds\n",
    "\n",
    "#             if fold_idx == len(DATA_label_test_dict) - 1:\n",
    "#                 BDT_DATA_preds = BDT_DATA_preds / len(DATA_label_test_dict)\n",
    "# else:\n",
    "\n",
    "#     bdt_train_data_dict, bdt_test_data_dict = {}, {}\n",
    "#     for fold_idx in range(len(DATA_label_test_dict)):\n",
    "        \n",
    "#         bdt_train_data_dict[f\"fold_{fold_idx}\"] = xgb.DMatrix(\n",
    "#             data=DATA_data_hlf_dict[f\"fold_{fold_idx}\"], label=DATA_label_dict[f\"fold_{fold_idx}\"], \n",
    "#             missing=-999.0, feature_names=list(DATA_hlf_vars_columns_dict[f\"fold_{fold_idx}\"])\n",
    "#         )\n",
    "#         bdt_test_data_dict[f\"fold_{fold_idx}\"] = xgb.DMatrix(\n",
    "#             data=DATA_data_hlf_test_dict[f\"fold_{fold_idx}\"], label=DATA_label_test_dict[f\"fold_{fold_idx}\"], \n",
    "#             missing=-999.0, feature_names=list(DATA_hlf_vars_columns_dict[f\"fold_{fold_idx}\"])\n",
    "#         )\n",
    "\n",
    "#         booster = xgb.Booster(param)\n",
    "#         booster.load_model(os.path.join(OUTPUT_DIRPATH, f'{CURRENT_TIME}_BDT_fold{fold_idx}.model'))\n",
    "\n",
    "#         BDT_DATA_preds.append(\n",
    "#             booster.predict(\n",
    "#                 bdt_test_data_dict[f\"fold_{fold_idx}\"], \n",
    "#                 iteration_range=(0, booster.best_iteration+1)\n",
    "#             )\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Plot to show data labels look ok\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "hist_axis = hist.axis.Regular(100, 0., 1., name='var', growth=False, underflow=False, overflow=False)\n",
    "\n",
    "data_hists, data_plot_labels = [], []\n",
    "if not EVAL_DATA_ON_ALL_FOLDS:\n",
    "    \n",
    "    for fold_idx in range(len(BDT_DATA_preds)):\n",
    "\n",
    "        data_hists.append(\n",
    "            hist.Hist(hist_axis, storage='weight').fill(\n",
    "                var=np.array(BDT_DATA_preds[fold_idx])[:, 0],\n",
    "            )\n",
    "        )\n",
    "        data_plot_labels.append(f\"fold {fold_idx}\")\n",
    "else:\n",
    "\n",
    "    data_hists.append(\n",
    "        hist.Hist(hist_axis, storage='weight').fill(\n",
    "            var=np.array(BDT_DATA_preds)[:, 0],\n",
    "        )\n",
    "    )\n",
    "    data_plot_labels.append(f\"sum over folds\")\n",
    "\n",
    "hep.histplot(\n",
    "    data_hists,\n",
    "    alpha=0.5, density=False, histtype='step',\n",
    "    label=data_plot_labels\n",
    ")\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================== started \n",
      " /eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v3/Run3_2024_mergedFullResolved_temp_v14/*merged.parquet\n",
      "[14:53:13] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:53:19] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:53:26] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:53:33] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[14:53:39] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1645117937192/work/src/learner.cc:576: \n",
      "Parameters: { \"device\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "======================== finished \n",
      " /eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v3/Run3_2024_mergedFullResolved_MultiBDT_output_DijetMass_22_23_temp_v14/allData_NOTAG_merged_merged_MultiBDT_output.parquet\n"
     ]
    }
   ],
   "source": [
    "FORCE_REEVAL = False\n",
    "\n",
    "# load and pre-process the data\n",
    "VARIATIONS_FILEPATHS_DICT = {\n",
    "    syst_name: get_filepath_dict(syst_name=syst_name) for syst_name in [\n",
    "        'nominal',\n",
    "        # 'Et_dependent_ScaleEB_up', 'Et_dependent_ScaleEB_down', 'Et_dependent_ScaleEE_up', 'Et_dependent_ScaleEE_down', \n",
    "        # 'Et_dependent_Smearing_up', 'Et_dependent_Smearing_down', \n",
    "        # 'jec_syst_Total_up', 'jec_syst_Total_down', 'jer_syst_up', 'jer_syst_down'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# load and pre-process the data\n",
    "DATA_FILEPATHS_DICT = {\n",
    "    'Data': [\n",
    "        # # 2022\n",
    "        # lpc_fileprefix+Run3_2022[:-4]+f\"/data/DataC_2022/*merged.parquet\",\n",
    "        # lpc_fileprefix+Run3_2022[:-4]+f\"/data/DataD_2022/*merged.parquet\",\n",
    "        # lpc_fileprefix+Run3_2022[:-4]+f\"/data/Data_EraE/*merged.parquet\",\n",
    "        # lpc_fileprefix+Run3_2022[:-4]+f\"/data/Data_EraF/*merged.parquet\",\n",
    "        # lpc_fileprefix+Run3_2022[:-4]+f\"/data/Data_EraG/*merged.parquet\",\n",
    "        # # 2023\n",
    "        # lpc_fileprefix+Run3_2023[:-4]+\"/data/Data_EraCv1/*merged.parquet\",\n",
    "        # lpc_fileprefix+Run3_2023[:-4]+\"/data/Data_EraCv2/*merged.parquet\",\n",
    "        # lpc_fileprefix+Run3_2023[:-4]+\"/data/Data_EraCv3/*merged.parquet\",\n",
    "        # lpc_fileprefix+Run3_2023[:-4]+\"/data/Data_EraCv4/*merged.parquet\",\n",
    "        # lpc_fileprefix+Run3_2023[:-4]+\"/data/Data_EraDv1/*merged.parquet\",\n",
    "        # lpc_fileprefix+Run3_2023[:-4]+\"/data/Data_EraDv2/*merged.parquet\",\n",
    "        # 2024\n",
    "        # lpc_fileprefix+Run3_2024[:-4]+\"/data/Data_EGamma0_EraB/*merged.parquet\",\n",
    "        # lpc_fileprefix+Run3_2024[:-4]+\"/data/Data_EGamma0_EraC/*merged.parquet\",\n",
    "        # lpc_fileprefix+Run3_2024[:-4]+\"/data/Data_EGamma0_EraD/*merged.parquet\",\n",
    "        # lpc_fileprefix+Run3_2024[:-4]+\"/data/Data_EGamma0_EraE/*merged.parquet\",\n",
    "        # lpc_fileprefix+Run3_2024[:-4]+\"/data/Data_EGamma0_EraF/*merged.parquet\",\n",
    "        # lpc_fileprefix+Run3_2024[:-4]+\"/data/Data_EGamma0_EraG/*merged.parquet\",\n",
    "        # lpc_fileprefix+Run3_2024[:-4]+\"/data/Data_EGamma0_EraH/*merged.parquet\",\n",
    "        # lpc_fileprefix+Run3_2024[:-4]+\"/data/Data_EGamma0_EraI_v1/*merged.parquet\",\n",
    "        # lpc_fileprefix+Run3_2024[:-4]+\"/data/Data_EGamma0_EraI_v2/*merged.parquet\",\n",
    "        # lpc_fileprefix+Run3_2024[:-4]+\"/data/Data_EGamma1_EraB/*merged.parquet\",\n",
    "        # lpc_fileprefix+Run3_2024[:-4]+\"/data/Data_EGamma1_EraC/*merged.parquet\",\n",
    "        # lpc_fileprefix+Run3_2024[:-4]+\"/data/Data_EGamma1_EraD/*merged.parquet\",\n",
    "        # lpc_fileprefix+Run3_2024[:-4]+\"/data/Data_EGamma1_EraE/*merged.parquet\",\n",
    "        # lpc_fileprefix+Run3_2024[:-4]+\"/data/Data_EGamma1_EraF/*merged.parquet\",\n",
    "        # lpc_fileprefix+Run3_2024[:-4]+\"/data/Data_EGamma1_EraG/*merged.parquet\",\n",
    "        # lpc_fileprefix+Run3_2024[:-4]+\"/data/Data_EGamma1_EraH/*merged.parquet\",\n",
    "        # lpc_fileprefix+Run3_2024[:-4]+\"/data/Data_EGamma1_EraI_v1/*merged.parquet\",\n",
    "        # lpc_fileprefix+Run3_2024[:-4]+\"/data/Data_EGamma1_EraI_v2/*merged.parquet\",\n",
    "        lpc_fileprefix+'Run3_2024_mergedFullResolved_temp_v14'+\"/*merged.parquet\"\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Sorts the predictions to map the output to the correct event\n",
    "def sorted_preds(preds, data_aux, sample, sorted_preds=False, sort_variable='hash'):\n",
    "\n",
    "    if np.size(np.unique(sample[sort_variable])) != np.size(sample[sort_variable]):\n",
    "        raise Exception(f\"The sort_variable you chose ({sort_variable}) does not have uniquely defined values for all events. This will cause sorting failures.\")\n",
    "    \n",
    "    if not sorted_preds:\n",
    "        flat_preds = np.concatenate([preds[fold_idx] for fold_idx in range(len(data_aux))])\n",
    "        preds_sort = np.argsort(\n",
    "            np.concatenate([data_aux[f\"fold_{fold_idx}\"].loc[:, sort_variable].to_numpy() for fold_idx in range(len(data_aux))])\n",
    "        )\n",
    "    else:\n",
    "        flat_preds = preds\n",
    "        preds_sort = np.arange(len(flat_preds))\n",
    "\n",
    "    sample_sort = np.argsort(np.argsort(\n",
    "        ak.to_numpy(sample[sort_variable], allow_missing=False)\n",
    "    ))\n",
    "\n",
    "    if not sorted_preds and np.any(\n",
    "        np.concatenate(\n",
    "            [data_aux[f\"fold_{fold_idx}\"].loc[:, sort_variable].to_numpy() for fold_idx in range(len(data_aux))]\n",
    "        )[preds_sort][sample_sort] != ak.to_numpy(sample[sort_variable], allow_missing=False)\n",
    "    ):\n",
    "        raise Exception(f\"Sort failed.\")\n",
    "\n",
    "    return flat_preds[preds_sort][sample_sort]\n",
    "\n",
    "def get_file_sample_name(dirpath: str, variation: str):\n",
    "    end_idx = dirpath.find(variation) - 1\n",
    "    start_idx = dirpath[:end_idx].rfind('/') + 1\n",
    "\n",
    "    if end_idx == -2 or start_idx == 0: return ''\n",
    "\n",
    "    return dirpath[start_idx:end_idx]\n",
    "\n",
    "def get_ttH_score(multibdt_output):\n",
    "    return multibdt_output[:, 0] / (multibdt_output[:, 0] + multibdt_output[:, 1])\n",
    "\n",
    "def get_QCD_score(multibdt_output):\n",
    "    return multibdt_output[:, 0] / (multibdt_output[:, 0] + multibdt_output[:, 2] + multibdt_output[:, 3])\n",
    "\n",
    "CATS = [\n",
    "    [0.987, 0.9982],\n",
    "    [0.92, 0.994],\n",
    "    [0.92, 0.9864],\n",
    "]\n",
    "\n",
    "def pass_category(multibdt_output, cat_i):\n",
    "    pass_ttH = get_ttH_score(multibdt_output) > CATS[cat_i][0]\n",
    "    pass_QCD = get_QCD_score(multibdt_output) > CATS[cat_i][1]\n",
    "\n",
    "    pass_prevQCD = get_QCD_score(multibdt_output) <= (\n",
    "        CATS[cat_i-1][1] if cat_i > 1 else 1\n",
    "    )\n",
    "\n",
    "    return pass_ttH & pass_QCD & pass_prevQCD\n",
    "\n",
    "# dirpath_addition = '_MultiBDT_output_mvaIDCorr_22_23'\n",
    "# dirpath_addition = '_HEFT_output'\n",
    "# dirpath_addition = '_MultiBDT_output_HEFT_22_23'\n",
    "dirpath_addition = '_MultiBDT_output_DijetMass_22_23'\n",
    "# dirpath_addition = '_MultiBDT_output_MbbRegDNNPairDijetMass_22_23'\n",
    "filename_addition = '_MultiBDT_output'\n",
    "basefilename_postfix = 'Run3_202x_mergedFullResolved'  # Resolved\n",
    "\n",
    "## MC SAMPLES ##\n",
    "# Load parquet files #\n",
    "for i, sample_name in enumerate(order):\n",
    "\n",
    "    for variation, variation_filepath_dict in VARIATIONS_FILEPATHS_DICT.items():\n",
    "\n",
    "        for dirpath in variation_filepath_dict[sample_name]:\n",
    "\n",
    "            if variation != 'nominal' and re.search('H', get_file_sample_name(dirpath, variation).upper()) is None: continue\n",
    "            if re.search('Q', get_file_sample_name(dirpath, variation).upper()) is not None: continue\n",
    "\n",
    "            print('======================== started \\n', dirpath)\n",
    "\n",
    "            for parquet_filepath in glob.glob(dirpath):\n",
    "                dest_filepath = parquet_filepath[:parquet_filepath.find('Run3_202')+len(basefilename_postfix)] + dirpath_addition + parquet_filepath[parquet_filepath.find('Run3_202')+len(basefilename_postfix):parquet_filepath.rfind('.')] + filename_addition + parquet_filepath[parquet_filepath.rfind('.'):]\n",
    "                if not os.path.exists(dest_filepath[:dest_filepath.rfind('/')]):\n",
    "                    os.makedirs(dest_filepath[:dest_filepath.rfind('/')])\n",
    "                elif not FORCE_REEVAL and os.path.exists(dest_filepath):\n",
    "                    print(f'file already exists at \\n{dest_filepath}\\n{\"=\"*60}')\n",
    "                    continue\n",
    "\n",
    "                sample = ak.from_parquet(parquet_filepath)\n",
    "                sample = sample[\n",
    "                    sample['nonRes_has_two_btagged_jets']\n",
    "                    & sample['fiducialGeometricFlag']\n",
    "                    & (\n",
    "                        (sample['lead_mvaID'] > -0.7)\n",
    "                        & (sample['sublead_mvaID'] > -0.7)\n",
    "                    )\n",
    "                ]\n",
    "\n",
    "                (\n",
    "                    NOTHING_IGNORE,\n",
    "                    IGNORE_data_df_dict, SAMPLE_data_test_df_dict, \n",
    "                    IGNORE_data_hlf_dict, IGNORE_label_dict,\n",
    "                    SAMPLE_data_hlf_test_dict, SAMPLE_label_test_dict, \n",
    "                    SAMPLE_hlf_vars_columns_dict,\n",
    "                    IGNORE_data_aux_dict, SAMPLE_data_test_aux_dict\n",
    "                ) = process_data(\n",
    "                    {\"sample\": [parquet_filepath]}, OUTPUT_DIRPATH, order=['sample'], mod_vals=MOD_VALS, k_fold_test=True,\n",
    "                    save=False, std_json_dirpath=OUTPUT_DIRPATH, \n",
    "                    jet_prefix='nonResReg_DNNpair' if re.search('MbbRegDNNPair', VARS) is not None else (\n",
    "                        'nonResReg' if re.search('MbbReg', VARS) is not None else 'nonRes'\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                sample_preds = []\n",
    "                for fold_idx in range(len(SAMPLE_data_test_df_dict)):\n",
    "                    \n",
    "                    with warnings.catch_warnings():\n",
    "                        warnings.simplefilter(\"ignore\")\n",
    "                        \n",
    "                        booster = xgb.Booster(param)\n",
    "                        booster.load_model(os.path.join(OUTPUT_DIRPATH, f'{CURRENT_TIME}_BDT_fold{fold_idx}.model'))\n",
    "\n",
    "                        bdt_test_sample_dict = xgb.DMatrix(\n",
    "                            data=SAMPLE_data_hlf_test_dict[f\"fold_{fold_idx}\"], label=SAMPLE_label_test_dict[f\"fold_{fold_idx}\"], \n",
    "                            missing=-999.0, feature_names=list(SAMPLE_hlf_vars_columns_dict[f\"fold_{fold_idx}\"])\n",
    "                        )\n",
    "\n",
    "                        sample_preds.append(\n",
    "                            booster.predict(\n",
    "                                bdt_test_sample_dict, \n",
    "                                iteration_range=(0, booster.best_iteration+1)\n",
    "                            )\n",
    "                        )\n",
    "\n",
    "                sample['MultiBDT_output'] = sorted_preds(\n",
    "                    sample_preds, SAMPLE_data_test_aux_dict, sample\n",
    "                )\n",
    "\n",
    "                merged_parquet = ak.to_parquet(sample, dest_filepath)\n",
    "                del sample\n",
    "                print('======================== finished \\n', dest_filepath)\n",
    "\n",
    "## DATA ##\n",
    "for dirpath in DATA_FILEPATHS_DICT['Data']:\n",
    "\n",
    "    print('======================== started \\n', dirpath)\n",
    "    parquet_filepath = glob.glob(dirpath)[0]\n",
    "    dest_filepath = parquet_filepath[:parquet_filepath.find('Run3_202')+len(basefilename_postfix)] + dirpath_addition + parquet_filepath[parquet_filepath.find('Run3_202')+len(basefilename_postfix):parquet_filepath.rfind('.')] + filename_addition + parquet_filepath[parquet_filepath.rfind('.'):]\n",
    "    if not os.path.exists(dest_filepath[:dest_filepath.rfind('/')]):\n",
    "        os.makedirs(dest_filepath[:dest_filepath.rfind('/')])\n",
    "    elif not FORCE_REEVAL and os.path.exists(dest_filepath):\n",
    "        print(f'file already exists at \\n{dest_filepath}\\n{\"=\"*60}')\n",
    "        continue\n",
    "    \n",
    "    jet_prefix = 'nonResReg_DNNpair' if re.search('MbbRegDNNPair', VARS) is not None else (\n",
    "        'nonResReg' if re.search('MbbReg', VARS) is not None else 'nonRes'\n",
    "    )\n",
    "    data_sample = ak.from_parquet(parquet_filepath)\n",
    "    data_sample = data_sample[\n",
    "        data_sample[f'{jet_prefix}_has_two_btagged_jets']\n",
    "        & data_sample['pass_fiducial_geometric']\n",
    "        & (\n",
    "            (\n",
    "                data_sample['Diphoton30_22_R9Id_OR_IsoCaloId_AND_HE_R9Id_Mass90']\n",
    "                & data_sample['Diphoton30_22_R9Id_OR_IsoCaloId_AND_HE_R9Id_Mass95']\n",
    "            ) \n",
    "            if 'Diphoton30_22_R9Id_OR_IsoCaloId_AND_HE_R9Id_Mass90' in data_sample.fields else (data_sample['mass'] > 0)\n",
    "        ) & (\n",
    "            (data_sample['lead_mvaID'] > -0.7)\n",
    "            & (data_sample['sublead_mvaID'] > -0.7)\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    (\n",
    "        NOTHING_IGNORE,\n",
    "        DATA_data_df_dict, DATA_data_test_df_dict, \n",
    "        DATA_data_hlf_dict, DATA_label_dict,\n",
    "        DATA_data_hlf_test_dict, DATA_label_test_dict, \n",
    "        DATA_hlf_vars_columns_dict,\n",
    "        DATA_data_aux_dict, DATA_data_test_aux_dict\n",
    "    ) = process_data(\n",
    "        {\"sample\": [parquet_filepath]}, OUTPUT_DIRPATH, order=['sample'], mod_vals=MOD_VALS, k_fold_test=True,\n",
    "        save=False, std_json_dirpath=OUTPUT_DIRPATH,\n",
    "        jet_prefix=jet_prefix\n",
    "    )\n",
    "\n",
    "    bdt_train_data_dict = xgb.DMatrix(\n",
    "        data=DATA_data_hlf_dict[f\"fold_0\"], label=DATA_label_dict[f\"fold_0\"], \n",
    "        missing=-999.0, feature_names=list(DATA_hlf_vars_columns_dict[f\"fold_0\"])\n",
    "    )\n",
    "    bdt_test_data_dict = xgb.DMatrix(\n",
    "        data=DATA_data_hlf_test_dict[f\"fold_0\"], label=DATA_label_test_dict[f\"fold_0\"], \n",
    "        missing=-999.0, feature_names=list(DATA_hlf_vars_columns_dict[f\"fold_0\"])\n",
    "    )\n",
    "\n",
    "    test_preds = []\n",
    "    for fold_idx in range(len(DATA_label_test_dict)):\n",
    "\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "\n",
    "            booster = xgb.Booster(param)\n",
    "            booster.load_model(os.path.join(OUTPUT_DIRPATH, f'{CURRENT_TIME}_BDT_fold{fold_idx}.model'))\n",
    "\n",
    "            # all-fold eval\n",
    "            BDT_train_preds = booster.predict(\n",
    "                bdt_train_data_dict, \n",
    "                iteration_range=(0, booster.best_iteration+1)\n",
    "            )\n",
    "            BDT_test_preds = booster.predict(\n",
    "                bdt_test_data_dict, \n",
    "                iteration_range=(0, booster.best_iteration+1)\n",
    "            )\n",
    "\n",
    "            BDT_all_preds = np.concatenate([BDT_train_preds, BDT_test_preds])\n",
    "            BDT_all_preds = BDT_all_preds[\n",
    "                np.argsort(\n",
    "                    np.concatenate([DATA_data_aux_dict[f\"fold_0\"].loc[:, 'hash'].to_numpy(), DATA_data_test_aux_dict[f\"fold_0\"].loc[:, 'hash'].to_numpy()])\n",
    "                )\n",
    "            ]\n",
    "\n",
    "            if fold_idx == 0:\n",
    "                data_preds = copy.deepcopy(BDT_all_preds)\n",
    "            else:\n",
    "                data_preds += BDT_all_preds\n",
    "\n",
    "                if fold_idx == len(DATA_label_test_dict) - 1:\n",
    "                    data_preds = data_preds / len(DATA_label_test_dict)\n",
    "\n",
    "\n",
    "            # single-fold eval\n",
    "            bdt_test_data_fold = xgb.DMatrix(\n",
    "                data=DATA_data_hlf_test_dict[f\"fold_{fold_idx}\"], label=DATA_label_test_dict[f\"fold_{fold_idx}\"], \n",
    "                missing=-999.0, feature_names=list(DATA_hlf_vars_columns_dict[f\"fold_{fold_idx}\"])\n",
    "            )\n",
    "\n",
    "            test_preds.append(\n",
    "                booster.predict(\n",
    "                    bdt_test_data_fold,\n",
    "                    iteration_range=(0, booster.best_iteration+1)\n",
    "                )\n",
    "            )\n",
    "\n",
    "    data_sample['MultiBDT_output'] = sorted_preds(\n",
    "        data_preds, DATA_data_test_aux_dict, data_sample,\n",
    "        sorted_preds=True\n",
    "    )\n",
    "    data_sample['MultiBDT_output_mod5'] = sorted_preds(\n",
    "        test_preds, DATA_data_test_aux_dict, data_sample\n",
    "    )\n",
    "\n",
    "    # print(f\"Total number of events in {dest_filepath}\\n = {ak.num(data_sample, axis=0)}\")\n",
    "    # for cat_i, cat in enumerate(CATS):\n",
    "    #     print(f\"Passing number of events in cat{cat_i} {dest_filepath}\\n = {ak.sum(pass_category(data_sample['MultiBDT_output'], cat_i), axis=0)}\")\n",
    "\n",
    "    merged_parquet = ak.to_parquet(data_sample, dest_filepath)\n",
    "    del data_sample\n",
    "    print('======================== finished \\n', dest_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
