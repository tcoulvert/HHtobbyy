{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmslpcgpu3.fnal.gov      Wed Jan 22 13:52:51 2025  555.42.06\n",
      "[0] Tesla P100-PCIE-12GB | 43Â°C,   1 % |     0 / 12288 MB |\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib widget\n",
    "# Stdlib packages\n",
    "import copy\n",
    "import datetime\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "# Common Py packages\n",
    "import awkward as ak\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from prettytable import PrettyTable\n",
    "from scipy.special import logit as inverse_sigmoid\n",
    "\n",
    "# HEP packages\n",
    "import gpustat\n",
    "import h5py\n",
    "import hist\n",
    "import mplhep as hep\n",
    "import xgboost as xgb\n",
    "from cycler import cycler\n",
    "\n",
    "# ML packages\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, fbeta_score\n",
    "from scipy.integrate import trapezoid\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Integer\n",
    "from skopt.utils import use_named_args\n",
    "\n",
    "# Module packages\n",
    "from data_processing_BDT import process_data\n",
    "\n",
    "gpustat.print_gpustat()\n",
    "\n",
    "plt.style.use(hep.style.CMS)\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "cmap_petroff10 = [\"#3f90da\", \"#ffa90e\", \"#bd1f01\", \"#94a4a2\", \"#832db6\", \"#a96b59\", \"#e76300\", \"#b9ac70\", \"#717581\", \"#92dadd\"]\n",
    "plt.rcParams.update({\"axes.prop_cycle\": cycler(\"color\", cmap_petroff10)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Locations and Model Naming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lpc_fileprefix = \"/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1\"\n",
    "\n",
    "FILEPATHS_DICT = {\n",
    "    'ggF HH': [\n",
    "        lpc_fileprefix+f\"/Run3_2022preEE_merged_v4/GluGluToHH/nominal/*\", \n",
    "        lpc_fileprefix+f\"/Run3_2022postEE_merged_v4/GluGluToHH/nominal/*\"\n",
    "    ],\n",
    "    # 'VBF HH': [\n",
    "    #     lpc_fileprefix+f\"/Run3_2022preEE_merged_v4/VBFHHto2B2G_CV_1_C2V_1_C3_1/nominal/*\", \n",
    "    #     lpc_fileprefix+f\"/Run3_2022postEE_merged_v4/VBFHHto2B2G_CV_1_C2V_1_C3_1/nominal/*\"\n",
    "    # ],\n",
    "    'ttH': [\n",
    "        lpc_fileprefix+f\"/Run3_2022preEE_merged_v4/ttHToGG/nominal/*\", \n",
    "        lpc_fileprefix+f\"/Run3_2022postEE_merged_v4/ttHToGG/nominal/*\"\n",
    "    ],\n",
    "    'VH': [\n",
    "        # VH\n",
    "        lpc_fileprefix+f\"/Run3_2022preEE_merged_v4/VHToGG/nominal/*\", \n",
    "        lpc_fileprefix+f\"/Run3_2022postEE_merged_v4/VHToGG/nominal/*\",\n",
    "    ],\n",
    "    'non-res + ggFH + VBFH': [\n",
    "        # GG + 3Jets\n",
    "        lpc_fileprefix+f\"/Run3_2022preEE_merged_v4/GGJets/nominal/*\", \n",
    "        lpc_fileprefix+f\"/Run3_2022postEE_merged_v4/GGJets/nominal/*\",\n",
    "        # GJet pT 20-40\n",
    "        lpc_fileprefix+f\"/Run3_2022preEE_merged_v4/GJetPt20To40/nominal/*\", \n",
    "        lpc_fileprefix+f\"/Run3_2022postEE_merged_v4/GJetPt20To40/nominal/*\",\n",
    "        # GJet pT 40-inf\n",
    "        lpc_fileprefix+f\"/Run3_2022preEE_merged_v4/GJetPt40/nominal/*\", \n",
    "        lpc_fileprefix+f\"/Run3_2022postEE_merged_v4/GJetPt40/nominal/*\",\n",
    "        # ggF H\n",
    "        lpc_fileprefix+f\"/Run3_2022preEE_merged_v4/GluGluHToGG/nominal/*\", \n",
    "        lpc_fileprefix+f\"/Run3_2022postEE_merged_v4/GluGluHToGG/nominal/*\",\n",
    "        # VBF H\n",
    "        lpc_fileprefix+f\"/Run3_2022preEE_merged_v4/VBFHToGG/nominal/*\", \n",
    "        lpc_fileprefix+f\"/Run3_2022postEE_merged_v4/VBFHToGG/nominal/*\",\n",
    "    ],\n",
    "    # 'single-H': [\n",
    "    #     # ggF H\n",
    "    #     lpc_fileprefix+f\"/Run3_2022preEE_merged_v4/GluGluHToGG/nominal/*\", \n",
    "    #     lpc_fileprefix+f\"/Run3_2022postEE_merged_v4/GluGluHToGG/nominal/*\",\n",
    "    #     # VBF H\n",
    "    #     lpc_fileprefix+f\"/Run3_2022preEE_merged_v4/VBFHToGG/nominal/*\", \n",
    "    #     lpc_fileprefix+f\"/Run3_2022postEE_merged_v4/VBFHToGG/nominal/*\",\n",
    "    #     # VH\n",
    "    #     lpc_fileprefix+f\"/Run3_2022preEE_merged_v4/VHToGG/nominal/*\", \n",
    "    #     lpc_fileprefix+f\"/Run3_2022postEE_merged_v4/VHToGG/nominal/*\",\n",
    "    # ],\n",
    "    # 'non-res': [\n",
    "    #     # GG + 3Jets\n",
    "    #     lpc_fileprefix+f\"/Run3_2022preEE_merged_v4/GGJets/nominal/*\", \n",
    "    #     lpc_fileprefix+f\"/Run3_2022postEE_merged_v4/GGJets/nominal/*\",\n",
    "    #     # GJet pT 20-40\n",
    "    #     lpc_fileprefix+f\"/Run3_2022preEE_merged_v4/GJetPt20To40/nominal/*\", \n",
    "    #     lpc_fileprefix+f\"/Run3_2022postEE_merged_v4/GJetPt20To40/nominal/*\",\n",
    "    #     # GJet pT 40-inf\n",
    "    #     lpc_fileprefix+f\"/Run3_2022preEE_merged_v4/GJetPt40/nominal/*\", \n",
    "    #     lpc_fileprefix+f\"/Run3_2022postEE_merged_v4/GJetPt40/nominal/*\",\n",
    "    # ],\n",
    "}\n",
    "\n",
    "CURRENT_DIRPATH = str(Path().absolute())\n",
    "# VERSION = 'v3'\n",
    "VERSION = 'v4'\n",
    "MOD_VALS = (5, 5)\n",
    "# VARS = 'nonres_and_ttH_and_DNN_vars'\n",
    "# CURRENT_TIME = '2024-12-10_19-08-41'\n",
    "# VARS = 'nonres_and_ttH_and_DNN_vars_no_photonIso_no_diphoMass'\n",
    "# CURRENT_TIME = '2024-12-12_16-57-20'\n",
    "# VARS = 'nonres_and_ttH_and_DNN_vars_no_photonIso'\n",
    "# CURRENT_TIME = '2024-12-11_13-40-30'\n",
    "# VARS = 'nonres_and_ttH_and_DNN_vars_no_photonIso_no_diphoPhi_no_diphoMass'\n",
    "# CURRENT_TIME = '2024-12-17_19-47-33'\n",
    "VARS = 'nonres_and_ttH_and_DNN_vars_no_photonIso_no_diphoPhi_no_diphoMass'\n",
    "CURRENT_TIME = '2025-01-18_21-26-07'\n",
    "# VARS = 'nonres_and_ttH_and_DNN_vars_no_photonIso'\n",
    "if 'CURRENT_TIME' in globals():\n",
    "    OUTPUT_DIRPATH = os.path.join(CURRENT_DIRPATH, f\"MultiClassBDT_model_outputs/{VERSION}/{VARS}\", CURRENT_TIME)\n",
    "else:\n",
    "    OUTPUT_DIRPATH = os.path.join(CURRENT_DIRPATH, f\"MultiClassBDT_model_outputs/{VERSION}/{VARS}\")\n",
    "\n",
    "if not os.path.exists(OUTPUT_DIRPATH):\n",
    "    os.makedirs(OUTPUT_DIRPATH)\n",
    "\n",
    "SEED = None\n",
    "seeded_rng = np.random.default_rng(seed=SEED)\n",
    "OPTIMIZE_SPACE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_weights(event_weights, labels, order=None, weighttype='rescaled_and_shifted', sig_rescale_factor=None):\n",
    "    if weighttype == 'abs':\n",
    "        return np.abs(event_weights)\n",
    "    \n",
    "    if order is not None:\n",
    "        sig_idx = -1\n",
    "        for i, sample_name in enumerate(order):\n",
    "            if re.search('ggF HH', sample_name) is not None:\n",
    "                sig_idx = i\n",
    "                break\n",
    "    else:\n",
    "        sig_idx = 0\n",
    "    \n",
    "    if sig_rescale_factor is None:\n",
    "        sig_sum = np.sum(event_weights[labels[:, sig_idx] == 1])\n",
    "        bkg_sum = np.sum(event_weights[labels[:, sig_idx] == 0])\n",
    "        \n",
    "        sig_rescale_factor = bkg_sum / sig_sum\n",
    "\n",
    "    scaled_weights = np.where(\n",
    "        labels[:, sig_idx] == 0, \n",
    "        event_weights,  # if bkg, do nothing\n",
    "        event_weights * sig_rescale_factor  # if sig, rescale to equal sum of all bkgs\n",
    "    )\n",
    "\n",
    "    abs_weights = np.abs(scaled_weights)\n",
    "\n",
    "    if weighttype == 'rescaled':\n",
    "        return abs_weights\n",
    "    elif weighttype == 'rescaled_and_shifted':\n",
    "        mean_weights = np.mean(scaled_weights)\n",
    "        rescaled_weights = abs_weights / mean_weights\n",
    "        return rescaled_weights\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"The only options for weighttype are 'abs', 'rescaled', and 'rescaled_and_shifted'. You provided {weighttype}\"\n",
    "        )\n",
    "\n",
    "# def training_weights(event_weights, labels, order=None, sig_rescale_factor=None):\n",
    "#     if order is None:\n",
    "#         order = [i for v in range(np.shape(labels)[0])]\n",
    "#     sum_dict, max_sum, max_i = {}, 0, 0\n",
    "#     for i, sample_name in enumerate(order):\n",
    "#         sum_dict[i] = np.sum(event_weights[labels[:, i] == 1])\n",
    "#         if np.sum(event_weights[labels[:, i] == 1]) > max_sum:\n",
    "#             max_sum, max_i = np.sum(event_weights[labels[:, i] == 1]), i\n",
    "\n",
    "#     label_i = np.sum(\n",
    "#         np.tile([i for i in range(np.shape(labels)[1])], (np.shape(labels)[0], 1)) * labels,\n",
    "#         axis=1\n",
    "#     )\n",
    "\n",
    "#     weight_factors = []\n",
    "#     for i in range(len(label_i)):\n",
    "#         weight_factors.append(\n",
    "#             max_sum / sum_dict[label_i[i]] if label_i[i] != max_i else 1\n",
    "#         )\n",
    "#     weights = event_weights * np.array(weight_factors)\n",
    "\n",
    "#     mean_weight = np.mean(weights)\n",
    "#     abs_weights = np.abs(weights)\n",
    "#     scaled_weights = abs_weights / mean_weight\n",
    "\n",
    "#     return scaled_weights\n",
    "\n",
    "\n",
    "def xgb_labels(labels):\n",
    "    label_i = np.sum(\n",
    "        np.tile([i for i in range(np.shape(labels)[1])], (np.shape(labels)[0], 1)) * labels,\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    return label_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading and Input Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# order = ['ggF HH', 'ttH', 'single-H', 'non-res']\n",
    "order = ['ggF HH', 'ttH', 'VH', 'non-res + ggFH + VBFH']\n",
    "\n",
    "(\n",
    "    sig_rescale_factor,\n",
    "    data_df_dict, data_test_df_dict, \n",
    "    data_hlf_dict, label_dict,\n",
    "    data_hlf_test_dict, label_test_dict, \n",
    "    hlf_vars_columns_dict,\n",
    "    data_aux_dict, data_test_aux_dict\n",
    ") = process_data(\n",
    "    FILEPATHS_DICT, OUTPUT_DIRPATH, order=order, seed=SEED, mod_vals=MOD_VALS,\n",
    "    save=False if 'CURRENT_TIME' in globals() else True,\n",
    "    std_json_dirpath=OUTPUT_DIRPATH if 'CURRENT_TIME' in globals() else None\n",
    ")\n",
    "\n",
    "# Make xgb-like labels (NOT one-hot encoded, but integer encoded for each class)\n",
    "xgb_label_dict = {\n",
    "    f\"fold_{fold_idx}\": copy.deepcopy(xgb_labels(label_dict[f\"fold_{fold_idx}\"])) for fold_idx in range(len(data_test_aux_dict))\n",
    "}\n",
    "xgb_label_test_dict = {\n",
    "    f\"fold_{fold_idx}\": copy.deepcopy(xgb_labels(label_test_dict[f\"fold_{fold_idx}\"])) for fold_idx in range(len(data_test_aux_dict))\n",
    "}\n",
    "\n",
    "# Make weight dicts:\n",
    "#   - the top two are with the training rescale (i.e. rescale sig eventWeight to match bkg and then shift for gradients)\n",
    "#   - the bottom two are the standard eventWeights (i.e. xs * lumi * genWeight) for proper plotting\n",
    "weight_train_dict = {\n",
    "    f\"fold_{fold_idx}\": copy.deepcopy(training_weights(data_aux_dict[f'fold_{fold_idx}'].loc[:, \"eventWeight\"].to_numpy(), label_dict[f'fold_{fold_idx}'], order=order, sig_rescale_factor=sig_rescale_factor)) for fold_idx in range(len(data_aux_dict))\n",
    "}\n",
    "weight_test_dict = {\n",
    "    f'fold_{fold_idx}': copy.deepcopy(training_weights(data_test_aux_dict[f'fold_{fold_idx}'].loc[:, \"eventWeight\"].to_numpy(), label_test_dict[f'fold_{fold_idx}'], order=order, sig_rescale_factor=sig_rescale_factor)) for fold_idx in range(len(data_test_aux_dict))\n",
    "}\n",
    "weights_plot_train_dict = {\n",
    "    f\"fold_{fold_idx}\": copy.deepcopy(data_aux_dict[f'fold_{fold_idx}'].loc[:, \"eventWeight\"].to_numpy()) for fold_idx in range(len(data_aux_dict))\n",
    "}\n",
    "weights_plot_test = {\n",
    "    f'fold_{fold_idx}': copy.deepcopy(data_test_aux_dict[f'fold_{fold_idx}'].loc[:, \"eventWeight\"].to_numpy()) for fold_idx in range(len(data_test_aux_dict))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "Num train: 1250553 -> 109307 sig & 221805 ttH bkg & 107774 single-H bkg & 811667 non-res bkg\n",
      "Num val: 312639 -> 27223 sig & 55400 ttH bkg & 26867 single-H bkg & 203149 non-res bkg\n",
      "Num test: 391785 -> 34224 sig & 69297 ttH bkg & 33713 single-H bkg & & 254551 non-res bkg\n",
      "============================================================\n",
      "fold 1\n",
      "Num train: 1251336 -> 108971 sig & 221976 ttH bkg & 107779 single-H bkg & 812610 non-res bkg\n",
      "Num val: 312835 -> 27495 sig & 55476 ttH bkg & 26926 single-H bkg & 202938 non-res bkg\n",
      "Num test: 390806 -> 34288 sig & 69050 ttH bkg & 33649 single-H bkg & & 253819 non-res bkg\n",
      "============================================================\n",
      "fold 2\n",
      "Num train: 1250948 -> 109226 sig & 221194 ttH bkg & 107849 single-H bkg & 812679 non-res bkg\n",
      "Num val: 312737 -> 27412 sig & 55433 ttH bkg & 26970 single-H bkg & 202922 non-res bkg\n",
      "Num test: 391292 -> 34116 sig & 69875 ttH bkg & 33535 single-H bkg & & 253766 non-res bkg\n",
      "============================================================\n",
      "fold 3\n",
      "Num train: 1251535 -> 109249 sig & 221495 ttH bkg & 107625 single-H bkg & 813166 non-res bkg\n",
      "Num val: 312884 -> 27422 sig & 55559 ttH bkg & 26990 single-H bkg & 202913 non-res bkg\n",
      "Num test: 390558 -> 34083 sig & 69448 ttH bkg & 33739 single-H bkg & & 253288 non-res bkg\n",
      "============================================================\n",
      "fold 4\n",
      "Num train: 1251552 -> 109813 sig & 222047 ttH bkg & 107562 single-H bkg & 812130 non-res bkg\n",
      "Num val: 312889 -> 26898 sig & 55623 ttH bkg & 27074 single-H bkg & 203294 non-res bkg\n",
      "Num test: 390536 -> 34043 sig & 68832 ttH bkg & 33718 single-H bkg & & 253943 non-res bkg\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "bdt_train_dict, bdt_val_dict, bdt_test_dict = {}, {}, {}\n",
    "\n",
    "train_data_dict, val_data_dict = {}, {}\n",
    "xgb_label_train_dict, xgb_label_val_dict = {}, {}\n",
    "weights_plot_train, weights_plot_val= {}, {}\n",
    "train_idxs_dict, val_idxs_dict = {}, {}\n",
    "for fold_idx in range(len(data_df_dict)):\n",
    "    if re.search('no_std', VARS) is not None:\n",
    "        print('no standardization')\n",
    "        train_val_data_dict = {key: value.to_numpy() for key, value in data_df_dict.items()}\n",
    "        test_data_dict = {key: value.to_numpy() for key, value in data_test_df_dict.items()}\n",
    "    else:\n",
    "        train_val_data_dict = data_hlf_dict\n",
    "        test_data_dict = data_hlf_test_dict\n",
    "    (\n",
    "        X_train, X_val, \n",
    "        y_train, y_val, \n",
    "        weight_train, weight_val, \n",
    "        weight_plot_train, weight_plot_val,\n",
    "        train_idxs, val_idxs\n",
    "    ) = train_test_split(\n",
    "        train_val_data_dict[f\"fold_{fold_idx}\"], xgb_label_dict[f\"fold_{fold_idx}\"], \n",
    "        weight_train_dict[f\"fold_{fold_idx}\"], weights_plot_train_dict[f\"fold_{fold_idx}\"],\n",
    "        range(len(train_val_data_dict[f\"fold_{fold_idx}\"])),\n",
    "        test_size=0.2, random_state=21\n",
    "    )\n",
    "\n",
    "    train_data_dict[f\"fold_{fold_idx}\"] = copy.deepcopy(X_train)\n",
    "    val_data_dict[f\"fold_{fold_idx}\"] = copy.deepcopy(X_val)\n",
    "\n",
    "    xgb_label_train_dict[f\"fold_{fold_idx}\"] = copy.deepcopy(y_train)\n",
    "    xgb_label_val_dict[f\"fold_{fold_idx}\"] = copy.deepcopy(y_val)\n",
    "\n",
    "    weights_plot_train[f\"fold_{fold_idx}\"] = copy.deepcopy(weight_plot_train)\n",
    "    weights_plot_val[f\"fold_{fold_idx}\"] = copy.deepcopy(weight_plot_val)\n",
    "\n",
    "    train_idxs_dict[f\"fold_{fold_idx}\"] = copy.deepcopy(train_idxs)\n",
    "    val_idxs_dict[f\"fold_{fold_idx}\"] = copy.deepcopy(val_idxs)\n",
    "\n",
    "    bdt_train_dict[f\"fold_{fold_idx}\"] = xgb.DMatrix(\n",
    "        data=X_train, label=y_train, \n",
    "        weight=weight_train,\n",
    "        missing=-999.0, feature_names=list(hlf_vars_columns_dict[f\"fold_{fold_idx}\"])\n",
    "    )\n",
    "    bdt_val_dict[f\"fold_{fold_idx}\"] = xgb.DMatrix(\n",
    "        data=X_val, label=y_val, \n",
    "        weight=weight_val,\n",
    "        missing=-999.0, feature_names=list(hlf_vars_columns_dict[f\"fold_{fold_idx}\"])\n",
    "    )\n",
    "    \n",
    "    bdt_test_dict[f\"fold_{fold_idx}\"] = xgb.DMatrix(\n",
    "        data=test_data_dict[f\"fold_{fold_idx}\"], label=xgb_label_test_dict[f\"fold_{fold_idx}\"], \n",
    "        weight=np.abs(weight_test_dict[f\"fold_{fold_idx}\"]),\n",
    "        missing=-999.0, feature_names=list(hlf_vars_columns_dict[f\"fold_{fold_idx}\"])\n",
    "    )\n",
    "\n",
    "    print(f\"fold {fold_idx}\")\n",
    "    print(f\"Num train: {len(y_train)} -> {sum(y_train == 0)} sig & {sum(y_train == 1)} ttH bkg & {sum(y_train == 2)} single-H bkg & {sum(y_train == 3)} non-res bkg\")\n",
    "    print(f\"Num val: {len(y_val)} -> {sum(y_val == 0)} sig & {sum(y_val == 1)} ttH bkg & {sum(y_val == 2)} single-H bkg & {sum(y_val == 3)} non-res bkg\")\n",
    "    print(f\"Num test: {len(label_test_dict[f'fold_{fold_idx}'])} -> {sum(label_test_dict[f'fold_{fold_idx}'] == np.array([1, 0, 0, 0]))[0]} sig & {sum(label_test_dict[f'fold_{fold_idx}'] == np.array([0, 1, 0, 0]))[1]} ttH bkg & {sum(label_test_dict[f'fold_{fold_idx}'] == np.array([0, 0, 1, 0]))[2]} single-H bkg & & {sum(label_test_dict[f'fold_{fold_idx}'] == np.array([0, 0, 0, 1]))[3]} non-res bkg\")\n",
    "    print('='*60)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Parameterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/57986259/multiclass-classification-with-xgboost-classifier\n",
    "# https://forecastegy.com/posts/xgboost-multiclass-classification-python/\n",
    "# https://indico.cern.ch/event/915265/contributions/3848138/attachments/2048174/3432202/kunlinRan_bbyy_20200531.pdf\n",
    "\n",
    "# https://xgboost.readthedocs.io/en/stable/tutorials/intercept.html - for looking at logits level BDT output\n",
    "# https://indico.cern.ch/event/915265/contributions/3848138/attachments/2048174/3432202/kunlinRan_bbyy_20200531.pdf - ATLAS HHbbgg BDT\n",
    "\n",
    "\n",
    "param = {}\n",
    "\n",
    "# Booster parameters\n",
    "param['eta']              = 0.05 # learning rate\n",
    "num_trees = round(25 / param['eta'])  # number of trees to make\n",
    "param['max_depth']        = 10  # maximum depth of a tree\n",
    "param['subsample']        = 0.5 # fraction of events to train tree on\n",
    "param['colsample_bytree'] = 0.5 # fraction of features to train tree on\n",
    "param['num_class']        = len(order) # num classes for multi-class training\n",
    "\n",
    "# Learning task parameters\n",
    "param['objective']   = 'multi:softprob'   # objective function\n",
    "param['eval_metric'] = 'merror'           # evaluation metric for cross validation\n",
    "param = list(param.items()) + [('eval_metric', 'mlogloss')]\n",
    "# param[\"disable_default_eval_metric\"] = True\n",
    "# param = list(param.items())\n",
    "\n",
    "\n",
    "\n",
    "def thresholded_weighted_merror(predt: np.ndarray, dtrain: xgb.DMatrix, threshold=0.9):\n",
    "    \"\"\"Used when there's no custom objective.\"\"\"\n",
    "    # No need to do transform, XGBoost handles it internally.\n",
    "    weights = dtrain.get_weight()\n",
    "    thresh_weight_merror = np.where(\n",
    "        np.logical_and(\n",
    "            np.max(predt, axis=1) >= threshold,\n",
    "            np.argmax(predt, axis=1) == dtrain.get_label()\n",
    "        ),\n",
    "        0,\n",
    "        weights\n",
    "    )\n",
    "    return f'WeightedMError@{threshold:.2f}', np.sum(thresh_weight_merror)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_hyperparams(\n",
    "    dtrain_dict: dict, dval_dict: dict, dtest_dict: dict, param, verbose: bool=False, verbose_eval=False\n",
    "):  \n",
    "    rng = np.random.default_rng()\n",
    "\n",
    "    space  = [\n",
    "        Real(1e-3, 0.1, \"log-uniform\", name='eta'),\n",
    "        Integer(1, 20, \"uniform\", name='max_depth'),\n",
    "        Real(1e-3, 1., \"log-uniform\", name='subsample'),\n",
    "        Real(0.1, 1., \"uniform\", name='colsample_bytree'),\n",
    "        # Real(1e-4, 1., \"log-uniform\", name='alpha'),\n",
    "        # Real(1e-4, 1., \"log-uniform\", name='lambda'),\n",
    "    ]\n",
    "\n",
    "    score_arrs = []\n",
    "\n",
    "    @use_named_args(space)\n",
    "    def objective(**X):\n",
    "        if verbose:\n",
    "            print(\"New configuration: {}\".format(X))\n",
    "\n",
    "        for key, val in X.items():\n",
    "            param[key] = val\n",
    "        num_trees = round(25 / X['eta'])\n",
    "\n",
    "        # randomly sample a fold to evaluate\n",
    "        fold_idx = rng.integers(0, 4)\n",
    "\n",
    "        evallist = [(dtrain_dict[f\"fold_{fold_idx}\"], 'train'), (dtest_dict[f\"fold_{fold_idx}\"], 'test'), (dval_dict[f\"fold_{fold_idx}\"], 'val')]\n",
    "        booster = xgb.train(\n",
    "            param, dtrain_dict[f\"fold_{fold_idx}\"], num_boost_round=num_trees, \n",
    "            evals=evallist, early_stopping_rounds=10, verbose_eval=verbose_eval,\n",
    "        )\n",
    "\n",
    "        eval_str = booster.eval(dval_dict[f\"fold_{fold_idx}\"], name='val', iteration=booster.best_iteration)\n",
    "\n",
    "        best_mlogloss = float(eval_str[eval_str.find('val-mlogloss:')+len('val-mlogloss:'):])\n",
    "        score_arrs.append(best_mlogloss)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Best val. mlogloss on fold{fold_idx} = {best_mlogloss}\")\n",
    "\n",
    "        return -best_mlogloss\n",
    "    \n",
    "    res_gp = gp_minimize(objective, space)\n",
    "    print(\"Best parameters: {}\".format(res_gp.x))\n",
    "\n",
    "    param['eta'] = float(res_gp.x[0])\n",
    "    param['max_depth'] = int(res_gp.x[1])\n",
    "    param['subsample'] = float(res_gp.x[2])\n",
    "    param['colsample_bytree'] = float(res_gp.x[3])\n",
    "    # param['alpha'] = float(res_gp.x[4])\n",
    "    # param['lambda'] = float(res_gp.x[5])\n",
    "    return param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.11610\ttrain-mlogloss:1.31273\ttest-merror:0.12826\ttest-mlogloss:1.31392\tval-merror:0.12741\tval-mlogloss:1.31428\n",
      "[25]\ttrain-merror:0.03929\ttrain-mlogloss:0.42492\ttest-merror:0.04959\ttest-mlogloss:0.43955\tval-merror:0.05249\tval-mlogloss:0.44284\n",
      "[50]\ttrain-merror:0.03298\ttrain-mlogloss:0.19606\ttest-merror:0.04466\ttest-mlogloss:0.21785\tval-merror:0.04664\tval-mlogloss:0.22241\n",
      "[75]\ttrain-merror:0.03004\ttrain-mlogloss:0.12201\ttest-merror:0.04279\ttest-mlogloss:0.15052\tval-merror:0.04546\tval-mlogloss:0.15560\n",
      "[100]\ttrain-merror:0.02784\ttrain-mlogloss:0.09362\ttest-merror:0.04206\ttest-mlogloss:0.12799\tval-merror:0.04486\tval-mlogloss:0.13337\n",
      "[125]\ttrain-merror:0.02541\ttrain-mlogloss:0.07883\ttest-merror:0.04152\ttest-mlogloss:0.11875\tval-merror:0.04402\tval-mlogloss:0.12434\n",
      "[150]\ttrain-merror:0.02327\ttrain-mlogloss:0.06998\ttest-merror:0.04119\ttest-mlogloss:0.11470\tval-merror:0.04368\tval-mlogloss:0.12052\n",
      "[175]\ttrain-merror:0.02119\ttrain-mlogloss:0.06362\ttest-merror:0.04072\ttest-mlogloss:0.11257\tval-merror:0.04316\tval-mlogloss:0.11858\n",
      "[200]\ttrain-merror:0.01914\ttrain-mlogloss:0.05867\ttest-merror:0.04056\ttest-mlogloss:0.11131\tval-merror:0.04303\tval-mlogloss:0.11754\n",
      "[225]\ttrain-merror:0.01738\ttrain-mlogloss:0.05487\ttest-merror:0.04057\ttest-mlogloss:0.11053\tval-merror:0.04277\tval-mlogloss:0.11689\n",
      "[242]\ttrain-merror:0.01613\ttrain-mlogloss:0.05251\ttest-merror:0.04050\ttest-mlogloss:0.11036\tval-merror:0.04285\tval-mlogloss:0.11682\n",
      "[232]\ttest-merror:0.040498\ttest-mlogloss:0.110358\n",
      "====================================================================================================\n",
      "fold 1\n",
      "[0]\ttrain-merror:0.06906\ttrain-mlogloss:1.30600\ttest-merror:0.08128\ttest-mlogloss:1.30762\tval-merror:0.07844\tval-mlogloss:1.30733\n",
      "[25]\ttrain-merror:0.03860\ttrain-mlogloss:0.41867\ttest-merror:0.04998\ttest-mlogloss:0.43586\tval-merror:0.04968\tval-mlogloss:0.43391\n",
      "[50]\ttrain-merror:0.03346\ttrain-mlogloss:0.19722\ttest-merror:0.04718\ttest-mlogloss:0.22280\tval-merror:0.04652\tval-mlogloss:0.22033\n",
      "[75]\ttrain-merror:0.03035\ttrain-mlogloss:0.12402\ttest-merror:0.04545\ttest-mlogloss:0.15625\tval-merror:0.04453\tval-mlogloss:0.15366\n",
      "[100]\ttrain-merror:0.02764\ttrain-mlogloss:0.09333\ttest-merror:0.04435\ttest-mlogloss:0.13193\tval-merror:0.04348\tval-mlogloss:0.12929\n",
      "[125]\ttrain-merror:0.02551\ttrain-mlogloss:0.07856\ttest-merror:0.04345\ttest-mlogloss:0.12272\tval-merror:0.04269\tval-mlogloss:0.11989\n",
      "[150]\ttrain-merror:0.02329\ttrain-mlogloss:0.06963\ttest-merror:0.04344\ttest-mlogloss:0.11873\tval-merror:0.04249\tval-mlogloss:0.11577\n",
      "[175]\ttrain-merror:0.02114\ttrain-mlogloss:0.06369\ttest-merror:0.04319\ttest-mlogloss:0.11668\tval-merror:0.04174\tval-mlogloss:0.11363\n",
      "[200]\ttrain-merror:0.01930\ttrain-mlogloss:0.05903\ttest-merror:0.04285\ttest-mlogloss:0.11550\tval-merror:0.04170\tval-mlogloss:0.11241\n",
      "[225]\ttrain-merror:0.01756\ttrain-mlogloss:0.05522\ttest-merror:0.04268\ttest-mlogloss:0.11481\tval-merror:0.04139\tval-mlogloss:0.11164\n",
      "[250]\ttrain-merror:0.01559\ttrain-mlogloss:0.05136\ttest-merror:0.04258\ttest-mlogloss:0.11421\tval-merror:0.04117\tval-mlogloss:0.11107\n",
      "[275]\ttrain-merror:0.01381\ttrain-mlogloss:0.04820\ttest-merror:0.04261\ttest-mlogloss:0.11400\tval-merror:0.04153\tval-mlogloss:0.11086\n",
      "[289]\ttrain-merror:0.01262\ttrain-mlogloss:0.04625\ttest-merror:0.04253\ttest-mlogloss:0.11396\tval-merror:0.04112\tval-mlogloss:0.11083\n",
      "[280]\ttest-merror:0.042655\ttest-mlogloss:0.113965\n",
      "====================================================================================================\n",
      "fold 2\n",
      "[0]\ttrain-merror:0.08821\ttrain-mlogloss:1.30819\ttest-merror:0.09970\ttest-mlogloss:1.30961\tval-merror:0.10185\tval-mlogloss:1.30973\n",
      "[25]\ttrain-merror:0.03792\ttrain-mlogloss:0.41674\ttest-merror:0.05085\ttest-mlogloss:0.43543\tval-merror:0.05035\tval-mlogloss:0.43449\n",
      "[50]\ttrain-merror:0.03306\ttrain-mlogloss:0.19521\ttest-merror:0.04709\ttest-mlogloss:0.22203\tval-merror:0.04689\tval-mlogloss:0.22076\n",
      "[75]\ttrain-merror:0.02975\ttrain-mlogloss:0.12204\ttest-merror:0.04529\ttest-mlogloss:0.15596\tval-merror:0.04431\tval-mlogloss:0.15433\n",
      "[100]\ttrain-merror:0.02717\ttrain-mlogloss:0.09223\ttest-merror:0.04431\ttest-mlogloss:0.13234\tval-merror:0.04349\tval-mlogloss:0.13071\n",
      "[125]\ttrain-merror:0.02459\ttrain-mlogloss:0.07712\ttest-merror:0.04364\ttest-mlogloss:0.12285\tval-merror:0.04299\tval-mlogloss:0.12120\n",
      "[150]\ttrain-merror:0.02239\ttrain-mlogloss:0.06820\ttest-merror:0.04342\ttest-mlogloss:0.11892\tval-merror:0.04282\tval-mlogloss:0.11713\n",
      "[175]\ttrain-merror:0.02017\ttrain-mlogloss:0.06174\ttest-merror:0.04272\ttest-mlogloss:0.11701\tval-merror:0.04260\tval-mlogloss:0.11517\n",
      "[200]\ttrain-merror:0.01823\ttrain-mlogloss:0.05722\ttest-merror:0.04264\ttest-mlogloss:0.11582\tval-merror:0.04266\tval-mlogloss:0.11410\n",
      "[225]\ttrain-merror:0.01637\ttrain-mlogloss:0.05316\ttest-merror:0.04239\ttest-mlogloss:0.11498\tval-merror:0.04230\tval-mlogloss:0.11326\n",
      "[250]\ttrain-merror:0.01457\ttrain-mlogloss:0.04957\ttest-merror:0.04221\ttest-mlogloss:0.11450\tval-merror:0.04234\tval-mlogloss:0.11298\n",
      "[275]\ttrain-merror:0.01298\ttrain-mlogloss:0.04676\ttest-merror:0.04219\ttest-mlogloss:0.11427\tval-merror:0.04191\tval-mlogloss:0.11279\n",
      "[300]\ttrain-merror:0.01122\ttrain-mlogloss:0.04392\ttest-merror:0.04223\ttest-mlogloss:0.11435\tval-merror:0.04181\tval-mlogloss:0.11270\n",
      "[306]\ttrain-merror:0.01097\ttrain-mlogloss:0.04335\ttest-merror:0.04221\ttest-mlogloss:0.11435\tval-merror:0.04178\tval-mlogloss:0.11270\n",
      "[296]\ttest-merror:0.042209\ttest-mlogloss:0.114347\n",
      "====================================================================================================\n",
      "fold 3\n",
      "[0]\ttrain-merror:0.05620\ttrain-mlogloss:1.30434\ttest-merror:0.06768\ttest-mlogloss:1.30567\tval-merror:0.06521\tval-mlogloss:1.30578\n",
      "[25]\ttrain-merror:0.03902\ttrain-mlogloss:0.42627\ttest-merror:0.05022\ttest-mlogloss:0.44157\tval-merror:0.05011\tval-mlogloss:0.44139\n",
      "[50]\ttrain-merror:0.03396\ttrain-mlogloss:0.20103\ttest-merror:0.04648\ttest-mlogloss:0.22380\tval-merror:0.04589\tval-mlogloss:0.22309\n",
      "[75]\ttrain-merror:0.03047\ttrain-mlogloss:0.12526\ttest-merror:0.04366\ttest-mlogloss:0.15451\tval-merror:0.04364\tval-mlogloss:0.15359\n",
      "[100]\ttrain-merror:0.02794\ttrain-mlogloss:0.09548\ttest-merror:0.04234\ttest-mlogloss:0.13051\tval-merror:0.04268\tval-mlogloss:0.12944\n",
      "[125]\ttrain-merror:0.02530\ttrain-mlogloss:0.08029\ttest-merror:0.04157\ttest-mlogloss:0.12056\tval-merror:0.04188\tval-mlogloss:0.11940\n",
      "[150]\ttrain-merror:0.02312\ttrain-mlogloss:0.07073\ttest-merror:0.04112\ttest-mlogloss:0.11590\tval-merror:0.04126\tval-mlogloss:0.11457\n",
      "[175]\ttrain-merror:0.02113\ttrain-mlogloss:0.06428\ttest-merror:0.04088\ttest-mlogloss:0.11372\tval-merror:0.04093\tval-mlogloss:0.11226\n",
      "[200]\ttrain-merror:0.01934\ttrain-mlogloss:0.05964\ttest-merror:0.04067\ttest-mlogloss:0.11253\tval-merror:0.04068\tval-mlogloss:0.11093\n",
      "[225]\ttrain-merror:0.01737\ttrain-mlogloss:0.05534\ttest-merror:0.04069\ttest-mlogloss:0.11187\tval-merror:0.04058\tval-mlogloss:0.11030\n",
      "[250]\ttrain-merror:0.01563\ttrain-mlogloss:0.05178\ttest-merror:0.04054\ttest-mlogloss:0.11133\tval-merror:0.04047\tval-mlogloss:0.10971\n",
      "[275]\ttrain-merror:0.01407\ttrain-mlogloss:0.04889\ttest-merror:0.04018\ttest-mlogloss:0.11101\tval-merror:0.04011\tval-mlogloss:0.10937\n",
      "[300]\ttrain-merror:0.01234\ttrain-mlogloss:0.04588\ttest-merror:0.04050\ttest-mlogloss:0.11097\tval-merror:0.04011\tval-mlogloss:0.10913\n",
      "[325]\ttrain-merror:0.01068\ttrain-mlogloss:0.04315\ttest-merror:0.04035\ttest-mlogloss:0.11073\tval-merror:0.04016\tval-mlogloss:0.10896\n",
      "[328]\ttrain-merror:0.01042\ttrain-mlogloss:0.04280\ttest-merror:0.04040\ttest-mlogloss:0.11072\tval-merror:0.04007\tval-mlogloss:0.10896\n",
      "[318]\ttest-merror:0.040399\ttest-mlogloss:0.110724\n",
      "====================================================================================================\n",
      "fold 4\n",
      "[0]\ttrain-merror:0.10008\ttrain-mlogloss:1.31032\ttest-merror:0.11297\ttest-mlogloss:1.31201\tval-merror:0.11319\tval-mlogloss:1.31185\n",
      "[25]\ttrain-merror:0.03806\ttrain-mlogloss:0.42095\ttest-merror:0.04926\ttest-mlogloss:0.43643\tval-merror:0.04763\tval-mlogloss:0.43589\n",
      "[50]\ttrain-merror:0.03283\ttrain-mlogloss:0.19661\ttest-merror:0.04540\ttest-mlogloss:0.21972\tval-merror:0.04474\tval-mlogloss:0.21899\n",
      "[75]\ttrain-merror:0.03000\ttrain-mlogloss:0.12361\ttest-merror:0.04406\ttest-mlogloss:0.15370\tval-merror:0.04358\tval-mlogloss:0.15289\n",
      "[100]\ttrain-merror:0.02764\ttrain-mlogloss:0.09364\ttest-merror:0.04319\ttest-mlogloss:0.13004\tval-merror:0.04308\tval-mlogloss:0.12903\n",
      "[125]\ttrain-merror:0.02515\ttrain-mlogloss:0.07883\ttest-merror:0.04259\ttest-mlogloss:0.12082\tval-merror:0.04204\tval-mlogloss:0.11995\n",
      "[150]\ttrain-merror:0.02304\ttrain-mlogloss:0.06972\ttest-merror:0.04217\ttest-mlogloss:0.11660\tval-merror:0.04205\tval-mlogloss:0.11578\n",
      "[175]\ttrain-merror:0.02115\ttrain-mlogloss:0.06365\ttest-merror:0.04178\ttest-mlogloss:0.11454\tval-merror:0.04157\tval-mlogloss:0.11370\n",
      "[200]\ttrain-merror:0.01923\ttrain-mlogloss:0.05884\ttest-merror:0.04182\ttest-mlogloss:0.11342\tval-merror:0.04135\tval-mlogloss:0.11271\n",
      "[225]\ttrain-merror:0.01723\ttrain-mlogloss:0.05477\ttest-merror:0.04159\ttest-mlogloss:0.11285\tval-merror:0.04149\tval-mlogloss:0.11212\n",
      "[250]\ttrain-merror:0.01537\ttrain-mlogloss:0.05118\ttest-merror:0.04179\ttest-mlogloss:0.11250\tval-merror:0.04134\tval-mlogloss:0.11167\n",
      "[275]\ttrain-merror:0.01377\ttrain-mlogloss:0.04815\ttest-merror:0.04155\ttest-mlogloss:0.11226\tval-merror:0.04113\tval-mlogloss:0.11134\n",
      "[300]\ttrain-merror:0.01192\ttrain-mlogloss:0.04505\ttest-merror:0.04142\ttest-mlogloss:0.11202\tval-merror:0.04134\tval-mlogloss:0.11105\n",
      "[311]\ttrain-merror:0.01122\ttrain-mlogloss:0.04389\ttest-merror:0.04128\ttest-mlogloss:0.11200\tval-merror:0.04151\tval-mlogloss:0.11108\n",
      "[302]\ttest-merror:0.041291\ttest-mlogloss:0.112004\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "if 'CURRENT_TIME' in globals():\n",
    "    OUTPUT_DIRPATH, OLD_TIME = os.path.split(OUTPUT_DIRPATH)\n",
    "CURRENT_TIME = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "OUTPUT_DIRPATH = os.path.join(OUTPUT_DIRPATH, CURRENT_TIME)\n",
    "if not os.path.exists(OUTPUT_DIRPATH):\n",
    "    os.makedirs(OUTPUT_DIRPATH)\n",
    "\n",
    "if OPTIMIZE_SPACE:\n",
    "\n",
    "    print('OPTIMIZING SPACE')\n",
    "\n",
    "    param_dict = {}\n",
    "    for name, value in param:\n",
    "        if value == 'merror':\n",
    "            continue\n",
    "        param_dict[name] = value\n",
    "        \n",
    "    param = optimize_hyperparams(bdt_train_dict, bdt_val_dict, bdt_test_dict, param_dict, verbose=True, verbose_eval=50)\n",
    "\n",
    "    with open(os.path.join(OUTPUT_DIRPATH, f'{CURRENT_TIME}_best_params.json'), 'w') as f:\n",
    "        json.dump(param, f)\n",
    "        print(param)\n",
    "\n",
    "    param['eval_metric'] = 'merror'\n",
    "    param = list(param.items()) + [('eval_metric', 'mlogloss')]\n",
    "\n",
    "evals_result_dict = {f\"fold_{fold_idx}\": dict() for fold_idx in range(len(bdt_train_dict))}\n",
    "for fold_idx in range(len(bdt_train_dict)):\n",
    "    print(f\"fold {fold_idx}\")\n",
    "    # Train bdt\n",
    "    evallist = [(bdt_train_dict[f\"fold_{fold_idx}\"], 'train'), (bdt_test_dict[f\"fold_{fold_idx}\"], 'test'), (bdt_val_dict[f\"fold_{fold_idx}\"], 'val')]\n",
    "    booster = xgb.train(\n",
    "        param, bdt_train_dict[f\"fold_{fold_idx}\"], num_boost_round=num_trees, \n",
    "        evals=evallist, early_stopping_rounds=10, verbose_eval=25, evals_result=evals_result_dict[f\"fold_{fold_idx}\"],\n",
    "        # custom_metric=thresholded_weighted_merror\n",
    "    )\n",
    "\n",
    "    booster.save_model(os.path.join(OUTPUT_DIRPATH, f'{CURRENT_TIME}_BDT_fold{fold_idx}.model'))\n",
    "    \n",
    "    # Print perf on test dataset\n",
    "    print(booster.eval(bdt_test_dict[f\"fold_{fold_idx}\"], name='test', iteration=booster.best_iteration))\n",
    "    print('='*100)\n",
    "\n",
    "with open(os.path.join(OUTPUT_DIRPATH, f'{CURRENT_TIME}_BDT_eval_result.json'), 'w') as f:\n",
    "    json.dump(evals_result_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance (ROC) Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_tpr = np.linspace(0, 1, 5000)  # copied from IN evaluate.py file\n",
    "roc_baseline = np.zeros(\n",
    "    (len(bdt_train_dict), len(base_tpr), len(order)), \n",
    "    dtype=float\n",
    ")\n",
    "area_baseline = np.zeros(\n",
    "    (len(bdt_train_dict), len(order)), \n",
    "    dtype=float\n",
    ")\n",
    "\n",
    "if 'old_test_dicts' in globals():\n",
    "    data_hlf_test_dict = copy.deepcopy(old_test_dicts['data_hlf_test_dict'])\n",
    "    data_test_aux_dict = copy.deepcopy(old_test_dicts['data_test_aux_dict'])\n",
    "    weight_test_dict = copy.deepcopy(old_test_dicts['weight_test_dict'])\n",
    "    weights_plot_test = copy.deepcopy(old_test_dicts['weights_plot_test'])\n",
    "    xgb_label_test_dict = copy.deepcopy(old_test_dicts['xgb_label_test_dict'])\n",
    "\n",
    "BDT_perf = {\n",
    "    sample_name: copy.deepcopy({\n",
    "        'base_tpr': base_tpr,\n",
    "        'class_order': copy.deepcopy(order),\n",
    "        # test data #\n",
    "        'preds': [],\n",
    "        'fprs_density': copy.deepcopy(roc_baseline), 'thresholds_density': copy.deepcopy(roc_baseline), 'areas_density': copy.deepcopy(area_baseline),\n",
    "        'fprs_weighted': copy.deepcopy(roc_baseline), 'thresholds_weighted': copy.deepcopy(roc_baseline), 'areas_weighted': copy.deepcopy(area_baseline),\n",
    "        'fprs_sum_density': copy.deepcopy(roc_baseline[0, ...]), 'thresholds_sum_density': copy.deepcopy(roc_baseline[0, ...]), 'areas_sum_density': copy.deepcopy(area_baseline[0, ...]),\n",
    "        'fprs_sum_weighted': copy.deepcopy(roc_baseline[0, ...]), 'thresholds_sum_weighted': copy.deepcopy(roc_baseline[0, ...]), 'areas_sum_weighted': copy.deepcopy(area_baseline[0, ...]),\n",
    "        # train data #\n",
    "        'train_preds': [], \n",
    "        'train_fprs_density': copy.deepcopy(roc_baseline), 'train_thresholds_density': copy.deepcopy(roc_baseline), 'train_areas_density': copy.deepcopy(area_baseline),\n",
    "        'train_fprs_weighted': copy.deepcopy(roc_baseline), 'train_thresholds_weighted': copy.deepcopy(roc_baseline), 'train_areas_weighted': copy.deepcopy(area_baseline),\n",
    "        'train_fprs_sum_density': copy.deepcopy(roc_baseline[0, ...]), 'train_thresholds_sum_density': copy.deepcopy(roc_baseline[0, ...]), 'train_areas_sum_density': copy.deepcopy(area_baseline[0, ...]),\n",
    "        'train_fprs_sum_weighted': copy.deepcopy(roc_baseline[0, ...]), 'train_thresholds_sum_weighted': copy.deepcopy(roc_baseline[0, ...]), 'train_areas_sum_weighted': copy.deepcopy(area_baseline[0, ...]),\n",
    "        # val data #\n",
    "        'val_preds': [],\n",
    "        'val_fprs_density': copy.deepcopy(roc_baseline), 'val_thresholds_density': copy.deepcopy(roc_baseline), 'val_areas_density': copy.deepcopy(area_baseline),\n",
    "        'val_fprs_weighted': copy.deepcopy(roc_baseline), 'val_thresholds_weighted': copy.deepcopy(roc_baseline), 'val_areas_weighted': copy.deepcopy(area_baseline),\n",
    "        'val_fprs_sum_density': copy.deepcopy(roc_baseline[0, ...]), 'val_thresholds_sum_density': copy.deepcopy(roc_baseline[0, ...]), 'val_areas_sum_density': copy.deepcopy(area_baseline[0, ...]),\n",
    "        'val_fprs_sum_weighted': copy.deepcopy(roc_baseline[0, ...]), 'val_thresholds_sum_weighted': copy.deepcopy(roc_baseline[0, ...]), 'val_areas_sum_weighted': copy.deepcopy(area_baseline[0, ...]),\n",
    "    }) for sample_name in order\n",
    "}\n",
    "\n",
    "for j, sample_name in enumerate(order):\n",
    "\n",
    "    for fold_idx in range(len(bdt_train_dict)):\n",
    "        booster = xgb.Booster(param)\n",
    "        booster.load_model(os.path.join(OUTPUT_DIRPATH, f'{CURRENT_TIME}_BDT_fold{fold_idx}.model'))\n",
    "    \n",
    "        for pred_type, dataset in [\n",
    "            ('train_', bdt_train_dict[f\"fold_{fold_idx}\"]),\n",
    "            ('val_', bdt_val_dict[f\"fold_{fold_idx}\"]),\n",
    "            ('', bdt_test_dict[f\"fold_{fold_idx}\"])\n",
    "        ]:\n",
    "            \n",
    "            BDT_perf[sample_name][pred_type + 'preds'].append(\n",
    "                booster.predict(\n",
    "                    dataset, \n",
    "                    iteration_range=(0, booster.best_iteration+1)\n",
    "                ).tolist()\n",
    "            )\n",
    "\n",
    "            for i, sample_name_ in enumerate(order):\n",
    "                \n",
    "                if sample_name_ == sample_name:\n",
    "                    event_mask = dataset.get_label() > -1\n",
    "                    pred_rescale = np.ones_like(event_mask)\n",
    "                else:\n",
    "                    event_mask = np.logical_or(dataset.get_label() == j, dataset.get_label() == i)\n",
    "                    pred_rescale = np.array(BDT_perf[sample_name][pred_type + 'preds'][-1])[:, j][event_mask] + np.array(BDT_perf[sample_name][pred_type + 'preds'][-1])[:, i][event_mask]\n",
    "                class_preds = np.array(BDT_perf[sample_name][pred_type + 'preds'][-1])[:, j][event_mask] / pred_rescale\n",
    "                class_truths = np.where(dataset.get_label() == j, 1, 0)[event_mask]\n",
    "                \n",
    "                for roc_type in ['density', 'weighted']:\n",
    "\n",
    "                    if roc_type == 'weighted':\n",
    "                        if re.search('train', pred_type) is not None:\n",
    "                            roc_weights = weights_plot_train[f\"fold_{fold_idx}\"][event_mask]\n",
    "                        elif re.search('val', pred_type) is not None:\n",
    "                            roc_weights = weights_plot_val[f\"fold_{fold_idx}\"][event_mask]\n",
    "                        else:\n",
    "                            roc_weights = weights_plot_test[f\"fold_{fold_idx}\"][event_mask]\n",
    "                    else:\n",
    "                        roc_weights = None\n",
    "\n",
    "                    fpr_bdt, tpr_bdt, threshold_bdt = roc_curve(class_truths, class_preds, sample_weight=roc_weights)\n",
    "                    fpr_bdt = np.interp(base_tpr, tpr_bdt, fpr_bdt)\n",
    "                    threshold_bdt = np.interp(base_tpr, tpr_bdt, threshold_bdt)\n",
    "\n",
    "                    BDT_perf[sample_name][pred_type + 'fprs_' + roc_type][fold_idx][:, i] = fpr_bdt\n",
    "                    BDT_perf[sample_name][pred_type + 'thresholds_' + roc_type][fold_idx][:, i] = threshold_bdt\n",
    "                    BDT_perf[sample_name][pred_type + 'areas_' + roc_type][fold_idx][i] = float(trapezoid(base_tpr, fpr_bdt))\n",
    "    \n",
    "    for pred_type, dataset_dict in [\n",
    "        ('train_', bdt_train_dict),\n",
    "        ('val_', bdt_val_dict),\n",
    "        ('', bdt_test_dict)\n",
    "    ]:\n",
    "\n",
    "        flat_preds = np.concatenate(BDT_perf[sample_name][f'{pred_type}preds'], axis=0)\n",
    "        flat_truths = np.concatenate([dataset_dict[f\"fold_{fold_idx}\"].get_label() for fold_idx in range(len(dataset_dict))], axis=0)\n",
    "\n",
    "        for i, sample_name_ in enumerate(order):\n",
    "            \n",
    "            if sample_name_ == sample_name:\n",
    "                event_mask = flat_truths > -1\n",
    "                pred_rescale = np.ones_like(event_mask)\n",
    "            else:\n",
    "                event_mask = np.logical_or(flat_truths == j, flat_truths == i)\n",
    "                pred_rescale = flat_preds[:, j][event_mask] + flat_preds[:, i][event_mask]\n",
    "            class_preds = flat_preds[:, j][event_mask] / pred_rescale\n",
    "            class_truths = np.where(flat_truths == j, 1, 0)[event_mask]\n",
    "            \n",
    "            for roc_type in ['density', 'weighted']:\n",
    "\n",
    "                if roc_type == 'weighted':\n",
    "                    if re.search('train', pred_type) is not None:\n",
    "                        roc_weights = np.concatenate([weights_plot_train[f\"fold_{fold_idx}\"] for fold_idx in range(len(weights_plot_train))], axis=0)[event_mask]\n",
    "                    elif re.search('val', pred_type) is not None:\n",
    "                        roc_weights = np.concatenate([weights_plot_val[f\"fold_{fold_idx}\"] for fold_idx in range(len(weights_plot_val))], axis=0)[event_mask]\n",
    "                    else:\n",
    "                        roc_weights = np.concatenate([weights_plot_test[f\"fold_{fold_idx}\"] for fold_idx in range(len(weights_plot_test))], axis=0)[event_mask]\n",
    "                else:\n",
    "                    roc_weights = None\n",
    "\n",
    "                fpr_bdt, tpr_bdt, threshold_bdt = roc_curve(class_truths, class_preds, sample_weight=roc_weights)\n",
    "                fpr_bdt = np.interp(base_tpr, tpr_bdt, fpr_bdt)\n",
    "                threshold_bdt = np.interp(base_tpr, tpr_bdt, threshold_bdt)\n",
    "\n",
    "                BDT_perf[sample_name][pred_type + 'fprs_sum_' + roc_type][:, i] = fpr_bdt\n",
    "                BDT_perf[sample_name][pred_type + 'thresholds_sum_' + roc_type][:, i] = threshold_bdt\n",
    "                BDT_perf[sample_name][pred_type + 'areas_sum_' + roc_type][i] = float(trapezoid(base_tpr, fpr_bdt))\n",
    "    \n",
    "    for key in BDT_perf[sample_name].keys():\n",
    "        if type(BDT_perf[sample_name][key]) is list:\n",
    "            continue\n",
    "        BDT_perf[sample_name][key] = BDT_perf[sample_name][key].tolist()\n",
    "\n",
    "\n",
    "with open(os.path.join(OUTPUT_DIRPATH, CURRENT_TIME+f\"_BDT_perf.json\"), 'w') as f:\n",
    "    json.dump(BDT_perf, f)\n",
    "\n",
    "# if RESAMPLE:\n",
    "#     data_hlf_test_dict = old_test_dicts['data_hlf_test_dict']\n",
    "#     weight_test_dict = old_test_dicts['weight_test_dict']\n",
    "#     weights_plot_test = old_test_dicts['weights_plot_test']\n",
    "#     xgb_label_test_dict = old_test_dicts['xgb_label_test_dict']\n",
    "\n",
    "#     for fold_idx in range(len(bdt_train_dict)):\n",
    "#         bdt_test_dict[f\"fold_{fold_idx}\"] = xgb.DMatrix(\n",
    "#             data=data_hlf_test_dict[f\"fold_{fold_idx}\"], label=xgb_label_test_dict[f\"fold_{fold_idx}\"], \n",
    "#             weight=np.abs(weight_test_dict[f\"fold_{fold_idx}\"]),\n",
    "#             missing=-999.0, feature_names=list(hlf_vars_columns_dict[f\"fold_{fold_idx}\"])\n",
    "#         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_list(list_of_lists):\n",
    "    max_length = np.max([len(list_i) for list_i in list_of_lists])\n",
    "    for list_i in list_of_lists:\n",
    "        while len(list_i) < max_length:\n",
    "            list_i.append(list_i[-1])\n",
    "\n",
    "    return list_of_lists\n",
    "\n",
    "def plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix, format='png'):\n",
    "    plot_prefix = plot_prefix + ('_' if plot_prefix != '' else '')\n",
    "    plot_postfix = plot_postfix + ('_' if plot_postfix != '' else '')\n",
    "    plot_name = plot_prefix + plot_name + plot_postfix + f'.{format}'\n",
    "\n",
    "    plot_filepath = os.path.join(plot_dirpath, plot_name)\n",
    "    return plot_filepath\n",
    "\n",
    "def plot_train_val_losses(\n",
    "    losses_arrs, labels, plot_name, plot_dirpath, \n",
    "    plot_prefix='', plot_postfix='', linestyles=None,\n",
    "    losses_std_arrs=None\n",
    "):\n",
    "    plt.figure(figsize=(9,7))\n",
    "    \n",
    "    if type(losses_arrs[0]) is float:\n",
    "        losses_arrs = [losses_arrs]\n",
    "    if linestyles is None:\n",
    "        linestyles = ['solid'] * len(losses_arrs)\n",
    "    if labels is None:\n",
    "        labels = [i for i in range(len(losses_arrs))]\n",
    "\n",
    "    if losses_std_arrs is not None:\n",
    "        for i in range(len(losses_std_arrs)):\n",
    "            plt.fill_between(\n",
    "                range(len(losses_std_arrs[i])), \n",
    "                losses_arrs[i]+losses_std_arrs[i], losses_arrs[i]-losses_std_arrs[i],\n",
    "                alpha=0.7\n",
    "            )\n",
    "\n",
    "    for i in range(len(losses_arrs)):\n",
    "        plt.plot(\n",
    "            range(len(losses_arrs[i])), \n",
    "            losses_arrs[i], \n",
    "            label=f\"{labels[i]} losses\", linestyle=linestyles[i],\n",
    "            alpha=0.7\n",
    "        )\n",
    "        \n",
    "    plt.legend(bbox_to_anchor=(1, 1))\n",
    "    plt.xlabel('EPOCH')\n",
    "    plt.ylabel('Data Loss')\n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix, format='pdf'), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.close()\n",
    "\n",
    "def plot_rocs(\n",
    "    fprs, tprs, labels, plot_name, plot_dirpath,\n",
    "    plot_prefix='', plot_postfix='', close=True, log=None\n",
    "):\n",
    "    plt.figure(figsize=(9,7))\n",
    "    \n",
    "    for fpr, tpr, label in zip(fprs, tprs, labels):\n",
    "        linestyle = 'solid' if re.search('IN', label) is not None else ('dashed' if re.search('BDT', label) is not None else 'dotted')\n",
    "        plt.plot(fpr, tpr, label=label, linestyle=linestyle)\n",
    "\n",
    "    plt.legend(bbox_to_anchor=(1, 1))\n",
    "    plt.xlabel('Background contamination')\n",
    "    plt.ylabel('Signal efficiency')\n",
    "    if log is not None and re.search('x', log) is not None:\n",
    "        plt.xscale('log')\n",
    "    elif log is not None and re.search('y', log) is not None:\n",
    "        plt.yscale('log')\n",
    "    \n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix, format='pdf'), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    if close:\n",
    "        plt.close()\n",
    "\n",
    "def plot_output_scores(\n",
    "    sigs_and_bkgs, order, plot_name, plot_dirpath,\n",
    "    plot_prefix='', plot_postfix='', bins=1000, weights=None, log=False, arctanh=False\n",
    "):\n",
    "    plt.figure(figsize=(9,7))\n",
    "\n",
    "    if arctanh:\n",
    "        end_point = 6.\n",
    "    else:\n",
    "        end_point = 1.\n",
    "    hist_axis = hist.axis.Regular(bins, 0., end_point, name='var', growth=False, underflow=False, overflow=False)\n",
    "    hists, labels = [], []\n",
    "    for sample_name in order:\n",
    "        if sample_name not in sigs_and_bkgs:\n",
    "            continue\n",
    "        hists.append(\n",
    "            hist.Hist(hist_axis, storage='weight').fill(\n",
    "                var=sigs_and_bkgs[sample_name], \n",
    "                weight=weights[sample_name] if weights is not None else np.ones_like(sigs_and_bkgs[sample_name])\n",
    "            )\n",
    "        )\n",
    "        labels.append(sample_name)\n",
    "    hep.histplot(\n",
    "        hists,\n",
    "        yerr=(True if weights is not None else False),\n",
    "        alpha=0.2, density=(False if weights is not None else True), histtype='step',\n",
    "        label=labels\n",
    "    )\n",
    "\n",
    "    plt.legend(bbox_to_anchor=(1, 1))\n",
    "    plt.xlabel('Output score')\n",
    "    if log:\n",
    "        plt.yscale('log')\n",
    "    \n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix, format='pdf'), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.close()\n",
    "\n",
    "def plot_s_over_root_b(\n",
    "    sig, bkg, label, plot_name, plot_dirpath,\n",
    "    plot_prefix='', plot_postfix='', bins=1000, weights={'sig': None, 'bkg': None},\n",
    "    lines=None, lines_labels=None, line_colors=None, arctanh=False\n",
    "):\n",
    "    plt.figure(figsize=(9,7))\n",
    "\n",
    "    if arctanh:\n",
    "        end_point = 6.\n",
    "        hist_axis = hist.axis.Regular(bins, 0., end_point, name='var', growth=False, underflow=False, overflow=False)\n",
    "    else:\n",
    "        end_point = 1.\n",
    "        hist_axis = hist.axis.Regular(bins, 0., end_point, name='var', growth=False, underflow=False, overflow=False)\n",
    "    sig_hist = hist.Hist(hist_axis, storage='weight').fill(var=sig, weight=weights['sig'] if weights['sig'] is not None else np.ones_like(sig))\n",
    "    bkg_hist = hist.Hist(hist_axis, storage='weight').fill(var=bkg, weight=weights['bkg'] if weights['bkg'] is not None else np.ones_like(bkg))\n",
    "    s_over_root_b_points = sig_hist.values().flatten() / np.sqrt(bkg_hist.values().flatten())\n",
    "    plt.plot(\n",
    "        np.arange(0., end_point, end_point*(1/bins)), s_over_root_b_points, \n",
    "        label=f'{label} - s/âb', alpha=0.8\n",
    "    )\n",
    "\n",
    "    if lines is not None:\n",
    "        for i in range(len(lines)):\n",
    "            plt.vlines(\n",
    "                lines[i], 0, np.max(s_over_root_b_points), \n",
    "                label='s/âb'+(' - '+lines_labels[i] if lines_labels is not None else ''), \n",
    "                alpha=0.5, colors=line_colors[i]\n",
    "            )\n",
    "    \n",
    "    plt.legend(bbox_to_anchor=(1, 1))\n",
    "    plt.xlabel('Output score')\n",
    "    plt.ylabel('s/âb')\n",
    "    \n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix, format='pdf'), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.close()\n",
    "\n",
    "def plot_confusion_matrix(\n",
    "    conf_matrix, class_labels, plot_name, plot_dirpath, \n",
    "    plot_prefix='', plot_postfix=''\n",
    "):\n",
    "    plt.figure(figsize=(9,7))\n",
    "\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=class_labels)\n",
    "    disp.plot(im_kw={'norm': 'log'})\n",
    "    \n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix, format='pdf'), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.close()\n",
    "\n",
    "def plot_feature_importance(\n",
    "    feature_scores, feature_labels, plot_name, plot_dirpath, \n",
    "    plot_prefix='', plot_postfix='', fscore_method='total_gain', log=True\n",
    "):\n",
    "    plt.figure(figsize=(18,14))\n",
    "\n",
    "    plt.barh(\n",
    "        np.arange(len(feature_scores)), feature_scores, align='center'\n",
    "    )\n",
    "    plt.yticks(np.arange(len(feature_scores)), feature_labels, fontsize=8)\n",
    "    plt.ylabel('Features')\n",
    "    plt.xlabel(f'F score ({fscore_method})')\n",
    "    if log:\n",
    "        plt.xscale('log')\n",
    "    \n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix, format='pdf'), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_cut_boundaries(sigs, bkgs, weights, bins=10000, arctanh=False):\n",
    "    hist_list_fold = []\n",
    "    cut_boundaries_fold = []\n",
    "    cut_s_over_root_bs_fold = []\n",
    "    sig_weights_fold = []\n",
    "    bkg_weights_fold = []\n",
    "    if len(np.shape(sigs)) == 1:\n",
    "        sigs, bkgs = [sigs], [bkgs] \n",
    "    if arctanh:\n",
    "        end_point = 6.\n",
    "    else:\n",
    "        end_point = 1.\n",
    "    for sig, bkg in zip(sigs, bkgs):\n",
    "        hist_axis = hist.axis.Regular(bins, 0., end_point, name='var', growth=False, underflow=False, overflow=False)\n",
    "        sig_hist = hist.Hist(hist_axis, storage='weight').fill(var=sig, weight=weights['sig'])\n",
    "        bkg_hist = hist.Hist(hist_axis, storage='weight').fill(var=bkg, weight=weights['bkg'])\n",
    "        hist_list_fold.append({'sig': copy.deepcopy(sig_hist), 'bkg': copy.deepcopy(bkg_hist)})\n",
    "\n",
    "        fold_idx_cuts_bins_inclusive = []\n",
    "        fold_idx_sig_weights = []\n",
    "        fold_idx_bkg_weights = []\n",
    "        fold_idx_prev_s_over_root_b = []\n",
    "        prev_s_over_root_b = 0\n",
    "        for i in range(bins):\n",
    "            s = np.sum(sig_hist.values().flatten()[\n",
    "                (bins-1) - i : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "            ])\n",
    "            sqrt_b = np.sqrt(np.sum(bkg_hist.values().flatten()[\n",
    "                (bins-1) - i : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "            ]))\n",
    "            if prev_s_over_root_b < (s / sqrt_b) or s < 0.25:\n",
    "                prev_s_over_root_b = s / sqrt_b\n",
    "                continue\n",
    "            else:\n",
    "                fold_idx_sig_weights.append(\n",
    "                    {\n",
    "                        'value': np.sum(sig_hist.values().flatten()[\n",
    "                            (bins) - i : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                        ]),\n",
    "                        'w2': np.sqrt(np.sum(sig_hist.variances().flatten()[\n",
    "                            (bins) - i : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                        ])),\n",
    "                    }\n",
    "                )\n",
    "                fold_idx_bkg_weights.append(\n",
    "                    {\n",
    "                        'value': np.sum(bkg_hist.values().flatten()[\n",
    "                            (bins) - i : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                        ]),\n",
    "                        'w2': np.sqrt(np.sum(bkg_hist.variances().flatten()[\n",
    "                            (bins) - i : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                        ])),\n",
    "                    }\n",
    "                )\n",
    "                fold_idx_cuts_bins_inclusive.append(bins - i)\n",
    "                fold_idx_prev_s_over_root_b.append(prev_s_over_root_b)\n",
    "                prev_s_over_root_b = 0\n",
    "        fold_idx_sig_weights.append(\n",
    "            {\n",
    "                'value': np.sum(sig_hist.values().flatten()[\n",
    "                    0 : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                ]),\n",
    "                'w2': np.sqrt(np.sum(sig_hist.variances().flatten()[\n",
    "                    0 : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                ])),\n",
    "            }\n",
    "        )\n",
    "        fold_idx_bkg_weights.append(\n",
    "            {\n",
    "                'value': np.sum(bkg_hist.values().flatten()[\n",
    "                    0 : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                ]),\n",
    "                'w2': np.sqrt(np.sum(bkg_hist.variances().flatten()[\n",
    "                    0 : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                ])),\n",
    "            }\n",
    "        )\n",
    "        fold_idx_cuts_bins_inclusive.append(0)\n",
    "        fold_idx_prev_s_over_root_b.append(prev_s_over_root_b)\n",
    "        fold_idx_score_cuts = [end_point * (bin_i / bins) for bin_i in fold_idx_cuts_bins_inclusive]\n",
    "        cut_boundaries_fold.append(fold_idx_score_cuts)\n",
    "        cut_s_over_root_bs_fold.append(fold_idx_prev_s_over_root_b)\n",
    "        sig_weights_fold.append(fold_idx_sig_weights)\n",
    "        bkg_weights_fold.append(fold_idx_bkg_weights)\n",
    "    return cut_boundaries_fold, cut_s_over_root_bs_fold, sig_weights_fold, bkg_weights_fold\n",
    "\n",
    "def p_to_xyz(p, split=True):  # makes a tetrahedron with height 1 and vertices {(0, 0, 0),  (â3/2, 0, â3/2),  (0, â3/2, â3/2),  (â3/2, â3/2, 0)}\n",
    "    rt3o2 = np.sqrt(3) / 2\n",
    "\n",
    "    x = rt3o2 * (0*p[:, 0] + p[:, 1] + p[:, 2] + 0*p[:, 3])\n",
    "    y = rt3o2 * (0*p[:, 0] + 0*p[:, 1] + p[:, 2] + p[:, 3])\n",
    "    z = rt3o2 * (0*p[:, 0] + p[:, 1] + 0*p[:, 2] + p[:, 3])\n",
    "\n",
    "    if split:\n",
    "        return x, y, z\n",
    "    else:\n",
    "        return np.column_stack((x, y, z))\n",
    "\n",
    "def optimize_cuts(\n",
    "    preds: np.ndarray, binary_labels: np.ndarray, weights: np.ndarray,\n",
    "    init_guess=[1e-9, 2e-3, 1e-2], param_names=['r1', 'r2', 'r3'], param_range=[(1e-11, 1e-4), (1e-3, 5e-2), (0., 1.)], \n",
    "    n_steps=int(5e2), verbose: bool=False, min_sig: float=0.2, prefactor: float=1e3, rng_seed: int=21\n",
    "):\n",
    "    xyz_preds = p_to_xyz(preds, split=False)\n",
    "\n",
    "    space  = [Real(float(param_range[i][0]), float(param_range[i][1]), (\"log-uniform\" if param_name == 'r4' else \"uniform\"), name=param_name) for i, param_name in enumerate(param_names)]\n",
    "\n",
    "    def space_transform(X):\n",
    "        triangle_vertices = X['r1']**(1/3) * np.array([\n",
    "            [np.sqrt(3)/2,         0,            np.sqrt(3)/2], \n",
    "            [0,                np.sqrt(3)/2,     np.sqrt(3)/2], \n",
    "            [np.sqrt(3)/2,     np.sqrt(3)/2,                0]\n",
    "        ])\n",
    "\n",
    "        sampled_point = (\n",
    "            (1 - np.sqrt((1 - X['r2']))) * triangle_vertices[0, :]\n",
    "        ) + (\n",
    "            np.sqrt((1 - X['r2']))*(1 - X['r3']) * triangle_vertices[1, :]\n",
    "        ) + (\n",
    "            np.sqrt((1 - X['r2']))*X['r3'] * triangle_vertices[2, :]\n",
    "        )\n",
    "\n",
    "        if verbose:\n",
    "            print(sampled_point)\n",
    "\n",
    "        return sampled_point\n",
    "\n",
    "    @use_named_args(space)\n",
    "    def objective(**X):\n",
    "        if verbose:\n",
    "            print(\"New configuration: {}\".format(X))\n",
    "\n",
    "        thresholds = space_transform(X)\n",
    "        sample_mask = np.all(xyz_preds < thresholds, axis=1)\n",
    "\n",
    "        # print(f\"total sig = {np.sum(weights[binary_labels == 1])}\")\n",
    "        # print(f\"total bkg = {np.sum(weights[binary_labels == 0])}\")\n",
    "\n",
    "        num_sig = np.abs(\n",
    "            np.sum(\n",
    "                weights[\n",
    "                    np.logical_and(\n",
    "                        binary_labels == 1,\n",
    "                        sample_mask\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "\n",
    "        num_bkg = np.abs(\n",
    "            np.sum(\n",
    "                weights[\n",
    "                    np.logical_and(\n",
    "                        binary_labels == 0,\n",
    "                        sample_mask\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "\n",
    "        s_over_root_b = num_sig / np.sqrt(num_bkg)\n",
    "\n",
    "        if num_sig == 0 and num_bkg == 0:\n",
    "            both_0 = prefactor*1e1\n",
    "            if verbose:\n",
    "                print(f\"both sig and bkg 0 at this hyperplane => {both_0}\")\n",
    "            return both_0\n",
    "        elif num_sig < min_sig:\n",
    "            small_sig = prefactor*0\n",
    "            if verbose:\n",
    "                print(f\"too little sig ({num_sig}) at this hyperplane => {small_sig}\")\n",
    "            return small_sig\n",
    "        elif num_bkg == 0:\n",
    "            zero_bkg = -prefactor*num_sig\n",
    "            if verbose:\n",
    "                print(f\"zero bkg at this hyperplane (likely due to finite data rather than real bkg-free zone) => {zero_bkg}\")\n",
    "            return zero_bkg\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"s/âb = {s_over_root_b}, s = {num_sig}, b = {num_bkg}\")\n",
    "\n",
    "        return -prefactor*s_over_root_b\n",
    "    \n",
    "    res_gp = gp_minimize(\n",
    "        objective, space, random_state=rng_seed, \n",
    "        n_calls=(n_steps + (1 if len(np.shape(init_guess)) == 1 else np.shape(init_guess)[0])), \n",
    "        n_initial_points=n_steps, x0=init_guess\n",
    "    )\n",
    "\n",
    "    opt_params = [float(res_gp.x[i]) for i in range(len(space))]\n",
    "    opt_cuts = [float(opt_cut) for opt_cut in space_transform({param_names[i]: res_gp.x[i] for i in range(len(param_names))})]\n",
    "    if verbose:\n",
    "        print(\"Best parameters: {}\".format(opt_cuts))\n",
    "        print(f\"Best s/âb = {-res_gp.fun / prefactor}\")\n",
    "\n",
    "    return opt_cuts, opt_params\n",
    "\n",
    "\n",
    "def multi_optimize_cut_boundaries(preds: list, binary_labels: np.ndarray, weights: np.ndarray, num_categories: int=3, min_sig: float=0.2):\n",
    "    init_param_range = [(1e-8, 1e-7), (1e-6, 1e-5), (1e-2, 1e-1)]\n",
    "    init_guess = [5e-8, 5e-6, 5e-2]\n",
    "    clf_dict = {}\n",
    "    param_clf_dict = {}\n",
    "    for cat in range(num_categories):\n",
    "\n",
    "        clf_dict[cat] = []\n",
    "        param_clf_dict[cat] = []\n",
    "\n",
    "        if cat == 0:\n",
    "            sliced_preds = np.array(preds)\n",
    "            sliced_labels = binary_labels\n",
    "            sliced_weights = weights\n",
    "            param_range = init_param_range\n",
    "            guess = init_guess\n",
    "\n",
    "        else:\n",
    "            slice_array = np.ones_like(binary_labels, dtype=bool)\n",
    "            for prev_cat in range(cat):\n",
    "                slice_array = np.logical_and(\n",
    "                    slice_array,\n",
    "                    np.logical_not(\n",
    "                        np.all(\n",
    "                            p_to_xyz(np.array(preds), split=False) < clf_dict[prev_cat], \n",
    "                            axis=1\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            sliced_preds = np.array(preds)[slice_array]\n",
    "            sliced_labels = binary_labels[slice_array]\n",
    "            sliced_weights = weights[slice_array]\n",
    "            # param_range = [(param_clf_dict[cat-1][0], init_param_range[0][1]), (param_clf_dict[cat-1][1], init_param_range[1][1]), init_param_range[2]]\n",
    "            # guess = [param_clf_dict[cat-1][0] + 1e-11, param_clf_dict[cat-1][1] + 1e-11, 0.5 * init_param_range[2][1]]\n",
    "            param_range = init_param_range\n",
    "            guess = init_guess\n",
    "            \n",
    "        opt_cuts, opt_params = optimize_cuts(\n",
    "            sliced_preds, sliced_labels, sliced_weights, verbose=False,\n",
    "            param_range=param_range, init_guess=guess, n_steps=200, min_sig=min_sig, rng_seed=None\n",
    "        )\n",
    "\n",
    "        clf_dict[cat] = opt_cuts\n",
    "        param_clf_dict[cat] = opt_params\n",
    "\n",
    "    return clf_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "MC_NAMES_PRETTY = {\n",
    "    \"GGJets\": r\"$\\gamma\\gamma+3j$\",\n",
    "    \"GJetPt20To40\": r\"$\\gamma+j$, 20<$p_T$<40GeV\",\n",
    "    \"GJetPt40\": r\"$\\gamma+j$, 40GeV<$p_T$\",\n",
    "    \"GluGluHToGG\": r\"ggF $H\\rightarrow \\gamma\\gamma$\",\n",
    "    \"VBFHToGG\": r\"VBF $H\\rightarrow \\gamma\\gamma$\",\n",
    "    \"VHToGG\": r\"V$H\\rightarrow\\gamma\\gamma$\",\n",
    "    \"ttHToGG\": r\"$t\\bar{t}H\\rightarrow\\gamma\\gamma$\",\n",
    "    \"GluGluToHH\": r\"ggF $HH\\rightarrow bb\\gamma\\gamma$\",\n",
    "    # \"VBFHHto2B2G_CV_1_C2V_1_C3_1\": r\"VBF $HH\\rightarrow bb\\gamma\\gamma$\",\n",
    "    \"signal\": r\"ggF $HH\\rightarrow bb\\gamma\\gamma$ + VBF $HH\\rightarrow bb\\gamma\\gamma$\",\n",
    "    # Names for order #\n",
    "    \"ggF HH\": r\"ggF $H\\rightarrow \\gamma\\gamma$\",\n",
    "    \"ttH\": r\"$t\\bar{t}H\\rightarrow\\gamma\\gamma$\",\n",
    "    \"single-H\": r\"ggF $H\\rightarrow \\gamma\\gamma$ + VBF $H\\rightarrow \\gamma\\gamma$ + V$H\\rightarrow\\gamma\\gamma$\",\n",
    "    \"non-res\": r\"$\\gamma\\gamma+3j$ + $\\gamma+j$, 20GeV<$p_T$\",\n",
    "    \"VH\": r\"V$H\\rightarrow\\gamma\\gamma$\",\n",
    "    \"non-res + ggFH + VBFH\": r\"$\\gamma\\gamma+3j$ + $\\gamma+j$, 20GeV<$p_T$ + ggF $H\\rightarrow \\gamma\\gamma$ + VBF $H\\rightarrow \\gamma\\gamma$\"\n",
    "    # Need to fill in pretty print for BSM samples #\n",
    "}\n",
    "LUMINOSITIES = {\n",
    "    '2022preEE': 7.9804, \n",
    "    '2022postEE': 26.6717,\n",
    "    # Need to fill in lumis for other eras #\n",
    "}\n",
    "LUMINOSITIES['total_lumi'] = sum(LUMINOSITIES.values())\n",
    "\n",
    "# Dictionary of variables\n",
    "VARIABLES = {\n",
    "    # key: hist.axis axes for plotting #\n",
    "    # MET variables\n",
    "    'puppiMET_sumEt': hist.axis.Regular(40, 150., 2000, name='var', label=r'puppiMET $\\Sigma E_T$ [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'puppiMET_pt': hist.axis.Regular(40, 20., 250, name='var', label=r'puppiMET $p_T$ [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'puppiMET_phi': hist.axis.Regular(20,-3.2, 3.2, name='var', label=r'puppiMET $\\phi$', growth=False, underflow=False, overflow=False), \n",
    "    # jet-MET variables\n",
    "    'DeltaPhi_j1MET': hist.axis.Regular(20,-3.2, 3.2, name='var', label=r'$\\Delta\\phi (j_1,E_T^{miss})$', growth=False, underflow=False, overflow=False), \n",
    "    'DeltaPhi_j2MET': hist.axis.Regular(20, -3.2, 3.2, name='var', label=r'$\\Delta\\phi (j_2,E_T^{miss})$', growth=False, underflow=False, overflow=False), \n",
    "    # jet-photon variables\n",
    "    'DeltaR_jg_min': hist.axis.Regular(30, 0, 5, name='var', label=r'min$(\\Delta R(jet, \\gamma))$', growth=False, underflow=False, overflow=False), \n",
    "    # jet variables\n",
    "    # 'jet1_pt': hist.axis.Regular(40, 20., 250, name='var', label=r'lead jet $p_T$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    # 'jet2_pt': hist.axis.Regular(40, 20., 250, name='var', label=r'sublead jet $p_T$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    'lead_bjet_pt': hist.axis.Regular(40, 20., 250, name='var', label=r'lead bjet $p_T$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    'lead_bjet_eta': hist.axis.Regular(20, -5., 5., name='var', label=r'lead bjet $\\eta$', growth=False, underflow=False, overflow=False),\n",
    "    'lead_bjet_phi': hist.axis.Regular(20, -3.2, 3.2, name='var', label=r'lead bjet $\\phi$', growth=False, underflow=False, overflow=False),\n",
    "    'sublead_bjet_pt': hist.axis.Regular(40, 20., 250, name='var', label=r'lead bjet $p_T$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    'sublead_bjet_eta': hist.axis.Regular(20, -5., 5., name='var', label=r'lead bjet $\\eta$', growth=False, underflow=False, overflow=False),\n",
    "    'sublead_bjet_phi': hist.axis.Regular(20, -3.2, 3.2, name='var', label=r'lead bjet $\\phi$', growth=False, underflow=False, overflow=False),\n",
    "    'n_jets': hist.axis.Integer(0, 10, name='var', label=r'$n_{jets}$', growth=False, underflow=False, overflow=False), \n",
    "    'chi_t0': hist.axis.Regular(40, 0., 150, name='var', label=r'$\\chi_{t0}^2$', growth=False, underflow=False, overflow=False), \n",
    "    'chi_t1': hist.axis.Regular(30, 0., 500, name='var', label=r'$\\chi_{t1}^2$', growth=False, underflow=False, overflow=False), \n",
    "    # lepton variables\n",
    "    'n_leptons': hist.axis.Integer(0, 10, name='var', label=r'$n_{leptons}$', growth=False, underflow=False, overflow=False),\n",
    "    'lepton1_pt': hist.axis.Regular(40, 0., 200., name='var', label=r'lead lepton $p_T$ [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'lepton2_pt': hist.axis.Regular(40, 0., 200., name='var', label=r'sublead lepton $p_T$ [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'lepton1_eta': hist.axis.Regular(30, -5., 5., name='var', label=r'lead lepton $\\eta$', growth=False, underflow=False, overflow=False), \n",
    "    'lepton2_eta': hist.axis.Regular(30, -5., 5., name='var', label=r'sublead lepton $\\eta$', growth=False, underflow=False, overflow=False),\n",
    "    'lepton1_phi': hist.axis.Regular(20, -3.2, 3.2, name='var', label=r'lead lepton $\\phi$', growth=False, underflow=False, overflow=False), \n",
    "    'lepton2_phi': hist.axis.Regular(20, -3.2, 3.2, name='var', label=r'sublead lepton $\\phi$', growth=False, underflow=False, overflow=False),\n",
    "    # diphoton variables\n",
    "    'pt': hist.axis.Regular(40, 20., 2000, name='var', label=r' $\\gamma\\gamma p_{T}$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    'eta': hist.axis.Regular(20, -5., 5., name='var', label=r'$\\gamma\\gamma \\eta$', growth=False, underflow=False, overflow=False), \n",
    "    'phi': hist.axis.Regular(20, -3.2, 3.2, name='var', label=r'$\\gamma \\gamma \\phi$', growth=False, underflow=False, overflow=False),\n",
    "    # angular (cos) variables\n",
    "    'abs_CosThetaStar_CS': hist.axis.Regular(20, 0, 1, name='var', label=r'|cos$(\\theta_{CS})$|', growth=False, underflow=False, overflow=False), \n",
    "    'abs_CosThetaStar_jj': hist.axis.Regular(20, 0, 1, name='var', label=r'|cos$(\\theta_{jj})$|', growth=False, underflow=False, overflow=False),\n",
    "    'CosThetaStar_CS': hist.axis.Regular(20, -1, 1, name='var', label=r'cos$(\\theta_{CS})$', growth=False, underflow=False, overflow=False), \n",
    "    'CosThetaStar_jj': hist.axis.Regular(20, -1, 1, name='var', label=r'cos$(\\theta_{jj})$', growth=False, underflow=False, overflow=False), \n",
    "    # jet-lepton variables\n",
    "    'leadBjet_leadLepton': hist.axis.Regular(30, 0, 5, name='var', label=r'$\\Delta R(bjet_{lead}, l_{lead})$', growth=False, underflow=False, overflow=False), \n",
    "    'leadBjet_subleadLepton': hist.axis.Regular(30, 0, 5, name='var', label=r'$\\Delta R(bjet_{lead}, l_{sublead})$', growth=False, underflow=False, overflow=False), \n",
    "    'subleadBjet_leadLepton': hist.axis.Regular(30, 0, 5, name='var', label=r'$\\Delta R(bjet_{sublead}, l_{lead})$', growth=False, underflow=False, overflow=False), \n",
    "    'subleadBjet_subleadLepton': hist.axis.Regular(30, 0, 5, name='var', label=r'$\\Delta R(bjet_{sublead}, l_{sublead})$', growth=False, underflow=False, overflow=False),\n",
    "    # dijet variables (must be blinded on data)\n",
    "    'dijet_mass': hist.axis.Regular(25, 25., 180., name='var', label=r'$M_{jj}$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    # diphoton variables (must be blinded on data)\n",
    "    'mass': hist.axis.Regular(25, 25., 180., name='var', label=r'$M_{\\gamma\\gamma}$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    # Yibo's BDT variables\n",
    "    'lead_mvaID': hist.axis.Regular(50, -1., 1., name='var', label=r'$\\gamma_{lead}$ MVA ID', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_mvaID': hist.axis.Regular(50, -1., 1., name='var', label=r'$\\gamma_{sublead}$ MVA ID', growth=False, underflow=False, overflow=False),\n",
    "    'CosThetaStar_gg': hist.axis.Regular(50, -1., 1., name='var', label=r'cos$(\\theta_{gg})$', growth=False, underflow=False, overflow=False),\n",
    "    'lead_pt_over_Mgg': hist.axis.Regular(50, 0., 1., name='var', label=r'$p_{T,\\gamma_1} / M_{\\gamma\\gamma}$', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_pt_over_Mgg': hist.axis.Regular(50, 0., 1., name='var', label=r'$p_{T,\\gamma_2} / M_{\\gamma\\gamma}$', growth=False, underflow=False, overflow=False),\n",
    "    'lead_sigmaE_over_E': hist.axis.Regular(50, 0., 1., name='var', label=r'$\\sigma {E,\\gamma_1} / E_{\\gamma\\gamma}$', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_sigmaE_over_E': hist.axis.Regular(50, 0., 1., name='var', label=r'$\\sigma {E,\\gamma_2} / E_{\\gamma\\gamma}$', growth=False, underflow=False, overflow=False),\n",
    "    'lead_bjet_pt_over_Mjj': hist.axis.Regular(50, 0., 1., name='var', label=r'$p_{T,j1} / M_{jj}$', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_bjet_pt_over_Mjj': hist.axis.Regular(50, 0., 1., name='var', label=r'$p_{T,j2} / M_{jj}$', growth=False, underflow=False, overflow=False),\n",
    "    'lead_bjet_btagPNetB': hist.axis.Regular(50, -1., 1., name='var', label=r'$j_{lead}$ PNet btag score', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_bjet_btagPNetB': hist.axis.Regular(50, -1., 1., name='var', label=r'$j_{sublead}$ PNet btag score', growth=False, underflow=False, overflow=False),\n",
    "    'lead_bjet_sigmapT_over_pT': hist.axis.Regular(50, 0., 1., name='var', label=r'$\\sigma p_{T,j1} / p_{T,jj}$', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_bjet_sigmapT_over_pT': hist.axis.Regular(50, 0., 1., name='var', label=r'$\\sigma p_{T,j2} / p_{T,jj}$', growth=False, underflow=False, overflow=False),\n",
    "    'dipho_mass_over_Mggjj': hist.axis.Regular(50, 0., 1., name='var', label=r'$M_{\\gamma\\gamma} / M_{\\gamma\\gamma jj}$', growth=False, underflow=False, overflow=False), \n",
    "    'dijet_mass_over_Mggjj': hist.axis.Regular(50, 0., 1., name='var', label=r'$M_{jj} / M_{\\gamma\\gamma jj}$', growth=False, underflow=False, overflow=False),\n",
    "    # My variables for non-reso reduction #\n",
    "    'lead_pfRelIso03_all_quadratic': hist.axis.Regular(50, -1., 1., name='var', label=r'$\\gamma_{lead}$ PF RelIso03 all quad.', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_pfRelIso03_all_quadratic': hist.axis.Regular(50, -1., 1., name='var', label=r'$\\gamma_{sublead}$ PF RelIso03 all quad.', growth=False, underflow=False, overflow=False),\n",
    "    # Michael's DNN variables #\n",
    "    'DeltaR_j1g1': hist.axis.Regular(50, 0., 5., name='var', label=r'$\\Delta R(bjet_{lead}, \\gamma_{lead})$', growth=False, underflow=False, overflow=False), \n",
    "    'DeltaR_j1g2': hist.axis.Regular(50, 0., 5., name='var', label=r'$\\Delta R(bjet_{lead}, \\gamma_{sublead})$', growth=False, underflow=False, overflow=False), \n",
    "    'DeltaR_j2g1': hist.axis.Regular(50, 0., 5., name='var', label=r'$\\Delta R(bjet_{sublead}, \\gamma_{lead})$', growth=False, underflow=False, overflow=False), \n",
    "    'DeltaR_j2g2': hist.axis.Regular(50, 0., 5., name='var', label=r'$\\Delta R(bjet_{sublead}, \\gamma_{sublead})$', growth=False, underflow=False, overflow=False),\n",
    "    'HHbbggCandidate_pt': hist.axis.Regular(100, 0., 700., name='var', label=r'HH $p_T$ [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'HHbbggCandidate_eta': hist.axis.Regular(50, -5., 5., name='var', label=r'HH $\\eta$', growth=False, underflow=False, overflow=False), \n",
    "    'HHbbggCandidate_phi': hist.axis.Regular(50, -3.2, 3.2, name='var', label=r'HH $\\phi$', growth=False, underflow=False, overflow=False),\n",
    "    'HHbbggCandidate_mass': hist.axis.Regular(25, 0., 700., name='var', label=r'$M_{HH}$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "}\n",
    "# Dictionary of variables to do MC/Data comparison\n",
    "VARIABLES_STD = {\n",
    "    # key: hist.axis axes for plotting #\n",
    "    # MET variables\n",
    "    'puppiMET_sumEt': hist.axis.Regular(40, -4., 4., name='var', label=r'puppiMET ln($\\Sigma E_T$) [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'puppiMET_pt': hist.axis.Regular(40, -4., 4., name='var', label=r'puppiMET ln($p_T$) [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'puppiMET_phi': hist.axis.Regular(40, -4., 4., name='var', label=r'puppiMET $\\phi$', growth=False, underflow=False, overflow=False), \n",
    "    # jet-MET variables\n",
    "    'DeltaPhi_j1MET': hist.axis.Regular(40, -4., 4., name='var', label=r'$\\Delta\\phi (j_1,E_T^{miss})$', growth=False, underflow=False, overflow=False), \n",
    "    'DeltaPhi_j2MET': hist.axis.Regular(40, -4., 4., name='var', label=r'$\\Delta\\phi (j_2,E_T^{miss})$', growth=False, underflow=False, overflow=False), \n",
    "    # jet-photon variables\n",
    "    'DeltaR_jg_min': hist.axis.Regular(40, -4., 4., name='var', label=r'min$(\\Delta R(jet, \\gamma))$', growth=False, underflow=False, overflow=False), \n",
    "    # jet variables\n",
    "    'lead_bjet_pt': hist.axis.Regular(40, -4., 4., name='var', label=r'lead bjet ln($p_T$) [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_bjet_pt': hist.axis.Regular(40, -4., 4., name='var', label=r'sublead bjet ln($p_T$) [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'lead_bjet_eta': hist.axis.Regular(40, -4., 4., name='var', label=r'lead bjet $\\eta$', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_bjet_eta': hist.axis.Regular(40, -4., 4., name='var', label=r'sublead bjet $\\eta$', growth=False, underflow=False, overflow=False),\n",
    "    'lead_bjet_phi': hist.axis.Regular(40, -4., 4., name='var', label=r'lead bjet $\\phi$', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_bjet_phi': hist.axis.Regular(40, -4., 4., name='var', label=r'sublead bjet $\\phi$', growth=False, underflow=False, overflow=False),\n",
    "    'n_jets': hist.axis.Regular(12, -4., 4., name='var', label=r'$n_{jets}$', growth=False, underflow=False, overflow=False), \n",
    "    'chi_t0': hist.axis.Regular(40, -4., 10., name='var', label=r'ln($\\chi_{t0}^2$)', growth=False, underflow=False, overflow=False), \n",
    "    'chi_t1': hist.axis.Regular(40, -4., 10., name='var', label=r'ln($\\chi_{t1}^2$)', growth=False, underflow=False, overflow=False), \n",
    "    # lepton variables\n",
    "    'n_leptons': hist.axis.Regular(12, -4., 4., name='var', label=r'$n_{leptons}$', growth=False, underflow=False, overflow=False),\n",
    "    'lepton1_pt': hist.axis.Regular(40, -4., 4., name='var', label=r'lead lepton ln($p_T$) [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'lepton2_pt': hist.axis.Regular(40, -4., 4., name='var', label=r'sublead lepton ln($p_T$) [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'lepton1_eta': hist.axis.Regular(40, -4., 4., name='var', label=r'lead lepton $\\eta$', growth=False, underflow=False, overflow=False), \n",
    "    'lepton2_eta': hist.axis.Regular(40, -4., 4., name='var', label=r'sublead lepton $\\eta$', growth=False, underflow=False, overflow=False),\n",
    "    'lepton1_phi': hist.axis.Regular(40, -4., 4., name='var', label=r'lead lepton $\\phi$', growth=False, underflow=False, overflow=False), \n",
    "    'lepton2_phi': hist.axis.Regular(40, -4., 4., name='var', label=r'sublead lepton $\\phi$', growth=False, underflow=False, overflow=False),\n",
    "    # diphoton variables\n",
    "    'pt': hist.axis.Regular(40, -4., 4., name='var', label=r' $\\gamma\\gamma$ ln($p_{T}$) [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    'eta': hist.axis.Regular(40, -4., 4., name='var', label=r'$\\gamma\\gamma \\eta$', growth=False, underflow=False, overflow=False), \n",
    "    'phi': hist.axis.Regular(40, -4., 4., name='var', label=r'$\\gamma \\gamma \\phi$', growth=False, underflow=False, overflow=False),\n",
    "    # angular (cos) variables\n",
    "    'abs_CosThetaStar_CS': hist.axis.Regular(40, -4., 4., name='var', label=r'|cos$(\\theta_{CS})$|', growth=False, underflow=False, overflow=False), \n",
    "    'abs_CosThetaStar_jj': hist.axis.Regular(40, -4., 4., name='var', label=r'|cos$(\\theta_{jj})$|', growth=False, underflow=False, overflow=False), \n",
    "    'CosThetaStar_CS': hist.axis.Regular(40, -1., 1., name='var', label=r'cos$(\\theta_{CS})$', growth=False, underflow=False, overflow=False), \n",
    "    'CosThetaStar_jj': hist.axis.Regular(40, -1., 1., name='var', label=r'cos$(\\theta_{jj})$', growth=False, underflow=False, overflow=False), \n",
    "    # jet-lepton variables\n",
    "    'leadBjet_leadLepton': hist.axis.Regular(40, -4., 4., name='var', label=r'$\\Delta R(bjet_{lead}, l_{lead})$', growth=False, underflow=False, overflow=False), \n",
    "    'leadBjet_subleadLepton': hist.axis.Regular(40, -4., 4., name='var', label=r'$\\Delta R(bjet_{lead}, l_{sublead})$', growth=False, underflow=False, overflow=False), \n",
    "    'subleadBjet_leadLepton': hist.axis.Regular(40, -4., 4., name='var', label=r'$\\Delta R(bjet_{sublead}, l_{lead})$', growth=False, underflow=False, overflow=False), \n",
    "    'subleadBjet_subleadLepton': hist.axis.Regular(40, -4., 4., name='var', label=r'$\\Delta R(bjet_{sublead}, l_{sublead})$', growth=False, underflow=False, overflow=False),\n",
    "    # dijet variables (must be blinded on data)\n",
    "    'dijet_mass': hist.axis.Regular(40, -4., 4., name='var', label=r'ln($M_{jj}$) [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    # diphoton variables (must be blinded on data)\n",
    "    'mass': hist.axis.Regular(40, -4., 4., name='var', label=r'$M_{\\gamma\\gamma}$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    # Yibo's BDT variables\n",
    "    'lead_mvaID': hist.axis.Regular(50, -4., 4., name='var', label=r'$\\gamma_{lead}$ MVA ID', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_mvaID': hist.axis.Regular(50, -4., 4., name='var', label=r'$\\gamma_{sublead}$ MVA ID', growth=False, underflow=False, overflow=False),\n",
    "    'CosThetaStar_gg': hist.axis.Regular(50, -4., 4., name='var', label=r'cos$(\\theta_{gg})$', growth=False, underflow=False, overflow=False),\n",
    "    'lead_pt_over_Mgg': hist.axis.Regular(50, -4., 4., name='var', label=r'$p_{T,\\gamma_1} / M_{\\gamma\\gamma}$', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_pt_over_Mgg': hist.axis.Regular(50, -4., 4., name='var', label=r'$p_{T,\\gamma_2} / M_{\\gamma\\gamma}$', growth=False, underflow=False, overflow=False),\n",
    "    'lead_sigmaE_over_E': hist.axis.Regular(50, -4., 4., name='var', label=r'exp($\\sigma {E,\\gamma_1} / E_{\\gamma\\gamma}$)', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_sigmaE_over_E': hist.axis.Regular(50, -4., 4., name='var', label=r'exp($\\sigma {E,\\gamma_2} / E_{\\gamma\\gamma}$)', growth=False, underflow=False, overflow=False),\n",
    "    'lead_bjet_pt_over_Mjj': hist.axis.Regular(50, -4., 4., name='var', label=r'$p_{T,j1} / M_{jj}$', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_bjet_pt_over_Mjj': hist.axis.Regular(50, -4., 4., name='var', label=r'$p_{T,j2} / M_{jj}$', growth=False, underflow=False, overflow=False),\n",
    "    'lead_bjet_btagPNetB': hist.axis.Regular(50, -4., 4., name='var', label=r'$j_{lead}$ PNet btag score', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_bjet_btagPNetB': hist.axis.Regular(50, -4., 4., name='var', label=r'$j_{sublead}$ PNet btag score', growth=False, underflow=False, overflow=False),\n",
    "    'lead_bjet_sigmapT_over_pT': hist.axis.Regular(50, -4., 4., name='var', label=r'exp($\\sigma p_{T,j1} / p_{T,jj}$)', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_bjet_sigmapT_over_pT': hist.axis.Regular(50, -4., 4., name='var', label=r'exp($\\sigma p_{T,j2} / p_{T,jj}$)', growth=False, underflow=False, overflow=False),\n",
    "    'dipho_mass_over_Mggjj': hist.axis.Regular(50, -4., 4., name='var', label=r'$M_{\\gamma\\gamma} / M_{\\gamma\\gamma jj}$', growth=False, underflow=False, overflow=False), \n",
    "    'dijet_mass_over_Mggjj': hist.axis.Regular(50, -4., 4., name='var', label=r'$M_{jj} / M_{\\gamma\\gamma jj}$', growth=False, underflow=False, overflow=False),\n",
    "    # My variables for non-reso reduction #\n",
    "    'lead_pfRelIso03_all_quadratic': hist.axis.Regular(50, -4., 4., name='var', label=r'$\\gamma_{lead}$ PF RelIso03 all quad.', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_pfRelIso03_all_quadratic': hist.axis.Regular(50, -4., 4., name='var', label=r'$\\gamma_{sublead}$ PF RelIso03 all quad.', growth=False, underflow=False, overflow=False),\n",
    "    # Michael's DNN variables #\n",
    "    'DeltaR_j1g1': hist.axis.Regular(50, -4., 4., name='var', label=r'$\\Delta R(bjet_{lead}, \\gamma_{lead})$', growth=False, underflow=False, overflow=False), \n",
    "    'DeltaR_j1g2': hist.axis.Regular(50, -4., 4., name='var', label=r'$\\Delta R(bjet_{lead}, \\gamma_{sublead})$', growth=False, underflow=False, overflow=False), \n",
    "    'DeltaR_j2g1': hist.axis.Regular(50, -4., 4., name='var', label=r'$\\Delta R(bjet_{sublead}, \\gamma_{lead})$', growth=False, underflow=False, overflow=False), \n",
    "    'DeltaR_j2g2': hist.axis.Regular(50, -4., 4., name='var', label=r'$\\Delta R(bjet_{sublead}, \\gamma_{sublead})$', growth=False, underflow=False, overflow=False),\n",
    "    'HHbbggCandidate_pt': hist.axis.Regular(100, -4., 4., name='var', label=r'HH ln($p_T$) [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'HHbbggCandidate_eta': hist.axis.Regular(50, -4., 4., name='var', label=r'HH $\\eta$', growth=False, underflow=False, overflow=False), \n",
    "    'HHbbggCandidate_phi': hist.axis.Regular(50, -4., 4., name='var', label=r'HH $\\phi$', growth=False, underflow=False, overflow=False),\n",
    "    'HHbbggCandidate_mass': hist.axis.Regular(50, -4., 4., name='var', label=r'ln($M_{HH}$) [GeV]', growth=False, underflow=False, overflow=False),\n",
    "}\n",
    "\n",
    "\n",
    "def make_input_plot(\n",
    "    output_dir, var_name, hist_list, fold_idx=None, labels=None, density=True, \n",
    "    plot_prefix='', plot_postfix='', alpha=0.8, linestyle=True\n",
    "):\n",
    "    fig, ax = plt.subplots()\n",
    "    if linestyle:\n",
    "        if fold_idx is not None:\n",
    "            linestyles = [\"solid\", \"dashed\", \"dotted\", \"solid\", \"dashed\", \"dotted\"]\n",
    "        else:\n",
    "            linestyles = [\"solid\", \"dotted\", \"solid\", \"dotted\"]\n",
    "        linestyles = linestyles * ((len(hist_list) // len(linestyles)) + 1)\n",
    "        linestyles = linestyles[:len(hist_list)]\n",
    "    else:\n",
    "        linestyles = None\n",
    "    hep.histplot(\n",
    "        hist_list, ax=ax, linewidth=3, histtype=\"step\", yerr=True, density=density,\n",
    "        linestyle=linestyles, label=labels, alpha=alpha\n",
    "    )\n",
    "    # Plotting niceties #\n",
    "    hep.cms.lumitext(f\"{LUMINOSITIES['total_lumi']:.2f}\" + r\"fb$^{-1}$ (13.6 TeV)\", ax=ax)\n",
    "    hep.cms.text(\"Work in Progress\", ax=ax)\n",
    "    # Plot legend properly\n",
    "    ax.legend(bbox_to_anchor=(1, 0.5))\n",
    "    # Make angular and chi^2 plots linear, otherwise log\n",
    "    if re.match('chi_t', var_name) is None and re.match('DeltaPhi', var_name) is None and re.match('mass', var_name) is None:\n",
    "        ax.set_yscale('log')\n",
    "    else:\n",
    "        ax.set_yscale('linear')\n",
    "    ax.set_yscale('linear')\n",
    "    # Save out the plot\n",
    "    if fold_idx is not None:\n",
    "        plt.savefig(f'{output_dir}/{plot_prefix}1dhist_{var_name}{plot_postfix}_fold{fold_idx}.pdf', bbox_inches='tight')\n",
    "        plt.savefig(f'{output_dir}/{plot_prefix}1dhist_{var_name}{plot_postfix}_fold{fold_idx}.png', bbox_inches='tight')\n",
    "    else:\n",
    "        plt.savefig(f'{output_dir}/{plot_prefix}1dhist_{var_name}{plot_postfix}.pdf', bbox_inches='tight')\n",
    "        plt.savefig(f'{output_dir}/{plot_prefix}1dhist_{var_name}{plot_postfix}.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss per Epoch Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"losses\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "if 'BDT_perf' not in globals():\n",
    "    with open(os.path.join(OUTPUT_DIRPATH, CURRENT_TIME+\"_BDT_perf.json\"), 'r') as f:\n",
    "        BDT_perf = json.load(f)\n",
    "\n",
    "if 'evals_result_dict' not in globals():\n",
    "    with open(os.path.join(OUTPUT_DIRPATH, CURRENT_TIME+\"_BDT_eval_result.json\"), 'r') as f:\n",
    "        evals_result_dict = json.load(f)\n",
    "\n",
    "# plot train/val/test losses\n",
    "all_train, all_val, all_test = [], [], []\n",
    "for fold_idx in range(len(evals_result_dict)):\n",
    "    all_train.append(evals_result_dict[f\"fold_{fold_idx}\"]['train']['mlogloss'])\n",
    "    all_val.append(evals_result_dict[f\"fold_{fold_idx}\"]['val']['mlogloss'])\n",
    "    all_test.append(evals_result_dict[f\"fold_{fold_idx}\"]['test']['mlogloss'])\n",
    "\n",
    "plot_train_val_losses(\n",
    "    all_train + all_val, [f'train fold {i}' for i in range(len(all_train))]+[f'val fold {i}' for i in range(len(all_val))],\n",
    "    'train_val_losses_vs_epoch', plot_dirpath, \n",
    "    linestyles=['solid']*len(all_train) + ['dashed']*len(all_val),\n",
    ")\n",
    "plot_train_val_losses(\n",
    "    all_train + all_test, [f'train fold {i}' for i in range(len(all_train))]+[f'test fold {i}' for i in range(len(all_test))],\n",
    "    'train_test_losses_vs_epoch', plot_dirpath,\n",
    "    linestyles=['solid']*len(all_train) + ['dotted']*len(all_test),\n",
    ")\n",
    "avg_train, avg_val, avg_test = np.mean(pad_list(all_train), axis=0), np.mean(pad_list(all_val), axis=0), np.mean(pad_list(all_test), axis=0)\n",
    "std_train, std_val, std_test = np.std(pad_list(all_train), axis=0), np.std(pad_list(all_val), axis=0), np.std(pad_list(all_test), axis=0)\n",
    "plot_train_val_losses(\n",
    "    [avg_train, avg_val, avg_test], ['train avg', 'val avg', 'test avg'],\n",
    "    'train_val_test_avg_vs_epoch', plot_dirpath,\n",
    "    losses_std_arrs=[std_train, std_val, std_test],\n",
    "    linestyles=['solid', 'dashed', 'dotted'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"ROCs\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "if 'BDT_perf' not in globals():\n",
    "    with open(os.path.join(OUTPUT_DIRPATH, CURRENT_TIME+\"_BDT_perf.json\"), 'r') as f:\n",
    "        BDT_perf = json.load(f)\n",
    "\n",
    "base_tpr = np.array(BDT_perf['ggF HH']['base_tpr'])\n",
    "\n",
    "# plot ROCs\n",
    "for j, sample_name in enumerate(order):\n",
    "\n",
    "    for fold_idx in range(len(bdt_train_dict)):\n",
    "\n",
    "        for roc_type in ['density', 'weighted']:\n",
    "\n",
    "            fprs = [np.array(BDT_perf[sample_name][f'fprs_{roc_type}'][fold_idx])[:, i] for i in range(len(order))]\n",
    "            tprs = [base_tpr for _ in range(len(order))]\n",
    "            labels = [\n",
    "                f\"{sample_name} vs. {'all' if i == j else sample_name_}, AUC = {BDT_perf[sample_name][f'areas_{roc_type}'][fold_idx][i]:.4f}\" \n",
    "                for i, sample_name_ in enumerate(order)\n",
    "            ]\n",
    "\n",
    "            plot_rocs(fprs, tprs, labels, f\"BDT_roc_{sample_name}_{roc_type}_testData_fold{fold_idx}\", plot_dirpath)\n",
    "\n",
    "    for roc_type in ['sum_density', 'sum_weighted']:\n",
    "\n",
    "        fprs = [np.array(BDT_perf[sample_name][f'fprs_{roc_type}'])[:, i] for i in range(len(order))]\n",
    "        tprs = [base_tpr for _ in range(len(order))]\n",
    "        labels = [\n",
    "            f\"{sample_name} vs. {'all' if i == j else sample_name_}, AUC = {BDT_perf[sample_name][f'areas_{roc_type}'][i]:.4f}\" \n",
    "            for i, sample_name_ in enumerate(order)\n",
    "        ]\n",
    "\n",
    "        plot_rocs(fprs, tprs, labels, f\"BDT_roc_{sample_name}_{roc_type}_testData_sum\", plot_dirpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Score Dist Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_985368/3121238121.py:127: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  plt.savefig(\n"
     ]
    }
   ],
   "source": [
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"output_scores\")\n",
    "# plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"output_scores_arctanh\")\n",
    "# plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"output_scores_resample\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "if 'BDT_perf' not in globals():\n",
    "    with open(os.path.join(OUTPUT_DIRPATH, CURRENT_TIME+\"_BDT_perf.json\"), 'r') as f:\n",
    "        BDT_perf = json.load(f)\n",
    "\n",
    "# plot Output scores\n",
    "for j, sample_name in enumerate(order):\n",
    "\n",
    "    for i, sample_name_ in enumerate(order):\n",
    "\n",
    "        for fold_idx in range(len(bdt_train_dict)):\n",
    "            \n",
    "            sigs_and_bkgs = {\n",
    "                sample_name__: np.array(BDT_perf[sample_name]['preds'][fold_idx])[:, j][bdt_test_dict[f\"fold_{fold_idx}\"].get_label() == k]\n",
    "                for k, sample_name__ in enumerate(order)\n",
    "            }\n",
    "            score_weights = {\n",
    "                sample_name__: weights_plot_test[f\"fold_{fold_idx}\"][bdt_test_dict[f\"fold_{fold_idx}\"].get_label() == k]\n",
    "                for k, sample_name__ in enumerate(order)\n",
    "            }\n",
    "\n",
    "            if sample_name_ != sample_name:\n",
    "                event_j_mask = bdt_test_dict[f\"fold_{fold_idx}\"].get_label() == j\n",
    "                pred_j_rescale = np.array(BDT_perf[sample_name]['preds'][fold_idx])[:, j][event_j_mask] + np.array(BDT_perf[sample_name]['preds'][fold_idx])[:, i][event_j_mask]\n",
    "                event_i_mask = bdt_test_dict[f\"fold_{fold_idx}\"].get_label() == i\n",
    "                pred_i_rescale = np.array(BDT_perf[sample_name]['preds'][fold_idx])[:, j][event_i_mask] + np.array(BDT_perf[sample_name]['preds'][fold_idx])[:, i][event_i_mask]\n",
    "\n",
    "                for sample_name__ in order:\n",
    "                    if sample_name__ == sample_name:\n",
    "                        sigs_and_bkgs[sample_name__] = sigs_and_bkgs[sample_name__] / pred_j_rescale\n",
    "                    elif sample_name__ == sample_name_:\n",
    "                        sigs_and_bkgs[sample_name__] = sigs_and_bkgs[sample_name__] / pred_i_rescale\n",
    "                    else:\n",
    "                        del sigs_and_bkgs[sample_name__]\n",
    "                        del score_weights[sample_name__]\n",
    "\n",
    "            if re.search('arctanh', plot_dirpath) is not None:\n",
    "                for key, value in sigs_and_bkgs.items():\n",
    "                    sigs_and_bkgs[key] = np.arctanh(value)\n",
    "\n",
    "            plot_output_scores(\n",
    "                sigs_and_bkgs, order, \n",
    "                f\"BDT_{sample_name}_vs_{sample_name_ if sample_name_ != sample_name else 'all'}_outputScoreWeighted_testData_fold{fold_idx}\", \n",
    "                plot_dirpath, weights=score_weights, log=True,\n",
    "                arctanh=True if re.search('arctanh', plot_dirpath) is not None else False\n",
    "            )\n",
    "            plot_output_scores(\n",
    "                sigs_and_bkgs, order, \n",
    "                f\"BDT_{sample_name}_vs_{sample_name_ if sample_name_ != sample_name else 'all'}_outputScoreDensity_testData_fold{fold_idx}\", \n",
    "                plot_dirpath,\n",
    "                arctanh=True if re.search('arctanh', plot_dirpath) is not None else False\n",
    "            )\n",
    "\n",
    "        flat_preds = np.concatenate([BDT_perf[sample_name]['preds'][fold_idx] for fold_idx in range(len(bdt_test_dict))], axis=0)\n",
    "        if re.search('arctanh', plot_dirpath) is not None:\n",
    "            flat_preds = np.arctanh(flat_preds)\n",
    "        flat_truths = np.concatenate([bdt_test_dict[f\"fold_{fold_idx}\"].get_label() for fold_idx in range(len(bdt_test_dict))], axis=0)\n",
    "        flat_weights = np.concatenate([weights_plot_test[f\"fold_{fold_idx}\"] for fold_idx in range(len(bdt_test_dict))], axis=0)\n",
    "\n",
    "        sigs_and_bkgs = {\n",
    "            sample_name__: flat_preds[:, j][flat_truths == k]\n",
    "            for k, sample_name__ in enumerate(order)\n",
    "        }\n",
    "        score_weights = {\n",
    "            sample_name__: flat_weights[flat_truths == k]\n",
    "            for k, sample_name__ in enumerate(order)\n",
    "        }\n",
    "        \n",
    "        if sample_name_ != sample_name:\n",
    "            event_j_mask = flat_truths == j\n",
    "            pred_j_rescale = (flat_preds[:, j] + flat_preds[:, i])[event_j_mask]\n",
    "            event_i_mask = flat_truths == i\n",
    "            pred_i_rescale = (flat_preds[:, j] + flat_preds[:, i])[event_i_mask]\n",
    "\n",
    "            for sample_name__ in order:\n",
    "                if sample_name__ == sample_name:\n",
    "                    sigs_and_bkgs[sample_name__] = sigs_and_bkgs[sample_name__] / pred_j_rescale\n",
    "                elif sample_name__ == sample_name_:\n",
    "                    sigs_and_bkgs[sample_name__] = sigs_and_bkgs[sample_name__] / pred_i_rescale\n",
    "                else:\n",
    "                    del sigs_and_bkgs[sample_name__]\n",
    "                    del score_weights[sample_name__]\n",
    "        \n",
    "        plot_output_scores(\n",
    "            sigs_and_bkgs, order, \n",
    "            f\"BDT_{sample_name}_vs_{sample_name_ if sample_name_ != sample_name else 'all'}_outputScoreWeighted_testData_sum\", \n",
    "            plot_dirpath, weights=score_weights, log=True,\n",
    "            arctanh=True if re.search('arctanh', plot_dirpath) is not None else False\n",
    "        )\n",
    "        plot_output_scores(\n",
    "            sigs_and_bkgs, order, \n",
    "            f\"BDT_{sample_name}_vs_{sample_name_ if sample_name_ != sample_name else 'all'}_outputScoreDensity_testData_sum\", \n",
    "            plot_dirpath,\n",
    "            arctanh=True if re.search('arctanh', plot_dirpath) is not None else False\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### s/âb Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "============================================================\n",
      "Cat1: 0.9995 < ggF HH score â¤ 1.0000 AND 120 GeV < m_HH < 130 GeV\n",
      "------------------------------------------------------------\n",
      "Cat1: Num ggF HH = 0.2265\n",
      "------------------------------------------------------------\n",
      "Cat1: Num ttH = 0.0739\n",
      "------------------------------------------------------------\n",
      "Cat1: Num VH = 0.0838\n",
      "------------------------------------------------------------\n",
      "Cat1: Num non-res + ggFH + VBFH = 0.1999\n",
      "------------------------------------------------------------\n",
      "Cat1: S = 0.2265, B = 0.3575, S/âB = 0.3789\n",
      "============================================================\n",
      "============================================================\n",
      "Cat2: 0.9981 < ggF HH score â¤ 0.9995 AND 120 GeV < m_HH < 130 GeV\n",
      "------------------------------------------------------------\n",
      "Cat2: Num ggF HH = 0.2305\n",
      "------------------------------------------------------------\n",
      "Cat2: Num ttH = 0.5000\n",
      "------------------------------------------------------------\n",
      "Cat2: Num VH = 0.1011\n",
      "------------------------------------------------------------\n",
      "Cat2: Num non-res + ggFH + VBFH = 2.9225\n",
      "------------------------------------------------------------\n",
      "Cat2: S = 0.2305, B = 3.5236, S/âB = 0.1228\n",
      "============================================================\n",
      "============================================================\n",
      "Cat3: 0.9909 < ggF HH score â¤ 0.9981 AND 120 GeV < m_HH < 130 GeV\n",
      "------------------------------------------------------------\n",
      "Cat3: Num ggF HH = 0.2383\n",
      "------------------------------------------------------------\n",
      "Cat3: Num ttH = 1.8321\n",
      "------------------------------------------------------------\n",
      "Cat3: Num VH = 0.1883\n",
      "------------------------------------------------------------\n",
      "Cat3: Num non-res + ggFH + VBFH = 15.4450\n",
      "------------------------------------------------------------\n",
      "Cat3: S = 0.2383, B = 17.4653, S/âB = 0.0570\n"
     ]
    }
   ],
   "source": [
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"s_over_rootb\")\n",
    "# plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"s_over_rootb_arctanh\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "if 'BDT_perf' not in globals():\n",
    "    with open(os.path.join(OUTPUT_DIRPATH, CURRENT_TIME+\"_BDT_perf.json\"), 'r') as f:\n",
    "        BDT_perf = json.load(f)\n",
    "\n",
    "# plot s/âb curves\n",
    "for j, sample_name in enumerate(order):\n",
    "\n",
    "    for i, sample_name_ in enumerate(order):\n",
    "\n",
    "        for fold_idx in range(len(bdt_train_dict)):\n",
    "\n",
    "            if sample_name_ == sample_name:\n",
    "                sig_mask = bdt_test_dict[f\"fold_{fold_idx}\"].get_label() == j\n",
    "                bkg_mask = bdt_test_dict[f\"fold_{fold_idx}\"].get_label() != j\n",
    "\n",
    "                sig_rescale = np.ones_like(sig_mask)\n",
    "                bkg_rescale = np.ones_like(bkg_mask)\n",
    "            else:\n",
    "                sig_mask = bdt_test_dict[f\"fold_{fold_idx}\"].get_label() == j\n",
    "                bkg_mask = bdt_test_dict[f\"fold_{fold_idx}\"].get_label() == i\n",
    "\n",
    "                sig_rescale = (\n",
    "                    np.array(BDT_perf[sample_name]['preds'][fold_idx])[:, j] \n",
    "                    + np.array(BDT_perf[sample_name]['preds'][fold_idx])[:, i]\n",
    "                )\n",
    "                bkg_rescale = (\n",
    "                    np.array(BDT_perf[sample_name]['preds'][fold_idx])[:, j] \n",
    "                    + np.array(BDT_perf[sample_name]['preds'][fold_idx])[:, i]\n",
    "                )\n",
    "\n",
    "            sigs_and_bkgs = {\n",
    "                'sig': (np.array(BDT_perf[sample_name]['preds'][fold_idx])[:, j] / sig_rescale)[sig_mask],\n",
    "                'bkg': (np.array(BDT_perf[sample_name]['preds'][fold_idx])[:, j] / bkg_rescale)[bkg_mask]\n",
    "            }\n",
    "            if re.search('arctanh', plot_dirpath) is not None:\n",
    "                sigs_and_bkgs['sig'] = np.arctanh(sigs_and_bkgs['sig'])\n",
    "                sigs_and_bkgs['bkg'] = np.arctanh(sigs_and_bkgs['bkg'])\n",
    "            score_weights = {\n",
    "                'sig': weights_plot_test[f\"fold_{fold_idx}\"][sig_mask],\n",
    "                'bkg': weights_plot_test[f\"fold_{fold_idx}\"][bkg_mask]\n",
    "            }\n",
    "\n",
    "\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\")\n",
    "                plot_s_over_root_b(\n",
    "                    sigs_and_bkgs['sig'], sigs_and_bkgs['bkg'], f\"{sample_name} vs. {sample_name_ if sample_name_ != sample_name else 'all'}\", \n",
    "                    f\"BDT_{sample_name}_vs_{sample_name_ if sample_name_ != sample_name else 'all'}_sOverRootb_testData_fold{fold_idx}\", \n",
    "                    plot_dirpath, weights=score_weights,\n",
    "                    arctanh=True if re.search('arctanh', plot_dirpath) is not None else False  \n",
    "                )\n",
    "\n",
    "                (\n",
    "                    cut_boundaries_fold, cut_s_over_root_bs_fold, sig_weights_fold, bkg_weights_fold\n",
    "                ) = optimize_cut_boundaries(\n",
    "                    sigs_and_bkgs['sig'], sigs_and_bkgs['bkg'], score_weights,\n",
    "                    arctanh=True if re.search('arctanh', plot_dirpath) is not None else False\n",
    "                )\n",
    "\n",
    "                BDT_cut_labels = [\n",
    "                    f\"cut={cut_boundaries_fold[0][cut_idx]:.4f}: s/âb={cut_s_over_root_bs_fold[0][cut_idx]:.5f}, s={sig_weights_fold[0][cut_idx]['value']:.5f}Â±{sig_weights_fold[0][cut_idx]['w2']:.5f}, b={bkg_weights_fold[0][cut_idx]['value']:.5f}Â±{bkg_weights_fold[0][cut_idx]['w2']:.5f}\" for cut_idx in range(len(cut_s_over_root_bs_fold[0]))\n",
    "                ]\n",
    "                line_labels = BDT_cut_labels[:10]\n",
    "                lines = cut_boundaries_fold[0][:10]\n",
    "                line_colors = cmap_petroff10\n",
    "\n",
    "                plot_s_over_root_b(\n",
    "                    sigs_and_bkgs['sig'], sigs_and_bkgs['bkg'], f\"{sample_name} vs. {sample_name_ if sample_name_ != sample_name else 'all'}\", \n",
    "                    f\"BDT_{sample_name}_vs_{sample_name_ if sample_name_ != sample_name else 'all'}_sOverRootb_withCuts_testData_fold{fold_idx}_{sample_name}\", plot_dirpath, \n",
    "                    weights=score_weights,\n",
    "                    lines=lines, lines_labels=line_labels, line_colors=line_colors,\n",
    "                    arctanh=True if re.search('arctanh', plot_dirpath) is not None else False\n",
    "                )\n",
    "            \n",
    "        flat_preds = np.concatenate([BDT_perf[sample_name]['preds'][fold_idx] for fold_idx in range(len(bdt_test_dict))], axis=0)\n",
    "        if re.search('arctanh', plot_dirpath) is not None:\n",
    "            flat_preds = np.arctanh(flat_preds)\n",
    "        flat_truths = np.concatenate([bdt_test_dict[f\"fold_{fold_idx}\"].get_label() for fold_idx in range(len(bdt_test_dict))], axis=0)\n",
    "        flat_weights = np.concatenate([weights_plot_test[f\"fold_{fold_idx}\"] for fold_idx in range(len(bdt_test_dict))], axis=0)\n",
    "\n",
    "        if sample_name_ == sample_name:\n",
    "            sig_mask = flat_truths == j\n",
    "            bkg_mask = flat_truths != j\n",
    "\n",
    "            sig_rescale = np.ones_like(sig_mask)\n",
    "            bkg_rescale = np.ones_like(bkg_mask)\n",
    "        else:\n",
    "            sig_mask = flat_truths == j\n",
    "            bkg_mask = flat_truths == i\n",
    "\n",
    "            sig_rescale = flat_preds[:, j] + flat_preds[:, i]\n",
    "            bkg_rescale = flat_preds[:, j] + flat_preds[:, i]\n",
    "\n",
    "        sigs_and_bkgs = {\n",
    "            'sig': (flat_preds[:, j] / sig_rescale)[sig_mask],\n",
    "            'bkg': (flat_preds[:, j] / bkg_rescale)[bkg_mask]\n",
    "        }\n",
    "        score_weights = {\n",
    "            'sig': flat_weights[sig_mask],\n",
    "            'bkg': flat_weights[bkg_mask]\n",
    "        }\n",
    "\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            plot_s_over_root_b(\n",
    "                sigs_and_bkgs['sig'], sigs_and_bkgs['bkg'], f\"{sample_name} vs. {sample_name_ if sample_name_ != sample_name else 'all'}\", \n",
    "                f\"BDT_{sample_name}_vs_{sample_name_ if sample_name_ != sample_name else 'all'}_sOverRootb_testData_sum\", \n",
    "                plot_dirpath, weights=score_weights,\n",
    "                arctanh=True if re.search('arctanh', plot_dirpath) is not None else False\n",
    "            )\n",
    "\n",
    "            (\n",
    "                cut_boundaries_fold, cut_s_over_root_bs_fold, sig_weights_fold, bkg_weights_fold\n",
    "            ) = optimize_cut_boundaries(\n",
    "                sigs_and_bkgs['sig'], sigs_and_bkgs['bkg'], score_weights,\n",
    "                arctanh=True if re.search('arctanh', plot_dirpath) is not None else False\n",
    "            )\n",
    "\n",
    "            BDT_cut_labels = [\n",
    "                f\"cut={cut_boundaries_fold[0][cut_idx]:.4f}: s/âb={cut_s_over_root_bs_fold[0][cut_idx]:.5f}, s={sig_weights_fold[0][cut_idx]['value']:.5f}Â±{sig_weights_fold[0][cut_idx]['w2']:.5f}, b={bkg_weights_fold[0][cut_idx]['value']:.5f}Â±{bkg_weights_fold[0][cut_idx]['w2']:.5f}\" for cut_idx in range(len(cut_s_over_root_bs_fold[0]))\n",
    "            ]\n",
    "            line_labels = BDT_cut_labels[:10]\n",
    "            lines = cut_boundaries_fold[0][:10]\n",
    "            line_colors = cmap_petroff10\n",
    "\n",
    "            plot_s_over_root_b(\n",
    "                sigs_and_bkgs['sig'], sigs_and_bkgs['bkg'], f\"{sample_name} vs. {sample_name_ if sample_name_ != sample_name else 'all'}\", \n",
    "                f\"BDT_{sample_name}_vs_{sample_name_ if sample_name_ != sample_name else 'all'}_sOverRootb_withCuts_testData_sum\", plot_dirpath, \n",
    "                weights=score_weights,\n",
    "                lines=lines, lines_labels=line_labels, line_colors=line_colors,\n",
    "                arctanh=True if re.search('arctanh', plot_dirpath) is not None else False\n",
    "            )\n",
    "\n",
    "        if j == 0 and i == 0:\n",
    "            flat_mass = np.concatenate([data_test_aux_dict[f\"fold_{fold_idx}\"]['mass'] for fold_idx in range(len(data_test_aux_dict))], axis=0)\n",
    "            if re.search('arctanh', plot_dirpath) is not None:\n",
    "                cat_lines = [6.0] + lines[:3]\n",
    "            else:\n",
    "                cat_lines = [1.0] + lines[:3]\n",
    "            cat_num_samples = {}\n",
    "            for k, cat in enumerate(['Cat1', 'Cat2', 'Cat3']):\n",
    "                cat_num_samples[cat] = {}\n",
    "                print('='*60)\n",
    "                print('='*60)\n",
    "                print(f\"{cat}: {cat_lines[k+1]:.4f} < ggF HH score â¤ {cat_lines[k]:.4f} AND 120 GeV < m_HH < 130 GeV\")\n",
    "                print('-'*60)\n",
    "                for m, sample_name in enumerate(order):\n",
    "                    cat_num_samples[cat][sample_name] = np.sum(\n",
    "                        flat_weights[\n",
    "                            np.logical_and(  # event passes conditions and is the right type (i.e. sample)\n",
    "                                np.logical_and(  # event passes category and mass conditions\n",
    "                                    np.logical_and(  # prediction is within category bounds\n",
    "                                        flat_preds[:, 0] <= cat_lines[k],\n",
    "                                        flat_preds[:, 0] > cat_lines[k+1]\n",
    "                                    ),\n",
    "                                    np.logical_and(  # diphoton mass is within 120-130 window\n",
    "                                        flat_mass < 130,\n",
    "                                        flat_mass > 120\n",
    "                                    ),\n",
    "                                ),\n",
    "                                flat_truths == m\n",
    "                            )\n",
    "                        ]\n",
    "                    )\n",
    "                    print(f\"{cat}: Num {sample_name} = {cat_num_samples[cat][sample_name]:.4f}\")\n",
    "                    print('-'*60)\n",
    "\n",
    "                print(f\"{cat}: S = {cat_num_samples[cat][order[0]]:.4f}, B = {np.sum([cat_num_samples[cat][order[v]] for v in range(1, len(order))]):.4f}, S/âB = {(cat_num_samples[cat][order[0]] / np.sqrt(np.sum([cat_num_samples[cat][order[v]] for v in range(1, len(order))]))):.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "============================================================\n",
      "Category 0 3D outputs < [4.571013300928796e-05, 0.002958582485768867, 0.002912885306845008] AND 120 GeV < m_HH < 130 GeV\n",
      "------------------------------------------------------------\n",
      "0: Num ggF HH = 0.2333\n",
      "------------------------------------------------------------\n",
      "0: Num ttH = 0.0240\n",
      "------------------------------------------------------------\n",
      "0: Num VH = 0.0672\n",
      "------------------------------------------------------------\n",
      "0: Num non-res + ggFH + VBFH = 1.4578\n",
      "------------------------------------------------------------\n",
      "0: S = 0.2333, B = 1.5490, S/âB = 0.1875\n",
      "============================================================\n",
      "============================================================\n",
      "Category 1 3D outputs NOT< [4.571013300928796e-05, 0.002958582485768867, 0.002912885306845008] AND 3D outputs < [0.00025897278509527135, 0.002792679853923484, 0.0025337103540497507] AND 120 GeV < m_HH < 130 GeV\n",
      "------------------------------------------------------------\n",
      "1: Num ggF HH = 0.2697\n",
      "------------------------------------------------------------\n",
      "1: Num ttH = 0.4020\n",
      "------------------------------------------------------------\n",
      "1: Num VH = 0.1597\n",
      "------------------------------------------------------------\n",
      "1: Num non-res + ggFH + VBFH = 2.9821\n",
      "------------------------------------------------------------\n",
      "1: S = 0.2697, B = 3.5437, S/âB = 0.1433\n",
      "============================================================\n",
      "============================================================\n",
      "Category 2 3D outputs NOT< [0.00025897278509527135, 0.002792679853923484, 0.0025337103540497507] AND 3D outputs < [0.00015953082067176068, 0.0031904568899924963, 0.0030309420216650075] AND 120 GeV < m_HH < 130 GeV\n",
      "------------------------------------------------------------\n",
      "2: Num ggF HH = 0.0158\n",
      "------------------------------------------------------------\n",
      "2: Num ttH = 0.0111\n",
      "------------------------------------------------------------\n",
      "2: Num VH = 0.0107\n",
      "------------------------------------------------------------\n",
      "2: Num non-res + ggFH + VBFH = 0.8858\n",
      "------------------------------------------------------------\n",
      "2: S = 0.0158, B = 0.9076, S/âB = 0.0166\n"
     ]
    }
   ],
   "source": [
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"s_over_rootb_multiOptim\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "if 'BDT_perf' not in globals():\n",
    "    with open(os.path.join(OUTPUT_DIRPATH, CURRENT_TIME+\"_BDT_perf.json\"), 'r') as f:\n",
    "        BDT_perf = json.load(f)\n",
    "\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(projection='3d')\n",
    "# # x_preds, y_preds, z_preds = p_to_xyz(np.concatenate([BDT_perf['ggF HH']['preds'][fold_idx] for fold_idx in range(len(bdt_test_dict))], axis=0))\n",
    "# for i, sample_name in enumerate(order):\n",
    "#     if i == 0:\n",
    "#         downsample = 100\n",
    "#     elif i == 1:\n",
    "#         downsample = 200\n",
    "#     elif i == 2:\n",
    "#         downsample = 400\n",
    "#     elif i == 3:\n",
    "#         downsample = 500\n",
    "\n",
    "#     x_preds, y_preds, z_preds = p_to_xyz(np.array(BDT_perf['ggF HH']['preds'][0])[bdt_test_dict[f\"fold_0\"].get_label() == i][::downsample])\n",
    "#     ax.scatter(x_preds, y_preds, z_preds, marker='.', label=sample_name)\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# # plot s/âb curves\n",
    "# for fold_idx in range(len(bdt_train_dict)):\n",
    "\n",
    "#     with warnings.catch_warnings():\n",
    "#         warnings.simplefilter(\"ignore\")\n",
    "#         clf_dict = multi_optimize_cut_boundaries(\n",
    "#             BDT_perf['ggF HH']['preds'][fold_idx], \n",
    "#             bdt_test_dict[f\"fold_{fold_idx}\"].get_label() == 0, \n",
    "#             weights_plot_test[f\"fold_{fold_idx}\"],\n",
    "#             min_sig=0.07\n",
    "#         )\n",
    "\n",
    "#     cat_dict = {}\n",
    "#     for cat in range(len(clf_dict)):\n",
    "#         prev_cat_slice = np.ones_like(weights_plot_test[f\"fold_{fold_idx}\"], dtype=bool)\n",
    "#         if cat > 0:\n",
    "#             for prev_cat in range(cat):\n",
    "#                 prev_cat_slice = np.logical_and(\n",
    "#                     prev_cat_slice,\n",
    "#                     np.logical_not(\n",
    "#                         np.all(\n",
    "#                             p_to_xyz(np.array(BDT_perf['ggF HH']['preds'][fold_idx]), split=False) < clf_dict[prev_cat], \n",
    "#                             axis=1\n",
    "#                         )\n",
    "#                     )\n",
    "#                 )\n",
    "#         cat_dict[cat] = np.logical_and(\n",
    "#             prev_cat_slice,\n",
    "#             np.all(\n",
    "#                 p_to_xyz(np.array(BDT_perf['ggF HH']['preds'][fold_idx]), split=False) < clf_dict[cat],\n",
    "#                 axis=1\n",
    "#             )\n",
    "#         )\n",
    "\n",
    "#     masses = data_test_aux_dict[f\"fold_{fold_idx}\"]['mass']\n",
    "#     cat_num_samples = {}\n",
    "#     for cat in range(len(clf_dict)):\n",
    "#         cat_num_samples[cat] = {}\n",
    "#         print('='*60)\n",
    "#         print('='*60)\n",
    "#         print(f\"Fold {fold_idx}: Category {cat} (SVM) AND 120 GeV < m_HH < 130 GeV\")\n",
    "#         print('-'*60)\n",
    "#         for m, sample_name in enumerate(order):\n",
    "#             cat_num_samples[cat][sample_name] = np.sum(\n",
    "#                 weights_plot_test[f\"fold_{fold_idx}\"][\n",
    "#                     np.logical_and(  # event passes conditions and is the right type (i.e. sample)\n",
    "#                         np.logical_and(  # event passes category and mass conditions\n",
    "#                             cat_dict[cat],  # event passes category selections\n",
    "#                             np.logical_and(  # diphoton mass is within 120-130 window\n",
    "#                                 masses < 130,\n",
    "#                                 masses > 120\n",
    "#                             ),\n",
    "#                         ),\n",
    "#                         bdt_test_dict[f\"fold_{fold_idx}\"].get_label() == m\n",
    "#                     )\n",
    "#                 ]\n",
    "#             )\n",
    "#             print(f\"{cat}: Num {sample_name} = {cat_num_samples[cat][sample_name]:.4f}\")\n",
    "#             print('-'*60)\n",
    "#         print(f\"{cat}: S = {cat_num_samples[cat][order[0]]:.4f}, B = {np.sum([cat_num_samples[cat][order[v]] for v in range(1, len(order))]):.4f}, S/âB = {(cat_num_samples[cat][order[0]] / np.sqrt(np.sum([cat_num_samples[cat][order[v]] for v in range(1, len(order))]))):.4f}\")\n",
    "\n",
    "# print('='*60)\n",
    "# print('='*60)\n",
    "# print('='*60)\n",
    "# print('='*60)\n",
    "\n",
    "flat_preds = np.concatenate([BDT_perf['ggF HH']['preds'][fold_idx] for fold_idx in range(len(bdt_test_dict))], axis=0)\n",
    "flat_truths = np.concatenate([bdt_test_dict[f\"fold_{fold_idx}\"].get_label() for fold_idx in range(len(bdt_test_dict))], axis=0)\n",
    "flat_weights = np.concatenate([weights_plot_test[f\"fold_{fold_idx}\"] for fold_idx in range(len(bdt_test_dict))], axis=0)\n",
    "# flat_weights = np.concatenate([weight_test_dict[f\"fold_{fold_idx}\"] for fold_idx in range(len(bdt_test_dict))], axis=0)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    clf_dict = multi_optimize_cut_boundaries(\n",
    "        flat_preds, flat_truths == 0, flat_weights\n",
    "    )\n",
    "\n",
    "    # plot_s_over_root_b(\n",
    "    #     sigs_and_bkgs['sig'], sigs_and_bkgs['bkg'], f\"{sample_name} vs. {sample_name_ if sample_name_ != sample_name else 'all'}\", \n",
    "    #     f\"BDT_{sample_name}_vs_{sample_name_ if sample_name_ != sample_name else 'all'}_sOverRootb_withCuts_testData_sum\", plot_dirpath, \n",
    "    #     weights=score_weights,\n",
    "    #     lines=lines, lines_labels=line_labels, line_colors=line_colors\n",
    "    # )\n",
    "\n",
    "flat_mass = np.concatenate([data_test_aux_dict[f\"fold_{fold_idx}\"]['mass'] for fold_idx in range(len(data_test_aux_dict))], axis=0)\n",
    "cat_dict = {}\n",
    "for cat in range(len(clf_dict)):\n",
    "    prev_cat_slice = np.ones_like(flat_weights, dtype=bool)\n",
    "    if cat > 0:\n",
    "        for prev_cat in range(cat):\n",
    "            prev_cat_slice = np.logical_and(\n",
    "                prev_cat_slice,\n",
    "                np.logical_not(\n",
    "                    np.all(\n",
    "                        p_to_xyz(flat_preds, split=False) < clf_dict[prev_cat], \n",
    "                        axis=1\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "    cat_dict[cat] = np.logical_and(\n",
    "        prev_cat_slice,\n",
    "        np.all(\n",
    "            p_to_xyz(flat_preds, split=False) < clf_dict[cat],\n",
    "            axis=1\n",
    "        )\n",
    "    )\n",
    "\n",
    "cat_num_samples = {}\n",
    "for cat in range(len(clf_dict)):\n",
    "    cat_num_samples[cat] = {}\n",
    "    print('='*60)\n",
    "    print('='*60)\n",
    "    print(f\"Category {cat} {f'3D outputs NOT< {clf_dict[cat-1]} AND ' if cat > 0 else ''}3D outputs < {clf_dict[cat]} AND 120 GeV < m_HH < 130 GeV\")\n",
    "    print('-'*60)\n",
    "    for m, sample_name in enumerate(order):\n",
    "        cat_num_samples[cat][sample_name] = np.sum(\n",
    "            flat_weights[\n",
    "                np.logical_and(  # event passes conditions and is the right type (i.e. sample)\n",
    "                    np.logical_and(  # event passes category and mass conditions\n",
    "                        cat_dict[cat],  # event passes category selections\n",
    "                        np.logical_and(  # diphoton mass is within 120-130 window\n",
    "                            flat_mass < 130,\n",
    "                            flat_mass > 120\n",
    "                        ),\n",
    "                    ),\n",
    "                    flat_truths == m\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "        print(f\"{cat}: Num {sample_name} = {cat_num_samples[cat][sample_name]:.4f}\")\n",
    "        print('-'*60)\n",
    "    print(f\"{cat}: S = {cat_num_samples[cat][order[0]]:.4f}, B = {np.sum([cat_num_samples[cat][order[v]] for v in range(1, len(order))]):.4f}, S/âB = {(cat_num_samples[cat][order[0]] / np.sqrt(np.sum([cat_num_samples[cat][order[v]] for v in range(1, len(order))]))):.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0: FÎ² (Î²=1) score = \n",
      "[4.47894679e-04 9.89867576e-02 5.74097440e-02 9.82563237e-01]\n",
      "fold 1: FÎ² (Î²=1) score = \n",
      "[4.13555808e-04 1.19583433e-01 7.64501313e-02 9.80960371e-01]\n",
      "fold 2: FÎ² (Î²=1) score = \n",
      "[4.41737302e-04 1.68677249e-01 8.49830926e-02 9.82702223e-01]\n",
      "fold 3: FÎ² (Î²=1) score = \n",
      "[4.42130383e-04 1.91808306e-01 6.76819839e-02 9.82319980e-01]\n",
      "fold 4: FÎ² (Î²=1) score = \n",
      "[4.59441551e-04 1.81688443e-01 7.64636853e-02 9.83081083e-01]\n",
      "Sum over folds: FÎ² (Î²=1) score = \n",
      "[4.40332432e-04 1.49309812e-01 7.24953346e-02 9.82325515e-01]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 900x700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 900x700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 900x700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 900x700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 900x700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 900x700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"confusion_matrix\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "if 'BDT_perf' not in globals():\n",
    "    with open(os.path.join(OUTPUT_DIRPATH, CURRENT_TIME+\"_BDT_perf.json\"), 'r') as f:\n",
    "        BDT_perf = json.load(f)\n",
    "\n",
    "beta = 1\n",
    "\n",
    "for fold_idx in range(len(BDT_perf['ggF HH']['preds'])):\n",
    "\n",
    "    pred_classes = np.argmax(BDT_perf['ggF HH']['preds'][fold_idx], axis=1)\n",
    "\n",
    "    conf_matrix = confusion_matrix(\n",
    "        bdt_test_dict[f\"fold_{fold_idx}\"].get_label(), \n",
    "        pred_classes,\n",
    "        sample_weight=weights_plot_test[f\"fold_{fold_idx}\"]\n",
    "    )\n",
    "\n",
    "    plot_confusion_matrix(\n",
    "        conf_matrix, order, f\"confusion_matrix_fold{fold_idx}\", plot_dirpath\n",
    "    )\n",
    "\n",
    "    f1_scores = fbeta_score(\n",
    "        bdt_test_dict[f\"fold_{fold_idx}\"].get_label(), \n",
    "        pred_classes,\n",
    "        beta=beta,\n",
    "        sample_weight=weights_plot_test[f\"fold_{fold_idx}\"], average=None\n",
    "    )\n",
    "    print(f\"fold {fold_idx}: FÎ² (Î²={beta}) score = \\n{f1_scores}\")\n",
    "\n",
    "full_pred_classes = np.argmax(\n",
    "    np.concatenate(\n",
    "        [\n",
    "            BDT_perf['ggF HH']['preds'][fold_idx] for fold_idx in range(len(BDT_perf['ggF HH']['preds']))\n",
    "        ]\n",
    "    ), axis=1\n",
    ")\n",
    "full_labels = np.concatenate(\n",
    "    [\n",
    "        bdt_test_dict[f\"fold_{fold_idx}\"].get_label() for fold_idx in range(len(BDT_perf['ggF HH']['preds']))\n",
    "    ]\n",
    ")\n",
    "full_weights = np.concatenate(\n",
    "    [\n",
    "        weights_plot_test[f\"fold_{fold_idx}\"] for fold_idx in range(len(BDT_perf['ggF HH']['preds']))\n",
    "    ]\n",
    ")\n",
    "\n",
    "conf_matrix = confusion_matrix(\n",
    "    full_labels, \n",
    "    full_pred_classes,\n",
    "    sample_weight=full_weights\n",
    ")\n",
    "\n",
    "plot_confusion_matrix(\n",
    "    conf_matrix, order, f\"confusion_matrix_sum\", plot_dirpath\n",
    ")\n",
    "\n",
    "f1_scores = fbeta_score(\n",
    "    full_labels, \n",
    "    full_pred_classes,\n",
    "    beta=beta,\n",
    "    sample_weight=full_weights, average=None\n",
    ")\n",
    "print(f\"Sum over folds: FÎ² (Î²={beta}) score = \\n{f1_scores}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"variable_importance\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "for fold_idx in range(len(bdt_train_dict)):\n",
    "    booster = xgb.Booster(param, model_file=os.path.join(OUTPUT_DIRPATH, f'{CURRENT_TIME}_BDT_fold{fold_idx}.model'))\n",
    "\n",
    "    labels = copy.deepcopy([key for key in hlf_vars_columns_dict[f'fold_{fold_idx}'].keys()])\n",
    "    labels.sort()\n",
    "    \n",
    "    booster.feature_names = labels\n",
    "    score_dict = booster.get_score(importance_type='total_gain')\n",
    "\n",
    "    sorted_scores, sorted_labels = [], []\n",
    "    for label, score in score_dict.items():\n",
    "        sorted_scores.append(score)\n",
    "        sorted_labels.append(label)\n",
    "\n",
    "    sorted_labels = np.array(sorted_labels)[np.argsort(sorted_scores)]\n",
    "    sorted_scores = np.sort(sorted_scores)\n",
    "\n",
    "    plot_feature_importance(\n",
    "        sorted_scores, sorted_labels, f'xgb_importance_fold{fold_idx}', plot_dirpath\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mass Sculpting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 38\u001b[0m\n\u001b[1;32m     32\u001b[0m train_hists[sample_name], val_hists[sample_name], test_hists[sample_name] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(), \u001b[38;5;28mlist\u001b[39m(), \u001b[38;5;28mlist\u001b[39m()\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m score_cut \u001b[38;5;129;01min\u001b[39;00m score_cuts:\n\u001b[1;32m     35\u001b[0m     train_mask \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     36\u001b[0m         xgb_label_train_dict[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfold_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m i\n\u001b[1;32m     37\u001b[0m     ) \u001b[38;5;241m&\u001b[39m (\n\u001b[0;32m---> 38\u001b[0m         \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBDT_perf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mggF HH\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain_preds\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfold_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[:, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m score_cut\n\u001b[1;32m     39\u001b[0m     )\n\u001b[1;32m     40\u001b[0m     val_mask \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     41\u001b[0m         xgb_label_val_dict[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfold_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m i\n\u001b[1;32m     42\u001b[0m     ) \u001b[38;5;241m&\u001b[39m (\n\u001b[1;32m     43\u001b[0m         np\u001b[38;5;241m.\u001b[39marray(BDT_perf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mggF HH\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_preds\u001b[39m\u001b[38;5;124m'\u001b[39m][fold_idx])[:, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m score_cut\n\u001b[1;32m     44\u001b[0m     )\n\u001b[1;32m     45\u001b[0m     test_mask \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     46\u001b[0m         xgb_label_test_dict[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfold_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m i\n\u001b[1;32m     47\u001b[0m     ) \u001b[38;5;241m&\u001b[39m (\n\u001b[1;32m     48\u001b[0m         np\u001b[38;5;241m.\u001b[39marray(BDT_perf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mggF HH\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreds\u001b[39m\u001b[38;5;124m'\u001b[39m][fold_idx])[:, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m score_cut\n\u001b[1;32m     49\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"mass_sculpting\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "if 'BDT_perf' not in globals():\n",
    "    with open(os.path.join(OUTPUT_DIRPATH, CURRENT_TIME+f\"_BDT_perf.json\"), 'r') as f:\n",
    "        BDT_perf = json.load(f)\n",
    "\n",
    "score_cuts = [0.0, 0.7, 0.99]\n",
    "label_arr = {\n",
    "    MC_NAMES_PRETTY[sample_name]: [f'score above {score_cut}' for score_cut in score_cuts] for sample_name in order\n",
    "}\n",
    "\n",
    "# Loop over and plot the per-fold variables\n",
    "for fold_idx in range(len(hlf_vars_columns_dict)):\n",
    "\n",
    "    for var_idx, var_name in enumerate(['mass', 'dijet_mass']):\n",
    "\n",
    "        plot_dirpath_ = os.path.join(plot_dirpath, var_name)\n",
    "        if not os.path.exists(plot_dirpath_):\n",
    "            os.makedirs(plot_dirpath_)\n",
    "\n",
    "        train_hists, val_hists, test_hists = {}, {}, {}\n",
    "        for i, sample_name in enumerate(order):\n",
    "\n",
    "            train_hists[sample_name], val_hists[sample_name], test_hists[sample_name] = list(), list(), list()\n",
    "            for score_cut in score_cuts:\n",
    "\n",
    "                train_mask = (\n",
    "                    xgb_label_train_dict[f'fold_{fold_idx}'] == i\n",
    "                ) & (\n",
    "                    np.array(BDT_perf['ggF HH']['train_preds'][fold_idx])[:, 0] > score_cut\n",
    "                )\n",
    "                val_mask = (\n",
    "                    xgb_label_val_dict[f'fold_{fold_idx}'] == i\n",
    "                ) & (\n",
    "                    np.array(BDT_perf['ggF HH']['val_preds'][fold_idx])[:, 0] > score_cut\n",
    "                )\n",
    "                test_mask = (\n",
    "                    xgb_label_test_dict[f'fold_{fold_idx}'] == i\n",
    "                ) & (\n",
    "                    np.array(BDT_perf['ggF HH']['preds'][fold_idx])[:, 0] > score_cut\n",
    "                )\n",
    "            \n",
    "                train_np = (\n",
    "                    data_aux_dict[f'fold_{fold_idx}'].iloc[train_idxs_dict[f'fold_{fold_idx}']]\n",
    "                ).loc[train_mask, var_name].to_numpy()\n",
    "                val_np = (\n",
    "                    data_aux_dict[f'fold_{fold_idx}'].iloc[val_idxs_dict[f'fold_{fold_idx}']]\n",
    "                ).loc[val_mask, var_name].to_numpy()\n",
    "                test_np = data_test_aux_dict[f'fold_{fold_idx}'].loc[test_mask, var_name].to_numpy()\n",
    "            \n",
    "                train_hists[sample_name].append(hist.Hist(VARIABLES[var_name]).fill(var=train_np))\n",
    "                val_hists[sample_name].append(hist.Hist(VARIABLES[var_name]).fill(var=val_np))\n",
    "                test_hists[sample_name].append(hist.Hist(VARIABLES[var_name]).fill(var=test_np))\n",
    "    \n",
    "            for j, (plot_type, histdict) in enumerate([('train_', train_hists), ('val_', val_hists), ('test_', test_hists)]):\n",
    "                make_input_plot(\n",
    "                    plot_dirpath_, var_name,\n",
    "                    histdict[sample_name], \n",
    "                    fold_idx=fold_idx, labels=label_arr[MC_NAMES_PRETTY[sample_name]], \n",
    "                    plot_prefix=plot_type+f'{sample_name}_scoreCut_'\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling for Mass Sculpting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_from_var(sample_var, sample_weight, n_events, n_samples_per_event=1, bins=100):\n",
    "    np_hist, bin_edges = np.histogram(sample_var, bins=bins, weights=sample_weight, density=True)\n",
    "    np_hist /= np.sum(np_hist)\n",
    "\n",
    "    bin_choices = seeded_rng.choice(np.arange(len(np_hist)), size=n_events*n_samples_per_event, p=np_hist)\n",
    "\n",
    "    value_choices = (bin_edges[bin_choices+1] - bin_edges[bin_choices]) * seeded_rng.random(size=n_events*n_samples_per_event) + bin_edges[bin_choices]\n",
    "\n",
    "    return value_choices\n",
    "\n",
    "def resample_grow_np(var, bool_arr, n_duplicates_per_event):\n",
    "    new_rows_shape = tuple([n_duplicates_per_event]+[1 for _ in range(1, len(np.shape(var)))])\n",
    "    new_rows = np.tile(\n",
    "        var[bool_arr],\n",
    "        new_rows_shape\n",
    "    )\n",
    "    return np.concatenate([var, new_rows])\n",
    "def resample_grow_pd(var, bool_arr, n_duplicates_per_event):\n",
    "    new_rows = pd.DataFrame(\n",
    "        np.tile(\n",
    "            ( var.loc[bool_arr] ).to_numpy(),\n",
    "            (n_duplicates_per_event, 1)\n",
    "        ),\n",
    "        columns=var.columns\n",
    "    )\n",
    "    return pd.concat([var, new_rows], ignore_index=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold0 for mass plot\n",
      "------------------------------------------------------------\n",
      "fold0 for dijet_mass plot\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 136\u001b[0m\n\u001b[1;32m    125\u001b[0m bdt_test_dict[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfold_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mDMatrix(\n\u001b[1;32m    126\u001b[0m     data\u001b[38;5;241m=\u001b[39mdata_hlf_test_dict[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfold_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m][nonres_bool], label\u001b[38;5;241m=\u001b[39mxgb_label_test_dict[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfold_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m][nonres_bool], \n\u001b[1;32m    127\u001b[0m     weight\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mabs(weight_test_dict[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfold_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m])[nonres_bool],\n\u001b[1;32m    128\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m999.0\u001b[39m, feature_names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(hlf_vars_columns_dict[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfold_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    129\u001b[0m )\n\u001b[1;32m    131\u001b[0m gjet_ggf_preds \u001b[38;5;241m=\u001b[39m booster\u001b[38;5;241m.\u001b[39mpredict(\n\u001b[1;32m    132\u001b[0m     bdt_test_dict[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfold_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m], \n\u001b[1;32m    133\u001b[0m     iteration_range\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, booster\u001b[38;5;241m.\u001b[39mbest_iteration\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    134\u001b[0m )[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 136\u001b[0m gg_ggf_preds \u001b[38;5;241m=\u001b[39m \u001b[43mbooster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDMatrix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_hlf_test_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfold_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfold_idx\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mgg_bool\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxgb_label_test_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfold_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfold_idx\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mgg_bool\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mabs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight_test_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfold_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfold_idx\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mgg_bool\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m999.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhlf_vars_columns_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfold_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfold_idx\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43miteration_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbooster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_iteration\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    144\u001b[0m tth_ggf_preds \u001b[38;5;241m=\u001b[39m booster\u001b[38;5;241m.\u001b[39mpredict(\n\u001b[1;32m    145\u001b[0m     xgb\u001b[38;5;241m.\u001b[39mDMatrix(\n\u001b[1;32m    146\u001b[0m         data\u001b[38;5;241m=\u001b[39mdata_hlf_test_dict[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfold_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m][tth_bool], label\u001b[38;5;241m=\u001b[39mxgb_label_test_dict[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfold_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m][tth_bool], \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m     iteration_range\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, booster\u001b[38;5;241m.\u001b[39mbest_iteration\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    151\u001b[0m )[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    153\u001b[0m \u001b[38;5;66;03m# def masked_mean(data, mask_val):\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;66;03m#     masked_x_sample = np.ma.array(data, mask=(data == mask_val))\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;66;03m#     return masked_x_sample.mean(axis=0)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;66;03m#     sorted_idxs_for_print = np.argsort(avgGJet_minus_avgttH)[::-1]\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m#     print(f\"Average GJet - Average ttH \\n{[f'{hlf_varnames_list[i]}, {avgGJet_minus_avgttH[i]}' for i in sorted_idxs_for_print]}\\n{'-'*60}\")\u001b[39;00m\n",
      "File \u001b[0;32m~/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/xgboost/core.py:1914\u001b[0m, in \u001b[0;36mBooster.predict\u001b[0;34m(self, data, output_margin, ntree_limit, pred_leaf, pred_contribs, approx_contribs, pred_interactions, validate_features, training, iteration_range, strict_shape)\u001b[0m\n\u001b[1;32m   1911\u001b[0m shape \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mPOINTER(c_bst_ulong)()\n\u001b[1;32m   1912\u001b[0m dims \u001b[38;5;241m=\u001b[39m c_bst_ulong()\n\u001b[1;32m   1913\u001b[0m _check_call(\n\u001b[0;32m-> 1914\u001b[0m     \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterPredictFromDMatrix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1915\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1916\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1917\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfrom_pystr_to_cstr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdims\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1921\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1922\u001b[0m )\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _prediction_output(shape, dims, preds, \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resample_ = 4\n",
    "RESAMPLE = (resample_) * 10  # Set to False for no resampling, otherwise sets the number of times to duplicate gjet data for resampling\n",
    "\n",
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"mass_sculpting_resample\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "score_cuts = [0.0, 0.7, 0.99, 0.999, 0.9995]\n",
    "label_arr = [f'score above {score_cut}' for score_cut in score_cuts]\n",
    "plot_vars = ['mass', 'dijet_mass', 'HHbbggCandidate_mass']\n",
    "        \n",
    "if 'old_test_dicts' not in globals():\n",
    "    old_test_dicts = {\n",
    "        'data_hlf_test_dict': copy.deepcopy(data_hlf_test_dict),\n",
    "        'data_test_aux_dict': copy.deepcopy(data_test_aux_dict),\n",
    "        'weight_test_dict': copy.deepcopy(weight_test_dict),\n",
    "        'weights_plot_test': copy.deepcopy(weights_plot_test),\n",
    "        'xgb_label_test_dict': copy.deepcopy(xgb_label_test_dict),\n",
    "    }\n",
    "elif 'old_test_dicts' in globals():\n",
    "    data_hlf_test_dict = copy.deepcopy(old_test_dicts['data_hlf_test_dict'])\n",
    "    data_test_aux_dict = copy.deepcopy(old_test_dicts['data_test_aux_dict'])\n",
    "    weight_test_dict = copy.deepcopy(old_test_dicts['weight_test_dict'])\n",
    "    weights_plot_test = copy.deepcopy(old_test_dicts['weights_plot_test'])\n",
    "    xgb_label_test_dict = copy.deepcopy(old_test_dicts['xgb_label_test_dict'])\n",
    "\n",
    "BDT_perf_resample = {\n",
    "    f'preds{score_cut}': copy.deepcopy({plot_var: list() for plot_var in plot_vars}) for score_cut in score_cuts\n",
    "}\n",
    "GJet_preds = []\n",
    "mean_values = {\n",
    "    'gj': list(),\n",
    "    'gg': list(),\n",
    "    'tth': list()\n",
    "}\n",
    "\n",
    "for fold_idx in range(len(bdt_train_dict)):\n",
    "    booster = xgb.Booster(param)\n",
    "    booster.load_model(os.path.join(OUTPUT_DIRPATH, f'{CURRENT_TIME}_BDT_fold{fold_idx}.model'))\n",
    "\n",
    "    # gj_bool = (data_test_aux_dict[f\"fold_{fold_idx}\"].loc[:, 'sample_name'] == \"GJetPt20To40\") | (data_test_aux_dict[f\"fold_{fold_idx}\"].loc[:, 'sample_name'] == \"GJetPt40\")\n",
    "    # gj_bool = (data_test_aux_dict[f\"fold_{fold_idx}\"].loc[:, 'sample_name'] == \"GJetPt40\")\n",
    "    nonres_bool = (data_test_aux_dict[f\"fold_{fold_idx}\"].loc[:, 'sample_name'] == \"GGJets\") | (data_test_aux_dict[f\"fold_{fold_idx}\"].loc[:, 'sample_name'] == \"GJetPt20To40\") | (data_test_aux_dict[f\"fold_{fold_idx}\"].loc[:, 'sample_name'] == \"GJetPt40\")\n",
    "\n",
    "    data_hlf_test_dict[f\"fold_{fold_idx}\"] = resample_grow_np(data_hlf_test_dict[f\"fold_{fold_idx}\"], nonres_bool, resample_)\n",
    "    data_test_aux_dict[f\"fold_{fold_idx}\"] = resample_grow_pd(data_test_aux_dict[f\"fold_{fold_idx}\"], nonres_bool, resample_)\n",
    "    weight_test_dict[f\"fold_{fold_idx}\"] = resample_grow_np(weight_test_dict[f\"fold_{fold_idx}\"], nonres_bool, resample_)\n",
    "    weights_plot_test[f\"fold_{fold_idx}\"] = resample_grow_np(weights_plot_test[f\"fold_{fold_idx}\"], nonres_bool, resample_)\n",
    "    xgb_label_test_dict[f\"fold_{fold_idx}\"] = resample_grow_np(xgb_label_test_dict[f\"fold_{fold_idx}\"], nonres_bool, resample_)\n",
    "\n",
    "    gg_bool = (data_test_aux_dict[f\"fold_{fold_idx}\"].loc[:, 'sample_name'] == \"GGJets\")\n",
    "    tth_bool = (data_test_aux_dict[f\"fold_{fold_idx}\"].loc[:, 'sample_name'] == \"ttHToGG\")\n",
    "    # gj_bool = (data_test_aux_dict[f\"fold_{fold_idx}\"].loc[:, 'sample_name'] == \"GJetPt40\")\n",
    "    gj_bool = (data_test_aux_dict[f\"fold_{fold_idx}\"].loc[:, 'sample_name'] == \"GJetPt20To40\") | (data_test_aux_dict[f\"fold_{fold_idx}\"].loc[:, 'sample_name'] == \"GJetPt40\")\n",
    "    hh_bool = (data_test_aux_dict[f\"fold_{fold_idx}\"].loc[:, 'sample_name'] == \"GluGluToHH\")\n",
    "    nonres_bool = (data_test_aux_dict[f\"fold_{fold_idx}\"].loc[:, 'sample_name'] == \"GGJets\") | (data_test_aux_dict[f\"fold_{fold_idx}\"].loc[:, 'sample_name'] == \"GJetPt20To40\") | (data_test_aux_dict[f\"fold_{fold_idx}\"].loc[:, 'sample_name'] == \"GJetPt40\")\n",
    "\n",
    "\n",
    "    for var_idx, plot_var in enumerate(plot_vars):\n",
    "        print(f\"fold{fold_idx} for {plot_var} plot\\n\" + \"-\"*60)\n",
    "\n",
    "        plot_dirpath_ = os.path.join(plot_dirpath, plot_var)\n",
    "        if not os.path.exists(plot_dirpath_):\n",
    "            os.makedirs(plot_dirpath_)\n",
    "\n",
    "        for _ in range(RESAMPLE // resample_):\n",
    "\n",
    "            for particle_type in ['lead', 'sublead']:\n",
    "\n",
    "                gg_mvaID = data_hlf_test_dict[f\"fold_{fold_idx}\"][\n",
    "                    gg_bool, \n",
    "                    hlf_vars_columns_dict[f\"fold_{fold_idx}\"][f\"{particle_type}_mvaID\"]\n",
    "                ]\n",
    "                data_hlf_test_dict[f\"fold_{fold_idx}\"][\n",
    "                    gj_bool, \n",
    "                    hlf_vars_columns_dict[f\"fold_{fold_idx}\"][f\"{particle_type}_mvaID\"]\n",
    "                ] = resample_from_var(\n",
    "                    gg_mvaID, \n",
    "                    weights_plot_test[f\"fold_{fold_idx}\"][gg_bool],\n",
    "                    np.sum(gj_bool),\n",
    "                    bins=190\n",
    "                )\n",
    "\n",
    "                tth_pNetB = data_hlf_test_dict[f\"fold_{fold_idx}\"][\n",
    "                    tth_bool, \n",
    "                    hlf_vars_columns_dict[f\"fold_{fold_idx}\"][f\"{particle_type}_bjet_btagPNetB\"]\n",
    "                ]\n",
    "                data_hlf_test_dict[f\"fold_{fold_idx}\"][\n",
    "                    nonres_bool, \n",
    "                    hlf_vars_columns_dict[f\"fold_{fold_idx}\"][f\"{particle_type}_bjet_btagPNetB\"]\n",
    "                ] = resample_from_var(\n",
    "                    tth_pNetB, \n",
    "                    weights_plot_test[f\"fold_{fold_idx}\"][tth_bool],\n",
    "                    np.sum(nonres_bool),\n",
    "                    bins=100\n",
    "                )\n",
    "\n",
    "                tth_sigmaE = data_hlf_test_dict[f\"fold_{fold_idx}\"][\n",
    "                    tth_bool, \n",
    "                    hlf_vars_columns_dict[f\"fold_{fold_idx}\"][f\"{particle_type}_sigmaE_over_E\"]\n",
    "                ]\n",
    "                data_hlf_test_dict[f\"fold_{fold_idx}\"][\n",
    "                    gj_bool, \n",
    "                    hlf_vars_columns_dict[f\"fold_{fold_idx}\"][f\"{particle_type}_sigmaE_over_E\"]\n",
    "                ] = resample_from_var(\n",
    "                    tth_sigmaE, \n",
    "                    np.abs(weights_plot_test[f\"fold_{fold_idx}\"][tth_bool]),\n",
    "                    np.sum(gj_bool),\n",
    "                    bins=100\n",
    "                )\n",
    "            hh_dijet = data_hlf_test_dict[f\"fold_{fold_idx}\"][\n",
    "                hh_bool, \n",
    "                hlf_vars_columns_dict[f\"fold_{fold_idx}\"][\"dijet_mass\"]\n",
    "            ]\n",
    "            data_hlf_test_dict[f\"fold_{fold_idx}\"][\n",
    "                nonres_bool, \n",
    "                hlf_vars_columns_dict[f\"fold_{fold_idx}\"][\"dijet_mass\"]\n",
    "            ] = resample_from_var(\n",
    "                hh_dijet, \n",
    "                np.abs(weights_plot_test[f\"fold_{fold_idx}\"][hh_bool]),\n",
    "                np.sum(nonres_bool),\n",
    "                bins=100\n",
    "            )\n",
    "\n",
    "            bdt_test_dict[f\"fold_{fold_idx}\"] = xgb.DMatrix(\n",
    "                data=data_hlf_test_dict[f\"fold_{fold_idx}\"][nonres_bool], label=xgb_label_test_dict[f\"fold_{fold_idx}\"][nonres_bool], \n",
    "                weight=np.abs(weight_test_dict[f\"fold_{fold_idx}\"])[nonres_bool],\n",
    "                missing=-999.0, feature_names=list(hlf_vars_columns_dict[f\"fold_{fold_idx}\"])\n",
    "            )\n",
    "\n",
    "            gjet_ggf_preds = booster.predict(\n",
    "                bdt_test_dict[f\"fold_{fold_idx}\"], \n",
    "                iteration_range=(0, booster.best_iteration+1)\n",
    "            )[:, 0]\n",
    "\n",
    "            gg_ggf_preds = booster.predict(\n",
    "                xgb.DMatrix(\n",
    "                    data=data_hlf_test_dict[f\"fold_{fold_idx}\"][gg_bool], label=xgb_label_test_dict[f\"fold_{fold_idx}\"][gg_bool], \n",
    "                    weight=np.abs(weight_test_dict[f\"fold_{fold_idx}\"])[gg_bool],\n",
    "                    missing=-999.0, feature_names=list(hlf_vars_columns_dict[f\"fold_{fold_idx}\"])\n",
    "                ), \n",
    "                iteration_range=(0, booster.best_iteration+1)\n",
    "            )[:, 0]\n",
    "            tth_ggf_preds = booster.predict(\n",
    "                xgb.DMatrix(\n",
    "                    data=data_hlf_test_dict[f\"fold_{fold_idx}\"][tth_bool], label=xgb_label_test_dict[f\"fold_{fold_idx}\"][tth_bool], \n",
    "                    weight=np.abs(weight_test_dict[f\"fold_{fold_idx}\"])[tth_bool],\n",
    "                    missing=-999.0, feature_names=list(hlf_vars_columns_dict[f\"fold_{fold_idx}\"])\n",
    "                ), \n",
    "                iteration_range=(0, booster.best_iteration+1)\n",
    "            )[:, 0]\n",
    "\n",
    "            # def masked_mean(data, mask_val):\n",
    "            #     masked_x_sample = np.ma.array(data, mask=(data == mask_val))\n",
    "            #     return masked_x_sample.mean(axis=0)\n",
    "            # mean_values['gj'].append(masked_mean(data_hlf_test_dict[f\"fold_{fold_idx}\"][gj_bool][gjet_ggf_preds >= 0.99], mask_val=-999.0))\n",
    "            # mean_values['gg'].append(masked_mean(data_hlf_test_dict[f\"fold_{fold_idx}\"][gg_bool][gg_ggf_preds >= 0.99], mask_val=-999.0))\n",
    "            # mean_values['tth'].append(masked_mean(data_hlf_test_dict[f\"fold_{fold_idx}\"][tth_bool][tth_ggf_preds >= 0.99], mask_val=-999.0))\n",
    "\n",
    "            # print(f\"Average GJet >= 0.99 \\n{average0p99_gjet}\\n{'-'*60}\")\n",
    "            # print(f\"Average GG >= 0.99 \\n{average0p99_gg}\\n{'-'*60}\")\n",
    "            # print(f\"Average ttH >= 0.99 \\n{average0p99_tth}\\n{'-'*60}\")\n",
    "\n",
    "            # hlf_varnames_list = ['' for _ in range(len(hlf_vars_columns_dict[f\"fold_{fold_idx}\"]))]\n",
    "            # for key, value in hlf_vars_columns_dict[f\"fold_{fold_idx}\"].items():\n",
    "            #     hlf_varnames_list[value] = key\n",
    "\n",
    "            # print(hlf_varnames_list)\n",
    "            # print('='*60)\n",
    "\n",
    "            # if _ == 9:\n",
    "            #     avgGJet_minus_avgGG = np.mean(mean_values['gj'], axis=0) - np.mean(mean_values['gg'], axis=0)\n",
    "            #     sorted_idxs_for_print = np.argsort(avgGJet_minus_avgGG)[::-1]\n",
    "            #     print(f\"Average GJet - Average GG \\n{[f'{hlf_varnames_list[i]}, {avgGJet_minus_avgGG[i]}' for i in sorted_idxs_for_print]}\\n{'-'*60}\")\n",
    "            #     avgGJet_minus_avgttH = np.mean(mean_values['gj'], axis=0) - np.mean(mean_values['tth'], axis=0)\n",
    "            #     sorted_idxs_for_print = np.argsort(avgGJet_minus_avgttH)[::-1]\n",
    "            #     print(f\"Average GJet - Average ttH \\n{[f'{hlf_varnames_list[i]}, {avgGJet_minus_avgttH[i]}' for i in sorted_idxs_for_print]}\\n{'-'*60}\")\n",
    "\n",
    "            if np.sum([len(GJet_preds[i]) for i in range(len(GJet_preds))]) < 100000:\n",
    "                GJet_preds.append(gjet_ggf_preds[gjet_ggf_preds > 0.9])\n",
    "\n",
    "            # print(f\"Num scores above 0.99 = {np.sum(all_ggf_preds > score_cuts[-3])}\")\n",
    "            # print(f\"Num scores above 0.991 = {np.sum(all_ggf_preds > 0.991)}\")\n",
    "            # print(f\"Num scores above 0.995 = {np.sum(all_ggf_preds > 0.995)}\")\n",
    "            # print(f\"Num scores above 0.999 = {np.sum(all_ggf_preds > score_cuts[-2])}\")\n",
    "            # print(f\"Num scores above 0.9995 = {np.sum(all_ggf_preds > score_cuts[-1])}\")\n",
    "\n",
    "            for score_cut in score_cuts:\n",
    "                if len(BDT_perf_resample[f'preds{score_cut}'][plot_var]) >= 10000:\n",
    "                    continue\n",
    "\n",
    "                BDT_perf_resample[f'preds{score_cut}'][plot_var].append(\n",
    "                    data_test_aux_dict[f'fold_{fold_idx}'].loc[nonres_bool, plot_var].to_numpy()[gjet_ggf_preds > score_cut]\n",
    "                )\n",
    "        if fold_idx == 0 and plot_var == 'mass':\n",
    "            plt.figure()\n",
    "            plt.hist(np.concatenate(GJet_preds), bins=400, range=(0.9, 1.))\n",
    "            plt.savefig(os.path.join(plot_dirpath_, \"GJet_output_dist_with_resample0p9\"))\n",
    "\n",
    "        test_hists = [hist.Hist(VARIABLES[plot_var]).fill(var=np.concatenate(BDT_perf_resample[f'preds{score_cut}'][plot_var])) for score_cut in score_cuts]\n",
    "        make_input_plot(\n",
    "            plot_dirpath_, plot_var,\n",
    "            test_hists, \n",
    "            fold_idx=fold_idx, labels=label_arr, \n",
    "            plot_prefix='test_non-res_scoreCut_'\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"pre_std\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "label_arr_fold = [\n",
    "    MC_NAMES_PRETTY[\"GluGluToHH\"]+\" train\", MC_NAMES_PRETTY[\"GluGluToHH\"]+\" val\", MC_NAMES_PRETTY[\"GluGluToHH\"]+\" test\",\n",
    "    MC_NAMES_PRETTY[\"ttHToGG\"]+\" train\", MC_NAMES_PRETTY[\"ttHToGG\"]+\" val\", MC_NAMES_PRETTY[\"ttHToGG\"]+\" test\",\n",
    "    # MC_NAMES_PRETTY[\"single-H\"]+\" train\", MC_NAMES_PRETTY[\"single-H\"]+\" val\", MC_NAMES_PRETTY[\"single-H\"]+\" test\",\n",
    "    # MC_NAMES_PRETTY[\"non-res\"]+\" train\", MC_NAMES_PRETTY[\"non-res\"]+\" val\", MC_NAMES_PRETTY[\"non-res\"]+\" test\",\n",
    "    MC_NAMES_PRETTY[\"VH\"]+\" train\", MC_NAMES_PRETTY[\"VH\"]+\" val\", MC_NAMES_PRETTY[\"VH\"]+\" test\",\n",
    "    MC_NAMES_PRETTY[\"non-res + ggFH + VBFH\"]+\" train\", MC_NAMES_PRETTY[\"non-res + ggFH + VBFH\"]+\" val\", MC_NAMES_PRETTY[\"non-res + ggFH + VBFH\"]+\" test\",\n",
    "]\n",
    "# Loop over and plot the per-fold variables\n",
    "for fold_idx in range(len(hlf_vars_columns_dict)):\n",
    "\n",
    "    for var_name in hlf_vars_columns_dict['fold_0']:\n",
    "        if var_name in {'puppiMET_eta'}:\n",
    "            continue\n",
    "\n",
    "        plot_dirpath_ = os.path.join(plot_dirpath, var_name)\n",
    "        if not os.path.exists(plot_dirpath_):\n",
    "            os.makedirs(plot_dirpath_)\n",
    "\n",
    "        train_hists, val_hists, test_hists = {}, {}, {}\n",
    "        for i, sample_name in enumerate(order):\n",
    "            train_mask = xgb_label_train_dict[f'fold_{fold_idx}'] == i\n",
    "            val_mask = xgb_label_val_dict[f'fold_{fold_idx}'] == i\n",
    "            test_mask = xgb_label_test_dict[f'fold_{fold_idx}'] == i\n",
    "\n",
    "            train_np = (\n",
    "                data_df_dict[f'fold_{fold_idx}'].iloc[train_idxs_dict[f'fold_{fold_idx}']]\n",
    "            ).loc[train_mask, var_name].to_numpy()\n",
    "            val_np = (\n",
    "                data_df_dict[f'fold_{fold_idx}'].iloc[val_idxs_dict[f'fold_{fold_idx}']]\n",
    "            ).loc[val_mask, var_name].to_numpy()\n",
    "            test_np = data_test_df_dict[f'fold_{fold_idx}'].loc[test_mask, var_name].to_numpy()\n",
    "\n",
    "            train_hists[sample_name] = hist.Hist(VARIABLES[var_name]).fill(var=train_np)\n",
    "            val_hists[sample_name] = hist.Hist(VARIABLES[var_name]).fill(var=val_np)\n",
    "            test_hists[sample_name] = hist.Hist(VARIABLES[var_name]).fill(var=test_np)\n",
    "    \n",
    "            make_input_plot(\n",
    "                plot_dirpath_, var_name,\n",
    "                [train_hists[sample_name], val_hists[sample_name], test_hists[sample_name]], \n",
    "                fold_idx=fold_idx, labels=label_arr_fold[3*i : 3*(i+1)], plot_prefix=f'train_val_test_{sample_name}_'\n",
    "            )\n",
    "        for j, (plot_type, histdict) in enumerate([('train_', train_hists), ('val_', val_hists), ('test_', test_hists)]):\n",
    "            make_input_plot(\n",
    "                plot_dirpath_, var_name,\n",
    "                [histdict[sample_name] for sample_name in order], \n",
    "                fold_idx=fold_idx, labels=label_arr_fold[j::3], plot_prefix=plot_type\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"post_std\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "label_arr_fold = [\n",
    "    MC_NAMES_PRETTY[\"GluGluToHH\"]+\" train\", MC_NAMES_PRETTY[\"GluGluToHH\"]+\" val\", MC_NAMES_PRETTY[\"GluGluToHH\"]+\" test\",\n",
    "    MC_NAMES_PRETTY[\"ttHToGG\"]+\" train\", MC_NAMES_PRETTY[\"ttHToGG\"]+\" val\", MC_NAMES_PRETTY[\"ttHToGG\"]+\" test\",\n",
    "    # MC_NAMES_PRETTY[\"single-H\"]+\" train\", MC_NAMES_PRETTY[\"single-H\"]+\" val\", MC_NAMES_PRETTY[\"single-H\"]+\" test\",\n",
    "    # MC_NAMES_PRETTY[\"non-res\"]+\" train\", MC_NAMES_PRETTY[\"non-res\"]+\" val\", MC_NAMES_PRETTY[\"non-res\"]+\" test\",\n",
    "    MC_NAMES_PRETTY[\"VH\"]+\" train\", MC_NAMES_PRETTY[\"VH\"]+\" val\", MC_NAMES_PRETTY[\"VH\"]+\" test\",\n",
    "    MC_NAMES_PRETTY[\"non-res + ggFH + VBFH\"]+\" train\", MC_NAMES_PRETTY[\"non-res + ggFH + VBFH\"]+\" val\", MC_NAMES_PRETTY[\"non-res + ggFH + VBFH\"]+\" test\",\n",
    "]\n",
    "# Loop over and plot the per-fold variables\n",
    "for fold_idx in range(len(hlf_vars_columns_dict)):\n",
    "\n",
    "    for var_idx, var_name in enumerate(hlf_vars_columns_dict['fold_0']):\n",
    "        if var_name in {'puppiMET_eta'}:\n",
    "            continue\n",
    "\n",
    "        plot_dirpath_ = os.path.join(plot_dirpath, var_name)\n",
    "        if not os.path.exists(plot_dirpath_):\n",
    "            os.makedirs(plot_dirpath_)\n",
    "\n",
    "        train_hists, val_hists, test_hists = {}, {}, {}\n",
    "        for i, sample_name in enumerate(order):\n",
    "            train_mask = xgb_label_train_dict[f'fold_{fold_idx}'] == i\n",
    "            val_mask = xgb_label_val_dict[f'fold_{fold_idx}'] == i\n",
    "            test_mask = xgb_label_test_dict[f'fold_{fold_idx}'] == i\n",
    "\n",
    "            train_np = train_data_dict[f'fold_{fold_idx}'][train_mask, var_idx]\n",
    "            val_np = val_data_dict[f'fold_{fold_idx}'][val_mask, var_idx]\n",
    "            test_np = data_hlf_test_dict[f'fold_{fold_idx}'][test_mask, var_idx]\n",
    "\n",
    "            train_hists[sample_name] = hist.Hist(VARIABLES_STD[var_name]).fill(var=train_np)\n",
    "            val_hists[sample_name] = hist.Hist(VARIABLES_STD[var_name]).fill(var=val_np)\n",
    "            test_hists[sample_name] = hist.Hist(VARIABLES_STD[var_name]).fill(var=test_np)\n",
    "    \n",
    "            make_input_plot(\n",
    "                plot_dirpath_, var_name,\n",
    "                [train_hists[sample_name], val_hists[sample_name], test_hists[sample_name]], \n",
    "                fold_idx=fold_idx, labels=label_arr_fold[3*i : 3*(i+1)], plot_prefix=f'train_val_test_{sample_name}_'\n",
    "            )\n",
    "        for j, (plot_type, histdict) in enumerate([('train_', train_hists), ('val_', val_hists), ('test_', test_hists)]):\n",
    "            make_input_plot(\n",
    "                plot_dirpath_, var_name,\n",
    "                [histdict[sample_name] for sample_name in order], \n",
    "                fold_idx=fold_idx, labels=label_arr_fold[j::3], plot_prefix=plot_type\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save out new parquets for Yibo to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL_DATA_ON_ALL_FOLDS = False\n",
    "\n",
    "# load and pre-process the data\n",
    "DATA_FILEPATHS_DICT = {\n",
    "    'Data': [\n",
    "        lpc_fileprefix+f\"/Run3_2022preEE_merged_v3/Data_EraC/nominal/*\", \n",
    "        lpc_fileprefix+f\"/Run3_2022preEE_merged_v3/Data_EraD/nominal/*\",\n",
    "        lpc_fileprefix+f\"/Run3_2022postEE_merged_v3/Data_EraE/nominal/*\",\n",
    "        lpc_fileprefix+f\"/Run3_2022postEE_merged_v3/Data_EraF/nominal/*\",\n",
    "        lpc_fileprefix+f\"/Run3_2022postEE_merged_v3/Data_EraG/nominal/*\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "std_dirpath = '/uscms/home/tsievert/nobackup/XHYbbgg/HHtobbyy/MultiClassBDT_model_outputs/v2/nonres_and_ttH_and_DNN_vars/2024-11-22_16-40-53'\n",
    "\n",
    "(\n",
    "    NOTHING_IGNORE,\n",
    "    DATA_data_df_dict, DATA_data_test_df_dict, \n",
    "    DATA_data_hlf_dict, DATA_label_dict,\n",
    "    DATA_data_hlf_test_dict, DATA_label_test_dict, \n",
    "    DATA_hlf_vars_columns_dict,\n",
    "    DATA_data_aux_dict, DATA_data_test_aux_dict\n",
    ") = process_data(\n",
    "    DATA_FILEPATHS_DICT, OUTPUT_DIRPATH, order=['Data'], seed=SEED, mod_vals=MOD_VALS, k_fold_test=True,\n",
    "    save=False, std_json_dirpath=std_dirpath\n",
    ")\n",
    "\n",
    "BDT_DATA_preds = []\n",
    "\n",
    "bdt_train_data_dict, bdt_test_data_dict = {}, {}\n",
    "for fold_idx in range(len(DATA_label_test_dict)):\n",
    "    \n",
    "    bdt_train_data_dict[f\"fold_{fold_idx}\"] = xgb.DMatrix(\n",
    "        data=DATA_data_hlf_dict[f\"fold_{fold_idx}\"], label=DATA_label_dict[f\"fold_{fold_idx}\"], \n",
    "        missing=-999.0, feature_names=list(DATA_hlf_vars_columns_dict[f\"fold_{fold_idx}\"])\n",
    "    )\n",
    "    bdt_test_data_dict[f\"fold_{fold_idx}\"] = xgb.DMatrix(\n",
    "        data=DATA_data_hlf_test_dict[f\"fold_{fold_idx}\"], label=DATA_label_test_dict[f\"fold_{fold_idx}\"], \n",
    "        missing=-999.0, feature_names=list(DATA_hlf_vars_columns_dict[f\"fold_{fold_idx}\"])\n",
    "    )\n",
    "\n",
    "    booster = xgb.Booster(param)\n",
    "    booster.load_model(os.path.join(OUTPUT_DIRPATH, f'{CURRENT_TIME}_BDT_fold{fold_idx}.model'))\n",
    "\n",
    "    if EVAL_DATA_ON_ALL_FOLDS:\n",
    "\n",
    "        BDT_train_preds = booster.predict(\n",
    "            bdt_train_data_dict[f\"fold_{fold_idx}\"], \n",
    "            iteration_range=(0, booster.best_iteration+1)\n",
    "        )\n",
    "        BDT_test_preds = booster.predict(\n",
    "            bdt_test_data_dict[f\"fold_{fold_idx}\"], \n",
    "            iteration_range=(0, booster.best_iteration+1)\n",
    "        )\n",
    "\n",
    "        BDT_all_preds = np.concatenate([BDT_train_preds, BDT_test_preds])\n",
    "        BDT_all_preds = BDT_all_preds[\n",
    "            np.argsort(\n",
    "                np.concatenate([DATA_data_aux_dict[f\"fold_{fold_idx}\"].loc[:, 'hash'].to_numpy(), DATA_data_test_aux_dict[f\"fold_{fold_idx}\"].loc[:, 'hash'].to_numpy()])\n",
    "            )\n",
    "        ].tolist()\n",
    "\n",
    "        if fold_idx == 0:\n",
    "            BDT_DATA_preds = copy.deepcopy(BDT_all_preds)\n",
    "        else:\n",
    "            BDT_DATA_preds += BDT_all_preds\n",
    "\n",
    "            if fold_idx == len(DATA_label_test_dict) - 1:\n",
    "                BDT_DATA_preds = BDT_DATA_preds / len(DATA_label_test_dict)\n",
    "    else:\n",
    "\n",
    "        BDT_DATA_preds.append(\n",
    "            booster.predict(\n",
    "                bdt_test_data_dict[f\"fold_{fold_idx}\"], \n",
    "                iteration_range=(0, booster.best_iteration+1)\n",
    "            ).tolist()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Plot to show data labels look ok\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "hist_axis = hist.axis.Regular(100, 0., 1., name='var', growth=False, underflow=False, overflow=False)\n",
    "\n",
    "data_hists, data_plot_labels = [], []\n",
    "for fold_idx in range(len(BDT_DATA_preds)):\n",
    "\n",
    "    data_hists.append(\n",
    "        hist.Hist(hist_axis, storage='weight').fill(\n",
    "            var=np.array(BDT_DATA_preds[fold_idx])[:, 0],\n",
    "        )\n",
    "    )\n",
    "    data_plot_labels.append(f\"fold {fold_idx}\")\n",
    "\n",
    "hep.histplot(\n",
    "    data_hists,\n",
    "    alpha=0.5, density=False, histtype='step',\n",
    "    label=data_plot_labels\n",
    ")\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022preEE_merged_v3_MultiBDT_output/GluGluToHH/nominal/GluGluToHH_nominal_MultiBDT_output.parquet\n",
      "============================================================\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022postEE_merged_v3_MultiBDT_output/GluGluToHH/nominal/GluGluToHH_nominal_MultiBDT_output.parquet\n",
      "============================================================\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022preEE_merged_v3_MultiBDT_output/ttHToGG/nominal/ttHToGG_nominal_MultiBDT_output.parquet\n",
      "============================================================\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022postEE_merged_v3_MultiBDT_output/ttHToGG/nominal/ttHToGG_nominal_MultiBDT_output.parquet\n",
      "============================================================\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022preEE_merged_v3_MultiBDT_output/GluGluHToGG/nominal/GluGluHToGG_nominal_MultiBDT_output.parquet\n",
      "============================================================\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022postEE_merged_v3_MultiBDT_output/GluGluHToGG/nominal/GluGluHToGG_nominal_MultiBDT_output.parquet\n",
      "============================================================\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022preEE_merged_v3_MultiBDT_output/VBFHToGG/nominal/VBFHToGG_nominal_MultiBDT_output.parquet\n",
      "============================================================\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022postEE_merged_v3_MultiBDT_output/VBFHToGG/nominal/VBFHToGG_nominal_MultiBDT_output.parquet\n",
      "============================================================\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022preEE_merged_v3_MultiBDT_output/VHToGG/nominal/VHToGG_nominal_MultiBDT_output.parquet\n",
      "============================================================\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022postEE_merged_v3_MultiBDT_output/VHToGG/nominal/VHToGG_nominal_MultiBDT_output.parquet\n",
      "============================================================\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022preEE_merged_v3_MultiBDT_output/GGJets/nominal/GGJets_nominal_MultiBDT_output.parquet\n",
      "============================================================\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022postEE_merged_v3_MultiBDT_output/GGJets/nominal/GGJets_nominal_MultiBDT_output.parquet\n",
      "============================================================\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022preEE_merged_v3_MultiBDT_output/GJetPt20To40/nominal/GJetPt20To40_nominal_MultiBDT_output.parquet\n",
      "============================================================\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022postEE_merged_v3_MultiBDT_output/GJetPt20To40/nominal/GJetPt20To40_nominal_MultiBDT_output.parquet\n",
      "============================================================\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022preEE_merged_v3_MultiBDT_output/GJetPt40/nominal/GJetPt40_nominal_MultiBDT_output.parquet\n",
      "============================================================\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022postEE_merged_v3_MultiBDT_output/GJetPt40/nominal/GJetPt40_nominal_MultiBDT_output.parquet\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "if 'BDT_perf' not in globals():\n",
    "    with open(os.path.join(OUTPUT_DIRPATH, CURRENT_TIME+\"_BDT_perf.json\"), 'r') as f:\n",
    "        BDT_perf = json.load(f)\n",
    "\n",
    "# Sorts the predictions to map the output to the correct event\n",
    "def sorted_preds(preds, data_aux, sample, sorted_preds=False):\n",
    "    if not sorted_preds:\n",
    "        flat_preds = np.concatenate([preds[fold_idx] for fold_idx in range(len(data_aux))])\n",
    "        preds_sort = np.argsort(\n",
    "            np.concatenate([data_aux[f\"fold_{fold_idx}\"].loc[:, 'hash'].to_numpy() for fold_idx in range(len(data_aux))])\n",
    "        )\n",
    "    else:\n",
    "        flat_preds = preds\n",
    "        preds_sort = np.arange(len(flat_preds))\n",
    "\n",
    "    sample_sort = np.argsort(np.argsort(\n",
    "        ak.to_numpy(sample['hash'], allow_missing=False)\n",
    "    ))\n",
    "\n",
    "    return flat_preds[preds_sort][sample_sort]\n",
    "\n",
    "# Load parquet files #\n",
    "for i, sample_name in enumerate(order):\n",
    "    for dirpath in DATA_FILEPATHS_DICT[sample_name]:\n",
    "        parquet_filepath = glob.glob(dirpath)[0]\n",
    "        sample = ak.from_parquet(parquet_filepath)\n",
    "\n",
    "        sample_preds = [\n",
    "            np.array(BDT_perf[sample_name]['preds'][fold_idx])[bdt_test_dict[f\"fold_{fold_idx}\"].get_label() == i] for fold_idx in range(len(BDT_perf[sample_name]['preds']))\n",
    "        ]\n",
    "        sample_data_aux = {\n",
    "            f\"fold_{fold_idx}\": data_test_aux_dict[f\"fold_{fold_idx}\"].loc[bdt_test_dict[f\"fold_{fold_idx}\"].get_label() == i] for fold_idx in range(len(BDT_perf[sample_name]['preds']))\n",
    "        }\n",
    "\n",
    "        sample['MultiBDT_output'] = sorted_preds(\n",
    "            sample_preds, sample_data_aux, sample\n",
    "        )\n",
    "\n",
    "        dest_filepath = parquet_filepath[:parquet_filepath.find('v3')+2] + '_MultiBDT_output' + parquet_filepath[parquet_filepath.find('v3')+2:parquet_filepath.rfind('.')] + '_MultiBDT_output' + parquet_filepath[parquet_filepath.rfind('.'):]\n",
    "        if not os.path.exists(dest_filepath[:dest_filepath.rfind('/')]):\n",
    "            os.makedirs(dest_filepath[:dest_filepath.rfind('/')])\n",
    "        print(dest_filepath)\n",
    "        print('='*60)\n",
    "        merged_parquet = ak.to_parquet(sample, dest_filepath)\n",
    "\n",
    "if 'BDT_DATA_preds' in globals():\n",
    "\n",
    "    for dirpath in DATA_FILEPATHS_DICT['Data']:\n",
    "        parquet_filepath = glob.glob(dirpath)[0]\n",
    "        data_sample = ak.from_parquet(parquet_filepath)\n",
    "\n",
    "        data_sample_preds = [\n",
    "            np.array(BDT_DATA_preds[fold_idx]) for fold_idx in range(len(BDT_DATA_preds))\n",
    "        ]\n",
    "        data_sample_aux = {\n",
    "            f\"fold_{fold_idx}\": DATA_data_test_aux_dict[f\"fold_{fold_idx}\"] for fold_idx in range(len(BDT_DATA_preds))\n",
    "        }\n",
    "\n",
    "        sample['MultiBDT_output'] = sorted_preds(\n",
    "            data_sample_preds, data_sample_aux, data_sample,\n",
    "            sorted_preds=True if EVAL_DATA_ON_ALL_FOLDS else False\n",
    "        )\n",
    "\n",
    "        dest_filepath = parquet_filepath[:parquet_filepath.find('v3')+2] + '_MultiBDT_output' + parquet_filepath[parquet_filepath.find('v3')+2:parquet_filepath.rfind('.')] + '_MultiBDT_output' + parquet_filepath[parquet_filepath.rfind('.'):]\n",
    "        if not os.path.exists(dest_filepath[:dest_filepath.rfind('/')]):\n",
    "            os.makedirs(dest_filepath[:dest_filepath.rfind('/')])\n",
    "        print(dest_filepath)\n",
    "        print('='*60)\n",
    "        merged_parquet = ak.to_parquet(sample, dest_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
