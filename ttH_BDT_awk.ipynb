{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmslpcgpu3.fnal.gov      Wed Nov 13 13:41:18 2024  555.42.06\n",
      "[0] Tesla P100-PCIE-12GB | 42°C,   0 % |     0 / 12288 MB |\n"
     ]
    }
   ],
   "source": [
    "# Stdlib packages\n",
    "import copy\n",
    "import datetime\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "# Common Py packages\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "# HEP packages\n",
    "import gpustat\n",
    "import h5py\n",
    "import hist\n",
    "import mplhep as hep\n",
    "import xgboost as xgb\n",
    "from cycler import cycler\n",
    "\n",
    "\n",
    "# ML packages\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "\n",
    "# Module packages\n",
    "from data_processing_BDT import process_data\n",
    "\n",
    "gpustat.print_gpustat()\n",
    "\n",
    "plt.style.use(hep.style.CMS)\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "cmap_petroff10 = [\"#3f90da\", \"#ffa90e\", \"#bd1f01\", \"#94a4a2\", \"#832db6\", \"#a96b59\", \"#e76300\", \"#b9ac70\", \"#717581\", \"#92dadd\"]\n",
    "plt.rcParams.update({\"axes.prop_cycle\": cycler(\"color\", cmap_petroff10)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lpc_fileprefix = \"/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1\"\n",
    "\n",
    "FILEPATHS_DICT = {\n",
    "    'ggF HH': [\n",
    "        lpc_fileprefix+f\"/Run3_2022preEE_merged_v3/GluGluToHH/nominal/*\", \n",
    "        lpc_fileprefix+f\"/Run3_2022postEE_merged_v3/GluGluToHH/nominal/*\"\n",
    "    ],\n",
    "    # 'VBF HH': [\n",
    "    #     lpc_fileprefix+f\"/Run3_2022preEE_merged_v3/VBFHHto2B2G_CV_1_C2V_1_C3_1/nominal/*\", \n",
    "    #     lpc_fileprefix+f\"/Run3_2022postEE_merged_v3/VBFHHto2B2G_CV_1_C2V_1_C3_1/nominal/*\"\n",
    "    # ],\n",
    "    'ttH': [\n",
    "        lpc_fileprefix+f\"/Run3_2022preEE_merged_v3/ttHToGG/nominal/*\", \n",
    "        lpc_fileprefix+f\"/Run3_2022postEE_merged_v3/ttHToGG/nominal/*\"\n",
    "    ],\n",
    "    'non-res + single-H': [\n",
    "        # non-Resonant #\n",
    "        # GG + 3Jets\n",
    "        lpc_fileprefix+f\"/Run3_2022preEE_merged_v3/GGJets/nominal/*\", \n",
    "        lpc_fileprefix+f\"/Run3_2022postEE_merged_v3/GGJets/nominal/*\",\n",
    "        # GJet pT 20-40\n",
    "        lpc_fileprefix+f\"/Run3_2022preEE_merged_v3/GJetPt20To40/nominal/*\", \n",
    "        lpc_fileprefix+f\"/Run3_2022postEE_merged_v3/GJetPt20To40/nominal/*\",\n",
    "        # GJet pT 40-inf\n",
    "        lpc_fileprefix+f\"/Run3_2022preEE_merged_v3/GJetPt40/nominal/*\", \n",
    "        lpc_fileprefix+f\"/Run3_2022postEE_merged_v3/GJetPt40/nominal/*\",\n",
    "        # single-H #\n",
    "        # ggF H\n",
    "        lpc_fileprefix+f\"/Run3_2022preEE_merged_v3/GluGluHToGG/nominal/*\", \n",
    "        lpc_fileprefix+f\"/Run3_2022postEE_merged_v3/GluGluHToGG/nominal/*\",\n",
    "        # VBF H\n",
    "        lpc_fileprefix+f\"/Run3_2022preEE_merged_v3/VBFHToGG/nominal/*\", \n",
    "        lpc_fileprefix+f\"/Run3_2022postEE_merged_v3/VBFHToGG/nominal/*\",\n",
    "        # VH\n",
    "        lpc_fileprefix+f\"/Run3_2022preEE_merged_v3/VHToGG/nominal/*\", \n",
    "        lpc_fileprefix+f\"/Run3_2022postEE_merged_v3/VHToGG/nominal/*\",\n",
    "    ],\n",
    "    # 'VH': [\n",
    "    #     lpc_fileprefix+f\"/Run3_2022preEE_merged_v3/VHToGG/nominal/*\", \n",
    "    #     lpc_fileprefix+f\"/Run3_2022postEE_merged_v3/VHToGG/nominal/*\"\n",
    "    # ],\n",
    "}\n",
    "\n",
    "CURRENT_DIRPATH = str(Path().absolute())\n",
    "VERSION = 'v1'\n",
    "MOD_VALS = (5, 5)\n",
    "VARS = 'nonres_and_ttH_vars'\n",
    "CURRENT_TIME = '2024-11-08_13-13-20'\n",
    "OUTPUT_DIRPATH = os.path.join(CURRENT_DIRPATH, f\"MultiClassBDT_model_outputs/{VERSION}/{VARS}\", CURRENT_TIME)\n",
    "# OUTPUT_DIRPATH = os.path.join(CURRENT_DIRPATH, f\"MultiClassBDT_model_outputs/{VERSION}/{VARS}\")\n",
    "\n",
    "if not os.path.exists(OUTPUT_DIRPATH):\n",
    "    os.makedirs(OUTPUT_DIRPATH)\n",
    "\n",
    "SEED = 21\n",
    "OPTIMIZE_SPACE = False\n",
    "NUM_EPOCHS = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_weights(event_weights, labels, order=None):\n",
    "    if order is None:\n",
    "        order = [i for i in range(np.shape(labels)[0])]\n",
    "    sum_dict, max_sum, max_i = {}, 0, 0\n",
    "    for i, sample_name in enumerate(order):\n",
    "        sum_dict[i] = np.sum(event_weights[labels[:, i] == 1])\n",
    "        if np.sum(event_weights[labels[:, i] == 1]) > max_sum:\n",
    "            max_sum, max_i = np.sum(event_weights[labels[:, i] == 1]), i\n",
    "\n",
    "    label_i = np.sum(\n",
    "        np.tile([i for i in range(np.shape(labels)[1])], (np.shape(labels)[0], 1)) * labels,\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    weight_factors = []\n",
    "    for i in range(len(label_i)):\n",
    "        weight_factors.append(\n",
    "            max_sum / sum_dict[label_i[i]] if label_i[i] != max_i else 1\n",
    "        )\n",
    "    weights = event_weights * np.array(weight_factors)\n",
    "\n",
    "    mean_weight = np.mean(weights)\n",
    "    abs_weights = np.abs(weights)\n",
    "    scaled_weights = abs_weights / mean_weight\n",
    "\n",
    "    return scaled_weights\n",
    "\n",
    "def xgb_labels(labels):\n",
    "    label_i = np.sum(\n",
    "        np.tile([i for i in range(np.shape(labels)[1])], (np.shape(labels)[0], 1)) * labels,\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    return label_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data HLF: (1563192, 48)\n",
      "num ggF HH = 136530\n",
      "num ttH = 277205\n",
      "num non-res + single-H = 1149457\n",
      "Data HLF test: (391785, 48)\n",
      "num ggF HH = 34224\n",
      "num ttH = 69297\n",
      "num non-res + single-H = 288264\n",
      "Data HLF: (1564171, 48)\n",
      "num ggF HH = 136466\n",
      "num ttH = 277452\n",
      "num non-res + single-H = 1150253\n",
      "Data HLF test: (390806, 48)\n",
      "num ggF HH = 34288\n",
      "num ttH = 69050\n",
      "num non-res + single-H = 287468\n",
      "Data HLF: (1563685, 48)\n",
      "num ggF HH = 136638\n",
      "num ttH = 276627\n",
      "num non-res + single-H = 1150420\n",
      "Data HLF test: (391292, 48)\n",
      "num ggF HH = 34116\n",
      "num ttH = 69875\n",
      "num non-res + single-H = 287301\n",
      "Data HLF: (1564419, 48)\n",
      "num ggF HH = 136671\n",
      "num ttH = 277054\n",
      "num non-res + single-H = 1150694\n",
      "Data HLF test: (390558, 48)\n",
      "num ggF HH = 34083\n",
      "num ttH = 69448\n",
      "num non-res + single-H = 287027\n",
      "Data HLF: (1564441, 48)\n",
      "num ggF HH = 136711\n",
      "num ttH = 277670\n",
      "num non-res + single-H = 1150060\n",
      "Data HLF test: (390536, 48)\n",
      "num ggF HH = 34043\n",
      "num ttH = 68832\n",
      "num non-res + single-H = 287661\n"
     ]
    }
   ],
   "source": [
    "order = ['ggF HH', 'ttH', 'non-res + single-H']\n",
    "\n",
    "(\n",
    "    data_df_dict, data_test_df_dict, \n",
    "    data_hlf_dict, label_dict, \n",
    "    data_hlf_test_dict, label_test_dict, \n",
    "    hlf_vars_columns_dict,\n",
    "    data_aux_dict, data_test_aux_dict\n",
    ") = process_data(\n",
    "    FILEPATHS_DICT, OUTPUT_DIRPATH, order=order, seed=SEED, mod_vals=MOD_VALS, k_fold_test=True,\n",
    "    save=False,\n",
    ")\n",
    "\n",
    "xgb_label_dict = {\n",
    "    f\"fold_{fold_idx}\": copy.deepcopy(xgb_labels(label_dict[f\"fold_{fold_idx}\"])) for fold_idx in range(len(data_test_aux_dict))\n",
    "}\n",
    "xgb_label_test_dict = {\n",
    "    f\"fold_{fold_idx}\": copy.deepcopy(xgb_labels(label_test_dict[f\"fold_{fold_idx}\"])) for fold_idx in range(len(data_test_aux_dict))\n",
    "}\n",
    "\n",
    "weight_train_dict = {\n",
    "    f\"fold_{fold_idx}\": copy.deepcopy(training_weights(data_aux_dict[f'fold_{fold_idx}'].loc[:, \"eventWeight\"].to_numpy(), label_dict[f'fold_{fold_idx}'], order=order)) for fold_idx in range(len(data_test_aux_dict))\n",
    "}\n",
    "weight_test_dict = {\n",
    "    f'fold_{fold_idx}': copy.deepcopy(data_test_aux_dict[f'fold_{fold_idx}'].loc[:, \"eventWeight\"].to_numpy()) for fold_idx in range(len(data_test_aux_dict))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "Num train: 1250553 -> 109096 sig & 222178 ttH bkg & 919279 non-res + single-H bkg\n",
      "Num val: 312639 -> 27434 sig & 55027 ttH bkg & 230178 non-res + single-H bkg\n",
      "Num test: 391785 -> 34224 sig & 69297 ttH bkg & 288264 non-res + single-H bkg\n",
      "============================================================\n",
      "fold 1\n",
      "Num train: 1251336 -> 109298 sig & 221622 ttH bkg & 920416 non-res + single-H bkg\n",
      "Num val: 312835 -> 27168 sig & 55830 ttH bkg & 229837 non-res + single-H bkg\n",
      "Num test: 390806 -> 34288 sig & 69050 ttH bkg & 287468 non-res + single-H bkg\n",
      "============================================================\n",
      "fold 2\n",
      "Num train: 1250948 -> 109478 sig & 221207 ttH bkg & 920263 non-res + single-H bkg\n",
      "Num val: 312737 -> 27160 sig & 55420 ttH bkg & 230157 non-res + single-H bkg\n",
      "Num test: 391292 -> 34116 sig & 69875 ttH bkg & 287301 non-res + single-H bkg\n",
      "============================================================\n",
      "fold 3\n",
      "Num train: 1251535 -> 109266 sig & 221688 ttH bkg & 920581 non-res + single-H bkg\n",
      "Num val: 312884 -> 27405 sig & 55366 ttH bkg & 230113 non-res + single-H bkg\n",
      "Num test: 390558 -> 34083 sig & 69448 ttH bkg & 287027 non-res + single-H bkg\n",
      "============================================================\n",
      "fold 4\n",
      "Num train: 1251552 -> 109362 sig & 221957 ttH bkg & 920233 non-res + single-H bkg\n",
      "Num val: 312889 -> 27349 sig & 55713 ttH bkg & 229827 non-res + single-H bkg\n",
      "Num test: 390536 -> 34043 sig & 68832 ttH bkg & 287661 non-res + single-H bkg\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "bdt_train_dict, bdt_val_dict, bdt_test_dict = {}, {}, {}\n",
    "for fold_idx in range(len(data_df_dict)):\n",
    "    if re.search('no_std', VARS) is not None:\n",
    "        print('no standardization')\n",
    "        train_val_data_dict = {key: value.to_numpy() for key, value in data_df_dict.items()}\n",
    "        test_data_dict = {key: value.to_numpy() for key, value in data_test_df_dict.items()}\n",
    "    else:\n",
    "        train_val_data_dict = data_hlf_dict\n",
    "        test_data_dict = data_hlf_test_dict\n",
    "    (\n",
    "        X_train, X_val, y_train, y_val, weight_train, weight_val\n",
    "    ) = train_test_split(\n",
    "        train_val_data_dict[f\"fold_{fold_idx}\"], xgb_label_dict[f\"fold_{fold_idx}\"], \n",
    "        weight_train_dict[f\"fold_{fold_idx}\"],\n",
    "        test_size=0.2, random_state=21\n",
    "    )\n",
    "\n",
    "    bdt_train_dict[f\"fold_{fold_idx}\"] = xgb.DMatrix(\n",
    "        data=X_train, label=y_train, \n",
    "        weight=weight_train,\n",
    "        missing=-999.0, feature_names=list(hlf_vars_columns_dict[f\"fold_{fold_idx}\"])\n",
    "    )\n",
    "    bdt_val_dict[f\"fold_{fold_idx}\"] = xgb.DMatrix(\n",
    "        data=X_val, label=y_val, \n",
    "        weight=weight_val,\n",
    "        missing=-999.0, feature_names=list(hlf_vars_columns_dict[f\"fold_{fold_idx}\"])\n",
    "    )\n",
    "    \n",
    "    bdt_test_dict[f\"fold_{fold_idx}\"] = xgb.DMatrix(\n",
    "        data=test_data_dict[f\"fold_{fold_idx}\"], label=xgb_label_test_dict[f\"fold_{fold_idx}\"], \n",
    "        weight=np.abs(weight_test_dict[f\"fold_{fold_idx}\"]),\n",
    "        missing=-999.0, feature_names=list(hlf_vars_columns_dict[f\"fold_{fold_idx}\"])\n",
    "    )\n",
    "\n",
    "    print(f\"fold {fold_idx}\")\n",
    "    print(f\"Num train: {len(y_train)} -> {sum(y_train == 0)} sig & {sum(y_train == 1)} ttH bkg & {sum(y_train == 2)} non-res + single-H bkg\")\n",
    "    print(f\"Num val: {len(y_val)} -> {sum(y_val == 0)} sig & {sum(y_val == 1)} ttH bkg & {sum(y_val == 2)} non-res + single-H bkg\")\n",
    "    print(f\"Num test: {len(label_test_dict[f'fold_{fold_idx}'])} -> {sum(label_test_dict[f'fold_{fold_idx}'] == np.array([1, 0, 0]))[0]} sig & {sum(label_test_dict[f'fold_{fold_idx}'] == np.array([0, 1, 0]))[1]} ttH bkg & {sum(label_test_dict[f'fold_{fold_idx}'] == np.array([0, 0, 1]))[2]} non-res + single-H bkg\")\n",
    "    print('='*60)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/57986259/multiclass-classification-with-xgboost-classifier\n",
    "# https://forecastegy.com/posts/xgboost-multiclass-classification-python/\n",
    "# https://indico.cern.ch/event/915265/contributions/3848138/attachments/2048174/3432202/kunlinRan_bbyy_20200531.pdf\n",
    "\n",
    "\n",
    "param = {}\n",
    "\n",
    "# Booster parameters\n",
    "param['eta']              = 0.01 # learning rate\n",
    "param['max_depth']        = 5  # maximum depth of a tree\n",
    "param['subsample']        = 0.6 # fraction of events to train tree on\n",
    "param['colsample_bytree'] = 0.4 # fraction of features to train tree on\n",
    "param['num_class']        = np.shape(label_dict['fold_0'])[1] # num classes for ulti-class training\n",
    "\n",
    "# Learning task parameters\n",
    "param['objective']   = 'multi:softprob'   # objective function\n",
    "param['eval_metric'] = 'merror'           # evaluation metric for cross validation\n",
    "param = list(param.items()) + [('eval_metric', 'mlogloss')]\n",
    "\n",
    "num_trees = 1000  # number of trees to make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENT_TIME = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "OUTPUT_DIRPATH = os.path.join(OUTPUT_DIRPATH, CURRENT_TIME)\n",
    "if not os.path.exists(OUTPUT_DIRPATH):\n",
    "    os.makedirs(OUTPUT_DIRPATH)\n",
    "\n",
    "for fold_idx in range(len(bdt_train_dict)):\n",
    "    print(f\"fold {fold_idx}\")\n",
    "    # Train bdt\n",
    "    evallist = [(bdt_train_dict[f\"fold_{fold_idx}\"], 'train'), (bdt_test_dict[f\"fold_{fold_idx}\"], 'test'), (bdt_val_dict[f\"fold_{fold_idx}\"], 'val')]\n",
    "    booster = xgb.train(\n",
    "        param, bdt_train_dict[f\"fold_{fold_idx}\"], num_boost_round=num_trees, \n",
    "        evals=evallist, early_stopping_rounds=7, verbose_eval=True\n",
    "    )\n",
    "    booster.save_model(os.path.join(OUTPUT_DIRPATH, f'{CURRENT_TIME}_BDT_fold{fold_idx}.model'))\n",
    "    \n",
    "    # Print perf on test dataset\n",
    "    print(booster.eval(bdt_test_dict[f\"fold_{fold_idx}\"]))\n",
    "    print('='*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num ggF HH = (109096,), num not ggF HH = (1141457,)\n",
      "num ttH = (222178,), num not ttH = (1028375,)\n",
      "num non-res + single-H = (919279,), num not non-res + single-H = (331274,)\n",
      "num ggF HH = (27434,), num not ggF HH = (285205,)\n",
      "num ttH = (55027,), num not ttH = (257612,)\n",
      "num non-res + single-H = (230178,), num not non-res + single-H = (82461,)\n",
      "num ggF HH = (34224,), num not ggF HH = (357561,)\n",
      "num ttH = (69297,), num not ttH = (322488,)\n",
      "num non-res + single-H = (288264,), num not non-res + single-H = (103521,)\n",
      "num ggF HH = (109298,), num not ggF HH = (1142038,)\n",
      "num ttH = (221622,), num not ttH = (1029714,)\n",
      "num non-res + single-H = (920416,), num not non-res + single-H = (330920,)\n",
      "num ggF HH = (27168,), num not ggF HH = (285667,)\n",
      "num ttH = (55830,), num not ttH = (257005,)\n",
      "num non-res + single-H = (229837,), num not non-res + single-H = (82998,)\n",
      "num ggF HH = (34288,), num not ggF HH = (356518,)\n",
      "num ttH = (69050,), num not ttH = (321756,)\n",
      "num non-res + single-H = (287468,), num not non-res + single-H = (103338,)\n",
      "num ggF HH = (109478,), num not ggF HH = (1141470,)\n",
      "num ttH = (221207,), num not ttH = (1029741,)\n",
      "num non-res + single-H = (920263,), num not non-res + single-H = (330685,)\n",
      "num ggF HH = (27160,), num not ggF HH = (285577,)\n",
      "num ttH = (55420,), num not ttH = (257317,)\n",
      "num non-res + single-H = (230157,), num not non-res + single-H = (82580,)\n",
      "num ggF HH = (34116,), num not ggF HH = (357176,)\n",
      "num ttH = (69875,), num not ttH = (321417,)\n",
      "num non-res + single-H = (287301,), num not non-res + single-H = (103991,)\n",
      "num ggF HH = (109266,), num not ggF HH = (1142269,)\n",
      "num ttH = (221688,), num not ttH = (1029847,)\n",
      "num non-res + single-H = (920581,), num not non-res + single-H = (330954,)\n",
      "num ggF HH = (27405,), num not ggF HH = (285479,)\n",
      "num ttH = (55366,), num not ttH = (257518,)\n",
      "num non-res + single-H = (230113,), num not non-res + single-H = (82771,)\n",
      "num ggF HH = (34083,), num not ggF HH = (356475,)\n",
      "num ttH = (69448,), num not ttH = (321110,)\n",
      "num non-res + single-H = (287027,), num not non-res + single-H = (103531,)\n",
      "num ggF HH = (109362,), num not ggF HH = (1142190,)\n",
      "num ttH = (221957,), num not ttH = (1029595,)\n",
      "num non-res + single-H = (920233,), num not non-res + single-H = (331319,)\n",
      "num ggF HH = (27349,), num not ggF HH = (285540,)\n",
      "num ttH = (55713,), num not ttH = (257176,)\n",
      "num non-res + single-H = (229827,), num not non-res + single-H = (83062,)\n",
      "num ggF HH = (34043,), num not ggF HH = (356493,)\n",
      "num ttH = (68832,), num not ttH = (321704,)\n",
      "num non-res + single-H = (287661,), num not non-res + single-H = (102875,)\n"
     ]
    }
   ],
   "source": [
    "# OUTPUT_DIRPATH = os.path.join(OUTPUT_DIRPATH, CURRENT_TIME)\n",
    "# if not os.path.exists(OUTPUT_DIRPATH):\n",
    "#     os.makedirs(OUTPUT_DIRPATH)\n",
    "\n",
    "BDT_perf = {\n",
    "    'preds': [], 'fprs': [], 'tprs': [], 'thresholds': [], 'areas': [],\n",
    "    'train_preds': [], 'train_fprs': [], 'train_tprs': [], 'train_thresholds': [], 'train_areas': [],\n",
    "    'val_preds': [], 'val_fprs': [], 'val_tprs': [], 'val_thresholds': [], 'val_areas': [],\n",
    "    'class_order': copy.deepcopy(order),\n",
    "}\n",
    "base_tpr = np.linspace(0, 1, 5000)  # copied from IN evaluate.py file\n",
    "for fold_idx in range(len(bdt_train_dict)):\n",
    "    booster = xgb.Booster(param)\n",
    "    booster.load_model(os.path.join(OUTPUT_DIRPATH, f'{CURRENT_TIME}_BDT_fold{fold_idx}.model'))\n",
    "    \n",
    "    for pred_type, dataset in [\n",
    "        ('train_', bdt_train_dict[f\"fold_{fold_idx}\"]), \n",
    "        ('val_', bdt_val_dict[f\"fold_{fold_idx}\"]),\n",
    "        ('', bdt_test_dict[f\"fold_{fold_idx}\"])\n",
    "    ]:\n",
    "        BDT_perf[pred_type + 'preds'].append(booster.predict(dataset).tolist())\n",
    "        BDT_perf[pred_type + 'fprs'].append([copy.deepcopy(base_tpr.tolist()) for _ in order])\n",
    "        BDT_perf[pred_type + 'tprs'].append([copy.deepcopy(base_tpr.tolist()) for _ in order])\n",
    "        BDT_perf[pred_type + 'thresholds'].append([copy.deepcopy(base_tpr.tolist()) for _ in order])\n",
    "        BDT_perf[pred_type + 'areas'].append([0.0 for _ in order])\n",
    "        for i, sample_name in enumerate(order):\n",
    "            class_truths = np.where(dataset.get_label() == i, 1, 0)\n",
    "            class_preds = np.array(BDT_perf[pred_type + 'preds'][-1])[:, i]\n",
    "            # print(f\"num {sample_name} = {np.shape(class_truths[class_truths == 1])}, num not {sample_name} = {np.shape(class_truths[class_truths == 0])}\")\n",
    "            \n",
    "            fpr_bdt, tpr_bdt, threshold_bdt = roc_curve(class_truths, class_preds)\n",
    "            fpr_bdt = np.interp(base_tpr, tpr_bdt, fpr_bdt)\n",
    "            threshold_bdt = np.interp(base_tpr, tpr_bdt, threshold_bdt)\n",
    "\n",
    "            BDT_perf[pred_type + 'fprs'][fold_idx][i] = fpr_bdt.tolist()\n",
    "            BDT_perf[pred_type + 'tprs'][fold_idx][i] = base_tpr.tolist()\n",
    "            BDT_perf[pred_type + 'thresholds'][fold_idx][i] = threshold_bdt.tolist()\n",
    "            BDT_perf[pred_type + 'areas'][fold_idx][i] = float(auc(fpr_bdt, base_tpr))\n",
    "\n",
    "        BDT_perf[pred_type + 'fprs'][fold_idx] = np.column_stack(BDT_perf[pred_type + 'fprs'][fold_idx]).tolist()\n",
    "        BDT_perf[pred_type + 'tprs'][fold_idx] = np.column_stack(BDT_perf[pred_type + 'tprs'][fold_idx]).tolist()\n",
    "        BDT_perf[pred_type + 'thresholds'][fold_idx] = np.column_stack(BDT_perf[pred_type + 'thresholds'][fold_idx]).tolist()\n",
    "\n",
    "    with h5py.File(os.path.join(OUTPUT_DIRPATH, CURRENT_TIME+f\"_BDT_ROC_fold{fold_idx}.h5\"), \"w\") as out:\n",
    "        out['FPR'] = fpr_bdt\n",
    "        out['TPR'] = tpr_bdt\n",
    "        out['Thresholds'] = threshold_bdt\n",
    "\n",
    "with open(os.path.join(OUTPUT_DIRPATH, CURRENT_TIME+\"_BDT_perf.json\"), 'w') as f:\n",
    "    json.dump(BDT_perf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix, format='png'):\n",
    "    plot_prefix = plot_prefix + ('_' if plot_prefix != '' else '')\n",
    "    plot_postfix = plot_postfix + ('_' if plot_postfix != '' else '')\n",
    "    plot_name = plot_prefix + plot_name + plot_postfix + f'.{format}'\n",
    "\n",
    "    plot_filepath = os.path.join(plot_dirpath, plot_name)\n",
    "    return plot_filepath\n",
    "\n",
    "def plot_rocs(\n",
    "    fprs, tprs, labels, plot_name, plot_dirpath,\n",
    "    plot_prefix='', plot_postfix='', close=True, log=None\n",
    "):\n",
    "    plt.figure(figsize=(9,7))\n",
    "    \n",
    "    for fpr, tpr, label in zip(fprs, tprs, labels):\n",
    "        linestyle = 'solid' if re.search('IN', label) is not None else ('dashed' if re.search('BDT', label) is not None else 'dotted')\n",
    "        plt.plot(fpr, tpr, label=label, linestyle=linestyle)\n",
    "\n",
    "    plt.legend(bbox_to_anchor=(1, 1))\n",
    "    plt.xlabel('Background contamination')\n",
    "    plt.ylabel('Signal efficiency')\n",
    "    if log is not None and re.search('x', log) is not None:\n",
    "        plt.xscale('log')\n",
    "    elif log is not None and re.search('y', log) is not None:\n",
    "        plt.yscale('log')\n",
    "    \n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix, format='pdf'), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    if close:\n",
    "        plt.close()\n",
    "\n",
    "def plot_output_scores(\n",
    "    sigs_and_bkgs, order, plot_name, plot_dirpath,\n",
    "    plot_prefix='', plot_postfix='', bins=50, weights=None, log=False\n",
    "):\n",
    "    plt.figure(figsize=(9,7))\n",
    "\n",
    "    hist_axis = hist.axis.Regular(bins, 0., 1., name='var', growth=False, underflow=False, overflow=False)\n",
    "    hists = {}\n",
    "    for sample_name in order:\n",
    "        hists[sample_name] = hist.Hist(hist_axis, storage='weight').fill(\n",
    "            var=sigs_and_bkgs[sample_name], \n",
    "            weight=weights[sample_name] if weights is not None else np.ones_like(sigs_and_bkgs[sample_name])\n",
    "        )\n",
    "    hep.histplot(\n",
    "        [hists[sample_name] for sample_name in order],\n",
    "        yerr=(True if weights is not None else False),\n",
    "        alpha=0.7, density=(False if weights is not None else True), histtype='step',\n",
    "        label=[sample_name for sample_name in order]\n",
    "    )\n",
    "\n",
    "    plt.legend(bbox_to_anchor=(1, 1))\n",
    "    plt.xlabel('Output score')\n",
    "    if log:\n",
    "        plt.yscale('log')\n",
    "    \n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix, format='pdf'), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.close()\n",
    "\n",
    "def plot_s_over_root_b(\n",
    "    sigs_and_bkgs, order, labels, plot_name, plot_dirpath,\n",
    "    plot_prefix='', plot_postfix='', bins=50, weights={'sig': None, 'bkg': None},\n",
    "    lines=None, lines_labels=None, line_colors=None\n",
    "):\n",
    "    plt.figure(figsize=(9,7))\n",
    "\n",
    "    for idx, (sig, bkg, label) in enumerate(zip(sigs, bkgs, labels)):\n",
    "        linestyle = 'solid' if re.search('IN', label) is not None else ('dashed' if re.search('BDT', label) is not None else 'dotted')\n",
    "\n",
    "        hist_axis = hist.axis.Regular(bins, 0., 1., name='var', growth=False, underflow=False, overflow=False)\n",
    "        sig_hist = hist.Hist(hist_axis, storage='weight').fill(var=sig, weight=weights['sig'] if weights['sig'] is not None else np.ones_like(sig))\n",
    "        bkg_hist = hist.Hist(hist_axis, storage='weight').fill(var=bkg, weight=weights['bkg'] if weights['bkg'] is not None else np.ones_like(bkg))\n",
    "        s_over_root_b_points = sig_hist.values().flatten() / np.sqrt(bkg_hist.values().flatten())\n",
    "        plt.plot(\n",
    "            np.arange(0., 1., 1/bins), s_over_root_b_points, \n",
    "            label=f'{label} - s/√b', alpha=0.8, linestyle=linestyle\n",
    "        )\n",
    "\n",
    "        if lines is not None:\n",
    "            for i in range(len(lines[idx])):\n",
    "                plt.vlines(\n",
    "                    lines[idx][i], 0, np.max(s_over_root_b_points), \n",
    "                    label='s/√b'+(' - '+lines_labels[idx][i] if lines_labels is not None else ''), \n",
    "                    alpha=0.5, linestyle=linestyle, colors=line_colors[idx][i]\n",
    "                )\n",
    "    \n",
    "    plt.legend(bbox_to_anchor=(1, 1))\n",
    "    plt.xlabel('Output score')\n",
    "    plt.ylabel('s/√b')\n",
    "    \n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix, format='pdf'), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_cut_boundaries(sigs, bkgs, weights, bins=50):\n",
    "    hist_list_fold = []\n",
    "    cut_boundaries_fold = []\n",
    "    cut_s_over_root_bs_fold = []\n",
    "    sig_weights_fold = []\n",
    "    bkg_weights_fold = []\n",
    "    for sig, bkg in zip(sigs, bkgs):\n",
    "        hist_axis = hist.axis.Regular(bins, 0., 1., name='var', growth=False, underflow=False, overflow=False)\n",
    "        sig_hist = hist.Hist(hist_axis, storage='weight').fill(var=sig, weight=weights['sig'])\n",
    "        bkg_hist = hist.Hist(hist_axis, storage='weight').fill(var=bkg, weight=weights['bkg'])\n",
    "        hist_list_fold.append({'sig': copy.deepcopy(sig_hist), 'bkg': copy.deepcopy(bkg_hist)})\n",
    "\n",
    "        fold_idx_cuts_bins_inclusive = []\n",
    "        fold_idx_sig_weights = []\n",
    "        fold_idx_bkg_weights = []\n",
    "        fold_idx_prev_s_over_root_b = []\n",
    "        prev_s_over_root_b = 0\n",
    "        for i in range(bins):\n",
    "            s = np.sum(sig_hist.values().flatten()[\n",
    "                (bins-1) - i : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "            ])\n",
    "            sqrt_b = np.sqrt(np.sum(bkg_hist.values().flatten()[\n",
    "                (bins-1) - i : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "            ]))\n",
    "            if prev_s_over_root_b < (s / sqrt_b):\n",
    "                prev_s_over_root_b = s / sqrt_b\n",
    "                continue\n",
    "            else:\n",
    "                fold_idx_sig_weights.append(\n",
    "                    {\n",
    "                        'value': np.sum(sig_hist.values().flatten()[\n",
    "                            (bins) - i : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                        ]),\n",
    "                        'w2': np.sqrt(np.sum(sig_hist.variances().flatten()[\n",
    "                            (bins) - i : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                        ])),\n",
    "                    }\n",
    "                )\n",
    "                fold_idx_bkg_weights.append(\n",
    "                    {\n",
    "                        'value': np.sum(bkg_hist.values().flatten()[\n",
    "                            (bins) - i : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                        ]),\n",
    "                        'w2': np.sqrt(np.sum(bkg_hist.variances().flatten()[\n",
    "                            (bins) - i : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                        ])),\n",
    "                    }\n",
    "                )\n",
    "                fold_idx_cuts_bins_inclusive.append(bins - i)\n",
    "                fold_idx_prev_s_over_root_b.append(prev_s_over_root_b)\n",
    "                prev_s_over_root_b = 0\n",
    "        fold_idx_sig_weights.append(\n",
    "            {\n",
    "                'value': np.sum(sig_hist.values().flatten()[\n",
    "                    0 : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                ]),\n",
    "                'w2': np.sqrt(np.sum(sig_hist.variances().flatten()[\n",
    "                    0 : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                ])),\n",
    "            }\n",
    "        )\n",
    "        fold_idx_bkg_weights.append(\n",
    "            {\n",
    "                'value': np.sum(bkg_hist.values().flatten()[\n",
    "                    0 : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                ]),\n",
    "                'w2': np.sqrt(np.sum(bkg_hist.variances().flatten()[\n",
    "                    0 : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                ])),\n",
    "            }\n",
    "        )\n",
    "        fold_idx_cuts_bins_inclusive.append(0)\n",
    "        fold_idx_prev_s_over_root_b.append(prev_s_over_root_b)\n",
    "        fold_idx_score_cuts = [bin_i / bins for bin_i in fold_idx_cuts_bins_inclusive]\n",
    "        cut_boundaries_fold.append(fold_idx_score_cuts)\n",
    "        cut_s_over_root_bs_fold.append(fold_idx_prev_s_over_root_b)\n",
    "        sig_weights_fold.append(fold_idx_sig_weights)\n",
    "        bkg_weights_fold.append(fold_idx_bkg_weights)\n",
    "    return cut_boundaries_fold, cut_s_over_root_bs_fold, sig_weights_fold, bkg_weights_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 70\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# plot s/√b curves\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fold_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(bdt_train_dict)):\n\u001b[1;32m     69\u001b[0m     weights_plot \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m---> 70\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msig\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mweight_test_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfold_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfold_idx\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel_test_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfold_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfold_idx\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m,\n\u001b[1;32m     71\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbkg\u001b[39m\u001b[38;5;124m'\u001b[39m: weight_test_dict[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfold_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m][(label_test_dict[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfold_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)],\n\u001b[1;32m     72\u001b[0m     }\n\u001b[1;32m     74\u001b[0m     sigs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     75\u001b[0m         np\u001b[38;5;241m.\u001b[39marray(BDT_perf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreds\u001b[39m\u001b[38;5;124m'\u001b[39m][fold_idx])[label_test_dict[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfold_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m     76\u001b[0m         np\u001b[38;5;241m.\u001b[39mexp(np\u001b[38;5;241m.\u001b[39marray(IN_perf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall_preds\u001b[39m\u001b[38;5;124m'\u001b[39m][fold_idx]))[np\u001b[38;5;241m.\u001b[39marray(IN_perf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall_labels\u001b[39m\u001b[38;5;124m'\u001b[39m][fold_idx]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     77\u001b[0m     ]\n\u001b[1;32m     78\u001b[0m     bkgs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     79\u001b[0m         np\u001b[38;5;241m.\u001b[39marray(BDT_perf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreds\u001b[39m\u001b[38;5;124m'\u001b[39m][fold_idx])[label_test_dict[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfold_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m     80\u001b[0m         np\u001b[38;5;241m.\u001b[39mexp(np\u001b[38;5;241m.\u001b[39marray(IN_perf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall_preds\u001b[39m\u001b[38;5;124m'\u001b[39m][fold_idx]))[np\u001b[38;5;241m.\u001b[39marray(IN_perf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall_labels\u001b[39m\u001b[38;5;124m'\u001b[39m][fold_idx]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     81\u001b[0m     ]\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    }
   ],
   "source": [
    "# OUTPUT_DIRPATH = os.path.join(OUTPUT_DIRPATH, CURRENT_TIME)\n",
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "with open(os.path.join(OUTPUT_DIRPATH, CURRENT_TIME+\"_BDT_perf.json\"), 'r') as f:\n",
    "    BDT_perf = json.load(f)\n",
    "base_tpr = np.array(BDT_perf['tprs'][0])[:, 0]\n",
    "\n",
    "# plot ROCs\n",
    "avg_fprs, avg_aucs = [], []\n",
    "for fold_idx in range(len(bdt_train_dict)):\n",
    "    fprs = [np.array(BDT_perf['fprs'][fold_idx])[:, i] for i in range(len(order))]\n",
    "    avg_fprs.append(copy.deepcopy(BDT_perf['fprs'][fold_idx]))\n",
    "\n",
    "    tprs = [base_tpr for i in range(len(order))]\n",
    "\n",
    "    labels = [f\"{sample_name}, AUC = {BDT_perf['areas'][fold_idx][i]:.4f}\" for i, sample_name in enumerate(order)]\n",
    "\n",
    "    avg_aucs.append(copy.deepcopy(BDT_perf['areas'][fold_idx]))\n",
    "\n",
    "    plot_rocs(fprs, tprs, labels, f\"BDT_roc_testData_fold{fold_idx}\", plot_dirpath)\n",
    "plot_rocs(\n",
    "    np.mean(avg_fprs, axis=0).T, [base_tpr for i in range(len(order))], \n",
    "    [f\"{sample_name}, AUC = {np.mean(avg_aucs, axis=0)[i]:.4f}\" for i, sample_name in enumerate(order)], \n",
    "    f\"BDT_roc_testData_Avg\", plot_dirpath\n",
    ")\n",
    "flat_preds = np.concatenate(BDT_perf['preds'], axis=0)\n",
    "flat_truths = np.concatenate([bdt_test_dict[f\"fold_{fold_idx}\"].get_label() for fold_idx in range(len(bdt_train_dict))], axis=0)\n",
    "fprs, aucs = [], []\n",
    "for i, sample_name in enumerate(order):\n",
    "    fpr, tpr, threshold = roc_curve(flat_truths == i, flat_preds[:, i])\n",
    "    fpr = np.interp(base_tpr, tpr, fpr)\n",
    "    fpr[0] = 0.0\n",
    "    fprs.append(copy.deepcopy(fpr))\n",
    "    aucs.append(float(auc(fpr, base_tpr)))\n",
    "plot_rocs(\n",
    "    fprs, [base_tpr for i in range(len(order))], \n",
    "    [f\"{sample_name}, AUC = {aucs[i]:.4f}\" for i, sample_name in enumerate(order)], \n",
    "    f\"BDT_roc_testData_sum\", plot_dirpath\n",
    ")\n",
    "\n",
    "# plot Output scores\n",
    "for fold_idx in range(len(bdt_train_dict)):\n",
    "    weights_plot = {\n",
    "        sample_name: {\n",
    "            sample_name_: weight_test_dict[f\"fold_{fold_idx}\"][xgb_label_test_dict[f\"fold_{fold_idx}\"] == i] for i, sample_name_ in enumerate(order)\n",
    "        } for sample_name in order\n",
    "    }\n",
    "\n",
    "    sigs_and_bkgs = {\n",
    "        sample_name: {\n",
    "            sample_name_: np.array(BDT_perf['preds'][fold_idx])[:, j][xgb_label_test_dict[f\"fold_{fold_idx}\"] == i] for i, sample_name_ in enumerate(order)\n",
    "        } for j, sample_name in enumerate(order)\n",
    "    }\n",
    "\n",
    "    for i, sample_name in enumerate(order):\n",
    "        plot_output_scores(\n",
    "            sigs_and_bkgs[sample_name], order, f\"BDT_outputScoreWeighted_testData_fold{fold_idx}_{sample_name}\", \n",
    "            plot_dirpath, weights=weights_plot[sample_name], log=True\n",
    "        )\n",
    "        plot_output_scores(\n",
    "            sigs_and_bkgs[sample_name], order, f\"BDT_outputScoreDensity_testData_fold{fold_idx}_{sample_name}\", \n",
    "            plot_dirpath\n",
    "        )\n",
    "\n",
    "# plot s/√b curves\n",
    "for fold_idx in range(len(bdt_train_dict)):\n",
    "    weights_plot = {\n",
    "        'sig': weight_test_dict[f\"fold_{fold_idx}\"][(label_test_dict[f\"fold_{fold_idx}\"] == 1)],\n",
    "        'bkg': weight_test_dict[f\"fold_{fold_idx}\"][(label_test_dict[f\"fold_{fold_idx}\"] == 0)],\n",
    "    }\n",
    "    \n",
    "    sigs = [\n",
    "        np.array(BDT_perf['preds'][fold_idx])[label_test_dict[f\"fold_{fold_idx}\"] == 1],\n",
    "        np.exp(np.array(IN_perf['all_preds'][fold_idx]))[np.array(IN_perf['all_labels'][fold_idx]) == 1, 1]\n",
    "    ]\n",
    "    bkgs = [\n",
    "        np.array(BDT_perf['preds'][fold_idx])[label_test_dict[f\"fold_{fold_idx}\"] == 0],\n",
    "        np.exp(np.array(IN_perf['all_preds'][fold_idx]))[np.array(IN_perf['all_labels'][fold_idx]) == 0, 1]\n",
    "    ]\n",
    "    labels = [\"BDT\", \"IN\"]\n",
    "\n",
    "    plot_s_over_root_b(sigs, bkgs, labels, f\"BDT_IN_sOverRootb_testData_fold{fold_idx}\", plot_dirpath, weights=weights_plot)\n",
    "\n",
    "for fold_idx in range(len(bdt_train_dict)):\n",
    "    weights_plot = {\n",
    "        'sig': weight_test_dict[f\"fold_{fold_idx}\"][(label_test_dict[f\"fold_{fold_idx}\"] == 1)],\n",
    "        'bkg': weight_test_dict[f\"fold_{fold_idx}\"][(label_test_dict[f\"fold_{fold_idx}\"] == 0)],\n",
    "    }\n",
    "    \n",
    "    sigs = [\n",
    "        np.array(BDT_perf['preds'][fold_idx])[label_test_dict[f\"fold_{fold_idx}\"] == 1],\n",
    "        np.exp(np.array(IN_perf['all_preds'][fold_idx]))[np.array(IN_perf['all_labels'][fold_idx]) == 1, 1]\n",
    "    ]\n",
    "    bkgs = [\n",
    "        np.array(BDT_perf['preds'][fold_idx])[label_test_dict[f\"fold_{fold_idx}\"] == 0],\n",
    "        np.exp(np.array(IN_perf['all_preds'][fold_idx]))[np.array(IN_perf['all_labels'][fold_idx]) == 0, 1]\n",
    "    ]\n",
    "    labels = [\"BDT\", \"IN\"]\n",
    "\n",
    "    (\n",
    "        cut_boundaries_fold, cut_s_over_root_bs_fold, sig_weights_fold, bkg_weights_fold\n",
    "    ) = optimize_cut_boundaries(sigs, bkgs, weights_plot)\n",
    "\n",
    "    BDT_cut_labels = [\n",
    "        f\"s/√b={cut_s_over_root_bs_fold[0][cut_idx]:.4f}, s={sig_weights_fold[0][cut_idx]['value']:.4f}±{sig_weights_fold[0][cut_idx]['w2']:.4f}, b={bkg_weights_fold[0][cut_idx]['value']:.4f}±{bkg_weights_fold[0][cut_idx]['w2']:.4f}\" for cut_idx in range(len(cut_s_over_root_bs_fold[0]))\n",
    "    ]\n",
    "    IN_cut_labels = [\n",
    "        f\"s/√b={cut_s_over_root_bs_fold[1][cut_idx]:.4f}, s={sig_weights_fold[1][cut_idx]['value']:.4f}±{sig_weights_fold[1][cut_idx]['w2']:.4f}, b={bkg_weights_fold[1][cut_idx]['value']:.4f}±{bkg_weights_fold[1][cut_idx]['w2']:.4f}\" for cut_idx in range(len(cut_s_over_root_bs_fold[1]))\n",
    "    ]\n",
    "    line_labels = [BDT_cut_labels, IN_cut_labels]\n",
    "    lines = [cut_boundaries_fold[0], cut_boundaries_fold[1]]\n",
    "    line_colors=[cmap_petroff10, cmap_petroff10]\n",
    "\n",
    "    plot_s_over_root_b(\n",
    "        sigs, bkgs, labels, f\"BDT_IN_sOverRootb_withCuts_testData_fold{fold_idx}\", plot_dirpath, weights=weights_plot,\n",
    "        lines=lines, lines_labels=line_labels, line_colors=line_colors\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OUTPUT_DIRPATH = os.path.join(OUTPUT_DIRPATH, CURRENT_TIME)\n",
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "with open('/uscms/home/tsievert/nobackup/XHYbbgg/HHtobbyy/model_outputs/v8/extra_vars+/2024-10-09_20-47-24_IN_perf.json', 'r') as f:\n",
    "    IN_perf = json.load(f)\n",
    "\n",
    "# plot ROCs\n",
    "avg_fprs, avg_aucs = [], []\n",
    "for fold_idx in range(len(bdt_train_dict)):\n",
    "    fprs = [\n",
    "        BDT_perf['train_fprs'][fold_idx], \n",
    "        BDT_perf['val_fprs'][fold_idx],\n",
    "        BDT_perf['fprs'][fold_idx]\n",
    "    ]\n",
    "    avg_fprs.append(copy.deepcopy(fprs))\n",
    "    tprs = [base_tpr] * 3\n",
    "    labels = [\n",
    "        f\"BDT train data fold {fold_idx}, AUC = {BDT_perf['train_areas'][fold_idx]:.4f}\", \n",
    "        f\"BDT val data fold {fold_idx}, AUC = {BDT_perf['val_areas'][fold_idx]:.4f}\",\n",
    "        f\"BDT test data fold {fold_idx}, AUC = {BDT_perf['areas'][fold_idx]:.4f}\"\n",
    "    ]\n",
    "    avg_aucs.append(copy.deepcopy([\n",
    "        BDT_perf['train_areas'][fold_idx], \n",
    "        BDT_perf['val_areas'][fold_idx],\n",
    "        BDT_perf['areas'][fold_idx]\n",
    "    ]))\n",
    "\n",
    "    plot_rocs(fprs, tprs, labels, f\"BDT_roc_allData_fold{fold_idx}\", plot_dirpath, close=False, log='x')\n",
    "plot_rocs(\n",
    "    np.mean(avg_fprs, axis=0), [base_tpr] * 3, \n",
    "    [\n",
    "        f\"BDT train avg., AUC = {np.mean(avg_aucs, axis=0)[0]:.4f}\", \n",
    "        f\"BDT val avg., AUC = {np.mean(avg_aucs, axis=0)[1]:.4f}\",\n",
    "        f\"BDT test avg., AUC = {np.mean(avg_aucs, axis=0)[2]:.4f}\"\n",
    "    ], \n",
    "    f\"BDT_roc_allData_Avg\", plot_dirpath, close=False, log='x'\n",
    ")\n",
    "\n",
    "# plot Output scores\n",
    "# for fold_idx in range(len(bdt_train_dict)):\n",
    "#     #     'sig': weight_test_dict[f\"fold_{fold_idx}\"][(label_test_dict[f\"fold_{fold_idx}\"] == 1) & mask_arr[fold_idx]],\n",
    "#     #     'bkg': weight_test_dict[f\"fold_{fold_idx}\"][(label_test_dict[f\"fold_{fold_idx}\"] == 0) & mask_arr[fold_idx]],\n",
    "#     weights_plot = {\n",
    "#         'sig': weight_test_dict[f\"fold_{fold_idx}\"][(label_test_dict[f\"fold_{fold_idx}\"] == 1)],\n",
    "#         'bkg': weight_test_dict[f\"fold_{fold_idx}\"][(label_test_dict[f\"fold_{fold_idx}\"] == 0)],\n",
    "#     }\n",
    "    \n",
    "#     sigs = [\n",
    "#         np.array(BDT_perf['preds'][fold_idx])[label_test_dict[f\"fold_{fold_idx}\"] == 1],\n",
    "#         np.exp(np.array(IN_perf['all_preds'][fold_idx]))[np.array(IN_perf['all_labels'][fold_idx]) == 1, 1]\n",
    "#     ]\n",
    "#     bkgs = [\n",
    "#         np.array(BDT_perf['preds'][fold_idx])[label_test_dict[f\"fold_{fold_idx}\"] == 0],\n",
    "#         np.exp(np.array(IN_perf['all_preds'][fold_idx]))[np.array(IN_perf['all_labels'][fold_idx]) == 0, 1]\n",
    "#     ]\n",
    "#     labels = [\"BDT\", \"IN\"]\n",
    "\n",
    "#     plot_output_scores(sigs, bkgs, labels, f\"BDT_IN_outputScoreWeighted_testData_fold{fold_idx}\", plot_dirpath, weights=weights_plot)\n",
    "#     plot_output_scores(sigs, bkgs, labels, f\"BDT_IN_outputScoreDensity_testData_fold{fold_idx}\", plot_dirpath)\n",
    "\n",
    "# # plot s/√b curves\n",
    "# for fold_idx in range(len(bdt_train_dict)):\n",
    "#     weights_plot = {\n",
    "#         'sig': weight_test_dict[f\"fold_{fold_idx}\"][(label_test_dict[f\"fold_{fold_idx}\"] == 1)],\n",
    "#         'bkg': weight_test_dict[f\"fold_{fold_idx}\"][(label_test_dict[f\"fold_{fold_idx}\"] == 0)],\n",
    "#     }\n",
    "    \n",
    "#     sigs = [\n",
    "#         np.array(BDT_perf['preds'][fold_idx])[label_test_dict[f\"fold_{fold_idx}\"] == 1],\n",
    "#         np.exp(np.array(IN_perf['all_preds'][fold_idx]))[np.array(IN_perf['all_labels'][fold_idx]) == 1, 1]\n",
    "#     ]\n",
    "#     bkgs = [\n",
    "#         np.array(BDT_perf['preds'][fold_idx])[label_test_dict[f\"fold_{fold_idx}\"] == 0],\n",
    "#         np.exp(np.array(IN_perf['all_preds'][fold_idx]))[np.array(IN_perf['all_labels'][fold_idx]) == 0, 1]\n",
    "#     ]\n",
    "#     labels = [\"BDT\", \"IN\"]\n",
    "\n",
    "#     plot_s_over_root_b(sigs, bkgs, labels, f\"BDT_IN_sOverRootb_testData_fold{fold_idx}\", plot_dirpath, weights=weights_plot)\n",
    "\n",
    "# # for fold_idx in range(len(bdt_train_dict)):\n",
    "# #     weights_plot = {\n",
    "# #         'sig': weight_test_dict[f\"fold_{fold_idx}\"][(label_test_dict[f\"fold_{fold_idx}\"] == 1)],\n",
    "# #         'bkg': weight_test_dict[f\"fold_{fold_idx}\"][(label_test_dict[f\"fold_{fold_idx}\"] == 0)],\n",
    "# #     }\n",
    "    \n",
    "# #     sigs = [\n",
    "# #         np.array(BDT_perf['preds'][fold_idx])[label_test_dict[f\"fold_{fold_idx}\"] == 1],\n",
    "# #         np.exp(np.array(IN_perf['all_preds'][fold_idx]))[np.array(IN_perf['all_labels'][fold_idx]) == 1, 1]\n",
    "# #     ]\n",
    "# #     bkgs = [\n",
    "# #         np.array(BDT_perf['preds'][fold_idx])[label_test_dict[f\"fold_{fold_idx}\"] == 0],\n",
    "# #         np.exp(np.array(IN_perf['all_preds'][fold_idx]))[np.array(IN_perf['all_labels'][fold_idx]) == 0, 1]\n",
    "# #     ]\n",
    "# #     labels = [\"BDT\", \"IN\"]\n",
    "\n",
    "# #     (\n",
    "# #         cut_boundaries_fold, cut_s_over_root_bs_fold, sig_weights_fold, bkg_weights_fold\n",
    "# #     ) = optimize_cut_boundaries(sigs, bkgs, weights_plot)\n",
    "\n",
    "# #     BDT_cut_labels = [\n",
    "# #         f\"s/√b={cut_s_over_root_bs_fold[0][cut_idx]:.2f}, s={sig_weights_fold[0][cut_idx]['value']:.2f}±{sig_weights_fold[0][cut_idx]['w2']:.2f}, b={bkg_weights_fold[0][cut_idx]['value']:.2f}±{bkg_weights_fold[0][cut_idx]['w2']:.2f}\" for cut_idx in range(len(cut_s_over_root_bs_fold[0]))\n",
    "# #     ]\n",
    "# #     IN_cut_labels = [\n",
    "# #         f\"s/√b={cut_s_over_root_bs_fold[1][cut_idx]:.2f}, s={sig_weights_fold[1][cut_idx]['value']:.2f}±{sig_weights_fold[1][cut_idx]['w2']:.2f}, b={bkg_weights_fold[1][cut_idx]['value']:.2f}±{bkg_weights_fold[1][cut_idx]['w2']:.2f}\" for cut_idx in range(len(cut_s_over_root_bs_fold[1]))\n",
    "# #     ]\n",
    "# #     line_labels = [BDT_cut_labels, IN_cut_labels]\n",
    "# #     lines = [cut_boundaries_fold[0], cut_boundaries_fold[1]]\n",
    "# #     line_colors=[cmap_petroff10, cmap_petroff10]\n",
    "\n",
    "# #     plot_s_over_root_b(\n",
    "# #         sigs, bkgs, labels, f\"BDT_IN_sOverRootb_withCuts_testData_fold{fold_idx}\", plot_dirpath, weights=weights_plot,\n",
    "# #         lines=lines, lines_labels=line_labels, line_colors=line_colors\n",
    "# #     )    \n",
    "\n",
    "# for pred_type, dataset in [\n",
    "#         ('train_', bdt_train_dict[f\"fold_{fold_idx}\"]), \n",
    "#         ('val_', bdt_val_dict[f\"fold_{fold_idx}\"]),\n",
    "#         ('', bdt_test_dict[f\"fold_{fold_idx}\"])\n",
    "#     ]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.plot_importance(booster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "xgb.to_graphviz(booster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdtfile = rt.TFile.Open(\"TMVA.root\")\n",
    "bdttree = bdtfile.Get(\"TestTree\")\n",
    "bdtscore = tree2array(bdttree,\n",
    "                        branches = ['classID','BDT'])\n",
    "bdtframe = pd.DataFrame.from_records(bdtscore)\n",
    "bdtarray = bdtframe.values\n",
    "\n",
    "bdt_pred = bdtarray[:,1]\n",
    "bdt_target = np.zeros(shape=len(bdt_pred))\n",
    "bdt_target[bdtarray[:,0]==0] = 1 # Signal\n",
    "bdt_target[bdtarray[:,0]==1] = -1 # Background\n",
    "\n",
    "fpr_bdt, tpr_bdt, thresholds_bdt = roc_curve(bdt_target, bdt_pred)\n",
    "area_bdt = auc(fpr_bdt, tpr_bdt)\n",
    "\n",
    "with h5py.File(\"BDT_ROC.h5\",\"w\") as out:\n",
    "    out['FPR'] = fpr_bdt\n",
    "    out['TPR'] = tpr_bdt\n",
    "    out['Thresholds'] = thresholds_bdt\n",
    "    print(\"Saved ROC.\")\n",
    "\n",
    "TPR_thresholds = [0.96, 0.94, 0.935, 0.9, 0.7, 0.5, 0.3]\n",
    "print(\"BDT performance\")\n",
    "print(\"Threshold \\tSignal Efficiency \\tBackground contamination\")\n",
    "for TPR_threshold in TPR_thresholds:\n",
    "    thres_bdt_idx = np.argmax(tpr_bdt>TPR_threshold)\n",
    "    print(\"{0:.4}  \\t   {1:.4}   \\t\\t  {2:.4}\".format(thresholds_bdt[thres_bdt_idx], tpr_bdt[thres_bdt_idx],  fpr_bdt[thres_bdt_idx]))\n",
    "\n",
    "\n",
    "# TPR_threshold = 0.96\n",
    "# thres_bdt_idx = np.argmax(tpr_bdt>TPR_threshold)\n",
    "# print(\"Signal efficiency = {} @ {} ttH background contamination\".format(tpr_bdt[thres_bdt_idx], fpr_bdt[thres_bdt_idx]))\n",
    "# print(\"NN score threshold = {}\".format(thresholds_bdt[thres_bdt_idx]))\n",
    "\n",
    "plt.figure(figsize=(9,7))\n",
    "plt.plot(fpr_bdt,tpr_bdt,label=\"AUC = {}\".format(area_bdt))\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Background contamination')\n",
    "plt.ylabel('Signal efficiency')\n",
    "plt.axhline(tpr_bdt[thres_bdt_idx],ls='--',color='tab:gray')\n",
    "plt.axvline(fpr_bdt[thres_bdt_idx],ls='--',color='tab:gray')\n",
    "\n",
    "plt.figure(figsize=(9,7))\n",
    "plt.hist(bdt_pred[bdt_target==-1], bins=60, label='ttH background',alpha=0.5, normed=True)\n",
    "plt.hist(bdt_pred[bdt_target==1], bins=60, label='HH signal', alpha=0.5, normed=True)\n",
    "#plt.axvline(thresholds_bdt[thres_bdt_idx], ls='--',color='tab:gray')\n",
    "plt.legend(loc='best')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
