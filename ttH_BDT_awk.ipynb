{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmslpcgpu3.fnal.gov      Fri Nov  8 13:10:36 2024  555.42.06\n",
      "[0] Tesla P100-PCIE-12GB | 53°C,  91 % |   308 / 12288 MB | aherrera(306M)\n"
     ]
    }
   ],
   "source": [
    "# Stdlib packages\n",
    "import copy\n",
    "import datetime\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "# Common Py packages\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "# HEP packages\n",
    "import gpustat\n",
    "import h5py\n",
    "import hist\n",
    "import mplhep as hep\n",
    "import xgboost as xgb\n",
    "from cycler import cycler\n",
    "\n",
    "\n",
    "# ML packages\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "\n",
    "# Module packages\n",
    "from data_processing_BDT import process_data\n",
    "\n",
    "gpustat.print_gpustat()\n",
    "\n",
    "plt.style.use(hep.style.CMS)\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "cmap_petroff10 = [\"#3f90da\", \"#ffa90e\", \"#bd1f01\", \"#94a4a2\", \"#832db6\", \"#a96b59\", \"#e76300\", \"#b9ac70\", \"#717581\", \"#92dadd\"]\n",
    "plt.rcParams.update({\"axes.prop_cycle\": cycler(\"color\", cmap_petroff10)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lpc_fileprefix = \"/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1\"\n",
    "\n",
    "FILEPATHS_DICT = {\n",
    "    'ggF HH': [\n",
    "        lpc_fileprefix+f\"/Run3_2022preEE_merged_v3/GluGluToHH/nominal/*\", \n",
    "        lpc_fileprefix+f\"/Run3_2022postEE_merged_v3/GluGluToHH/nominal/*\"\n",
    "    ],\n",
    "    # 'VBF HH': [\n",
    "    #     lpc_fileprefix+f\"/Run3_2022preEE_merged_v3/VBFHHto2B2G_CV_1_C2V_1_C3_1/nominal/*\", \n",
    "    #     lpc_fileprefix+f\"/Run3_2022postEE_merged_v3/VBFHHto2B2G_CV_1_C2V_1_C3_1/nominal/*\"\n",
    "    # ],\n",
    "    'ttH': [\n",
    "        lpc_fileprefix+f\"/Run3_2022preEE_merged_v3/ttHToGG/nominal/*\", \n",
    "        lpc_fileprefix+f\"/Run3_2022postEE_merged_v3/ttHToGG/nominal/*\"\n",
    "    ],\n",
    "    'non-res + single-H': [\n",
    "        # non-Resonant #\n",
    "        # GG + 3Jets\n",
    "        lpc_fileprefix+f\"/Run3_2022preEE_merged_v3/GGJets/nominal/*\", \n",
    "        lpc_fileprefix+f\"/Run3_2022postEE_merged_v3/GGJets/nominal/*\",\n",
    "        # GJet pT 20-40\n",
    "        lpc_fileprefix+f\"/Run3_2022preEE_merged_v3/GJetPt20To40/nominal/*\", \n",
    "        lpc_fileprefix+f\"/Run3_2022postEE_merged_v3/GJetPt20To40/nominal/*\",\n",
    "        # GJet pT 40-inf\n",
    "        lpc_fileprefix+f\"/Run3_2022preEE_merged_v3/GJetPt40/nominal/*\", \n",
    "        lpc_fileprefix+f\"/Run3_2022postEE_merged_v3/GJetPt40/nominal/*\",\n",
    "        # single-H #\n",
    "        # ggF H\n",
    "        lpc_fileprefix+f\"/Run3_2022preEE_merged_v3/GluGluHToGG/nominal/*\", \n",
    "        lpc_fileprefix+f\"/Run3_2022postEE_merged_v3/GluGluHToGG/nominal/*\",\n",
    "        # VBF H\n",
    "        lpc_fileprefix+f\"/Run3_2022preEE_merged_v3/VBFHToGG/nominal/*\", \n",
    "        lpc_fileprefix+f\"/Run3_2022postEE_merged_v3/VBFHToGG/nominal/*\",\n",
    "        # VH\n",
    "        lpc_fileprefix+f\"/Run3_2022preEE_merged_v3/VHToGG/nominal/*\", \n",
    "        lpc_fileprefix+f\"/Run3_2022postEE_merged_v3/VHToGG/nominal/*\",\n",
    "    ],\n",
    "    # 'VH': [\n",
    "    #     lpc_fileprefix+f\"/Run3_2022preEE_merged_v3/VHToGG/nominal/*\", \n",
    "    #     lpc_fileprefix+f\"/Run3_2022postEE_merged_v3/VHToGG/nominal/*\"\n",
    "    # ],\n",
    "}\n",
    "\n",
    "CURRENT_DIRPATH = str(Path().absolute())\n",
    "VERSION = 'v1'\n",
    "MOD_VALS = (5, 5)\n",
    "VARS = 'nonres_and_ttH_vars'\n",
    "# OUTPUT_DIRPATH = os.path.join(CURRENT_DIRPATH, f\"MultiClassBDT_model_outputs/{VERSION}/{VARS}\", CURRENT_TIME)\n",
    "OUTPUT_DIRPATH = os.path.join(CURRENT_DIRPATH, f\"MultiClassBDT_model_outputs/{VERSION}/{VARS}\")\n",
    "\n",
    "if not os.path.exists(OUTPUT_DIRPATH):\n",
    "    os.makedirs(OUTPUT_DIRPATH)\n",
    "\n",
    "SEED = 21\n",
    "OPTIMIZE_SPACE = False\n",
    "NUM_EPOCHS = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_weights(event_weights, labels, order=None):\n",
    "    if order is None:\n",
    "        order = [i for i in range(np.shape(labels)[0])]\n",
    "    sum_dict, max_sum, max_i = {}, 0, 0\n",
    "    for i, sample_name in enumerate(order):\n",
    "        sum_dict[i] = np.sum(event_weights[labels[:, i] == 1])\n",
    "        if np.sum(event_weights[labels[:, i] == 1]) > max_sum:\n",
    "            max_sum, max_i = np.sum(event_weights[labels[:, i] == 1]), i\n",
    "\n",
    "    label_i = np.sum(\n",
    "        np.tile([i for i in range(np.shape(labels)[1])], (np.shape(labels)[0], 1)) * labels,\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    weight_factors = []\n",
    "    for i in range(len(label_i)):\n",
    "        weight_factors.append(\n",
    "            max_sum / sum_dict[label_i[i]] if label_i[i] != max_i else 1\n",
    "        )\n",
    "    weights = event_weights * np.array(weight_factors)\n",
    "\n",
    "    mean_weight = np.mean(weights)\n",
    "    abs_weights = np.abs(weights)\n",
    "    scaled_weights = abs_weights / mean_weight\n",
    "\n",
    "    return scaled_weights\n",
    "\n",
    "def xgb_labels(labels):\n",
    "    label_i = np.sum(\n",
    "        np.tile([i for i in range(np.shape(labels)[1])], (np.shape(labels)[0], 1)) * labels,\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    return label_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data HLF: (1563192, 48)\n",
      "num ggF HH = 136530\n",
      "num ttH = 277205\n",
      "num non-res + single-H = 1149457\n",
      "Data HLF test: (391785, 48)\n",
      "num ggF HH = 34224\n",
      "num ttH = 69297\n",
      "num non-res + single-H = 288264\n",
      "Data HLF: (1564171, 48)\n",
      "num ggF HH = 136466\n",
      "num ttH = 277452\n",
      "num non-res + single-H = 1150253\n",
      "Data HLF test: (390806, 48)\n",
      "num ggF HH = 34288\n",
      "num ttH = 69050\n",
      "num non-res + single-H = 287468\n",
      "Data HLF: (1563685, 48)\n",
      "num ggF HH = 136638\n",
      "num ttH = 276627\n",
      "num non-res + single-H = 1150420\n",
      "Data HLF test: (391292, 48)\n",
      "num ggF HH = 34116\n",
      "num ttH = 69875\n",
      "num non-res + single-H = 287301\n",
      "Data HLF: (1564419, 48)\n",
      "num ggF HH = 136671\n",
      "num ttH = 277054\n",
      "num non-res + single-H = 1150694\n",
      "Data HLF test: (390558, 48)\n",
      "num ggF HH = 34083\n",
      "num ttH = 69448\n",
      "num non-res + single-H = 287027\n",
      "Data HLF: (1564441, 48)\n",
      "num ggF HH = 136711\n",
      "num ttH = 277670\n",
      "num non-res + single-H = 1150060\n",
      "Data HLF test: (390536, 48)\n",
      "num ggF HH = 34043\n",
      "num ttH = 68832\n",
      "num non-res + single-H = 287661\n"
     ]
    }
   ],
   "source": [
    "order = ['ggF HH', 'ttH', 'non-res + single-H']\n",
    "\n",
    "(\n",
    "    data_df_dict, data_test_df_dict, \n",
    "    data_hlf_dict, label_dict, \n",
    "    data_hlf_test_dict, label_test_dict, \n",
    "    high_level_fields_dict, input_hlf_vars_dict, hlf_vars_columns_dict,\n",
    "    data_aux_dict, data_test_aux_dict\n",
    ") = process_data(\n",
    "    FILEPATHS_DICT, OUTPUT_DIRPATH, order=order, seed=SEED, mod_vals=MOD_VALS, k_fold_test=True\n",
    ")\n",
    "\n",
    "xgb_label_dict = {\n",
    "    f\"fold_{fold_idx}\": copy.deepcopy(xgb_labels(label_dict[f\"fold_{fold_idx}\"])) for fold_idx in range(len(data_test_aux_dict))\n",
    "}\n",
    "xgb_label_test_dict = {\n",
    "    f\"fold_{fold_idx}\": copy.deepcopy(xgb_labels(label_test_dict[f\"fold_{fold_idx}\"])) for fold_idx in range(len(data_test_aux_dict))\n",
    "}\n",
    "\n",
    "weight_train_dict = {\n",
    "    f\"fold_{fold_idx}\": copy.deepcopy(training_weights(data_aux_dict[f'fold_{fold_idx}'].loc[:, \"eventWeight\"].to_numpy(), label_dict[f'fold_{fold_idx}'], order=order)) for fold_idx in range(len(data_test_aux_dict))\n",
    "}\n",
    "weight_test_dict = {\n",
    "    f'fold_{fold_idx}': copy.deepcopy(data_test_aux_dict[f'fold_{fold_idx}'].loc[:, \"eventWeight\"].to_numpy()) for fold_idx in range(len(data_test_aux_dict))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "Num train: 1250553 -> 109096 sig & 222178 ttH bkg & 919279 non-res + single-H bkg\n",
      "Num val: 312639 -> 27434 sig & 55027 ttH bkg & 230178 non-res + single-H bkg\n",
      "Num test: 391785 -> 34224 sig & 69297 ttH bkg & 288264 non-res + single-H bkg\n",
      "============================================================\n",
      "fold 1\n",
      "Num train: 1251336 -> 109298 sig & 221622 ttH bkg & 920416 non-res + single-H bkg\n",
      "Num val: 312835 -> 27168 sig & 55830 ttH bkg & 229837 non-res + single-H bkg\n",
      "Num test: 390806 -> 34288 sig & 69050 ttH bkg & 287468 non-res + single-H bkg\n",
      "============================================================\n",
      "fold 2\n",
      "Num train: 1250948 -> 109478 sig & 221207 ttH bkg & 920263 non-res + single-H bkg\n",
      "Num val: 312737 -> 27160 sig & 55420 ttH bkg & 230157 non-res + single-H bkg\n",
      "Num test: 391292 -> 34116 sig & 69875 ttH bkg & 287301 non-res + single-H bkg\n",
      "============================================================\n",
      "fold 3\n",
      "Num train: 1251535 -> 109266 sig & 221688 ttH bkg & 920581 non-res + single-H bkg\n",
      "Num val: 312884 -> 27405 sig & 55366 ttH bkg & 230113 non-res + single-H bkg\n",
      "Num test: 390558 -> 34083 sig & 69448 ttH bkg & 287027 non-res + single-H bkg\n",
      "============================================================\n",
      "fold 4\n",
      "Num train: 1251552 -> 109362 sig & 221957 ttH bkg & 920233 non-res + single-H bkg\n",
      "Num val: 312889 -> 27349 sig & 55713 ttH bkg & 229827 non-res + single-H bkg\n",
      "Num test: 390536 -> 34043 sig & 68832 ttH bkg & 287661 non-res + single-H bkg\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "bdt_train_dict, bdt_val_dict, bdt_test_dict = {}, {}, {}\n",
    "for fold_idx in range(len(data_df_dict)):\n",
    "    if re.search('no_std', VARS) is not None:\n",
    "        print('no standardization')\n",
    "        train_val_data_dict = {key: value.to_numpy() for key, value in data_df_dict.items()}\n",
    "        test_data_dict = {key: value.to_numpy() for key, value in data_test_df_dict.items()}\n",
    "    else:\n",
    "        train_val_data_dict = data_hlf_dict\n",
    "        test_data_dict = data_hlf_test_dict\n",
    "    (\n",
    "        X_train, X_val, y_train, y_val, weight_train, weight_val\n",
    "    ) = train_test_split(\n",
    "        train_val_data_dict[f\"fold_{fold_idx}\"], xgb_label_dict[f\"fold_{fold_idx}\"], weight_train_dict[f\"fold_{fold_idx}\"],\n",
    "        test_size=0.2, random_state=21\n",
    "    )\n",
    "\n",
    "    bdt_train_dict[f\"fold_{fold_idx}\"] = xgb.DMatrix(\n",
    "        data=X_train, label=y_train, \n",
    "        weight=weight_train,\n",
    "        missing=-999.0, feature_names=list(high_level_fields_dict[f\"fold_{fold_idx}\"])\n",
    "    )\n",
    "    bdt_val_dict[f\"fold_{fold_idx}\"] = xgb.DMatrix(\n",
    "        data=X_val, label=y_val, \n",
    "        weight=weight_val,\n",
    "        missing=-999.0, feature_names=list(high_level_fields_dict[f\"fold_{fold_idx}\"])\n",
    "    )\n",
    "    \n",
    "    bdt_test_dict[f\"fold_{fold_idx}\"] = xgb.DMatrix(\n",
    "        data=test_data_dict[f\"fold_{fold_idx}\"], label=xgb_label_test_dict[f\"fold_{fold_idx}\"], \n",
    "        weight=np.abs(weight_test_dict[f\"fold_{fold_idx}\"]),\n",
    "        missing=-999.0, feature_names=list(high_level_fields_dict[f\"fold_{fold_idx}\"])\n",
    "    )\n",
    "\n",
    "    print(f\"fold {fold_idx}\")\n",
    "    print(f\"Num train: {len(y_train)} -> {sum(y_train == 0)} sig & {sum(y_train == 1)} ttH bkg & {sum(y_train == 2)} non-res + single-H bkg\")\n",
    "    print(f\"Num val: {len(y_val)} -> {sum(y_val == 0)} sig & {sum(y_val == 1)} ttH bkg & {sum(y_val == 2)} non-res + single-H bkg\")\n",
    "    print(f\"Num test: {len(label_test_dict[f'fold_{fold_idx}'])} -> {sum(label_test_dict[f'fold_{fold_idx}'] == np.array([1, 0, 0]))[0]} sig & {sum(label_test_dict[f'fold_{fold_idx}'] == np.array([0, 1, 0]))[1]} ttH bkg & {sum(label_test_dict[f'fold_{fold_idx}'] == np.array([0, 0, 1]))[2]} non-res + single-H bkg\")\n",
    "    print('='*60)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0: max = 27.1178, min = 0.0016, mean ± std. dev. = 1.6918 ± 2.5556\n",
      "fold 1: max = 27.1368, min = 0.0016, mean ± std. dev. = 1.6972 ± 2.5651\n",
      "fold 2: max = 27.1991, min = 0.0016, mean ± std. dev. = 1.6869 ± 2.5528\n",
      "fold 3: max = 27.1529, min = 0.0016, mean ± std. dev. = 1.6906 ± 2.5552\n",
      "fold 4: max = 27.0900, min = 0.0016, mean ± std. dev. = 1.6887 ± 2.5516\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(f'fold {i}: max = {np.max(weight_train_dict[f\"fold_{i}\"]):.4f}, min = {np.min(weight_train_dict[f\"fold_{i}\"]):.4f}, mean ± std. dev. = {np.mean(weight_train_dict[f\"fold_{i}\"]):.4f} ± {np.std(weight_train_dict[f\"fold_{i}\"]):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/57986259/multiclass-classification-with-xgboost-classifier\n",
    "# https://forecastegy.com/posts/xgboost-multiclass-classification-python/\n",
    "# https://indico.cern.ch/event/915265/contributions/3848138/attachments/2048174/3432202/kunlinRan_bbyy_20200531.pdf\n",
    "\n",
    "\n",
    "param = {}\n",
    "\n",
    "# Booster parameters\n",
    "param['eta']              = 0.01 # learning rate\n",
    "param['max_depth']        = 5  # maximum depth of a tree\n",
    "param['subsample']        = 0.6 # fraction of events to train tree on\n",
    "param['colsample_bytree'] = 0.4 # fraction of features to train tree on\n",
    "param['num_class']        = np.shape(label_dict['fold_0'])[1] # num classes for ulti-class training\n",
    "\n",
    "# Learning task parameters\n",
    "param['objective']   = 'multi:softprob'   # objective function\n",
    "param['eval_metric'] = 'merror'           # evaluation metric for cross validation\n",
    "param = list(param.items()) + [('eval_metric', 'mlogloss')]\n",
    "\n",
    "num_trees = 1000  # number of trees to make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "[0]\ttrain-merror:0.15501\ttrain-mlogloss:1.08970\ttest-merror:0.17075\ttest-mlogloss:1.08989\tval-merror:0.15614\tval-mlogloss:1.08998\n",
      "[1]\ttrain-merror:0.16322\ttrain-mlogloss:1.08243\ttest-merror:0.21088\ttest-mlogloss:1.08380\tval-merror:0.16439\tval-mlogloss:1.08268\n"
     ]
    }
   ],
   "source": [
    "CURRENT_TIME = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "OUTPUT_DIRPATH = os.path.join(OUTPUT_DIRPATH, CURRENT_TIME)\n",
    "if not os.path.exists(OUTPUT_DIRPATH):\n",
    "    os.makedirs(OUTPUT_DIRPATH)\n",
    "\n",
    "for fold_idx in range(len(bdt_train_dict)):\n",
    "    print(f\"fold {fold_idx}\")\n",
    "    # Train bdt\n",
    "    evallist = [(bdt_train_dict[f\"fold_{fold_idx}\"], 'train'), (bdt_test_dict[f\"fold_{fold_idx}\"], 'test'), (bdt_val_dict[f\"fold_{fold_idx}\"], 'val')]\n",
    "    booster = xgb.train(\n",
    "        param, bdt_train_dict[f\"fold_{fold_idx}\"], num_boost_round=num_trees, \n",
    "        evals=evallist, early_stopping_rounds=7, verbose_eval=True\n",
    "    )\n",
    "    booster.save_model(os.path.join(OUTPUT_DIRPATH, f'{CURRENT_TIME}_BDT_fold{fold_idx}.model'))\n",
    "    \n",
    "    # Print perf on test dataset\n",
    "    print(booster.eval(bdt_test_dict[f\"fold_{fold_idx}\"]))\n",
    "    print('='*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1250553,)\n",
      "True\n",
      "(1250553, 3)\n",
      "False\n",
      "False\n",
      "False\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y should be a 1d array, got an array of shape (1250553, 3) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(np\u001b[38;5;241m.\u001b[39marray(BDT_perf[pred_type \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreds\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])[np\u001b[38;5;241m.\u001b[39marray(BDT_perf[pred_type \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreds\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])[:,\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m BDT_perf[pred_type \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreds\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m]])\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(np\u001b[38;5;241m.\u001b[39marray(BDT_perf[pred_type \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreds\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])[np\u001b[38;5;241m.\u001b[39marray(BDT_perf[pred_type \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreds\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])[:,\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m!=\u001b[39m BDT_perf[pred_type \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreds\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m2\u001b[39m]])\n\u001b[0;32m---> 30\u001b[0m fpr_bdt, tpr_bdt, threshold_bdt \u001b[38;5;241m=\u001b[39m \u001b[43mroc_curve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_label\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBDT_perf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpred_type\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpreds\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m fpr_bdt \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39minterp(base_tpr, tpr_bdt, fpr_bdt)\n\u001b[1;32m     32\u001b[0m threshold_bdt \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39minterp(base_tpr, tpr_bdt, threshold_bdt)\n",
      "File \u001b[0;32m~/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:1145\u001b[0m, in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m   1044\u001b[0m     {\n\u001b[1;32m   1045\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1054\u001b[0m     y_true, y_score, \u001b[38;5;241m*\u001b[39m, pos_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, drop_intermediate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m ):\n\u001b[1;32m   1056\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute Receiver operating characteristic (ROC).\u001b[39;00m\n\u001b[1;32m   1057\u001b[0m \n\u001b[1;32m   1058\u001b[0m \u001b[38;5;124;03m    Note: this implementation is restricted to the binary classification task.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1143\u001b[0m \u001b[38;5;124;03m    array([ inf, 0.8 , 0.4 , 0.35, 0.1 ])\u001b[39;00m\n\u001b[1;32m   1144\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1145\u001b[0m     fps, tps, thresholds \u001b[38;5;241m=\u001b[39m \u001b[43m_binary_clf_curve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1146\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1149\u001b[0m     \u001b[38;5;66;03m# Attempt to drop thresholds corresponding to points in between and\u001b[39;00m\n\u001b[1;32m   1150\u001b[0m     \u001b[38;5;66;03m# collinear with other points. These are always suboptimal and do not\u001b[39;00m\n\u001b[1;32m   1151\u001b[0m     \u001b[38;5;66;03m# appear on a plotted ROC curve (and thus do not affect the AUC).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1156\u001b[0m     \u001b[38;5;66;03m# but does not drop more complicated cases like fps = [1, 3, 7],\u001b[39;00m\n\u001b[1;32m   1157\u001b[0m     \u001b[38;5;66;03m# tps = [1, 2, 4]; there is no harm in keeping too many thresholds.\u001b[39;00m\n\u001b[1;32m   1158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m drop_intermediate \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fps) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[0;32m~/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:821\u001b[0m, in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    819\u001b[0m check_consistent_length(y_true, y_score, sample_weight)\n\u001b[1;32m    820\u001b[0m y_true \u001b[38;5;241m=\u001b[39m column_or_1d(y_true)\n\u001b[0;32m--> 821\u001b[0m y_score \u001b[38;5;241m=\u001b[39m \u001b[43mcolumn_or_1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    822\u001b[0m assert_all_finite(y_true)\n\u001b[1;32m    823\u001b[0m assert_all_finite(y_score)\n",
      "File \u001b[0;32m~/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/sklearn/utils/validation.py:1406\u001b[0m, in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, dtype, warn)\u001b[0m\n\u001b[1;32m   1395\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1396\u001b[0m             (\n\u001b[1;32m   1397\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA column-vector y was passed when a 1d array was\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1402\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m   1403\u001b[0m         )\n\u001b[1;32m   1404\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _asarray_with_order(xp\u001b[38;5;241m.\u001b[39mreshape(y, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,)), order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[0;32m-> 1406\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1407\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my should be a 1d array, got an array of shape \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(shape)\n\u001b[1;32m   1408\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: y should be a 1d array, got an array of shape (1250553, 3) instead."
     ]
    }
   ],
   "source": [
    "# OUTPUT_DIRPATH = os.path.join(OUTPUT_DIRPATH, CURRENT_TIME)\n",
    "# if not os.path.exists(OUTPUT_DIRPATH):\n",
    "#     os.makedirs(OUTPUT_DIRPATH)\n",
    "\n",
    "BDT_perf = {\n",
    "    'preds': [], 'fprs': [], 'tprs': [], 'thresholds': [], 'areas': [],\n",
    "    'train_preds': [], 'train_fprs': [], 'train_tprs': [], 'train_thresholds': [], 'train_areas': [],\n",
    "    'val_preds': [], 'val_fprs': [], 'val_tprs': [], 'val_thresholds': [], 'val_areas': [],\n",
    "}\n",
    "base_tpr = np.linspace(0, 1, 5000)  # copied from IN evaluate.py file\n",
    "for fold_idx in range(len(bdt_train_dict)):\n",
    "    booster = xgb.Booster(param)\n",
    "    booster.load_model(os.path.join(OUTPUT_DIRPATH, f'{CURRENT_TIME}_BDT_fold{fold_idx}.model'))\n",
    "    \n",
    "    for pred_type, dataset in [\n",
    "        ('train_', bdt_train_dict[f\"fold_{fold_idx}\"]), \n",
    "        ('val_', bdt_val_dict[f\"fold_{fold_idx}\"]),\n",
    "        ('', bdt_test_dict[f\"fold_{fold_idx}\"])\n",
    "    ]:\n",
    "        BDT_perf[pred_type + 'preds'].append(booster.predict(dataset).tolist())\n",
    "        print(np.shape(dataset.get_label()))\n",
    "        print(np.all(dataset.get_label() == dataset.get_label()[0]))\n",
    "        print(np.shape(BDT_perf[pred_type + 'preds'][-1]))\n",
    "        print(np.all(BDT_perf[pred_type + 'preds'][-1][:][0] == BDT_perf[pred_type + 'preds'][-1][0][0]))\n",
    "        print(np.all(BDT_perf[pred_type + 'preds'][-1][:][1] == BDT_perf[pred_type + 'preds'][-1][0][1]))\n",
    "        print(np.all(BDT_perf[pred_type + 'preds'][-1][:][2] == BDT_perf[pred_type + 'preds'][-1][0][2]))\n",
    "        print(np.array(BDT_perf[pred_type + 'preds'][-1])[np.array(BDT_perf[pred_type + 'preds'][-1])[:,0] != BDT_perf[pred_type + 'preds'][-1][0][0]])\n",
    "        print(np.array(BDT_perf[pred_type + 'preds'][-1])[np.array(BDT_perf[pred_type + 'preds'][-1])[:,1] != BDT_perf[pred_type + 'preds'][-1][0][1]])\n",
    "        print(np.array(BDT_perf[pred_type + 'preds'][-1])[np.array(BDT_perf[pred_type + 'preds'][-1])[:,2] != BDT_perf[pred_type + 'preds'][-1][0][2]])\n",
    "        fpr_bdt, tpr_bdt, threshold_bdt = roc_curve(dataset.get_label(), BDT_perf[pred_type + 'preds'][-1])\n",
    "        fpr_bdt = np.interp(base_tpr, tpr_bdt, fpr_bdt)\n",
    "        threshold_bdt = np.interp(base_tpr, tpr_bdt, threshold_bdt)\n",
    "        BDT_perf[pred_type + 'fprs'].append(fpr_bdt.tolist())\n",
    "        BDT_perf[pred_type + 'tprs'].append(tpr_bdt.tolist())\n",
    "        BDT_perf[pred_type + 'thresholds'].append(threshold_bdt.tolist())\n",
    "\n",
    "        BDT_perf[pred_type + 'areas'].append(float(auc(fpr_bdt, base_tpr)))\n",
    "\n",
    "    with h5py.File(os.path.join(OUTPUT_DIRPATH, CURRENT_TIME+f\"_BDT_ROC_fold{fold_idx}.h5\"), \"w\") as out:\n",
    "        out['FPR'] = fpr_bdt\n",
    "        out['TPR'] = tpr_bdt\n",
    "        out['Thresholds'] = threshold_bdt\n",
    "\n",
    "with open(os.path.join(OUTPUT_DIRPATH, CURRENT_TIME+\"_BDT_perf.json\"), 'w') as f:\n",
    "    json.dump(BDT_perf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix, format='png'):\n",
    "    plot_prefix = plot_prefix + ('_' if plot_prefix != '' else '')\n",
    "    plot_postfix = plot_postfix + ('_' if plot_postfix != '' else '')\n",
    "    plot_name = plot_prefix + plot_name + plot_postfix + f'.{format}'\n",
    "\n",
    "    plot_filepath = os.path.join(plot_dirpath, plot_name)\n",
    "    return plot_filepath\n",
    "\n",
    "def plot_rocs(\n",
    "    fprs, tprs, labels, plot_name, plot_dirpath,\n",
    "    plot_prefix='', plot_postfix='', close=True, log=None\n",
    "):\n",
    "    plt.figure(figsize=(9,7))\n",
    "    \n",
    "    for fpr, tpr, label in zip(fprs, tprs, labels):\n",
    "        linestyle = 'solid' if re.search('IN', label) is not None else ('dashed' if re.search('BDT', label) is not None else 'dotted')\n",
    "        plt.plot(fpr, tpr, label=label, linestyle=linestyle)\n",
    "\n",
    "    plt.legend(bbox_to_anchor=(1, 1))\n",
    "    plt.xlabel('Background contamination')\n",
    "    plt.ylabel('Signal efficiency')\n",
    "    if log is not None and re.search('x', log) is not None:\n",
    "        plt.xscale('log')\n",
    "    elif log is not None and re.search('y', log) is not None:\n",
    "        plt.yscale('log')\n",
    "    \n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix, format='pdf'), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    if close:\n",
    "        plt.close()\n",
    "\n",
    "def plot_output_scores(\n",
    "    sigs, bkgs, labels, plot_name, plot_dirpath,\n",
    "    plot_prefix='', plot_postfix='', bins=50, weights={'sig': None, 'bkg': None}\n",
    "):\n",
    "    plt.figure(figsize=(9,7))\n",
    "\n",
    "    for sig, bkg, label in zip(sigs, bkgs, labels):\n",
    "        hist_axis = hist.axis.Regular(bins, 0., 1., name='var', growth=False, underflow=False, overflow=False)\n",
    "        sig_hist = hist.Hist(hist_axis, storage='weight').fill(var=sig, weight=weights['sig'] if weights['sig'] is not None else np.ones_like(sig))\n",
    "        bkg_hist = hist.Hist(hist_axis, storage='weight').fill(var=bkg, weight=weights['bkg'] if weights['bkg'] is not None else np.ones_like(bkg))\n",
    "        hep.histplot(\n",
    "            [sig_hist, bkg_hist],\n",
    "            yerr=(True if weights['sig'] is not None else False),\n",
    "            alpha=0.7, density=(False if weights['sig'] is not None else True), histtype='step',\n",
    "            label=[f'{label} - HH signal', f'{label} - ttH background']\n",
    "        )\n",
    "\n",
    "    plt.legend(bbox_to_anchor=(1, 1))\n",
    "    plt.xlabel('Output score')\n",
    "    \n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix, format='pdf'), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.close()\n",
    "\n",
    "def plot_s_over_root_b(\n",
    "    sigs, bkgs, labels, plot_name, plot_dirpath,\n",
    "    plot_prefix='', plot_postfix='', bins=50, weights={'sig': None, 'bkg': None},\n",
    "    lines=None, lines_labels=None, line_colors=None\n",
    "):\n",
    "    plt.figure(figsize=(9,7))\n",
    "\n",
    "    for idx, (sig, bkg, label) in enumerate(zip(sigs, bkgs, labels)):\n",
    "        linestyle = 'solid' if re.search('IN', label) is not None else ('dashed' if re.search('BDT', label) is not None else 'dotted')\n",
    "\n",
    "        hist_axis = hist.axis.Regular(bins, 0., 1., name='var', growth=False, underflow=False, overflow=False)\n",
    "        sig_hist = hist.Hist(hist_axis, storage='weight').fill(var=sig, weight=weights['sig'] if weights['sig'] is not None else np.ones_like(sig))\n",
    "        bkg_hist = hist.Hist(hist_axis, storage='weight').fill(var=bkg, weight=weights['bkg'] if weights['bkg'] is not None else np.ones_like(bkg))\n",
    "        s_over_root_b_points = sig_hist.values().flatten() / np.sqrt(bkg_hist.values().flatten())\n",
    "        plt.plot(\n",
    "            np.arange(0., 1., 1/bins), s_over_root_b_points, \n",
    "            label=f'{label} - s/√b', alpha=0.8, linestyle=linestyle\n",
    "        )\n",
    "\n",
    "        if lines is not None:\n",
    "            for i in range(len(lines[idx])):\n",
    "                plt.vlines(\n",
    "                    lines[idx][i], 0, np.max(s_over_root_b_points), \n",
    "                    label='s/√b'+(' - '+lines_labels[idx][i] if lines_labels is not None else ''), \n",
    "                    alpha=0.5, linestyle=linestyle, colors=line_colors[idx][i]\n",
    "                )\n",
    "    \n",
    "    plt.legend(bbox_to_anchor=(1, 1))\n",
    "    plt.xlabel('Output score')\n",
    "    plt.ylabel('s/√b')\n",
    "    \n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix, format='pdf'), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_cut_boundaries(sigs, bkgs, weights, bins=50):\n",
    "    hist_list_fold = []\n",
    "    cut_boundaries_fold = []\n",
    "    cut_s_over_root_bs_fold = []\n",
    "    sig_weights_fold = []\n",
    "    bkg_weights_fold = []\n",
    "    for sig, bkg in zip(sigs, bkgs):\n",
    "        hist_axis = hist.axis.Regular(bins, 0., 1., name='var', growth=False, underflow=False, overflow=False)\n",
    "        sig_hist = hist.Hist(hist_axis, storage='weight').fill(var=sig, weight=weights['sig'])\n",
    "        bkg_hist = hist.Hist(hist_axis, storage='weight').fill(var=bkg, weight=weights['bkg'])\n",
    "        hist_list_fold.append({'sig': copy.deepcopy(sig_hist), 'bkg': copy.deepcopy(bkg_hist)})\n",
    "\n",
    "        fold_idx_cuts_bins_inclusive = []\n",
    "        fold_idx_sig_weights = []\n",
    "        fold_idx_bkg_weights = []\n",
    "        fold_idx_prev_s_over_root_b = []\n",
    "        prev_s_over_root_b = 0\n",
    "        for i in range(bins):\n",
    "            s = np.sum(sig_hist.values().flatten()[\n",
    "                (bins-1) - i : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "            ])\n",
    "            sqrt_b = np.sqrt(np.sum(bkg_hist.values().flatten()[\n",
    "                (bins-1) - i : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "            ]))\n",
    "            if prev_s_over_root_b < (s / sqrt_b):\n",
    "                prev_s_over_root_b = s / sqrt_b\n",
    "                continue\n",
    "            else:\n",
    "                fold_idx_sig_weights.append(\n",
    "                    {\n",
    "                        'value': np.sum(sig_hist.values().flatten()[\n",
    "                            (bins) - i : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                        ]),\n",
    "                        'w2': np.sqrt(np.sum(sig_hist.variances().flatten()[\n",
    "                            (bins) - i : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                        ])),\n",
    "                    }\n",
    "                )\n",
    "                fold_idx_bkg_weights.append(\n",
    "                    {\n",
    "                        'value': np.sum(bkg_hist.values().flatten()[\n",
    "                            (bins) - i : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                        ]),\n",
    "                        'w2': np.sqrt(np.sum(bkg_hist.variances().flatten()[\n",
    "                            (bins) - i : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                        ])),\n",
    "                    }\n",
    "                )\n",
    "                fold_idx_cuts_bins_inclusive.append(bins - i)\n",
    "                fold_idx_prev_s_over_root_b.append(prev_s_over_root_b)\n",
    "                prev_s_over_root_b = 0\n",
    "        fold_idx_sig_weights.append(\n",
    "            {\n",
    "                'value': np.sum(sig_hist.values().flatten()[\n",
    "                    0 : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                ]),\n",
    "                'w2': np.sqrt(np.sum(sig_hist.variances().flatten()[\n",
    "                    0 : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                ])),\n",
    "            }\n",
    "        )\n",
    "        fold_idx_bkg_weights.append(\n",
    "            {\n",
    "                'value': np.sum(bkg_hist.values().flatten()[\n",
    "                    0 : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                ]),\n",
    "                'w2': np.sqrt(np.sum(bkg_hist.variances().flatten()[\n",
    "                    0 : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                ])),\n",
    "            }\n",
    "        )\n",
    "        fold_idx_cuts_bins_inclusive.append(0)\n",
    "        fold_idx_prev_s_over_root_b.append(prev_s_over_root_b)\n",
    "        fold_idx_score_cuts = [bin_i / bins for bin_i in fold_idx_cuts_bins_inclusive]\n",
    "        cut_boundaries_fold.append(fold_idx_score_cuts)\n",
    "        cut_s_over_root_bs_fold.append(fold_idx_prev_s_over_root_b)\n",
    "        sig_weights_fold.append(fold_idx_sig_weights)\n",
    "        bkg_weights_fold.append(fold_idx_bkg_weights)\n",
    "    return cut_boundaries_fold, cut_s_over_root_bs_fold, sig_weights_fold, bkg_weights_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OUTPUT_DIRPATH = os.path.join(OUTPUT_DIRPATH, CURRENT_TIME)\n",
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "with open('/uscms/home/tsievert/nobackup/XHYbbgg/HHtobbyy/model_outputs/v8/extra_vars+/2024-10-09_20-47-24_IN_perf.json', 'r') as f:\n",
    "    IN_perf = json.load(f)\n",
    "\n",
    "# plot ROCs\n",
    "avg_fprs, avg_aucs = [], []\n",
    "for fold_idx in range(len(bdt_train_dict)):\n",
    "    fprs = [BDT_perf['fprs'][fold_idx], IN_perf['fprs'][fold_idx]]\n",
    "    avg_fprs.append(copy.deepcopy(fprs))\n",
    "    tprs = [base_tpr] * 2\n",
    "    labels = [f\"BDT, AUC = {BDT_perf['areas'][fold_idx]:.4f}\", f\"IN, AUC = {auc(IN_perf['fprs'][fold_idx], base_tpr):.4f}\"]\n",
    "    avg_aucs.append(copy.deepcopy([BDT_perf['areas'][fold_idx], auc(IN_perf['fprs'][fold_idx], base_tpr)]))\n",
    "\n",
    "    plot_rocs(fprs, tprs, labels, f\"BDT_IN_roc_testData_fold{fold_idx}\", plot_dirpath)\n",
    "plot_rocs(\n",
    "    np.mean(avg_fprs, axis=0), [base_tpr] * 2, \n",
    "    [f\"BDT, AUC = {np.mean(avg_aucs, axis=0)[0]:.4f}\", f\"IN, AUC = {np.mean(avg_aucs, axis=0)[1]:.4f}\"], \n",
    "    f\"BDT_IN_roc_testData_Avg\", plot_dirpath\n",
    ")\n",
    "\n",
    "# plot Output scores\n",
    "for fold_idx in range(len(bdt_train_dict)):\n",
    "    #     'sig': weight_test_dict[f\"fold_{fold_idx}\"][(label_test_dict[f\"fold_{fold_idx}\"] == 1) & mask_arr[fold_idx]],\n",
    "    #     'bkg': weight_test_dict[f\"fold_{fold_idx}\"][(label_test_dict[f\"fold_{fold_idx}\"] == 0) & mask_arr[fold_idx]],\n",
    "    weights_plot = {\n",
    "        'sig': weight_test_dict[f\"fold_{fold_idx}\"][(label_test_dict[f\"fold_{fold_idx}\"] == 1)],\n",
    "        'bkg': weight_test_dict[f\"fold_{fold_idx}\"][(label_test_dict[f\"fold_{fold_idx}\"] == 0)],\n",
    "    }\n",
    "    \n",
    "    sigs = [\n",
    "        np.array(BDT_perf['preds'][fold_idx])[label_test_dict[f\"fold_{fold_idx}\"] == 1],\n",
    "        np.exp(np.array(IN_perf['all_preds'][fold_idx]))[np.array(IN_perf['all_labels'][fold_idx]) == 1, 1]\n",
    "    ]\n",
    "    bkgs = [\n",
    "        np.array(BDT_perf['preds'][fold_idx])[label_test_dict[f\"fold_{fold_idx}\"] == 0],\n",
    "        np.exp(np.array(IN_perf['all_preds'][fold_idx]))[np.array(IN_perf['all_labels'][fold_idx]) == 0, 1]\n",
    "    ]\n",
    "    labels = [\"BDT\", \"IN\"]\n",
    "\n",
    "    plot_output_scores(sigs, bkgs, labels, f\"BDT_IN_outputScoreWeighted_testData_fold{fold_idx}\", plot_dirpath, weights=weights_plot)\n",
    "    plot_output_scores(sigs, bkgs, labels, f\"BDT_IN_outputScoreDensity_testData_fold{fold_idx}\", plot_dirpath)\n",
    "\n",
    "# plot s/√b curves\n",
    "for fold_idx in range(len(bdt_train_dict)):\n",
    "    weights_plot = {\n",
    "        'sig': weight_test_dict[f\"fold_{fold_idx}\"][(label_test_dict[f\"fold_{fold_idx}\"] == 1)],\n",
    "        'bkg': weight_test_dict[f\"fold_{fold_idx}\"][(label_test_dict[f\"fold_{fold_idx}\"] == 0)],\n",
    "    }\n",
    "    \n",
    "    sigs = [\n",
    "        np.array(BDT_perf['preds'][fold_idx])[label_test_dict[f\"fold_{fold_idx}\"] == 1],\n",
    "        np.exp(np.array(IN_perf['all_preds'][fold_idx]))[np.array(IN_perf['all_labels'][fold_idx]) == 1, 1]\n",
    "    ]\n",
    "    bkgs = [\n",
    "        np.array(BDT_perf['preds'][fold_idx])[label_test_dict[f\"fold_{fold_idx}\"] == 0],\n",
    "        np.exp(np.array(IN_perf['all_preds'][fold_idx]))[np.array(IN_perf['all_labels'][fold_idx]) == 0, 1]\n",
    "    ]\n",
    "    labels = [\"BDT\", \"IN\"]\n",
    "\n",
    "    plot_s_over_root_b(sigs, bkgs, labels, f\"BDT_IN_sOverRootb_testData_fold{fold_idx}\", plot_dirpath, weights=weights_plot)\n",
    "\n",
    "for fold_idx in range(len(bdt_train_dict)):\n",
    "    weights_plot = {\n",
    "        'sig': weight_test_dict[f\"fold_{fold_idx}\"][(label_test_dict[f\"fold_{fold_idx}\"] == 1)],\n",
    "        'bkg': weight_test_dict[f\"fold_{fold_idx}\"][(label_test_dict[f\"fold_{fold_idx}\"] == 0)],\n",
    "    }\n",
    "    \n",
    "    sigs = [\n",
    "        np.array(BDT_perf['preds'][fold_idx])[label_test_dict[f\"fold_{fold_idx}\"] == 1],\n",
    "        np.exp(np.array(IN_perf['all_preds'][fold_idx]))[np.array(IN_perf['all_labels'][fold_idx]) == 1, 1]\n",
    "    ]\n",
    "    bkgs = [\n",
    "        np.array(BDT_perf['preds'][fold_idx])[label_test_dict[f\"fold_{fold_idx}\"] == 0],\n",
    "        np.exp(np.array(IN_perf['all_preds'][fold_idx]))[np.array(IN_perf['all_labels'][fold_idx]) == 0, 1]\n",
    "    ]\n",
    "    labels = [\"BDT\", \"IN\"]\n",
    "\n",
    "    (\n",
    "        cut_boundaries_fold, cut_s_over_root_bs_fold, sig_weights_fold, bkg_weights_fold\n",
    "    ) = optimize_cut_boundaries(sigs, bkgs, weights_plot)\n",
    "\n",
    "    BDT_cut_labels = [\n",
    "        f\"s/√b={cut_s_over_root_bs_fold[0][cut_idx]:.4f}, s={sig_weights_fold[0][cut_idx]['value']:.4f}±{sig_weights_fold[0][cut_idx]['w2']:.4f}, b={bkg_weights_fold[0][cut_idx]['value']:.4f}±{bkg_weights_fold[0][cut_idx]['w2']:.4f}\" for cut_idx in range(len(cut_s_over_root_bs_fold[0]))\n",
    "    ]\n",
    "    IN_cut_labels = [\n",
    "        f\"s/√b={cut_s_over_root_bs_fold[1][cut_idx]:.4f}, s={sig_weights_fold[1][cut_idx]['value']:.4f}±{sig_weights_fold[1][cut_idx]['w2']:.4f}, b={bkg_weights_fold[1][cut_idx]['value']:.4f}±{bkg_weights_fold[1][cut_idx]['w2']:.4f}\" for cut_idx in range(len(cut_s_over_root_bs_fold[1]))\n",
    "    ]\n",
    "    line_labels = [BDT_cut_labels, IN_cut_labels]\n",
    "    lines = [cut_boundaries_fold[0], cut_boundaries_fold[1]]\n",
    "    line_colors=[cmap_petroff10, cmap_petroff10]\n",
    "\n",
    "    plot_s_over_root_b(\n",
    "        sigs, bkgs, labels, f\"BDT_IN_sOverRootb_withCuts_testData_fold{fold_idx}\", plot_dirpath, weights=weights_plot,\n",
    "        lines=lines, lines_labels=line_labels, line_colors=line_colors\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OUTPUT_DIRPATH = os.path.join(OUTPUT_DIRPATH, CURRENT_TIME)\n",
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "with open('/uscms/home/tsievert/nobackup/XHYbbgg/HHtobbyy/model_outputs/v8/extra_vars+/2024-10-09_20-47-24_IN_perf.json', 'r') as f:\n",
    "    IN_perf = json.load(f)\n",
    "\n",
    "# plot ROCs\n",
    "avg_fprs, avg_aucs = [], []\n",
    "for fold_idx in range(len(bdt_train_dict)):\n",
    "    fprs = [\n",
    "        BDT_perf['train_fprs'][fold_idx], \n",
    "        BDT_perf['val_fprs'][fold_idx],\n",
    "        BDT_perf['fprs'][fold_idx]\n",
    "    ]\n",
    "    avg_fprs.append(copy.deepcopy(fprs))\n",
    "    tprs = [base_tpr] * 3\n",
    "    labels = [\n",
    "        f\"BDT train data fold {fold_idx}, AUC = {BDT_perf['train_areas'][fold_idx]:.4f}\", \n",
    "        f\"BDT val data fold {fold_idx}, AUC = {BDT_perf['val_areas'][fold_idx]:.4f}\",\n",
    "        f\"BDT test data fold {fold_idx}, AUC = {BDT_perf['areas'][fold_idx]:.4f}\"\n",
    "    ]\n",
    "    avg_aucs.append(copy.deepcopy([\n",
    "        BDT_perf['train_areas'][fold_idx], \n",
    "        BDT_perf['val_areas'][fold_idx],\n",
    "        BDT_perf['areas'][fold_idx]\n",
    "    ]))\n",
    "\n",
    "    plot_rocs(fprs, tprs, labels, f\"BDT_roc_allData_fold{fold_idx}\", plot_dirpath, close=False, log='x')\n",
    "plot_rocs(\n",
    "    np.mean(avg_fprs, axis=0), [base_tpr] * 3, \n",
    "    [\n",
    "        f\"BDT train avg., AUC = {np.mean(avg_aucs, axis=0)[0]:.4f}\", \n",
    "        f\"BDT val avg., AUC = {np.mean(avg_aucs, axis=0)[1]:.4f}\",\n",
    "        f\"BDT test avg., AUC = {np.mean(avg_aucs, axis=0)[2]:.4f}\"\n",
    "    ], \n",
    "    f\"BDT_roc_allData_Avg\", plot_dirpath, close=False, log='x'\n",
    ")\n",
    "\n",
    "# plot Output scores\n",
    "# for fold_idx in range(len(bdt_train_dict)):\n",
    "#     #     'sig': weight_test_dict[f\"fold_{fold_idx}\"][(label_test_dict[f\"fold_{fold_idx}\"] == 1) & mask_arr[fold_idx]],\n",
    "#     #     'bkg': weight_test_dict[f\"fold_{fold_idx}\"][(label_test_dict[f\"fold_{fold_idx}\"] == 0) & mask_arr[fold_idx]],\n",
    "#     weights_plot = {\n",
    "#         'sig': weight_test_dict[f\"fold_{fold_idx}\"][(label_test_dict[f\"fold_{fold_idx}\"] == 1)],\n",
    "#         'bkg': weight_test_dict[f\"fold_{fold_idx}\"][(label_test_dict[f\"fold_{fold_idx}\"] == 0)],\n",
    "#     }\n",
    "    \n",
    "#     sigs = [\n",
    "#         np.array(BDT_perf['preds'][fold_idx])[label_test_dict[f\"fold_{fold_idx}\"] == 1],\n",
    "#         np.exp(np.array(IN_perf['all_preds'][fold_idx]))[np.array(IN_perf['all_labels'][fold_idx]) == 1, 1]\n",
    "#     ]\n",
    "#     bkgs = [\n",
    "#         np.array(BDT_perf['preds'][fold_idx])[label_test_dict[f\"fold_{fold_idx}\"] == 0],\n",
    "#         np.exp(np.array(IN_perf['all_preds'][fold_idx]))[np.array(IN_perf['all_labels'][fold_idx]) == 0, 1]\n",
    "#     ]\n",
    "#     labels = [\"BDT\", \"IN\"]\n",
    "\n",
    "#     plot_output_scores(sigs, bkgs, labels, f\"BDT_IN_outputScoreWeighted_testData_fold{fold_idx}\", plot_dirpath, weights=weights_plot)\n",
    "#     plot_output_scores(sigs, bkgs, labels, f\"BDT_IN_outputScoreDensity_testData_fold{fold_idx}\", plot_dirpath)\n",
    "\n",
    "# # plot s/√b curves\n",
    "# for fold_idx in range(len(bdt_train_dict)):\n",
    "#     weights_plot = {\n",
    "#         'sig': weight_test_dict[f\"fold_{fold_idx}\"][(label_test_dict[f\"fold_{fold_idx}\"] == 1)],\n",
    "#         'bkg': weight_test_dict[f\"fold_{fold_idx}\"][(label_test_dict[f\"fold_{fold_idx}\"] == 0)],\n",
    "#     }\n",
    "    \n",
    "#     sigs = [\n",
    "#         np.array(BDT_perf['preds'][fold_idx])[label_test_dict[f\"fold_{fold_idx}\"] == 1],\n",
    "#         np.exp(np.array(IN_perf['all_preds'][fold_idx]))[np.array(IN_perf['all_labels'][fold_idx]) == 1, 1]\n",
    "#     ]\n",
    "#     bkgs = [\n",
    "#         np.array(BDT_perf['preds'][fold_idx])[label_test_dict[f\"fold_{fold_idx}\"] == 0],\n",
    "#         np.exp(np.array(IN_perf['all_preds'][fold_idx]))[np.array(IN_perf['all_labels'][fold_idx]) == 0, 1]\n",
    "#     ]\n",
    "#     labels = [\"BDT\", \"IN\"]\n",
    "\n",
    "#     plot_s_over_root_b(sigs, bkgs, labels, f\"BDT_IN_sOverRootb_testData_fold{fold_idx}\", plot_dirpath, weights=weights_plot)\n",
    "\n",
    "# # for fold_idx in range(len(bdt_train_dict)):\n",
    "# #     weights_plot = {\n",
    "# #         'sig': weight_test_dict[f\"fold_{fold_idx}\"][(label_test_dict[f\"fold_{fold_idx}\"] == 1)],\n",
    "# #         'bkg': weight_test_dict[f\"fold_{fold_idx}\"][(label_test_dict[f\"fold_{fold_idx}\"] == 0)],\n",
    "# #     }\n",
    "    \n",
    "# #     sigs = [\n",
    "# #         np.array(BDT_perf['preds'][fold_idx])[label_test_dict[f\"fold_{fold_idx}\"] == 1],\n",
    "# #         np.exp(np.array(IN_perf['all_preds'][fold_idx]))[np.array(IN_perf['all_labels'][fold_idx]) == 1, 1]\n",
    "# #     ]\n",
    "# #     bkgs = [\n",
    "# #         np.array(BDT_perf['preds'][fold_idx])[label_test_dict[f\"fold_{fold_idx}\"] == 0],\n",
    "# #         np.exp(np.array(IN_perf['all_preds'][fold_idx]))[np.array(IN_perf['all_labels'][fold_idx]) == 0, 1]\n",
    "# #     ]\n",
    "# #     labels = [\"BDT\", \"IN\"]\n",
    "\n",
    "# #     (\n",
    "# #         cut_boundaries_fold, cut_s_over_root_bs_fold, sig_weights_fold, bkg_weights_fold\n",
    "# #     ) = optimize_cut_boundaries(sigs, bkgs, weights_plot)\n",
    "\n",
    "# #     BDT_cut_labels = [\n",
    "# #         f\"s/√b={cut_s_over_root_bs_fold[0][cut_idx]:.2f}, s={sig_weights_fold[0][cut_idx]['value']:.2f}±{sig_weights_fold[0][cut_idx]['w2']:.2f}, b={bkg_weights_fold[0][cut_idx]['value']:.2f}±{bkg_weights_fold[0][cut_idx]['w2']:.2f}\" for cut_idx in range(len(cut_s_over_root_bs_fold[0]))\n",
    "# #     ]\n",
    "# #     IN_cut_labels = [\n",
    "# #         f\"s/√b={cut_s_over_root_bs_fold[1][cut_idx]:.2f}, s={sig_weights_fold[1][cut_idx]['value']:.2f}±{sig_weights_fold[1][cut_idx]['w2']:.2f}, b={bkg_weights_fold[1][cut_idx]['value']:.2f}±{bkg_weights_fold[1][cut_idx]['w2']:.2f}\" for cut_idx in range(len(cut_s_over_root_bs_fold[1]))\n",
    "# #     ]\n",
    "# #     line_labels = [BDT_cut_labels, IN_cut_labels]\n",
    "# #     lines = [cut_boundaries_fold[0], cut_boundaries_fold[1]]\n",
    "# #     line_colors=[cmap_petroff10, cmap_petroff10]\n",
    "\n",
    "# #     plot_s_over_root_b(\n",
    "# #         sigs, bkgs, labels, f\"BDT_IN_sOverRootb_withCuts_testData_fold{fold_idx}\", plot_dirpath, weights=weights_plot,\n",
    "# #         lines=lines, lines_labels=line_labels, line_colors=line_colors\n",
    "# #     )    \n",
    "\n",
    "# for pred_type, dataset in [\n",
    "#         ('train_', bdt_train_dict[f\"fold_{fold_idx}\"]), \n",
    "#         ('val_', bdt_val_dict[f\"fold_{fold_idx}\"]),\n",
    "#         ('', bdt_test_dict[f\"fold_{fold_idx}\"])\n",
    "#     ]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.plot_importance(booster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "xgb.to_graphviz(booster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdtfile = rt.TFile.Open(\"TMVA.root\")\n",
    "bdttree = bdtfile.Get(\"TestTree\")\n",
    "bdtscore = tree2array(bdttree,\n",
    "                        branches = ['classID','BDT'])\n",
    "bdtframe = pd.DataFrame.from_records(bdtscore)\n",
    "bdtarray = bdtframe.values\n",
    "\n",
    "bdt_pred = bdtarray[:,1]\n",
    "bdt_target = np.zeros(shape=len(bdt_pred))\n",
    "bdt_target[bdtarray[:,0]==0] = 1 # Signal\n",
    "bdt_target[bdtarray[:,0]==1] = -1 # Background\n",
    "\n",
    "fpr_bdt, tpr_bdt, thresholds_bdt = roc_curve(bdt_target, bdt_pred)\n",
    "area_bdt = auc(fpr_bdt, tpr_bdt)\n",
    "\n",
    "with h5py.File(\"BDT_ROC.h5\",\"w\") as out:\n",
    "    out['FPR'] = fpr_bdt\n",
    "    out['TPR'] = tpr_bdt\n",
    "    out['Thresholds'] = thresholds_bdt\n",
    "    print(\"Saved ROC.\")\n",
    "\n",
    "TPR_thresholds = [0.96, 0.94, 0.935, 0.9, 0.7, 0.5, 0.3]\n",
    "print(\"BDT performance\")\n",
    "print(\"Threshold \\tSignal Efficiency \\tBackground contamination\")\n",
    "for TPR_threshold in TPR_thresholds:\n",
    "    thres_bdt_idx = np.argmax(tpr_bdt>TPR_threshold)\n",
    "    print(\"{0:.4}  \\t   {1:.4}   \\t\\t  {2:.4}\".format(thresholds_bdt[thres_bdt_idx], tpr_bdt[thres_bdt_idx],  fpr_bdt[thres_bdt_idx]))\n",
    "\n",
    "\n",
    "# TPR_threshold = 0.96\n",
    "# thres_bdt_idx = np.argmax(tpr_bdt>TPR_threshold)\n",
    "# print(\"Signal efficiency = {} @ {} ttH background contamination\".format(tpr_bdt[thres_bdt_idx], fpr_bdt[thres_bdt_idx]))\n",
    "# print(\"NN score threshold = {}\".format(thresholds_bdt[thres_bdt_idx]))\n",
    "\n",
    "plt.figure(figsize=(9,7))\n",
    "plt.plot(fpr_bdt,tpr_bdt,label=\"AUC = {}\".format(area_bdt))\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Background contamination')\n",
    "plt.ylabel('Signal efficiency')\n",
    "plt.axhline(tpr_bdt[thres_bdt_idx],ls='--',color='tab:gray')\n",
    "plt.axvline(fpr_bdt[thres_bdt_idx],ls='--',color='tab:gray')\n",
    "\n",
    "plt.figure(figsize=(9,7))\n",
    "plt.hist(bdt_pred[bdt_target==-1], bins=60, label='ttH background',alpha=0.5, normed=True)\n",
    "plt.hist(bdt_pred[bdt_target==1], bins=60, label='HH signal', alpha=0.5, normed=True)\n",
    "#plt.axvline(thresholds_bdt[thres_bdt_idx], ls='--',color='tab:gray')\n",
    "plt.legend(loc='best')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
