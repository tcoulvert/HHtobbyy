{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmslpcgpu3.fnal.gov      Fri Nov 22 16:22:20 2024  555.42.06\n",
      "[0] Tesla P100-PCIE-12GB | 42Â°C,   0 % |     0 / 12288 MB |\n"
     ]
    }
   ],
   "source": [
    "# Stdlib packages\n",
    "import copy\n",
    "import datetime\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "# Common Py packages\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from prettytable import PrettyTable\n",
    "from scipy.special import logit as inverse_sigmoid\n",
    "\n",
    "# HEP packages\n",
    "import gpustat\n",
    "import h5py\n",
    "import hist\n",
    "import mplhep as hep\n",
    "import xgboost as xgb\n",
    "from cycler import cycler\n",
    "\n",
    "\n",
    "# ML packages\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "from scipy.integrate import trapezoid\n",
    "\n",
    "# Module packages\n",
    "from data_processing_BDT import process_data\n",
    "\n",
    "gpustat.print_gpustat()\n",
    "\n",
    "plt.style.use(hep.style.CMS)\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "cmap_petroff10 = [\"#3f90da\", \"#ffa90e\", \"#bd1f01\", \"#94a4a2\", \"#832db6\", \"#a96b59\", \"#e76300\", \"#b9ac70\", \"#717581\", \"#92dadd\"]\n",
    "plt.rcParams.update({\"axes.prop_cycle\": cycler(\"color\", cmap_petroff10)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lpc_fileprefix = \"/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1\"\n",
    "\n",
    "FILEPATHS_DICT = {\n",
    "    'ggF HH': [\n",
    "        lpc_fileprefix+f\"/Run3_2022preEE_merged_v3/GluGluToHH/nominal/*\", \n",
    "        lpc_fileprefix+f\"/Run3_2022postEE_merged_v3/GluGluToHH/nominal/*\"\n",
    "    ],\n",
    "    # 'VBF HH': [\n",
    "    #     lpc_fileprefix+f\"/Run3_2022preEE_merged_v3/VBFHHto2B2G_CV_1_C2V_1_C3_1/nominal/*\", \n",
    "    #     lpc_fileprefix+f\"/Run3_2022postEE_merged_v3/VBFHHto2B2G_CV_1_C2V_1_C3_1/nominal/*\"\n",
    "    # ],\n",
    "    'ttH': [\n",
    "        lpc_fileprefix+f\"/Run3_2022preEE_merged_v3/ttHToGG/nominal/*\", \n",
    "        lpc_fileprefix+f\"/Run3_2022postEE_merged_v3/ttHToGG/nominal/*\"\n",
    "    ],\n",
    "    # 'non-res + single-H': [\n",
    "    #     # non-Resonant #\n",
    "    #     # GG + 3Jets\n",
    "    #     lpc_fileprefix+f\"/Run3_2022preEE_merged_v3/GGJets/nominal/*\", \n",
    "    #     lpc_fileprefix+f\"/Run3_2022postEE_merged_v3/GGJets/nominal/*\",\n",
    "    #     # GJet pT 20-40\n",
    "    #     lpc_fileprefix+f\"/Run3_2022preEE_merged_v3/GJetPt20To40/nominal/*\", \n",
    "    #     lpc_fileprefix+f\"/Run3_2022postEE_merged_v3/GJetPt20To40/nominal/*\",\n",
    "    #     # GJet pT 40-inf\n",
    "    #     lpc_fileprefix+f\"/Run3_2022preEE_merged_v3/GJetPt40/nominal/*\", \n",
    "    #     lpc_fileprefix+f\"/Run3_2022postEE_merged_v3/GJetPt40/nominal/*\",\n",
    "    #     # single-H #\n",
    "    #     # ggF H\n",
    "    #     lpc_fileprefix+f\"/Run3_2022preEE_merged_v3/GluGluHToGG/nominal/*\", \n",
    "    #     lpc_fileprefix+f\"/Run3_2022postEE_merged_v3/GluGluHToGG/nominal/*\",\n",
    "    #     # VBF H\n",
    "    #     lpc_fileprefix+f\"/Run3_2022preEE_merged_v3/VBFHToGG/nominal/*\", \n",
    "    #     lpc_fileprefix+f\"/Run3_2022postEE_merged_v3/VBFHToGG/nominal/*\",\n",
    "    #     # VH\n",
    "    #     lpc_fileprefix+f\"/Run3_2022preEE_merged_v3/VHToGG/nominal/*\", \n",
    "    #     lpc_fileprefix+f\"/Run3_2022postEE_merged_v3/VHToGG/nominal/*\",\n",
    "    # ],\n",
    "    'single-H': [\n",
    "        # ggF H\n",
    "        lpc_fileprefix+f\"/Run3_2022preEE_merged_v3/GluGluHToGG/nominal/*\", \n",
    "        lpc_fileprefix+f\"/Run3_2022postEE_merged_v3/GluGluHToGG/nominal/*\",\n",
    "        # VBF H\n",
    "        lpc_fileprefix+f\"/Run3_2022preEE_merged_v3/VBFHToGG/nominal/*\", \n",
    "        lpc_fileprefix+f\"/Run3_2022postEE_merged_v3/VBFHToGG/nominal/*\",\n",
    "        # VH\n",
    "        lpc_fileprefix+f\"/Run3_2022preEE_merged_v3/VHToGG/nominal/*\", \n",
    "        lpc_fileprefix+f\"/Run3_2022postEE_merged_v3/VHToGG/nominal/*\",\n",
    "    ],\n",
    "    'non-res': [\n",
    "        # GG + 3Jets\n",
    "        lpc_fileprefix+f\"/Run3_2022preEE_merged_v3/GGJets/nominal/*\", \n",
    "        lpc_fileprefix+f\"/Run3_2022postEE_merged_v3/GGJets/nominal/*\",\n",
    "        # GJet pT 20-40\n",
    "        lpc_fileprefix+f\"/Run3_2022preEE_merged_v3/GJetPt20To40/nominal/*\", \n",
    "        lpc_fileprefix+f\"/Run3_2022postEE_merged_v3/GJetPt20To40/nominal/*\",\n",
    "        # GJet pT 40-inf\n",
    "        lpc_fileprefix+f\"/Run3_2022preEE_merged_v3/GJetPt40/nominal/*\", \n",
    "        lpc_fileprefix+f\"/Run3_2022postEE_merged_v3/GJetPt40/nominal/*\",\n",
    "    ],\n",
    "    # 'VH': [\n",
    "    #     lpc_fileprefix+f\"/Run3_2022preEE_merged_v3/VHToGG/nominal/*\", \n",
    "    #     lpc_fileprefix+f\"/Run3_2022postEE_merged_v3/VHToGG/nominal/*\"\n",
    "    # ],\n",
    "}\n",
    "\n",
    "CURRENT_DIRPATH = str(Path().absolute())\n",
    "VERSION = 'v1'\n",
    "MOD_VALS = (5, 5)\n",
    "VARS = 'nonres_and_ttH_vars'\n",
    "# CURRENT_TIME = '2024-11-08_13-13-20'\n",
    "# CURRENT_TIME = '2024-11-16_13-10-23'\n",
    "if 'CURRENT_TIME' in globals():\n",
    "    OUTPUT_DIRPATH = os.path.join(CURRENT_DIRPATH, f\"MultiClassBDT_model_outputs/{VERSION}/{VARS}\", CURRENT_TIME)\n",
    "else:\n",
    "    OUTPUT_DIRPATH = os.path.join(CURRENT_DIRPATH, f\"MultiClassBDT_model_outputs/{VERSION}/{VARS}\")\n",
    "\n",
    "if not os.path.exists(OUTPUT_DIRPATH):\n",
    "    os.makedirs(OUTPUT_DIRPATH)\n",
    "\n",
    "SEED = 21\n",
    "OPTIMIZE_SPACE = False\n",
    "NUM_EPOCHS = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_weights(event_weights, labels, order=None, weighttype='rescaled_and_shifted', sig_rescale_factor=None):\n",
    "    if weighttype == 'abs':\n",
    "        return np.abs(event_weights)\n",
    "    \n",
    "    if order is not None:\n",
    "        sig_idx = -1\n",
    "        for i, sample_name in enumerate(order):\n",
    "            if re.search('ggF HH', sample_name) is not None:\n",
    "                sig_idx = i\n",
    "                break\n",
    "    else:\n",
    "        sig_idx = 0\n",
    "    \n",
    "    if sig_rescale_factor is None:\n",
    "        sig_sum = np.sum(event_weights[labels[:, sig_idx] == 1])\n",
    "        bkg_sum = np.sum(event_weights[labels[:, sig_idx] == 0])\n",
    "        \n",
    "        sig_rescale_factor = bkg_sum / sig_sum\n",
    "\n",
    "    scaled_weights = np.where(\n",
    "        labels[:, sig_idx] == 0, \n",
    "        event_weights,  # if bkg, do nothing\n",
    "        event_weights * sig_rescale_factor  # if sig, rescale to equal sum of all bkgs\n",
    "    )\n",
    "\n",
    "    abs_weights = np.abs(scaled_weights)\n",
    "\n",
    "    if weighttype == 'rescaled':\n",
    "        return abs_weights\n",
    "    elif weighttype == 'rescaled_and_shifted':\n",
    "        mean_weights = np.mean(scaled_weights)\n",
    "        rescaled_weights = abs_weights / mean_weights\n",
    "        return rescaled_weights\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"The only options for weighttype are 'abs', 'rescaled', and 'rescaled_and_shifted'. You provided {weighttype}\"\n",
    "        )\n",
    "\n",
    "# def training_weights(event_weights, labels, order=None):\n",
    "#     if order is None:\n",
    "#         order = [i for v in range(np.shape(labels)[0])]\n",
    "#     sum_dict, max_sum, max_i = {}, 0, 0\n",
    "#     for i, sample_name in enumerate(order):\n",
    "#         sum_dict[i] = np.sum(event_weights[labels[:, i] == 1])\n",
    "#         if np.sum(event_weights[labels[:, i] == 1]) > max_sum:\n",
    "#             max_sum, max_i = np.sum(event_weights[labels[:, i] == 1]), i\n",
    "\n",
    "#     label_i = np.sum(\n",
    "#         np.tile([i for i in range(np.shape(labels)[1])], (np.shape(labels)[0], 1)) * labels,\n",
    "#         axis=1\n",
    "#     )\n",
    "\n",
    "#     weight_factors = []\n",
    "#     for i in range(len(label_i)):\n",
    "#         weight_factors.append(\n",
    "#             max_sum / sum_dict[label_i[i]] if label_i[i] != max_i else 1\n",
    "#         )\n",
    "#     weights = event_weights * np.array(weight_factors)\n",
    "\n",
    "#     mean_weight = np.mean(weights)\n",
    "#     abs_weights = np.abs(weights)\n",
    "#     scaled_weights = abs_weights / mean_weight\n",
    "\n",
    "#     return scaled_weights\n",
    "\n",
    "\n",
    "def xgb_labels(labels):\n",
    "    label_i = np.sum(\n",
    "        np.tile([i for i in range(np.shape(labels)[1])], (np.shape(labels)[0], 1)) * labels,\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    return label_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/uscms/home/tsievert/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot broadcast RegularArray of size 346502 with RegularArray of size 587391\n\n(https://github.com/scikit-hep/awkward-1.0/blob/1.10.3/src/awkward/_util.py#L920)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 10\u001b[0m\n\u001b[1;32m      1\u001b[0m order \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mggF HH\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mttH\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msingle-H\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnon-res\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      3\u001b[0m (\n\u001b[1;32m      4\u001b[0m     sig_rescale_factor,\n\u001b[1;32m      5\u001b[0m     data_df_dict, data_test_df_dict, \n\u001b[1;32m      6\u001b[0m     data_hlf_dict, label_dict, \n\u001b[1;32m      7\u001b[0m     data_hlf_test_dict, label_test_dict, \n\u001b[1;32m      8\u001b[0m     hlf_vars_columns_dict,\n\u001b[1;32m      9\u001b[0m     data_aux_dict, data_test_aux_dict\n\u001b[0;32m---> 10\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mFILEPATHS_DICT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mOUTPUT_DIRPATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSEED\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmod_vals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMOD_VALS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk_fold_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCURRENT_TIME\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Make xgb-like labels (NOT one-hot encoded, but integer encoded for each class)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m xgb_label_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfold_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m: copy\u001b[38;5;241m.\u001b[39mdeepcopy(xgb_labels(label_dict[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfold_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m])) \u001b[38;5;28;01mfor\u001b[39;00m fold_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(data_test_aux_dict))\n\u001b[1;32m     18\u001b[0m }\n",
      "File \u001b[0;32m/uscms_data/d3/tsievert/XHYbbgg/HHtobbyy/data_processing_BDT.py:29\u001b[0m, in \u001b[0;36mprocess_data\u001b[0;34m(filepaths_dict, output_dirpath, order, seed, mod_vals, k_fold_test, save)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Rescale factor for sig and bkg samples\u001b[39;00m\n\u001b[1;32m     28\u001b[0m sum_of_sig \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(samples[order[\u001b[38;5;241m0\u001b[39m]][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meventWeight\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 29\u001b[0m sum_of_bkg \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m[\u001b[49m\u001b[43morder\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meventWeight\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m sig_rescale_factor \u001b[38;5;241m=\u001b[39m sum_of_bkg \u001b[38;5;241m/\u001b[39m sum_of_sig\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Convert parquet files to pandas DFs #\u001b[39;00m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36msum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/numpy/core/fromnumeric.py:2298\u001b[0m, in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2295\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[1;32m   2296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n\u001b[0;32m-> 2298\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2299\u001b[0m \u001b[43m                      \u001b[49m\u001b[43minitial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/numpy/core/fromnumeric.py:86\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     84\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n\u001b[0;32m---> 86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mufunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpasskwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/numpy/lib/mixins.py:21\u001b[0m, in \u001b[0;36m_binary_method.<locals>.func\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _disables_array_ufunc(other):\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mufunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/awkward/highlevel.py:1411\u001b[0m, in \u001b[0;36mArray.__array_ufunc__\u001b[0;34m(self, ufunc, method, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1354\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1355\u001b[0m \u001b[38;5;124;03mIntercepts attempts to pass this Array to a NumPy\u001b[39;00m\n\u001b[1;32m   1356\u001b[0m \u001b[38;5;124;03m[universal functions](https://docs.scipy.org/doc/numpy/reference/ufuncs.html)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1408\u001b[0m \u001b[38;5;124;03mSee also #__array_function__.\u001b[39;00m\n\u001b[1;32m   1409\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1410\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_tracers\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1411\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mak\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray_ufunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mufunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1412\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ak\u001b[38;5;241m.\u001b[39m_connect\u001b[38;5;241m.\u001b[39m_jax\u001b[38;5;241m.\u001b[39mjax_utils\u001b[38;5;241m.\u001b[39marray_ufunc(\n\u001b[1;32m   1414\u001b[0m         \u001b[38;5;28mself\u001b[39m, ufunc, method, inputs, kwargs\n\u001b[1;32m   1415\u001b[0m     )\n",
      "File \u001b[0;32m~/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/awkward/_connect/_numpy.py:250\u001b[0m, in \u001b[0;36marray_ufunc\u001b[0;34m(ufunc, method, inputs, kwargs)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    241\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno overloads for custom types: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    242\u001b[0m                 ufunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[38;5;241m+\u001b[39m ak\u001b[38;5;241m.\u001b[39m_util\u001b[38;5;241m.\u001b[39mexception_suffix(\u001b[38;5;18m__file__\u001b[39m)\n\u001b[1;32m    246\u001b[0m         )\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 250\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mak\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_and_apply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgetfunction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbehavior\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_records\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpass_depth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ak\u001b[38;5;241m.\u001b[39m_util\u001b[38;5;241m.\u001b[39mwrap(out[\u001b[38;5;241m0\u001b[39m], behavior)\n",
      "File \u001b[0;32m~/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/awkward/_util.py:1172\u001b[0m, in \u001b[0;36mbroadcast_and_apply\u001b[0;34m(inputs, getfunction, behavior, allow_records, pass_depth, pass_user, user, left_broadcast, right_broadcast, numpy_to_regular, regular_to_jagged)\u001b[0m\n\u001b[1;32m   1170\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1171\u001b[0m     isscalar \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 1172\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbroadcast_pack\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43misscalar\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1173\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mtuple\u001b[39m)\n\u001b[1;32m   1174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(broadcast_unpack(x, isscalar) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m out)\n",
      "File \u001b[0;32m~/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/awkward/_util.py:915\u001b[0m, in \u001b[0;36mbroadcast_and_apply.<locals>.apply\u001b[0;34m(inputs, depth, user)\u001b[0m\n\u001b[1;32m    913\u001b[0m         nextinputs\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39mcontent[: \u001b[38;5;28mlen\u001b[39m(x) \u001b[38;5;241m*\u001b[39m x\u001b[38;5;241m.\u001b[39msize])\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 915\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    916\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot broadcast RegularArray of size \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    917\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m with RegularArray of size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    918\u001b[0m                 x\u001b[38;5;241m.\u001b[39msize, maxsize\n\u001b[1;32m    919\u001b[0m             )\n\u001b[1;32m    920\u001b[0m             \u001b[38;5;241m+\u001b[39m exception_suffix(\u001b[38;5;18m__file__\u001b[39m)\n\u001b[1;32m    921\u001b[0m         )\n\u001b[1;32m    922\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    923\u001b[0m     nextinputs\u001b[38;5;241m.\u001b[39mappend(x)\n",
      "\u001b[0;31mValueError\u001b[0m: cannot broadcast RegularArray of size 346502 with RegularArray of size 587391\n\n(https://github.com/scikit-hep/awkward-1.0/blob/1.10.3/src/awkward/_util.py#L920)"
     ]
    }
   ],
   "source": [
    "order = ['ggF HH', 'ttH', 'single-H', 'non-res']\n",
    "\n",
    "(\n",
    "    sig_rescale_factor,\n",
    "    data_df_dict, data_test_df_dict, \n",
    "    data_hlf_dict, label_dict, \n",
    "    data_hlf_test_dict, label_test_dict, \n",
    "    hlf_vars_columns_dict,\n",
    "    data_aux_dict, data_test_aux_dict\n",
    ") = process_data(\n",
    "    FILEPATHS_DICT, OUTPUT_DIRPATH, order=order, seed=SEED, mod_vals=MOD_VALS, k_fold_test=True,\n",
    "    save=False if 'CURRENT_TIME' in globals() else True\n",
    ")\n",
    "\n",
    "# Make xgb-like labels (NOT one-hot encoded, but integer encoded for each class)\n",
    "xgb_label_dict = {\n",
    "    f\"fold_{fold_idx}\": copy.deepcopy(xgb_labels(label_dict[f\"fold_{fold_idx}\"])) for fold_idx in range(len(data_test_aux_dict))\n",
    "}\n",
    "xgb_label_test_dict = {\n",
    "    f\"fold_{fold_idx}\": copy.deepcopy(xgb_labels(label_test_dict[f\"fold_{fold_idx}\"])) for fold_idx in range(len(data_test_aux_dict))\n",
    "}\n",
    "\n",
    "# Make weight dicts:\n",
    "#   - the top two are with the training rescale (i.e. rescale sig eventWeight to match bkg and then shift for gradients)\n",
    "#   - the bottom two are the standard eventWeights (i.e. xs * lumi * genWeight) for proper plotting\n",
    "weight_train_dict = {\n",
    "    f\"fold_{fold_idx}\": copy.deepcopy(training_weights(data_aux_dict[f'fold_{fold_idx}'].loc[:, \"eventWeight\"].to_numpy(), label_dict[f'fold_{fold_idx}'], order=order, sig_rescale_factor=sig_rescale_factor)) for fold_idx in range(len(data_aux_dict))\n",
    "}\n",
    "weight_test_dict = {\n",
    "    f'fold_{fold_idx}': copy.deepcopy(training_weights(data_test_aux_dict[f'fold_{fold_idx}'].loc[:, \"eventWeight\"].to_numpy(), label_dict[f'fold_{fold_idx}'], order=order, sig_rescale_factor=sig_rescale_factor)) for fold_idx in range(len(data_test_aux_dict))\n",
    "}\n",
    "weights_plot_train_dict = {\n",
    "    f\"fold_{fold_idx}\": copy.deepcopy(data_aux_dict[f'fold_{fold_idx}'].loc[:, \"eventWeight\"].to_numpy()) for fold_idx in range(len(data_aux_dict))\n",
    "}\n",
    "weights_plot_test = {\n",
    "    f'fold_{fold_idx}': copy.deepcopy(data_test_aux_dict[f'fold_{fold_idx}'].loc[:, \"eventWeight\"].to_numpy()) for fold_idx in range(len(data_test_aux_dict))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "Num train: 1250553 -> 109209 sig & 221927 ttH bkg & 375391 non-res + single-H bkg\n",
      "Num val: 312639 -> 27321 sig & 55278 ttH bkg & 93827 non-res + single-H bkg\n",
      "============================================================\n",
      "fold 1\n",
      "Num train: 1251336 -> 109163 sig & 221954 ttH bkg & 375690 non-res + single-H bkg\n",
      "Num val: 312835 -> 27303 sig & 55498 ttH bkg & 93803 non-res + single-H bkg\n",
      "============================================================\n",
      "fold 2\n",
      "Num train: 1250948 -> 109179 sig & 221279 ttH bkg & 376271 non-res + single-H bkg\n",
      "Num val: 312737 -> 27459 sig & 55348 ttH bkg & 93951 non-res + single-H bkg\n",
      "============================================================\n",
      "fold 3\n",
      "Num train: 1251535 -> 109262 sig & 221529 ttH bkg & 376945 non-res + single-H bkg\n",
      "Num val: 312884 -> 27409 sig & 55525 ttH bkg & 93987 non-res + single-H bkg\n",
      "============================================================\n",
      "fold 4\n",
      "Num train: 1251552 -> 109333 sig & 222071 ttH bkg & 375573 non-res + single-H bkg\n",
      "Num val: 312889 -> 27378 sig & 55599 ttH bkg & 94126 non-res + single-H bkg\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "bdt_train_dict, bdt_val_dict, bdt_test_dict = {}, {}, {}\n",
    "\n",
    "weights_plot_train, weights_plot_val= {}, {}\n",
    "for fold_idx in range(len(data_df_dict)):\n",
    "    if re.search('no_std', VARS) is not None:\n",
    "        print('no standardization')\n",
    "        train_val_data_dict = {key: value.to_numpy() for key, value in data_df_dict.items()}\n",
    "        test_data_dict = {key: value.to_numpy() for key, value in data_test_df_dict.items()}\n",
    "    else:\n",
    "        train_val_data_dict = data_hlf_dict\n",
    "        test_data_dict = data_hlf_test_dict\n",
    "    (\n",
    "        X_train, X_val, y_train, y_val, weight_train, weight_val, weight_plot_train, weight_plot_val\n",
    "    ) = train_test_split(\n",
    "        train_val_data_dict[f\"fold_{fold_idx}\"], xgb_label_dict[f\"fold_{fold_idx}\"], \n",
    "        weight_train_dict[f\"fold_{fold_idx}\"], weights_plot_train_dict[f\"fold_{fold_idx}\"],\n",
    "        test_size=0.2, random_state=21\n",
    "    )\n",
    "    weights_plot_train[f\"fold_{fold_idx}\"] = copy.deepcopy(weight_plot_train)\n",
    "    weights_plot_val[f\"fold_{fold_idx}\"] = copy.deepcopy(weight_plot_val)\n",
    "\n",
    "    bdt_train_dict[f\"fold_{fold_idx}\"] = xgb.DMatrix(\n",
    "        data=X_train, label=y_train, \n",
    "        weight=weight_train,\n",
    "        missing=-999.0, feature_names=list(hlf_vars_columns_dict[f\"fold_{fold_idx}\"])\n",
    "    )\n",
    "    bdt_val_dict[f\"fold_{fold_idx}\"] = xgb.DMatrix(\n",
    "        data=X_val, label=y_val, \n",
    "        weight=weight_val,\n",
    "        missing=-999.0, feature_names=list(hlf_vars_columns_dict[f\"fold_{fold_idx}\"])\n",
    "    )\n",
    "    \n",
    "    bdt_test_dict[f\"fold_{fold_idx}\"] = xgb.DMatrix(\n",
    "        data=test_data_dict[f\"fold_{fold_idx}\"], label=xgb_label_test_dict[f\"fold_{fold_idx}\"], \n",
    "        weight=np.abs(weight_test_dict[f\"fold_{fold_idx}\"]),\n",
    "        missing=-999.0, feature_names=list(hlf_vars_columns_dict[f\"fold_{fold_idx}\"])\n",
    "    )\n",
    "\n",
    "    print(f\"fold {fold_idx}\")\n",
    "    print(f\"Num train: {len(y_train)} -> {sum(y_train == 0)} sig & {sum(y_train == 1)} ttH bkg & {sum(y_train == 2)} non-res + single-H bkg\")\n",
    "    print(f\"Num val: {len(y_val)} -> {sum(y_val == 0)} sig & {sum(y_val == 1)} ttH bkg & {sum(y_val == 2)} non-res + single-H bkg\")\n",
    "    # print(f\"Num test: {len(label_test_dict[f'fold_{fold_idx}'])} -> {sum(label_test_dict[f'fold_{fold_idx}'] == np.array([1, 0, 0]))[0]} sig & {sum(label_test_dict[f'fold_{fold_idx}'] == np.array([0, 1, 0]))[1]} ttH bkg & {sum(label_test_dict[f'fold_{fold_idx}'] == np.array([0, 0, 1]))[2]} non-res + single-H bkg\")\n",
    "    print('='*60)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/57986259/multiclass-classification-with-xgboost-classifier\n",
    "# https://forecastegy.com/posts/xgboost-multiclass-classification-python/\n",
    "# https://indico.cern.ch/event/915265/contributions/3848138/attachments/2048174/3432202/kunlinRan_bbyy_20200531.pdf\n",
    "\n",
    "\n",
    "param = {}\n",
    "\n",
    "# Booster parameters\n",
    "param['eta']              = 0.05 # learning rate\n",
    "param['max_depth']        = 10  # maximum depth of a tree\n",
    "param['subsample']        = 0.5 # fraction of events to train tree on\n",
    "param['colsample_bytree'] = 0.5 # fraction of features to train tree on\n",
    "param['num_class']        = np.shape(label_dict['fold_0'])[1] # num classes for multi-class training\n",
    "\n",
    "# Learning task parameters\n",
    "param['objective']   = 'multi:softprob'   # objective function\n",
    "param['eval_metric'] = 'merror'           # evaluation metric for cross validation\n",
    "param = list(param.items()) + [('eval_metric', 'mlogloss')]\n",
    "# param[\"disable_default_eval_metric\"] = True\n",
    "# param = list(param.items())\n",
    "\n",
    "num_trees = 1500  # number of trees to make\n",
    "\n",
    "def thresholded_weighted_merror(predt: np.ndarray, dtrain: xgb.DMatrix, threshold=0.9):\n",
    "    \"\"\"Used when there's no custom objective.\"\"\"\n",
    "    # No need to do transform, XGBoost handles it internally.\n",
    "    weights = dtrain.get_weight()\n",
    "    thresh_weight_merror = np.where(\n",
    "        np.logical_and(\n",
    "            np.max(predt, axis=1) >= threshold,\n",
    "            np.argmax(predt, axis=1) == dtrain.get_label()\n",
    "        ),\n",
    "        0,\n",
    "        weights\n",
    "    )\n",
    "    return f'WeightedMError@{threshold:.2f}', np.sum(thresh_weight_merror)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "[0]\ttrain-merror:0.23151\ttrain-mlogloss:1.33325\ttest-merror:0.75382\ttest-mlogloss:1.37088\tval-merror:0.23872\tval-mlogloss:1.33418\n",
      "[25]\ttrain-merror:0.18320\ttrain-mlogloss:0.72981\ttest-merror:0.70439\ttest-mlogloss:1.17164\tval-merror:0.19236\tval-mlogloss:0.74304\n",
      "[50]\ttrain-merror:0.17091\ttrain-mlogloss:0.53996\ttest-merror:0.65865\ttest-mlogloss:1.08873\tval-merror:0.18216\tval-mlogloss:0.56292\n",
      "[75]\ttrain-merror:0.16190\ttrain-mlogloss:0.46294\ttest-merror:0.61953\ttest-mlogloss:1.03196\tval-merror:0.17597\tval-mlogloss:0.49521\n",
      "[100]\ttrain-merror:0.15395\ttrain-mlogloss:0.42146\ttest-merror:0.58757\ttest-mlogloss:0.98915\tval-merror:0.17100\tval-mlogloss:0.46260\n",
      "[125]\ttrain-merror:0.14657\ttrain-mlogloss:0.39415\ttest-merror:0.56147\ttest-mlogloss:0.95168\tval-merror:0.16646\tval-mlogloss:0.44363\n",
      "[150]\ttrain-merror:0.14113\ttrain-mlogloss:0.37529\ttest-merror:0.54535\ttest-mlogloss:0.92762\tval-merror:0.16370\tval-mlogloss:0.43262\n",
      "[175]\ttrain-merror:0.13484\ttrain-mlogloss:0.35842\ttest-merror:0.52441\ttest-mlogloss:0.90050\tval-merror:0.15986\tval-mlogloss:0.42318\n",
      "[200]\ttrain-merror:0.12913\ttrain-mlogloss:0.34438\ttest-merror:0.50771\ttest-mlogloss:0.88086\tval-merror:0.15670\tval-mlogloss:0.41645\n",
      "[225]\ttrain-merror:0.12351\ttrain-mlogloss:0.33133\ttest-merror:0.49008\ttest-mlogloss:0.86052\tval-merror:0.15398\tval-mlogloss:0.41040\n",
      "[250]\ttrain-merror:0.11921\ttrain-mlogloss:0.32088\ttest-merror:0.48001\ttest-mlogloss:0.84842\tval-merror:0.15231\tval-mlogloss:0.40634\n",
      "[275]\ttrain-merror:0.11386\ttrain-mlogloss:0.30941\ttest-merror:0.46187\ttest-mlogloss:0.82784\tval-merror:0.14917\tval-mlogloss:0.40080\n",
      "[300]\ttrain-merror:0.10971\ttrain-mlogloss:0.30042\ttest-merror:0.45128\ttest-mlogloss:0.81534\tval-merror:0.14757\tval-mlogloss:0.39723\n",
      "[325]\ttrain-merror:0.10561\ttrain-mlogloss:0.29191\ttest-merror:0.43873\ttest-mlogloss:0.79977\tval-merror:0.14578\tval-mlogloss:0.39325\n",
      "[350]\ttrain-merror:0.10152\ttrain-mlogloss:0.28323\ttest-merror:0.42636\ttest-mlogloss:0.78523\tval-merror:0.14370\tval-mlogloss:0.38929\n",
      "[375]\ttrain-merror:0.09793\ttrain-mlogloss:0.27566\ttest-merror:0.41512\ttest-mlogloss:0.77250\tval-merror:0.14233\tval-mlogloss:0.38602\n",
      "[400]\ttrain-merror:0.09476\ttrain-mlogloss:0.26870\ttest-merror:0.40850\ttest-mlogloss:0.76406\tval-merror:0.14089\tval-mlogloss:0.38346\n",
      "[425]\ttrain-merror:0.09234\ttrain-mlogloss:0.26326\ttest-merror:0.40569\ttest-mlogloss:0.76149\tval-merror:0.14020\tval-mlogloss:0.38227\n",
      "[450]\ttrain-merror:0.08941\ttrain-mlogloss:0.25711\ttest-merror:0.39966\ttest-mlogloss:0.75622\tval-merror:0.13943\tval-mlogloss:0.38043\n",
      "[475]\ttrain-merror:0.08672\ttrain-mlogloss:0.25093\ttest-merror:0.39212\ttest-mlogloss:0.74589\tval-merror:0.13807\tval-mlogloss:0.37789\n",
      "[500]\ttrain-merror:0.08431\ttrain-mlogloss:0.24568\ttest-merror:0.38893\ttest-mlogloss:0.74262\tval-merror:0.13766\tval-mlogloss:0.37666\n",
      "[525]\ttrain-merror:0.08147\ttrain-mlogloss:0.23961\ttest-merror:0.38025\ttest-mlogloss:0.73139\tval-merror:0.13604\tval-mlogloss:0.37395\n",
      "[550]\ttrain-merror:0.07911\ttrain-mlogloss:0.23480\ttest-merror:0.37686\ttest-mlogloss:0.72686\tval-merror:0.13556\tval-mlogloss:0.37259\n",
      "[575]\ttrain-merror:0.07686\ttrain-mlogloss:0.22994\ttest-merror:0.37402\ttest-mlogloss:0.72367\tval-merror:0.13490\tval-mlogloss:0.37154\n",
      "[600]\ttrain-merror:0.07454\ttrain-mlogloss:0.22509\ttest-merror:0.37106\ttest-mlogloss:0.71950\tval-merror:0.13435\tval-mlogloss:0.37040\n",
      "[625]\ttrain-merror:0.07268\ttrain-mlogloss:0.22104\ttest-merror:0.37026\ttest-mlogloss:0.71924\tval-merror:0.13416\tval-mlogloss:0.36999\n",
      "[650]\ttrain-merror:0.07046\ttrain-mlogloss:0.21660\ttest-merror:0.36711\ttest-mlogloss:0.71656\tval-merror:0.13372\tval-mlogloss:0.36917\n",
      "[675]\ttrain-merror:0.06850\ttrain-mlogloss:0.21234\ttest-merror:0.36529\ttest-mlogloss:0.71436\tval-merror:0.13350\tval-mlogloss:0.36832\n",
      "[700]\ttrain-merror:0.06667\ttrain-mlogloss:0.20844\ttest-merror:0.36369\ttest-mlogloss:0.71239\tval-merror:0.13328\tval-mlogloss:0.36765\n",
      "[725]\ttrain-merror:0.06459\ttrain-mlogloss:0.20447\ttest-merror:0.36151\ttest-mlogloss:0.71066\tval-merror:0.13302\tval-mlogloss:0.36722\n",
      "[750]\ttrain-merror:0.06283\ttrain-mlogloss:0.20079\ttest-merror:0.36017\ttest-mlogloss:0.70968\tval-merror:0.13268\tval-mlogloss:0.36668\n",
      "[775]\ttrain-merror:0.06071\ttrain-mlogloss:0.19614\ttest-merror:0.35465\ttest-mlogloss:0.70228\tval-merror:0.13184\tval-mlogloss:0.36483\n",
      "[800]\ttrain-merror:0.05879\ttrain-mlogloss:0.19206\ttest-merror:0.34975\ttest-mlogloss:0.69619\tval-merror:0.13127\tval-mlogloss:0.36338\n",
      "[825]\ttrain-merror:0.05713\ttrain-mlogloss:0.18860\ttest-merror:0.34888\ttest-mlogloss:0.69512\tval-merror:0.13100\tval-mlogloss:0.36280\n",
      "[828]\ttrain-merror:0.05696\ttrain-mlogloss:0.18828\ttest-merror:0.34928\ttest-mlogloss:0.69519\tval-merror:0.13095\tval-mlogloss:0.36283\n",
      "[818]\ttest-merror:0.349275\ttest-mlogloss:0.695188\n",
      "====================================================================================================\n",
      "fold 1\n",
      "[0]\ttrain-merror:0.25460\ttrain-mlogloss:1.33720\ttest-merror:0.72416\ttest-mlogloss:1.36970\tval-merror:0.26621\tval-mlogloss:1.33820\n",
      "[25]\ttrain-merror:0.18191\ttrain-mlogloss:0.71908\ttest-merror:0.68753\ttest-mlogloss:1.16164\tval-merror:0.19470\tval-mlogloss:0.73602\n",
      "[50]\ttrain-merror:0.16989\ttrain-mlogloss:0.53825\ttest-merror:0.64440\ttest-mlogloss:1.08555\tval-merror:0.18484\tval-mlogloss:0.56607\n",
      "[75]\ttrain-merror:0.16074\ttrain-mlogloss:0.46016\ttest-merror:0.61008\ttest-mlogloss:1.03353\tval-merror:0.17870\tval-mlogloss:0.49787\n",
      "[100]\ttrain-merror:0.15354\ttrain-mlogloss:0.41912\ttest-merror:0.58107\ttest-mlogloss:0.99465\tval-merror:0.17430\tval-mlogloss:0.46635\n",
      "[125]\ttrain-merror:0.14676\ttrain-mlogloss:0.39280\ttest-merror:0.55576\ttest-mlogloss:0.95829\tval-merror:0.17026\tval-mlogloss:0.44859\n",
      "[150]\ttrain-merror:0.13973\ttrain-mlogloss:0.37190\ttest-merror:0.53046\ttest-mlogloss:0.92534\tval-merror:0.16574\tval-mlogloss:0.43582\n",
      "[175]\ttrain-merror:0.13368\ttrain-mlogloss:0.35604\ttest-merror:0.51239\ttest-mlogloss:0.90189\tval-merror:0.16204\tval-mlogloss:0.42736\n",
      "[200]\ttrain-merror:0.12885\ttrain-mlogloss:0.34353\ttest-merror:0.50111\ttest-mlogloss:0.88546\tval-merror:0.15943\tval-mlogloss:0.42182\n",
      "[225]\ttrain-merror:0.12230\ttrain-mlogloss:0.32930\ttest-merror:0.47814\ttest-mlogloss:0.85709\tval-merror:0.15529\tval-mlogloss:0.41395\n",
      "[250]\ttrain-merror:0.11679\ttrain-mlogloss:0.31678\ttest-merror:0.45978\ttest-mlogloss:0.83310\tval-merror:0.15188\tval-mlogloss:0.40743\n",
      "[275]\ttrain-merror:0.11308\ttrain-mlogloss:0.30795\ttest-merror:0.45229\ttest-mlogloss:0.82465\tval-merror:0.15033\tval-mlogloss:0.40447\n",
      "[300]\ttrain-merror:0.10921\ttrain-mlogloss:0.29961\ttest-merror:0.44453\ttest-mlogloss:0.81418\tval-merror:0.14903\tval-mlogloss:0.40128\n",
      "[325]\ttrain-merror:0.10535\ttrain-mlogloss:0.29147\ttest-merror:0.43371\ttest-mlogloss:0.80236\tval-merror:0.14745\tval-mlogloss:0.39801\n",
      "[350]\ttrain-merror:0.10229\ttrain-mlogloss:0.28466\ttest-merror:0.42797\ttest-mlogloss:0.79522\tval-merror:0.14622\tval-mlogloss:0.39566\n",
      "[375]\ttrain-merror:0.09887\ttrain-mlogloss:0.27740\ttest-merror:0.42011\ttest-mlogloss:0.78567\tval-merror:0.14492\tval-mlogloss:0.39309\n",
      "[400]\ttrain-merror:0.09579\ttrain-mlogloss:0.27081\ttest-merror:0.41374\ttest-mlogloss:0.77966\tval-merror:0.14387\tval-mlogloss:0.39104\n",
      "[425]\ttrain-merror:0.09305\ttrain-mlogloss:0.26491\ttest-merror:0.40992\ttest-mlogloss:0.77529\tval-merror:0.14318\tval-mlogloss:0.38949\n",
      "[450]\ttrain-merror:0.09005\ttrain-mlogloss:0.25863\ttest-merror:0.40444\ttest-mlogloss:0.76873\tval-merror:0.14220\tval-mlogloss:0.38758\n",
      "[475]\ttrain-merror:0.08639\ttrain-mlogloss:0.25063\ttest-merror:0.38889\ttest-mlogloss:0.74891\tval-merror:0.13967\tval-mlogloss:0.38284\n",
      "[500]\ttrain-merror:0.08415\ttrain-mlogloss:0.24560\ttest-merror:0.38519\ttest-mlogloss:0.74390\tval-merror:0.13893\tval-mlogloss:0.38136\n",
      "[525]\ttrain-merror:0.08196\ttrain-mlogloss:0.24096\ttest-merror:0.38380\ttest-mlogloss:0.74363\tval-merror:0.13871\tval-mlogloss:0.38086\n",
      "[550]\ttrain-merror:0.07926\ttrain-mlogloss:0.23488\ttest-merror:0.37549\ttest-mlogloss:0.73263\tval-merror:0.13756\tval-mlogloss:0.37815\n",
      "[575]\ttrain-merror:0.07716\ttrain-mlogloss:0.23062\ttest-merror:0.37476\ttest-mlogloss:0.73316\tval-merror:0.13731\tval-mlogloss:0.37776\n",
      "[600]\ttrain-merror:0.07480\ttrain-mlogloss:0.22567\ttest-merror:0.37154\ttest-mlogloss:0.72843\tval-merror:0.13673\tval-mlogloss:0.37640\n",
      "[625]\ttrain-merror:0.07253\ttrain-mlogloss:0.22107\ttest-merror:0.36899\ttest-mlogloss:0.72536\tval-merror:0.13623\tval-mlogloss:0.37530\n",
      "[650]\ttrain-merror:0.06969\ttrain-mlogloss:0.21509\ttest-merror:0.35983\ttest-mlogloss:0.71438\tval-merror:0.13502\tval-mlogloss:0.37257\n",
      "[675]\ttrain-merror:0.06743\ttrain-mlogloss:0.20992\ttest-merror:0.35357\ttest-mlogloss:0.70610\tval-merror:0.13398\tval-mlogloss:0.37037\n",
      "[700]\ttrain-merror:0.06540\ttrain-mlogloss:0.20592\ttest-merror:0.35179\ttest-mlogloss:0.70449\tval-merror:0.13352\tval-mlogloss:0.36971\n",
      "[725]\ttrain-merror:0.06329\ttrain-mlogloss:0.20158\ttest-merror:0.34674\ttest-mlogloss:0.69840\tval-merror:0.13287\tval-mlogloss:0.36817\n",
      "[750]\ttrain-merror:0.06158\ttrain-mlogloss:0.19779\ttest-merror:0.34384\ttest-mlogloss:0.69642\tval-merror:0.13246\tval-mlogloss:0.36755\n",
      "[775]\ttrain-merror:0.05946\ttrain-mlogloss:0.19296\ttest-merror:0.33860\ttest-mlogloss:0.68814\tval-merror:0.13150\tval-mlogloss:0.36541\n",
      "[800]\ttrain-merror:0.05777\ttrain-mlogloss:0.18933\ttest-merror:0.33695\ttest-mlogloss:0.68578\tval-merror:0.13135\tval-mlogloss:0.36463\n",
      "[803]\ttrain-merror:0.05754\ttrain-mlogloss:0.18894\ttest-merror:0.33658\ttest-mlogloss:0.68596\tval-merror:0.13140\tval-mlogloss:0.36463\n",
      "[793]\ttest-merror:0.336582\ttest-mlogloss:0.685963\n",
      "====================================================================================================\n",
      "fold 2\n",
      "[0]\ttrain-merror:0.22917\ttrain-mlogloss:1.33371\ttest-merror:0.75805\ttest-mlogloss:1.37193\tval-merror:0.23806\tval-mlogloss:1.33479\n",
      "[25]\ttrain-merror:0.18080\ttrain-mlogloss:0.71780\ttest-merror:0.71156\ttest-mlogloss:1.16578\tval-merror:0.19206\tval-mlogloss:0.73359\n",
      "[50]\ttrain-merror:0.16822\ttrain-mlogloss:0.53242\ttest-merror:0.65729\ttest-mlogloss:1.08367\tval-merror:0.18233\tval-mlogloss:0.55881\n",
      "[75]\ttrain-merror:0.15949\ttrain-mlogloss:0.45812\ttest-merror:0.61621\ttest-mlogloss:1.03107\tval-merror:0.17614\tval-mlogloss:0.49454\n",
      "[100]\ttrain-merror:0.15149\ttrain-mlogloss:0.41701\ttest-merror:0.58378\ttest-mlogloss:0.98779\tval-merror:0.17123\tval-mlogloss:0.46292\n",
      "[125]\ttrain-merror:0.14414\ttrain-mlogloss:0.39014\ttest-merror:0.55602\ttest-mlogloss:0.95185\tval-merror:0.16685\tval-mlogloss:0.44490\n",
      "[150]\ttrain-merror:0.13802\ttrain-mlogloss:0.37074\ttest-merror:0.53376\ttest-mlogloss:0.92576\tval-merror:0.16358\tval-mlogloss:0.43376\n",
      "[175]\ttrain-merror:0.13287\ttrain-mlogloss:0.35568\ttest-merror:0.51907\ttest-mlogloss:0.90601\tval-merror:0.16117\tval-mlogloss:0.42657\n",
      "[200]\ttrain-merror:0.12764\ttrain-mlogloss:0.34214\ttest-merror:0.50219\ttest-mlogloss:0.88671\tval-merror:0.15846\tval-mlogloss:0.42033\n",
      "[225]\ttrain-merror:0.12280\ttrain-mlogloss:0.33014\ttest-merror:0.48820\ttest-mlogloss:0.86888\tval-merror:0.15613\tval-mlogloss:0.41509\n",
      "[250]\ttrain-merror:0.11845\ttrain-mlogloss:0.31982\ttest-merror:0.47696\ttest-mlogloss:0.85720\tval-merror:0.15431\tval-mlogloss:0.41128\n",
      "[275]\ttrain-merror:0.11378\ttrain-mlogloss:0.30975\ttest-merror:0.46533\ttest-mlogloss:0.84120\tval-merror:0.15210\tval-mlogloss:0.40696\n",
      "[300]\ttrain-merror:0.10872\ttrain-mlogloss:0.29936\ttest-merror:0.44795\ttest-mlogloss:0.81951\tval-merror:0.14898\tval-mlogloss:0.40174\n",
      "[325]\ttrain-merror:0.10454\ttrain-mlogloss:0.29010\ttest-merror:0.43306\ttest-mlogloss:0.80143\tval-merror:0.14668\tval-mlogloss:0.39715\n",
      "[350]\ttrain-merror:0.10023\ttrain-mlogloss:0.28066\ttest-merror:0.41627\ttest-mlogloss:0.77985\tval-merror:0.14372\tval-mlogloss:0.39183\n",
      "[375]\ttrain-merror:0.09699\ttrain-mlogloss:0.27356\ttest-merror:0.41093\ttest-mlogloss:0.77372\tval-merror:0.14270\tval-mlogloss:0.38960\n",
      "[400]\ttrain-merror:0.09435\ttrain-mlogloss:0.26780\ttest-merror:0.40857\ttest-mlogloss:0.77138\tval-merror:0.14229\tval-mlogloss:0.38858\n",
      "[425]\ttrain-merror:0.09084\ttrain-mlogloss:0.25981\ttest-merror:0.39641\ttest-mlogloss:0.75372\tval-merror:0.14031\tval-mlogloss:0.38427\n",
      "[450]\ttrain-merror:0.08821\ttrain-mlogloss:0.25411\ttest-merror:0.39314\ttest-mlogloss:0.74843\tval-merror:0.13948\tval-mlogloss:0.38270\n",
      "[475]\ttrain-merror:0.08583\ttrain-mlogloss:0.24912\ttest-merror:0.39058\ttest-mlogloss:0.74534\tval-merror:0.13917\tval-mlogloss:0.38175\n",
      "[500]\ttrain-merror:0.08325\ttrain-mlogloss:0.24379\ttest-merror:0.38530\ttest-mlogloss:0.74003\tval-merror:0.13857\tval-mlogloss:0.38040\n",
      "[525]\ttrain-merror:0.08107\ttrain-mlogloss:0.23890\ttest-merror:0.38213\ttest-mlogloss:0.73609\tval-merror:0.13803\tval-mlogloss:0.37920\n",
      "[550]\ttrain-merror:0.07896\ttrain-mlogloss:0.23422\ttest-merror:0.37813\ttest-mlogloss:0.73246\tval-merror:0.13746\tval-mlogloss:0.37807\n",
      "[575]\ttrain-merror:0.07670\ttrain-mlogloss:0.22937\ttest-merror:0.37483\ttest-mlogloss:0.72889\tval-merror:0.13699\tval-mlogloss:0.37706\n",
      "[600]\ttrain-merror:0.07451\ttrain-mlogloss:0.22498\ttest-merror:0.37211\ttest-mlogloss:0.72566\tval-merror:0.13667\tval-mlogloss:0.37612\n",
      "[625]\ttrain-merror:0.07227\ttrain-mlogloss:0.21994\ttest-merror:0.36755\ttest-mlogloss:0.72046\tval-merror:0.13599\tval-mlogloss:0.37459\n",
      "[650]\ttrain-merror:0.07005\ttrain-mlogloss:0.21561\ttest-merror:0.36465\ttest-mlogloss:0.71750\tval-merror:0.13549\tval-mlogloss:0.37380\n",
      "[666]\ttrain-merror:0.06881\ttrain-mlogloss:0.21324\ttest-merror:0.36466\ttest-mlogloss:0.71749\tval-merror:0.13559\tval-mlogloss:0.37367\n",
      "[656]\ttest-merror:0.364655\ttest-mlogloss:0.717495\n",
      "====================================================================================================\n",
      "fold 3\n",
      "[0]\ttrain-merror:0.23277\ttrain-mlogloss:1.33445\ttest-merror:0.85568\ttest-mlogloss:1.37807\tval-merror:0.24020\tval-mlogloss:1.33521\n",
      "[25]\ttrain-merror:0.18246\ttrain-mlogloss:0.72223\ttest-merror:0.71702\ttest-mlogloss:1.18310\tval-merror:0.19171\tval-mlogloss:0.73474\n",
      "[50]\ttrain-merror:0.17125\ttrain-mlogloss:0.53880\ttest-merror:0.66507\ttest-mlogloss:1.10046\tval-merror:0.18289\tval-mlogloss:0.56097\n",
      "[75]\ttrain-merror:0.16110\ttrain-mlogloss:0.46095\ttest-merror:0.62560\ttest-mlogloss:1.04668\tval-merror:0.17578\tval-mlogloss:0.49272\n",
      "[100]\ttrain-merror:0.15325\ttrain-mlogloss:0.41912\ttest-merror:0.59371\ttest-mlogloss:1.00535\tval-merror:0.17057\tval-mlogloss:0.45993\n",
      "[125]\ttrain-merror:0.14625\ttrain-mlogloss:0.39326\ttest-merror:0.56735\ttest-mlogloss:0.96832\tval-merror:0.16640\tval-mlogloss:0.44246\n",
      "[150]\ttrain-merror:0.13814\ttrain-mlogloss:0.37101\ttest-merror:0.53615\ttest-mlogloss:0.92787\tval-merror:0.16138\tval-mlogloss:0.42844\n",
      "[175]\ttrain-merror:0.13152\ttrain-mlogloss:0.35416\ttest-merror:0.51382\ttest-mlogloss:0.90098\tval-merror:0.15740\tval-mlogloss:0.41907\n",
      "[200]\ttrain-merror:0.12657\ttrain-mlogloss:0.34060\ttest-merror:0.49814\ttest-mlogloss:0.88211\tval-merror:0.15492\tval-mlogloss:0.41257\n",
      "[225]\ttrain-merror:0.12139\ttrain-mlogloss:0.32833\ttest-merror:0.48445\ttest-mlogloss:0.86344\tval-merror:0.15241\tval-mlogloss:0.40696\n",
      "[250]\ttrain-merror:0.11689\ttrain-mlogloss:0.31772\ttest-merror:0.47160\ttest-mlogloss:0.84874\tval-merror:0.15035\tval-mlogloss:0.40259\n",
      "[275]\ttrain-merror:0.11303\ttrain-mlogloss:0.30877\ttest-merror:0.46194\ttest-mlogloss:0.83802\tval-merror:0.14859\tval-mlogloss:0.39927\n",
      "[300]\ttrain-merror:0.10877\ttrain-mlogloss:0.29944\ttest-merror:0.44889\ttest-mlogloss:0.82456\tval-merror:0.14631\tval-mlogloss:0.39528\n",
      "[325]\ttrain-merror:0.10433\ttrain-mlogloss:0.29022\ttest-merror:0.43655\ttest-mlogloss:0.80943\tval-merror:0.14444\tval-mlogloss:0.39112\n",
      "[350]\ttrain-merror:0.10115\ttrain-mlogloss:0.28306\ttest-merror:0.43064\ttest-mlogloss:0.80128\tval-merror:0.14317\tval-mlogloss:0.38862\n",
      "[375]\ttrain-merror:0.09719\ttrain-mlogloss:0.27480\ttest-merror:0.41905\ttest-mlogloss:0.78758\tval-merror:0.14126\tval-mlogloss:0.38502\n",
      "[400]\ttrain-merror:0.09397\ttrain-mlogloss:0.26743\ttest-merror:0.41106\ttest-mlogloss:0.77799\tval-merror:0.13975\tval-mlogloss:0.38220\n",
      "[425]\ttrain-merror:0.09096\ttrain-mlogloss:0.26074\ttest-merror:0.40397\ttest-mlogloss:0.76988\tval-merror:0.13849\tval-mlogloss:0.37980\n",
      "[450]\ttrain-merror:0.08900\ttrain-mlogloss:0.25626\ttest-merror:0.40282\ttest-mlogloss:0.76975\tval-merror:0.13854\tval-mlogloss:0.37911\n",
      "[475]\ttrain-merror:0.08551\ttrain-mlogloss:0.24837\ttest-merror:0.38698\ttest-mlogloss:0.75033\tval-merror:0.13643\tval-mlogloss:0.37450\n",
      "[500]\ttrain-merror:0.08275\ttrain-mlogloss:0.24226\ttest-merror:0.38076\ttest-mlogloss:0.74354\tval-merror:0.13547\tval-mlogloss:0.37251\n",
      "[525]\ttrain-merror:0.08019\ttrain-mlogloss:0.23697\ttest-merror:0.37682\ttest-mlogloss:0.73784\tval-merror:0.13495\tval-mlogloss:0.37089\n",
      "[550]\ttrain-merror:0.07798\ttrain-mlogloss:0.23205\ttest-merror:0.37257\ttest-mlogloss:0.73130\tval-merror:0.13442\tval-mlogloss:0.36927\n",
      "[575]\ttrain-merror:0.07542\ttrain-mlogloss:0.22602\ttest-merror:0.36553\ttest-mlogloss:0.72120\tval-merror:0.13333\tval-mlogloss:0.36665\n",
      "[600]\ttrain-merror:0.07312\ttrain-mlogloss:0.22112\ttest-merror:0.36219\ttest-mlogloss:0.71680\tval-merror:0.13262\tval-mlogloss:0.36522\n",
      "[625]\ttrain-merror:0.07130\ttrain-mlogloss:0.21699\ttest-merror:0.35872\ttest-mlogloss:0.71340\tval-merror:0.13187\tval-mlogloss:0.36423\n",
      "[650]\ttrain-merror:0.06923\ttrain-mlogloss:0.21264\ttest-merror:0.35555\ttest-mlogloss:0.70949\tval-merror:0.13127\tval-mlogloss:0.36310\n",
      "[675]\ttrain-merror:0.06727\ttrain-mlogloss:0.20817\ttest-merror:0.35145\ttest-mlogloss:0.70551\tval-merror:0.13085\tval-mlogloss:0.36179\n",
      "[700]\ttrain-merror:0.06537\ttrain-mlogloss:0.20444\ttest-merror:0.34970\ttest-mlogloss:0.70520\tval-merror:0.13067\tval-mlogloss:0.36142\n",
      "[725]\ttrain-merror:0.06331\ttrain-mlogloss:0.19986\ttest-merror:0.34614\ttest-mlogloss:0.69900\tval-merror:0.12963\tval-mlogloss:0.35971\n",
      "[750]\ttrain-merror:0.06145\ttrain-mlogloss:0.19617\ttest-merror:0.34492\ttest-mlogloss:0.69768\tval-merror:0.12935\tval-mlogloss:0.35914\n",
      "[775]\ttrain-merror:0.05963\ttrain-mlogloss:0.19259\ttest-merror:0.34315\ttest-mlogloss:0.69593\tval-merror:0.12904\tval-mlogloss:0.35854\n",
      "[800]\ttrain-merror:0.05781\ttrain-mlogloss:0.18866\ttest-merror:0.33954\ttest-mlogloss:0.69189\tval-merror:0.12851\tval-mlogloss:0.35749\n",
      "[805]\ttrain-merror:0.05745\ttrain-mlogloss:0.18804\ttest-merror:0.33980\ttest-mlogloss:0.69199\tval-merror:0.12854\tval-mlogloss:0.35748\n",
      "[795]\ttest-merror:0.339796\ttest-mlogloss:0.691991\n",
      "====================================================================================================\n",
      "fold 4\n",
      "[0]\ttrain-merror:0.25768\ttrain-mlogloss:1.33723\ttest-merror:0.75257\ttest-mlogloss:1.37326\tval-merror:0.26925\tval-mlogloss:1.33836\n",
      "[25]\ttrain-merror:0.18197\ttrain-mlogloss:0.72181\ttest-merror:0.71530\ttest-mlogloss:1.18215\tval-merror:0.19359\tval-mlogloss:0.73842\n",
      "[50]\ttrain-merror:0.17070\ttrain-mlogloss:0.53738\ttest-merror:0.66687\ttest-mlogloss:1.09506\tval-merror:0.18447\tval-mlogloss:0.56503\n",
      "[75]\ttrain-merror:0.16145\ttrain-mlogloss:0.45934\ttest-merror:0.63280\ttest-mlogloss:1.04418\tval-merror:0.17809\tval-mlogloss:0.49699\n",
      "[100]\ttrain-merror:0.15337\ttrain-mlogloss:0.41954\ttest-merror:0.59974\ttest-mlogloss:0.99910\tval-merror:0.17257\tval-mlogloss:0.46636\n",
      "[125]\ttrain-merror:0.14621\ttrain-mlogloss:0.39226\ttest-merror:0.57268\ttest-mlogloss:0.96261\tval-merror:0.16881\tval-mlogloss:0.44774\n",
      "[150]\ttrain-merror:0.13854\ttrain-mlogloss:0.37047\ttest-merror:0.54159\ttest-mlogloss:0.92202\tval-merror:0.16364\tval-mlogloss:0.43382\n",
      "[175]\ttrain-merror:0.13159\ttrain-mlogloss:0.35334\ttest-merror:0.51385\ttest-mlogloss:0.89085\tval-merror:0.15932\tval-mlogloss:0.42423\n",
      "[200]\ttrain-merror:0.12641\ttrain-mlogloss:0.33999\ttest-merror:0.49985\ttest-mlogloss:0.87310\tval-merror:0.15678\tval-mlogloss:0.41816\n",
      "[225]\ttrain-merror:0.12066\ttrain-mlogloss:0.32707\ttest-merror:0.48032\ttest-mlogloss:0.84889\tval-merror:0.15343\tval-mlogloss:0.41169\n",
      "[250]\ttrain-merror:0.11657\ttrain-mlogloss:0.31746\ttest-merror:0.47303\ttest-mlogloss:0.83915\tval-merror:0.15186\tval-mlogloss:0.40814\n",
      "[275]\ttrain-merror:0.11217\ttrain-mlogloss:0.30737\ttest-merror:0.46067\ttest-mlogloss:0.82463\tval-merror:0.14985\tval-mlogloss:0.40388\n",
      "[300]\ttrain-merror:0.10767\ttrain-mlogloss:0.29736\ttest-merror:0.44416\ttest-mlogloss:0.80518\tval-merror:0.14733\tval-mlogloss:0.39894\n",
      "[325]\ttrain-merror:0.10368\ttrain-mlogloss:0.28849\ttest-merror:0.43240\ttest-mlogloss:0.78988\tval-merror:0.14511\tval-mlogloss:0.39498\n",
      "[350]\ttrain-merror:0.10040\ttrain-mlogloss:0.28132\ttest-merror:0.42556\ttest-mlogloss:0.78070\tval-merror:0.14388\tval-mlogloss:0.39232\n",
      "[375]\ttrain-merror:0.09715\ttrain-mlogloss:0.27431\ttest-merror:0.41626\ttest-mlogloss:0.77200\tval-merror:0.14279\tval-mlogloss:0.38981\n",
      "[400]\ttrain-merror:0.09402\ttrain-mlogloss:0.26735\ttest-merror:0.40762\ttest-mlogloss:0.76115\tval-merror:0.14123\tval-mlogloss:0.38699\n",
      "[425]\ttrain-merror:0.09074\ttrain-mlogloss:0.25996\ttest-merror:0.39642\ttest-mlogloss:0.74804\tval-merror:0.13991\tval-mlogloss:0.38356\n",
      "[450]\ttrain-merror:0.08779\ttrain-mlogloss:0.25333\ttest-merror:0.38851\ttest-mlogloss:0.73683\tval-merror:0.13844\tval-mlogloss:0.38075\n",
      "[475]\ttrain-merror:0.08521\ttrain-mlogloss:0.24768\ttest-merror:0.38529\ttest-mlogloss:0.73251\tval-merror:0.13801\tval-mlogloss:0.37933\n",
      "[500]\ttrain-merror:0.08279\ttrain-mlogloss:0.24191\ttest-merror:0.37919\ttest-mlogloss:0.72558\tval-merror:0.13710\tval-mlogloss:0.37737\n",
      "[525]\ttrain-merror:0.08032\ttrain-mlogloss:0.23635\ttest-merror:0.37461\ttest-mlogloss:0.71741\tval-merror:0.13610\tval-mlogloss:0.37521\n",
      "[550]\ttrain-merror:0.07799\ttrain-mlogloss:0.23128\ttest-merror:0.37118\ttest-mlogloss:0.71259\tval-merror:0.13560\tval-mlogloss:0.37382\n",
      "[575]\ttrain-merror:0.07581\ttrain-mlogloss:0.22658\ttest-merror:0.36794\ttest-mlogloss:0.70879\tval-merror:0.13514\tval-mlogloss:0.37273\n",
      "[600]\ttrain-merror:0.07377\ttrain-mlogloss:0.22255\ttest-merror:0.36682\ttest-mlogloss:0.70843\tval-merror:0.13491\tval-mlogloss:0.37231\n",
      "[625]\ttrain-merror:0.07150\ttrain-mlogloss:0.21762\ttest-merror:0.35978\ttest-mlogloss:0.70185\tval-merror:0.13422\tval-mlogloss:0.37080\n",
      "[650]\ttrain-merror:0.06967\ttrain-mlogloss:0.21386\ttest-merror:0.35962\ttest-mlogloss:0.70190\tval-merror:0.13419\tval-mlogloss:0.37032\n",
      "[675]\ttrain-merror:0.06784\ttrain-mlogloss:0.21026\ttest-merror:0.35907\ttest-mlogloss:0.70189\tval-merror:0.13404\tval-mlogloss:0.37006\n",
      "[700]\ttrain-merror:0.06591\ttrain-mlogloss:0.20649\ttest-merror:0.35830\ttest-mlogloss:0.70132\tval-merror:0.13395\tval-mlogloss:0.36979\n",
      "[725]\ttrain-merror:0.06402\ttrain-mlogloss:0.20241\ttest-merror:0.35540\ttest-mlogloss:0.69790\tval-merror:0.13366\tval-mlogloss:0.36888\n",
      "[750]\ttrain-merror:0.06227\ttrain-mlogloss:0.19867\ttest-merror:0.35357\ttest-mlogloss:0.69630\tval-merror:0.13326\tval-mlogloss:0.36830\n",
      "[775]\ttrain-merror:0.06029\ttrain-mlogloss:0.19412\ttest-merror:0.34777\ttest-mlogloss:0.68861\tval-merror:0.13247\tval-mlogloss:0.36655\n",
      "[784]\ttrain-merror:0.05966\ttrain-mlogloss:0.19299\ttest-merror:0.34720\ttest-mlogloss:0.68920\tval-merror:0.13252\tval-mlogloss:0.36657\n",
      "[774]\ttest-merror:0.347205\ttest-mlogloss:0.689202\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "if 'CURRENT_TIME' in globals():\n",
    "    OUTPUT_DIRPATH, OLD_TIME = os.path.split(OUTPUT_DIRPATH)\n",
    "CURRENT_TIME = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "OUTPUT_DIRPATH = os.path.join(OUTPUT_DIRPATH, CURRENT_TIME)\n",
    "if not os.path.exists(OUTPUT_DIRPATH):\n",
    "    os.makedirs(OUTPUT_DIRPATH)\n",
    "\n",
    "evals_result_dict = {f\"fold_{fold_idx}\": dict() for fold_idx in range(len(bdt_train_dict))}\n",
    "for fold_idx in range(len(bdt_train_dict)):\n",
    "    print(f\"fold {fold_idx}\")\n",
    "    # Train bdt\n",
    "    evallist = [(bdt_train_dict[f\"fold_{fold_idx}\"], 'train'), (bdt_test_dict[f\"fold_{fold_idx}\"], 'test'), (bdt_val_dict[f\"fold_{fold_idx}\"], 'val')]\n",
    "    booster = xgb.train(\n",
    "        param, bdt_train_dict[f\"fold_{fold_idx}\"], num_boost_round=num_trees, \n",
    "        evals=evallist, early_stopping_rounds=10, verbose_eval=25, evals_result=evals_result_dict[f\"fold_{fold_idx}\"],\n",
    "        # custom_metric=thresholded_weighted_merror\n",
    "    )\n",
    "\n",
    "    booster.save_model(os.path.join(OUTPUT_DIRPATH, f'{CURRENT_TIME}_BDT_fold{fold_idx}.model'))\n",
    "    \n",
    "    # Print perf on test dataset\n",
    "    print(booster.eval(bdt_test_dict[f\"fold_{fold_idx}\"], name='test', iteration=booster.best_iteration))\n",
    "    print('='*100)\n",
    "\n",
    "with open(os.path.join(OUTPUT_DIRPATH, f'{CURRENT_TIME}_BDT_eval_result.json'), 'w') as f:\n",
    "    json.dump(evals_result_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_tpr = np.linspace(0, 1, 5000)  # copied from IN evaluate.py file\n",
    "roc_baseline = np.zeros(\n",
    "    (len(bdt_train_dict), len(base_tpr), len(order)), \n",
    "    dtype=float\n",
    ")\n",
    "area_baseline = np.zeros(\n",
    "    (len(bdt_train_dict), len(order)), \n",
    "    dtype=float\n",
    ")\n",
    "\n",
    "BDT_perf = {\n",
    "    sample_name: copy.deepcopy({\n",
    "        'base_tpr': base_tpr,\n",
    "        'class_order': copy.deepcopy(order),\n",
    "        # test data #\n",
    "        'preds': [],\n",
    "        'fprs_density': copy.deepcopy(roc_baseline), 'thresholds_density': copy.deepcopy(roc_baseline), 'areas_density': copy.deepcopy(area_baseline),\n",
    "        'fprs_weighted': copy.deepcopy(roc_baseline), 'thresholds_weighted': copy.deepcopy(roc_baseline), 'areas_weighted': copy.deepcopy(area_baseline),\n",
    "        'fprs_sum_density': copy.deepcopy(roc_baseline[0, ...]), 'thresholds_sum_density': copy.deepcopy(roc_baseline[0, ...]), 'areas_sum_density': copy.deepcopy(area_baseline[0, ...]),\n",
    "        'fprs_sum_weighted': copy.deepcopy(roc_baseline[0, ...]), 'thresholds_sum_weighted': copy.deepcopy(roc_baseline[0, ...]), 'areas_sum_weighted': copy.deepcopy(area_baseline[0, ...]),\n",
    "        # train data #\n",
    "        'train_preds': [], \n",
    "        'train_fprs_density': copy.deepcopy(roc_baseline), 'train_thresholds_density': copy.deepcopy(roc_baseline), 'train_areas_density': copy.deepcopy(area_baseline),\n",
    "        'train_fprs_weighted': copy.deepcopy(roc_baseline), 'train_thresholds_weighted': copy.deepcopy(roc_baseline), 'train_areas_weighted': copy.deepcopy(area_baseline),\n",
    "        'train_fprs_sum_density': copy.deepcopy(roc_baseline[0, ...]), 'train_thresholds_sum_density': copy.deepcopy(roc_baseline[0, ...]), 'train_areas_sum_density': copy.deepcopy(area_baseline[0, ...]),\n",
    "        'train_fprs_sum_weighted': copy.deepcopy(roc_baseline[0, ...]), 'train_thresholds_sum_weighted': copy.deepcopy(roc_baseline[0, ...]), 'train_areas_sum_weighted': copy.deepcopy(area_baseline[0, ...]),\n",
    "        # val data #\n",
    "        'val_preds': [],\n",
    "        'val_fprs_density': copy.deepcopy(roc_baseline), 'val_thresholds_density': copy.deepcopy(roc_baseline), 'val_areas_density': copy.deepcopy(area_baseline),\n",
    "        'val_fprs_weighted': copy.deepcopy(roc_baseline), 'val_thresholds_weighted': copy.deepcopy(roc_baseline), 'val_areas_weighted': copy.deepcopy(area_baseline),\n",
    "        'val_fprs_sum_density': copy.deepcopy(roc_baseline[0, ...]), 'val_thresholds_sum_density': copy.deepcopy(roc_baseline[0, ...]), 'val_areas_sum_density': copy.deepcopy(area_baseline[0, ...]),\n",
    "        'val_fprs_sum_weighted': copy.deepcopy(roc_baseline[0, ...]), 'val_thresholds_sum_weighted': copy.deepcopy(roc_baseline[0, ...]), 'val_areas_sum_weighted': copy.deepcopy(area_baseline[0, ...]),\n",
    "    }) for sample_name in order\n",
    "}\n",
    "\n",
    "for j, sample_name in enumerate(order):\n",
    "\n",
    "    for fold_idx in range(len(bdt_train_dict)):\n",
    "        booster = xgb.Booster(param)\n",
    "        booster.load_model(os.path.join(OUTPUT_DIRPATH, f'{CURRENT_TIME}_BDT_fold{fold_idx}.model'))\n",
    "    \n",
    "        for pred_type, dataset in [\n",
    "            ('train_', bdt_train_dict[f\"fold_{fold_idx}\"]),\n",
    "            ('val_', bdt_val_dict[f\"fold_{fold_idx}\"]),\n",
    "            ('', bdt_test_dict[f\"fold_{fold_idx}\"])\n",
    "        ]:\n",
    "            BDT_perf[sample_name][pred_type + 'preds'].append(\n",
    "                booster.predict(\n",
    "                    dataset, \n",
    "                    iteration_range=(0, booster.best_iteration+1)\n",
    "                ).tolist()\n",
    "            )\n",
    "\n",
    "            for i, sample_name_ in enumerate(order):\n",
    "                \n",
    "                if sample_name_ == sample_name:\n",
    "                    event_mask = dataset.get_label() > -1\n",
    "                    pred_rescale = np.ones_like(event_mask)\n",
    "                else:\n",
    "                    event_mask = np.logical_or(dataset.get_label() == j, dataset.get_label() == i)\n",
    "                    pred_rescale = np.array(BDT_perf[sample_name][pred_type + 'preds'][-1])[:, j][event_mask] + np.array(BDT_perf[sample_name][pred_type + 'preds'][-1])[:, i][event_mask]\n",
    "                class_preds = np.array(BDT_perf[sample_name][pred_type + 'preds'][-1])[:, j][event_mask] / pred_rescale\n",
    "                class_truths = np.where(dataset.get_label() == j, 1, 0)[event_mask]\n",
    "                \n",
    "                for roc_type in ['density', 'weighted']:\n",
    "\n",
    "                    if roc_type == 'weighted':\n",
    "                        if re.search('train', pred_type) is not None:\n",
    "                            roc_weights = weights_plot_train[f\"fold_{fold_idx}\"][event_mask]\n",
    "                        elif re.search('val', pred_type) is not None:\n",
    "                            roc_weights = weights_plot_val[f\"fold_{fold_idx}\"][event_mask]\n",
    "                        else:\n",
    "                            roc_weights = weights_plot_test[f\"fold_{fold_idx}\"][event_mask]\n",
    "                    else:\n",
    "                        roc_weights = None\n",
    "\n",
    "                    fpr_bdt, tpr_bdt, threshold_bdt = roc_curve(class_truths, class_preds, sample_weight=roc_weights)\n",
    "                    fpr_bdt = np.interp(base_tpr, tpr_bdt, fpr_bdt)\n",
    "                    threshold_bdt = np.interp(base_tpr, tpr_bdt, threshold_bdt)\n",
    "\n",
    "                    BDT_perf[sample_name][pred_type + 'fprs_' + roc_type][fold_idx][:, i] = fpr_bdt\n",
    "                    BDT_perf[sample_name][pred_type + 'thresholds_' + roc_type][fold_idx][:, i] = threshold_bdt\n",
    "                    BDT_perf[sample_name][pred_type + 'areas_' + roc_type][fold_idx][i] = float(trapezoid(base_tpr, fpr_bdt))\n",
    "    \n",
    "    for pred_type, dataset_dict in [\n",
    "        ('train_', bdt_train_dict),\n",
    "        ('val_', bdt_val_dict),\n",
    "        ('', bdt_test_dict)\n",
    "    ]:\n",
    "\n",
    "        flat_preds = np.concatenate(BDT_perf[sample_name][f'{pred_type}preds'], axis=0)\n",
    "        flat_truths = np.concatenate([dataset_dict[f\"fold_{fold_idx}\"].get_label() for fold_idx in range(len(dataset_dict))], axis=0)\n",
    "\n",
    "        for i, sample_name_ in enumerate(order):\n",
    "            \n",
    "            if sample_name_ == sample_name:\n",
    "                event_mask = flat_truths > -1\n",
    "                pred_rescale = np.ones_like(event_mask)\n",
    "            else:\n",
    "                event_mask = np.logical_or(flat_truths == j, flat_truths == i)\n",
    "                pred_rescale = flat_preds[:, j][event_mask] + flat_preds[:, i][event_mask]\n",
    "            class_preds = flat_preds[:, j][event_mask] / pred_rescale\n",
    "            class_truths = np.where(flat_truths == j, 1, 0)[event_mask]\n",
    "            \n",
    "            for roc_type in ['density', 'weighted']:\n",
    "\n",
    "                if roc_type == 'weighted':\n",
    "                    if re.search('train', pred_type) is not None:\n",
    "                        roc_weights = np.concatenate([weights_plot_train[f\"fold_{fold_idx}\"] for fold_idx in range(len(weights_plot_train))], axis=0)[event_mask]\n",
    "                    elif re.search('val', pred_type) is not None:\n",
    "                        roc_weights = np.concatenate([weights_plot_val[f\"fold_{fold_idx}\"] for fold_idx in range(len(weights_plot_val))], axis=0)[event_mask]\n",
    "                    else:\n",
    "                        roc_weights = np.concatenate([weights_plot_test[f\"fold_{fold_idx}\"] for fold_idx in range(len(weights_plot_test))], axis=0)[event_mask]\n",
    "                else:\n",
    "                    roc_weights = None\n",
    "\n",
    "                fpr_bdt, tpr_bdt, threshold_bdt = roc_curve(class_truths, class_preds, sample_weight=roc_weights)\n",
    "                fpr_bdt = np.interp(base_tpr, tpr_bdt, fpr_bdt)\n",
    "                threshold_bdt = np.interp(base_tpr, tpr_bdt, threshold_bdt)\n",
    "\n",
    "                BDT_perf[sample_name][pred_type + 'fprs_sum_' + roc_type][:, i] = fpr_bdt\n",
    "                BDT_perf[sample_name][pred_type + 'thresholds_sum_' + roc_type][:, i] = threshold_bdt\n",
    "                BDT_perf[sample_name][pred_type + 'areas_sum_' + roc_type][i] = float(trapezoid(base_tpr, fpr_bdt))\n",
    "    \n",
    "    for key in BDT_perf[sample_name].keys():\n",
    "        if type(BDT_perf[sample_name][key]) is list:\n",
    "            continue\n",
    "        BDT_perf[sample_name][key] = BDT_perf[sample_name][key].tolist()\n",
    "\n",
    "    # with h5py.File(os.path.join(OUTPUT_DIRPATH, CURRENT_TIME+f\"_BDT_ROC_fold{fold_idx}.h5\"), \"w\") as out:\n",
    "    #     out['FPR'] = fpr_bdt\n",
    "    #     out['TPR'] = tpr_bdt\n",
    "    #     out['Thresholds'] = threshold_bdt\n",
    "\n",
    "with open(os.path.join(OUTPUT_DIRPATH, CURRENT_TIME+\"_BDT_perf.json\"), 'w') as f:\n",
    "    json.dump(BDT_perf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_list(list_of_lists):\n",
    "    max_length = np.max([len(list_i) for list_i in list_of_lists])\n",
    "    for list_i in list_of_lists:\n",
    "        while len(list_i) < max_length:\n",
    "            list_i.append(list_i[-1])\n",
    "\n",
    "    return list_of_lists\n",
    "\n",
    "def plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix, format='png'):\n",
    "    plot_prefix = plot_prefix + ('_' if plot_prefix != '' else '')\n",
    "    plot_postfix = plot_postfix + ('_' if plot_postfix != '' else '')\n",
    "    plot_name = plot_prefix + plot_name + plot_postfix + f'.{format}'\n",
    "\n",
    "    plot_filepath = os.path.join(plot_dirpath, plot_name)\n",
    "    return plot_filepath\n",
    "\n",
    "def plot_train_val_losses(\n",
    "    losses_arrs, labels, plot_name, plot_dirpath, \n",
    "    plot_prefix='', plot_postfix='', linestyles=None,\n",
    "    losses_std_arrs=None\n",
    "):\n",
    "    plt.figure(figsize=(9,7))\n",
    "    \n",
    "    if type(losses_arrs[0]) is float:\n",
    "        losses_arrs = [losses_arrs]\n",
    "    if linestyles is None:\n",
    "        linestyles = ['solid'] * len(losses_arrs)\n",
    "    if labels is None:\n",
    "        labels = [i for i in range(len(losses_arrs))]\n",
    "\n",
    "    if losses_std_arrs is not None:\n",
    "        for i in range(len(losses_std_arrs)):\n",
    "            plt.fill_between(\n",
    "                range(len(losses_std_arrs[i])), \n",
    "                losses_arrs[i]+losses_std_arrs[i], losses_arrs[i]-losses_std_arrs[i],\n",
    "                alpha=0.7\n",
    "            )\n",
    "\n",
    "    for i in range(len(losses_arrs)):\n",
    "        plt.plot(\n",
    "            range(len(losses_arrs[i])), \n",
    "            losses_arrs[i], \n",
    "            label=f\"{labels[i]} losses\", linestyle=linestyles[i],\n",
    "            alpha=0.7\n",
    "        )\n",
    "        \n",
    "    plt.legend(bbox_to_anchor=(1, 1))\n",
    "    plt.xlabel('EPOCH')\n",
    "    plt.ylabel('Data Loss')\n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix, format='pdf'), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.close()\n",
    "\n",
    "def plot_rocs(\n",
    "    fprs, tprs, labels, plot_name, plot_dirpath,\n",
    "    plot_prefix='', plot_postfix='', close=True, log=None\n",
    "):\n",
    "    plt.figure(figsize=(9,7))\n",
    "    \n",
    "    for fpr, tpr, label in zip(fprs, tprs, labels):\n",
    "        linestyle = 'solid' if re.search('IN', label) is not None else ('dashed' if re.search('BDT', label) is not None else 'dotted')\n",
    "        plt.plot(fpr, tpr, label=label, linestyle=linestyle)\n",
    "\n",
    "    plt.legend(bbox_to_anchor=(1, 1))\n",
    "    plt.xlabel('Background contamination')\n",
    "    plt.ylabel('Signal efficiency')\n",
    "    if log is not None and re.search('x', log) is not None:\n",
    "        plt.xscale('log')\n",
    "    elif log is not None and re.search('y', log) is not None:\n",
    "        plt.yscale('log')\n",
    "    \n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix, format='pdf'), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    if close:\n",
    "        plt.close()\n",
    "\n",
    "def plot_output_scores(\n",
    "    sigs_and_bkgs, order, plot_name, plot_dirpath,\n",
    "    plot_prefix='', plot_postfix='', bins=50, weights=None, log=False\n",
    "):\n",
    "    plt.figure(figsize=(9,7))\n",
    "\n",
    "    hist_axis = hist.axis.Regular(bins, 0., 1., name='var', growth=False, underflow=False, overflow=False)\n",
    "    hists, labels = [], []\n",
    "    for sample_name in order:\n",
    "        if sample_name not in sigs_and_bkgs:\n",
    "            continue\n",
    "        hists.append(\n",
    "            hist.Hist(hist_axis, storage='weight').fill(\n",
    "                var=sigs_and_bkgs[sample_name], \n",
    "                weight=weights[sample_name] if weights is not None else np.ones_like(sigs_and_bkgs[sample_name])\n",
    "            )\n",
    "        )\n",
    "        labels.append(sample_name)\n",
    "    hep.histplot(\n",
    "        hists,\n",
    "        yerr=(True if weights is not None else False),\n",
    "        alpha=0.7, density=(False if weights is not None else True), histtype='step',\n",
    "        label=labels\n",
    "    )\n",
    "\n",
    "    plt.legend(bbox_to_anchor=(1, 1))\n",
    "    plt.xlabel('Output score')\n",
    "    if log:\n",
    "        plt.yscale('log')\n",
    "    \n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix, format='pdf'), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.close()\n",
    "\n",
    "def plot_s_over_root_b(\n",
    "    sig, bkg, label, plot_name, plot_dirpath,\n",
    "    plot_prefix='', plot_postfix='', bins=50, weights={'sig': None, 'bkg': None},\n",
    "    lines=None, lines_labels=None, line_colors=None\n",
    "):\n",
    "    plt.figure(figsize=(9,7))\n",
    "\n",
    "    hist_axis = hist.axis.Regular(bins, 0., 1., name='var', growth=False, underflow=False, overflow=False)\n",
    "    sig_hist = hist.Hist(hist_axis, storage='weight').fill(var=sig, weight=weights['sig'] if weights['sig'] is not None else np.ones_like(sig))\n",
    "    bkg_hist = hist.Hist(hist_axis, storage='weight').fill(var=bkg, weight=weights['bkg'] if weights['bkg'] is not None else np.ones_like(bkg))\n",
    "    s_over_root_b_points = sig_hist.values().flatten() / np.sqrt(bkg_hist.values().flatten())\n",
    "    plt.plot(\n",
    "        np.arange(0., 1., 1/bins), s_over_root_b_points, \n",
    "        label=f'{label} - s/âb', alpha=0.8\n",
    "    )\n",
    "\n",
    "    if lines is not None:\n",
    "        for i in range(len(lines)):\n",
    "            plt.vlines(\n",
    "                lines[i], 0, np.max(s_over_root_b_points), \n",
    "                label='s/âb'+(' - '+lines_labels[i] if lines_labels is not None else ''), \n",
    "                alpha=0.5, colors=line_colors[i]\n",
    "            )\n",
    "    \n",
    "    plt.legend(bbox_to_anchor=(1, 1))\n",
    "    plt.xlabel('Output score')\n",
    "    plt.ylabel('s/âb')\n",
    "    \n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix, format='pdf'), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_cut_boundaries(sigs, bkgs, weights, bins=50):\n",
    "    hist_list_fold = []\n",
    "    cut_boundaries_fold = []\n",
    "    cut_s_over_root_bs_fold = []\n",
    "    sig_weights_fold = []\n",
    "    bkg_weights_fold = []\n",
    "    if len(np.shape(sigs)) == 1:\n",
    "        sigs, bkgs = [sigs], [bkgs] \n",
    "    for sig, bkg in zip(sigs, bkgs):\n",
    "        hist_axis = hist.axis.Regular(bins, 0., 1., name='var', growth=False, underflow=False, overflow=False)\n",
    "        sig_hist = hist.Hist(hist_axis, storage='weight').fill(var=sig, weight=weights['sig'])\n",
    "        bkg_hist = hist.Hist(hist_axis, storage='weight').fill(var=bkg, weight=weights['bkg'])\n",
    "        hist_list_fold.append({'sig': copy.deepcopy(sig_hist), 'bkg': copy.deepcopy(bkg_hist)})\n",
    "\n",
    "        fold_idx_cuts_bins_inclusive = []\n",
    "        fold_idx_sig_weights = []\n",
    "        fold_idx_bkg_weights = []\n",
    "        fold_idx_prev_s_over_root_b = []\n",
    "        prev_s_over_root_b = 0\n",
    "        for i in range(bins):\n",
    "            s = np.sum(sig_hist.values().flatten()[\n",
    "                (bins-1) - i : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "            ])\n",
    "            sqrt_b = np.sqrt(np.sum(bkg_hist.values().flatten()[\n",
    "                (bins-1) - i : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "            ]))\n",
    "            if prev_s_over_root_b < (s / sqrt_b):\n",
    "                prev_s_over_root_b = s / sqrt_b\n",
    "                continue\n",
    "            else:\n",
    "                fold_idx_sig_weights.append(\n",
    "                    {\n",
    "                        'value': np.sum(sig_hist.values().flatten()[\n",
    "                            (bins) - i : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                        ]),\n",
    "                        'w2': np.sqrt(np.sum(sig_hist.variances().flatten()[\n",
    "                            (bins) - i : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                        ])),\n",
    "                    }\n",
    "                )\n",
    "                fold_idx_bkg_weights.append(\n",
    "                    {\n",
    "                        'value': np.sum(bkg_hist.values().flatten()[\n",
    "                            (bins) - i : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                        ]),\n",
    "                        'w2': np.sqrt(np.sum(bkg_hist.variances().flatten()[\n",
    "                            (bins) - i : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                        ])),\n",
    "                    }\n",
    "                )\n",
    "                fold_idx_cuts_bins_inclusive.append(bins - i)\n",
    "                fold_idx_prev_s_over_root_b.append(prev_s_over_root_b)\n",
    "                prev_s_over_root_b = 0\n",
    "        fold_idx_sig_weights.append(\n",
    "            {\n",
    "                'value': np.sum(sig_hist.values().flatten()[\n",
    "                    0 : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                ]),\n",
    "                'w2': np.sqrt(np.sum(sig_hist.variances().flatten()[\n",
    "                    0 : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                ])),\n",
    "            }\n",
    "        )\n",
    "        fold_idx_bkg_weights.append(\n",
    "            {\n",
    "                'value': np.sum(bkg_hist.values().flatten()[\n",
    "                    0 : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                ]),\n",
    "                'w2': np.sqrt(np.sum(bkg_hist.variances().flatten()[\n",
    "                    0 : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                ])),\n",
    "            }\n",
    "        )\n",
    "        fold_idx_cuts_bins_inclusive.append(0)\n",
    "        fold_idx_prev_s_over_root_b.append(prev_s_over_root_b)\n",
    "        fold_idx_score_cuts = [bin_i / bins for bin_i in fold_idx_cuts_bins_inclusive]\n",
    "        cut_boundaries_fold.append(fold_idx_score_cuts)\n",
    "        cut_s_over_root_bs_fold.append(fold_idx_prev_s_over_root_b)\n",
    "        sig_weights_fold.append(fold_idx_sig_weights)\n",
    "        bkg_weights_fold.append(fold_idx_bkg_weights)\n",
    "    return cut_boundaries_fold, cut_s_over_root_bs_fold, sig_weights_fold, bkg_weights_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"losses\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "if 'BDT_perf' not in globals():\n",
    "    with open(os.path.join(OUTPUT_DIRPATH, CURRENT_TIME+\"_BDT_perf.json\"), 'r') as f:\n",
    "        BDT_perf = json.load(f)\n",
    "\n",
    "if 'evals_result_dict' not in globals():\n",
    "    with open(os.path.join(OUTPUT_DIRPATH, CURRENT_TIME+\"_BDT_eval_result.json\"), 'r') as f:\n",
    "        evals_result_dict = json.load(f)\n",
    "\n",
    "# plot train/val/test losses\n",
    "all_train, all_val, all_test = [], [], []\n",
    "for fold_idx in range(len(evals_result_dict)):\n",
    "    all_train.append(evals_result_dict[f\"fold_{fold_idx}\"]['train']['mlogloss'])\n",
    "    all_val.append(evals_result_dict[f\"fold_{fold_idx}\"]['val']['mlogloss'])\n",
    "    all_test.append(evals_result_dict[f\"fold_{fold_idx}\"]['test']['mlogloss'])\n",
    "\n",
    "plot_train_val_losses(\n",
    "    all_train + all_val, [f'train fold {i}' for i in range(len(all_train))]+[f'val fold {i}' for i in range(len(all_val))],\n",
    "    'train_val_losses_vs_epoch', plot_dirpath, \n",
    "    linestyles=['solid']*len(all_train) + ['dashed']*len(all_val),\n",
    ")\n",
    "plot_train_val_losses(\n",
    "    all_train + all_test, [f'train fold {i}' for i in range(len(all_train))]+[f'test fold {i}' for i in range(len(all_test))],\n",
    "    'train_test_losses_vs_epoch', plot_dirpath,\n",
    "    linestyles=['solid']*len(all_train) + ['dotted']*len(all_test),\n",
    ")\n",
    "avg_train, avg_val, avg_test = np.mean(pad_list(all_train), axis=0), np.mean(pad_list(all_val), axis=0), np.mean(pad_list(all_test), axis=0)\n",
    "std_train, std_val, std_test = np.std(pad_list(all_train), axis=0), np.std(pad_list(all_val), axis=0), np.std(pad_list(all_test), axis=0)\n",
    "plot_train_val_losses(\n",
    "    [avg_train, avg_val, avg_test], ['train avg', 'val avg', 'test avg'],\n",
    "    'train_val_test_avg_vs_epoch', plot_dirpath,\n",
    "    losses_std_arrs=[std_train, std_val, std_test],\n",
    "    linestyles=['solid', 'dashed', 'dotted'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"ROCs\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "if 'BDT_perf' not in globals():\n",
    "    with open(os.path.join(OUTPUT_DIRPATH, CURRENT_TIME+\"_BDT_perf.json\"), 'r') as f:\n",
    "        BDT_perf = json.load(f)\n",
    "\n",
    "base_tpr = np.array(BDT_perf['ggF HH']['base_tpr'])\n",
    "\n",
    "# plot ROCs\n",
    "for j, sample_name in enumerate(order):\n",
    "\n",
    "    for fold_idx in range(len(bdt_train_dict)):\n",
    "\n",
    "        for roc_type in ['density', 'weighted']:\n",
    "\n",
    "            fprs = [np.array(BDT_perf[sample_name][f'fprs_{roc_type}'][fold_idx])[:, i] for i in range(len(order))]\n",
    "            tprs = [base_tpr for _ in range(len(order))]\n",
    "            labels = [\n",
    "                f\"{sample_name} vs. {'all' if i == j else sample_name_}, AUC = {BDT_perf[sample_name][f'areas_{roc_type}'][fold_idx][i]:.4f}\" \n",
    "                for i, sample_name_ in enumerate(order)\n",
    "            ]\n",
    "\n",
    "            plot_rocs(fprs, tprs, labels, f\"BDT_roc_{sample_name}_{roc_type}_testData_fold{fold_idx}\", plot_dirpath)\n",
    "\n",
    "    for roc_type in ['sum_density', 'sum_weighted']:\n",
    "\n",
    "        fprs = [np.array(BDT_perf[sample_name][f'fprs_{roc_type}'])[:, i] for i in range(len(order))]\n",
    "        tprs = [base_tpr for _ in range(len(order))]\n",
    "        labels = [\n",
    "            f\"{sample_name} vs. {'all' if i == j else sample_name_}, AUC = {BDT_perf[sample_name][f'areas_{roc_type}'][i]:.4f}\" \n",
    "            for i, sample_name_ in enumerate(order)\n",
    "        ]\n",
    "\n",
    "        plot_rocs(fprs, tprs, labels, f\"BDT_roc_{sample_name}_{roc_type}_testData_sum\", plot_dirpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"output_scores\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "if 'BDT_perf' not in globals():\n",
    "    with open(os.path.join(OUTPUT_DIRPATH, CURRENT_TIME+\"_BDT_perf.json\"), 'r') as f:\n",
    "        BDT_perf = json.load(f)\n",
    "\n",
    "# plot Output scores\n",
    "for j, sample_name in enumerate(order):\n",
    "\n",
    "    for i, sample_name_ in enumerate(order):\n",
    "\n",
    "        for fold_idx in range(len(bdt_train_dict)):\n",
    "            \n",
    "            sigs_and_bkgs = {\n",
    "                sample_name__: np.array(BDT_perf[sample_name]['preds'][fold_idx])[:, j][bdt_test_dict[f\"fold_{fold_idx}\"].get_label() == k]\n",
    "                for k, sample_name__ in enumerate(order)\n",
    "            }\n",
    "            score_weights = {\n",
    "                sample_name__: weights_plot_test[f\"fold_{fold_idx}\"][bdt_test_dict[f\"fold_{fold_idx}\"].get_label() == k]\n",
    "                for k, sample_name__ in enumerate(order)\n",
    "            }\n",
    "\n",
    "            if sample_name_ != sample_name:\n",
    "                event_j_mask = bdt_test_dict[f\"fold_{fold_idx}\"].get_label() == j\n",
    "                pred_j_rescale = np.array(BDT_perf[sample_name]['preds'][fold_idx])[:, j][event_j_mask] + np.array(BDT_perf[sample_name]['preds'][fold_idx])[:, i][event_j_mask]\n",
    "                event_i_mask = bdt_test_dict[f\"fold_{fold_idx}\"].get_label() == i\n",
    "                pred_i_rescale = np.array(BDT_perf[sample_name]['preds'][fold_idx])[:, j][event_i_mask] + np.array(BDT_perf[sample_name]['preds'][fold_idx])[:, i][event_i_mask]\n",
    "\n",
    "                for sample_name__ in order:\n",
    "                    if sample_name__ == sample_name:\n",
    "                        sigs_and_bkgs[sample_name__] = sigs_and_bkgs[sample_name__] / pred_j_rescale\n",
    "                    elif sample_name__ == sample_name_:\n",
    "                        sigs_and_bkgs[sample_name__] = sigs_and_bkgs[sample_name__] / pred_i_rescale\n",
    "                    else:\n",
    "                        del sigs_and_bkgs[sample_name__]\n",
    "                        del score_weights[sample_name__]\n",
    "\n",
    "            plot_output_scores(\n",
    "                sigs_and_bkgs, order, \n",
    "                f\"BDT_{sample_name}_vs_{sample_name_ if sample_name_ != sample_name else 'all'}_outputScoreWeighted_testData_fold{fold_idx}\", \n",
    "                plot_dirpath, weights=score_weights, log=True\n",
    "            )\n",
    "            plot_output_scores(\n",
    "                sigs_and_bkgs, order, \n",
    "                f\"BDT_{sample_name}_vs_{sample_name_ if sample_name_ != sample_name else 'all'}_outputScoreDensity_testData_fold{fold_idx}\", \n",
    "                plot_dirpath\n",
    "            )\n",
    "\n",
    "        flat_preds = np.concatenate([BDT_perf[sample_name]['preds'][fold_idx] for fold_idx in range(len(bdt_test_dict))], axis=0)\n",
    "        flat_truths = np.concatenate([bdt_test_dict[f\"fold_{fold_idx}\"].get_label() for fold_idx in range(len(bdt_test_dict))], axis=0)\n",
    "        flat_weights = np.concatenate([weights_plot_test[f\"fold_{fold_idx}\"] for fold_idx in range(len(bdt_test_dict))], axis=0)\n",
    "\n",
    "        sigs_and_bkgs = {\n",
    "            sample_name__: flat_preds[:, j][flat_truths == k]\n",
    "            for k, sample_name__ in enumerate(order)\n",
    "        }\n",
    "        score_weights = {\n",
    "            sample_name__: flat_weights[flat_truths == k]\n",
    "            for k, sample_name__ in enumerate(order)\n",
    "        }\n",
    "        \n",
    "        if sample_name_ != sample_name:\n",
    "            event_j_mask = flat_truths == j\n",
    "            pred_j_rescale = (flat_preds[:, j] + flat_preds[:, i])[event_j_mask]\n",
    "            event_i_mask = flat_truths == i\n",
    "            pred_i_rescale = (flat_preds[:, j] + flat_preds[:, i])[event_i_mask]\n",
    "\n",
    "            for sample_name__ in order:\n",
    "                if sample_name__ == sample_name:\n",
    "                    sigs_and_bkgs[sample_name__] = sigs_and_bkgs[sample_name__] / pred_j_rescale\n",
    "                elif sample_name__ == sample_name_:\n",
    "                    sigs_and_bkgs[sample_name__] = sigs_and_bkgs[sample_name__] / pred_i_rescale\n",
    "                else:\n",
    "                    del sigs_and_bkgs[sample_name__]\n",
    "                    del score_weights[sample_name__]\n",
    "        \n",
    "        plot_output_scores(\n",
    "            sigs_and_bkgs, order, \n",
    "            f\"BDT_{sample_name}_vs_{sample_name_ if sample_name_ != sample_name else 'all'}_outputScoreWeighted_testData_sum\", \n",
    "            plot_dirpath, weights=score_weights, log=True\n",
    "        )\n",
    "        plot_output_scores(\n",
    "            sigs_and_bkgs, order, \n",
    "            f\"BDT_{sample_name}_vs_{sample_name_ if sample_name_ != sample_name else 'all'}_outputScoreDensity_testData_sum\", \n",
    "            plot_dirpath\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "============================================================\n",
      "Cat1: 0.98 < ggF HH score â¤ 1.00 AND 120 GeV < m_HH < 130 GeV\n",
      "------------------------------------------------------------\n",
      "Cat1: Num ggF HH = 0.2271\n",
      "------------------------------------------------------------\n",
      "Cat1: Num ttH = 0.0032\n",
      "------------------------------------------------------------\n",
      "Cat1: Num single-H = 0.1231\n",
      "------------------------------------------------------------\n",
      "Cat1: Num non-res = 0.8044\n",
      "------------------------------------------------------------\n",
      "Cat1: S = 0.2271, B = 0.9307, S/âB = 0.2354\n",
      "============================================================\n",
      "============================================================\n",
      "Cat2: 0.92 < ggF HH score â¤ 0.98 AND 120 GeV < m_HH < 130 GeV\n",
      "------------------------------------------------------------\n",
      "Cat2: Num ggF HH = 0.2175\n",
      "------------------------------------------------------------\n",
      "Cat2: Num ttH = 0.0466\n",
      "------------------------------------------------------------\n",
      "Cat2: Num single-H = 0.4629\n",
      "------------------------------------------------------------\n",
      "Cat2: Num non-res = 7.4617\n",
      "------------------------------------------------------------\n",
      "Cat2: S = 0.2175, B = 7.9713, S/âB = 0.0770\n",
      "============================================================\n",
      "============================================================\n",
      "Cat3: 0.78 < ggF HH score â¤ 0.92 AND 120 GeV < m_HH < 130 GeV\n",
      "------------------------------------------------------------\n",
      "Cat3: Num ggF HH = 0.1718\n",
      "------------------------------------------------------------\n",
      "Cat3: Num ttH = 0.1279\n",
      "------------------------------------------------------------\n",
      "Cat3: Num single-H = 1.1001\n",
      "------------------------------------------------------------\n",
      "Cat3: Num non-res = 24.2096\n",
      "------------------------------------------------------------\n",
      "Cat3: S = 0.1718, B = 25.4376, S/âB = 0.0341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3719143/12448675.py:139: RuntimeWarning: invalid value encountered in sqrt\n",
      "  s_over_root_b_points = sig_hist.values().flatten() / np.sqrt(bkg_hist.values().flatten())\n",
      "/tmp/ipykernel_3719143/12448675.py:139: RuntimeWarning: invalid value encountered in sqrt\n",
      "  s_over_root_b_points = sig_hist.values().flatten() / np.sqrt(bkg_hist.values().flatten())\n"
     ]
    }
   ],
   "source": [
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"s_over_rootb\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "if 'BDT_perf' not in globals():\n",
    "    with open(os.path.join(OUTPUT_DIRPATH, CURRENT_TIME+\"_BDT_perf.json\"), 'r') as f:\n",
    "        BDT_perf = json.load(f)\n",
    "\n",
    "# plot s/âb curves\n",
    "for j, sample_name in enumerate(order):\n",
    "\n",
    "    for i, sample_name_ in enumerate(order):\n",
    "\n",
    "        for fold_idx in range(len(bdt_train_dict)):\n",
    "\n",
    "            if sample_name_ == sample_name:\n",
    "                sig_mask = bdt_test_dict[f\"fold_{fold_idx}\"].get_label() == j\n",
    "                bkg_mask = bdt_test_dict[f\"fold_{fold_idx}\"].get_label() != j\n",
    "\n",
    "                sig_rescale = np.ones_like(sig_mask)\n",
    "                bkg_rescale = np.ones_like(bkg_mask)\n",
    "            else:\n",
    "                sig_mask = bdt_test_dict[f\"fold_{fold_idx}\"].get_label() == j\n",
    "                bkg_mask = bdt_test_dict[f\"fold_{fold_idx}\"].get_label() == i\n",
    "\n",
    "                sig_rescale = (\n",
    "                    np.array(BDT_perf[sample_name]['preds'][fold_idx])[:, j] \n",
    "                    + np.array(BDT_perf[sample_name]['preds'][fold_idx])[:, i]\n",
    "                )\n",
    "                bkg_rescale = (\n",
    "                    np.array(BDT_perf[sample_name]['preds'][fold_idx])[:, j] \n",
    "                    + np.array(BDT_perf[sample_name]['preds'][fold_idx])[:, i]\n",
    "                )\n",
    "\n",
    "            sigs_and_bkgs = {\n",
    "                'sig': (np.array(BDT_perf[sample_name]['preds'][fold_idx])[:, j] / sig_rescale)[sig_mask],\n",
    "                'bkg': (np.array(BDT_perf[sample_name]['preds'][fold_idx])[:, j] / bkg_rescale)[bkg_mask]\n",
    "            }\n",
    "            score_weights = {\n",
    "                'sig': weights_plot_test[f\"fold_{fold_idx}\"][sig_mask],\n",
    "                'bkg': weights_plot_test[f\"fold_{fold_idx}\"][bkg_mask]\n",
    "            }\n",
    "\n",
    "            plot_s_over_root_b(\n",
    "                sigs_and_bkgs['sig'], sigs_and_bkgs['bkg'], f\"{sample_name} vs. {sample_name_ if sample_name_ != sample_name else 'all'}\", \n",
    "                f\"BDT_{sample_name}_vs_{sample_name_ if sample_name_ != sample_name else 'all'}_sOverRootb_testData_fold{fold_idx}\", \n",
    "                plot_dirpath, weights=score_weights\n",
    "            )\n",
    "\n",
    "            (\n",
    "                cut_boundaries_fold, cut_s_over_root_bs_fold, sig_weights_fold, bkg_weights_fold\n",
    "            ) = optimize_cut_boundaries(\n",
    "                sigs_and_bkgs['sig'], sigs_and_bkgs['bkg'], score_weights\n",
    "            )\n",
    "\n",
    "            BDT_cut_labels = [\n",
    "                f\"s/âb={cut_s_over_root_bs_fold[0][cut_idx]:.4f}, s={sig_weights_fold[0][cut_idx]['value']:.4f}Â±{sig_weights_fold[0][cut_idx]['w2']:.4f}, b={bkg_weights_fold[0][cut_idx]['value']:.4f}Â±{bkg_weights_fold[0][cut_idx]['w2']:.4f}\" for cut_idx in range(len(cut_s_over_root_bs_fold[0]))\n",
    "            ]\n",
    "            line_labels = BDT_cut_labels[:10]\n",
    "            lines = cut_boundaries_fold[0][:10]\n",
    "            line_colors = cmap_petroff10\n",
    "\n",
    "            plot_s_over_root_b(\n",
    "                sigs_and_bkgs['sig'], sigs_and_bkgs['bkg'], f\"{sample_name} vs. {sample_name_ if sample_name_ != sample_name else 'all'}\", \n",
    "                f\"BDT_{sample_name}_vs_{sample_name_ if sample_name_ != sample_name else 'all'}_sOverRootb_withCuts_testData_fold{fold_idx}_{sample_name}\", plot_dirpath, \n",
    "                weights=score_weights,\n",
    "                lines=lines, lines_labels=line_labels, line_colors=line_colors\n",
    "            )\n",
    "            \n",
    "\n",
    "        flat_preds = np.concatenate([BDT_perf[sample_name]['preds'][fold_idx] for fold_idx in range(len(bdt_test_dict))], axis=0)\n",
    "        flat_truths = np.concatenate([bdt_test_dict[f\"fold_{fold_idx}\"].get_label() for fold_idx in range(len(bdt_test_dict))], axis=0)\n",
    "        flat_weights = np.concatenate([weights_plot_test[f\"fold_{fold_idx}\"] for fold_idx in range(len(bdt_test_dict))], axis=0)\n",
    "\n",
    "        if sample_name_ == sample_name:\n",
    "            sig_mask = flat_truths == j\n",
    "            bkg_mask = flat_truths != j\n",
    "\n",
    "            sig_rescale = np.ones_like(sig_mask)\n",
    "            bkg_rescale = np.ones_like(bkg_mask)\n",
    "        else:\n",
    "            sig_mask = flat_truths == j\n",
    "            bkg_mask = flat_truths == i\n",
    "\n",
    "            sig_rescale = flat_preds[:, j] + flat_preds[:, i]\n",
    "            bkg_rescale = flat_preds[:, j] + flat_preds[:, i]\n",
    "\n",
    "        sigs_and_bkgs = {\n",
    "            'sig': (flat_preds[:, j] / sig_rescale)[sig_mask],\n",
    "            'bkg': (flat_preds[:, j] / bkg_rescale)[bkg_mask]\n",
    "        }\n",
    "        score_weights = {\n",
    "            'sig': flat_weights[sig_mask],\n",
    "            'bkg': flat_weights[bkg_mask]\n",
    "        }\n",
    "\n",
    "        plot_s_over_root_b(\n",
    "            sigs_and_bkgs['sig'], sigs_and_bkgs['bkg'], f\"{sample_name} vs. {sample_name_ if sample_name_ != sample_name else 'all'}\", \n",
    "            f\"BDT_{sample_name}_vs_{sample_name_ if sample_name_ != sample_name else 'all'}_sOverRootb_testData_sum\", \n",
    "            plot_dirpath, weights=score_weights\n",
    "        )\n",
    "\n",
    "        (\n",
    "            cut_boundaries_fold, cut_s_over_root_bs_fold, sig_weights_fold, bkg_weights_fold\n",
    "        ) = optimize_cut_boundaries(\n",
    "            sigs_and_bkgs['sig'], sigs_and_bkgs['bkg'], score_weights\n",
    "        )\n",
    "\n",
    "        BDT_cut_labels = [\n",
    "            f\"s/âb={cut_s_over_root_bs_fold[0][cut_idx]:.4f}, s={sig_weights_fold[0][cut_idx]['value']:.4f}Â±{sig_weights_fold[0][cut_idx]['w2']:.4f}, b={bkg_weights_fold[0][cut_idx]['value']:.4f}Â±{bkg_weights_fold[0][cut_idx]['w2']:.4f}\" for cut_idx in range(len(cut_s_over_root_bs_fold[0]))\n",
    "        ]\n",
    "        line_labels = BDT_cut_labels[:10]\n",
    "        lines = cut_boundaries_fold[0][:10]\n",
    "        line_colors = cmap_petroff10\n",
    "\n",
    "        plot_s_over_root_b(\n",
    "            sigs_and_bkgs['sig'], sigs_and_bkgs['bkg'], f\"{sample_name} vs. {sample_name_ if sample_name_ != sample_name else 'all'}\", \n",
    "            f\"BDT_{sample_name}_vs_{sample_name_ if sample_name_ != sample_name else 'all'}_sOverRootb_withCuts_testData_sum\", plot_dirpath, \n",
    "            weights=score_weights,\n",
    "            lines=lines, lines_labels=line_labels, line_colors=line_colors\n",
    "        )\n",
    "\n",
    "        if j == 0 and i == 0:\n",
    "            flat_mass = np.concatenate([data_test_aux_dict[f\"fold_{fold_idx}\"]['mass'] for fold_idx in range(len(data_test_aux_dict))], axis=0)\n",
    "            cat_lines = [1.0] + lines[:3]\n",
    "            cat_num_samples = {}\n",
    "            for k, cat in enumerate(['Cat1', 'Cat2', 'Cat3']):\n",
    "                cat_num_samples[cat] = {}\n",
    "                print('='*60)\n",
    "                print('='*60)\n",
    "                print(f\"{cat}: {cat_lines[k+1]:.2f} < ggF HH score â¤ {cat_lines[k]:.2f} AND 120 GeV < m_HH < 130 GeV\")\n",
    "                print('-'*60)\n",
    "                for m, sample_name in enumerate(order):\n",
    "                    cat_num_samples[cat][sample_name] = np.sum(\n",
    "                        flat_weights[\n",
    "                            np.logical_and(  # event passes conditions and is the right type (i.e. sample)\n",
    "                                np.logical_and(  # event passes category and mass conditions\n",
    "                                    np.logical_and(  # prediction is within category bounds\n",
    "                                        flat_preds[:, 0] <= cat_lines[k],\n",
    "                                        flat_preds[:, 0] > cat_lines[k+1]\n",
    "                                    ),\n",
    "                                    np.logical_and(  # diphoton mass is within 120-130 window\n",
    "                                        flat_mass < 130,\n",
    "                                        flat_mass > 120\n",
    "                                    ),\n",
    "                                ),\n",
    "                                flat_truths == m\n",
    "                            )\n",
    "                        ]\n",
    "                    )\n",
    "                    print(f\"{cat}: Num {sample_name} = {cat_num_samples[cat][sample_name]:.4f}\")\n",
    "                    print('-'*60)\n",
    "\n",
    "                print(f\"{cat}: S = {cat_num_samples[cat][order[0]]:.4f}, B = {np.sum([cat_num_samples[cat][order[v]] for v in range(1, len(order))]):.4f}, S/âB = {(cat_num_samples[cat][order[0]] / np.sqrt(np.sum([cat_num_samples[cat][order[v]] for v in range(1, len(order))]))):.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"variable_importance\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "for fold_idx in range(len(bdt_train_dict)):\n",
    "    booster = xgb.Booster(param)\n",
    "    booster.load_model(os.path.join(OUTPUT_DIRPATH, f'{CURRENT_TIME}_BDT_fold{fold_idx}.model'))\n",
    "    \n",
    "    xgb.plot_importance(booster)\n",
    "    plt.savefig(\n",
    "        plot_filepath(f'xgb_importance_fold{fold_idx}', plot_dirpath, '', ''),\n",
    "    )\n",
    "    plt.savefig(\n",
    "        plot_filepath(f'xgb_importance_fold{fold_idx}', plot_dirpath, '', '', format='pdf'),\n",
    "    )\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MC_NAMES_PRETTY = {\n",
    "#     \"GGJets\": r\"$\\gamma\\gamma+3j$\",\n",
    "#     \"GJetPt20To40\": r\"$\\gamma+j$, 20<$p_T$<40GeV\",\n",
    "#     \"GJetPt40\": r\"$\\gamma+j$, 40GeV<$p_T$\",\n",
    "#     \"GluGluHToGG\": r\"ggF $H\\rightarrow \\gamma\\gamma$\",\n",
    "#     \"VBFHToGG\": r\"VBF $H\\rightarrow \\gamma\\gamma$\",\n",
    "#     \"VHToGG\": r\"V$H\\rightarrow\\gamma\\gamma$\",\n",
    "#     \"ttHToGG\": r\"$t\\bar{t}H\\rightarrow\\gamma\\gamma$\",\n",
    "#     \"GluGluToHH\": r\"ggF $HH\\rightarrow bb\\gamma\\gamma$\",\n",
    "#     \"signal\": r\"ggF $HH\\rightarrow bb\\gamma\\gamma$ + VBF $HH\\rightarrow bb\\gamma\\gamma$\"\n",
    "#     # \"VBFHHto2B2G_CV_1_C2V_1_C3_1\": r\"VBF $HH\\rightarrow bb\\gamma\\gamma$\",\n",
    "#     # Need to fill in pretty print for BSM samples #\n",
    "# }\n",
    "# LUMINOSITIES = {\n",
    "#     '2022preEE': 7.9804, \n",
    "#     '2022postEE': 26.6717,\n",
    "#     # Need to fill in lumis for other eras #\n",
    "# }\n",
    "# LUMINOSITIES['total_lumi'] = sum(LUMINOSITIES.values())\n",
    "\n",
    "# # Dictionary of variables\n",
    "# VARIABLES = {\n",
    "#     # key: hist.axis axes for plotting #\n",
    "#     # MET variables\n",
    "#     'puppiMET_sumEt': hist.axis.Regular(40, 150., 2000, name='var', label=r'puppiMET $\\Sigma E_T$ [GeV]', growth=False, underflow=False, overflow=False), \n",
    "#     'puppiMET_pt': hist.axis.Regular(40, 20., 250, name='var', label=r'puppiMET $p_T$ [GeV]', growth=False, underflow=False, overflow=False), \n",
    "#     'puppiMET_phi': hist.axis.Regular(20,-3.2, 3.2, name='var', label=r'puppiMET $\\phi$', growth=False, underflow=False, overflow=False), \n",
    "#     # jet-MET variables\n",
    "#     'DeltaPhi_j1MET': hist.axis.Regular(20,-3.2, 3.2, name='var', label=r'$\\Delta\\phi (j_1,E_T^{miss})$', growth=False, underflow=False, overflow=False), \n",
    "#     'DeltaPhi_j2MET': hist.axis.Regular(20, -3.2, 3.2, name='var', label=r'$\\Delta\\phi (j_2,E_T^{miss})$', growth=False, underflow=False, overflow=False), \n",
    "#     # jet-photon variables\n",
    "#     'DeltaR_jg_min': hist.axis.Regular(30, 0, 5, name='var', label=r'min$(\\Delta R(jet, \\gamma))$', growth=False, underflow=False, overflow=False), \n",
    "#     # jet variables\n",
    "#     # 'jet1_pt': hist.axis.Regular(40, 20., 250, name='var', label=r'lead jet $p_T$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "#     # 'jet2_pt': hist.axis.Regular(40, 20., 250, name='var', label=r'sublead jet $p_T$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "#     'lead_bjet_pt': hist.axis.Regular(40, 20., 250, name='var', label=r'lead bjet $p_T$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "#     'lead_bjet_eta': hist.axis.Regular(20, -5., 5., name='var', label=r'lead bjet $\\eta$', growth=False, underflow=False, overflow=False),\n",
    "#     'lead_bjet_phi': hist.axis.Regular(20, -3.2, 3.2, name='var', label=r'lead bjet $\\phi$', growth=False, underflow=False, overflow=False),\n",
    "#     'sublead_bjet_pt': hist.axis.Regular(40, 20., 250, name='var', label=r'lead bjet $p_T$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "#     'sublead_bjet_eta': hist.axis.Regular(20, -5., 5., name='var', label=r'lead bjet $\\eta$', growth=False, underflow=False, overflow=False),\n",
    "#     'sublead_bjet_phi': hist.axis.Regular(20, -3.2, 3.2, name='var', label=r'lead bjet $\\phi$', growth=False, underflow=False, overflow=False),\n",
    "#     'n_jets': hist.axis.Integer(0, 10, name='var', label=r'$n_{jets}$', growth=False, underflow=False, overflow=False), \n",
    "#     'chi_t0': hist.axis.Regular(40, 0., 150, name='var', label=r'$\\chi_{t0}^2$', growth=False, underflow=False, overflow=False), \n",
    "#     'chi_t1': hist.axis.Regular(30, 0., 500, name='var', label=r'$\\chi_{t1}^2$', growth=False, underflow=False, overflow=False), \n",
    "#     # lepton variables\n",
    "#     'n_leptons': hist.axis.Integer(0, 10, name='var', label=r'$n_{leptons}$', growth=False, underflow=False, overflow=False),\n",
    "#     'lepton1_pt': hist.axis.Regular(40, 0., 200., name='var', label=r'lead lepton $p_T$ [GeV]', growth=False, underflow=False, overflow=False), \n",
    "#     'lepton2_pt': hist.axis.Regular(40, 0., 200., name='var', label=r'sublead lepton $p_T$ [GeV]', growth=False, underflow=False, overflow=False), \n",
    "#     'lepton1_eta': hist.axis.Regular(30, -5., 5., name='var', label=r'lead lepton $\\eta$', growth=False, underflow=False, overflow=False), \n",
    "#     'lepton2_eta': hist.axis.Regular(30, -5., 5., name='var', label=r'sublead lepton $\\eta$', growth=False, underflow=False, overflow=False),\n",
    "#     'lepton1_phi': hist.axis.Regular(20, -3.2, 3.2, name='var', label=r'lead lepton $\\phi$', growth=False, underflow=False, overflow=False), \n",
    "#     'lepton2_phi': hist.axis.Regular(20, -3.2, 3.2, name='var', label=r'sublead lepton $\\phi$', growth=False, underflow=False, overflow=False),\n",
    "#     # diphoton variables\n",
    "#     'pt': hist.axis.Regular(40, 20., 2000, name='var', label=r' $\\gamma\\gamma p_{T}$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "#     'eta': hist.axis.Regular(20, -5., 5., name='var', label=r'$\\gamma\\gamma \\eta$', growth=False, underflow=False, overflow=False), \n",
    "#     'phi': hist.axis.Regular(20, -3.2, 3.2, name='var', label=r'$\\gamma \\gamma \\phi$', growth=False, underflow=False, overflow=False),\n",
    "#     # angular (cos) variables\n",
    "#     'abs_CosThetaStar_CS': hist.axis.Regular(20, 0, 1, name='var', label=r'|cos$(\\theta_{CS})$|', growth=False, underflow=False, overflow=False), \n",
    "#     'abs_CosThetaStar_jj': hist.axis.Regular(20, 0, 1, name='var', label=r'|cos$(\\theta_{jj})$|', growth=False, underflow=False, overflow=False),\n",
    "#     'CosThetaStar_CS': hist.axis.Regular(20, -1, 1, name='var', label=r'cos$(\\theta_{CS})$', growth=False, underflow=False, overflow=False), \n",
    "#     'CosThetaStar_jj': hist.axis.Regular(20, -1, 1, name='var', label=r'cos$(\\theta_{jj})$', growth=False, underflow=False, overflow=False), \n",
    "#     # jet-lepton variables\n",
    "#     'leadBjet_leadLepton': hist.axis.Regular(30, 0, 5, name='var', label=r'$\\Delta R(bjet_{lead}, l_{lead})$', growth=False, underflow=False, overflow=False), \n",
    "#     'leadBjet_subleadLepton': hist.axis.Regular(30, 0, 5, name='var', label=r'$\\Delta R(bjet_{lead}, l_{sublead})$', growth=False, underflow=False, overflow=False), \n",
    "#     'subleadBjet_leadLepton': hist.axis.Regular(30, 0, 5, name='var', label=r'$\\Delta R(bjet_{sublead}, l_{lead})$', growth=False, underflow=False, overflow=False), \n",
    "#     'subleadBjet_subleadLepton': hist.axis.Regular(30, 0, 5, name='var', label=r'$\\Delta R(bjet_{sublead}, l_{sublead})$', growth=False, underflow=False, overflow=False),\n",
    "#     # dijet variables (must be blinded on data)\n",
    "#     'dijet_mass': hist.axis.Regular(50, 25., 180., name='var', label=r'$M_{jj}$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "#     # diphoton variables (must be blinded on data)\n",
    "#     'mass': hist.axis.Regular(50, 25., 180., name='var', label=r'$M_{\\gamma\\gamma}$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "# }\n",
    "# # Dictionary of variables to do MC/Data comparison\n",
    "# VARIABLES_STD = {\n",
    "#     # key: hist.axis axes for plotting #\n",
    "#     # MET variables\n",
    "#     'puppiMET_sumEt': hist.axis.Regular(40, -4., 4., name='var', label=r'puppiMET ln($\\Sigma E_T$) [GeV]', growth=False, underflow=False, overflow=False), \n",
    "#     'puppiMET_pt': hist.axis.Regular(40, -4., 4., name='var', label=r'puppiMET ln($p_T$) [GeV]', growth=False, underflow=False, overflow=False), \n",
    "#     'puppiMET_phi': hist.axis.Regular(40, -4., 4., name='var', label=r'puppiMET $\\phi$', growth=False, underflow=False, overflow=False), \n",
    "#     # jet-MET variables\n",
    "#     'DeltaPhi_j1MET': hist.axis.Regular(40, -4., 4., name='var', label=r'$\\Delta\\phi (j_1,E_T^{miss})$', growth=False, underflow=False, overflow=False), \n",
    "#     'DeltaPhi_j2MET': hist.axis.Regular(40, -4., 4., name='var', label=r'$\\Delta\\phi (j_2,E_T^{miss})$', growth=False, underflow=False, overflow=False), \n",
    "#     # jet-photon variables\n",
    "#     'DeltaR_jg_min': hist.axis.Regular(40, -4., 4., name='var', label=r'min$(\\Delta R(jet, \\gamma))$', growth=False, underflow=False, overflow=False), \n",
    "#     # jet variables\n",
    "#     'lead_bjet_pt': hist.axis.Regular(40, -4., 4., name='var', label=r'lead bjet ln($p_T$) [GeV]', growth=False, underflow=False, overflow=False), \n",
    "#     'sublead_bjet_pt': hist.axis.Regular(40, -4., 4., name='var', label=r'sublead bjet ln($p_T$) [GeV]', growth=False, underflow=False, overflow=False), \n",
    "#     'lead_bjet_eta': hist.axis.Regular(40, -4., 4., name='var', label=r'lead bjet $\\eta$', growth=False, underflow=False, overflow=False), \n",
    "#     'sublead_bjet_eta': hist.axis.Regular(40, -4., 4., name='var', label=r'sublead bjet $\\eta$', growth=False, underflow=False, overflow=False),\n",
    "#     'lead_bjet_phi': hist.axis.Regular(40, -4., 4., name='var', label=r'lead bjet $\\phi$', growth=False, underflow=False, overflow=False), \n",
    "#     'sublead_bjet_phi': hist.axis.Regular(40, -4., 4., name='var', label=r'sublead bjet $\\phi$', growth=False, underflow=False, overflow=False),\n",
    "#     'n_jets': hist.axis.Regular(12, -4., 4., name='var', label=r'$n_{jets}$', growth=False, underflow=False, overflow=False), \n",
    "#     'chi_t0': hist.axis.Regular(40, -4., 10., name='var', label=r'ln($\\chi_{t0}^2$)', growth=False, underflow=False, overflow=False), \n",
    "#     'chi_t1': hist.axis.Regular(40, -4., 10., name='var', label=r'ln($\\chi_{t1}^2$)', growth=False, underflow=False, overflow=False), \n",
    "#     # lepton variables\n",
    "#     'n_leptons': hist.axis.Regular(12, -4., 4., name='var', label=r'$n_{leptons}$', growth=False, underflow=False, overflow=False),\n",
    "#     'lepton1_pt': hist.axis.Regular(40, -4., 4., name='var', label=r'lead lepton ln($p_T$) [GeV]', growth=False, underflow=False, overflow=False), \n",
    "#     'lepton2_pt': hist.axis.Regular(40, -4., 4., name='var', label=r'sublead lepton ln($p_T$) [GeV]', growth=False, underflow=False, overflow=False), \n",
    "#     'lepton1_eta': hist.axis.Regular(40, -4., 4., name='var', label=r'lead lepton $\\eta$', growth=False, underflow=False, overflow=False), \n",
    "#     'lepton2_eta': hist.axis.Regular(40, -4., 4., name='var', label=r'sublead lepton $\\eta$', growth=False, underflow=False, overflow=False),\n",
    "#     'lepton1_phi': hist.axis.Regular(40, -4., 4., name='var', label=r'lead lepton $\\phi$', growth=False, underflow=False, overflow=False), \n",
    "#     'lepton2_phi': hist.axis.Regular(40, -4., 4., name='var', label=r'sublead lepton $\\phi$', growth=False, underflow=False, overflow=False),\n",
    "#     # diphoton variables\n",
    "#     'pt': hist.axis.Regular(40, -4., 4., name='var', label=r' $\\gamma\\gamma$ ln($p_{T}$) [GeV]', growth=False, underflow=False, overflow=False),\n",
    "#     'eta': hist.axis.Regular(40, -4., 4., name='var', label=r'$\\gamma\\gamma \\eta$', growth=False, underflow=False, overflow=False), \n",
    "#     'phi': hist.axis.Regular(40, -4., 4., name='var', label=r'$\\gamma \\gamma \\phi$', growth=False, underflow=False, overflow=False),\n",
    "#     # angular (cos) variables\n",
    "#     'abs_CosThetaStar_CS': hist.axis.Regular(40, -4., 4., name='var', label=r'|cos$(\\theta_{CS})$|', growth=False, underflow=False, overflow=False), \n",
    "#     'abs_CosThetaStar_jj': hist.axis.Regular(40, -4., 4., name='var', label=r'|cos$(\\theta_{jj})$|', growth=False, underflow=False, overflow=False), \n",
    "#     'CosThetaStar_CS': hist.axis.Regular(40, -1., 1., name='var', label=r'cos$(\\theta_{CS})$', growth=False, underflow=False, overflow=False), \n",
    "#     'CosThetaStar_jj': hist.axis.Regular(40, -1., 1., name='var', label=r'cos$(\\theta_{jj})$', growth=False, underflow=False, overflow=False), \n",
    "#     # jet-lepton variables\n",
    "#     'leadBjet_leadLepton': hist.axis.Regular(40, -4., 4. if re.search('vars_to_RNN', VARS) is not None else 10., name='var', label=r'$\\Delta R(bjet_{lead}, l_{lead})$', growth=False, underflow=False, overflow=False), \n",
    "#     'leadBjet_subleadLepton': hist.axis.Regular(40, -4., 4. if re.search('vars_to_RNN', VARS) is not None else 10., name='var', label=r'$\\Delta R(bjet_{lead}, l_{sublead})$', growth=False, underflow=False, overflow=False), \n",
    "#     'subleadBjet_leadLepton': hist.axis.Regular(40, -4., 4. if re.search('vars_to_RNN', VARS) is not None else 10., name='var', label=r'$\\Delta R(bjet_{sublead}, l_{lead})$', growth=False, underflow=False, overflow=False), \n",
    "#     'subleadBjet_subleadLepton': hist.axis.Regular(40, -4., 4. if re.search('vars_to_RNN', VARS) is not None else 10., name='var', label=r'$\\Delta R(bjet_{sublead}, l_{sublead})$', growth=False, underflow=False, overflow=False),\n",
    "#     # dijet variables (must be blinded on data)\n",
    "#     'dijet_mass': hist.axis.Regular(40, -4., 4., name='var', label=r'ln($M_{jj}$) [GeV]', growth=False, underflow=False, overflow=False),\n",
    "#     # diphoton variables (must be blinded on data)\n",
    "#     'mass': hist.axis.Regular(40, -4., 4., name='var', label=r'$M_{\\gamma\\gamma}$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "# }\n",
    "\n",
    "# def post_std_np_arrays(\n",
    "#         data, data_test, fold, var_name, train_index=None, val_index=None\n",
    "# ):\n",
    "#     sig_mask = label_dict[f'fold_{fold}'] == 1\n",
    "#     sig_test_mask = label_test_dict[f'fold_{fold}'] == 1\n",
    "#     bkg_mask = label_dict[f'fold_{fold}'] == 0\n",
    "#     bkg_test_mask = label_test_dict[f'fold_{fold}'] == 0\n",
    "#     if train_index is not None and val_index is not None:\n",
    "#         sig_train_mask = sig_mask & train_index \n",
    "#         sig_val_mask = sig_mask & val_index\n",
    "#         bkg_train_mask = bkg_mask & train_index\n",
    "#         bkg_val_mask = bkg_mask & val_index\n",
    "#         if var_name in (high_level_fields_dict[f'fold_{fold}'] - set(input_hlf_vars_dict[f'fold_{fold}'])):\n",
    "#             sig_train_np = data[data_list_index_map(var_name, data, sig_train_mask, n_pFields=N_PARTICLE_FIELDS)]\n",
    "#             sig_val_np = data[data_list_index_map(var_name, data, sig_val_mask, n_pFields=N_PARTICLE_FIELDS)]\n",
    "#             sig_test_np = data_test[data_list_index_map(var_name, data_test, sig_test_mask, n_pFields=N_PARTICLE_FIELDS)]\n",
    "#             bkg_train_np = data[data_list_index_map(var_name, data, bkg_train_mask, n_pFields=N_PARTICLE_FIELDS)]\n",
    "#             bkg_val_np = data[data_list_index_map(var_name, data, bkg_val_mask, n_pFields=N_PARTICLE_FIELDS)]\n",
    "#             bkg_test_np = data_test[data_list_index_map(var_name, data_test, bkg_test_mask, n_pFields=N_PARTICLE_FIELDS)]\n",
    "#         else:\n",
    "#             index2 = hlf_vars_columns_dict[f'fold_{fold}'][var_name]\n",
    "#             sig_train_np = data[sig_train_mask, index2]\n",
    "#             sig_val_np = data[sig_val_mask, index2]\n",
    "#             sig_test_np = data_test[sig_test_mask, index2]\n",
    "#             bkg_train_np = data[bkg_train_mask, index2]\n",
    "#             bkg_val_np = data[bkg_val_mask, index2]\n",
    "#             bkg_test_np = data_test[bkg_test_mask, index2]\n",
    "\n",
    "#         return (\n",
    "#             sig_train_np, sig_val_np, sig_test_np, \n",
    "#             bkg_train_np, bkg_val_np, bkg_test_np\n",
    "#         )\n",
    "#     elif train_index is None and val_index is None:\n",
    "#         if var_name in (high_level_fields_dict[f'fold_{fold}'] - set(input_hlf_vars_dict[f'fold_{fold}'])):\n",
    "#             # index2, index3 = index_map[var_name]\n",
    "#             sig_train_np = data[data_list_index_map(var_name, data, sig_mask, n_pFields=N_PARTICLE_FIELDS)]\n",
    "#             sig_test_np = data_test[data_list_index_map(var_name, data_test, sig_test_mask, n_pFields=N_PARTICLE_FIELDS)]\n",
    "#             bkg_train_np = data[data_list_index_map(var_name, data, bkg_mask, n_pFields=N_PARTICLE_FIELDS)]\n",
    "#             bkg_test_np = data_test[data_list_index_map(var_name, data_test, bkg_test_mask, n_pFields=N_PARTICLE_FIELDS)]\n",
    "#         else:\n",
    "#             index2 = hlf_vars_columns_dict[f'fold_{fold}'][var_name]\n",
    "#             sig_train_np = data[sig_mask, index2]\n",
    "#             sig_test_np = data_test[sig_test_mask, index2]\n",
    "#             bkg_train_np = data[bkg_mask, index2]\n",
    "#             bkg_test_np = data_test[bkg_test_mask, index2]\n",
    "#         return (\n",
    "#             copy.deepcopy(sig_train_np), copy.deepcopy(sig_test_np), \n",
    "#             copy.deepcopy(bkg_train_np), copy.deepcopy(bkg_test_np)\n",
    "#         )\n",
    "#     else:\n",
    "#         raise Exception(\"Either both train_index and val_index must be 'None', or both should not be 'None'. You cannot mix and match.\")\n",
    "\n",
    "# def aux_np_arrays(var_name, score_cut, IN_full_eval_dict, fold):\n",
    "#     sig_train_mask = (label_dict[f'fold_{fold}'] == 1) & (\n",
    "#         np.exp(IN_full_eval_dict['train']['all_preds'][fold])[:, 1] > score_cut\n",
    "#     )\n",
    "#     sig_test_mask = (label_test_dict[f'fold_{fold}'] == 1) & (\n",
    "#         np.exp(IN_full_eval_dict['test']['all_preds'][fold])[:, 1] > score_cut\n",
    "#     )\n",
    "#     bkg_train_mask = (label_dict[f'fold_{fold}'] == 0) & (\n",
    "#         np.exp(IN_full_eval_dict['train']['all_preds'][fold])[:, 1] > score_cut\n",
    "#     )\n",
    "#     bkg_test_mask = (label_test_dict[f'fold_{fold}'] == 0) & (\n",
    "#         np.exp(IN_full_eval_dict['test']['all_preds'][fold])[:, 1] > score_cut\n",
    "#     )\n",
    "\n",
    "#     sig_train_np = data_aux_dict[f'fold_{fold}'].loc[sig_train_mask, var_name].to_numpy()\n",
    "#     sig_test_np = data_test_aux_dict[f'fold_{fold}'].loc[sig_test_mask, var_name].to_numpy()\n",
    "#     bkg_train_np = data_aux_dict[f'fold_{fold}'].loc[bkg_train_mask, var_name].to_numpy()\n",
    "#     bkg_test_np = data_test_aux_dict[f'fold_{fold}'].loc[bkg_test_mask, var_name].to_numpy()\n",
    "\n",
    "#     return (\n",
    "#         copy.deepcopy(sig_train_np), copy.deepcopy(sig_test_np), \n",
    "#         copy.deepcopy(bkg_train_np), copy.deepcopy(bkg_test_np)\n",
    "#     )\n",
    "\n",
    "# def make_input_plot(\n",
    "#     output_dir, var_name, hist_list, fold_idx=None, labels=None, density=True, \n",
    "#     plot_prefix='', plot_postfix='', alpha=0.8, linestyle=True\n",
    "# ):\n",
    "#     fig, ax = plt.subplots()\n",
    "#     if linestyle:\n",
    "#         if fold_idx is not None:\n",
    "#             linestyles = [\"solid\", \"dashed\", \"dotted\", \"solid\", \"dashed\", \"dotted\"]\n",
    "#         else:\n",
    "#             linestyles = [\"solid\", \"dotted\", \"solid\", \"dotted\"]\n",
    "#         linestyles = linestyles * ((len(hist_list) // len(linestyles)) + 1)\n",
    "#         linestyles = linestyles[:len(hist_list)]\n",
    "#     else:\n",
    "#         linestyles = None\n",
    "#     hep.histplot(\n",
    "#         hist_list, ax=ax, linewidth=3, histtype=\"step\", yerr=True, density=density,\n",
    "#         linestyle=linestyles, label=labels, alpha=alpha\n",
    "#     )\n",
    "#     # Plotting niceties #\n",
    "#     hep.cms.lumitext(f\"{LUMINOSITIES['total_lumi']:.2f}\" + r\"fb$^{-1}$ (13.6 TeV)\", ax=ax)\n",
    "#     hep.cms.text(\"Work in Progress\", ax=ax)\n",
    "#     # Plot legend properly\n",
    "#     ax.legend(bbox_to_anchor=(1, 0.5))\n",
    "#     # Make angular and chi^2 plots linear, otherwise log\n",
    "#     if re.match('chi_t', var_name) is None and re.match('DeltaPhi', var_name) is None and re.match('mass', var_name) is None:\n",
    "#         ax.set_yscale('log')\n",
    "#     else:\n",
    "#         ax.set_yscale('linear')\n",
    "#     ax.set_yscale('linear')\n",
    "#     # Save out the plot\n",
    "#     if fold_idx is not None:\n",
    "#         output_dir_ = os.path.join(output_dir, \"fold\")\n",
    "#         if not os.path.exists(output_dir_):\n",
    "#             os.makedirs(output_dir_)\n",
    "#         plt.savefig(f'{output_dir_}/{plot_prefix}1dhist_{var_name}{plot_postfix}_fold{fold_idx}.pdf', bbox_inches='tight')\n",
    "#         plt.savefig(f'{output_dir_}/{plot_prefix}1dhist_{var_name}{plot_postfix}_fold{fold_idx}.png', bbox_inches='tight')\n",
    "#     else:\n",
    "#         plt.savefig(f'{output_dir}/{plot_prefix}1dhist_{var_name}{plot_postfix}.pdf', bbox_inches='tight')\n",
    "#         plt.savefig(f'{output_dir}/{plot_prefix}1dhist_{var_name}{plot_postfix}.png', bbox_inches='tight')\n",
    "#     plt.close()\n",
    "\n",
    "# def plot_input_vars_after_score_cut(\n",
    "#     IN_info, score_cut, destdir, fold, plot_prefix, plot_postfix='', method='std', \n",
    "#     weights={'sig': None, 'bkg': None}, all_sig=False, all_bkg=False,\n",
    "#     mask=None\n",
    "# ):\n",
    "#     if method == 'std':\n",
    "#         if mask is None:\n",
    "#             mask = np.ones(np.shape(IN_info['mean_pred'])[0], dtype=bool)\n",
    "#         sig_mask = np.exp(\n",
    "#             IN_info['mean_pred']\n",
    "#         )[\n",
    "#             np.logical_and(\n",
    "#                 np.array(IN_info['mean_label']) == 1, mask\n",
    "#             ),1\n",
    "#         ] > score_cut\n",
    "#         bkg_mask = np.exp(\n",
    "#             IN_info['mean_pred']\n",
    "#         )[\n",
    "#             np.logical_and(\n",
    "#                 np.array(IN_info['mean_label']) == 0, mask\n",
    "#             ),1\n",
    "#         ] > score_cut\n",
    "\n",
    "#         for var_name in high_level_fields_dict[f'fold_{fold}']:\n",
    "#             if var_name in {'event', 'puppiMET_eta'}:\n",
    "#                 continue\n",
    "#             sig_var = data_test_df_dict[f'fold_{fold}'].loc[(label_test_dict[f'fold_{fold}']==1) & mask, var_name]\n",
    "#             sig_hist = hist.Hist(VARIABLES[var_name]).fill(\n",
    "#                 var=sig_var.loc[sig_mask], \n",
    "#                 weight=weights['sig'][sig_mask] if weights['sig'] is not None else np.ones(np.sum(sig_mask))\n",
    "#             )\n",
    "#             bkg_var = data_test_df_dict[f'fold_{fold}'].loc[(label_test_dict[f'fold_{fold}']==0) & mask, var_name]\n",
    "#             bkg_hist = hist.Hist(VARIABLES[var_name]).fill(\n",
    "#                 var=bkg_var.loc[bkg_mask], \n",
    "#                 weight=weights['bkg'][bkg_mask] if weights['bkg'] is not None else np.ones(np.sum(bkg_mask))\n",
    "#             )\n",
    "#             make_input_plot(\n",
    "#                 destdir, var_name, [sig_hist, bkg_hist], fold, plot_prefix=plot_prefix, \n",
    "#                 plot_postfix=plot_postfix+f'_ttHscore{score_cut}', labels=['HH signal', 'ttH background'], density=False if weights['sig'] is not None else True\n",
    "#             )\n",
    "#     elif method == 'round_robin':\n",
    "#         if mask is None:\n",
    "#             mask = np.ones(np.shape(IN_info['all_preds'][fold])[0], dtype=bool)\n",
    "        \n",
    "#         for var_name in high_level_fields_dict[f'fold_{fold}']:\n",
    "#             if var_name in {'event', 'puppiMET_eta'}:\n",
    "#                 continue\n",
    "#             sig_var = data_test_df_dict[f'fold_{fold}'].loc[(label_test_dict[f'fold_{fold}']==1) & mask, var_name]\n",
    "#             bkg_var = data_test_df_dict[f'fold_{fold}'].loc[(label_test_dict[f'fold_{fold}']==0) & mask, var_name]\n",
    "#             sig_masks, bkg_masks = [], []\n",
    "#             hists, labels = [], []\n",
    "#             for cut in score_cut if score_cut is list else [score_cut]:\n",
    "#                 sig_masks.append(np.exp(\n",
    "#                     IN_info['all_preds'][fold]\n",
    "#                 )[\n",
    "#                     np.logical_and(\n",
    "#                         np.array(IN_info['all_labels'][fold]) == 1, mask\n",
    "#                     ),1\n",
    "#                 ] > cut)\n",
    "#                 bkg_masks.append(np.exp(\n",
    "#                     IN_info['all_preds'][fold]\n",
    "#                 )[\n",
    "#                     np.logical_and(\n",
    "#                         np.array(IN_info['all_labels'][fold]) == 0, mask\n",
    "#                     ),1\n",
    "#                 ] > cut)\n",
    "                \n",
    "#                 hists.append(hist.Hist(VARIABLES[var_name]).fill(\n",
    "#                     var=sig_var.loc[sig_masks[-1]], \n",
    "#                     weight=weights['sig'][sig_masks[-1]] if weights['sig'] is not None else np.ones(np.sum(sig_masks[-1]))\n",
    "#                 ))\n",
    "#                 hists.append(hist.Hist(VARIABLES[var_name]).fill(\n",
    "#                     var=bkg_var.loc[bkg_masks[-1]], \n",
    "#                     weight=weights['bkg'][bkg_masks[-1]] if weights['bkg'] is not None else np.ones(np.sum(bkg_masks[-1]))\n",
    "#                 ))\n",
    "#                 labels.extend([f'HH signal, ttH-score > {cut}', f'ttH background, ttH-score > {cut}'])\n",
    "#             make_input_plot(\n",
    "#                 destdir, var_name, hists, fold, plot_prefix=plot_prefix, \n",
    "#                 plot_postfix=plot_postfix+f'_ttHscore_scan', labels=labels, density=False if weights['sig'] is not None else True\n",
    "#             )\n",
    "#     elif method == 'arr':\n",
    "#         if mask is None:\n",
    "#             mask = np.ones(np.shape(IN_info['mean_pred'])[0], dtype=bool)\n",
    "#         for var_name in high_level_fields_dict[f'fold_{fold}']:\n",
    "#             if var_name in {'event', 'puppiMET_eta'}:\n",
    "#                 continue\n",
    "#             sig_var = data_test_df_dict[f'fold_{fold}'].loc[(label_test_dict[f'fold_{fold}']==1) & mask, var_name]\n",
    "#             bkg_var = data_test_df_dict[f'fold_{fold}'].loc[(label_test_dict[f'fold_{fold}']==0) & mask, var_name]\n",
    "#             sig_masks, bkg_masks = [], []\n",
    "#             hists, labels = [], []\n",
    "#             for cut in score_cut:\n",
    "#                 sig_masks.append(np.exp(\n",
    "#                     IN_info['mean_pred']\n",
    "#                 )[\n",
    "#                     np.logical_and(\n",
    "#                         np.array(IN_info['mean_label']) == 1, mask\n",
    "#                     ),1\n",
    "#                 ] > cut)\n",
    "#                 bkg_masks.append(np.exp(\n",
    "#                     IN_info['mean_pred']\n",
    "#                 )[\n",
    "#                     np.logical_and(\n",
    "#                         np.array(IN_info['mean_label']) == 0, mask\n",
    "#                     ),1\n",
    "#                 ] > cut)\n",
    "                \n",
    "#                 hists.append(hist.Hist(VARIABLES[var_name]).fill(\n",
    "#                     var=sig_var.loc[sig_masks[-1]], \n",
    "#                     weight=weights['sig'][sig_masks[-1]] if weights['sig'] is not None else np.ones(np.sum(sig_masks[-1]))\n",
    "#                 ))\n",
    "#                 hists.append(hist.Hist(VARIABLES[var_name]).fill(\n",
    "#                     var=bkg_var.loc[bkg_masks[-1]], \n",
    "#                     weight=weights['bkg'][bkg_masks[-1]] if weights['bkg'] is not None else np.ones(np.sum(bkg_masks[-1]))\n",
    "#                 ))\n",
    "#                 labels.extend([f'HH signal, ttH-score > {cut}', f'ttH background, ttH-score > {cut}'])\n",
    "#             make_input_plot(\n",
    "#                 destdir, var_name, hists, fold, plot_prefix=plot_prefix, \n",
    "#                 plot_postfix=plot_postfix+f'_ttHscore_scan', labels=labels, density=False if weights['sig'] is not None else True\n",
    "#             )\n",
    "#     else:\n",
    "#         raise Exception(f\"Must used method 'std'. You used {method}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
