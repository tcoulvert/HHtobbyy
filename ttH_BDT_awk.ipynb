{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmslpcgpu3.fnal.gov      Wed Jan 29 22:02:42 2025  555.42.06\n",
      "[0] Tesla P100-PCIE-12GB | 41Â°C,   1 % |     0 / 12288 MB |\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib widget\n",
    "# Stdlib packages\n",
    "import copy\n",
    "import datetime\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "# Common Py packages\n",
    "import awkward as ak\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from prettytable import PrettyTable\n",
    "from scipy.special import logit as inverse_sigmoid\n",
    "\n",
    "# HEP packages\n",
    "import gpustat\n",
    "import h5py\n",
    "import hist\n",
    "import mplhep as hep\n",
    "import xgboost as xgb\n",
    "from cycler import cycler\n",
    "\n",
    "# ML packages\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, fbeta_score\n",
    "from scipy.integrate import trapezoid\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Integer\n",
    "from skopt.utils import use_named_args\n",
    "\n",
    "# Module packages\n",
    "from data_processing_BDT import process_data\n",
    "\n",
    "gpustat.print_gpustat()\n",
    "\n",
    "plt.style.use(hep.style.CMS)\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "cmap_petroff10 = [\"#3f90da\", \"#ffa90e\", \"#bd1f01\", \"#94a4a2\", \"#832db6\", \"#a96b59\", \"#e76300\", \"#b9ac70\", \"#717581\", \"#92dadd\"]\n",
    "plt.rcParams.update({\"axes.prop_cycle\": cycler(\"color\", cmap_petroff10)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Locations and Model Naming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lpc_fileprefix = \"/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1\"\n",
    "\n",
    "FILEPATHS_DICT = {\n",
    "    'ggF HH': [\n",
    "        lpc_fileprefix+f\"/Run3_2022preEE_merged_v5/GluGluToHH/nominal/*\", \n",
    "        lpc_fileprefix+f\"/Run3_2022postEE_merged_v5/GluGluToHH/nominal/*\"\n",
    "    ],\n",
    "    # 'VBF HH': [\n",
    "    #     lpc_fileprefix+f\"/Run3_2022preEE_merged_v4/VBFHHto2B2G_CV_1_C2V_1_C3_1/nominal/*\", \n",
    "    #     lpc_fileprefix+f\"/Run3_2022postEE_merged_v4/VBFHHto2B2G_CV_1_C2V_1_C3_1/nominal/*\"\n",
    "    # ],\n",
    "    'ttH': [\n",
    "        lpc_fileprefix+f\"/Run3_2022preEE_merged_v5/ttHToGG/nominal/*\", \n",
    "        lpc_fileprefix+f\"/Run3_2022postEE_merged_v5/ttHToGG/nominal/*\"\n",
    "    ],\n",
    "    'VH': [\n",
    "        # VH\n",
    "        lpc_fileprefix+f\"/Run3_2022preEE_merged_v5/VHToGG/nominal/*\", \n",
    "        lpc_fileprefix+f\"/Run3_2022postEE_merged_v5/VHToGG/nominal/*\",\n",
    "    ],\n",
    "    'non-res + ggFH + VBFH': [\n",
    "        # GG + 3Jets\n",
    "        lpc_fileprefix+f\"/Run3_2022preEE_merged_v5/GGJets/nominal/*\", \n",
    "        lpc_fileprefix+f\"/Run3_2022postEE_merged_v5/GGJets/nominal/*\",\n",
    "        # GJet pT 20-40\n",
    "        lpc_fileprefix+f\"/Run3_2022preEE_merged_v5/GJetPt20To40/nominal/*\", \n",
    "        lpc_fileprefix+f\"/Run3_2022postEE_merged_v5/GJetPt20To40/nominal/*\",\n",
    "        # GJet pT 40-inf\n",
    "        lpc_fileprefix+f\"/Run3_2022preEE_merged_v5/GJetPt40/nominal/*\", \n",
    "        lpc_fileprefix+f\"/Run3_2022postEE_merged_v5/GJetPt40/nominal/*\",\n",
    "        # ggF H\n",
    "        lpc_fileprefix+f\"/Run3_2022preEE_merged_v5/GluGluHToGG/nominal/*\", \n",
    "        lpc_fileprefix+f\"/Run3_2022postEE_merged_v5/GluGluHToGG/nominal/*\",\n",
    "        # VBF H\n",
    "        lpc_fileprefix+f\"/Run3_2022preEE_merged_v5/VBFHToGG/nominal/*\", \n",
    "        lpc_fileprefix+f\"/Run3_2022postEE_merged_v5/VBFHToGG/nominal/*\",\n",
    "    ],\n",
    "    # 'single-H': [\n",
    "    #     # ggF H\n",
    "    #     lpc_fileprefix+f\"/Run3_2022preEE_merged_v4/GluGluHToGG/nominal/*\", \n",
    "    #     lpc_fileprefix+f\"/Run3_2022postEE_merged_v4/GluGluHToGG/nominal/*\",\n",
    "    #     # VBF H\n",
    "    #     lpc_fileprefix+f\"/Run3_2022preEE_merged_v4/VBFHToGG/nominal/*\", \n",
    "    #     lpc_fileprefix+f\"/Run3_2022postEE_merged_v4/VBFHToGG/nominal/*\",\n",
    "    #     # VH\n",
    "    #     lpc_fileprefix+f\"/Run3_2022preEE_merged_v4/VHToGG/nominal/*\", \n",
    "    #     lpc_fileprefix+f\"/Run3_2022postEE_merged_v4/VHToGG/nominal/*\",\n",
    "    # ],\n",
    "    # 'non-res': [\n",
    "    #     # GG + 3Jets\n",
    "    #     lpc_fileprefix+f\"/Run3_2022preEE_merged_v4/GGJets/nominal/*\", \n",
    "    #     lpc_fileprefix+f\"/Run3_2022postEE_merged_v4/GGJets/nominal/*\",\n",
    "    #     # GJet pT 20-40\n",
    "    #     lpc_fileprefix+f\"/Run3_2022preEE_merged_v4/GJetPt20To40/nominal/*\", \n",
    "    #     lpc_fileprefix+f\"/Run3_2022postEE_merged_v4/GJetPt20To40/nominal/*\",\n",
    "    #     # GJet pT 40-inf\n",
    "    #     lpc_fileprefix+f\"/Run3_2022preEE_merged_v4/GJetPt40/nominal/*\", \n",
    "    #     lpc_fileprefix+f\"/Run3_2022postEE_merged_v4/GJetPt40/nominal/*\",\n",
    "    # ],\n",
    "}\n",
    "\n",
    "CURRENT_DIRPATH = str(Path().absolute())\n",
    "VERSION = 'v8'\n",
    "MOD_VALS = (5, 5)\n",
    "# VARS = 'nonres_and_ttH_and_DNN_vars_no_diphoMass'\n",
    "# CURRENT_TIME = '2025-01-23_09-59-35'\n",
    "VARS = 'nonres_and_ttH_and_DNN_vars_no_badVars_no_badMyyVars'\n",
    "# CURRENT_TIME = '2025-01-24_23-18-02'\n",
    "if 'CURRENT_TIME' in globals():\n",
    "    OUTPUT_DIRPATH = os.path.join(CURRENT_DIRPATH, f\"MultiClassBDT_model_outputs/{VERSION}/{VARS}\", CURRENT_TIME)\n",
    "else:\n",
    "    OUTPUT_DIRPATH = os.path.join(CURRENT_DIRPATH, f\"MultiClassBDT_model_outputs/{VERSION}/{VARS}\")\n",
    "\n",
    "if not os.path.exists(OUTPUT_DIRPATH):\n",
    "    os.makedirs(OUTPUT_DIRPATH)\n",
    "\n",
    "OTHER_BKG_RESCALE = 50\n",
    "OPTIMIZE_SPACE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_weights(event_weights, labels, order=None, weighttype='rescaled_and_shifted', sig_rescale_factor=None):\n",
    "    if weighttype == 'abs':\n",
    "        return np.abs(event_weights)\n",
    "    \n",
    "    if order is not None:\n",
    "        sig_idx, big_bkg_idx = -1, -1\n",
    "        for i, sample_name in enumerate(order):\n",
    "            if re.search('ggF HH', sample_name) is not None:\n",
    "                sig_idx = i\n",
    "                continue\n",
    "            if re.search('non-res', sample_name) is not None:\n",
    "                big_bkg_idx = i\n",
    "                continue\n",
    "    else:\n",
    "        sig_idx, big_bkg_idx = 0, len(order)-1\n",
    "    \n",
    "    if sig_rescale_factor is None:\n",
    "        sig_sum = np.sum(event_weights[labels[:, sig_idx] == 1])\n",
    "        bkg_sum = np.sum(event_weights[labels[:, sig_idx] == 0])\n",
    "        \n",
    "        sig_rescale_factor = bkg_sum / sig_sum\n",
    "\n",
    "    scaled_weights = np.where(\n",
    "        labels[:, sig_idx] == 0, \n",
    "        np.where(\n",
    "            np.argmax(labels, axis=1) != big_bkg_idx,  \n",
    "            event_weights * OTHER_BKG_RESCALE,  # if not big bkg, rescale\n",
    "            event_weights  # otherwise do nothing\n",
    "        ),\n",
    "        event_weights * sig_rescale_factor  # if sig, rescale to equal sum of all bkgs\n",
    "    )\n",
    "\n",
    "    abs_weights = np.abs(scaled_weights)\n",
    "\n",
    "    if weighttype == 'rescaled':\n",
    "        return abs_weights\n",
    "    elif weighttype == 'rescaled_and_shifted':\n",
    "        mean_weights = np.mean(scaled_weights)\n",
    "        rescaled_weights = abs_weights / mean_weights\n",
    "        return rescaled_weights\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"The only options for weighttype are 'abs', 'rescaled', and 'rescaled_and_shifted'. You provided {weighttype}\"\n",
    "        )\n",
    "\n",
    "# def training_weights(event_weights, labels, order=None, sig_rescale_factor=None):\n",
    "#     if order is None:\n",
    "#         order = [i for v in range(np.shape(labels)[0])]\n",
    "#     sum_dict, max_sum, max_i = {}, 0, 0\n",
    "#     for i, sample_name in enumerate(order):\n",
    "#         sum_dict[i] = np.sum(event_weights[labels[:, i] == 1])\n",
    "#         if np.sum(event_weights[labels[:, i] == 1]) > max_sum:\n",
    "#             max_sum, max_i = np.sum(event_weights[labels[:, i] == 1]), i\n",
    "\n",
    "#     label_i = np.sum(\n",
    "#         np.tile([i for i in range(np.shape(labels)[1])], (np.shape(labels)[0], 1)) * labels,\n",
    "#         axis=1\n",
    "#     )\n",
    "\n",
    "#     weight_factors = []\n",
    "#     for i in range(len(label_i)):\n",
    "#         weight_factors.append(\n",
    "#             max_sum / sum_dict[label_i[i]] if label_i[i] != max_i else 1\n",
    "#         )\n",
    "#     weights = event_weights * np.array(weight_factors)\n",
    "\n",
    "#     mean_weight = np.mean(weights)\n",
    "#     abs_weights = np.abs(weights)\n",
    "#     scaled_weights = abs_weights / mean_weight\n",
    "\n",
    "#     return scaled_weights\n",
    "\n",
    "\n",
    "def xgb_labels(labels):\n",
    "    label_i = np.sum(\n",
    "        np.tile([i for i in range(np.shape(labels)[1])], (np.shape(labels)[0], 1)) * labels,\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    return label_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading and Input Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# order = ['ggF HH', 'ttH', 'single-H', 'non-res']\n",
    "order = ['ggF HH', 'ttH', 'VH', 'non-res + ggFH + VBFH']\n",
    "\n",
    "(\n",
    "    sig_rescale_factor,\n",
    "    data_df_dict, data_test_df_dict, \n",
    "    data_hlf_dict, label_dict,\n",
    "    data_hlf_test_dict, label_test_dict, \n",
    "    hlf_vars_columns_dict,\n",
    "    data_aux_dict, data_test_aux_dict\n",
    ") = process_data(\n",
    "    FILEPATHS_DICT, OUTPUT_DIRPATH, order=order, mod_vals=MOD_VALS,\n",
    "    save=False if 'CURRENT_TIME' in globals() else True,\n",
    "    std_json_dirpath=OUTPUT_DIRPATH if 'CURRENT_TIME' in globals() else None,\n",
    "    other_bkg_rescale=OTHER_BKG_RESCALE\n",
    ")\n",
    "\n",
    "# Make xgb-like labels (NOT one-hot encoded, but integer encoded for each class)\n",
    "xgb_label_dict = {\n",
    "    f\"fold_{fold_idx}\": copy.deepcopy(xgb_labels(label_dict[f\"fold_{fold_idx}\"])) for fold_idx in range(len(data_test_aux_dict))\n",
    "}\n",
    "xgb_label_test_dict = {\n",
    "    f\"fold_{fold_idx}\": copy.deepcopy(xgb_labels(label_test_dict[f\"fold_{fold_idx}\"])) for fold_idx in range(len(data_test_aux_dict))\n",
    "}\n",
    "\n",
    "# Make weight dicts:\n",
    "#   - the top two are with the training rescale (i.e. rescale sig eventWeight to match bkg and then shift for gradients)\n",
    "#   - the bottom two are the standard eventWeights (i.e. xs * lumi * genWeight) for proper plotting\n",
    "weight_train_dict = {\n",
    "    f\"fold_{fold_idx}\": copy.deepcopy(training_weights(data_aux_dict[f'fold_{fold_idx}'].loc[:, \"eventWeight\"].to_numpy(), label_dict[f'fold_{fold_idx}'], order=order, sig_rescale_factor=sig_rescale_factor)) for fold_idx in range(len(data_aux_dict))\n",
    "}\n",
    "weight_test_dict = {\n",
    "    f'fold_{fold_idx}': copy.deepcopy(training_weights(data_test_aux_dict[f'fold_{fold_idx}'].loc[:, \"eventWeight\"].to_numpy(), label_test_dict[f'fold_{fold_idx}'], order=order, sig_rescale_factor=sig_rescale_factor)) for fold_idx in range(len(data_test_aux_dict))\n",
    "}\n",
    "weights_plot_train_dict = {\n",
    "    f\"fold_{fold_idx}\": copy.deepcopy(data_aux_dict[f'fold_{fold_idx}'].loc[:, \"eventWeight\"].to_numpy()) for fold_idx in range(len(data_aux_dict))\n",
    "}\n",
    "weights_plot_test = {\n",
    "    f'fold_{fold_idx}': copy.deepcopy(data_test_aux_dict[f'fold_{fold_idx}'].loc[:, \"eventWeight\"].to_numpy()) for fold_idx in range(len(data_test_aux_dict))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "Num train: 1250553 -> 109202 sig & 221813 ttH bkg & 107711 single-H bkg & 811827 non-res bkg\n",
      "Num val: 312639 -> 27328 sig & 55392 ttH bkg & 26930 single-H bkg & 202989 non-res bkg\n",
      "Num test: 391785 -> 34224 sig & 69297 ttH bkg & 33713 single-H bkg & & 254551 non-res bkg\n",
      "============================================================\n",
      "fold 1\n",
      "Num train: 1251336 -> 109538 sig & 221692 ttH bkg & 107855 single-H bkg & 812251 non-res bkg\n",
      "Num val: 312835 -> 26928 sig & 55760 ttH bkg & 26850 single-H bkg & 203297 non-res bkg\n",
      "Num test: 390806 -> 34288 sig & 69050 ttH bkg & 33649 single-H bkg & & 253819 non-res bkg\n",
      "============================================================\n",
      "fold 2\n",
      "Num train: 1250948 -> 109282 sig & 221260 ttH bkg & 108006 single-H bkg & 812400 non-res bkg\n",
      "Num val: 312737 -> 27356 sig & 55367 ttH bkg & 26813 single-H bkg & 203201 non-res bkg\n",
      "Num test: 391292 -> 34116 sig & 69875 ttH bkg & 33535 single-H bkg & & 253766 non-res bkg\n",
      "============================================================\n",
      "fold 3\n",
      "Num train: 1251535 -> 109354 sig & 221822 ttH bkg & 107689 single-H bkg & 812670 non-res bkg\n",
      "Num val: 312884 -> 27317 sig & 55232 ttH bkg & 26926 single-H bkg & 203409 non-res bkg\n",
      "Num test: 390558 -> 34083 sig & 69448 ttH bkg & 33739 single-H bkg & & 253288 non-res bkg\n",
      "============================================================\n",
      "fold 4\n",
      "Num train: 1251552 -> 109336 sig & 221879 ttH bkg & 107866 single-H bkg & 812471 non-res bkg\n",
      "Num val: 312889 -> 27375 sig & 55791 ttH bkg & 26770 single-H bkg & 202953 non-res bkg\n",
      "Num test: 390536 -> 34043 sig & 68832 ttH bkg & 33718 single-H bkg & & 253943 non-res bkg\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "bdt_train_dict, bdt_val_dict, bdt_test_dict = {}, {}, {}\n",
    "\n",
    "train_data_dict, val_data_dict = {}, {}\n",
    "xgb_label_train_dict, xgb_label_val_dict = {}, {}\n",
    "weights_plot_train, weights_plot_val= {}, {}\n",
    "train_idxs_dict, val_idxs_dict = {}, {}\n",
    "for fold_idx in range(len(data_df_dict)):\n",
    "    if re.search('no_std', VARS) is not None:\n",
    "        print('no standardization')\n",
    "        train_val_data_dict = {key: value.to_numpy() for key, value in data_df_dict.items()}\n",
    "        test_data_dict = {key: value.to_numpy() for key, value in data_test_df_dict.items()}\n",
    "    else:\n",
    "        train_val_data_dict = data_hlf_dict\n",
    "        test_data_dict = data_hlf_test_dict\n",
    "    (\n",
    "        X_train, X_val, \n",
    "        y_train, y_val, \n",
    "        weight_train, weight_val, \n",
    "        weight_plot_train, weight_plot_val,\n",
    "        train_idxs, val_idxs\n",
    "    ) = train_test_split(\n",
    "        train_val_data_dict[f\"fold_{fold_idx}\"], xgb_label_dict[f\"fold_{fold_idx}\"], \n",
    "        weight_train_dict[f\"fold_{fold_idx}\"], weights_plot_train_dict[f\"fold_{fold_idx}\"],\n",
    "        range(len(train_val_data_dict[f\"fold_{fold_idx}\"])),\n",
    "        test_size=0.2, random_state=21\n",
    "    )\n",
    "\n",
    "    train_data_dict[f\"fold_{fold_idx}\"] = copy.deepcopy(X_train)\n",
    "    val_data_dict[f\"fold_{fold_idx}\"] = copy.deepcopy(X_val)\n",
    "\n",
    "    xgb_label_train_dict[f\"fold_{fold_idx}\"] = copy.deepcopy(y_train)\n",
    "    xgb_label_val_dict[f\"fold_{fold_idx}\"] = copy.deepcopy(y_val)\n",
    "\n",
    "    weights_plot_train[f\"fold_{fold_idx}\"] = copy.deepcopy(weight_plot_train)\n",
    "    weights_plot_val[f\"fold_{fold_idx}\"] = copy.deepcopy(weight_plot_val)\n",
    "\n",
    "    train_idxs_dict[f\"fold_{fold_idx}\"] = copy.deepcopy(train_idxs)\n",
    "    val_idxs_dict[f\"fold_{fold_idx}\"] = copy.deepcopy(val_idxs)\n",
    "\n",
    "    bdt_train_dict[f\"fold_{fold_idx}\"] = xgb.DMatrix(\n",
    "        data=X_train, label=y_train, \n",
    "        weight=weight_train,\n",
    "        missing=-999.0, feature_names=list(hlf_vars_columns_dict[f\"fold_{fold_idx}\"])\n",
    "    )\n",
    "    bdt_val_dict[f\"fold_{fold_idx}\"] = xgb.DMatrix(\n",
    "        data=X_val, label=y_val, \n",
    "        weight=weight_val,\n",
    "        missing=-999.0, feature_names=list(hlf_vars_columns_dict[f\"fold_{fold_idx}\"])\n",
    "    )\n",
    "    \n",
    "    bdt_test_dict[f\"fold_{fold_idx}\"] = xgb.DMatrix(\n",
    "        data=test_data_dict[f\"fold_{fold_idx}\"], label=xgb_label_test_dict[f\"fold_{fold_idx}\"], \n",
    "        weight=np.abs(weight_test_dict[f\"fold_{fold_idx}\"]),\n",
    "        missing=-999.0, feature_names=list(hlf_vars_columns_dict[f\"fold_{fold_idx}\"])\n",
    "    )\n",
    "\n",
    "    print(f\"fold {fold_idx}\")\n",
    "    print(f\"Num train: {len(y_train)} -> {sum(y_train == 0)} sig & {sum(y_train == 1)} ttH bkg & {sum(y_train == 2)} single-H bkg & {sum(y_train == 3)} non-res bkg\")\n",
    "    print(f\"Num val: {len(y_val)} -> {sum(y_val == 0)} sig & {sum(y_val == 1)} ttH bkg & {sum(y_val == 2)} single-H bkg & {sum(y_val == 3)} non-res bkg\")\n",
    "    print(f\"Num test: {len(label_test_dict[f'fold_{fold_idx}'])} -> {sum(label_test_dict[f'fold_{fold_idx}'] == np.array([1, 0, 0, 0]))[0]} sig & {sum(label_test_dict[f'fold_{fold_idx}'] == np.array([0, 1, 0, 0]))[1]} ttH bkg & {sum(label_test_dict[f'fold_{fold_idx}'] == np.array([0, 0, 1, 0]))[2]} single-H bkg & & {sum(label_test_dict[f'fold_{fold_idx}'] == np.array([0, 0, 0, 1]))[3]} non-res bkg\")\n",
    "    print('='*60)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Parameterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/57986259/multiclass-classification-with-xgboost-classifier\n",
    "# https://forecastegy.com/posts/xgboost-multiclass-classification-python/\n",
    "# https://indico.cern.ch/event/915265/contributions/3848138/attachments/2048174/3432202/kunlinRan_bbyy_20200531.pdf\n",
    "\n",
    "# https://xgboost.readthedocs.io/en/stable/tutorials/intercept.html - for looking at logits level BDT output\n",
    "# https://indico.cern.ch/event/915265/contributions/3848138/attachments/2048174/3432202/kunlinRan_bbyy_20200531.pdf - ATLAS HHbbgg BDT\n",
    "\n",
    "\n",
    "param = {}\n",
    "\n",
    "# Booster parameters\n",
    "param['eta']              = 0.05 # learning rate\n",
    "num_trees = round(25 / param['eta'])  # number of trees to make\n",
    "# param['max_depth']        = 8  # maximum depth of a tree\n",
    "# param['subsample']        = 1 # fraction of events to train tree on\n",
    "# param['colsample_bytree'] = 0.33 # fraction of features to train tree on\n",
    "param['max_depth']        = 10  # maximum depth of a tree\n",
    "param['subsample']        = 0.6 # fraction of events to train tree on\n",
    "param['colsample_bytree'] = 0.6 # fraction of features to train tree on\n",
    "param['num_class']        = len(order) # num classes for multi-class training\n",
    "\n",
    "# Learning task parameters\n",
    "param['objective']   = 'multi:softprob'   # objective function\n",
    "param['eval_metric'] = 'merror'           # evaluation metric for cross validation\n",
    "param = list(param.items()) + [('eval_metric', 'mlogloss')]\n",
    "# param[\"disable_default_eval_metric\"] = True\n",
    "# param = list(param.items())\n",
    "\n",
    "\n",
    "def thresholded_weighted_merror(predt: np.ndarray, dtrain: xgb.DMatrix, threshold=0.95):\n",
    "    \"\"\"Used when there's no custom objective.\"\"\"\n",
    "    # No need to do transform, XGBoost handles it internally.\n",
    "    weights = dtrain.get_weight()\n",
    "    thresh_weight_merror = np.where(\n",
    "        np.logical_and(\n",
    "            np.max(predt, axis=1) >= threshold,\n",
    "            np.argmax(predt, axis=1) == dtrain.get_label()\n",
    "        ),\n",
    "        0,\n",
    "        weights\n",
    "    )\n",
    "    return f'WeightedMError@{threshold:.2f}', np.sum(thresh_weight_merror)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_hyperparams(\n",
    "    dtrain_dict: dict, dval_dict: dict, dtest_dict: dict, param, verbose: bool=False, verbose_eval=False\n",
    "):  \n",
    "    rng = np.random.default_rng()\n",
    "\n",
    "    space  = [\n",
    "        Real(1e-3, 0.1, \"log-uniform\", name='eta'),\n",
    "        Integer(1, 20, \"uniform\", name='max_depth'),\n",
    "        Real(1e-3, 1., \"log-uniform\", name='subsample'),\n",
    "        Real(0.1, 1., \"uniform\", name='colsample_bytree'),\n",
    "        # Real(1e-4, 1., \"log-uniform\", name='alpha'),\n",
    "        # Real(1e-4, 1., \"log-uniform\", name='lambda'),\n",
    "    ]\n",
    "\n",
    "    score_arrs = []\n",
    "\n",
    "    @use_named_args(space)\n",
    "    def objective(**X):\n",
    "        if verbose:\n",
    "            print(\"New configuration: {}\".format(X))\n",
    "\n",
    "        for key, val in X.items():\n",
    "            param[key] = val\n",
    "        num_trees = round(25 / X['eta'])\n",
    "\n",
    "        # randomly sample a fold to evaluate\n",
    "        fold_idx = rng.integers(0, 4)\n",
    "\n",
    "        evallist = [(dtrain_dict[f\"fold_{fold_idx}\"], 'train'), (dtest_dict[f\"fold_{fold_idx}\"], 'test'), (dval_dict[f\"fold_{fold_idx}\"], 'val')]\n",
    "        booster = xgb.train(\n",
    "            param, dtrain_dict[f\"fold_{fold_idx}\"], num_boost_round=num_trees, \n",
    "            evals=evallist, early_stopping_rounds=10, verbose_eval=verbose_eval,\n",
    "        )\n",
    "\n",
    "        eval_str = booster.eval(dval_dict[f\"fold_{fold_idx}\"], name='val', iteration=booster.best_iteration)\n",
    "\n",
    "        best_mlogloss = float(eval_str[eval_str.find('val-mlogloss:')+len('val-mlogloss:'):])\n",
    "        score_arrs.append(best_mlogloss)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Best val. mlogloss on fold{fold_idx} = {best_mlogloss}\")\n",
    "\n",
    "        return -best_mlogloss\n",
    "    \n",
    "    res_gp = gp_minimize(objective, space)\n",
    "    print(\"Best parameters: {}\".format(res_gp.x))\n",
    "\n",
    "    param['eta'] = float(res_gp.x[0])\n",
    "    param['max_depth'] = int(res_gp.x[1])\n",
    "    param['subsample'] = float(res_gp.x[2])\n",
    "    param['colsample_bytree'] = float(res_gp.x[3])\n",
    "    # param['alpha'] = float(res_gp.x[4])\n",
    "    # param['lambda'] = float(res_gp.x[5])\n",
    "    return param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "[0]\ttrain-merror:0.08633\ttrain-mlogloss:1.30941\ttest-merror:0.09693\ttest-mlogloss:1.31031\tval-merror:0.10046\tval-mlogloss:1.31082\n",
      "[25]\ttrain-merror:0.05218\ttrain-mlogloss:0.45391\ttest-merror:0.06496\ttest-mlogloss:0.47222\tval-merror:0.06756\tval-mlogloss:0.47704\n",
      "[50]\ttrain-merror:0.04780\ttrain-mlogloss:0.24290\ttest-merror:0.06201\ttest-mlogloss:0.27115\tval-merror:0.06506\tval-mlogloss:0.27735\n",
      "[75]\ttrain-merror:0.04500\ttrain-mlogloss:0.17534\ttest-merror:0.06117\ttest-mlogloss:0.21243\tval-merror:0.06384\tval-mlogloss:0.21934\n",
      "[100]\ttrain-merror:0.04169\ttrain-mlogloss:0.14749\ttest-merror:0.06041\ttest-mlogloss:0.19268\tval-merror:0.06292\tval-mlogloss:0.20008\n",
      "[125]\ttrain-merror:0.03888\ttrain-mlogloss:0.13290\ttest-merror:0.05973\ttest-mlogloss:0.18521\tval-merror:0.06276\tval-mlogloss:0.19279\n",
      "[150]\ttrain-merror:0.03644\ttrain-mlogloss:0.12320\ttest-merror:0.05972\ttest-mlogloss:0.18200\tval-merror:0.06261\tval-mlogloss:0.18979\n",
      "[175]\ttrain-merror:0.03391\ttrain-mlogloss:0.11600\ttest-merror:0.05957\ttest-mlogloss:0.18060\tval-merror:0.06288\tval-mlogloss:0.18866\n",
      "[200]\ttrain-merror:0.03150\ttrain-mlogloss:0.10978\ttest-merror:0.05985\ttest-mlogloss:0.18005\tval-merror:0.06292\tval-mlogloss:0.18821\n",
      "[225]\ttrain-merror:0.02964\ttrain-mlogloss:0.10486\ttest-merror:0.05985\ttest-mlogloss:0.17978\tval-merror:0.06291\tval-mlogloss:0.18799\n",
      "[240]\ttrain-merror:0.02825\ttrain-mlogloss:0.10209\ttest-merror:0.05993\ttest-mlogloss:0.17970\tval-merror:0.06281\tval-mlogloss:0.18798\n",
      "[230]\ttest-merror:0.059929\ttest-mlogloss:0.179701\n",
      "====================================================================================================\n",
      "fold 1\n",
      "[0]\ttrain-merror:0.06613\ttrain-mlogloss:1.30308\ttest-merror:0.07902\ttest-mlogloss:1.30398\tval-merror:0.07646\tval-mlogloss:1.30378\n",
      "[25]\ttrain-merror:0.05229\ttrain-mlogloss:0.45166\ttest-merror:0.06636\ttest-mlogloss:0.47282\tval-merror:0.06552\tval-mlogloss:0.47114\n",
      "[50]\ttrain-merror:0.04824\ttrain-mlogloss:0.24640\ttest-merror:0.06451\ttest-mlogloss:0.27846\tval-merror:0.06374\tval-mlogloss:0.27654\n",
      "[75]\ttrain-merror:0.04461\ttrain-mlogloss:0.17606\ttest-merror:0.06294\ttest-mlogloss:0.21718\tval-merror:0.06132\tval-mlogloss:0.21515\n",
      "[100]\ttrain-merror:0.04182\ttrain-mlogloss:0.14866\ttest-merror:0.06207\ttest-mlogloss:0.19762\tval-merror:0.06043\tval-mlogloss:0.19580\n",
      "[125]\ttrain-merror:0.03875\ttrain-mlogloss:0.13335\ttest-merror:0.06163\ttest-mlogloss:0.18984\tval-merror:0.05980\tval-mlogloss:0.18779\n",
      "[150]\ttrain-merror:0.03620\ttrain-mlogloss:0.12354\ttest-merror:0.06166\ttest-mlogloss:0.18655\tval-merror:0.05970\tval-mlogloss:0.18456\n",
      "[175]\ttrain-merror:0.03388\ttrain-mlogloss:0.11618\ttest-merror:0.06132\ttest-mlogloss:0.18507\tval-merror:0.05968\tval-mlogloss:0.18303\n",
      "[200]\ttrain-merror:0.03164\ttrain-mlogloss:0.11022\ttest-merror:0.06134\ttest-mlogloss:0.18425\tval-merror:0.06014\tval-mlogloss:0.18235\n",
      "[225]\ttrain-merror:0.02959\ttrain-mlogloss:0.10542\ttest-merror:0.06140\ttest-mlogloss:0.18403\tval-merror:0.06005\tval-mlogloss:0.18210\n",
      "[250]\ttrain-merror:0.02766\ttrain-mlogloss:0.10108\ttest-merror:0.06121\ttest-mlogloss:0.18402\tval-merror:0.05976\tval-mlogloss:0.18204\n",
      "[254]\ttrain-merror:0.02736\ttrain-mlogloss:0.10036\ttest-merror:0.06121\ttest-mlogloss:0.18403\tval-merror:0.05972\tval-mlogloss:0.18204\n",
      "[245]\ttest-merror:0.061286\ttest-mlogloss:0.184055\n",
      "====================================================================================================\n",
      "fold 2\n",
      "[0]\ttrain-merror:0.06432\ttrain-mlogloss:1.30283\ttest-merror:0.07714\ttest-mlogloss:1.30403\tval-merror:0.07763\tval-mlogloss:1.30400\n",
      "[25]\ttrain-merror:0.05156\ttrain-mlogloss:0.44984\ttest-merror:0.06625\ttest-mlogloss:0.47233\tval-merror:0.06532\tval-mlogloss:0.47148\n",
      "[50]\ttrain-merror:0.04816\ttrain-mlogloss:0.24449\ttest-merror:0.06466\ttest-mlogloss:0.27842\tval-merror:0.06358\tval-mlogloss:0.27679\n",
      "[75]\ttrain-merror:0.04454\ttrain-mlogloss:0.17531\ttest-merror:0.06285\ttest-mlogloss:0.21863\tval-merror:0.06222\tval-mlogloss:0.21682\n",
      "[100]\ttrain-merror:0.04147\ttrain-mlogloss:0.14730\ttest-merror:0.06205\ttest-mlogloss:0.19905\tval-merror:0.06125\tval-mlogloss:0.19718\n",
      "[125]\ttrain-merror:0.03871\ttrain-mlogloss:0.13237\ttest-merror:0.06189\ttest-mlogloss:0.19145\tval-merror:0.06109\tval-mlogloss:0.18959\n",
      "[150]\ttrain-merror:0.03593\ttrain-mlogloss:0.12248\ttest-merror:0.06159\ttest-mlogloss:0.18833\tval-merror:0.06114\tval-mlogloss:0.18626\n",
      "[175]\ttrain-merror:0.03358\ttrain-mlogloss:0.11505\ttest-merror:0.06197\ttest-mlogloss:0.18694\tval-merror:0.06158\tval-mlogloss:0.18479\n",
      "[200]\ttrain-merror:0.03110\ttrain-mlogloss:0.10880\ttest-merror:0.06167\ttest-mlogloss:0.18607\tval-merror:0.06139\tval-mlogloss:0.18385\n",
      "[225]\ttrain-merror:0.02902\ttrain-mlogloss:0.10385\ttest-merror:0.06171\ttest-mlogloss:0.18595\tval-merror:0.06160\tval-mlogloss:0.18354\n",
      "[246]\ttrain-merror:0.02747\ttrain-mlogloss:0.10029\ttest-merror:0.06195\ttest-mlogloss:0.18603\tval-merror:0.06184\tval-mlogloss:0.18359\n",
      "[236]\ttest-merror:0.061946\ttest-mlogloss:0.186029\n",
      "====================================================================================================\n",
      "fold 3\n",
      "[0]\ttrain-merror:0.07459\ttrain-mlogloss:1.30689\ttest-merror:0.08591\ttest-mlogloss:1.30790\tval-merror:0.08532\tval-mlogloss:1.30785\n",
      "[25]\ttrain-merror:0.05415\ttrain-mlogloss:0.45991\ttest-merror:0.06667\ttest-mlogloss:0.47886\tval-merror:0.06573\tval-mlogloss:0.47818\n",
      "[50]\ttrain-merror:0.04881\ttrain-mlogloss:0.24712\ttest-merror:0.06343\ttest-mlogloss:0.27607\tval-merror:0.06249\tval-mlogloss:0.27491\n",
      "[75]\ttrain-merror:0.04540\ttrain-mlogloss:0.17792\ttest-merror:0.06202\ttest-mlogloss:0.21576\tval-merror:0.06083\tval-mlogloss:0.21417\n",
      "[100]\ttrain-merror:0.04230\ttrain-mlogloss:0.14904\ttest-merror:0.06171\ttest-mlogloss:0.19541\tval-merror:0.05978\tval-mlogloss:0.19341\n",
      "[125]\ttrain-merror:0.03929\ttrain-mlogloss:0.13423\ttest-merror:0.06132\ttest-mlogloss:0.18797\tval-merror:0.05926\tval-mlogloss:0.18577\n",
      "[150]\ttrain-merror:0.03668\ttrain-mlogloss:0.12461\ttest-merror:0.06108\ttest-mlogloss:0.18465\tval-merror:0.05940\tval-mlogloss:0.18243\n",
      "[175]\ttrain-merror:0.03410\ttrain-mlogloss:0.11705\ttest-merror:0.06105\ttest-mlogloss:0.18307\tval-merror:0.05930\tval-mlogloss:0.18079\n",
      "[200]\ttrain-merror:0.03198\ttrain-mlogloss:0.11117\ttest-merror:0.06091\ttest-mlogloss:0.18235\tval-merror:0.05930\tval-mlogloss:0.18001\n",
      "[225]\ttrain-merror:0.02967\ttrain-mlogloss:0.10562\ttest-merror:0.06094\ttest-mlogloss:0.18197\tval-merror:0.05912\tval-mlogloss:0.17968\n",
      "[234]\ttrain-merror:0.02901\ttrain-mlogloss:0.10405\ttest-merror:0.06093\ttest-mlogloss:0.18191\tval-merror:0.05916\tval-mlogloss:0.17969\n",
      "[225]\ttest-merror:0.061068\ttest-mlogloss:0.181919\n",
      "====================================================================================================\n",
      "fold 4\n",
      "[0]\ttrain-merror:0.08626\ttrain-mlogloss:1.31131\ttest-merror:0.09936\ttest-mlogloss:1.31258\tval-merror:0.10003\tval-mlogloss:1.31270\n",
      "[25]\ttrain-merror:0.05193\ttrain-mlogloss:0.44462\ttest-merror:0.06419\ttest-mlogloss:0.46451\tval-merror:0.06477\tval-mlogloss:0.46512\n",
      "[50]\ttrain-merror:0.04787\ttrain-mlogloss:0.24161\ttest-merror:0.06280\ttest-mlogloss:0.27209\tval-merror:0.06336\tval-mlogloss:0.27272\n",
      "[75]\ttrain-merror:0.04460\ttrain-mlogloss:0.17460\ttest-merror:0.06147\ttest-mlogloss:0.21449\tval-merror:0.06251\tval-mlogloss:0.21502\n",
      "[100]\ttrain-merror:0.04169\ttrain-mlogloss:0.14696\ttest-merror:0.06119\ttest-mlogloss:0.19525\tval-merror:0.06147\tval-mlogloss:0.19584\n",
      "[125]\ttrain-merror:0.03908\ttrain-mlogloss:0.13296\ttest-merror:0.06121\ttest-mlogloss:0.18830\tval-merror:0.06123\tval-mlogloss:0.18874\n",
      "[150]\ttrain-merror:0.03640\ttrain-mlogloss:0.12317\ttest-merror:0.06063\ttest-mlogloss:0.18510\tval-merror:0.06090\tval-mlogloss:0.18545\n",
      "[175]\ttrain-merror:0.03414\ttrain-mlogloss:0.11625\ttest-merror:0.06072\ttest-mlogloss:0.18383\tval-merror:0.06058\tval-mlogloss:0.18412\n",
      "[200]\ttrain-merror:0.03177\ttrain-mlogloss:0.11007\ttest-merror:0.06086\ttest-mlogloss:0.18305\tval-merror:0.06104\tval-mlogloss:0.18327\n",
      "[225]\ttrain-merror:0.02976\ttrain-mlogloss:0.10509\ttest-merror:0.06082\ttest-mlogloss:0.18274\tval-merror:0.06098\tval-mlogloss:0.18283\n",
      "[250]\ttrain-merror:0.02779\ttrain-mlogloss:0.10086\ttest-merror:0.06090\ttest-mlogloss:0.18274\tval-merror:0.06071\tval-mlogloss:0.18271\n",
      "[241]\ttest-merror:0.060914\ttest-mlogloss:0.182733\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "if 'CURRENT_TIME' in globals():\n",
    "    OUTPUT_DIRPATH, OLD_TIME = os.path.split(OUTPUT_DIRPATH)\n",
    "CURRENT_TIME = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "OUTPUT_DIRPATH = os.path.join(OUTPUT_DIRPATH, CURRENT_TIME)\n",
    "if not os.path.exists(OUTPUT_DIRPATH):\n",
    "    os.makedirs(OUTPUT_DIRPATH)\n",
    "\n",
    "if OPTIMIZE_SPACE:\n",
    "\n",
    "    print('OPTIMIZING SPACE')\n",
    "\n",
    "    param_dict = {}\n",
    "    for name, value in param:\n",
    "        if value == 'merror':\n",
    "            continue\n",
    "        param_dict[name] = value\n",
    "        \n",
    "    param = optimize_hyperparams(bdt_train_dict, bdt_val_dict, bdt_test_dict, param_dict, verbose=True, verbose_eval=50)\n",
    "\n",
    "    with open(os.path.join(OUTPUT_DIRPATH, f'{CURRENT_TIME}_best_params.json'), 'w') as f:\n",
    "        json.dump(param, f)\n",
    "        print(param)\n",
    "\n",
    "    param['eval_metric'] = 'merror'\n",
    "    param = list(param.items()) + [('eval_metric', 'mlogloss')]\n",
    "\n",
    "evals_result_dict = {f\"fold_{fold_idx}\": dict() for fold_idx in range(len(bdt_train_dict))}\n",
    "for fold_idx in range(len(bdt_train_dict)):\n",
    "    print(f\"fold {fold_idx}\")\n",
    "    # Train bdt\n",
    "    evallist = [(bdt_train_dict[f\"fold_{fold_idx}\"], 'train'), (bdt_test_dict[f\"fold_{fold_idx}\"], 'test'), (bdt_val_dict[f\"fold_{fold_idx}\"], 'val')]\n",
    "    booster = xgb.train(\n",
    "        param, bdt_train_dict[f\"fold_{fold_idx}\"], num_boost_round=num_trees, \n",
    "        evals=evallist, early_stopping_rounds=10, verbose_eval=25, evals_result=evals_result_dict[f\"fold_{fold_idx}\"],\n",
    "        # custom_metric=thresholded_weighted_merror\n",
    "    )\n",
    "\n",
    "    booster.save_model(os.path.join(OUTPUT_DIRPATH, f'{CURRENT_TIME}_BDT_fold{fold_idx}.model'))\n",
    "    \n",
    "    # Print perf on test dataset\n",
    "    print(booster.eval(bdt_test_dict[f\"fold_{fold_idx}\"], name='test', iteration=booster.best_iteration))\n",
    "    print('='*100)\n",
    "\n",
    "with open(os.path.join(OUTPUT_DIRPATH, f'{CURRENT_TIME}_BDT_eval_result.json'), 'w') as f:\n",
    "    json.dump(evals_result_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance (ROC) Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_tpr = np.linspace(0, 1, 5000)  # copied from IN evaluate.py file\n",
    "roc_baseline = np.zeros(\n",
    "    (len(bdt_train_dict), len(base_tpr), len(order)), \n",
    "    dtype=float\n",
    ")\n",
    "area_baseline = np.zeros(\n",
    "    (len(bdt_train_dict), len(order)), \n",
    "    dtype=float\n",
    ")\n",
    "\n",
    "BDT_perf = {\n",
    "    sample_name: copy.deepcopy({\n",
    "        'base_tpr': base_tpr,\n",
    "        'class_order': copy.deepcopy(order),\n",
    "        # test data #\n",
    "        'preds': [],\n",
    "        'fprs_density': copy.deepcopy(roc_baseline), 'thresholds_density': copy.deepcopy(roc_baseline), 'areas_density': copy.deepcopy(area_baseline),\n",
    "        'fprs_weighted': copy.deepcopy(roc_baseline), 'thresholds_weighted': copy.deepcopy(roc_baseline), 'areas_weighted': copy.deepcopy(area_baseline),\n",
    "        'fprs_sum_density': copy.deepcopy(roc_baseline[0, ...]), 'thresholds_sum_density': copy.deepcopy(roc_baseline[0, ...]), 'areas_sum_density': copy.deepcopy(area_baseline[0, ...]),\n",
    "        'fprs_sum_weighted': copy.deepcopy(roc_baseline[0, ...]), 'thresholds_sum_weighted': copy.deepcopy(roc_baseline[0, ...]), 'areas_sum_weighted': copy.deepcopy(area_baseline[0, ...]),\n",
    "        # train data #\n",
    "        'train_preds': [], \n",
    "        'train_fprs_density': copy.deepcopy(roc_baseline), 'train_thresholds_density': copy.deepcopy(roc_baseline), 'train_areas_density': copy.deepcopy(area_baseline),\n",
    "        'train_fprs_weighted': copy.deepcopy(roc_baseline), 'train_thresholds_weighted': copy.deepcopy(roc_baseline), 'train_areas_weighted': copy.deepcopy(area_baseline),\n",
    "        'train_fprs_sum_density': copy.deepcopy(roc_baseline[0, ...]), 'train_thresholds_sum_density': copy.deepcopy(roc_baseline[0, ...]), 'train_areas_sum_density': copy.deepcopy(area_baseline[0, ...]),\n",
    "        'train_fprs_sum_weighted': copy.deepcopy(roc_baseline[0, ...]), 'train_thresholds_sum_weighted': copy.deepcopy(roc_baseline[0, ...]), 'train_areas_sum_weighted': copy.deepcopy(area_baseline[0, ...]),\n",
    "        # val data #\n",
    "        'val_preds': [],\n",
    "        'val_fprs_density': copy.deepcopy(roc_baseline), 'val_thresholds_density': copy.deepcopy(roc_baseline), 'val_areas_density': copy.deepcopy(area_baseline),\n",
    "        'val_fprs_weighted': copy.deepcopy(roc_baseline), 'val_thresholds_weighted': copy.deepcopy(roc_baseline), 'val_areas_weighted': copy.deepcopy(area_baseline),\n",
    "        'val_fprs_sum_density': copy.deepcopy(roc_baseline[0, ...]), 'val_thresholds_sum_density': copy.deepcopy(roc_baseline[0, ...]), 'val_areas_sum_density': copy.deepcopy(area_baseline[0, ...]),\n",
    "        'val_fprs_sum_weighted': copy.deepcopy(roc_baseline[0, ...]), 'val_thresholds_sum_weighted': copy.deepcopy(roc_baseline[0, ...]), 'val_areas_sum_weighted': copy.deepcopy(area_baseline[0, ...]),\n",
    "    }) for sample_name in order\n",
    "}\n",
    "\n",
    "for j, sample_name in enumerate(order):\n",
    "\n",
    "    for fold_idx in range(len(bdt_train_dict)):\n",
    "        booster = xgb.Booster(param)\n",
    "\n",
    "        try:\n",
    "            booster.load_model(os.path.join(OUTPUT_DIRPATH, f'{CURRENT_TIME}_BDT_fold{fold_idx}.model'))\n",
    "        except:\n",
    "            raise FileNotFoundError(f\"No model file at fold {fold_idx}.\")\n",
    "    \n",
    "        for pred_type, dataset in [\n",
    "            ('train_', bdt_train_dict[f\"fold_{fold_idx}\"]),\n",
    "            ('val_', bdt_val_dict[f\"fold_{fold_idx}\"]),\n",
    "            ('', bdt_test_dict[f\"fold_{fold_idx}\"])\n",
    "        ]:\n",
    "            \n",
    "            BDT_perf[sample_name][pred_type + 'preds'].append(\n",
    "                booster.predict(\n",
    "                    dataset, \n",
    "                    iteration_range=(0, booster.best_iteration+1)\n",
    "                ).tolist()\n",
    "            )\n",
    "\n",
    "            for i, sample_name_ in enumerate(order):\n",
    "                \n",
    "                if sample_name_ == sample_name:\n",
    "                    event_mask = dataset.get_label() > -1\n",
    "                    pred_rescale = np.ones_like(event_mask)\n",
    "                else:\n",
    "                    event_mask = np.logical_or(dataset.get_label() == j, dataset.get_label() == i)\n",
    "                    pred_rescale = np.array(BDT_perf[sample_name][pred_type + 'preds'][-1])[:, j][event_mask] + np.array(BDT_perf[sample_name][pred_type + 'preds'][-1])[:, i][event_mask]\n",
    "                class_preds = np.array(BDT_perf[sample_name][pred_type + 'preds'][-1])[:, j][event_mask] / pred_rescale\n",
    "                class_truths = np.where(dataset.get_label() == j, 1, 0)[event_mask]\n",
    "                \n",
    "                for roc_type in ['density', 'weighted']:\n",
    "\n",
    "                    if roc_type == 'weighted':\n",
    "                        if re.search('train', pred_type) is not None:\n",
    "                            roc_weights = weights_plot_train[f\"fold_{fold_idx}\"][event_mask]\n",
    "                        elif re.search('val', pred_type) is not None:\n",
    "                            roc_weights = weights_plot_val[f\"fold_{fold_idx}\"][event_mask]\n",
    "                        else:\n",
    "                            roc_weights = weights_plot_test[f\"fold_{fold_idx}\"][event_mask]\n",
    "                    else:\n",
    "                        roc_weights = None\n",
    "\n",
    "                    fpr_bdt, tpr_bdt, threshold_bdt = roc_curve(class_truths, class_preds, sample_weight=roc_weights)\n",
    "                    fpr_bdt = np.interp(base_tpr, tpr_bdt, fpr_bdt)\n",
    "                    threshold_bdt = np.interp(base_tpr, tpr_bdt, threshold_bdt)\n",
    "\n",
    "                    BDT_perf[sample_name][pred_type + 'fprs_' + roc_type][fold_idx][:, i] = fpr_bdt\n",
    "                    BDT_perf[sample_name][pred_type + 'thresholds_' + roc_type][fold_idx][:, i] = threshold_bdt\n",
    "                    BDT_perf[sample_name][pred_type + 'areas_' + roc_type][fold_idx][i] = float(trapezoid(base_tpr, fpr_bdt))\n",
    "    \n",
    "    for pred_type, dataset_dict in [\n",
    "        ('train_', bdt_train_dict),\n",
    "        ('val_', bdt_val_dict),\n",
    "        ('', bdt_test_dict)\n",
    "    ]:\n",
    "\n",
    "        flat_preds = np.concatenate(BDT_perf[sample_name][f'{pred_type}preds'], axis=0)\n",
    "        flat_truths = np.concatenate([dataset_dict[f\"fold_{fold_idx}\"].get_label() for fold_idx in range(len(dataset_dict))], axis=0)\n",
    "\n",
    "        for i, sample_name_ in enumerate(order):\n",
    "            \n",
    "            if sample_name_ == sample_name:\n",
    "                event_mask = flat_truths > -1\n",
    "                pred_rescale = np.ones_like(event_mask)\n",
    "            else:\n",
    "                event_mask = np.logical_or(flat_truths == j, flat_truths == i)\n",
    "                pred_rescale = flat_preds[:, j][event_mask] + flat_preds[:, i][event_mask]\n",
    "            class_preds = flat_preds[:, j][event_mask] / pred_rescale\n",
    "            class_truths = np.where(flat_truths == j, 1, 0)[event_mask]\n",
    "            \n",
    "            for roc_type in ['density', 'weighted']:\n",
    "\n",
    "                if roc_type == 'weighted':\n",
    "                    if re.search('train', pred_type) is not None:\n",
    "                        roc_weights = np.concatenate([weights_plot_train[f\"fold_{fold_idx}\"] for fold_idx in range(len(weights_plot_train))], axis=0)[event_mask]\n",
    "                    elif re.search('val', pred_type) is not None:\n",
    "                        roc_weights = np.concatenate([weights_plot_val[f\"fold_{fold_idx}\"] for fold_idx in range(len(weights_plot_val))], axis=0)[event_mask]\n",
    "                    else:\n",
    "                        roc_weights = np.concatenate([weights_plot_test[f\"fold_{fold_idx}\"] for fold_idx in range(len(weights_plot_test))], axis=0)[event_mask]\n",
    "                else:\n",
    "                    roc_weights = None\n",
    "\n",
    "                fpr_bdt, tpr_bdt, threshold_bdt = roc_curve(class_truths, class_preds, sample_weight=roc_weights)\n",
    "                fpr_bdt = np.interp(base_tpr, tpr_bdt, fpr_bdt)\n",
    "                threshold_bdt = np.interp(base_tpr, tpr_bdt, threshold_bdt)\n",
    "\n",
    "                BDT_perf[sample_name][pred_type + 'fprs_sum_' + roc_type][:, i] = fpr_bdt\n",
    "                BDT_perf[sample_name][pred_type + 'thresholds_sum_' + roc_type][:, i] = threshold_bdt\n",
    "                BDT_perf[sample_name][pred_type + 'areas_sum_' + roc_type][i] = float(trapezoid(base_tpr, fpr_bdt))\n",
    "    \n",
    "    for key in BDT_perf[sample_name].keys():\n",
    "        if type(BDT_perf[sample_name][key]) is list:\n",
    "            continue\n",
    "        BDT_perf[sample_name][key] = BDT_perf[sample_name][key].tolist()\n",
    "\n",
    "\n",
    "with open(os.path.join(OUTPUT_DIRPATH, CURRENT_TIME+f\"_BDT_perf.json\"), 'w') as f:\n",
    "    json.dump(BDT_perf, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_list(list_of_lists):\n",
    "    max_length = np.max([len(list_i) for list_i in list_of_lists])\n",
    "    for list_i in list_of_lists:\n",
    "        while len(list_i) < max_length:\n",
    "            list_i.append(list_i[-1])\n",
    "\n",
    "    return list_of_lists\n",
    "\n",
    "def plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix, format='png'):\n",
    "    plot_prefix = plot_prefix + ('_' if plot_prefix != '' else '')\n",
    "    plot_postfix = plot_postfix + ('_' if plot_postfix != '' else '')\n",
    "    plot_name = plot_prefix + plot_name + plot_postfix + f'.{format}'\n",
    "\n",
    "    plot_filepath = os.path.join(plot_dirpath, plot_name)\n",
    "    return plot_filepath\n",
    "\n",
    "def plot_train_val_losses(\n",
    "    losses_arrs, labels, plot_name, plot_dirpath, \n",
    "    plot_prefix='', plot_postfix='', linestyles=None,\n",
    "    losses_std_arrs=None\n",
    "):\n",
    "    plt.figure(figsize=(9,7))\n",
    "    \n",
    "    if type(losses_arrs[0]) is float:\n",
    "        losses_arrs = [losses_arrs]\n",
    "    if linestyles is None:\n",
    "        linestyles = ['solid'] * len(losses_arrs)\n",
    "    if labels is None:\n",
    "        labels = [i for i in range(len(losses_arrs))]\n",
    "\n",
    "    if losses_std_arrs is not None:\n",
    "        for i in range(len(losses_std_arrs)):\n",
    "            plt.fill_between(\n",
    "                range(len(losses_std_arrs[i])), \n",
    "                losses_arrs[i]+losses_std_arrs[i], losses_arrs[i]-losses_std_arrs[i],\n",
    "                alpha=0.7\n",
    "            )\n",
    "\n",
    "    for i in range(len(losses_arrs)):\n",
    "        plt.plot(\n",
    "            range(len(losses_arrs[i])), \n",
    "            losses_arrs[i], \n",
    "            label=f\"{labels[i]} losses\", linestyle=linestyles[i],\n",
    "            alpha=0.7\n",
    "        )\n",
    "        \n",
    "    plt.legend(bbox_to_anchor=(1, 1))\n",
    "    plt.xlabel('EPOCH')\n",
    "    plt.ylabel('Data Loss')\n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix, format='pdf'), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.close()\n",
    "\n",
    "def plot_rocs(\n",
    "    fprs, tprs, labels, plot_name, plot_dirpath,\n",
    "    plot_prefix='', plot_postfix='', close=True, log=None\n",
    "):\n",
    "    plt.figure(figsize=(9,7))\n",
    "    \n",
    "    for fpr, tpr, label in zip(fprs, tprs, labels):\n",
    "        linestyle = 'solid' if re.search('IN', label) is not None else ('dashed' if re.search('BDT', label) is not None else 'dotted')\n",
    "        plt.plot(fpr, tpr, label=label, linestyle=linestyle)\n",
    "\n",
    "    plt.legend(bbox_to_anchor=(1, 1))\n",
    "    plt.xlabel('Background contamination')\n",
    "    plt.ylabel('Signal efficiency')\n",
    "    if log is not None and re.search('x', log) is not None:\n",
    "        plt.xscale('log')\n",
    "    elif log is not None and re.search('y', log) is not None:\n",
    "        plt.yscale('log')\n",
    "    \n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix, format='pdf'), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    if close:\n",
    "        plt.close()\n",
    "\n",
    "def plot_output_scores(\n",
    "    sigs_and_bkgs, order, plot_name, plot_dirpath,\n",
    "    plot_prefix='', plot_postfix='', bins=1000, weights=None, log=False, arctanh=False\n",
    "):\n",
    "    plt.figure(figsize=(9,7))\n",
    "\n",
    "    if arctanh:\n",
    "        end_point = 6.\n",
    "    else:\n",
    "        end_point = 1.\n",
    "    hist_axis = hist.axis.Regular(bins, 0., end_point, name='var', growth=False, underflow=False, overflow=False)\n",
    "    hists, labels = [], []\n",
    "    for sample_name in order:\n",
    "        if sample_name not in sigs_and_bkgs:\n",
    "            continue\n",
    "        hists.append(\n",
    "            hist.Hist(hist_axis, storage='weight').fill(\n",
    "                var=sigs_and_bkgs[sample_name], \n",
    "                weight=weights[sample_name] if weights is not None else np.ones_like(sigs_and_bkgs[sample_name])\n",
    "            )\n",
    "        )\n",
    "        labels.append(sample_name)\n",
    "    hep.histplot(\n",
    "        hists,\n",
    "        yerr=(True if weights is not None else False),\n",
    "        alpha=0.2, density=(False if weights is not None else True), histtype='step',\n",
    "        label=labels\n",
    "    )\n",
    "\n",
    "    plt.legend(bbox_to_anchor=(1, 1))\n",
    "    plt.xlabel('Output score')\n",
    "    if log:\n",
    "        plt.yscale('log')\n",
    "    \n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix, format='pdf'), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.close()\n",
    "\n",
    "def plot_s_over_root_b(\n",
    "    sig, bkg, label, plot_name, plot_dirpath,\n",
    "    plot_prefix='', plot_postfix='', bins=1000, weights={'sig': None, 'bkg': None},\n",
    "    lines=None, lines_labels=None, line_colors=None, arctanh=False\n",
    "):\n",
    "    plt.figure(figsize=(9,7))\n",
    "\n",
    "    if arctanh:\n",
    "        end_point = 6.\n",
    "        hist_axis = hist.axis.Regular(bins, 0., end_point, name='var', growth=False, underflow=False, overflow=False)\n",
    "    else:\n",
    "        end_point = 1.\n",
    "        hist_axis = hist.axis.Regular(bins, 0., end_point, name='var', growth=False, underflow=False, overflow=False)\n",
    "    sig_hist = hist.Hist(hist_axis, storage='weight').fill(var=sig, weight=weights['sig'] if weights['sig'] is not None else np.ones_like(sig))\n",
    "    bkg_hist = hist.Hist(hist_axis, storage='weight').fill(var=bkg, weight=weights['bkg'] if weights['bkg'] is not None else np.ones_like(bkg))\n",
    "    s_over_root_b_points = sig_hist.values().flatten() / np.sqrt(bkg_hist.values().flatten())\n",
    "    plt.plot(\n",
    "        np.arange(0., end_point, end_point*(1/bins)), s_over_root_b_points, \n",
    "        label=f'{label} - s/âb', alpha=0.8\n",
    "    )\n",
    "\n",
    "    if lines is not None:\n",
    "        for i in range(len(lines)):\n",
    "            plt.vlines(\n",
    "                lines[i], 0, np.max(s_over_root_b_points), \n",
    "                label='s/âb'+(' - '+lines_labels[i] if lines_labels is not None else ''), \n",
    "                alpha=0.5, colors=line_colors[i]\n",
    "            )\n",
    "    \n",
    "    plt.legend(bbox_to_anchor=(1, 1))\n",
    "    plt.xlabel('Output score')\n",
    "    plt.ylabel('s/âb')\n",
    "    \n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix, format='pdf'), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.close()\n",
    "\n",
    "def plot_confusion_matrix(\n",
    "    conf_matrix, class_labels, plot_name, plot_dirpath, \n",
    "    plot_prefix='', plot_postfix=''\n",
    "):\n",
    "    plt.figure(figsize=(9,7))\n",
    "\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=class_labels)\n",
    "    disp.plot(im_kw={'norm': 'log'})\n",
    "    \n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix, format='pdf'), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.close()\n",
    "\n",
    "def plot_feature_importance(\n",
    "    feature_scores, feature_labels, plot_name, plot_dirpath, \n",
    "    plot_prefix='', plot_postfix='', fscore_method='total_gain', log=True\n",
    "):\n",
    "    plt.figure(figsize=(18,14))\n",
    "\n",
    "    plt.barh(\n",
    "        np.arange(len(feature_scores)), feature_scores, align='center'\n",
    "    )\n",
    "    plt.yticks(np.arange(len(feature_scores)), feature_labels, fontsize=8)\n",
    "    plt.ylabel('Features')\n",
    "    plt.xlabel(f'F score ({fscore_method})')\n",
    "    if log:\n",
    "        plt.xscale('log')\n",
    "    \n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.savefig(\n",
    "        plot_filepath(plot_name, plot_dirpath, plot_prefix, plot_postfix, format='pdf'), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_cut_boundaries(sigs, bkgs, weights, bins=10000, arctanh=False):\n",
    "    hist_list_fold = []\n",
    "    cut_boundaries_fold = []\n",
    "    cut_s_over_root_bs_fold = []\n",
    "    sig_weights_fold = []\n",
    "    bkg_weights_fold = []\n",
    "    if len(np.shape(sigs)) == 1:\n",
    "        sigs, bkgs = [sigs], [bkgs] \n",
    "    if arctanh:\n",
    "        end_point = 6.\n",
    "    else:\n",
    "        end_point = 1.\n",
    "    for sig, bkg in zip(sigs, bkgs):\n",
    "        hist_axis = hist.axis.Regular(bins, 0., end_point, name='var', growth=False, underflow=False, overflow=False)\n",
    "        sig_hist = hist.Hist(hist_axis, storage='weight').fill(var=sig, weight=weights['sig'])\n",
    "        bkg_hist = hist.Hist(hist_axis, storage='weight').fill(var=bkg, weight=weights['bkg'])\n",
    "        hist_list_fold.append({'sig': copy.deepcopy(sig_hist), 'bkg': copy.deepcopy(bkg_hist)})\n",
    "\n",
    "        fold_idx_cuts_bins_inclusive = []\n",
    "        fold_idx_sig_weights = []\n",
    "        fold_idx_bkg_weights = []\n",
    "        fold_idx_prev_s_over_root_b = []\n",
    "        prev_s_over_root_b = 0\n",
    "        for i in range(bins):\n",
    "            s = np.sum(sig_hist.values().flatten()[\n",
    "                (bins-1) - i : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "            ])\n",
    "            sqrt_b = np.sqrt(np.sum(bkg_hist.values().flatten()[\n",
    "                (bins-1) - i : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "            ]))\n",
    "            if prev_s_over_root_b < (s / sqrt_b) or s < 0.25:\n",
    "                prev_s_over_root_b = s / sqrt_b\n",
    "                continue\n",
    "            else:\n",
    "                fold_idx_sig_weights.append(\n",
    "                    {\n",
    "                        'value': np.sum(sig_hist.values().flatten()[\n",
    "                            (bins) - i : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                        ]),\n",
    "                        'w2': np.sqrt(np.sum(sig_hist.variances().flatten()[\n",
    "                            (bins) - i : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                        ])),\n",
    "                    }\n",
    "                )\n",
    "                fold_idx_bkg_weights.append(\n",
    "                    {\n",
    "                        'value': np.sum(bkg_hist.values().flatten()[\n",
    "                            (bins) - i : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                        ]),\n",
    "                        'w2': np.sqrt(np.sum(bkg_hist.variances().flatten()[\n",
    "                            (bins) - i : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                        ])),\n",
    "                    }\n",
    "                )\n",
    "                fold_idx_cuts_bins_inclusive.append(bins - i)\n",
    "                fold_idx_prev_s_over_root_b.append(prev_s_over_root_b)\n",
    "                prev_s_over_root_b = 0\n",
    "        fold_idx_sig_weights.append(\n",
    "            {\n",
    "                'value': np.sum(sig_hist.values().flatten()[\n",
    "                    0 : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                ]),\n",
    "                'w2': np.sqrt(np.sum(sig_hist.variances().flatten()[\n",
    "                    0 : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                ])),\n",
    "            }\n",
    "        )\n",
    "        fold_idx_bkg_weights.append(\n",
    "            {\n",
    "                'value': np.sum(bkg_hist.values().flatten()[\n",
    "                    0 : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                ]),\n",
    "                'w2': np.sqrt(np.sum(bkg_hist.variances().flatten()[\n",
    "                    0 : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                ])),\n",
    "            }\n",
    "        )\n",
    "        fold_idx_cuts_bins_inclusive.append(0)\n",
    "        fold_idx_prev_s_over_root_b.append(prev_s_over_root_b)\n",
    "        fold_idx_score_cuts = [end_point * (bin_i / bins) for bin_i in fold_idx_cuts_bins_inclusive]\n",
    "        cut_boundaries_fold.append(fold_idx_score_cuts)\n",
    "        cut_s_over_root_bs_fold.append(fold_idx_prev_s_over_root_b)\n",
    "        sig_weights_fold.append(fold_idx_sig_weights)\n",
    "        bkg_weights_fold.append(fold_idx_bkg_weights)\n",
    "    return cut_boundaries_fold, cut_s_over_root_bs_fold, sig_weights_fold, bkg_weights_fold\n",
    "\n",
    "def p_to_xyz(p, split=True):  # makes a tetrahedron with height 1 and vertices {(0, 0, 0),  (â3/2, 0, â3/2),  (0, â3/2, â3/2),  (â3/2, â3/2, 0)}\n",
    "    rt3o2 = np.sqrt(3) / 2\n",
    "\n",
    "    x = rt3o2 * (0*p[:, 0] + p[:, 1] + p[:, 2] + 0*p[:, 3])\n",
    "    y = rt3o2 * (0*p[:, 0] + 0*p[:, 1] + p[:, 2] + p[:, 3])\n",
    "    z = rt3o2 * (0*p[:, 0] + p[:, 1] + 0*p[:, 2] + p[:, 3])\n",
    "\n",
    "    if split:\n",
    "        return x, y, z\n",
    "    else:\n",
    "        return np.column_stack((x, y, z))\n",
    "\n",
    "def optimize_cuts(\n",
    "    preds: np.ndarray, binary_labels: np.ndarray, weights: np.ndarray,\n",
    "    init_guess=[1e-9, 2e-3, 1e-2], param_names=['r1', 'r2', 'r3'], param_range=[(1e-11, 1e-4), (1e-3, 5e-2), (0., 1.)], \n",
    "    n_steps=int(5e2), verbose: bool=False, min_sig: float=0.2, prefactor: float=1e3, rng_seed: int=21\n",
    "):\n",
    "    xyz_preds = p_to_xyz(preds, split=False)\n",
    "\n",
    "    space  = [Real(float(param_range[i][0]), float(param_range[i][1]), (\"log-uniform\" if param_name == 'r4' else \"uniform\"), name=param_name) for i, param_name in enumerate(param_names)]\n",
    "\n",
    "    def space_transform(X):\n",
    "        triangle_vertices = X['r1']**(1/3) * np.array([\n",
    "            [np.sqrt(3)/2,         0,            np.sqrt(3)/2], \n",
    "            [0,                np.sqrt(3)/2,     np.sqrt(3)/2], \n",
    "            [np.sqrt(3)/2,     np.sqrt(3)/2,                0]\n",
    "        ])\n",
    "\n",
    "        sampled_point = (\n",
    "            (1 - np.sqrt((1 - X['r2']))) * triangle_vertices[0, :]\n",
    "        ) + (\n",
    "            np.sqrt((1 - X['r2']))*(1 - X['r3']) * triangle_vertices[1, :]\n",
    "        ) + (\n",
    "            np.sqrt((1 - X['r2']))*X['r3'] * triangle_vertices[2, :]\n",
    "        )\n",
    "\n",
    "        if verbose:\n",
    "            print(sampled_point)\n",
    "\n",
    "        return sampled_point\n",
    "\n",
    "    @use_named_args(space)\n",
    "    def objective(**X):\n",
    "        if verbose:\n",
    "            print(\"New configuration: {}\".format(X))\n",
    "\n",
    "        thresholds = space_transform(X)\n",
    "        sample_mask = np.all(xyz_preds < thresholds, axis=1)\n",
    "\n",
    "        # print(f\"total sig = {np.sum(weights[binary_labels == 1])}\")\n",
    "        # print(f\"total bkg = {np.sum(weights[binary_labels == 0])}\")\n",
    "\n",
    "        num_sig = np.abs(\n",
    "            np.sum(\n",
    "                weights[\n",
    "                    np.logical_and(\n",
    "                        binary_labels == 1,\n",
    "                        sample_mask\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "\n",
    "        num_bkg = np.abs(\n",
    "            np.sum(\n",
    "                weights[\n",
    "                    np.logical_and(\n",
    "                        binary_labels == 0,\n",
    "                        sample_mask\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "\n",
    "        s_over_root_b = num_sig / np.sqrt(num_bkg)\n",
    "\n",
    "        if num_sig == 0 and num_bkg == 0:\n",
    "            both_0 = prefactor*1e1\n",
    "            if verbose:\n",
    "                print(f\"both sig and bkg 0 at this hyperplane => {both_0}\")\n",
    "            return both_0\n",
    "        elif num_sig < min_sig:\n",
    "            small_sig = prefactor*0\n",
    "            if verbose:\n",
    "                print(f\"too little sig ({num_sig}) at this hyperplane => {small_sig}\")\n",
    "            return small_sig\n",
    "        elif num_bkg == 0:\n",
    "            zero_bkg = -prefactor*num_sig\n",
    "            if verbose:\n",
    "                print(f\"zero bkg at this hyperplane (likely due to finite data rather than real bkg-free zone) => {zero_bkg}\")\n",
    "            return zero_bkg\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"s/âb = {s_over_root_b}, s = {num_sig}, b = {num_bkg}\")\n",
    "\n",
    "        return -prefactor*s_over_root_b\n",
    "    \n",
    "    res_gp = gp_minimize(\n",
    "        objective, space, random_state=rng_seed, \n",
    "        n_calls=(n_steps + (1 if len(np.shape(init_guess)) == 1 else np.shape(init_guess)[0])), \n",
    "        n_initial_points=n_steps, x0=init_guess\n",
    "    )\n",
    "\n",
    "    opt_params = [float(res_gp.x[i]) for i in range(len(space))]\n",
    "    opt_cuts = [float(opt_cut) for opt_cut in space_transform({param_names[i]: res_gp.x[i] for i in range(len(param_names))})]\n",
    "    if verbose:\n",
    "        print(\"Best parameters: {}\".format(opt_cuts))\n",
    "        print(f\"Best s/âb = {-res_gp.fun / prefactor}\")\n",
    "\n",
    "    return opt_cuts, opt_params\n",
    "\n",
    "\n",
    "def multi_optimize_cut_boundaries(preds: list, binary_labels: np.ndarray, weights: np.ndarray, num_categories: int=3, min_sig: float=0.2):\n",
    "    init_param_range = [(1e-8, 1e-7), (1e-6, 1e-5), (1e-2, 1e-1)]\n",
    "    init_guess = [5e-8, 5e-6, 5e-2]\n",
    "    clf_dict = {}\n",
    "    param_clf_dict = {}\n",
    "    for cat in range(num_categories):\n",
    "\n",
    "        clf_dict[cat] = []\n",
    "        param_clf_dict[cat] = []\n",
    "\n",
    "        if cat == 0:\n",
    "            sliced_preds = np.array(preds)\n",
    "            sliced_labels = binary_labels\n",
    "            sliced_weights = weights\n",
    "            param_range = init_param_range\n",
    "            guess = init_guess\n",
    "\n",
    "        else:\n",
    "            slice_array = np.ones_like(binary_labels, dtype=bool)\n",
    "            for prev_cat in range(cat):\n",
    "                slice_array = np.logical_and(\n",
    "                    slice_array,\n",
    "                    np.logical_not(\n",
    "                        np.all(\n",
    "                            p_to_xyz(np.array(preds), split=False) < clf_dict[prev_cat], \n",
    "                            axis=1\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            sliced_preds = np.array(preds)[slice_array]\n",
    "            sliced_labels = binary_labels[slice_array]\n",
    "            sliced_weights = weights[slice_array]\n",
    "            # param_range = [(param_clf_dict[cat-1][0], init_param_range[0][1]), (param_clf_dict[cat-1][1], init_param_range[1][1]), init_param_range[2]]\n",
    "            # guess = [param_clf_dict[cat-1][0] + 1e-11, param_clf_dict[cat-1][1] + 1e-11, 0.5 * init_param_range[2][1]]\n",
    "            param_range = init_param_range\n",
    "            guess = init_guess\n",
    "            \n",
    "        opt_cuts, opt_params = optimize_cuts(\n",
    "            sliced_preds, sliced_labels, sliced_weights, verbose=False,\n",
    "            param_range=param_range, init_guess=guess, n_steps=200, min_sig=min_sig, rng_seed=None\n",
    "        )\n",
    "\n",
    "        clf_dict[cat] = opt_cuts\n",
    "        param_clf_dict[cat] = opt_params\n",
    "\n",
    "    return clf_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "MC_NAMES_PRETTY = {\n",
    "    \"GGJets\": r\"$\\gamma\\gamma+3j$\",\n",
    "    \"GJetPt20To40\": r\"$\\gamma+j$, 20<$p_T$<40GeV\",\n",
    "    \"GJetPt40\": r\"$\\gamma+j$, 40GeV<$p_T$\",\n",
    "    \"GluGluHToGG\": r\"ggF $H\\rightarrow \\gamma\\gamma$\",\n",
    "    \"VBFHToGG\": r\"VBF $H\\rightarrow \\gamma\\gamma$\",\n",
    "    \"VHToGG\": r\"V$H\\rightarrow\\gamma\\gamma$\",\n",
    "    \"ttHToGG\": r\"$t\\bar{t}H\\rightarrow\\gamma\\gamma$\",\n",
    "    \"GluGluToHH\": r\"ggF $HH\\rightarrow bb\\gamma\\gamma$\",\n",
    "    # \"VBFHHto2B2G_CV_1_C2V_1_C3_1\": r\"VBF $HH\\rightarrow bb\\gamma\\gamma$\",\n",
    "    \"signal\": r\"ggF $HH\\rightarrow bb\\gamma\\gamma$ + VBF $HH\\rightarrow bb\\gamma\\gamma$\",\n",
    "    # Names for order #\n",
    "    \"ggF HH\": r\"ggF $H\\rightarrow \\gamma\\gamma$\",\n",
    "    \"ttH\": r\"$t\\bar{t}H\\rightarrow\\gamma\\gamma$\",\n",
    "    \"single-H\": r\"ggF $H\\rightarrow \\gamma\\gamma$ + VBF $H\\rightarrow \\gamma\\gamma$ + V$H\\rightarrow\\gamma\\gamma$\",\n",
    "    \"non-res\": r\"$\\gamma\\gamma+3j$ + $\\gamma+j$, 20GeV<$p_T$\",\n",
    "    \"VH\": r\"V$H\\rightarrow\\gamma\\gamma$\",\n",
    "    \"non-res + ggFH + VBFH\": r\"$\\gamma\\gamma+3j$ + $\\gamma+j$, 20GeV<$p_T$ + ggF $H\\rightarrow \\gamma\\gamma$ + VBF $H\\rightarrow \\gamma\\gamma$\"\n",
    "    # Need to fill in pretty print for BSM samples #\n",
    "}\n",
    "LUMINOSITIES = {\n",
    "    '2022preEE': 7.9804, \n",
    "    '2022postEE': 26.6717,\n",
    "    # Need to fill in lumis for other eras #\n",
    "}\n",
    "LUMINOSITIES['total_lumi'] = sum(LUMINOSITIES.values())\n",
    "\n",
    "# Dictionary of variables\n",
    "VARIABLES = {\n",
    "    # key: hist.axis axes for plotting #\n",
    "    # MET variables\n",
    "    'puppiMET_sumEt': hist.axis.Regular(40, 150., 2000, name='var', label=r'puppiMET $\\Sigma E_T$ [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'puppiMET_pt': hist.axis.Regular(40, 20., 250, name='var', label=r'puppiMET $p_T$ [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'puppiMET_phi': hist.axis.Regular(20,-3.2, 3.2, name='var', label=r'puppiMET $\\phi$', growth=False, underflow=False, overflow=False), \n",
    "    # jet-MET variables\n",
    "    'DeltaPhi_j1MET': hist.axis.Regular(20,-3.2, 3.2, name='var', label=r'$\\Delta\\phi (j_1,E_T^{miss})$', growth=False, underflow=False, overflow=False), \n",
    "    'DeltaPhi_j2MET': hist.axis.Regular(20, -3.2, 3.2, name='var', label=r'$\\Delta\\phi (j_2,E_T^{miss})$', growth=False, underflow=False, overflow=False), \n",
    "    # jet-photon variables\n",
    "    'DeltaR_jg_min': hist.axis.Regular(30, 0, 5, name='var', label=r'min$(\\Delta R(jet, \\gamma))$', growth=False, underflow=False, overflow=False), \n",
    "    # jet variables\n",
    "    # 'jet1_pt': hist.axis.Regular(40, 20., 250, name='var', label=r'lead jet $p_T$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    # 'jet2_pt': hist.axis.Regular(40, 20., 250, name='var', label=r'sublead jet $p_T$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    'lead_bjet_pt': hist.axis.Regular(40, 20., 250, name='var', label=r'lead bjet $p_T$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    'lead_bjet_eta': hist.axis.Regular(20, -5., 5., name='var', label=r'lead bjet $\\eta$', growth=False, underflow=False, overflow=False),\n",
    "    'lead_bjet_phi': hist.axis.Regular(20, -3.2, 3.2, name='var', label=r'lead bjet $\\phi$', growth=False, underflow=False, overflow=False),\n",
    "    'sublead_bjet_pt': hist.axis.Regular(40, 20., 250, name='var', label=r'lead bjet $p_T$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    'sublead_bjet_eta': hist.axis.Regular(20, -5., 5., name='var', label=r'lead bjet $\\eta$', growth=False, underflow=False, overflow=False),\n",
    "    'sublead_bjet_phi': hist.axis.Regular(20, -3.2, 3.2, name='var', label=r'lead bjet $\\phi$', growth=False, underflow=False, overflow=False),\n",
    "    'n_jets': hist.axis.Integer(0, 10, name='var', label=r'$n_{jets}$', growth=False, underflow=False, overflow=False), \n",
    "    'chi_t0': hist.axis.Regular(40, 0., 150, name='var', label=r'$\\chi_{t0}^2$', growth=False, underflow=False, overflow=False), \n",
    "    'chi_t1': hist.axis.Regular(30, 0., 500, name='var', label=r'$\\chi_{t1}^2$', growth=False, underflow=False, overflow=False), \n",
    "    # lepton variables\n",
    "    'n_leptons': hist.axis.Integer(0, 10, name='var', label=r'$n_{leptons}$', growth=False, underflow=False, overflow=False),\n",
    "    'lepton1_pt': hist.axis.Regular(40, 0., 200., name='var', label=r'lead lepton $p_T$ [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'lepton2_pt': hist.axis.Regular(40, 0., 200., name='var', label=r'sublead lepton $p_T$ [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'lepton1_eta': hist.axis.Regular(30, -5., 5., name='var', label=r'lead lepton $\\eta$', growth=False, underflow=False, overflow=False), \n",
    "    'lepton2_eta': hist.axis.Regular(30, -5., 5., name='var', label=r'sublead lepton $\\eta$', growth=False, underflow=False, overflow=False),\n",
    "    'lepton1_phi': hist.axis.Regular(20, -3.2, 3.2, name='var', label=r'lead lepton $\\phi$', growth=False, underflow=False, overflow=False), \n",
    "    'lepton2_phi': hist.axis.Regular(20, -3.2, 3.2, name='var', label=r'sublead lepton $\\phi$', growth=False, underflow=False, overflow=False),\n",
    "    # diphoton variables\n",
    "    'pt': hist.axis.Regular(40, 20., 2000, name='var', label=r' $\\gamma\\gamma p_{T}$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    'eta': hist.axis.Regular(20, -5., 5., name='var', label=r'$\\gamma\\gamma \\eta$', growth=False, underflow=False, overflow=False), \n",
    "    'phi': hist.axis.Regular(20, -3.2, 3.2, name='var', label=r'$\\gamma \\gamma \\phi$', growth=False, underflow=False, overflow=False),\n",
    "    # angular (cos) variables\n",
    "    'abs_CosThetaStar_CS': hist.axis.Regular(20, 0, 1, name='var', label=r'|cos$(\\theta_{CS})$|', growth=False, underflow=False, overflow=False), \n",
    "    'abs_CosThetaStar_jj': hist.axis.Regular(20, 0, 1, name='var', label=r'|cos$(\\theta_{jj})$|', growth=False, underflow=False, overflow=False),\n",
    "    'CosThetaStar_CS': hist.axis.Regular(20, -1, 1, name='var', label=r'cos$(\\theta_{CS})$', growth=False, underflow=False, overflow=False), \n",
    "    'CosThetaStar_jj': hist.axis.Regular(20, -1, 1, name='var', label=r'cos$(\\theta_{jj})$', growth=False, underflow=False, overflow=False), \n",
    "    # jet-lepton variables\n",
    "    'leadBjet_leadLepton': hist.axis.Regular(30, 0, 5, name='var', label=r'$\\Delta R(bjet_{lead}, l_{lead})$', growth=False, underflow=False, overflow=False), \n",
    "    'leadBjet_subleadLepton': hist.axis.Regular(30, 0, 5, name='var', label=r'$\\Delta R(bjet_{lead}, l_{sublead})$', growth=False, underflow=False, overflow=False), \n",
    "    'subleadBjet_leadLepton': hist.axis.Regular(30, 0, 5, name='var', label=r'$\\Delta R(bjet_{sublead}, l_{lead})$', growth=False, underflow=False, overflow=False), \n",
    "    'subleadBjet_subleadLepton': hist.axis.Regular(30, 0, 5, name='var', label=r'$\\Delta R(bjet_{sublead}, l_{sublead})$', growth=False, underflow=False, overflow=False),\n",
    "    # dijet variables (must be blinded on data)\n",
    "    'dijet_mass': hist.axis.Regular(25, 25., 180., name='var', label=r'$M_{jj}$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    # diphoton variables (must be blinded on data)\n",
    "    'mass': hist.axis.Regular(25, 25., 180., name='var', label=r'$M_{\\gamma\\gamma}$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    # Yibo's BDT variables\n",
    "    'lead_mvaID': hist.axis.Regular(50, -1., 1., name='var', label=r'$\\gamma_{lead}$ MVA ID', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_mvaID': hist.axis.Regular(50, -1., 1., name='var', label=r'$\\gamma_{sublead}$ MVA ID', growth=False, underflow=False, overflow=False),\n",
    "    'CosThetaStar_gg': hist.axis.Regular(50, -1., 1., name='var', label=r'cos$(\\theta_{gg})$', growth=False, underflow=False, overflow=False),\n",
    "    'lead_pt_over_Mgg': hist.axis.Regular(50, 0., 1., name='var', label=r'$p_{T,\\gamma_1} / M_{\\gamma\\gamma}$', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_pt_over_Mgg': hist.axis.Regular(50, 0., 1., name='var', label=r'$p_{T,\\gamma_2} / M_{\\gamma\\gamma}$', growth=False, underflow=False, overflow=False),\n",
    "    'lead_sigmaE_over_E': hist.axis.Regular(50, 0., 1., name='var', label=r'$\\sigma {E,\\gamma_1} / E_{\\gamma\\gamma}$', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_sigmaE_over_E': hist.axis.Regular(50, 0., 1., name='var', label=r'$\\sigma {E,\\gamma_2} / E_{\\gamma\\gamma}$', growth=False, underflow=False, overflow=False),\n",
    "    'lead_bjet_pt_over_Mjj': hist.axis.Regular(50, 0., 1., name='var', label=r'$p_{T,j1} / M_{jj}$', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_bjet_pt_over_Mjj': hist.axis.Regular(50, 0., 1., name='var', label=r'$p_{T,j2} / M_{jj}$', growth=False, underflow=False, overflow=False),\n",
    "    'lead_bjet_btagPNetB': hist.axis.Regular(50, -1., 1., name='var', label=r'$j_{lead}$ PNet btag score', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_bjet_btagPNetB': hist.axis.Regular(50, -1., 1., name='var', label=r'$j_{sublead}$ PNet btag score', growth=False, underflow=False, overflow=False),\n",
    "    'lead_bjet_sigmapT_over_pT': hist.axis.Regular(50, 0., 1., name='var', label=r'$\\sigma p_{T,j1} / p_{T,jj}$', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_bjet_sigmapT_over_pT': hist.axis.Regular(50, 0., 1., name='var', label=r'$\\sigma p_{T,j2} / p_{T,jj}$', growth=False, underflow=False, overflow=False),\n",
    "    'dipho_mass_over_Mggjj': hist.axis.Regular(50, 0., 1., name='var', label=r'$M_{\\gamma\\gamma} / M_{\\gamma\\gamma jj}$', growth=False, underflow=False, overflow=False), \n",
    "    'dijet_mass_over_Mggjj': hist.axis.Regular(50, 0., 1., name='var', label=r'$M_{jj} / M_{\\gamma\\gamma jj}$', growth=False, underflow=False, overflow=False),\n",
    "    # My variables for non-reso reduction #\n",
    "    'lead_pfRelIso03_all_quadratic': hist.axis.Regular(50, -1., 1., name='var', label=r'$\\gamma_{lead}$ PF RelIso03 all quad.', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_pfRelIso03_all_quadratic': hist.axis.Regular(50, -1., 1., name='var', label=r'$\\gamma_{sublead}$ PF RelIso03 all quad.', growth=False, underflow=False, overflow=False),\n",
    "    # Michael's DNN variables #\n",
    "    'DeltaR_j1g1': hist.axis.Regular(50, 0., 5., name='var', label=r'$\\Delta R(bjet_{lead}, \\gamma_{lead})$', growth=False, underflow=False, overflow=False), \n",
    "    'DeltaR_j1g2': hist.axis.Regular(50, 0., 5., name='var', label=r'$\\Delta R(bjet_{lead}, \\gamma_{sublead})$', growth=False, underflow=False, overflow=False), \n",
    "    'DeltaR_j2g1': hist.axis.Regular(50, 0., 5., name='var', label=r'$\\Delta R(bjet_{sublead}, \\gamma_{lead})$', growth=False, underflow=False, overflow=False), \n",
    "    'DeltaR_j2g2': hist.axis.Regular(50, 0., 5., name='var', label=r'$\\Delta R(bjet_{sublead}, \\gamma_{sublead})$', growth=False, underflow=False, overflow=False),\n",
    "    'HHbbggCandidate_pt': hist.axis.Regular(100, 0., 700., name='var', label=r'HH $p_T$ [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'HHbbggCandidate_eta': hist.axis.Regular(50, -5., 5., name='var', label=r'HH $\\eta$', growth=False, underflow=False, overflow=False), \n",
    "    'HHbbggCandidate_phi': hist.axis.Regular(50, -3.2, 3.2, name='var', label=r'HH $\\phi$', growth=False, underflow=False, overflow=False),\n",
    "    'HHbbggCandidate_mass': hist.axis.Regular(25, 0., 700., name='var', label=r'$M_{HH}$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    # ATLAS variables #\n",
    "    'pt_balance': hist.axis.Regular(100, 0., 2., name='var', label=r'$p_{T,HH} / (p_{T,\\gamma1} + p_{T,\\gamma2} + p_{T,j1} + p_{T,j2})$', growth=False, underflow=False, overflow=False), \n",
    "    # VH variables #\n",
    "    'DeltaPhi_jj': hist.axis.Regular(20, -3.2, 3.2, name='var', label=r'$\\Delta\\phi (j_1,j_2)$', growth=False, underflow=False, overflow=False),\n",
    "    'DeltaEta_jj': hist.axis.Regular(20, 0., 10., name='var', label=r'$\\Delta\\eta (j_1,j_2)$', growth=False, underflow=False, overflow=False),\n",
    "    'isr_jet_pt': hist.axis.Regular(100, 0., 200., name='var', label=r'ISR jet $p_T$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    'DeltaPhi_isr_jet_z': hist.axis.Regular(20, -3.2, 3.2, name='var', label=r'$\\Delta\\phi (j_{ISR},jj)$', growth=False, underflow=False, overflow=False),\n",
    "    'dijet_pt': hist.axis.Regular(100, 0., 500., name='var', label=r'jj $p_T$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "}\n",
    "# Dictionary of variables to do MC/Data comparison\n",
    "VARIABLES_STD = {\n",
    "    # key: hist.axis axes for plotting #\n",
    "    # MET variables\n",
    "    'puppiMET_sumEt': hist.axis.Regular(40, -4., 4., name='var', label=r'puppiMET ln($\\Sigma E_T$) [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'puppiMET_pt': hist.axis.Regular(40, -4., 4., name='var', label=r'puppiMET ln($p_T$) [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'puppiMET_phi': hist.axis.Regular(40, -4., 4., name='var', label=r'puppiMET $\\phi$', growth=False, underflow=False, overflow=False), \n",
    "    # jet-MET variables\n",
    "    'DeltaPhi_j1MET': hist.axis.Regular(40, -4., 4., name='var', label=r'$\\Delta\\phi (j_1,E_T^{miss})$', growth=False, underflow=False, overflow=False), \n",
    "    'DeltaPhi_j2MET': hist.axis.Regular(40, -4., 4., name='var', label=r'$\\Delta\\phi (j_2,E_T^{miss})$', growth=False, underflow=False, overflow=False), \n",
    "    # jet-photon variables\n",
    "    'DeltaR_jg_min': hist.axis.Regular(40, -4., 4., name='var', label=r'min$(\\Delta R(jet, \\gamma))$', growth=False, underflow=False, overflow=False), \n",
    "    # jet variables\n",
    "    'lead_bjet_pt': hist.axis.Regular(40, -4., 4., name='var', label=r'lead bjet ln($p_T$) [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_bjet_pt': hist.axis.Regular(40, -4., 4., name='var', label=r'sublead bjet ln($p_T$) [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'lead_bjet_eta': hist.axis.Regular(40, -4., 4., name='var', label=r'lead bjet $\\eta$', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_bjet_eta': hist.axis.Regular(40, -4., 4., name='var', label=r'sublead bjet $\\eta$', growth=False, underflow=False, overflow=False),\n",
    "    'lead_bjet_phi': hist.axis.Regular(40, -4., 4., name='var', label=r'lead bjet $\\phi$', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_bjet_phi': hist.axis.Regular(40, -4., 4., name='var', label=r'sublead bjet $\\phi$', growth=False, underflow=False, overflow=False),\n",
    "    'n_jets': hist.axis.Regular(12, -4., 4., name='var', label=r'$n_{jets}$', growth=False, underflow=False, overflow=False), \n",
    "    'chi_t0': hist.axis.Regular(40, -4., 10., name='var', label=r'ln($\\chi_{t0}^2$)', growth=False, underflow=False, overflow=False), \n",
    "    'chi_t1': hist.axis.Regular(40, -4., 10., name='var', label=r'ln($\\chi_{t1}^2$)', growth=False, underflow=False, overflow=False), \n",
    "    # lepton variables\n",
    "    'n_leptons': hist.axis.Regular(12, -4., 4., name='var', label=r'$n_{leptons}$', growth=False, underflow=False, overflow=False),\n",
    "    'lepton1_pt': hist.axis.Regular(40, -4., 4., name='var', label=r'lead lepton ln($p_T$) [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'lepton2_pt': hist.axis.Regular(40, -4., 4., name='var', label=r'sublead lepton ln($p_T$) [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'lepton1_eta': hist.axis.Regular(40, -4., 4., name='var', label=r'lead lepton $\\eta$', growth=False, underflow=False, overflow=False), \n",
    "    'lepton2_eta': hist.axis.Regular(40, -4., 4., name='var', label=r'sublead lepton $\\eta$', growth=False, underflow=False, overflow=False),\n",
    "    'lepton1_phi': hist.axis.Regular(40, -4., 4., name='var', label=r'lead lepton $\\phi$', growth=False, underflow=False, overflow=False), \n",
    "    'lepton2_phi': hist.axis.Regular(40, -4., 4., name='var', label=r'sublead lepton $\\phi$', growth=False, underflow=False, overflow=False),\n",
    "    # diphoton variables\n",
    "    'pt': hist.axis.Regular(40, -4., 4., name='var', label=r' $\\gamma\\gamma$ ln($p_{T}$) [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    'eta': hist.axis.Regular(40, -4., 4., name='var', label=r'$\\gamma\\gamma \\eta$', growth=False, underflow=False, overflow=False), \n",
    "    'phi': hist.axis.Regular(40, -4., 4., name='var', label=r'$\\gamma \\gamma \\phi$', growth=False, underflow=False, overflow=False),\n",
    "    # angular (cos) variables\n",
    "    'abs_CosThetaStar_CS': hist.axis.Regular(40, -4., 4., name='var', label=r'|cos$(\\theta_{CS})$|', growth=False, underflow=False, overflow=False), \n",
    "    'abs_CosThetaStar_jj': hist.axis.Regular(40, -4., 4., name='var', label=r'|cos$(\\theta_{jj})$|', growth=False, underflow=False, overflow=False), \n",
    "    'CosThetaStar_CS': hist.axis.Regular(40, -1., 1., name='var', label=r'cos$(\\theta_{CS})$', growth=False, underflow=False, overflow=False), \n",
    "    'CosThetaStar_jj': hist.axis.Regular(40, -1., 1., name='var', label=r'cos$(\\theta_{jj})$', growth=False, underflow=False, overflow=False), \n",
    "    # jet-lepton variables\n",
    "    'leadBjet_leadLepton': hist.axis.Regular(40, -4., 4., name='var', label=r'$\\Delta R(bjet_{lead}, l_{lead})$', growth=False, underflow=False, overflow=False), \n",
    "    'leadBjet_subleadLepton': hist.axis.Regular(40, -4., 4., name='var', label=r'$\\Delta R(bjet_{lead}, l_{sublead})$', growth=False, underflow=False, overflow=False), \n",
    "    'subleadBjet_leadLepton': hist.axis.Regular(40, -4., 4., name='var', label=r'$\\Delta R(bjet_{sublead}, l_{lead})$', growth=False, underflow=False, overflow=False), \n",
    "    'subleadBjet_subleadLepton': hist.axis.Regular(40, -4., 4., name='var', label=r'$\\Delta R(bjet_{sublead}, l_{sublead})$', growth=False, underflow=False, overflow=False),\n",
    "    # dijet variables (must be blinded on data)\n",
    "    'dijet_mass': hist.axis.Regular(40, -4., 4., name='var', label=r'ln($M_{jj}$) [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    # diphoton variables (must be blinded on data)\n",
    "    'mass': hist.axis.Regular(40, -4., 4., name='var', label=r'$M_{\\gamma\\gamma}$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    # Yibo's BDT variables\n",
    "    'lead_mvaID': hist.axis.Regular(50, -4., 4., name='var', label=r'$\\gamma_{lead}$ MVA ID', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_mvaID': hist.axis.Regular(50, -4., 4., name='var', label=r'$\\gamma_{sublead}$ MVA ID', growth=False, underflow=False, overflow=False),\n",
    "    'CosThetaStar_gg': hist.axis.Regular(50, -1., 1., name='var', label=r'cos$(\\theta_{gg})$', growth=False, underflow=False, overflow=False),\n",
    "    'lead_pt_over_Mgg': hist.axis.Regular(50, -4., 4., name='var', label=r'$p_{T,\\gamma_1} / M_{\\gamma\\gamma}$', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_pt_over_Mgg': hist.axis.Regular(50, -4., 4., name='var', label=r'$p_{T,\\gamma_2} / M_{\\gamma\\gamma}$', growth=False, underflow=False, overflow=False),\n",
    "    'lead_sigmaE_over_E': hist.axis.Regular(50, -4., 4., name='var', label=r'$\\sigma {E,\\gamma_1} / E_{\\gamma\\gamma}$', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_sigmaE_over_E': hist.axis.Regular(50, -4., 4., name='var', label=r'$\\sigma {E,\\gamma_2} / E_{\\gamma\\gamma}$', growth=False, underflow=False, overflow=False),\n",
    "    'lead_bjet_pt_over_Mjj': hist.axis.Regular(50, -4., 4., name='var', label=r'$p_{T,j1} / M_{jj}$', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_bjet_pt_over_Mjj': hist.axis.Regular(50, -4., 4., name='var', label=r'$p_{T,j2} / M_{jj}$', growth=False, underflow=False, overflow=False),\n",
    "    'lead_bjet_btagPNetB': hist.axis.Regular(50, -4., 4., name='var', label=r'$j_{lead}$ PNet btag score', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_bjet_btagPNetB': hist.axis.Regular(50, -4., 4., name='var', label=r'$j_{sublead}$ PNet btag score', growth=False, underflow=False, overflow=False),\n",
    "    'lead_bjet_sigmapT_over_pT': hist.axis.Regular(50, -4., 4., name='var', label=r'$\\sigma p_{T,j1} / p_{T,jj}$', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_bjet_sigmapT_over_pT': hist.axis.Regular(50, -4., 4., name='var', label=r'$\\sigma p_{T,j2} / p_{T,jj}$', growth=False, underflow=False, overflow=False),\n",
    "    'dipho_mass_over_Mggjj': hist.axis.Regular(50, -4., 4., name='var', label=r'$M_{\\gamma\\gamma} / M_{\\gamma\\gamma jj}$', growth=False, underflow=False, overflow=False), \n",
    "    'dijet_mass_over_Mggjj': hist.axis.Regular(50, -4., 4., name='var', label=r'$M_{jj} / M_{\\gamma\\gamma jj}$', growth=False, underflow=False, overflow=False),\n",
    "    # My variables for non-reso reduction #\n",
    "    'lead_pfRelIso03_all_quadratic': hist.axis.Regular(50, -4., 4., name='var', label=r'$\\gamma_{lead}$ PF RelIso03 all quad.', growth=False, underflow=False, overflow=False), \n",
    "    'sublead_pfRelIso03_all_quadratic': hist.axis.Regular(50, -4., 4., name='var', label=r'$\\gamma_{sublead}$ PF RelIso03 all quad.', growth=False, underflow=False, overflow=False),\n",
    "    # Michael's DNN variables #\n",
    "    'DeltaR_j1g1': hist.axis.Regular(50, -4., 4., name='var', label=r'$\\Delta R(bjet_{lead}, \\gamma_{lead})$', growth=False, underflow=False, overflow=False), \n",
    "    'DeltaR_j1g2': hist.axis.Regular(50, -4., 4., name='var', label=r'$\\Delta R(bjet_{lead}, \\gamma_{sublead})$', growth=False, underflow=False, overflow=False), \n",
    "    'DeltaR_j2g1': hist.axis.Regular(50, -4., 4., name='var', label=r'$\\Delta R(bjet_{sublead}, \\gamma_{lead})$', growth=False, underflow=False, overflow=False), \n",
    "    'DeltaR_j2g2': hist.axis.Regular(50, -4., 4., name='var', label=r'$\\Delta R(bjet_{sublead}, \\gamma_{sublead})$', growth=False, underflow=False, overflow=False),\n",
    "    'HHbbggCandidate_pt': hist.axis.Regular(100, -4., 4., name='var', label=r'HH ln($p_T$) [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'HHbbggCandidate_eta': hist.axis.Regular(50, -4., 4., name='var', label=r'HH $\\eta$', growth=False, underflow=False, overflow=False), \n",
    "    'HHbbggCandidate_phi': hist.axis.Regular(50, -4., 4., name='var', label=r'HH $\\phi$', growth=False, underflow=False, overflow=False),\n",
    "    'HHbbggCandidate_mass': hist.axis.Regular(50, -4., 4., name='var', label=r'ln($M_{HH}$) [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    # ATLAS variables #\n",
    "    'pt_balance': hist.axis.Regular(100, -4., 4., name='var', label=r'ln($p_{T,HH} / (p_{T,\\gamma1} + p_{T,\\gamma2} + p_{T,j1} + p_{T,j2})$)', growth=False, underflow=False, overflow=False), \n",
    "    # VH variables #\n",
    "    'DeltaPhi_jj': hist.axis.Regular(20, -4., 4., name='var', label=r'$\\Delta\\phi (j_1,j_2)$', growth=False, underflow=False, overflow=False),\n",
    "    'DeltaEta_jj': hist.axis.Regular(20, -4., 4., name='var', label=r'$\\Delta\\eta (j_1,j_2)$', growth=False, underflow=False, overflow=False),\n",
    "    'isr_jet_pt': hist.axis.Regular(100, -4., 4., name='var', label=r'ISR jet ln($p_T$) [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    'DeltaPhi_isr_jet_z': hist.axis.Regular(20, -4., 4., name='var', label=r'$\\Delta\\phi (j_{ISR},jj)$', growth=False, underflow=False, overflow=False),\n",
    "    'dijet_pt': hist.axis.Regular(100, -4., 4., name='var', label=r'jj ln($p_T$) [GeV]', growth=False, underflow=False, overflow=False),\n",
    "}\n",
    "\n",
    "\n",
    "def make_input_plot(\n",
    "    output_dir, var_name, hist_list, fold_idx=None, labels=None, density=True, \n",
    "    plot_prefix='', plot_postfix='', alpha=0.8, linestyle=True\n",
    "):\n",
    "    fig, ax = plt.subplots()\n",
    "    if linestyle:\n",
    "        if fold_idx is not None:\n",
    "            linestyles = [\"solid\", \"dashed\", \"dotted\", \"solid\", \"dashed\", \"dotted\"]\n",
    "        else:\n",
    "            linestyles = [\"solid\", \"dotted\", \"solid\", \"dotted\"]\n",
    "        linestyles = linestyles * ((len(hist_list) // len(linestyles)) + 1)\n",
    "        linestyles = linestyles[:len(hist_list)]\n",
    "    else:\n",
    "        linestyles = None\n",
    "    hep.histplot(\n",
    "        hist_list, ax=ax, linewidth=3, histtype=\"step\", yerr=True, density=density,\n",
    "        linestyle=linestyles, label=labels, alpha=alpha\n",
    "    )\n",
    "    # Plotting niceties #\n",
    "    hep.cms.lumitext(f\"{LUMINOSITIES['total_lumi']:.2f}\" + r\"fb$^{-1}$ (13.6 TeV)\", ax=ax)\n",
    "    hep.cms.text(\"Work in Progress\", ax=ax)\n",
    "    # Plot legend properly\n",
    "    ax.legend(bbox_to_anchor=(1, 0.5))\n",
    "    # Make angular and chi^2 plots linear, otherwise log\n",
    "    if re.match('chi_t', var_name) is None and re.match('DeltaPhi', var_name) is None and re.match('mass', var_name) is None:\n",
    "        ax.set_yscale('log')\n",
    "    else:\n",
    "        ax.set_yscale('linear')\n",
    "    ax.set_yscale('linear')\n",
    "    # Save out the plot\n",
    "    if fold_idx is not None:\n",
    "        plt.savefig(f'{output_dir}/{plot_prefix}1dhist_{var_name}{plot_postfix}_fold{fold_idx}.pdf', bbox_inches='tight')\n",
    "        plt.savefig(f'{output_dir}/{plot_prefix}1dhist_{var_name}{plot_postfix}_fold{fold_idx}.png', bbox_inches='tight')\n",
    "    else:\n",
    "        plt.savefig(f'{output_dir}/{plot_prefix}1dhist_{var_name}{plot_postfix}.pdf', bbox_inches='tight')\n",
    "        plt.savefig(f'{output_dir}/{plot_prefix}1dhist_{var_name}{plot_postfix}.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss per Epoch Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"losses\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "if 'BDT_perf' not in globals():\n",
    "    with open(os.path.join(OUTPUT_DIRPATH, CURRENT_TIME+\"_BDT_perf.json\"), 'r') as f:\n",
    "        BDT_perf = json.load(f)\n",
    "\n",
    "if 'evals_result_dict' not in globals():\n",
    "    with open(os.path.join(OUTPUT_DIRPATH, CURRENT_TIME+\"_BDT_eval_result.json\"), 'r') as f:\n",
    "        evals_result_dict = json.load(f)\n",
    "\n",
    "# plot train/val/test losses\n",
    "all_train, all_val, all_test = [], [], []\n",
    "for fold_idx in range(len(evals_result_dict)):\n",
    "    all_train.append(evals_result_dict[f\"fold_{fold_idx}\"]['train']['mlogloss'])\n",
    "    all_val.append(evals_result_dict[f\"fold_{fold_idx}\"]['val']['mlogloss'])\n",
    "    all_test.append(evals_result_dict[f\"fold_{fold_idx}\"]['test']['mlogloss'])\n",
    "\n",
    "plot_train_val_losses(\n",
    "    all_train + all_val, [f'train fold {i}' for i in range(len(all_train))]+[f'val fold {i}' for i in range(len(all_val))],\n",
    "    'train_val_losses_vs_epoch', plot_dirpath, \n",
    "    linestyles=['solid']*len(all_train) + ['dashed']*len(all_val),\n",
    ")\n",
    "plot_train_val_losses(\n",
    "    all_train + all_test, [f'train fold {i}' for i in range(len(all_train))]+[f'test fold {i}' for i in range(len(all_test))],\n",
    "    'train_test_losses_vs_epoch', plot_dirpath,\n",
    "    linestyles=['solid']*len(all_train) + ['dotted']*len(all_test),\n",
    ")\n",
    "avg_train, avg_val, avg_test = np.mean(pad_list(all_train), axis=0), np.mean(pad_list(all_val), axis=0), np.mean(pad_list(all_test), axis=0)\n",
    "std_train, std_val, std_test = np.std(pad_list(all_train), axis=0), np.std(pad_list(all_val), axis=0), np.std(pad_list(all_test), axis=0)\n",
    "plot_train_val_losses(\n",
    "    [avg_train, avg_val, avg_test], ['train avg', 'val avg', 'test avg'],\n",
    "    'train_val_test_avg_vs_epoch', plot_dirpath,\n",
    "    losses_std_arrs=[std_train, std_val, std_test],\n",
    "    linestyles=['solid', 'dashed', 'dotted'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"ROCs\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "if 'BDT_perf' not in globals():\n",
    "    with open(os.path.join(OUTPUT_DIRPATH, CURRENT_TIME+\"_BDT_perf.json\"), 'r') as f:\n",
    "        BDT_perf = json.load(f)\n",
    "\n",
    "base_tpr = np.array(BDT_perf['ggF HH']['base_tpr'])\n",
    "\n",
    "# plot ROCs\n",
    "for j, sample_name in enumerate(order):\n",
    "\n",
    "    for fold_idx in range(len(bdt_train_dict)):\n",
    "\n",
    "        for roc_type in ['density', 'weighted']:\n",
    "\n",
    "            fprs = [np.array(BDT_perf[sample_name][f'fprs_{roc_type}'][fold_idx])[:, i] for i in range(len(order))]\n",
    "            tprs = [base_tpr for _ in range(len(order))]\n",
    "            labels = [\n",
    "                f\"{sample_name} vs. {'all' if i == j else sample_name_}, AUC = {BDT_perf[sample_name][f'areas_{roc_type}'][fold_idx][i]:.4f}\" \n",
    "                for i, sample_name_ in enumerate(order)\n",
    "            ]\n",
    "\n",
    "            plot_rocs(fprs, tprs, labels, f\"BDT_roc_{sample_name}_{roc_type}_testData_fold{fold_idx}\", plot_dirpath)\n",
    "\n",
    "    for roc_type in ['sum_density', 'sum_weighted']:\n",
    "\n",
    "        fprs = [np.array(BDT_perf[sample_name][f'fprs_{roc_type}'])[:, i] for i in range(len(order))]\n",
    "        tprs = [base_tpr for _ in range(len(order))]\n",
    "        labels = [\n",
    "            f\"{sample_name} vs. {'all' if i == j else sample_name_}, AUC = {BDT_perf[sample_name][f'areas_{roc_type}'][i]:.4f}\" \n",
    "            for i, sample_name_ in enumerate(order)\n",
    "        ]\n",
    "\n",
    "        plot_rocs(fprs, tprs, labels, f\"BDT_roc_{sample_name}_{roc_type}_testData_sum\", plot_dirpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Score Dist Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"output_scores\")\n",
    "# plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"output_scores_arctanh\")\n",
    "# plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"output_scores_resample\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "if 'BDT_perf' not in globals():\n",
    "    with open(os.path.join(OUTPUT_DIRPATH, CURRENT_TIME+\"_BDT_perf.json\"), 'r') as f:\n",
    "        BDT_perf = json.load(f)\n",
    "\n",
    "# plot Output scores\n",
    "for j, sample_name in enumerate(order):\n",
    "\n",
    "    for i, sample_name_ in enumerate(order):\n",
    "\n",
    "        for fold_idx in range(len(bdt_train_dict)):\n",
    "            \n",
    "            sigs_and_bkgs = {\n",
    "                sample_name__: np.array(BDT_perf[sample_name]['preds'][fold_idx])[:, j][bdt_test_dict[f\"fold_{fold_idx}\"].get_label() == k]\n",
    "                for k, sample_name__ in enumerate(order)\n",
    "            }\n",
    "            score_weights = {\n",
    "                sample_name__: weights_plot_test[f\"fold_{fold_idx}\"][bdt_test_dict[f\"fold_{fold_idx}\"].get_label() == k]\n",
    "                for k, sample_name__ in enumerate(order)\n",
    "            }\n",
    "\n",
    "            if sample_name_ != sample_name:\n",
    "                event_j_mask = bdt_test_dict[f\"fold_{fold_idx}\"].get_label() == j\n",
    "                pred_j_rescale = np.array(BDT_perf[sample_name]['preds'][fold_idx])[:, j][event_j_mask] + np.array(BDT_perf[sample_name]['preds'][fold_idx])[:, i][event_j_mask]\n",
    "                event_i_mask = bdt_test_dict[f\"fold_{fold_idx}\"].get_label() == i\n",
    "                pred_i_rescale = np.array(BDT_perf[sample_name]['preds'][fold_idx])[:, j][event_i_mask] + np.array(BDT_perf[sample_name]['preds'][fold_idx])[:, i][event_i_mask]\n",
    "\n",
    "                for sample_name__ in order:\n",
    "                    if sample_name__ == sample_name:\n",
    "                        sigs_and_bkgs[sample_name__] = sigs_and_bkgs[sample_name__] / pred_j_rescale\n",
    "                    elif sample_name__ == sample_name_:\n",
    "                        sigs_and_bkgs[sample_name__] = sigs_and_bkgs[sample_name__] / pred_i_rescale\n",
    "                    else:\n",
    "                        del sigs_and_bkgs[sample_name__]\n",
    "                        del score_weights[sample_name__]\n",
    "\n",
    "            if re.search('arctanh', plot_dirpath) is not None:\n",
    "                for key, value in sigs_and_bkgs.items():\n",
    "                    sigs_and_bkgs[key] = np.arctanh(value)\n",
    "\n",
    "            plot_output_scores(\n",
    "                sigs_and_bkgs, order, \n",
    "                f\"BDT_{sample_name}_vs_{sample_name_ if sample_name_ != sample_name else 'all'}_outputScoreWeighted_testData_fold{fold_idx}\", \n",
    "                plot_dirpath, weights=score_weights, log=True,\n",
    "                arctanh=True if re.search('arctanh', plot_dirpath) is not None else False\n",
    "            )\n",
    "            plot_output_scores(\n",
    "                sigs_and_bkgs, order, \n",
    "                f\"BDT_{sample_name}_vs_{sample_name_ if sample_name_ != sample_name else 'all'}_outputScoreDensity_testData_fold{fold_idx}\", \n",
    "                plot_dirpath,\n",
    "                arctanh=True if re.search('arctanh', plot_dirpath) is not None else False\n",
    "            )\n",
    "\n",
    "        flat_preds = np.concatenate([BDT_perf[sample_name]['preds'][fold_idx] for fold_idx in range(len(bdt_test_dict))], axis=0)\n",
    "        if re.search('arctanh', plot_dirpath) is not None:\n",
    "            flat_preds = np.arctanh(flat_preds)\n",
    "        flat_truths = np.concatenate([bdt_test_dict[f\"fold_{fold_idx}\"].get_label() for fold_idx in range(len(bdt_test_dict))], axis=0)\n",
    "        flat_weights = np.concatenate([weights_plot_test[f\"fold_{fold_idx}\"] for fold_idx in range(len(bdt_test_dict))], axis=0)\n",
    "\n",
    "        sigs_and_bkgs = {\n",
    "            sample_name__: flat_preds[:, j][flat_truths == k]\n",
    "            for k, sample_name__ in enumerate(order)\n",
    "        }\n",
    "        score_weights = {\n",
    "            sample_name__: flat_weights[flat_truths == k]\n",
    "            for k, sample_name__ in enumerate(order)\n",
    "        }\n",
    "        \n",
    "        if sample_name_ != sample_name:\n",
    "            event_j_mask = flat_truths == j\n",
    "            pred_j_rescale = (flat_preds[:, j] + flat_preds[:, i])[event_j_mask]\n",
    "            event_i_mask = flat_truths == i\n",
    "            pred_i_rescale = (flat_preds[:, j] + flat_preds[:, i])[event_i_mask]\n",
    "\n",
    "            for sample_name__ in order:\n",
    "                if sample_name__ == sample_name:\n",
    "                    sigs_and_bkgs[sample_name__] = sigs_and_bkgs[sample_name__] / pred_j_rescale\n",
    "                elif sample_name__ == sample_name_:\n",
    "                    sigs_and_bkgs[sample_name__] = sigs_and_bkgs[sample_name__] / pred_i_rescale\n",
    "                else:\n",
    "                    del sigs_and_bkgs[sample_name__]\n",
    "                    del score_weights[sample_name__]\n",
    "        \n",
    "        plot_output_scores(\n",
    "            sigs_and_bkgs, order, \n",
    "            f\"BDT_{sample_name}_vs_{sample_name_ if sample_name_ != sample_name else 'all'}_outputScoreWeighted_testData_sum\", \n",
    "            plot_dirpath, weights=score_weights, log=True,\n",
    "            arctanh=True if re.search('arctanh', plot_dirpath) is not None else False\n",
    "        )\n",
    "        plot_output_scores(\n",
    "            sigs_and_bkgs, order, \n",
    "            f\"BDT_{sample_name}_vs_{sample_name_ if sample_name_ != sample_name else 'all'}_outputScoreDensity_testData_sum\", \n",
    "            plot_dirpath,\n",
    "            arctanh=True if re.search('arctanh', plot_dirpath) is not None else False\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### s/âb Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "============================================================\n",
      "Cat1: 0.9981 < ggF HH score â¤ 1.0000 AND 120 GeV < m_HH < 130 GeV\n",
      "------------------------------------------------------------\n",
      "Cat1: Num ggF HH = 0.2568\n",
      "------------------------------------------------------------\n",
      "Cat1: Num ttH = 0.0155\n",
      "------------------------------------------------------------\n",
      "Cat1: Num VH = 0.0226\n",
      "------------------------------------------------------------\n",
      "Cat1: Num non-res + ggFH + VBFH = 0.8258\n",
      "------------------------------------------------------------\n",
      "Cat1: Num GluGluHToGG = 0.08629836380170425\n",
      "------------------------------------------------------------\n",
      "Cat1: Num VBFHToGG = 0.007476296044939805\n",
      "------------------------------------------------------------\n",
      "Cat1: Num GGJets = 0.7320599965316763\n",
      "------------------------------------------------------------\n",
      "Cat1: Num GJetPt20To40 = 0.0\n",
      "------------------------------------------------------------\n",
      "Cat1: Num GJetPt40 = 0.0\n",
      "------------------------------------------------------------\n",
      "Cat1: S = 0.2568, B = 0.8639, S/âB = 0.2763\n",
      "============================================================\n",
      "============================================================\n",
      "Cat2: 0.9934 < ggF HH score â¤ 0.9981 AND 120 GeV < m_HH < 130 GeV\n",
      "------------------------------------------------------------\n",
      "Cat2: Num ggF HH = 0.2360\n",
      "------------------------------------------------------------\n",
      "Cat2: Num ttH = 0.1277\n",
      "------------------------------------------------------------\n",
      "Cat2: Num VH = 0.1128\n",
      "------------------------------------------------------------\n",
      "Cat2: Num non-res + ggFH + VBFH = 7.6498\n",
      "------------------------------------------------------------\n",
      "Cat2: Num GluGluHToGG = 0.4810571855573651\n",
      "------------------------------------------------------------\n",
      "Cat2: Num VBFHToGG = 0.03856949745394247\n",
      "------------------------------------------------------------\n",
      "Cat2: Num GGJets = 5.896036594099847\n",
      "------------------------------------------------------------\n",
      "Cat2: Num GJetPt20To40 = 0.0\n",
      "------------------------------------------------------------\n",
      "Cat2: Num GJetPt40 = 1.2341594322756537\n",
      "------------------------------------------------------------\n",
      "Cat2: S = 0.2360, B = 7.8903, S/âB = 0.0840\n",
      "============================================================\n",
      "============================================================\n",
      "Cat3: 0.9675 < ggF HH score â¤ 0.9934 AND 120 GeV < m_HH < 130 GeV\n",
      "------------------------------------------------------------\n",
      "Cat3: Num ggF HH = 0.2370\n",
      "------------------------------------------------------------\n",
      "Cat3: Num ttH = 0.7368\n",
      "------------------------------------------------------------\n",
      "Cat3: Num VH = 0.2644\n",
      "------------------------------------------------------------\n",
      "Cat3: Num non-res + ggFH + VBFH = 32.0173\n",
      "------------------------------------------------------------\n",
      "Cat3: Num GluGluHToGG = 1.526176813161934\n",
      "------------------------------------------------------------\n",
      "Cat3: Num VBFHToGG = 0.12296375222734676\n",
      "------------------------------------------------------------\n",
      "Cat3: Num GGJets = 26.66563765670609\n",
      "------------------------------------------------------------\n",
      "Cat3: Num GJetPt20To40 = 0.0\n",
      "------------------------------------------------------------\n",
      "Cat3: Num GJetPt40 = 3.7024782968269614\n",
      "------------------------------------------------------------\n",
      "Cat3: S = 0.2370, B = 33.0184, S/âB = 0.0412\n"
     ]
    }
   ],
   "source": [
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"s_over_rootb\")\n",
    "# plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"s_over_rootb_arctanh\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "if 'BDT_perf' not in globals():\n",
    "    with open(os.path.join(OUTPUT_DIRPATH, CURRENT_TIME+\"_BDT_perf.json\"), 'r') as f:\n",
    "        BDT_perf = json.load(f)\n",
    "\n",
    "# plot s/âb curves\n",
    "for j, sample_name in enumerate(order):\n",
    "\n",
    "    for i, sample_name_ in enumerate(order):\n",
    "\n",
    "        for fold_idx in range(len(BDT_perf['ggF HH']['preds'])):\n",
    "\n",
    "            if sample_name_ == sample_name:\n",
    "                sig_mask = bdt_test_dict[f\"fold_{fold_idx}\"].get_label() == j\n",
    "                bkg_mask = bdt_test_dict[f\"fold_{fold_idx}\"].get_label() != j\n",
    "\n",
    "                sig_rescale = np.ones_like(sig_mask)\n",
    "                bkg_rescale = np.ones_like(bkg_mask)\n",
    "            else:\n",
    "                sig_mask = bdt_test_dict[f\"fold_{fold_idx}\"].get_label() == j\n",
    "                bkg_mask = bdt_test_dict[f\"fold_{fold_idx}\"].get_label() == i\n",
    "\n",
    "                sig_rescale = (\n",
    "                    np.array(BDT_perf[sample_name]['preds'][fold_idx])[:, j] \n",
    "                    + np.array(BDT_perf[sample_name]['preds'][fold_idx])[:, i]\n",
    "                )\n",
    "                bkg_rescale = (\n",
    "                    np.array(BDT_perf[sample_name]['preds'][fold_idx])[:, j] \n",
    "                    + np.array(BDT_perf[sample_name]['preds'][fold_idx])[:, i]\n",
    "                )\n",
    "\n",
    "            sigs_and_bkgs = {\n",
    "                'sig': (np.array(BDT_perf[sample_name]['preds'][fold_idx])[:, j] / sig_rescale)[sig_mask],\n",
    "                'bkg': (np.array(BDT_perf[sample_name]['preds'][fold_idx])[:, j] / bkg_rescale)[bkg_mask]\n",
    "            }\n",
    "            if re.search('arctanh', plot_dirpath) is not None:\n",
    "                sigs_and_bkgs['sig'] = np.arctanh(sigs_and_bkgs['sig'])\n",
    "                sigs_and_bkgs['bkg'] = np.arctanh(sigs_and_bkgs['bkg'])\n",
    "            score_weights = {\n",
    "                'sig': weights_plot_test[f\"fold_{fold_idx}\"][sig_mask],\n",
    "                'bkg': weights_plot_test[f\"fold_{fold_idx}\"][bkg_mask]\n",
    "            }\n",
    "\n",
    "\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\")\n",
    "                plot_s_over_root_b(\n",
    "                    sigs_and_bkgs['sig'], sigs_and_bkgs['bkg'], f\"{sample_name} vs. {sample_name_ if sample_name_ != sample_name else 'all'}\", \n",
    "                    f\"BDT_{sample_name}_vs_{sample_name_ if sample_name_ != sample_name else 'all'}_sOverRootb_testData_fold{fold_idx}\", \n",
    "                    plot_dirpath, weights=score_weights,\n",
    "                    arctanh=True if re.search('arctanh', plot_dirpath) is not None else False  \n",
    "                )\n",
    "\n",
    "                (\n",
    "                    cut_boundaries_fold, cut_s_over_root_bs_fold, sig_weights_fold, bkg_weights_fold\n",
    "                ) = optimize_cut_boundaries(\n",
    "                    sigs_and_bkgs['sig'], sigs_and_bkgs['bkg'], score_weights,\n",
    "                    arctanh=True if re.search('arctanh', plot_dirpath) is not None else False\n",
    "                )\n",
    "\n",
    "                BDT_cut_labels = [\n",
    "                    f\"cut={cut_boundaries_fold[0][cut_idx]:.4f}: s/âb={cut_s_over_root_bs_fold[0][cut_idx]:.5f}, s={sig_weights_fold[0][cut_idx]['value']:.5f}Â±{sig_weights_fold[0][cut_idx]['w2']:.5f}, b={bkg_weights_fold[0][cut_idx]['value']:.5f}Â±{bkg_weights_fold[0][cut_idx]['w2']:.5f}\" for cut_idx in range(len(cut_s_over_root_bs_fold[0]))\n",
    "                ]\n",
    "                line_labels = BDT_cut_labels[:10]\n",
    "                lines = cut_boundaries_fold[0][:10]\n",
    "                line_colors = cmap_petroff10\n",
    "\n",
    "                plot_s_over_root_b(\n",
    "                    sigs_and_bkgs['sig'], sigs_and_bkgs['bkg'], f\"{sample_name} vs. {sample_name_ if sample_name_ != sample_name else 'all'}\", \n",
    "                    f\"BDT_{sample_name}_vs_{sample_name_ if sample_name_ != sample_name else 'all'}_sOverRootb_withCuts_testData_fold{fold_idx}_{sample_name}\", plot_dirpath, \n",
    "                    weights=score_weights,\n",
    "                    lines=lines, lines_labels=line_labels, line_colors=line_colors,\n",
    "                    arctanh=True if re.search('arctanh', plot_dirpath) is not None else False\n",
    "                )\n",
    "            \n",
    "        flat_preds = np.concatenate([BDT_perf[sample_name]['preds'][fold_idx] for fold_idx in range(len(BDT_perf['ggF HH']['preds']))], axis=0)\n",
    "        if re.search('arctanh', plot_dirpath) is not None:\n",
    "            flat_preds = np.arctanh(flat_preds)\n",
    "        flat_truths = np.concatenate([bdt_test_dict[f\"fold_{fold_idx}\"].get_label() for fold_idx in range(len(BDT_perf['ggF HH']['preds']))], axis=0)\n",
    "        flat_weights = np.concatenate([weights_plot_test[f\"fold_{fold_idx}\"] for fold_idx in range(len(BDT_perf['ggF HH']['preds']))], axis=0)\n",
    "        flat_sample_names = np.concatenate([data_test_aux_dict[f\"fold_{fold_idx}\"]['sample_name'] for fold_idx in range(len(BDT_perf['ggF HH']['preds']))], axis=0)\n",
    "\n",
    "        if sample_name_ == sample_name:\n",
    "            sig_mask = flat_truths == j\n",
    "            bkg_mask = flat_truths != j\n",
    "\n",
    "            sig_rescale = np.ones_like(sig_mask)\n",
    "            bkg_rescale = np.ones_like(bkg_mask)\n",
    "        else:\n",
    "            sig_mask = flat_truths == j\n",
    "            bkg_mask = flat_truths == i\n",
    "\n",
    "            sig_rescale = flat_preds[:, j] + flat_preds[:, i]\n",
    "            bkg_rescale = flat_preds[:, j] + flat_preds[:, i]\n",
    "\n",
    "        sigs_and_bkgs = {\n",
    "            'sig': (flat_preds[:, j] / sig_rescale)[sig_mask],\n",
    "            'bkg': (flat_preds[:, j] / bkg_rescale)[bkg_mask]\n",
    "        }\n",
    "        score_weights = {\n",
    "            'sig': flat_weights[sig_mask],\n",
    "            'bkg': flat_weights[bkg_mask]\n",
    "        }\n",
    "\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            plot_s_over_root_b(\n",
    "                sigs_and_bkgs['sig'], sigs_and_bkgs['bkg'], f\"{sample_name} vs. {sample_name_ if sample_name_ != sample_name else 'all'}\", \n",
    "                f\"BDT_{sample_name}_vs_{sample_name_ if sample_name_ != sample_name else 'all'}_sOverRootb_testData_sum\", \n",
    "                plot_dirpath, weights=score_weights,\n",
    "                arctanh=True if re.search('arctanh', plot_dirpath) is not None else False\n",
    "            )\n",
    "\n",
    "            (\n",
    "                cut_boundaries_fold, cut_s_over_root_bs_fold, sig_weights_fold, bkg_weights_fold\n",
    "            ) = optimize_cut_boundaries(\n",
    "                sigs_and_bkgs['sig'], sigs_and_bkgs['bkg'], score_weights,\n",
    "                arctanh=True if re.search('arctanh', plot_dirpath) is not None else False\n",
    "            )\n",
    "\n",
    "            BDT_cut_labels = [\n",
    "                f\"cut={cut_boundaries_fold[0][cut_idx]:.4f}: s/âb={cut_s_over_root_bs_fold[0][cut_idx]:.5f}, s={sig_weights_fold[0][cut_idx]['value']:.5f}Â±{sig_weights_fold[0][cut_idx]['w2']:.5f}, b={bkg_weights_fold[0][cut_idx]['value']:.5f}Â±{bkg_weights_fold[0][cut_idx]['w2']:.5f}\" for cut_idx in range(len(cut_s_over_root_bs_fold[0]))\n",
    "            ]\n",
    "            line_labels = BDT_cut_labels[:10]\n",
    "            lines = cut_boundaries_fold[0][:10]\n",
    "            line_colors = cmap_petroff10\n",
    "\n",
    "            plot_s_over_root_b(\n",
    "                sigs_and_bkgs['sig'], sigs_and_bkgs['bkg'], f\"{sample_name} vs. {sample_name_ if sample_name_ != sample_name else 'all'}\", \n",
    "                f\"BDT_{sample_name}_vs_{sample_name_ if sample_name_ != sample_name else 'all'}_sOverRootb_withCuts_testData_sum\", plot_dirpath, \n",
    "                weights=score_weights,\n",
    "                lines=lines, lines_labels=line_labels, line_colors=line_colors,\n",
    "                arctanh=True if re.search('arctanh', plot_dirpath) is not None else False\n",
    "            )\n",
    "\n",
    "        if j == 0 and i == 0:\n",
    "            flat_mass = np.concatenate([data_test_aux_dict[f\"fold_{fold_idx}\"]['mass'] for fold_idx in range(len(BDT_perf['ggF HH']['preds']))], axis=0)\n",
    "            if re.search('arctanh', plot_dirpath) is not None:\n",
    "                cat_lines = [6.0] + lines[:3]\n",
    "            else:\n",
    "                cat_lines = [1.0] + lines[:3]\n",
    "            cat_num_samples = {}\n",
    "            for k, cat in enumerate(['Cat1', 'Cat2', 'Cat3']):\n",
    "                cat_num_samples[cat] = {}\n",
    "                print('='*60)\n",
    "                print('='*60)\n",
    "                print(f\"{cat}: {cat_lines[k+1]:.4f} < ggF HH score â¤ {cat_lines[k]:.4f} AND 120 GeV < m_HH < 130 GeV\")\n",
    "                print('-'*60)\n",
    "                for m, sample_name in enumerate(order):\n",
    "                    sample_bool = np.logical_and(  # event passes conditions and is the right type (i.e. sample)\n",
    "                        np.logical_and(  # event passes category and mass conditions\n",
    "                            np.logical_and(  # prediction is within category bounds\n",
    "                                flat_preds[:, 0] <= cat_lines[k],\n",
    "                                flat_preds[:, 0] > cat_lines[k+1]\n",
    "                            ),\n",
    "                            np.logical_and(  # diphoton mass is within 120-130 window\n",
    "                                flat_mass < 130,\n",
    "                                flat_mass > 120\n",
    "                            ),\n",
    "                        ),\n",
    "                        flat_truths == m\n",
    "                    )\n",
    "                    cat_num_samples[cat][sample_name] = np.sum(\n",
    "                        flat_weights[sample_bool]\n",
    "                    )\n",
    "                    print(f\"{cat}: Num {sample_name} = {cat_num_samples[cat][sample_name]:.4f}\")\n",
    "                    print('-'*60)\n",
    "                    if sample_name == order[-1]:\n",
    "                        for smpl in ['GluGluHToGG', 'VBFHToGG', 'GGJets', 'GJetPt20To40', 'GJetPt40']:\n",
    "                            smpl_num = np.sum(\n",
    "                                flat_weights[\n",
    "                                    np.logical_and(\n",
    "                                        sample_bool,\n",
    "                                        flat_sample_names == smpl\n",
    "                                    )\n",
    "                                ]\n",
    "                            )\n",
    "                            print(f\"{cat}: Num {smpl} = {smpl_num}\")\n",
    "                            print('-'*60)\n",
    "\n",
    "                print(f\"{cat}: S = {cat_num_samples[cat][order[0]]:.4f}, B = {np.sum([cat_num_samples[cat][order[v]] for v in range(1, len(order))]):.4f}, S/âB = {(cat_num_samples[cat][order[0]] / np.sqrt(np.sum([cat_num_samples[cat][order[v]] for v in range(1, len(order))]))):.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "============================================================\n",
      "Category 0 3D outputs < [0.00014055027654462777, 0.0019279517132367056, 0.0017874033775492724] AND 120 GeV < m_HH < 130 GeV\n",
      "------------------------------------------------------------\n",
      "0: Num ggF HH = 0.4181\n",
      "------------------------------------------------------------\n",
      "0: Num ttH = 0.1792\n",
      "------------------------------------------------------------\n",
      "0: Num VH = 0.1668\n",
      "------------------------------------------------------------\n",
      "0: Num non-res + ggFH + VBFH = 3.0598\n",
      "------------------------------------------------------------\n",
      "0: S = 0.4181, B = 3.4058, S/âB = 0.2265\n",
      "============================================================\n",
      "============================================================\n",
      "Category 1 3D outputs NOT< [0.00014055027654462777, 0.0019279517132367056, 0.0017874033775492724] AND 3D outputs < [0.00015953082067176068, 0.0031904568899924963, 0.0030309420216650075] AND 120 GeV < m_HH < 130 GeV\n",
      "------------------------------------------------------------\n",
      "1: Num ggF HH = 0.0754\n",
      "------------------------------------------------------------\n",
      "1: Num ttH = 0.0950\n",
      "------------------------------------------------------------\n",
      "1: Num VH = 0.0466\n",
      "------------------------------------------------------------\n",
      "1: Num non-res + ggFH + VBFH = 1.8324\n",
      "------------------------------------------------------------\n",
      "1: S = 0.0754, B = 1.9740, S/âB = 0.0537\n",
      "============================================================\n",
      "============================================================\n",
      "Category 2 3D outputs NOT< [0.00015953082067176068, 0.0031904568899924963, 0.0030309420216650075] AND 3D outputs < [0.00012428479978053485, 0.0036933592767097153, 0.003569109152819045] AND 120 GeV < m_HH < 130 GeV\n",
      "------------------------------------------------------------\n",
      "2: Num ggF HH = 0.0135\n",
      "------------------------------------------------------------\n",
      "2: Num ttH = 0.0069\n",
      "------------------------------------------------------------\n",
      "2: Num VH = 0.0089\n",
      "------------------------------------------------------------\n",
      "2: Num non-res + ggFH + VBFH = 0.2208\n",
      "------------------------------------------------------------\n",
      "2: S = 0.0135, B = 0.2365, S/âB = 0.0277\n"
     ]
    }
   ],
   "source": [
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"s_over_rootb_multiOptim\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "if 'BDT_perf' not in globals():\n",
    "    with open(os.path.join(OUTPUT_DIRPATH, CURRENT_TIME+\"_BDT_perf.json\"), 'r') as f:\n",
    "        BDT_perf = json.load(f)\n",
    "\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(projection='3d')\n",
    "# # x_preds, y_preds, z_preds = p_to_xyz(np.concatenate([BDT_perf['ggF HH']['preds'][fold_idx] for fold_idx in range(len(bdt_test_dict))], axis=0))\n",
    "# for i, sample_name in enumerate(order):\n",
    "#     if i == 0:\n",
    "#         downsample = 100\n",
    "#     elif i == 1:\n",
    "#         downsample = 200\n",
    "#     elif i == 2:\n",
    "#         downsample = 400\n",
    "#     elif i == 3:\n",
    "#         downsample = 500\n",
    "\n",
    "#     x_preds, y_preds, z_preds = p_to_xyz(np.array(BDT_perf['ggF HH']['preds'][0])[bdt_test_dict[f\"fold_0\"].get_label() == i][::downsample])\n",
    "#     ax.scatter(x_preds, y_preds, z_preds, marker='.', label=sample_name)\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# # plot s/âb curves\n",
    "# for fold_idx in range(len(bdt_train_dict)):\n",
    "\n",
    "#     with warnings.catch_warnings():\n",
    "#         warnings.simplefilter(\"ignore\")\n",
    "#         clf_dict = multi_optimize_cut_boundaries(\n",
    "#             BDT_perf['ggF HH']['preds'][fold_idx], \n",
    "#             bdt_test_dict[f\"fold_{fold_idx}\"].get_label() == 0, \n",
    "#             weights_plot_test[f\"fold_{fold_idx}\"],\n",
    "#             min_sig=0.07\n",
    "#         )\n",
    "\n",
    "#     cat_dict = {}\n",
    "#     for cat in range(len(clf_dict)):\n",
    "#         prev_cat_slice = np.ones_like(weights_plot_test[f\"fold_{fold_idx}\"], dtype=bool)\n",
    "#         if cat > 0:\n",
    "#             for prev_cat in range(cat):\n",
    "#                 prev_cat_slice = np.logical_and(\n",
    "#                     prev_cat_slice,\n",
    "#                     np.logical_not(\n",
    "#                         np.all(\n",
    "#                             p_to_xyz(np.array(BDT_perf['ggF HH']['preds'][fold_idx]), split=False) < clf_dict[prev_cat], \n",
    "#                             axis=1\n",
    "#                         )\n",
    "#                     )\n",
    "#                 )\n",
    "#         cat_dict[cat] = np.logical_and(\n",
    "#             prev_cat_slice,\n",
    "#             np.all(\n",
    "#                 p_to_xyz(np.array(BDT_perf['ggF HH']['preds'][fold_idx]), split=False) < clf_dict[cat],\n",
    "#                 axis=1\n",
    "#             )\n",
    "#         )\n",
    "\n",
    "#     masses = data_test_aux_dict[f\"fold_{fold_idx}\"]['mass']\n",
    "#     cat_num_samples = {}\n",
    "#     for cat in range(len(clf_dict)):\n",
    "#         cat_num_samples[cat] = {}\n",
    "#         print('='*60)\n",
    "#         print('='*60)\n",
    "#         print(f\"Fold {fold_idx}: Category {cat} (SVM) AND 120 GeV < m_HH < 130 GeV\")\n",
    "#         print('-'*60)\n",
    "#         for m, sample_name in enumerate(order):\n",
    "#             cat_num_samples[cat][sample_name] = np.sum(\n",
    "#                 weights_plot_test[f\"fold_{fold_idx}\"][\n",
    "#                     np.logical_and(  # event passes conditions and is the right type (i.e. sample)\n",
    "#                         np.logical_and(  # event passes category and mass conditions\n",
    "#                             cat_dict[cat],  # event passes category selections\n",
    "#                             np.logical_and(  # diphoton mass is within 120-130 window\n",
    "#                                 masses < 130,\n",
    "#                                 masses > 120\n",
    "#                             ),\n",
    "#                         ),\n",
    "#                         bdt_test_dict[f\"fold_{fold_idx}\"].get_label() == m\n",
    "#                     )\n",
    "#                 ]\n",
    "#             )\n",
    "#             print(f\"{cat}: Num {sample_name} = {cat_num_samples[cat][sample_name]:.4f}\")\n",
    "#             print('-'*60)\n",
    "#         print(f\"{cat}: S = {cat_num_samples[cat][order[0]]:.4f}, B = {np.sum([cat_num_samples[cat][order[v]] for v in range(1, len(order))]):.4f}, S/âB = {(cat_num_samples[cat][order[0]] / np.sqrt(np.sum([cat_num_samples[cat][order[v]] for v in range(1, len(order))]))):.4f}\")\n",
    "\n",
    "# print('='*60)\n",
    "# print('='*60)\n",
    "# print('='*60)\n",
    "# print('='*60)\n",
    "\n",
    "flat_preds = np.concatenate([BDT_perf['ggF HH']['preds'][fold_idx] for fold_idx in range(len(bdt_test_dict))], axis=0)\n",
    "flat_truths = np.concatenate([bdt_test_dict[f\"fold_{fold_idx}\"].get_label() for fold_idx in range(len(bdt_test_dict))], axis=0)\n",
    "flat_weights = np.concatenate([weights_plot_test[f\"fold_{fold_idx}\"] for fold_idx in range(len(bdt_test_dict))], axis=0)\n",
    "# flat_weights = np.concatenate([weight_test_dict[f\"fold_{fold_idx}\"] for fold_idx in range(len(bdt_test_dict))], axis=0)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    clf_dict = multi_optimize_cut_boundaries(\n",
    "        flat_preds, flat_truths == 0, flat_weights\n",
    "    )\n",
    "\n",
    "    # plot_s_over_root_b(\n",
    "    #     sigs_and_bkgs['sig'], sigs_and_bkgs['bkg'], f\"{sample_name} vs. {sample_name_ if sample_name_ != sample_name else 'all'}\", \n",
    "    #     f\"BDT_{sample_name}_vs_{sample_name_ if sample_name_ != sample_name else 'all'}_sOverRootb_withCuts_testData_sum\", plot_dirpath, \n",
    "    #     weights=score_weights,\n",
    "    #     lines=lines, lines_labels=line_labels, line_colors=line_colors\n",
    "    # )\n",
    "\n",
    "flat_mass = np.concatenate([data_test_aux_dict[f\"fold_{fold_idx}\"]['mass'] for fold_idx in range(len(data_test_aux_dict))], axis=0)\n",
    "cat_dict = {}\n",
    "for cat in range(len(clf_dict)):\n",
    "    prev_cat_slice = np.ones_like(flat_weights, dtype=bool)\n",
    "    if cat > 0:\n",
    "        for prev_cat in range(cat):\n",
    "            prev_cat_slice = np.logical_and(\n",
    "                prev_cat_slice,\n",
    "                np.logical_not(\n",
    "                    np.all(\n",
    "                        p_to_xyz(flat_preds, split=False) < clf_dict[prev_cat], \n",
    "                        axis=1\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "    cat_dict[cat] = np.logical_and(\n",
    "        prev_cat_slice,\n",
    "        np.all(\n",
    "            p_to_xyz(flat_preds, split=False) < clf_dict[cat],\n",
    "            axis=1\n",
    "        )\n",
    "    )\n",
    "\n",
    "cat_num_samples = {}\n",
    "for cat in range(len(clf_dict)):\n",
    "    cat_num_samples[cat] = {}\n",
    "    print('='*60)\n",
    "    print('='*60)\n",
    "    print(f\"Category {cat} {f'3D outputs NOT< {clf_dict[cat-1]} AND ' if cat > 0 else ''}3D outputs < {clf_dict[cat]} AND 120 GeV < m_HH < 130 GeV\")\n",
    "    print('-'*60)\n",
    "    for m, sample_name in enumerate(order):\n",
    "        cat_num_samples[cat][sample_name] = np.sum(\n",
    "            flat_weights[\n",
    "                np.logical_and(  # event passes conditions and is the right type (i.e. sample)\n",
    "                    np.logical_and(  # event passes category and mass conditions\n",
    "                        cat_dict[cat],  # event passes category selections\n",
    "                        np.logical_and(  # diphoton mass is within 120-130 window\n",
    "                            flat_mass < 130,\n",
    "                            flat_mass > 120\n",
    "                        ),\n",
    "                    ),\n",
    "                    flat_truths == m\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "        print(f\"{cat}: Num {sample_name} = {cat_num_samples[cat][sample_name]:.4f}\")\n",
    "        print('-'*60)\n",
    "    print(f\"{cat}: S = {cat_num_samples[cat][order[0]]:.4f}, B = {np.sum([cat_num_samples[cat][order[v]] for v in range(1, len(order))]):.4f}, S/âB = {(cat_num_samples[cat][order[0]] / np.sqrt(np.sum([cat_num_samples[cat][order[v]] for v in range(1, len(order))]))):.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0: FÎ² (Î²=1) score = \n",
      "[4.01089194e-04 8.61848865e-02 6.45028776e-02 9.79722976e-01]\n",
      "fold 1: FÎ² (Î²=1) score = \n",
      "[3.71182878e-04 8.79411493e-02 4.65617774e-02 9.77726339e-01]\n",
      "fold 2: FÎ² (Î²=1) score = \n",
      "[3.65808669e-04 7.44426354e-02 5.37988106e-02 9.77978355e-01]\n",
      "fold 3: FÎ² (Î²=1) score = \n",
      "[3.73826408e-04 7.67835555e-02 4.12288239e-02 9.77964763e-01]\n",
      "fold 4: FÎ² (Î²=1) score = \n",
      "[3.95642043e-04 1.00789910e-01 5.00066266e-02 9.79439014e-01]\n",
      "Sum over folds: FÎ² (Î²=1) score = \n",
      "[3.80967879e-04 8.42409541e-02 5.01465839e-02 9.78564149e-01]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 900x700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 900x700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 900x700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 900x700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 900x700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 900x700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"confusion_matrix\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "if 'BDT_perf' not in globals():\n",
    "    with open(os.path.join(OUTPUT_DIRPATH, CURRENT_TIME+\"_BDT_perf.json\"), 'r') as f:\n",
    "        BDT_perf = json.load(f)\n",
    "\n",
    "beta = 1\n",
    "normalize = 'true'  # 'true' for normalize over rows, None for absoulte yields\n",
    "\n",
    "for fold_idx in range(len(BDT_perf['ggF HH']['preds'])):\n",
    "\n",
    "    pred_classes = np.argmax(BDT_perf['ggF HH']['preds'][fold_idx], axis=1)\n",
    "\n",
    "    conf_matrix = confusion_matrix(\n",
    "        bdt_test_dict[f\"fold_{fold_idx}\"].get_label(), \n",
    "        pred_classes,\n",
    "        sample_weight=weights_plot_test[f\"fold_{fold_idx}\"],\n",
    "        normalize=normalize\n",
    "    )\n",
    "\n",
    "    plot_confusion_matrix(\n",
    "        conf_matrix, order, f\"confusion_matrix_fold{fold_idx}{'_norm_'+normalize if normalize is not None else ''}\", plot_dirpath\n",
    "    )\n",
    "\n",
    "    f1_scores = fbeta_score(\n",
    "        bdt_test_dict[f\"fold_{fold_idx}\"].get_label(), \n",
    "        pred_classes,\n",
    "        beta=beta,\n",
    "        sample_weight=weights_plot_test[f\"fold_{fold_idx}\"], average=None\n",
    "    )\n",
    "    print(f\"fold {fold_idx}: FÎ² (Î²={beta}) score = \\n{f1_scores}\")\n",
    "\n",
    "full_pred_classes = np.argmax(\n",
    "    np.concatenate(\n",
    "        [\n",
    "            BDT_perf['ggF HH']['preds'][fold_idx] for fold_idx in range(len(BDT_perf['ggF HH']['preds']))\n",
    "        ]\n",
    "    ), axis=1\n",
    ")\n",
    "full_labels = np.concatenate(\n",
    "    [\n",
    "        bdt_test_dict[f\"fold_{fold_idx}\"].get_label() for fold_idx in range(len(BDT_perf['ggF HH']['preds']))\n",
    "    ]\n",
    ")\n",
    "full_weights = np.concatenate(\n",
    "    [\n",
    "        weights_plot_test[f\"fold_{fold_idx}\"] for fold_idx in range(len(BDT_perf['ggF HH']['preds']))\n",
    "    ]\n",
    ")\n",
    "\n",
    "conf_matrix = confusion_matrix(\n",
    "    full_labels, \n",
    "    full_pred_classes,\n",
    "    sample_weight=full_weights,\n",
    "    normalize=normalize\n",
    ")\n",
    "\n",
    "plot_confusion_matrix(\n",
    "    conf_matrix, order, f\"confusion_matrix_sum{'_norm_'+normalize if normalize is not None else ''}\", plot_dirpath\n",
    ")\n",
    "\n",
    "f1_scores = fbeta_score(\n",
    "    full_labels, \n",
    "    full_pred_classes,\n",
    "    beta=beta,\n",
    "    sample_weight=full_weights, average=None\n",
    ")\n",
    "print(f\"Sum over folds: FÎ² (Î²={beta}) score = \\n{f1_scores}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"variable_importance\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "for fold_idx in range(len(bdt_train_dict)):\n",
    "    booster = xgb.Booster(param, model_file=os.path.join(OUTPUT_DIRPATH, f'{CURRENT_TIME}_BDT_fold{fold_idx}.model'))\n",
    "\n",
    "    labels = copy.deepcopy([key for key in hlf_vars_columns_dict[f'fold_{fold_idx}'].keys()])\n",
    "    labels.sort()\n",
    "    \n",
    "    booster.feature_names = labels\n",
    "    score_dict = booster.get_score(importance_type='total_gain')\n",
    "\n",
    "    sorted_scores, sorted_labels = [], []\n",
    "    for label, score in score_dict.items():\n",
    "        sorted_scores.append(score)\n",
    "        sorted_labels.append(label)\n",
    "\n",
    "    sorted_labels = np.array(sorted_labels)[np.argsort(sorted_scores)]\n",
    "    sorted_scores = np.sort(sorted_scores)\n",
    "\n",
    "    plot_feature_importance(\n",
    "        sorted_scores, sorted_labels, f'xgb_importance_fold{fold_idx}', plot_dirpath\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Variable Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "------------------------------------------------------------\n",
      "mass                            1.000000\n",
      "HHbbggCandidate_mass            0.375709\n",
      "CosThetaStar_CS                 0.004460\n",
      "CosThetaStar_gg                 0.001330\n",
      "CosThetaStar_jj                 0.001529\n",
      "DeltaEta_jj                    -0.017657\n",
      "DeltaPhi_isr_jet_z              0.012729\n",
      "DeltaPhi_j1MET                 -0.000128\n",
      "DeltaPhi_j2MET                  0.000717\n",
      "DeltaPhi_jj                     0.001864\n",
      "DeltaR_jg_min                  -0.059714\n",
      "HHbbggCandidate_eta             0.004782\n",
      "HHbbggCandidate_pt              0.043332\n",
      "chi_t0                          0.006656\n",
      "chi_t1                          0.001299\n",
      "dijet_mass                      0.021438\n",
      "dijet_mass_over_Mggjj          -0.304632\n",
      "dijet_pt                        0.049606\n",
      "eta                             0.006297\n",
      "isr_jet_pt                      0.015894\n",
      "leadBjet_leadLepton            -0.055153\n",
      "lead_bjet_btagPNetB            -0.079635\n",
      "lead_bjet_eta                   0.001464\n",
      "lead_bjet_pt                    0.052944\n",
      "lead_bjet_pt_over_Mjj           0.044314\n",
      "lead_bjet_sigmapT_over_pT      -0.024856\n",
      "lead_mvaID                      0.025086\n",
      "lead_sigmaE_over_E             -0.060878\n",
      "lepton1_eta                    -0.055157\n",
      "lepton1_pt                     -0.054411\n",
      "n_jets                         -0.014539\n",
      "n_leptons                      -0.053621\n",
      "pt                              0.084853\n",
      "pt_balance                     -0.089345\n",
      "puppiMET_pt                    -0.031629\n",
      "puppiMET_sumEt                  0.192666\n",
      "subleadBjet_leadLepton         -0.055152\n",
      "sublead_bjet_btagPNetB         -0.064706\n",
      "sublead_bjet_eta               -0.000348\n",
      "sublead_bjet_pt                -0.008921\n",
      "sublead_bjet_pt_over_Mjj       -0.017221\n",
      "sublead_bjet_sigmapT_over_pT    0.012028\n",
      "sublead_mvaID                   0.033735\n",
      "sublead_sigmaE_over_E          -0.085996\n",
      "Name: mass, dtype: float64\n",
      "============================================================\n",
      "============================================================\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2205033/3023114728.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfold_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_aux_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmerged_pd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_df_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf\"fold_{fold_idx}\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mass'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'HHbbggCandidate_mass'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mmerged_pd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_aux_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf\"fold_{fold_idx}\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mdata_corr_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf\"fold_{fold_idx}\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerged_pd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"fold {fold_idx}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, method, min_periods, numeric_only)\u001b[0m\n\u001b[1;32m  11048\u001b[0m         \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11049\u001b[0m         \u001b[0mmat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11050\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11051\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"pearson\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 11052\u001b[0;31m             \u001b[0mcorrel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibalgos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnancorr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_periods\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  11053\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"spearman\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11054\u001b[0m             \u001b[0mcorrel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibalgos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnancorr_spearman\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_periods\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11055\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"kendall\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_corr_dict = {}\n",
    "for fold_idx in range(len(data_aux_dict)):\n",
    "    merged_pd = copy.deepcopy(data_df_dict[f\"fold_{fold_idx}\"])\n",
    "    for i, var_name in enumerate(['mass', 'HHbbggCandidate_mass']):\n",
    "        merged_pd.insert(i, var_name, data_aux_dict[f\"fold_{fold_idx}\"].loc[:, var_name])\n",
    "    data_corr_dict[f\"fold_{fold_idx}\"] = merged_pd.corr()\n",
    "\n",
    "    print(f\"fold {fold_idx}\")\n",
    "    print('-'*60)\n",
    "    print(data_corr_dict[f\"fold_{fold_idx}\"].iloc[0, :])\n",
    "    print(f\"{'='*60}\\n{'='*60}\\n{'='*60}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mass Sculpting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 38\u001b[0m\n\u001b[1;32m     32\u001b[0m train_hists[sample_name], val_hists[sample_name], test_hists[sample_name] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(), \u001b[38;5;28mlist\u001b[39m(), \u001b[38;5;28mlist\u001b[39m()\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m score_cut \u001b[38;5;129;01min\u001b[39;00m score_cuts:\n\u001b[1;32m     35\u001b[0m     train_mask \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     36\u001b[0m         xgb_label_train_dict[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfold_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m i\n\u001b[1;32m     37\u001b[0m     ) \u001b[38;5;241m&\u001b[39m (\n\u001b[0;32m---> 38\u001b[0m         \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBDT_perf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mggF HH\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain_preds\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfold_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[:, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m score_cut\n\u001b[1;32m     39\u001b[0m     )\n\u001b[1;32m     40\u001b[0m     val_mask \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     41\u001b[0m         xgb_label_val_dict[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfold_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m i\n\u001b[1;32m     42\u001b[0m     ) \u001b[38;5;241m&\u001b[39m (\n\u001b[1;32m     43\u001b[0m         np\u001b[38;5;241m.\u001b[39marray(BDT_perf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mggF HH\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_preds\u001b[39m\u001b[38;5;124m'\u001b[39m][fold_idx])[:, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m score_cut\n\u001b[1;32m     44\u001b[0m     )\n\u001b[1;32m     45\u001b[0m     test_mask \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     46\u001b[0m         xgb_label_test_dict[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfold_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m i\n\u001b[1;32m     47\u001b[0m     ) \u001b[38;5;241m&\u001b[39m (\n\u001b[1;32m     48\u001b[0m         np\u001b[38;5;241m.\u001b[39marray(BDT_perf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mggF HH\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreds\u001b[39m\u001b[38;5;124m'\u001b[39m][fold_idx])[:, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m score_cut\n\u001b[1;32m     49\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"mass_sculpting\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "if 'BDT_perf' not in globals():\n",
    "    with open(os.path.join(OUTPUT_DIRPATH, CURRENT_TIME+f\"_BDT_perf.json\"), 'r') as f:\n",
    "        BDT_perf = json.load(f)\n",
    "\n",
    "score_cuts = [0.0, 0.7, 0.99]\n",
    "label_arr = {\n",
    "    MC_NAMES_PRETTY[sample_name]: [f'score above {score_cut}' for score_cut in score_cuts] for sample_name in order\n",
    "}\n",
    "\n",
    "# Loop over and plot the per-fold variables\n",
    "for fold_idx in range(len(hlf_vars_columns_dict)):\n",
    "\n",
    "    for var_idx, var_name in enumerate(['mass', 'dijet_mass']):\n",
    "\n",
    "        plot_dirpath_ = os.path.join(plot_dirpath, var_name)\n",
    "        if not os.path.exists(plot_dirpath_):\n",
    "            os.makedirs(plot_dirpath_)\n",
    "\n",
    "        train_hists, val_hists, test_hists = {}, {}, {}\n",
    "        for i, sample_name in enumerate(order):\n",
    "\n",
    "            train_hists[sample_name], val_hists[sample_name], test_hists[sample_name] = list(), list(), list()\n",
    "            for score_cut in score_cuts:\n",
    "\n",
    "                train_mask = (\n",
    "                    xgb_label_train_dict[f'fold_{fold_idx}'] == i\n",
    "                ) & (\n",
    "                    np.array(BDT_perf['ggF HH']['train_preds'][fold_idx])[:, 0] > score_cut\n",
    "                )\n",
    "                val_mask = (\n",
    "                    xgb_label_val_dict[f'fold_{fold_idx}'] == i\n",
    "                ) & (\n",
    "                    np.array(BDT_perf['ggF HH']['val_preds'][fold_idx])[:, 0] > score_cut\n",
    "                )\n",
    "                test_mask = (\n",
    "                    xgb_label_test_dict[f'fold_{fold_idx}'] == i\n",
    "                ) & (\n",
    "                    np.array(BDT_perf['ggF HH']['preds'][fold_idx])[:, 0] > score_cut\n",
    "                )\n",
    "            \n",
    "                train_np = (\n",
    "                    data_aux_dict[f'fold_{fold_idx}'].iloc[train_idxs_dict[f'fold_{fold_idx}']]\n",
    "                ).loc[train_mask, var_name].to_numpy()\n",
    "                val_np = (\n",
    "                    data_aux_dict[f'fold_{fold_idx}'].iloc[val_idxs_dict[f'fold_{fold_idx}']]\n",
    "                ).loc[val_mask, var_name].to_numpy()\n",
    "                test_np = data_test_aux_dict[f'fold_{fold_idx}'].loc[test_mask, var_name].to_numpy()\n",
    "            \n",
    "                train_hists[sample_name].append(hist.Hist(VARIABLES[var_name]).fill(var=train_np))\n",
    "                val_hists[sample_name].append(hist.Hist(VARIABLES[var_name]).fill(var=val_np))\n",
    "                test_hists[sample_name].append(hist.Hist(VARIABLES[var_name]).fill(var=test_np))\n",
    "    \n",
    "            for j, (plot_type, histdict) in enumerate([('train_', train_hists), ('val_', val_hists), ('test_', test_hists)]):\n",
    "                make_input_plot(\n",
    "                    plot_dirpath_, var_name,\n",
    "                    histdict[sample_name], \n",
    "                    fold_idx=fold_idx, labels=label_arr[MC_NAMES_PRETTY[sample_name]], \n",
    "                    plot_prefix=plot_type+f'{sample_name}_scoreCut_'\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling for Mass Sculpting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_from_var(sample_var, sample_weight, n_events, n_samples_per_event=1, bins=100, seed=None):\n",
    "    resample_rng = np.random.default_rng(seed=seed)\n",
    "\n",
    "    np_hist, bin_edges = np.histogram(sample_var, bins=bins, weights=sample_weight, density=True)\n",
    "    np_hist /= np.sum(np_hist)\n",
    "\n",
    "    bin_choices = resample_rng.choice(np.arange(len(np_hist)), size=n_events*n_samples_per_event, p=np_hist)\n",
    "\n",
    "    value_choices = (bin_edges[bin_choices+1] - bin_edges[bin_choices]) * resample_rng.random(size=n_events*n_samples_per_event) + bin_edges[bin_choices]\n",
    "\n",
    "    return value_choices\n",
    "\n",
    "def resample_grow_np(var, bool_arr, n_duplicates_per_event):\n",
    "    new_rows_shape = tuple([n_duplicates_per_event]+[1 for _ in range(1, len(np.shape(var)))])\n",
    "    new_rows = np.tile(\n",
    "        var[bool_arr],\n",
    "        new_rows_shape\n",
    "    )\n",
    "    return np.concatenate([var, new_rows])\n",
    "def resample_grow_pd(var, bool_arr, n_duplicates_per_event):\n",
    "    new_rows = pd.DataFrame(\n",
    "        np.tile(\n",
    "            ( var.loc[bool_arr] ).to_numpy(),\n",
    "            (n_duplicates_per_event, 1)\n",
    "        ),\n",
    "        columns=var.columns\n",
    "    )\n",
    "    return pd.concat([var, new_rows], ignore_index=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resample_ = 10\n",
    "RESAMPLE = (resample_) * 10  # Set to False for no resampling, otherwise sets the number of times to duplicate gjet data for resampling\n",
    "\n",
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"mass_sculpting_resample\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "score_cuts = [0.0, 0.7, 0.99, 0.9984]\n",
    "label_arr = [f'score above {score_cut}' for score_cut in score_cuts]\n",
    "plot_vars = ['mass', 'dijet_mass', 'HHbbggCandidate_mass']\n",
    "\n",
    "BDT_perf_resample = [\n",
    "    {\n",
    "        f'preds{score_cut}': copy.deepcopy({plot_var: list() for plot_var in plot_vars}) for score_cut in score_cuts\n",
    "    } for fold_idx in range(len(bdt_train_dict))\n",
    "]\n",
    "GJet_preds = []\n",
    "mean_values = {\n",
    "    'gj': list(),\n",
    "    'gg': list(),\n",
    "    'tth': list()\n",
    "}\n",
    "\n",
    "for fold_idx in range(len(bdt_train_dict)):\n",
    "    booster = xgb.Booster(param)\n",
    "    booster.load_model(os.path.join(OUTPUT_DIRPATH, f'{CURRENT_TIME}_BDT_fold{fold_idx}.model'))\n",
    "\n",
    "    nonres_bool = (data_test_aux_dict[f\"fold_{fold_idx}\"].loc[:, 'sample_name'] == \"GGJets\") | (data_test_aux_dict[f\"fold_{fold_idx}\"].loc[:, 'sample_name'] == \"GJetPt20To40\") | (data_test_aux_dict[f\"fold_{fold_idx}\"].loc[:, 'sample_name'] == \"GJetPt40\")\n",
    "\n",
    "    data_hlf_test = resample_grow_np(data_hlf_test_dict[f\"fold_{fold_idx}\"], nonres_bool, resample_)\n",
    "    data_test_aux = resample_grow_pd(data_test_aux_dict[f\"fold_{fold_idx}\"], nonres_bool, resample_)\n",
    "    weight_test = resample_grow_np(weight_test_dict[f\"fold_{fold_idx}\"], nonres_bool, resample_)\n",
    "    weights_plot = resample_grow_np(weights_plot_test[f\"fold_{fold_idx}\"], nonres_bool, resample_)\n",
    "    xgb_label_test = resample_grow_np(xgb_label_test_dict[f\"fold_{fold_idx}\"], nonres_bool, resample_)\n",
    "\n",
    "    gg_bool = (data_test_aux.loc[:, 'sample_name'] == \"GGJets\")\n",
    "    tth_bool = (data_test_aux.loc[:, 'sample_name'] == \"ttHToGG\")\n",
    "    gj_bool = (data_test_aux.loc[:, 'sample_name'] == \"GJetPt20To40\") | (data_test_aux.loc[:, 'sample_name'] == \"GJetPt40\")\n",
    "    hh_bool = (data_test_aux.loc[:, 'sample_name'] == \"GluGluToHH\")\n",
    "    nonres_bool = (data_test_aux.loc[:, 'sample_name'] == \"GGJets\") | (data_test_aux.loc[:, 'sample_name'] == \"GJetPt20To40\") | (data_test_aux.loc[:, 'sample_name'] == \"GJetPt40\")\n",
    "\n",
    "\n",
    "    for var_idx, plot_var in enumerate(plot_vars):\n",
    "\n",
    "        plot_dirpath_ = os.path.join(plot_dirpath, plot_var)\n",
    "        if not os.path.exists(plot_dirpath_):\n",
    "            os.makedirs(plot_dirpath_)\n",
    "\n",
    "        for _ in range(RESAMPLE // resample_):\n",
    "\n",
    "            for particle_type in ['lead', 'sublead']:\n",
    "\n",
    "                # gg_mvaID = data_hlf_test[\n",
    "                #     gg_bool, \n",
    "                #     hlf_vars_columns_dict[f\"fold_{fold_idx}\"][f\"{particle_type}_mvaID\"]\n",
    "                # ]\n",
    "                # data_hlf_test[\n",
    "                #     gj_bool, \n",
    "                #     hlf_vars_columns_dict[f\"fold_{fold_idx}\"][f\"{particle_type}_mvaID\"]\n",
    "                # ] = resample_from_var(\n",
    "                #     gg_mvaID, \n",
    "                #     weights_plot[gg_bool],\n",
    "                #     np.sum(gj_bool),\n",
    "                #     bins=190\n",
    "                # )\n",
    "\n",
    "                tth_pNetB = data_hlf_test[\n",
    "                    tth_bool, \n",
    "                    hlf_vars_columns_dict[f\"fold_{fold_idx}\"][f\"{particle_type}_bjet_btagPNetB\"]\n",
    "                ]\n",
    "                data_hlf_test[\n",
    "                    nonres_bool, \n",
    "                    hlf_vars_columns_dict[f\"fold_{fold_idx}\"][f\"{particle_type}_bjet_btagPNetB\"]\n",
    "                ] = resample_from_var(\n",
    "                    tth_pNetB, \n",
    "                    weights_plot[tth_bool],\n",
    "                    np.sum(nonres_bool),\n",
    "                    bins=100\n",
    "                )\n",
    "\n",
    "                # tth_sigmaE = data_hlf_test[\n",
    "                #     tth_bool, \n",
    "                #     hlf_vars_columns_dict[f\"fold_{fold_idx}\"][f\"{particle_type}_sigmaE_over_E\"]\n",
    "                # ]\n",
    "                # data_hlf_test[\n",
    "                #     gj_bool, \n",
    "                #     hlf_vars_columns_dict[f\"fold_{fold_idx}\"][f\"{particle_type}_sigmaE_over_E\"]\n",
    "                # ] = resample_from_var(\n",
    "                #     tth_sigmaE, \n",
    "                #     np.abs(weights_plot[tth_bool]),\n",
    "                #     np.sum(gj_bool),\n",
    "                #     bins=100\n",
    "                # )\n",
    "            # hh_dijet = data_hlf_test[\n",
    "            #     hh_bool, \n",
    "            #     hlf_vars_columns_dict[f\"fold_{fold_idx}\"][\"dijet_mass\"]\n",
    "            # ]\n",
    "            # data_hlf_test[\n",
    "            #     nonres_bool, \n",
    "            #     hlf_vars_columns_dict[f\"fold_{fold_idx}\"][\"dijet_mass\"]\n",
    "            # ] = resample_from_var(\n",
    "            #     hh_dijet, \n",
    "            #     np.abs(weights_plot[hh_bool]),\n",
    "            #     np.sum(nonres_bool),\n",
    "            #     bins=100\n",
    "            # )\n",
    "\n",
    "            nonres_ggf_preds = booster.predict(\n",
    "                xgb.DMatrix(\n",
    "                    data=data_hlf_test[nonres_bool], label=xgb_label_test[nonres_bool], \n",
    "                    weight=np.abs(weight_test)[nonres_bool],\n",
    "                    missing=-999.0, feature_names=list(hlf_vars_columns_dict[f\"fold_{fold_idx}\"])\n",
    "                ), \n",
    "                iteration_range=(0, booster.best_iteration+1)\n",
    "            )[:, 0]\n",
    "\n",
    "            # gg_ggf_preds = booster.predict(\n",
    "            #     xgb.DMatrix(\n",
    "            #         data=data_hlf_test[gg_bool], label=xgb_label_test[gg_bool], \n",
    "            #         weight=np.abs(weight_test)[gg_bool],\n",
    "            #         missing=-999.0, feature_names=list(hlf_vars_columns_dict[f\"fold_{fold_idx}\"])\n",
    "            #     ), \n",
    "            #     iteration_range=(0, booster.best_iteration+1)\n",
    "            # )[:, 0]\n",
    "            # tth_ggf_preds = booster.predict(\n",
    "            #     xgb.DMatrix(\n",
    "            #         data=data_hlf_test[tth_bool], label=xgb_label_test[tth_bool], \n",
    "            #         weight=np.abs(weight_test)[tth_bool],\n",
    "            #         missing=-999.0, feature_names=list(hlf_vars_columns_dict[f\"fold_{fold_idx}\"])\n",
    "            #     ), \n",
    "            #     iteration_range=(0, booster.best_iteration+1)\n",
    "            # )[:, 0]\n",
    "\n",
    "            if np.sum([len(GJet_preds[i]) for i in range(len(GJet_preds))]) < 100000:\n",
    "                GJet_preds.append(nonres_ggf_preds[nonres_ggf_preds > 0.9])\n",
    "\n",
    "            for score_cut in score_cuts:\n",
    "                if len(BDT_perf_resample[fold_idx][f'preds{score_cut}'][plot_var]) >= 10000:\n",
    "                    continue\n",
    "\n",
    "                BDT_perf_resample[fold_idx][f'preds{score_cut}'][plot_var].append(\n",
    "                    data_test_aux.loc[nonres_bool, plot_var].to_numpy()[nonres_ggf_preds > score_cut]\n",
    "                )\n",
    "        if fold_idx == 0 and plot_var == 'mass':\n",
    "            plt.figure()\n",
    "            plt.hist(np.concatenate(GJet_preds), bins=400, range=(0.9, 1.))\n",
    "            plt.savefig(os.path.join(plot_dirpath_, \"GJet_output_dist_with_resample0p9\"))\n",
    "\n",
    "        test_hists = [hist.Hist(VARIABLES[plot_var]).fill(var=np.concatenate(BDT_perf_resample[fold_idx][f'preds{score_cut}'][plot_var])) for score_cut in score_cuts]\n",
    "        make_input_plot(\n",
    "            plot_dirpath_, plot_var,\n",
    "            test_hists, \n",
    "            fold_idx=fold_idx, labels=label_arr, \n",
    "            plot_prefix='test_non-res_scoreCut_'\n",
    "        )\n",
    "\n",
    "for var_idx, plot_var in enumerate(plot_vars):\n",
    "\n",
    "    plot_dirpath_ = os.path.join(plot_dirpath, plot_var)\n",
    "    if not os.path.exists(plot_dirpath_):\n",
    "        os.makedirs(plot_dirpath_)\n",
    "\n",
    "    test_hists = [hist.Hist(VARIABLES[plot_var]).fill(\n",
    "        var=np.concatenate(\n",
    "            [np.concatenate(BDT_perf_resample[fold_idx][f'preds{score_cut}'][plot_var]) for fold_idx in range(len(BDT_perf_resample))]\n",
    "        )\n",
    "    ) for score_cut in score_cuts]\n",
    "    make_input_plot(\n",
    "        plot_dirpath_, plot_var,\n",
    "        test_hists, \n",
    "        fold_idx=None, labels=label_arr, \n",
    "        plot_prefix='test_non-res_scoreCut_'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"pre_std\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "label_arr_fold = [\n",
    "    MC_NAMES_PRETTY[\"GluGluToHH\"]+\" train\", MC_NAMES_PRETTY[\"GluGluToHH\"]+\" val\", MC_NAMES_PRETTY[\"GluGluToHH\"]+\" test\",\n",
    "    MC_NAMES_PRETTY[\"ttHToGG\"]+\" train\", MC_NAMES_PRETTY[\"ttHToGG\"]+\" val\", MC_NAMES_PRETTY[\"ttHToGG\"]+\" test\",\n",
    "    # MC_NAMES_PRETTY[\"single-H\"]+\" train\", MC_NAMES_PRETTY[\"single-H\"]+\" val\", MC_NAMES_PRETTY[\"single-H\"]+\" test\",\n",
    "    # MC_NAMES_PRETTY[\"non-res\"]+\" train\", MC_NAMES_PRETTY[\"non-res\"]+\" val\", MC_NAMES_PRETTY[\"non-res\"]+\" test\",\n",
    "    MC_NAMES_PRETTY[\"VH\"]+\" train\", MC_NAMES_PRETTY[\"VH\"]+\" val\", MC_NAMES_PRETTY[\"VH\"]+\" test\",\n",
    "    MC_NAMES_PRETTY[\"non-res + ggFH + VBFH\"]+\" train\", MC_NAMES_PRETTY[\"non-res + ggFH + VBFH\"]+\" val\", MC_NAMES_PRETTY[\"non-res + ggFH + VBFH\"]+\" test\",\n",
    "]\n",
    "# Loop over and plot the per-fold variables\n",
    "for fold_idx in range(len(hlf_vars_columns_dict)):\n",
    "\n",
    "    for var_name in hlf_vars_columns_dict['fold_0']:\n",
    "        if var_name in {'puppiMET_eta'}:\n",
    "            continue\n",
    "\n",
    "        plot_dirpath_ = os.path.join(plot_dirpath, var_name)\n",
    "        if not os.path.exists(plot_dirpath_):\n",
    "            os.makedirs(plot_dirpath_)\n",
    "\n",
    "        train_hists, val_hists, test_hists = {}, {}, {}\n",
    "        for i, sample_name in enumerate(order):\n",
    "            train_mask = xgb_label_train_dict[f'fold_{fold_idx}'] == i\n",
    "            val_mask = xgb_label_val_dict[f'fold_{fold_idx}'] == i\n",
    "            test_mask = xgb_label_test_dict[f'fold_{fold_idx}'] == i\n",
    "\n",
    "            train_np = (\n",
    "                data_df_dict[f'fold_{fold_idx}'].iloc[train_idxs_dict[f'fold_{fold_idx}']]\n",
    "            ).loc[train_mask, var_name].to_numpy()\n",
    "            val_np = (\n",
    "                data_df_dict[f'fold_{fold_idx}'].iloc[val_idxs_dict[f'fold_{fold_idx}']]\n",
    "            ).loc[val_mask, var_name].to_numpy()\n",
    "            test_np = data_test_df_dict[f'fold_{fold_idx}'].loc[test_mask, var_name].to_numpy()\n",
    "\n",
    "            train_hists[sample_name] = hist.Hist(VARIABLES[var_name]).fill(var=train_np)\n",
    "            val_hists[sample_name] = hist.Hist(VARIABLES[var_name]).fill(var=val_np)\n",
    "            test_hists[sample_name] = hist.Hist(VARIABLES[var_name]).fill(var=test_np)\n",
    "    \n",
    "            make_input_plot(\n",
    "                plot_dirpath_, var_name,\n",
    "                [train_hists[sample_name], val_hists[sample_name], test_hists[sample_name]], \n",
    "                fold_idx=fold_idx, labels=label_arr_fold[3*i : 3*(i+1)], plot_prefix=f'train_val_test_{sample_name}_'\n",
    "            )\n",
    "        for j, (plot_type, histdict) in enumerate([('train_', train_hists), ('val_', val_hists), ('test_', test_hists)]):\n",
    "            make_input_plot(\n",
    "                plot_dirpath_, var_name,\n",
    "                [histdict[sample_name] for sample_name in order], \n",
    "                fold_idx=fold_idx, labels=label_arr_fold[j::3], plot_prefix=plot_type\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dirpath = os.path.join(OUTPUT_DIRPATH, \"plots\", \"post_std\")\n",
    "if not os.path.exists(plot_dirpath):\n",
    "    os.makedirs(plot_dirpath)\n",
    "\n",
    "label_arr_fold = [\n",
    "    MC_NAMES_PRETTY[\"GluGluToHH\"]+\" train\", MC_NAMES_PRETTY[\"GluGluToHH\"]+\" val\", MC_NAMES_PRETTY[\"GluGluToHH\"]+\" test\",\n",
    "    MC_NAMES_PRETTY[\"ttHToGG\"]+\" train\", MC_NAMES_PRETTY[\"ttHToGG\"]+\" val\", MC_NAMES_PRETTY[\"ttHToGG\"]+\" test\",\n",
    "    # MC_NAMES_PRETTY[\"single-H\"]+\" train\", MC_NAMES_PRETTY[\"single-H\"]+\" val\", MC_NAMES_PRETTY[\"single-H\"]+\" test\",\n",
    "    # MC_NAMES_PRETTY[\"non-res\"]+\" train\", MC_NAMES_PRETTY[\"non-res\"]+\" val\", MC_NAMES_PRETTY[\"non-res\"]+\" test\",\n",
    "    MC_NAMES_PRETTY[\"VH\"]+\" train\", MC_NAMES_PRETTY[\"VH\"]+\" val\", MC_NAMES_PRETTY[\"VH\"]+\" test\",\n",
    "    MC_NAMES_PRETTY[\"non-res + ggFH + VBFH\"]+\" train\", MC_NAMES_PRETTY[\"non-res + ggFH + VBFH\"]+\" val\", MC_NAMES_PRETTY[\"non-res + ggFH + VBFH\"]+\" test\",\n",
    "]\n",
    "# Loop over and plot the per-fold variables\n",
    "for fold_idx in range(len(hlf_vars_columns_dict)):\n",
    "\n",
    "    for var_idx, var_name in enumerate(hlf_vars_columns_dict['fold_0']):\n",
    "        if var_name in {'puppiMET_eta'}:\n",
    "            continue\n",
    "\n",
    "        plot_dirpath_ = os.path.join(plot_dirpath, var_name)\n",
    "        if not os.path.exists(plot_dirpath_):\n",
    "            os.makedirs(plot_dirpath_)\n",
    "\n",
    "        train_hists, val_hists, test_hists = {}, {}, {}\n",
    "        for i, sample_name in enumerate(order):\n",
    "            train_mask = xgb_label_train_dict[f'fold_{fold_idx}'] == i\n",
    "            val_mask = xgb_label_val_dict[f'fold_{fold_idx}'] == i\n",
    "            test_mask = xgb_label_test_dict[f'fold_{fold_idx}'] == i\n",
    "\n",
    "            train_np = train_data_dict[f'fold_{fold_idx}'][train_mask, var_idx]\n",
    "            val_np = val_data_dict[f'fold_{fold_idx}'][val_mask, var_idx]\n",
    "            test_np = data_hlf_test_dict[f'fold_{fold_idx}'][test_mask, var_idx]\n",
    "\n",
    "            train_hists[sample_name] = hist.Hist(VARIABLES_STD[var_name]).fill(var=train_np)\n",
    "            val_hists[sample_name] = hist.Hist(VARIABLES_STD[var_name]).fill(var=val_np)\n",
    "            test_hists[sample_name] = hist.Hist(VARIABLES_STD[var_name]).fill(var=test_np)\n",
    "    \n",
    "            make_input_plot(\n",
    "                plot_dirpath_, var_name,\n",
    "                [train_hists[sample_name], val_hists[sample_name], test_hists[sample_name]], \n",
    "                fold_idx=fold_idx, labels=label_arr_fold[3*i : 3*(i+1)], plot_prefix=f'train_val_test_{sample_name}_'\n",
    "            )\n",
    "        for j, (plot_type, histdict) in enumerate([('train_', train_hists), ('val_', val_hists), ('test_', test_hists)]):\n",
    "            make_input_plot(\n",
    "                plot_dirpath_, var_name,\n",
    "                [histdict[sample_name] for sample_name in order], \n",
    "                fold_idx=fold_idx, labels=label_arr_fold[j::3], plot_prefix=plot_type\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save out new parquets for Yibo to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL_DATA_ON_ALL_FOLDS = True\n",
    "\n",
    "# load and pre-process the data\n",
    "DATA_FILEPATHS_DICT = {\n",
    "    'Data': [\n",
    "        lpc_fileprefix+f\"/Run3_2022preEE_merged_v5/Data_EraC/nominal/*\", \n",
    "        lpc_fileprefix+f\"/Run3_2022preEE_merged_v5/Data_EraD/nominal/*\",\n",
    "        lpc_fileprefix+f\"/Run3_2022postEE_merged_v5/Data_EraE/nominal/*\",\n",
    "        lpc_fileprefix+f\"/Run3_2022postEE_merged_v5/Data_EraF/nominal/*\",\n",
    "        lpc_fileprefix+f\"/Run3_2022postEE_merged_v5/Data_EraG/nominal/*\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "(\n",
    "    NOTHING_IGNORE,\n",
    "    DATA_data_df_dict, DATA_data_test_df_dict, \n",
    "    DATA_data_hlf_dict, DATA_label_dict,\n",
    "    DATA_data_hlf_test_dict, DATA_label_test_dict, \n",
    "    DATA_hlf_vars_columns_dict,\n",
    "    DATA_data_aux_dict, DATA_data_test_aux_dict\n",
    ") = process_data(\n",
    "    DATA_FILEPATHS_DICT, OUTPUT_DIRPATH, order=['Data'], mod_vals=MOD_VALS, k_fold_test=True,\n",
    "    save=False, std_json_dirpath=OUTPUT_DIRPATH\n",
    ")\n",
    "\n",
    "BDT_DATA_preds = []\n",
    "\n",
    "if EVAL_DATA_ON_ALL_FOLDS:\n",
    "\n",
    "    bdt_train_data_dict = xgb.DMatrix(\n",
    "        data=DATA_data_hlf_dict[f\"fold_0\"], label=DATA_label_dict[f\"fold_0\"], \n",
    "        missing=-999.0, feature_names=list(DATA_hlf_vars_columns_dict[f\"fold_0\"])\n",
    "    )\n",
    "    bdt_test_data_dict = xgb.DMatrix(\n",
    "        data=DATA_data_hlf_test_dict[f\"fold_0\"], label=DATA_label_test_dict[f\"fold_0\"], \n",
    "        missing=-999.0, feature_names=list(DATA_hlf_vars_columns_dict[f\"fold_0\"])\n",
    "    )\n",
    "\n",
    "    for fold_idx in range(len(DATA_label_test_dict)):\n",
    "        booster = xgb.Booster(param)\n",
    "        booster.load_model(os.path.join(OUTPUT_DIRPATH, f'{CURRENT_TIME}_BDT_fold{fold_idx}.model'))\n",
    "\n",
    "        BDT_train_preds = booster.predict(\n",
    "            bdt_train_data_dict, \n",
    "            iteration_range=(0, booster.best_iteration+1)\n",
    "        )\n",
    "        BDT_test_preds = booster.predict(\n",
    "            bdt_test_data_dict, \n",
    "            iteration_range=(0, booster.best_iteration+1)\n",
    "        )\n",
    "\n",
    "        BDT_all_preds = np.concatenate([BDT_train_preds, BDT_test_preds])\n",
    "        BDT_all_preds = BDT_all_preds[\n",
    "            np.argsort(\n",
    "                np.concatenate([DATA_data_aux_dict[f\"fold_0\"].loc[:, 'hash'].to_numpy(), DATA_data_test_aux_dict[f\"fold_0\"].loc[:, 'hash'].to_numpy()])\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        if fold_idx == 0:\n",
    "            BDT_DATA_preds = copy.deepcopy(BDT_all_preds)\n",
    "        else:\n",
    "            BDT_DATA_preds += BDT_all_preds\n",
    "\n",
    "            if fold_idx == len(DATA_label_test_dict) - 1:\n",
    "                BDT_DATA_preds = BDT_DATA_preds / len(DATA_label_test_dict)\n",
    "else:\n",
    "\n",
    "    bdt_train_data_dict, bdt_test_data_dict = {}, {}\n",
    "    for fold_idx in range(len(DATA_label_test_dict)):\n",
    "        \n",
    "        bdt_train_data_dict[f\"fold_{fold_idx}\"] = xgb.DMatrix(\n",
    "            data=DATA_data_hlf_dict[f\"fold_{fold_idx}\"], label=DATA_label_dict[f\"fold_{fold_idx}\"], \n",
    "            missing=-999.0, feature_names=list(DATA_hlf_vars_columns_dict[f\"fold_{fold_idx}\"])\n",
    "        )\n",
    "        bdt_test_data_dict[f\"fold_{fold_idx}\"] = xgb.DMatrix(\n",
    "            data=DATA_data_hlf_test_dict[f\"fold_{fold_idx}\"], label=DATA_label_test_dict[f\"fold_{fold_idx}\"], \n",
    "            missing=-999.0, feature_names=list(DATA_hlf_vars_columns_dict[f\"fold_{fold_idx}\"])\n",
    "        )\n",
    "\n",
    "        booster = xgb.Booster(param)\n",
    "        booster.load_model(os.path.join(OUTPUT_DIRPATH, f'{CURRENT_TIME}_BDT_fold{fold_idx}.model'))\n",
    "\n",
    "        BDT_DATA_preds.append(\n",
    "            booster.predict(\n",
    "                bdt_test_data_dict[f\"fold_{fold_idx}\"], \n",
    "                iteration_range=(0, booster.best_iteration+1)\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Plot to show data labels look ok\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "hist_axis = hist.axis.Regular(100, 0., 1., name='var', growth=False, underflow=False, overflow=False)\n",
    "\n",
    "data_hists, data_plot_labels = [], []\n",
    "if not EVAL_DATA_ON_ALL_FOLDS:\n",
    "    \n",
    "    for fold_idx in range(len(BDT_DATA_preds)):\n",
    "\n",
    "        data_hists.append(\n",
    "            hist.Hist(hist_axis, storage='weight').fill(\n",
    "                var=np.array(BDT_DATA_preds[fold_idx])[:, 0],\n",
    "            )\n",
    "        )\n",
    "        data_plot_labels.append(f\"fold {fold_idx}\")\n",
    "else:\n",
    "\n",
    "    data_hists.append(\n",
    "        hist.Hist(hist_axis, storage='weight').fill(\n",
    "            var=np.array(BDT_DATA_preds)[:, 0],\n",
    "        )\n",
    "    )\n",
    "    data_plot_labels.append(f\"sum over folds\")\n",
    "\n",
    "hep.histplot(\n",
    "    data_hists,\n",
    "    alpha=0.5, density=False, histtype='step',\n",
    "    label=data_plot_labels\n",
    ")\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022preEE_merged_v5_MultiBDT_output/GluGluToHH/nominal/GluGluToHH_nominal_MultiBDT_output.parquet\n",
      "============================================================\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022postEE_merged_v5_MultiBDT_output/GluGluToHH/nominal/GluGluToHH_nominal_MultiBDT_output.parquet\n",
      "============================================================\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022preEE_merged_v5_MultiBDT_output/ttHToGG/nominal/ttHToGG_nominal_MultiBDT_output.parquet\n",
      "============================================================\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022postEE_merged_v5_MultiBDT_output/ttHToGG/nominal/ttHToGG_nominal_MultiBDT_output.parquet\n",
      "============================================================\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022preEE_merged_v5_MultiBDT_output/VHToGG/nominal/VHToGG_nominal_MultiBDT_output.parquet\n",
      "============================================================\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022postEE_merged_v5_MultiBDT_output/VHToGG/nominal/VHToGG_nominal_MultiBDT_output.parquet\n",
      "============================================================\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022preEE_merged_v5_MultiBDT_output/GGJets/nominal/GGJets_nominal_MultiBDT_output.parquet\n",
      "============================================================\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022postEE_merged_v5_MultiBDT_output/GGJets/nominal/GGJets_nominal_MultiBDT_output.parquet\n",
      "============================================================\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022preEE_merged_v5_MultiBDT_output/GJetPt20To40/nominal/GJetPt20To40_nominal_MultiBDT_output.parquet\n",
      "============================================================\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022postEE_merged_v5_MultiBDT_output/GJetPt20To40/nominal/GJetPt20To40_nominal_MultiBDT_output.parquet\n",
      "============================================================\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022preEE_merged_v5_MultiBDT_output/GJetPt40/nominal/GJetPt40_nominal_MultiBDT_output.parquet\n",
      "============================================================\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022postEE_merged_v5_MultiBDT_output/GJetPt40/nominal/GJetPt40_nominal_MultiBDT_output.parquet\n",
      "============================================================\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022preEE_merged_v5_MultiBDT_output/GluGluHToGG/nominal/GluGluHToGG_nominal_MultiBDT_output.parquet\n",
      "============================================================\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022postEE_merged_v5_MultiBDT_output/GluGluHToGG/nominal/GluGluHToGG_nominal_MultiBDT_output.parquet\n",
      "============================================================\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022preEE_merged_v5_MultiBDT_output/VBFHToGG/nominal/VBFHToGG_nominal_MultiBDT_output.parquet\n",
      "============================================================\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022postEE_merged_v5_MultiBDT_output/VBFHToGG/nominal/VBFHToGG_nominal_MultiBDT_output.parquet\n",
      "============================================================\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022preEE_merged_v5_MultiBDT_output/Data_EraC/nominal/Data_EraC_nominal_MultiBDT_output.parquet\n",
      "============================================================\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022preEE_merged_v5_MultiBDT_output/Data_EraD/nominal/Data_EraD_nominal_MultiBDT_output.parquet\n",
      "============================================================\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022postEE_merged_v5_MultiBDT_output/Data_EraE/nominal/Data_EraE_nominal_MultiBDT_output.parquet\n",
      "============================================================\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022postEE_merged_v5_MultiBDT_output/Data_EraF/nominal/Data_EraF_nominal_MultiBDT_output.parquet\n",
      "============================================================\n",
      "/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1/Run3_2022postEE_merged_v5_MultiBDT_output/Data_EraG/nominal/Data_EraG_nominal_MultiBDT_output.parquet\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# load and pre-process the data\n",
    "DATA_FILEPATHS_DICT = {\n",
    "    'Data': [\n",
    "        lpc_fileprefix+f\"/Run3_2022preEE_merged_v5/Data_EraC/nominal/*\", \n",
    "        lpc_fileprefix+f\"/Run3_2022preEE_merged_v5/Data_EraD/nominal/*\",\n",
    "        lpc_fileprefix+f\"/Run3_2022postEE_merged_v5/Data_EraE/nominal/*\",\n",
    "        lpc_fileprefix+f\"/Run3_2022postEE_merged_v5/Data_EraF/nominal/*\",\n",
    "        lpc_fileprefix+f\"/Run3_2022postEE_merged_v5/Data_EraG/nominal/*\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Sorts the predictions to map the output to the correct event\n",
    "def sorted_preds(preds, data_aux, sample, sorted_preds=False):\n",
    "    if not sorted_preds:\n",
    "        flat_preds = np.concatenate([preds[fold_idx] for fold_idx in range(len(data_aux))])\n",
    "        preds_sort = np.argsort(\n",
    "            np.concatenate([data_aux[f\"fold_{fold_idx}\"].loc[:, 'hash'].to_numpy() for fold_idx in range(len(data_aux))])\n",
    "        )\n",
    "    else:\n",
    "        flat_preds = preds\n",
    "        preds_sort = np.arange(len(flat_preds))\n",
    "\n",
    "    sample_sort = np.argsort(np.argsort(\n",
    "        ak.to_numpy(sample['hash'], allow_missing=False)\n",
    "    ))\n",
    "\n",
    "    return flat_preds[preds_sort][sample_sort]\n",
    "\n",
    "## MC SAMPLES ##\n",
    "# Load parquet files #\n",
    "for i, sample_name in enumerate(order):\n",
    "    for dirpath in FILEPATHS_DICT[sample_name]:\n",
    "        parquet_filepath = glob.glob(dirpath)[0]\n",
    "        sample = ak.from_parquet(parquet_filepath)\n",
    "\n",
    "        (\n",
    "            NOTHING_IGNORE,\n",
    "            IGNORE_data_df_dict, SAMPLE_data_test_df_dict, \n",
    "            IGNORE_data_hlf_dict, IGNORE_label_dict,\n",
    "            SAMPLE_data_hlf_test_dict, SAMPLE_label_test_dict, \n",
    "            SAMPLE_hlf_vars_columns_dict,\n",
    "            IGNORE_data_aux_dict, SAMPLE_data_test_aux_dict\n",
    "        ) = process_data(\n",
    "            {\"sample\": [parquet_filepath]}, OUTPUT_DIRPATH, order=['sample'], mod_vals=MOD_VALS, k_fold_test=True,\n",
    "            save=False, std_json_dirpath=OUTPUT_DIRPATH\n",
    "        )\n",
    "\n",
    "        sample_preds = []\n",
    "        for fold_idx in range(len(SAMPLE_data_test_df_dict)):\n",
    "            booster = xgb.Booster(param)\n",
    "            booster.load_model(os.path.join(OUTPUT_DIRPATH, f'{CURRENT_TIME}_BDT_fold{fold_idx}.model'))\n",
    "\n",
    "            bdt_test_sample_dict = xgb.DMatrix(\n",
    "                data=SAMPLE_data_hlf_test_dict[f\"fold_{fold_idx}\"], label=SAMPLE_label_test_dict[f\"fold_{fold_idx}\"], \n",
    "                missing=-999.0, feature_names=list(SAMPLE_hlf_vars_columns_dict[f\"fold_{fold_idx}\"])\n",
    "            )\n",
    "\n",
    "            sample_preds.append(\n",
    "                booster.predict(\n",
    "                    bdt_test_sample_dict, \n",
    "                    iteration_range=(0, booster.best_iteration+1)\n",
    "                )\n",
    "            )\n",
    "\n",
    "        sample['MultiBDT_output'] = sorted_preds(\n",
    "            sample_preds, SAMPLE_data_test_aux_dict, sample\n",
    "        )\n",
    "\n",
    "        dest_filepath = parquet_filepath[:parquet_filepath.find('v5')+2] + '_MultiBDT_output' + parquet_filepath[parquet_filepath.find('v5')+2:parquet_filepath.rfind('.')] + '_MultiBDT_output' + parquet_filepath[parquet_filepath.rfind('.'):]\n",
    "        if not os.path.exists(dest_filepath[:dest_filepath.rfind('/')]):\n",
    "            os.makedirs(dest_filepath[:dest_filepath.rfind('/')])\n",
    "        print(dest_filepath)\n",
    "        print('='*60)\n",
    "        merged_parquet = ak.to_parquet(sample, dest_filepath)\n",
    "\n",
    "## DATA ##\n",
    "for dirpath in DATA_FILEPATHS_DICT['Data']:\n",
    "    parquet_filepath = glob.glob(dirpath)[0]\n",
    "    data_sample = ak.from_parquet(parquet_filepath)\n",
    "\n",
    "    (\n",
    "        NOTHING_IGNORE,\n",
    "        DATA_data_df_dict, DATA_data_test_df_dict, \n",
    "        DATA_data_hlf_dict, DATA_label_dict,\n",
    "        DATA_data_hlf_test_dict, DATA_label_test_dict, \n",
    "        DATA_hlf_vars_columns_dict,\n",
    "        DATA_data_aux_dict, DATA_data_test_aux_dict\n",
    "    ) = process_data(\n",
    "        {\"sample\": [parquet_filepath]}, OUTPUT_DIRPATH, order=['sample'], mod_vals=MOD_VALS, k_fold_test=True,\n",
    "        save=False, std_json_dirpath=OUTPUT_DIRPATH\n",
    "    )\n",
    "\n",
    "    bdt_train_data_dict = xgb.DMatrix(\n",
    "        data=DATA_data_hlf_dict[f\"fold_0\"], label=DATA_label_dict[f\"fold_0\"], \n",
    "        missing=-999.0, feature_names=list(DATA_hlf_vars_columns_dict[f\"fold_0\"])\n",
    "    )\n",
    "    bdt_test_data_dict = xgb.DMatrix(\n",
    "        data=DATA_data_hlf_test_dict[f\"fold_0\"], label=DATA_label_test_dict[f\"fold_0\"], \n",
    "        missing=-999.0, feature_names=list(DATA_hlf_vars_columns_dict[f\"fold_0\"])\n",
    "    )\n",
    "\n",
    "    for fold_idx in range(len(DATA_label_test_dict)):\n",
    "        booster = xgb.Booster(param)\n",
    "        booster.load_model(os.path.join(OUTPUT_DIRPATH, f'{CURRENT_TIME}_BDT_fold{fold_idx}.model'))\n",
    "\n",
    "        BDT_train_preds = booster.predict(\n",
    "            bdt_train_data_dict, \n",
    "            iteration_range=(0, booster.best_iteration+1)\n",
    "        )\n",
    "        BDT_test_preds = booster.predict(\n",
    "            bdt_test_data_dict, \n",
    "            iteration_range=(0, booster.best_iteration+1)\n",
    "        )\n",
    "\n",
    "        BDT_all_preds = np.concatenate([BDT_train_preds, BDT_test_preds])\n",
    "        BDT_all_preds = BDT_all_preds[\n",
    "            np.argsort(\n",
    "                np.concatenate([DATA_data_aux_dict[f\"fold_0\"].loc[:, 'hash'].to_numpy(), DATA_data_test_aux_dict[f\"fold_0\"].loc[:, 'hash'].to_numpy()])\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        if fold_idx == 0:\n",
    "            data_preds = copy.deepcopy(BDT_all_preds)\n",
    "        else:\n",
    "            data_preds += BDT_all_preds\n",
    "\n",
    "            if fold_idx == len(DATA_label_test_dict) - 1:\n",
    "                data_preds = data_preds / len(DATA_label_test_dict)\n",
    "\n",
    "    data_sample['MultiBDT_output'] = sorted_preds(\n",
    "        data_preds, DATA_data_test_aux_dict, data_sample,\n",
    "        sorted_preds=True\n",
    "    )\n",
    "\n",
    "    dest_filepath = parquet_filepath[:parquet_filepath.find('v5')+2] + '_MultiBDT_output' + parquet_filepath[parquet_filepath.find('v5')+2:parquet_filepath.rfind('.')] + '_MultiBDT_output' + parquet_filepath[parquet_filepath.rfind('.'):]\n",
    "    if not os.path.exists(dest_filepath[:dest_filepath.rfind('/')]):\n",
    "        os.makedirs(dest_filepath[:dest_filepath.rfind('/')])\n",
    "    print(dest_filepath)\n",
    "    print('='*60)\n",
    "    merged_parquet = ak.to_parquet(data_sample, dest_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
