{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c64a0763",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "import awkward as ak\n",
    "import hist\n",
    "import numpy as np\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import mplhep as hep\n",
    "# from cycler import cycler\n",
    "\n",
    "# plt.style.use(hep.style.CMS)\n",
    "# plt.rcParams.update({'font.size': 20})\n",
    "# cmap_petroff10 = [\"#3f90da\", \"#ffa90e\", \"#bd1f01\", \"#94a4a2\", \"#832db6\", \"#a96b59\", \"#e76300\", \"#b9ac70\", \"#717581\", \"#92dadd\"]\n",
    "# plt.rcParams.update({\"axes.prop_cycle\": cycler(\"color\", cmap_petroff10)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56168f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "lpc_fileprefix = \"/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v3.1/\"\n",
    "\n",
    "# lpc_filegroup = lambda s: f'Run3_{s}_mergedFullAllVars_MultiBDT_output'\n",
    "lpc_filegroup = lambda s: f'Run3_{s}_mergedFullAllVars_MultiBDT_output_flag'\n",
    "MC_FILEPREFIX_22 = os.path.join(lpc_fileprefix, lpc_filegroup('2022'), 'sim', '')\n",
    "MC_FILEPREFIX_23 = os.path.join(lpc_fileprefix, lpc_filegroup('2023'), 'sim', '')\n",
    "MC_FILEPREFIX_24 = os.path.join(lpc_fileprefix, lpc_filegroup('2024'), 'sim', '')\n",
    "DATA_FILEPREFIX_22 = os.path.join(lpc_fileprefix, lpc_filegroup('2022'), 'data', '')\n",
    "DATA_FILEPREFIX_23 = os.path.join(lpc_fileprefix, lpc_filegroup('2023'), 'data', '')\n",
    "DATA_FILEPREFIX_24 = os.path.join(lpc_fileprefix, lpc_filegroup('2024'), 'data', '')\n",
    "\n",
    "signal_filegroup = lambda s: f'{s}/GluGlutoHH_kl-1p00_kt-1p00_c2-0p00'\n",
    "ttH_filegroup = lambda s: f'{s}/ttHtoGG' if s != 'postEE' else f'{s}/ttHToGG'\n",
    "bbH_filegroup = lambda s: f'{s}/bbHtoGG'\n",
    "VH_filegroup = lambda s: f'{s}/VHtoGG'\n",
    "ggFH_filegroup = lambda s: f'{s}/GluGluHtoGG'\n",
    "VBFH_filegroup = lambda s: f'{s}/VBFHtoGG' if s != 'postEE' else f'{s}/VBFHToGG'\n",
    "\n",
    "END_FILEPATH = '*boostedCat.parquet'\n",
    "\n",
    "FILEPATHS = {}\n",
    "for name, filegroup in {\n",
    "    'ggF HH': signal_filegroup, \n",
    "    # 'ttH': ttH_filegroup, 'bbH': bbH_filegroup,\n",
    "    # 'VH': VH_filegroup, 'ggF H': ggFH_filegroup, 'VBF H': VBFH_filegroup,\n",
    "}.items():\n",
    "    FILEPATHS[name] = [\n",
    "        glob.glob(os.path.join(MC_FILEPREFIX_22, filegroup('preEE'), 'nominal', END_FILEPATH)),\n",
    "        glob.glob(os.path.join(MC_FILEPREFIX_22, filegroup('postEE'), 'nominal', END_FILEPATH)),\n",
    "        glob.glob(os.path.join(MC_FILEPREFIX_23, filegroup('preBPix'), 'nominal', END_FILEPATH)),\n",
    "        glob.glob(os.path.join(MC_FILEPREFIX_23, filegroup('postBPix'), 'nominal', END_FILEPATH))\n",
    "    ]\n",
    "\n",
    "FILEPATHS['Data'] = [\n",
    "    glob.glob(os.path.join(DATA_FILEPREFIX_22, END_FILEPATH)),\n",
    "    glob.glob(os.path.join(DATA_FILEPREFIX_23, END_FILEPATH))\n",
    "]\n",
    "\n",
    "order = ['ggF HH', 'ttH + bbH', 'VH', 'non-res + ggFH + VBFH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fb302af",
   "metadata": {},
   "outputs": [],
   "source": [
    "brunella_signal = np.loadtxt('/uscms/home/tsievert/nobackup/XHYbbgg/HHtobbyy/signal_pass_boosted.csv', delimiter=',', skiprows=1, usecols=(1,2))\n",
    "brunella_data = np.loadtxt('/uscms/home/tsievert/nobackup/XHYbbgg/HHtobbyy/pass_boosted_data.csv', delimiter=',', skiprows=1, usecols=(1,2))\n",
    "\n",
    "brunella_pass_boosted_lumis = {\n",
    "    'ggF HH': brunella_signal[:, 0], 'Data': brunella_data[:, 0]\n",
    "}\n",
    "brunella_pass_boosted_events = {\n",
    "    'ggF HH': brunella_signal[:, 1], 'Data': brunella_data[:, 1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d711073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ggF HH num events: 359202\n",
      "ggF HH yield: 2.066039634150619\n",
      "ggF HH boosted yield: 0.06595600450749883\n",
      "============================================================\n",
      "============================================================\n",
      "============================================================\n",
      "ggF HH\n",
      "------------------------------------------------------------\n",
      "Num ggF HH that pass boosted: 13538\n",
      "Data num events: ... vh_score: 711725, y_proba: 711725, is_boosted: 711725}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "key \"eventWeight\" does not exist (not in record)\n\n(https://github.com/scikit-hep/awkward-1.0/blob/1.10.3/src/libawkward/util.cpp#L525)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 36\u001b[0m\n\u001b[1;32m     33\u001b[0m sample \u001b[38;5;241m=\u001b[39m ak\u001b[38;5;241m.\u001b[39mconcatenate(sample_list)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m num events: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mak\u001b[38;5;241m.\u001b[39mnum(sample,\u001b[38;5;250m \u001b[39maxis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m yield: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mak\u001b[38;5;241m.\u001b[39msum(\u001b[43msample\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meventWeight\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m,\u001b[38;5;250m \u001b[39maxis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     38\u001b[0m pass_boosted \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     39\u001b[0m     (sample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis_boosted\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;241m&\u001b[39m (sample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmass\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m100\u001b[39m) \u001b[38;5;241m&\u001b[39m (sample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmass\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m180\u001b[39m)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;66;03m# & (sample['nonResReg_DNNpair_dijet_mass_DNNreg'] > 70) & (sample['nonResReg_DNNpair_dijet_mass_DNNreg'] < 190)\u001b[39;00m\n\u001b[1;32m     44\u001b[0m )\n\u001b[1;32m     45\u001b[0m pass_boosted_lumis[name] \u001b[38;5;241m=\u001b[39m ak\u001b[38;5;241m.\u001b[39mto_numpy(sample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlumi\u001b[39m\u001b[38;5;124m'\u001b[39m][pass_boosted])\n",
      "File \u001b[0;32m~/nobackup/miniforge3/envs/higgs-dna/lib/python3.10/site-packages/awkward/highlevel.py:991\u001b[0m, in \u001b[0;36mArray.__getitem__\u001b[0;34m(self, where)\u001b[0m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    580\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    581\u001b[0m \u001b[38;5;124;03m    where (many types supported; see below): Index of positions to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;124;03mhave the same dimension as the array being indexed.\u001b[39;00m\n\u001b[1;32m    989\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    990\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_tracers\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 991\u001b[0m     tmp \u001b[38;5;241m=\u001b[39m ak\u001b[38;5;241m.\u001b[39m_util\u001b[38;5;241m.\u001b[39mwrap(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayout\u001b[49m\u001b[43m[\u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m]\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_behavior)\n\u001b[1;32m    992\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    993\u001b[0m     tmp \u001b[38;5;241m=\u001b[39m ak\u001b[38;5;241m.\u001b[39m_connect\u001b[38;5;241m.\u001b[39m_jax\u001b[38;5;241m.\u001b[39mjax_utils\u001b[38;5;241m.\u001b[39m_jaxtracers_getitem(\u001b[38;5;28mself\u001b[39m, where)\n",
      "\u001b[0;31mValueError\u001b[0m: key \"eventWeight\" does not exist (not in record)\n\n(https://github.com/scikit-hep/awkward-1.0/blob/1.10.3/src/libawkward/util.cpp#L525)"
     ]
    }
   ],
   "source": [
    "def get_ttH_score(multibdt_output):\n",
    "    return multibdt_output[:, 0] / (multibdt_output[:, 0] + multibdt_output[:, 1])\n",
    "\n",
    "def get_QCD_score(multibdt_output):\n",
    "    return multibdt_output[:, 0] / (multibdt_output[:, 0] + multibdt_output[:, 2] + multibdt_output[:, 3])\n",
    "\n",
    "CATS = [\n",
    "    [0.979, 0.9983],\n",
    "    [0.96, 0.9951],\n",
    "    [0.89, 0.9868],\n",
    "]\n",
    "\n",
    "def pass_category(multibdt_output, cat_i):\n",
    "    pass_ttH = get_ttH_score(multibdt_output) > CATS[cat_i][0]\n",
    "    pass_QCD = get_QCD_score(multibdt_output) > CATS[cat_i][1]\n",
    "\n",
    "    pass_prevQCD = get_QCD_score(multibdt_output) <= (\n",
    "        CATS[cat_i-1][1] if cat_i > 1 else 1\n",
    "    )\n",
    "\n",
    "    print(np.nonzero(pass_ttH))\n",
    "    print(np.max(get_ttH_score(multibdt_output)))\n",
    "    print(np.min(get_ttH_score(multibdt_output)))\n",
    "    print(np.nonzero(pass_QCD))\n",
    "    print(np.nonzero(pass_prevQCD))\n",
    "\n",
    "    return pass_ttH & pass_QCD & pass_prevQCD\n",
    "\n",
    "pass_boosted_lumis, pass_boosted_events = {}, {}\n",
    "for name, filepaths in FILEPATHS.items():\n",
    "    if name != 'ggF HH' and name != 'Data': continue\n",
    "    sample_list = [ak.from_parquet(filepath) for filepath in filepaths]\n",
    "    sample = ak.concatenate(sample_list)\n",
    "\n",
    "    print(f'{name} num events: {ak.num(sample, axis=0)}')\n",
    "    print(f'{name} yield: {ak.sum(sample[\"eventWeight\"], axis=0)}')\n",
    "\n",
    "    pass_boosted = (\n",
    "        (sample['is_boosted'] == 1)\n",
    "        & (sample['mass'] > 100) & (sample['mass'] < 180)\n",
    "        & (sample['lead_mvaID'] > -0.7) & (sample['sublead_mvaID'] > -0.7)\n",
    "        # & (sample['weight'] > 0)\n",
    "        # & (sample['nonResReg_DNNpair_dijet_mass_DNNreg'] > 70) & (sample['nonResReg_DNNpair_dijet_mass_DNNreg'] < 190)\n",
    "    )\n",
    "    pass_boosted_lumis[name] = ak.to_numpy(sample['lumi'][pass_boosted])\n",
    "    pass_boosted_events[name] = ak.to_numpy(sample['event'][pass_boosted])\n",
    "\n",
    "    if name != 'Data': \n",
    "        print(f'{name} boosted yield: {ak.sum(sample[\"eventWeight\"][pass_boosted], axis=0)}')\n",
    "\n",
    "    print('='*60+'\\n'+'='*60+'\\n'+'='*60)\n",
    "    print(name)\n",
    "    print('-'*60)\n",
    "    print(f\"Num {name} that pass boosted: {ak.sum(pass_boosted, axis=0)}\")\n",
    "    # for cat_i in range(0, 3):\n",
    "    #     MultiBDT_output = np.array([\n",
    "    #         sample['MultiBDT_output_' + \"\".join(output_dim.split())] for output_dim in order\n",
    "    #     ]).T\n",
    "    #     print(np.max(MultiBDT_output[:, 0]))\n",
    "    #     print(np.min(MultiBDT_output[:, 0]))\n",
    "    #     passed_cat = pass_category(MultiBDT_output, cat_i)\n",
    "    #     print(np.nonzero(passed_cat))\n",
    "    #     pass_cat = (\n",
    "    #         pass_category(MultiBDT_output, cat_i)\n",
    "    #         & sample['MultiBDT_flag']\n",
    "    #     )\n",
    "    #     pass_both = (pass_cat & pass_boosted)\n",
    "\n",
    "    #     print('-'*60)\n",
    "    #     print(f\"Num {name} that pass cat {cat_i+1}: {ak.sum(pass_cat, axis=0)}\")\n",
    "    #     print(f\"Num {name} that pass both: {ak.sum(pass_both, axis=0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "048b74a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ggF HH\n",
      "Num FNAL-Caltech-Purdue ggF HH events that pass boosted: 13538\n",
      "Num SnT ggF HH events that pass boosted: 13538\n",
      "Num F-C-P events with repeated lumis: 2362\n",
      "Num SnT events with repeated lumis: 2362\n",
      "Num F-C-P events with repeated events: 181\n",
      "Num SnT events with repeated events: 181\n",
      "Lumis in FNAL-Caltech-Purdue boosted that are not in SnT boosted: \n",
      "[]\n",
      "    Counts of repeated Lumis same in FCP and SnT? True\n",
      "Lumis in SnT boosted that are not in FNAL-Caltech-Purdue boosted: \n",
      "[]\n",
      "    Counts of repeated Lumis same in FCP and SnT? True\n",
      "Events in FNAL-Caltech-Purdue boosted that are not in SnT boosted: \n",
      "[]\n",
      "    Counts of repeated Events same in FCP and SnT? True\n",
      "Events in SnT boosted that are not in FNAL-Caltech-Purdue boosted: \n",
      "[]\n",
      "    Counts of repeated Events same in FCP and SnT? True\n",
      "============================================================\n",
      "Data\n",
      "Num FNAL-Caltech-Purdue Data events that pass boosted: 3\n",
      "Num SnT Data events that pass boosted: 3\n",
      "Num F-C-P events with repeated lumis: 0\n",
      "Num SnT events with repeated lumis: 0\n",
      "Num F-C-P events with repeated events: 0\n",
      "Num SnT events with repeated events: 0\n",
      "Lumis in FNAL-Caltech-Purdue boosted that are not in SnT boosted: \n",
      "[]\n",
      "    Counts of repeated Lumis same in FCP and SnT? True\n",
      "Lumis in SnT boosted that are not in FNAL-Caltech-Purdue boosted: \n",
      "[]\n",
      "    Counts of repeated Lumis same in FCP and SnT? True\n",
      "Events in FNAL-Caltech-Purdue boosted that are not in SnT boosted: \n",
      "[]\n",
      "    Counts of repeated Events same in FCP and SnT? True\n",
      "Events in SnT boosted that are not in FNAL-Caltech-Purdue boosted: \n",
      "[]\n",
      "    Counts of repeated Events same in FCP and SnT? True\n"
     ]
    }
   ],
   "source": [
    "for key in brunella_pass_boosted_lumis.keys():\n",
    "    print(\"=\"*60)\n",
    "    print(key)\n",
    "    print(f\"Num FNAL-Caltech-Purdue {key} events that pass boosted: {np.size(pass_boosted_lumis[key])}\")\n",
    "    print(f\"Num SnT {key} events that pass boosted: {np.size(brunella_pass_boosted_lumis[key])}\")\n",
    "\n",
    "    unique_FCP_lumis, unique_FCP_lumi_indices, unique_FCP_lumi_counts = np.unique(pass_boosted_lumis[key], return_index=True, return_counts=True)\n",
    "    print(f\"Num F-C-P events with repeated lumis: {np.sum(unique_FCP_lumi_counts >= 2)}\")\n",
    "    unique_SnT_lumis, unique_SnT_lumi_indices, unique_SnT_lumi_counts = np.unique(brunella_pass_boosted_lumis[key], return_index=True, return_counts=True)\n",
    "    print(f\"Num SnT events with repeated lumis: {np.sum(unique_SnT_lumi_counts >= 2)}\")\n",
    "\n",
    "    unique_FCP_events, unique_FCP_event_indices, unique_FCP_event_counts = np.unique(pass_boosted_events[key], return_index=True, return_counts=True)\n",
    "    print(f\"Num F-C-P events with repeated events: {np.sum(unique_FCP_event_counts >= 2)}\")\n",
    "    unique_SnT_events, unique_SnT_event_indices, unique_SnT_event_counts = np.unique(brunella_pass_boosted_events[key], return_index=True, return_counts=True)\n",
    "    print(f\"Num SnT events with repeated events: {np.sum(unique_SnT_event_counts >= 2)}\")\n",
    "    \n",
    "    FCP_lumi_order = np.argsort(unique_FCP_lumis)\n",
    "    print(f\"Lumis in FNAL-Caltech-Purdue boosted that are not in SnT boosted: \\n{np.setdiff1d(unique_FCP_lumis, unique_SnT_lumis)}\")\n",
    "    print(f\"    Counts of repeated Lumis same in FCP and SnT? {np.all(unique_FCP_lumi_counts[FCP_lumi_order] == unique_SnT_lumi_counts[FCP_lumi_order])}\")\n",
    "\n",
    "    SnT_lumi_order = np.argsort(unique_SnT_lumis)\n",
    "    print(f\"Lumis in SnT boosted that are not in FNAL-Caltech-Purdue boosted: \\n{np.setdiff1d(unique_SnT_lumis, unique_FCP_lumis)}\")\n",
    "    print(f\"    Counts of repeated Lumis same in FCP and SnT? {np.all(unique_FCP_lumi_counts[SnT_lumi_order] == unique_SnT_lumi_counts[SnT_lumi_order])}\")\n",
    "\n",
    "    FCP_event_order = np.argsort(unique_FCP_events)\n",
    "    print(f\"Events in FNAL-Caltech-Purdue boosted that are not in SnT boosted: \\n{np.setdiff1d(unique_FCP_events, unique_SnT_events)}\")\n",
    "    print(f\"    Counts of repeated Events same in FCP and SnT? {np.all(unique_FCP_event_counts[FCP_event_order] == unique_SnT_event_counts[FCP_event_order])}\")\n",
    "\n",
    "    SnT_event_order = np.argsort(unique_SnT_events)\n",
    "    print(f\"Events in SnT boosted that are not in FNAL-Caltech-Purdue boosted: \\n{np.setdiff1d(unique_SnT_events, unique_FCP_events)}\")\n",
    "    print(f\"    Counts of repeated Events same in FCP and SnT? {np.all(unique_FCP_event_counts[SnT_event_order] == unique_SnT_event_counts[SnT_event_order])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171bd418",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "higgs-dna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
