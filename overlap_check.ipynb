{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c64a0763",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "import awkward as ak\n",
    "import hist\n",
    "import numpy as np\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import mplhep as hep\n",
    "# from cycler import cycler\n",
    "\n",
    "# plt.style.use(hep.style.CMS)\n",
    "# plt.rcParams.update({'font.size': 20})\n",
    "# cmap_petroff10 = [\"#3f90da\", \"#ffa90e\", \"#bd1f01\", \"#94a4a2\", \"#832db6\", \"#a96b59\", \"#e76300\", \"#b9ac70\", \"#717581\", \"#92dadd\"]\n",
    "# plt.rcParams.update({\"axes.prop_cycle\": cycler(\"color\", cmap_petroff10)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56168f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "lpc_fileprefix = \"/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v3.1/\"\n",
    "\n",
    "# lpc_filegroup = lambda s: f'Run3_{s}_mergedFullAllVars_MultiBDT_output'\n",
    "lpc_filegroup = lambda s: f'Run3_{s}_mergedFullAllVars_MultiBDT_output_flag'\n",
    "MC_FILEPREFIX_22 = os.path.join(lpc_fileprefix, lpc_filegroup('2022'), 'sim', '')\n",
    "MC_FILEPREFIX_23 = os.path.join(lpc_fileprefix, lpc_filegroup('2023'), 'sim', '')\n",
    "MC_FILEPREFIX_24 = os.path.join(lpc_fileprefix, lpc_filegroup('2024'), 'sim', '')\n",
    "DATA_FILEPREFIX_22 = os.path.join(lpc_fileprefix, lpc_filegroup('2022'), 'data', '')\n",
    "DATA_FILEPREFIX_23 = os.path.join(lpc_fileprefix, lpc_filegroup('2023'), 'data', '')\n",
    "DATA_FILEPREFIX_24 = os.path.join(lpc_fileprefix, lpc_filegroup('2024'), 'data', '')\n",
    "\n",
    "signal_filegroup = lambda s: f'{s}/GluGlutoHH_kl-1p00_kt-1p00_c2-0p00'\n",
    "ttH_filegroup = lambda s: f'{s}/ttHtoGG' if s != 'postEE' else f'{s}/ttHToGG'\n",
    "bbH_filegroup = lambda s: f'{s}/bbHtoGG'\n",
    "VH_filegroup = lambda s: f'{s}/VHtoGG'\n",
    "ggFH_filegroup = lambda s: f'{s}/GluGluHtoGG'\n",
    "VBFH_filegroup = lambda s: f'{s}/VBFHtoGG' if s != 'postEE' else f'{s}/VBFHToGG'\n",
    "\n",
    "END_FILEPATH = '*boostedCat.parquet'\n",
    "\n",
    "FILEPATHS = {}\n",
    "for name, filegroup in {\n",
    "    'ggF HH': signal_filegroup, \n",
    "    # 'ttH': ttH_filegroup, 'bbH': bbH_filegroup,\n",
    "    # 'VH': VH_filegroup, 'ggF H': ggFH_filegroup, 'VBF H': VBFH_filegroup,\n",
    "}.items():\n",
    "    FILEPATHS[name] = [\n",
    "        glob.glob(os.path.join(MC_FILEPREFIX_22, filegroup('preEE'), 'nominal', END_FILEPATH)),\n",
    "        glob.glob(os.path.join(MC_FILEPREFIX_22, filegroup('postEE'), 'nominal', END_FILEPATH)),\n",
    "        glob.glob(os.path.join(MC_FILEPREFIX_23, filegroup('preBPix'), 'nominal', END_FILEPATH)),\n",
    "        glob.glob(os.path.join(MC_FILEPREFIX_23, filegroup('postBPix'), 'nominal', END_FILEPATH))\n",
    "    ]\n",
    "\n",
    "FILEPATHS['Data'] = [\n",
    "    glob.glob(os.path.join(DATA_FILEPREFIX_22, END_FILEPATH)),\n",
    "    glob.glob(os.path.join(DATA_FILEPREFIX_23, END_FILEPATH))\n",
    "]\n",
    "\n",
    "order = ['ggF HH', 'ttH + bbH', 'VH', 'non-res + ggFH + VBFH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fb302af",
   "metadata": {},
   "outputs": [],
   "source": [
    "brunella_signal = np.loadtxt('/uscms/home/tsievert/nobackup/XHYbbgg/HHtobbyy/signal_pass_boosted.csv', delimiter=',', skiprows=1, usecols=(1,2))\n",
    "brunella_data = np.loadtxt('/uscms/home/tsievert/nobackup/XHYbbgg/HHtobbyy/pass_boosted_data.csv', delimiter=',', skiprows=1, usecols=(1,2))\n",
    "\n",
    "brunella_pass_boosted_lumis = {\n",
    "    'ggF HH': brunella_signal[:, 0], 'Data': brunella_data[:, 0]\n",
    "}\n",
    "brunella_pass_boosted_events = {\n",
    "    'ggF HH': brunella_signal[:, 1], 'Data': brunella_data[:, 1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d711073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "============================================================\n",
      "============================================================\n",
      "ggF HH\n",
      "------------------------------------------------------------\n",
      "Num ggF HH that pass boosted: 13538\n",
      "============================================================\n",
      "============================================================\n",
      "============================================================\n",
      "Data\n",
      "------------------------------------------------------------\n",
      "Num Data that pass boosted: 3\n"
     ]
    }
   ],
   "source": [
    "def get_ttH_score(multibdt_output):\n",
    "    return multibdt_output[:, 0] / (multibdt_output[:, 0] + multibdt_output[:, 1])\n",
    "\n",
    "def get_QCD_score(multibdt_output):\n",
    "    return multibdt_output[:, 0] / (multibdt_output[:, 0] + multibdt_output[:, 2] + multibdt_output[:, 3])\n",
    "\n",
    "CATS = [\n",
    "    [0.979, 0.9983],\n",
    "    [0.96, 0.9951],\n",
    "    [0.89, 0.9868],\n",
    "]\n",
    "\n",
    "def pass_category(multibdt_output, cat_i):\n",
    "    pass_ttH = get_ttH_score(multibdt_output) > CATS[cat_i][0]\n",
    "    pass_QCD = get_QCD_score(multibdt_output) > CATS[cat_i][1]\n",
    "\n",
    "    pass_prevQCD = get_QCD_score(multibdt_output) <= (\n",
    "        CATS[cat_i-1][1] if cat_i > 1 else 1\n",
    "    )\n",
    "\n",
    "    print(np.nonzero(pass_ttH))\n",
    "    print(np.max(get_ttH_score(multibdt_output)))\n",
    "    print(np.min(get_ttH_score(multibdt_output)))\n",
    "    print(np.nonzero(pass_QCD))\n",
    "    print(np.nonzero(pass_prevQCD))\n",
    "\n",
    "    return pass_ttH & pass_QCD & pass_prevQCD\n",
    "\n",
    "pass_boosted_lumis, pass_boosted_events = {}, {}\n",
    "for name, filepaths in FILEPATHS.items():\n",
    "    if name != 'ggF HH' and name != 'Data': continue\n",
    "    sample_list = [ak.from_parquet(filepath) for filepath in filepaths]\n",
    "    sample = ak.concatenate(sample_list)\n",
    "\n",
    "    pass_boosted = (\n",
    "        (sample['is_boosted'] == 1)\n",
    "        & (sample['mass'] > 100) & (sample['mass'] < 180)\n",
    "        & (sample['lead_mvaID'] > -0.7) & (sample['sublead_mvaID'] > -0.7)\n",
    "        # & (sample['weight'] > 0)\n",
    "        # & (sample['nonResReg_DNNpair_dijet_mass_DNNreg'] > 70) & (sample['nonResReg_DNNpair_dijet_mass_DNNreg'] < 190)\n",
    "    )\n",
    "    pass_boosted_lumis[name] = ak.to_numpy(sample['lumi'][pass_boosted])\n",
    "    pass_boosted_events[name] = ak.to_numpy(sample['event'][pass_boosted])\n",
    "\n",
    "    print('='*60+'\\n'+'='*60+'\\n'+'='*60)\n",
    "    print(name)\n",
    "    print('-'*60)\n",
    "    print(f\"Num {name} that pass boosted: {ak.sum(pass_boosted, axis=0)}\")\n",
    "    # for cat_i in range(0, 3):\n",
    "    #     MultiBDT_output = np.array([\n",
    "    #         sample['MultiBDT_output_' + \"\".join(output_dim.split())] for output_dim in order\n",
    "    #     ]).T\n",
    "    #     print(np.max(MultiBDT_output[:, 0]))\n",
    "    #     print(np.min(MultiBDT_output[:, 0]))\n",
    "    #     passed_cat = pass_category(MultiBDT_output, cat_i)\n",
    "    #     print(np.nonzero(passed_cat))\n",
    "    #     pass_cat = (\n",
    "    #         pass_category(MultiBDT_output, cat_i)\n",
    "    #         & sample['MultiBDT_flag']\n",
    "    #     )\n",
    "    #     pass_both = (pass_cat & pass_boosted)\n",
    "\n",
    "    #     print('-'*60)\n",
    "    #     print(f\"Num {name} that pass cat {cat_i+1}: {ak.sum(pass_cat, axis=0)}\")\n",
    "    #     print(f\"Num {name} that pass both: {ak.sum(pass_both, axis=0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "048b74a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ggF HH\n",
      "Num FNAL-Caltech-Purdue ggF HH events that pass boosted: 13538\n",
      "Num SnT ggF HH events that pass boosted: 13538\n",
      "Num F-C-P events with repeated lumis: 2362\n",
      "Num SnT events with repeated lumis: 2362\n",
      "Num F-C-P events with repeated events: 181\n",
      "Num SnT events with repeated events: 181\n",
      "Lumis in FNAL-Caltech-Purdue boosted that are not in SnT boosted: \n",
      "[]\n",
      "    Counts of repeated Lumis same in FCP and SnT? True\n",
      "Lumis in SnT boosted that are not in FNAL-Caltech-Purdue boosted: \n",
      "[]\n",
      "    Counts of repeated Lumis same in FCP and SnT? True\n",
      "Events in FNAL-Caltech-Purdue boosted that are not in SnT boosted: \n",
      "[]\n",
      "    Counts of repeated Events same in FCP and SnT? True\n",
      "Events in SnT boosted that are not in FNAL-Caltech-Purdue boosted: \n",
      "[]\n",
      "    Counts of repeated Events same in FCP and SnT? True\n",
      "============================================================\n",
      "Data\n",
      "Num FNAL-Caltech-Purdue Data events that pass boosted: 3\n",
      "Num SnT Data events that pass boosted: 3\n",
      "Num F-C-P events with repeated lumis: 0\n",
      "Num SnT events with repeated lumis: 0\n",
      "Num F-C-P events with repeated events: 0\n",
      "Num SnT events with repeated events: 0\n",
      "Lumis in FNAL-Caltech-Purdue boosted that are not in SnT boosted: \n",
      "[]\n",
      "    Counts of repeated Lumis same in FCP and SnT? True\n",
      "Lumis in SnT boosted that are not in FNAL-Caltech-Purdue boosted: \n",
      "[]\n",
      "    Counts of repeated Lumis same in FCP and SnT? True\n",
      "Events in FNAL-Caltech-Purdue boosted that are not in SnT boosted: \n",
      "[]\n",
      "    Counts of repeated Events same in FCP and SnT? True\n",
      "Events in SnT boosted that are not in FNAL-Caltech-Purdue boosted: \n",
      "[]\n",
      "    Counts of repeated Events same in FCP and SnT? True\n"
     ]
    }
   ],
   "source": [
    "for key in brunella_pass_boosted_lumis.keys():\n",
    "    print(\"=\"*60)\n",
    "    print(key)\n",
    "    print(f\"Num FNAL-Caltech-Purdue {key} events that pass boosted: {np.size(pass_boosted_lumis[key])}\")\n",
    "    print(f\"Num SnT {key} events that pass boosted: {np.size(brunella_pass_boosted_lumis[key])}\")\n",
    "\n",
    "    unique_FCP_lumis, unique_FCP_lumi_indices, unique_FCP_lumi_counts = np.unique(pass_boosted_lumis[key], return_index=True, return_counts=True)\n",
    "    print(f\"Num F-C-P events with repeated lumis: {np.sum(unique_FCP_lumi_counts >= 2)}\")\n",
    "    unique_SnT_lumis, unique_SnT_lumi_indices, unique_SnT_lumi_counts = np.unique(brunella_pass_boosted_lumis[key], return_index=True, return_counts=True)\n",
    "    print(f\"Num SnT events with repeated lumis: {np.sum(unique_SnT_lumi_counts >= 2)}\")\n",
    "\n",
    "    unique_FCP_events, unique_FCP_event_indices, unique_FCP_event_counts = np.unique(pass_boosted_events[key], return_index=True, return_counts=True)\n",
    "    print(f\"Num F-C-P events with repeated events: {np.sum(unique_FCP_event_counts >= 2)}\")\n",
    "    unique_SnT_events, unique_SnT_event_indices, unique_SnT_event_counts = np.unique(brunella_pass_boosted_events[key], return_index=True, return_counts=True)\n",
    "    print(f\"Num SnT events with repeated events: {np.sum(unique_SnT_event_counts >= 2)}\")\n",
    "    \n",
    "    FCP_lumi_order = np.argsort(unique_FCP_lumis)\n",
    "    print(f\"Lumis in FNAL-Caltech-Purdue boosted that are not in SnT boosted: \\n{np.setdiff1d(unique_FCP_lumis, unique_SnT_lumis)}\")\n",
    "    print(f\"    Counts of repeated Lumis same in FCP and SnT? {np.all(unique_FCP_lumi_counts[FCP_lumi_order] == unique_SnT_lumi_counts[FCP_lumi_order])}\")\n",
    "\n",
    "    SnT_lumi_order = np.argsort(unique_SnT_lumis)\n",
    "    print(f\"Lumis in SnT boosted that are not in FNAL-Caltech-Purdue boosted: \\n{np.setdiff1d(unique_SnT_lumis, unique_FCP_lumis)}\")\n",
    "    print(f\"    Counts of repeated Lumis same in FCP and SnT? {np.all(unique_FCP_lumi_counts[SnT_lumi_order] == unique_SnT_lumi_counts[SnT_lumi_order])}\")\n",
    "\n",
    "    FCP_event_order = np.argsort(unique_FCP_events)\n",
    "    print(f\"Events in FNAL-Caltech-Purdue boosted that are not in SnT boosted: \\n{np.setdiff1d(unique_FCP_events, unique_SnT_events)}\")\n",
    "    print(f\"    Counts of repeated Events same in FCP and SnT? {np.all(unique_FCP_event_counts[FCP_event_order] == unique_SnT_event_counts[FCP_event_order])}\")\n",
    "\n",
    "    SnT_event_order = np.argsort(unique_SnT_events)\n",
    "    print(f\"Events in SnT boosted that are not in FNAL-Caltech-Purdue boosted: \\n{np.setdiff1d(unique_SnT_events, unique_FCP_events)}\")\n",
    "    print(f\"    Counts of repeated Events same in FCP and SnT? {np.all(unique_FCP_event_counts[SnT_event_order] == unique_SnT_event_counts[SnT_event_order])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171bd418",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "higgs-dna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
