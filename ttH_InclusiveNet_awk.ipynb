{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmslpcgpu1.fnal.gov      Tue Sep  3 16:15:08 2024  555.42.02\n",
      "[0] Tesla P100-PCIE-12GB | 45Â°C,   0 % |  2748 / 12288 MB | ckapsiak(2746M)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Stdlib packages\n",
    "import copy\n",
    "import datetime\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "# Common Py packages\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "# HEP packages\n",
    "import gpustat\n",
    "import hist\n",
    "import mplhep as hep\n",
    "from cycler import cycler\n",
    "\n",
    "# ML packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Module packages\n",
    "from AMSGrad import AMSGrad\n",
    "from data_processing import process_data, data_list_index_map\n",
    "from evaluate import evaluate\n",
    "from InclusiveNetwork import InclusiveNetwork\n",
    "from ParticleHLF import ParticleHLF\n",
    "from space_optimization import optimize_hyperparams\n",
    "from train import train\n",
    "\n",
    "gpustat.print_gpustat()\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "plt.style.use(hep.style.CMS)\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "cmap_petroff10 = [\"#3f90da\", \"#ffa90e\", \"#bd1f01\", \"#94a4a2\", \"#832db6\", \"#a96b59\", \"#e76300\", \"#b9ac70\", \"#717581\", \"#92dadd\"]\n",
    "plt.rcParams.update({\"axes.prop_cycle\": cycler(\"color\", cmap_petroff10)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lpc_fileprefix = \"/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1\"\n",
    "\n",
    "V2_MERGED = True\n",
    "\n",
    "SIGNAL_FILEPATHS = [\n",
    "    # Test sig files #\n",
    "    # '/uscms/home/tsievert/nobackup/XHYbbgg/HiggsDNA_official/output_test_HH/Run3_2022preEE/GluGluToHH/nominal/*',\n",
    "    # '/uscms/home/tsievert/nobackup/XHYbbgg/HiggsDNA_official/output_test_HH/Run3_2022preEE_merged_v2/GluGluToHH/nominal/*',\n",
    "    # ggF HH # \n",
    "    lpc_fileprefix+f\"/Run3_2022preEE_merged{'_v2' if V2_MERGED else ''}/GluGluToHH/nominal/*\", lpc_fileprefix+f\"/Run3_2022postEE_merged{'_v2' if V2_MERGED else ''}/GluGluToHH/nominal/*\",\n",
    "    # VBF HH #\n",
    "    # lpc_fileprefix+f\"/Run3_2022preEE_merged{'_v2' if V2_MERGED else ''}/VBFHHto2B2G_CV_1_C2V_1_C3_1/nominal/*\", lpc_fileprefix+f\"/Run3_2022postEE_merged{'_v2' if V2_MERGED else ''}/VBFHHto2B2G_CV_1_C2V_1_C3_1/nominal/*\",\n",
    "]\n",
    "BKG_FILEPATHS = [\n",
    "    # ttH (i.e. the main bkg to reduce) #\n",
    "    # lpc_fileprefix+f\"/Run3_2022preEE_merged{'_v2' if V2_MERGED else ''}/ttHToGG/nominal/*\", lpc_fileprefix+f\"/Run3_2022postEE_merged{'_v2' if V2_MERGED else ''}/ttHToGG/nominal/*\",\n",
    "    lpc_fileprefix+f\"/Run3_2022preEE_merged{'_v2' if V2_MERGED else ''}/ttHToGG/nominal/*\", lpc_fileprefix+f\"/Run3_2022postEE_merged{'_v2' if V2_MERGED else ''}/ttHToGG/nominal/*\",\n",
    "    # # Other single H samples #\n",
    "    # lpc_fileprefix+f\"/Run3_2022preEE_merged{'_v2' if V2_MERGED else ''}/GluGluHToGG/nominal/*\", lpc_fileprefix+f\"/Run3_2022postEE_merged{'_v2' if V2_MERGED else ''}/GluGluHToGG/nominal/*\",\n",
    "    # lpc_fileprefix+f\"/Run3_2022preEE_merged{'_v2' if V2_MERGED else ''}/VBFHToGG/nominal/*\", lpc_fileprefix+f\"/Run3_2022postEE_merged{'_v2' if V2_MERGED else ''}/VBFHToGG/nominal/*\",\n",
    "    # lpc_fileprefix+f\"/Run3_2022preEE_merged{'_v2' if V2_MERGED else ''}/VHToGG/nominal/*\", lpc_fileprefix+f\"/Run3_2022postEE_merged{'_v2' if V2_MERGED else ''}/VHToGG/nominal/*\",\n",
    "    # # Prompt-Prompt samples #\n",
    "    # lpc_fileprefix+f\"/Run3_2022preEE_merged{'_v2' if V2_MERGED else ''}/GGJets/nominal/*\", lpc_fileprefix+f\"/Run3_2022postEE_merged{'_v2' if V2_MERGED else ''}/GGJets/nominal/*\",\n",
    "    # # Prompt-Fake samples #\n",
    "    # lpc_fileprefix+f\"/Run3_2022preEE_merged{'_v2' if V2_MERGED else ''}/GJetPt20To40/nominal/*\", lpc_fileprefix+f\"/Run3_2022postEE_merged{'_v2' if V2_MERGED else ''}/GJetPt20To40/nominal/*\",\n",
    "    # lpc_fileprefix+f\"/Run3_2022preEE_merged{'_v2' if V2_MERGED else ''}/GJetPt40/nominal/*\", lpc_fileprefix+f\"/Run3_2022postEE_merged{'_v2' if V2_MERGED else ''}/GJetPt40/nominal/*\",\n",
    "    # Fake-Fake samples #\n",
    "    # ADD HERE #\n",
    "]\n",
    "\n",
    "\n",
    "CURRENT_DIRPATH = str(Path().absolute())\n",
    "VERSION = 'v4'\n",
    "if VERSION == 'v1':\n",
    "    CRITERION = \"NLLLoss\"\n",
    "    N_PARTICLES, N_PARTICLE_FIELDS = 4, 6\n",
    "elif VERSION == 'v2':\n",
    "    # CRITERION == \"BCELoss\"\n",
    "    CRITERION = \"NLLLoss\"\n",
    "    N_PARTICLES, N_PARTICLE_FIELDS = 4, 6\n",
    "elif VERSION == 'v3':\n",
    "    CRITERION = \"NLLLoss\"\n",
    "    N_PARTICLES, N_PARTICLE_FIELDS = 4, 6\n",
    "elif VERSION == 'v4':\n",
    "    CRITERION = \"NLLLoss\"\n",
    "    # N_PARTICLES, N_PARTICLE_FIELDS = 6, 7\n",
    "    N_PARTICLES, N_PARTICLE_FIELDS = 4, 6\n",
    "elif VERSION == 'v5':\n",
    "    CRITERION = \"NLLLoss\"\n",
    "    N_PARTICLES, N_PARTICLE_FIELDS = 4, 6\n",
    "MOD_VALS = (2, 2)\n",
    "# VARS = 'base_vars'\n",
    "# CURRENT_TIME = '2024-08-10_10-29-50'\n",
    "# CURRENT_TIME = '2024-08-17_18-23-49'\n",
    "VARS = 'extra_vars'\n",
    "# CURRENT_TIME = '2024-08-10_13-16-12'\n",
    "# CURRENT_TIME = '2024-08-17_11-45-34'\n",
    "# CURRENT_TIME = '2024-08-20_23-02-48'\n",
    "# VARS = 'extra_vars_no_dijet_mass'\n",
    "# CURRENT_TIME = '2024-08-21_15-28-02'\n",
    "# VARS = 'no_bad_vars'\n",
    "# CURRENT_TIME = '2024-08-28_17-57-36'\n",
    "# VARS = 'simplified_bad_vars'\n",
    "# CURRENT_TIME = '2024-08-29_14-39-08'\n",
    "# VARS = 'extra_vars_and_bools'\n",
    "# CURRENT_TIME = '2024-08-29_16-33-23'\n",
    "# VARS = 'extra_vars_in_RNN'\n",
    "# CURRENT_TIME = '2024-08-29_19-26-50'\n",
    "# VARS = f'extra_vars_mod{MOD_VALS[0]}-{MOD_VALS[1]}'\n",
    "OUTPUT_DIRPATH = CURRENT_DIRPATH + f\"/model_outputs/{VERSION}/{VARS}/\"\n",
    "\n",
    "if not os.path.exists(OUTPUT_DIRPATH):\n",
    "    os.makedirs(OUTPUT_DIRPATH)\n",
    "\n",
    "SEED = 21\n",
    "OPTIMIZE_SPACE = False\n",
    "NUM_EPOCHS = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/uscms/home/tsievert/nobackup/miniconda3/envs/higgs-dna-hhbbgg/lib/python3.10/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data list: (258332, 4, 6)\n",
      "Data HLF: (258332, 14)\n",
      "n signal = 85041, n bkg = 173291\n",
      "Data list test: (258924, 4, 6)\n",
      "Data HLF test: (258924, 14)\n",
      "n signal = 85713, n bkg = 173211\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    data_df, data_test_df, \n",
    "    data_list, data_hlf, label, \n",
    "    data_list_test, data_hlf_test, label_test, \n",
    "    high_level_fields, input_hlf_vars, hlf_vars_columns,\n",
    "    data_aux, data_test_aux\n",
    ") = process_data(\n",
    "    4, 6, SIGNAL_FILEPATHS, BKG_FILEPATHS, OUTPUT_DIRPATH, seed=SEED, return_pre_std=True, mod_vals=MOD_VALS\n",
    ")\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_val_losses(\n",
    "    IN_info, plot_prefix, plot_postfix='', method='arr', labels=None, sort=None\n",
    "):\n",
    "    plt.figure(figsize=(9,7))\n",
    "    if method == 'std':\n",
    "        plt.plot(\n",
    "            range(len(IN_info['train_losses_arr'])), \n",
    "            IN_info['train_losses_arr'], label=f\"Train data losses\", \n",
    "            alpha=0.7\n",
    "        )\n",
    "        plt.plot(\n",
    "            range(len(IN_info['train_losses_arr'])), \n",
    "            IN_info['val_losses_arr'], label=f\"Validation data losses\", \n",
    "            alpha=0.7\n",
    "        )\n",
    "    elif method == 'arr':\n",
    "        linestyles = ['solid', 'dotted']\n",
    "        linestyles = linestyles * ((2*len(IN_info['all_preds']) // len(linestyles)) + 1)\n",
    "        linestyles = linestyles[:2*len(IN_info['all_preds'])]\n",
    "        for fold_idx in range(skf.get_n_splits()):\n",
    "            plt.plot(\n",
    "                range(len(IN_info['train_losses_arr'][fold_idx])), \n",
    "                IN_info['train_losses_arr'][fold_idx], \n",
    "                label=f\"Train data losses - fold {fold_idx}\", alpha=0.5,\n",
    "                linestyle=linestyles[fold_idx if fold_idx%2 == 0 else fold_idx+1]\n",
    "            )\n",
    "            plt.plot(\n",
    "                range(len(IN_info['train_losses_arr'][fold_idx])), \n",
    "                IN_info['val_losses_arr'][fold_idx], \n",
    "                label=f\"Validation data losses - fold {fold_idx}\", alpha=0.5,\n",
    "                linestyle=linestyles[fold_idx+1 if fold_idx%2 == 0 else fold_idx]\n",
    "            )\n",
    "    else:\n",
    "        raise Exception(f\"Must used methods 'std' or 'arr'. You used {method}.\")\n",
    "    plt.legend(bbox_to_anchor=(1, 1))\n",
    "    plt.xlabel('EPOCH')\n",
    "    plt.ylabel('Data Loss')\n",
    "    plt.savefig(f'{plot_prefix}_train_val_losses{plot_postfix}.pdf', bbox_inches='tight')\n",
    "    plt.savefig(f'{plot_prefix}_train_val_losses{plot_postfix}.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def plot_roc(\n",
    "    IN_info, plot_prefix, plot_postfix='', method='std', \n",
    "    labels=None, yscale='linear', run2=True, sort=None\n",
    "):\n",
    "    run2_sigEff = [.9704, .9498, .9196, .7536, .5777, .3837]\n",
    "    run2_bkgCont = [.2831, .2114, .1539, .0442, .0158, .0041]\n",
    "    run2_bkgCont_err = [.0077, .0036, .0011, .0032, .0006, .0001]\n",
    "    plt.figure(figsize=(9,7))\n",
    "    if method == 'std':\n",
    "        plt.plot(\n",
    "            IN_info['mean_fprs'], IN_info['base_tpr'], \n",
    "            label=\"Run3 NN AUC = %.4f\" % (IN_info['mean_area'])\n",
    "        )\n",
    "    elif method == 'arr':\n",
    "        linestyles = ['dashed', 'dotted']\n",
    "        linestyles = linestyles * ((len(IN_info['all_preds']) // len(linestyles)) + 1)\n",
    "        linestyles = linestyles[:len(IN_info['all_preds'])]\n",
    "        for fold_idx in range(skf.get_n_splits()):\n",
    "            plt.plot(\n",
    "                IN_info['fprs'][fold_idx], IN_info['base_tpr'],\n",
    "                label=\"Run3 NN - fold %d\" % (fold_idx), linestyle=linestyles[fold_idx],\n",
    "                alpha=0.5\n",
    "            )\n",
    "        plt.plot(\n",
    "            IN_info['mean_fprs'], IN_info['base_tpr'], \n",
    "            label=\"Run3 NN AUC = %.4f\" % (IN_info['mean_area']),\n",
    "            alpha=0.8\n",
    "        )\n",
    "    elif method == 'IN_arr':\n",
    "        linestyles = ['solid', 'dashed', 'dotted']\n",
    "        linestyles = linestyles * ((len(IN_info) // len(linestyles)) + 1)\n",
    "        linestyles = linestyles[:len(IN_info)]\n",
    "        if sort is not None:\n",
    "            index_arr = sort\n",
    "        else:\n",
    "            index_arr = range(len(IN_info))\n",
    "        for i in index_arr:\n",
    "            plt.plot(\n",
    "                IN_info[i]['mean_fprs'], IN_info[i]['base_tpr'], \n",
    "                label=(labels[i]+', ' if labels is not None else '') + \"AUC = %.4f\" % (IN_info[i]['mean_area']), \n",
    "                linestyle=linestyles[i]\n",
    "            )\n",
    "    else:\n",
    "        raise Exception(f\"Must used methods 'std', 'arr', or 'IN_arr'. You used {method}.\")\n",
    "    if run2:\n",
    "        plt.errorbar(run2_bkgCont, run2_sigEff, xerr=run2_bkgCont_err, label=\"Run2 NN AUC (val data) = {}\".format(0.9469))\n",
    "    if yscale is not None:\n",
    "        plt.yscale(yscale)\n",
    "    plt.ylim(0.1, 1.1)\n",
    "    plt.legend(bbox_to_anchor=(1, 1))\n",
    "    plt.xlabel('Background contamination')\n",
    "    plt.ylabel('Signal efficiency')\n",
    "    plt.savefig(f'{plot_prefix}_roc_curve{plot_postfix}.pdf', bbox_inches='tight')\n",
    "    plt.savefig(f'{plot_prefix}_roc_curve{plot_postfix}.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def plot_output_score(\n",
    "        IN_info, plot_prefix, plot_postfix='', method='arr', labels=None, \n",
    "        weights={'sig': None, 'bkg': None}, n_bins=50\n",
    "    ):\n",
    "    plt.figure(figsize=(9,7))\n",
    "    if method == 'std':\n",
    "        sig_np = np.exp(\n",
    "            IN_info['mean_pred']\n",
    "        )[\n",
    "            np.array(IN_info['mean_label']) == 1,1\n",
    "        ]\n",
    "        bkg_np = np.exp(\n",
    "            IN_info['mean_pred']\n",
    "        )[\n",
    "            np.array(IN_info['mean_label']) == 0,1\n",
    "        ]\n",
    "        hist_axis = hist.axis.Regular(n_bins, 0., 1., name='var', growth=False, underflow=False, overflow=False)\n",
    "        sig_hist = hist.Hist(hist_axis, storage='weight').fill(var=sig_np, weight=weights['sig'] if weights['sig'] is not None else np.ones_like(sig_np))\n",
    "        bkg_hist = hist.Hist(hist_axis, storage='weight').fill(var=bkg_np, weight=weights['bkg'] if weights['sig'] is not None else np.ones_like(bkg_np))\n",
    "        hep.histplot(\n",
    "            [sig_hist, bkg_hist], w2=np.array([sig_hist.variances(), bkg_hist.variances()]),\n",
    "            alpha=0.7, density=(False if weights['sig'] is not None else True), histtype='step',\n",
    "            label=['HH signal', 'ttH background']\n",
    "        )\n",
    "    elif method == 'arr':\n",
    "        linestyles = ['dashed', 'dotted']\n",
    "        linestyles = linestyles * ((len(IN_info['all_preds']) // len(linestyles)) + 1)\n",
    "        linestyles = linestyles[:len(IN_info['all_preds'])]\n",
    "        for fold_idx in range(skf.get_n_splits()):\n",
    "            sig_np = np.exp(\n",
    "                IN_info['all_preds'][fold_idx]\n",
    "            )[\n",
    "                np.array(IN_info['all_labels'][fold_idx]) == 1,1\n",
    "            ]\n",
    "            bkg_np = np.exp(\n",
    "                IN_info['all_preds'][fold_idx]\n",
    "            )[\n",
    "                np.array(IN_info['all_labels'][fold_idx]) == 0,1\n",
    "            ]\n",
    "            hist_axis = hist.axis.Regular(n_bins, 0., 1., name='var', growth=False, underflow=False, overflow=False)\n",
    "            sig_hist = hist.Hist(hist_axis, storage='weight').fill(var=sig_np, weight=weights['sig'] if weights['sig'] is not None else np.ones_like(sig_np))\n",
    "            bkg_hist = hist.Hist(hist_axis, storage='weight').fill(var=bkg_np, weight=weights['bkg'] if weights['sig'] is not None else np.ones_like(bkg_np))\n",
    "            hep.histplot(\n",
    "                [sig_hist, bkg_hist], w2=np.array([sig_hist.variances(), bkg_hist.variances()]),\n",
    "                alpha=0.7, density=(False if weights['sig'] is not None else True), histtype='step',\n",
    "                label=[\n",
    "                    'HH signal'+(' - '+labels[fold_idx] if labels is not None else ''), \n",
    "                    'ttH background'+(' - '+labels[fold_idx] if labels is not None else '')\n",
    "                ], linestyle=[linestyles[fold_idx], linestyles[fold_idx]]\n",
    "            )\n",
    "        sig_np = np.exp(\n",
    "            IN_info['mean_pred']\n",
    "        )[\n",
    "            np.array(IN_info['mean_label']) == 1,1\n",
    "        ]\n",
    "        bkg_np = np.exp(\n",
    "            IN_info['mean_pred']\n",
    "        )[\n",
    "            np.array(IN_info['mean_label']) == 0,1\n",
    "        ]\n",
    "        hist_axis = hist.axis.Regular(n_bins, 0., 1., name='var', growth=False, underflow=False, overflow=False)\n",
    "        sig_hist = hist.Hist(hist_axis, storage='weight').fill(var=sig_np, weight=weights['sig'] if weights['sig'] is not None else np.ones_like(sig_np))\n",
    "        bkg_hist = hist.Hist(hist_axis, storage='weight').fill(var=bkg_np, weight=weights['bkg'] if weights['sig'] is not None else np.ones_like(bkg_np))\n",
    "        hep.histplot(\n",
    "            [sig_hist, bkg_hist], w2=np.array([sig_hist.variances(), bkg_hist.variances()]),\n",
    "            alpha=0.7, density=(False if weights['sig'] is not None else True), histtype='step',\n",
    "            label=['HH signal', 'ttH background']\n",
    "        )\n",
    "    elif method == 'IN_arr':\n",
    "        linestyles = ['solid', 'dashed', 'dotted']\n",
    "        linestyles = linestyles * ((len(IN_info) // len(linestyles)) + 1)\n",
    "        linestyles = linestyles[:len(IN_info)]\n",
    "        for i in range(len(IN_info)):\n",
    "            sig_np = np.exp(\n",
    "                IN_info[i]['mean_pred']\n",
    "            )[\n",
    "                np.array(IN_info[i]['mean_label']) == 1,1\n",
    "            ]\n",
    "            bkg_np = np.exp(\n",
    "                IN_info[i]['mean_pred']\n",
    "            )[\n",
    "                np.array(IN_info[i]['mean_label']) == 0,1\n",
    "            ]\n",
    "            hist_axis = hist.axis.Regular(n_bins, 0., 1., name='var', growth=False, underflow=False, overflow=False)\n",
    "            sig_hist = hist.Hist(hist_axis, storage='weight').fill(var=sig_np, weight=weights[i]['sig'] if weights[i]['sig'] is not None else np.ones_like(sig_np))\n",
    "            bkg_hist = hist.Hist(hist_axis, storage='weight').fill(var=bkg_np, weight=weights[i]['bkg'] if weights[i]['sig'] is not None else np.ones_like(bkg_np))\n",
    "            hep.histplot(\n",
    "                [sig_hist, bkg_hist], w2=np.array([sig_hist.variances(), bkg_hist.variances()]),\n",
    "                alpha=0.7, density=(False if weights[i]['sig'] is not None else True), histtype='step',\n",
    "                label=[\n",
    "                    'HH signal'+(' - '+labels[i] if labels is not None else ''), \n",
    "                    'ttH background'+(' - '+labels[i] if labels is not None else '')\n",
    "                ], linestyle=[linestyles[i], linestyles[i]]\n",
    "            )\n",
    "    else:\n",
    "        raise Exception(f\"Must used methods 'std', 'arr', or 'IN_arr'. You used {method}.\")\n",
    "    plt.legend(bbox_to_anchor=(1, 1))\n",
    "    plt.xlabel(\"Counts\", fontsize=18)\n",
    "    plt.xlabel(\"Threshold\", fontsize=18)\n",
    "    plt.savefig(f'{plot_prefix}_model_score_dist{plot_postfix}.pdf', bbox_inches='tight')\n",
    "    plt.savefig(f'{plot_prefix}_model_score_dist{plot_postfix}.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def s_over_root_b(\n",
    "        IN_info, plot_prefix, plot_postfix='', method='arr', labels=None, \n",
    "        weights={'sig': None, 'bkg': None}, lines_fold=None, lines=None, lines_labels=None, \n",
    "        lines_colors=None, only_fold=None, no_fold=False, n_bins=50\n",
    "    ):\n",
    "    plt.figure(figsize=(9,7))\n",
    "    if method == 'std':\n",
    "        sig_np = np.exp(\n",
    "            IN_info['mean_pred']\n",
    "        )[\n",
    "            np.array(IN_info['mean_label']) == 1,1\n",
    "        ]\n",
    "        bkg_np = np.exp(\n",
    "            IN_info['mean_pred']\n",
    "        )[\n",
    "            np.array(IN_info['mean_label']) == 0,1\n",
    "        ]\n",
    "        hist_axis = hist.axis.Regular(n_bins, 0., 1., name='var', growth=False, underflow=False, overflow=False)\n",
    "        sig_hist = hist.Hist(hist_axis, storage='weight').fill(var=sig_np, weight=weights['sig'])\n",
    "        bkg_hist = hist.Hist(hist_axis, storage='weight').fill(var=bkg_np, weight=weights['bkg'])\n",
    "        s_over_root_b_points = sig_hist.values().flatten() / np.sqrt(bkg_hist.values().flatten())\n",
    "        plt.plot(\n",
    "            np.arange(0., 1., 1/n_bins), s_over_root_b_points, \n",
    "            label='s/âb', alpha=0.8 \n",
    "        )\n",
    "    elif method == 'arr':\n",
    "        linestyles = ['dashed', 'dotted']\n",
    "        linestyles = linestyles * ((len(IN_info['all_preds']) // len(linestyles)) + 1)\n",
    "        linestyles = linestyles[:len(IN_info['all_preds'])]\n",
    "        for fold_idx in range(skf.get_n_splits()):\n",
    "            if (only_fold is not None and fold_idx != only_fold) or no_fold == True:\n",
    "                continue\n",
    "            sig_np = np.exp(\n",
    "                IN_info['all_preds'][fold_idx]\n",
    "            )[\n",
    "                np.array(IN_info['all_labels'][fold_idx]) == 1,1\n",
    "            ]\n",
    "            bkg_np = np.exp(\n",
    "                IN_info['all_preds'][fold_idx]\n",
    "            )[\n",
    "                np.array(IN_info['all_labels'][fold_idx]) == 0,1\n",
    "            ]\n",
    "            hist_axis = hist.axis.Regular(n_bins, 0., 1., name='var', growth=False, underflow=False, overflow=False)\n",
    "            sig_hist = hist.Hist(hist_axis, storage='weight').fill(var=sig_np, weight=weights['sig'])\n",
    "            bkg_hist = hist.Hist(hist_axis, storage='weight').fill(var=bkg_np, weight=weights['bkg'])\n",
    "            s_over_root_b_points = sig_hist.values().flatten() / np.sqrt(bkg_hist.values().flatten())\n",
    "            plt.plot(\n",
    "                np.arange(0., 1., 1/n_bins), s_over_root_b_points, \n",
    "                label='s/âb'+(' - fold '+labels[fold_idx] if labels is not None else ''), \n",
    "                alpha=0.5, linestyle=linestyles[fold_idx], \n",
    "            )\n",
    "            if lines_fold is not None:\n",
    "                for i in range(len(lines_fold[fold_idx])):\n",
    "                    plt.vlines(\n",
    "                        lines_fold[fold_idx][i], 0, np.max(s_over_root_b_points), \n",
    "                        label='s/âb'+(' - '+lines_labels[fold_idx][i] if lines_labels is not None else ''), \n",
    "                        alpha=0.5, colors=lines_colors[fold_idx][i]\n",
    "                    )\n",
    "        if only_fold is None:\n",
    "            sig_np = np.exp(\n",
    "                IN_info['mean_pred']\n",
    "            )[\n",
    "                np.array(IN_info['mean_label']) == 1,1\n",
    "            ]\n",
    "            bkg_np = np.exp(\n",
    "                IN_info['mean_pred']\n",
    "            )[\n",
    "                np.array(IN_info['mean_label']) == 0,1\n",
    "            ]\n",
    "            hist_axis = hist.axis.Regular(n_bins, 0., 1., name='var', growth=False, underflow=False, overflow=False)\n",
    "            sig_hist = hist.Hist(hist_axis, storage='weight').fill(var=sig_np, weight=weights['sig'])\n",
    "            bkg_hist = hist.Hist(hist_axis, storage='weight').fill(var=bkg_np, weight=weights['bkg'])\n",
    "            s_over_root_b_points = sig_hist.values().flatten() / np.sqrt(bkg_hist.values().flatten())\n",
    "            plt.plot(\n",
    "                np.arange(0., 1., 1/n_bins), s_over_root_b_points, \n",
    "                label='s/âb - avg. over folds', \n",
    "                alpha=0.5, \n",
    "            )\n",
    "            if lines is not None:\n",
    "                for i in range(len(lines)):\n",
    "                    plt.vlines(\n",
    "                        lines[i], 0, np.max(s_over_root_b_points), \n",
    "                        label='s/âb - avg.'+(' - '+lines_labels[i] if lines_labels is not None else ''), \n",
    "                        alpha=0.5, colors=lines_colors[i]\n",
    "                    )\n",
    "    elif method == 'IN_arr':\n",
    "        linestyles = ['solid', 'dashed', 'dotted']\n",
    "        linestyles = linestyles * ((len(IN_info) // len(linestyles)) + 1)\n",
    "        linestyles = linestyles[:len(IN_info)]\n",
    "        for i in range(len(IN_info)):\n",
    "            sig_np = np.exp(\n",
    "                IN_info[i]['all_preds'][0]\n",
    "            )[\n",
    "                np.array(IN_info[i]['all_labels'][0]) == 1,1\n",
    "            ]\n",
    "            bkg_np = np.exp(\n",
    "                IN_info[i]['all_preds'][0]\n",
    "            )[\n",
    "                np.array(IN_info[i]['all_labels'][0]) == 0,1\n",
    "            ]\n",
    "            hist_axis = hist.axis.Regular(n_bins, 0., 1., name='var', growth=False, underflow=False, overflow=False)\n",
    "            sig_hist = hist.Hist(hist_axis, storage='weight').fill(var=sig_np, weight=weights[i]['sig'])\n",
    "            bkg_hist = hist.Hist(hist_axis, storage='weight').fill(var=bkg_np, weight=weights[i]['bkg'])\n",
    "            plt.plot(\n",
    "                np.arange(0., 1., 1/n_bins), sig_hist.values().flatten() / np.sqrt(bkg_hist.values().flatten()), \n",
    "                label='s/âb'+(' - '+labels[i] if labels is not None else ''), \n",
    "                alpha=0.5, linestyle=linestyles[i], \n",
    "            )\n",
    "    else:\n",
    "        raise Exception(f\"Must used methods 'std', 'arr', or 'IN_arr'. You used {method}.\")\n",
    "    plt.legend(bbox_to_anchor=(1, 1))\n",
    "    plt.xlabel(\"Counts\", fontsize=18)\n",
    "    plt.xlabel(\"Threshold\", fontsize=18)\n",
    "    plt.savefig(f'{plot_prefix}_model_s_over_b{plot_postfix}.pdf', bbox_inches='tight')\n",
    "    plt.savefig(f'{plot_prefix}_model_s_over_b{plot_postfix}.png', bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "MC_NAMES_PRETTY = {\n",
    "    \"GGJets\": r\"$\\gamma\\gamma+3j$\",\n",
    "    \"GJetPt20To40\": r\"$\\gamma+j$, 20<$p_T$<40GeV\",\n",
    "    \"GJetPt40\": r\"$\\gamma+j$, 40GeV<$p_T$\",\n",
    "    \"GluGluHToGG\": r\"ggF $H\\rightarrow \\gamma\\gamma$\",\n",
    "    \"VBFHToGG\": r\"VBF $H\\rightarrow \\gamma\\gamma$\",\n",
    "    \"VHToGG\": r\"V$H\\rightarrow\\gamma\\gamma$\",\n",
    "    \"ttHToGG\": r\"$t\\bar{t}H\\rightarrow\\gamma\\gamma$\",\n",
    "    \"GluGluToHH\": r\"ggF $HH\\rightarrow bb\\gamma\\gamma$\",\n",
    "    \"signal\": r\"ggF $HH\\rightarrow bb\\gamma\\gamma$ + VBF $HH\\rightarrow bb\\gamma\\gamma$\"\n",
    "    # \"VBFHHto2B2G_CV_1_C2V_1_C3_1\": r\"VBF $HH\\rightarrow bb\\gamma\\gamma$\",\n",
    "    # Need to fill in pretty print for BSM samples #\n",
    "}\n",
    "LUMINOSITIES = {\n",
    "    '2022preEE': 7.9804, \n",
    "    '2022postEE': 26.6717,\n",
    "    # Need to fill in lumis for other eras #\n",
    "}\n",
    "LUMINOSITIES['total_lumi'] = sum(LUMINOSITIES.values())\n",
    "\n",
    "# Dictionary of variables\n",
    "VARIABLES = {\n",
    "    # key: hist.axis axes for plotting #\n",
    "    # MET variables\n",
    "    'puppiMET_sumEt': hist.axis.Regular(40, 20., 250, name='var', label=r'puppiMET $\\Sigma E_T$ [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'puppiMET_pt': hist.axis.Regular(40, 20., 250, name='var', label=r'puppiMET $p_T$ [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'puppiMET_phi': hist.axis.Regular(20,-3.2, 3.2, name='var', label=r'puppiMET $\\phi$', growth=False, underflow=False, overflow=False), \n",
    "    # jet-MET variables\n",
    "    'DeltaPhi_j1MET': hist.axis.Regular(20,-3.2, 3.2, name='var', label=r'$\\Delta\\phi (j_1,E_T^{miss})$', growth=False, underflow=False, overflow=False), \n",
    "    'DeltaPhi_j2MET': hist.axis.Regular(20, -3.2, 3.2, name='var', label=r'$\\Delta\\phi (j_2,E_T^{miss})$', growth=False, underflow=False, overflow=False), \n",
    "    # jet-photon variables\n",
    "    'DeltaR_jg_min': hist.axis.Regular(30, 0, 5, name='var', label=r'min$(\\Delta R(jet, \\gamma))$', growth=False, underflow=False, overflow=False), \n",
    "    # jet variables\n",
    "    'jet1_pt': hist.axis.Regular(40, 20., 250, name='var', label=r'lead jet $p_T$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    'jet2_pt': hist.axis.Regular(40, 20., 250, name='var', label=r'sublead jet $p_T$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    'n_jets': hist.axis.Integer(0, 10, name='var', label=r'$n_{jets}$', growth=False, underflow=False, overflow=False), \n",
    "    'chi_t0': hist.axis.Regular(40, 0., 150, name='var', label=r'$\\chi_{t0}^2$', growth=False, underflow=False, overflow=False), \n",
    "    'chi_t1': hist.axis.Regular(30, 0., 500, name='var', label=r'$\\chi_{t1}^2$', growth=False, underflow=False, overflow=False), \n",
    "    # lepton variables\n",
    "    'lepton1_pt': hist.axis.Regular(40, 0., 200., name='var', label=r'lead lepton $p_T$ [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'lepton2_pt': hist.axis.Regular(40, 0., 200., name='var', label=r'sublead lepton $p_T$ [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'lepton1_eta': hist.axis.Regular(30, -5., 5., name='var', label=r'lead lepton $\\eta$', growth=False, underflow=False, overflow=False), \n",
    "    'lepton2_eta': hist.axis.Regular(30, -5., 5., name='var', label=r'sublead lepton $\\eta$', growth=False, underflow=False, overflow=False),\n",
    "    'lepton1_phi': hist.axis.Regular(20, -3.2, 3.2, name='var', label=r'lead lepton $\\phi$', growth=False, underflow=False, overflow=False), \n",
    "    'lepton2_phi': hist.axis.Regular(20, -3.2, 3.2, name='var', label=r'sublead lepton $\\phi$', growth=False, underflow=False, overflow=False),\n",
    "    # diphoton variables\n",
    "    'pt': hist.axis.Regular(40, 20., 2000, name='var', label=r' $\\gamma\\gamma p_{T}$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    'eta': hist.axis.Regular(20, -5., 5., name='var', label=r'$\\gamma\\gamma \\eta$', growth=False, underflow=False, overflow=False), \n",
    "    'phi': hist.axis.Regular(20, -3.2, 3.2, name='var', label=r'$\\gamma \\gamma \\phi$', growth=False, underflow=False, overflow=False),\n",
    "    # angular (cos) variables\n",
    "    'abs_CosThetaStar_CS': hist.axis.Regular(20, 0, 1, name='var', label=r'|cos$(\\theta_{CS})$|', growth=False, underflow=False, overflow=False), \n",
    "    'abs_CosThetaStar_jj': hist.axis.Regular(20, 0, 1, name='var', label=r'|cos$(\\theta_{jj})$|', growth=False, underflow=False, overflow=False),\n",
    "    'CosThetaStar_CS': hist.axis.Regular(20, -1, 1, name='var', label=r'cos$(\\theta_{CS})$', growth=False, underflow=False, overflow=False), \n",
    "    'CosThetaStar_jj': hist.axis.Regular(20, -1, 1, name='var', label=r'cos$(\\theta_{jj})$', growth=False, underflow=False, overflow=False), \n",
    "    # jet-lepton variables\n",
    "    'leadBjet_leadLepton': hist.axis.Regular(30, 0, 5, name='var', label=r'$\\Delta R(bjet_{lead}, l_{lead})$', growth=False, underflow=False, overflow=False), \n",
    "    'leadBjet_subleadLepton': hist.axis.Regular(30, 0, 5, name='var', label=r'$\\Delta R(bjet_{lead}, l_{sublead})$', growth=False, underflow=False, overflow=False), \n",
    "    'subleadBjet_leadLepton': hist.axis.Regular(30, 0, 5, name='var', label=r'$\\Delta R(bjet_{sublead}, l_{lead})$', growth=False, underflow=False, overflow=False), \n",
    "    'subleadBjet_subleadLepton': hist.axis.Regular(30, 0, 5, name='var', label=r'$\\Delta R(bjet_{sublead}, l_{sublead})$', growth=False, underflow=False, overflow=False),\n",
    "    # dijet variables (must be blinded on data)\n",
    "    'dijet_mass': hist.axis.Regular(50, 25., 180., name='var', label=r'$M_{jj}$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    # diphoton variables (must be blinded on data)\n",
    "    'mass': hist.axis.Regular(50, 25., 180., name='var', label=r'$M_{\\gamma\\gamma}$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "}\n",
    "# Dictionary of variables to do MC/Data comparison\n",
    "VARIABLES_STD = {\n",
    "    # key: hist.axis axes for plotting #\n",
    "    # MET variables\n",
    "    'puppiMET_sumEt': hist.axis.Regular(40, -10., 4., name='var', label=r'puppiMET $\\Sigma E_T$ [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'puppiMET_pt': hist.axis.Regular(40, -10., 4., name='var', label=r'puppiMET $p_T$ [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'puppiMET_phi': hist.axis.Regular(40, -10., 4., name='var', label=r'puppiMET $\\phi$', growth=False, underflow=False, overflow=False), \n",
    "    # jet-MET variables\n",
    "    'DeltaPhi_j1MET': hist.axis.Regular(40, -10., 4., name='var', label=r'$\\Delta\\phi (j_1,E_T^{miss})$', growth=False, underflow=False, overflow=False), \n",
    "    'DeltaPhi_j2MET': hist.axis.Regular(40, -10., 4., name='var', label=r'$\\Delta\\phi (j_2,E_T^{miss})$', growth=False, underflow=False, overflow=False), \n",
    "    # jet-photon variables\n",
    "    'DeltaR_jg_min': hist.axis.Regular(40, -10., 4., name='var', label=r'min$(\\Delta R(jet, \\gamma))$', growth=False, underflow=False, overflow=False), \n",
    "    # jet variables\n",
    "    'jet1_pt': hist.axis.Regular(40, -10., 4., name='var', label=r'lead jet $p_T$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    'jet2_pt': hist.axis.Regular(40, -10., 4., name='var', label=r'sublead jet $p_T$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    'n_jets': hist.axis.Regular(40, -10., 4., name='var', label=r'$n_{jets}$', growth=False, underflow=False, overflow=False), \n",
    "    'chi_t0': hist.axis.Regular(40, -10., 4., name='var', label=r'$\\chi_{t0}^2$', growth=False, underflow=False, overflow=False), \n",
    "    'chi_t1': hist.axis.Regular(40, -10., 4., name='var', label=r'$\\chi_{t1}^2$', growth=False, underflow=False, overflow=False), \n",
    "    # lepton variables\n",
    "    'lepton1_pt': hist.axis.Regular(40, -10., 4., name='var', label=r'lead lepton $p_T$ [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'lepton2_pt': hist.axis.Regular(40, -10., 4., name='var', label=r'sublead lepton $p_T$ [GeV]', growth=False, underflow=False, overflow=False), \n",
    "    'lepton1_eta': hist.axis.Regular(40, -10., 4., name='var', label=r'lead lepton $\\eta$', growth=False, underflow=False, overflow=False), \n",
    "    'lepton2_eta': hist.axis.Regular(40, -10., 4., name='var', label=r'sublead lepton $\\eta$', growth=False, underflow=False, overflow=False),\n",
    "    'lepton1_phi': hist.axis.Regular(40, -10., 4., name='var', label=r'lead lepton $\\phi$', growth=False, underflow=False, overflow=False), \n",
    "    'lepton2_phi': hist.axis.Regular(40, -10., 4., name='var', label=r'sublead lepton $\\phi$', growth=False, underflow=False, overflow=False),\n",
    "    # diphoton variables\n",
    "    'pt': hist.axis.Regular(40, -10., 4., name='var', label=r' $\\gamma\\gamma p_{T}$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    'eta': hist.axis.Regular(40, -10., 4., name='var', label=r'$\\gamma\\gamma \\eta$', growth=False, underflow=False, overflow=False), \n",
    "    'phi': hist.axis.Regular(40, -10., 4., name='var', label=r'$\\gamma \\gamma \\phi$', growth=False, underflow=False, overflow=False),\n",
    "    # angular (cos) variables\n",
    "    'abs_CosThetaStar_CS': hist.axis.Regular(40, -10., 4., name='var', label=r'|cos$(\\theta_{CS})$|', growth=False, underflow=False, overflow=False), \n",
    "    'abs_CosThetaStar_jj': hist.axis.Regular(40, -10., 4., name='var', label=r'|cos$(\\theta_{jj})$|', growth=False, underflow=False, overflow=False), \n",
    "    'CosThetaStar_CS': hist.axis.Regular(40, -10., 4., name='var', label=r'cos$(\\theta_{CS})$', growth=False, underflow=False, overflow=False), \n",
    "    'CosThetaStar_jj': hist.axis.Regular(40, -10., 4., name='var', label=r'cos$(\\theta_{jj})$', growth=False, underflow=False, overflow=False), \n",
    "    # jet-lepton variables\n",
    "    'leadBjet_leadLepton': hist.axis.Regular(40, -10., 4., name='var', label=r'$\\Delta R(bjet_{lead}, l_{lead})$', growth=False, underflow=False, overflow=False), \n",
    "    'leadBjet_subleadLepton': hist.axis.Regular(40, -10., 4., name='var', label=r'$\\Delta R(bjet_{lead}, l_{sublead})$', growth=False, underflow=False, overflow=False), \n",
    "    'subleadBjet_leadLepton': hist.axis.Regular(40, -10., 4., name='var', label=r'$\\Delta R(bjet_{sublead}, l_{lead})$', growth=False, underflow=False, overflow=False), \n",
    "    'subleadBjet_subleadLepton': hist.axis.Regular(40, -10., 4., name='var', label=r'$\\Delta R(bjet_{sublead}, l_{sublead})$', growth=False, underflow=False, overflow=False),\n",
    "    # dijet variables (must be blinded on data)\n",
    "    'dijet_mass': hist.axis.Regular(40, -10., 4., name='var', label=r'$M_{jj}$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "    # diphoton variables (must be blinded on data)\n",
    "    'mass': hist.axis.Regular(40, -10., 4., name='var', label=r'$M_{\\gamma\\gamma}$ [GeV]', growth=False, underflow=False, overflow=False),\n",
    "}\n",
    "\n",
    "def post_std_np_arrays(\n",
    "        data, data_test, var_name, train_index=None, val_index=None\n",
    "):\n",
    "    sig_mask = label == 1\n",
    "    sig_test_mask = label_test == 1\n",
    "    bkg_mask = label == 0\n",
    "    bkg_test_mask = label_test == 0\n",
    "    if train_index is not None and val_index is not None:\n",
    "        sig_train_mask = sig_mask & train_index \n",
    "        sig_val_mask = sig_mask & val_index\n",
    "        bkg_train_mask = bkg_mask & train_index\n",
    "        bkg_val_mask = bkg_mask & val_index\n",
    "        if var_name in (high_level_fields - set(input_hlf_vars)):\n",
    "            sig_train_np = data[data_list_index_map(var_name, data, sig_train_mask)]\n",
    "            sig_val_np = data[data_list_index_map(var_name, data, sig_val_mask)]\n",
    "            sig_test_np = data_test[data_list_index_map(var_name, data_test, sig_test_mask)]\n",
    "            bkg_train_np = data[data_list_index_map(var_name, data, sig_train_mask)]\n",
    "            bkg_val_np = data[data_list_index_map(var_name, data, bkg_val_mask)]\n",
    "            bkg_test_np = data_test[data_list_index_map(var_name, data_test, bkg_test_mask)]\n",
    "        else:\n",
    "            index2 = hlf_vars_columns[var_name]\n",
    "            sig_train_np = data[sig_train_mask, index2]\n",
    "            sig_val_np = data[sig_val_mask, index2]\n",
    "            sig_test_np = data_test[sig_test_mask, index2]\n",
    "            bkg_train_np = data[bkg_train_mask, index2]\n",
    "            bkg_val_np = data[bkg_val_mask, index2]\n",
    "            bkg_test_np = data_test[bkg_test_mask, index2]\n",
    "\n",
    "        return (\n",
    "            sig_train_np, sig_val_np, sig_test_np, \n",
    "            bkg_train_np, bkg_val_np, bkg_test_np\n",
    "        )\n",
    "    elif train_index is None and val_index is None:\n",
    "        if var_name in (high_level_fields - set(input_hlf_vars)):\n",
    "            # index2, index3 = index_map[var_name]\n",
    "            sig_train_np = data[data_list_index_map(var_name, data, sig_mask)]\n",
    "            sig_test_np = data_test[data_list_index_map(var_name, data_test, sig_test_mask)]\n",
    "            bkg_train_np = data[data_list_index_map(var_name, data, bkg_mask)]\n",
    "            bkg_test_np = data_test[data_list_index_map(var_name, data_test, bkg_test_mask)]\n",
    "        else:\n",
    "            index2 = hlf_vars_columns[var_name]\n",
    "            sig_train_np = data[sig_mask, index2]\n",
    "            sig_test_np = data_test[sig_test_mask, index2]\n",
    "            bkg_train_np = data[bkg_mask, index2]\n",
    "            bkg_test_np = data_test[bkg_test_mask, index2]\n",
    "        return (\n",
    "            copy.deepcopy(sig_train_np), copy.deepcopy(sig_test_np), \n",
    "            copy.deepcopy(bkg_train_np), copy.deepcopy(bkg_test_np)\n",
    "        )\n",
    "    else:\n",
    "        raise Exception(\"Either both train_index and val_index must be 'None', or both should not be 'None'. You cannot mix and match.\")\n",
    "\n",
    "def aux_np_arrays(var_name, score_cut, IN_full_eval_dict):\n",
    "    sig_train_mask = (label == 1) & (\n",
    "        np.exp(IN_full_eval_dict['train']['mean_pred'])[:, 1] > score_cut\n",
    "    )\n",
    "    sig_test_mask = (label_test == 1) & (\n",
    "        np.exp(IN_full_eval_dict['test']['mean_pred'])[:, 1] > score_cut\n",
    "    )\n",
    "    bkg_train_mask = (label == 0) & (\n",
    "        np.exp(IN_full_eval_dict['train']['mean_pred'])[:, 1] > score_cut\n",
    "    )\n",
    "    bkg_test_mask = (label_test == 0) & (\n",
    "        np.exp(IN_full_eval_dict['test']['mean_pred'])[:, 1] > score_cut\n",
    "    )\n",
    "\n",
    "    sig_train_np = data_aux.loc[sig_train_mask, var_name].to_numpy()\n",
    "    sig_test_np = data_test_aux.loc[sig_test_mask, var_name].to_numpy()\n",
    "    bkg_train_np = data_aux.loc[bkg_train_mask, var_name].to_numpy()\n",
    "    bkg_test_np = data_test_aux.loc[bkg_test_mask, var_name].to_numpy()\n",
    "\n",
    "    return (\n",
    "        copy.deepcopy(sig_train_np), copy.deepcopy(sig_test_np), \n",
    "        copy.deepcopy(bkg_train_np), copy.deepcopy(bkg_test_np)\n",
    "    )\n",
    "\n",
    "def make_input_plot(output_dir, var_name, hist_list, fold_idx=None, labels=None, density=True, plot_prefix='', plot_postfix='', alpha=0.8, linestyle=True):\n",
    "    fig, ax = plt.subplots()\n",
    "    if linestyle:\n",
    "        if fold_idx is not None:\n",
    "            linestyles = [\"solid\", \"dashed\", \"dotted\", \"solid\", \"dashed\", \"dotted\"]\n",
    "        else:\n",
    "            linestyles = [\"solid\", \"dotted\", \"solid\", \"dotted\"]\n",
    "        linestyles = linestyles * ((len(hist_list) // len(linestyles)) + 1)\n",
    "        linestyles = linestyles[:len(hist_list)]\n",
    "    else:\n",
    "        linestyles = None\n",
    "    hep.histplot(\n",
    "        hist_list, ax=ax, linewidth=3, histtype=\"step\", yerr=True, density=density,\n",
    "        linestyle=linestyles, label=labels, alpha=alpha\n",
    "    )\n",
    "    # Plotting niceties #\n",
    "    hep.cms.lumitext(f\"{LUMINOSITIES['total_lumi']:.2f}\" + r\"fb$^{-1}$ (13.6 TeV)\", ax=ax)\n",
    "    hep.cms.text(\"Work in Progress\", ax=ax)\n",
    "    # Plot legend properly\n",
    "    ax.legend(bbox_to_anchor=(1, 0.5))\n",
    "    # Make angular and chi^2 plots linear, otherwise log\n",
    "    if re.match('chi_t', var_name) is None and re.match('DeltaPhi', var_name) is None and re.match('mass', var_name) is None:\n",
    "        ax.set_yscale('log')\n",
    "    else:\n",
    "        ax.set_yscale('linear')\n",
    "    ax.set_yscale('linear')\n",
    "    # Save out the plot\n",
    "    if fold_idx is not None:\n",
    "        output_dir = output_dir + \"fold/\"\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "        plt.savefig(f'{output_dir}/{plot_prefix}1dhist_{var_name}{plot_postfix}_fold{fold_idx}.pdf', bbox_inches='tight')\n",
    "        plt.savefig(f'{output_dir}/{plot_prefix}1dhist_{var_name}{plot_postfix}_fold{fold_idx}.png', bbox_inches='tight')\n",
    "    else:\n",
    "        plt.savefig(f'{output_dir}/{plot_prefix}1dhist_{var_name}{plot_postfix}.pdf', bbox_inches='tight')\n",
    "        plt.savefig(f'{output_dir}/{plot_prefix}1dhist_{var_name}{plot_postfix}.png', bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_layers': 2, 'initial_nodes': 500, 'dropout': 0.27817607062770483, 'gru_layers': 2, 'gru_size': 500, 'dropout_g': 0.6184468141076988, 'learning_rate': 0.004851812500501461, 'batch_size': 4000, 'L2_reg': 0.0001}\n",
      "Epoch 0/149\n",
      "training Loss: 0.0001 Acc: 47.4197\n",
      "validation Loss: 0.0001 Acc: 69.2633\n",
      "Saving..\n",
      "Epoch 1/149\n",
      "training Loss: 0.0001 Acc: 66.0117\n",
      "validation Loss: 0.0001 Acc: 66.1010\n",
      "Epoch 2/149\n",
      "training Loss: 0.0001 Acc: 67.6421\n",
      "validation Loss: 0.0001 Acc: 64.8558\n",
      "Epoch 3/149\n",
      "training Loss: 0.0000 Acc: 68.0085\n",
      "validation Loss: 0.0001 Acc: 75.3794\n",
      "Saving..\n",
      "Epoch 4/149\n",
      "training Loss: 0.0000 Acc: 68.1518\n",
      "validation Loss: 0.0001 Acc: 70.4854\n",
      "Epoch 5/149\n",
      "training Loss: 0.0000 Acc: 69.6577\n",
      "validation Loss: 0.0001 Acc: 74.2268\n",
      "Epoch 6/149\n",
      "training Loss: 0.0000 Acc: 70.2297\n",
      "validation Loss: 0.0001 Acc: 67.9370\n",
      "Epoch 7/149\n",
      "training Loss: 0.0000 Acc: 70.1211\n",
      "validation Loss: 0.0001 Acc: 67.2246\n",
      "Epoch 8/149\n",
      "training Loss: 0.0000 Acc: 70.3542\n",
      "validation Loss: 0.0001 Acc: 75.2925\n",
      "Epoch 9/149\n",
      "training Loss: 0.0000 Acc: 69.9893\n",
      "validation Loss: 0.0001 Acc: 70.9545\n",
      "Epoch 10/149\n",
      "training Loss: 0.0000 Acc: 70.6988\n",
      "validation Loss: 0.0001 Acc: 69.4023\n",
      "Epoch 11/149\n",
      "training Loss: 0.0000 Acc: 70.5207\n",
      "validation Loss: 0.0001 Acc: 73.7113\n",
      "Epoch 12/149\n",
      "training Loss: 0.0000 Acc: 71.0304\n",
      "validation Loss: 0.0000 Acc: 72.3792\n",
      "Epoch 13/149\n",
      "training Loss: 0.0000 Acc: 71.3895\n",
      "validation Loss: 0.0001 Acc: 74.1805\n",
      "Epoch 14/149\n",
      "training Loss: 0.0000 Acc: 71.7515\n",
      "validation Loss: 0.0000 Acc: 71.4989\n",
      "Epoch 15/149\n",
      "training Loss: 0.0000 Acc: 71.6559\n",
      "validation Loss: 0.0000 Acc: 72.2229\n",
      "Epoch 16/149\n",
      "training Loss: 0.0000 Acc: 72.2061\n",
      "validation Loss: 0.0000 Acc: 74.7481\n",
      "Epoch 17/149\n",
      "training Loss: 0.0000 Acc: 72.0107\n",
      "validation Loss: 0.0000 Acc: 68.2092\n",
      "Epoch 18/149\n",
      "training Loss: 0.0000 Acc: 71.8239\n",
      "validation Loss: 0.0000 Acc: 73.6708\n",
      "Epoch 19/149\n",
      "training Loss: 0.0000 Acc: 71.7211\n",
      "validation Loss: 0.0000 Acc: 76.0338\n",
      "Saving..\n",
      "Epoch 20/149\n",
      "training Loss: 0.0000 Acc: 72.4465\n",
      "validation Loss: 0.0000 Acc: 73.1611\n",
      "Epoch 21/149\n",
      "training Loss: 0.0000 Acc: 72.2756\n",
      "validation Loss: 0.0000 Acc: 72.6515\n",
      "Epoch 22/149\n",
      "training Loss: 0.0000 Acc: 71.6892\n",
      "validation Loss: 0.0000 Acc: 74.0183\n",
      "Epoch 23/149\n",
      "training Loss: 0.0000 Acc: 72.3278\n",
      "validation Loss: 0.0000 Acc: 73.9025\n",
      "Epoch 24/149\n",
      "training Loss: 0.0000 Acc: 72.3060\n",
      "validation Loss: 0.0000 Acc: 72.8078\n",
      "Epoch 25/149\n",
      "training Loss: 0.0000 Acc: 72.6608\n",
      "validation Loss: 0.0000 Acc: 72.9642\n",
      "Epoch 26/149\n",
      "training Loss: 0.0000 Acc: 72.3857\n",
      "validation Loss: 0.0000 Acc: 69.9930\n",
      "Epoch 27/149\n",
      "training Loss: 0.0000 Acc: 71.9585\n",
      "validation Loss: 0.0000 Acc: 72.7094\n",
      "Epoch 28/149\n",
      "training Loss: 0.0000 Acc: 72.5044\n",
      "validation Loss: 0.0000 Acc: 74.8986\n",
      "Epoch 29/149\n",
      "training Loss: 0.0000 Acc: 72.9330\n",
      "validation Loss: 0.0000 Acc: 71.6900\n",
      "Epoch 30/149\n",
      "training Loss: 0.0000 Acc: 72.8490\n",
      "validation Loss: 0.0000 Acc: 72.5704\n",
      "Epoch 31/149\n",
      "training Loss: 0.0000 Acc: 72.7535\n",
      "validation Loss: 0.0000 Acc: 74.4121\n",
      "Epoch 32/149\n",
      "training Loss: 0.0000 Acc: 72.9214\n",
      "validation Loss: 0.0000 Acc: 72.2402\n",
      "Epoch 33/149\n",
      "training Loss: 0.0000 Acc: 72.6840\n",
      "validation Loss: 0.0000 Acc: 72.4487\n",
      "Epoch 34/149\n",
      "training Loss: 0.0000 Acc: 73.4717\n",
      "validation Loss: 0.0000 Acc: 70.9139\n",
      "Epoch 35/149\n",
      "training Loss: 0.0000 Acc: 72.1366\n",
      "validation Loss: 0.0000 Acc: 73.4623\n",
      "Epoch 36/149\n",
      "training Loss: 0.0000 Acc: 72.7390\n",
      "validation Loss: 0.0000 Acc: 73.1438\n",
      "Epoch 37/149\n",
      "training Loss: 0.0000 Acc: 73.2458\n",
      "validation Loss: 0.0000 Acc: 71.9796\n",
      "Epoch 38/149\n",
      "training Loss: 0.0000 Acc: 72.5493\n",
      "validation Loss: 0.0000 Acc: 73.8040\n",
      "Epoch 39/149\n",
      "training Loss: 0.0000 Acc: 73.1328\n",
      "validation Loss: 0.0000 Acc: 73.7519\n",
      "Epoch 40/149\n",
      "training Loss: 0.0000 Acc: 72.9880\n",
      "validation Loss: 0.0000 Acc: 72.9584\n",
      "Epoch 41/149\n",
      "training Loss: 0.0000 Acc: 73.1213\n",
      "validation Loss: 0.0000 Acc: 72.1939\n",
      "Epoch 42/149\n",
      "training Loss: 0.0000 Acc: 72.8823\n",
      "validation Loss: 0.0000 Acc: 74.3195\n",
      "Epoch 43/149\n",
      "training Loss: 0.0000 Acc: 73.3935\n",
      "validation Loss: 0.0000 Acc: 74.1399\n",
      "Epoch 44/149\n",
      "training Loss: 0.0000 Acc: 73.3167\n",
      "validation Loss: 0.0000 Acc: 72.9816\n",
      "Early stopped.\n",
      "Best val acc: 76.033829\n",
      "----------\n",
      "Epoch 0/149\n",
      "training Loss: 0.0001 Acc: 38.8448\n",
      "validation Loss: 0.0001 Acc: 60.6336\n",
      "Saving..\n",
      "Epoch 1/149\n",
      "training Loss: 0.0001 Acc: 65.0169\n",
      "validation Loss: 0.0001 Acc: 70.5548\n",
      "Saving..\n",
      "Epoch 2/149\n",
      "training Loss: 0.0001 Acc: 66.4258\n",
      "validation Loss: 0.0001 Acc: 67.4099\n",
      "Epoch 3/149\n",
      "training Loss: 0.0001 Acc: 67.4799\n",
      "validation Loss: 0.0001 Acc: 69.8019\n",
      "Epoch 4/149\n",
      "training Loss: 0.0001 Acc: 68.9062\n",
      "validation Loss: 0.0001 Acc: 68.0123\n",
      "Epoch 5/149\n",
      "training Loss: 0.0000 Acc: 69.0134\n",
      "validation Loss: 0.0001 Acc: 72.3561\n",
      "Saving..\n",
      "Epoch 6/149\n",
      "training Loss: 0.0000 Acc: 69.4651\n",
      "validation Loss: 0.0001 Acc: 70.4680\n",
      "Epoch 7/149\n",
      "training Loss: 0.0000 Acc: 69.2291\n",
      "validation Loss: 0.0001 Acc: 73.5144\n",
      "Saving..\n",
      "Epoch 8/149\n",
      "training Loss: 0.0000 Acc: 69.1813\n",
      "validation Loss: 0.0001 Acc: 72.6167\n",
      "Epoch 9/149\n",
      "training Loss: 0.0000 Acc: 70.3571\n",
      "validation Loss: 0.0001 Acc: 67.8617\n",
      "Epoch 10/149\n",
      "training Loss: 0.0000 Acc: 70.8103\n",
      "validation Loss: 0.0001 Acc: 66.3964\n",
      "Epoch 11/149\n",
      "training Loss: 0.0000 Acc: 70.1746\n",
      "validation Loss: 0.0000 Acc: 71.2962\n",
      "Epoch 12/149\n",
      "training Loss: 0.0000 Acc: 70.9971\n",
      "validation Loss: 0.0001 Acc: 69.7903\n",
      "Epoch 13/149\n",
      "training Loss: 0.0000 Acc: 70.4237\n",
      "validation Loss: 0.0001 Acc: 75.8311\n",
      "Saving..\n",
      "Epoch 14/149\n",
      "training Loss: 0.0000 Acc: 71.0536\n",
      "validation Loss: 0.0001 Acc: 70.4680\n",
      "Epoch 15/149\n",
      "training Loss: 0.0000 Acc: 70.3397\n",
      "validation Loss: 0.0001 Acc: 75.5647\n",
      "Epoch 16/149\n",
      "training Loss: 0.0000 Acc: 70.9116\n",
      "validation Loss: 0.0000 Acc: 73.4275\n",
      "Epoch 17/149\n",
      "training Loss: 0.0000 Acc: 71.9267\n",
      "validation Loss: 0.0000 Acc: 71.0877\n",
      "Epoch 18/149\n",
      "training Loss: 0.0000 Acc: 71.4821\n",
      "validation Loss: 0.0000 Acc: 72.5182\n",
      "Epoch 19/149\n",
      "training Loss: 0.0000 Acc: 71.4155\n",
      "validation Loss: 0.0000 Acc: 71.4815\n",
      "Epoch 20/149\n",
      "training Loss: 0.0000 Acc: 71.5994\n",
      "validation Loss: 0.0000 Acc: 74.2210\n",
      "Epoch 21/149\n",
      "training Loss: 0.0000 Acc: 72.3292\n",
      "validation Loss: 0.0000 Acc: 70.7170\n",
      "Epoch 22/149\n",
      "training Loss: 0.0000 Acc: 72.0005\n",
      "validation Loss: 0.0000 Acc: 72.6283\n",
      "Epoch 23/149\n",
      "training Loss: 0.0000 Acc: 72.0584\n",
      "validation Loss: 0.0000 Acc: 73.6534\n",
      "Epoch 24/149\n",
      "training Loss: 0.0000 Acc: 72.0874\n",
      "validation Loss: 0.0000 Acc: 74.1168\n",
      "Epoch 25/149\n",
      "training Loss: 0.0000 Acc: 72.7260\n",
      "validation Loss: 0.0000 Acc: 69.8483\n",
      "Epoch 26/149\n",
      "training Loss: 0.0000 Acc: 71.6226\n",
      "validation Loss: 0.0000 Acc: 73.9951\n",
      "Epoch 27/149\n",
      "training Loss: 0.0000 Acc: 72.6782\n",
      "validation Loss: 0.0000 Acc: 70.6649\n",
      "Epoch 28/149\n",
      "training Loss: 0.0000 Acc: 72.0396\n",
      "validation Loss: 0.0000 Acc: 73.0858\n",
      "Epoch 29/149\n",
      "training Loss: 0.0000 Acc: 72.2887\n",
      "validation Loss: 0.0000 Acc: 72.8889\n",
      "Epoch 30/149\n",
      "training Loss: 0.0000 Acc: 72.3118\n",
      "validation Loss: 0.0000 Acc: 72.1070\n",
      "Epoch 31/149\n",
      "training Loss: 0.0000 Acc: 72.6579\n",
      "validation Loss: 0.0000 Acc: 72.4545\n",
      "Early stopped.\n",
      "Best val acc: 75.831116\n",
      "----------\n",
      "Epoch 0/149\n",
      "training Loss: 0.0001 Acc: 52.2907\n",
      "validation Loss: 0.0001 Acc: 69.8946\n",
      "Saving..\n",
      "Epoch 1/149\n",
      "training Loss: 0.0001 Acc: 68.7107\n",
      "validation Loss: 0.0001 Acc: 68.6841\n",
      "Epoch 2/149\n",
      "training Loss: 0.0001 Acc: 69.4159\n",
      "validation Loss: 0.0001 Acc: 74.2616\n",
      "Saving..\n",
      "Epoch 3/149\n",
      "training Loss: 0.0000 Acc: 69.5230\n",
      "validation Loss: 0.0001 Acc: 63.4368\n",
      "Epoch 4/149\n",
      "training Loss: 0.0000 Acc: 69.5679\n",
      "validation Loss: 0.0001 Acc: 71.8348\n",
      "Epoch 5/149\n",
      "training Loss: 0.0000 Acc: 71.3200\n",
      "validation Loss: 0.0001 Acc: 67.4042\n",
      "Epoch 6/149\n",
      "training Loss: 0.0000 Acc: 70.4715\n",
      "validation Loss: 0.0001 Acc: 70.5780\n",
      "Epoch 7/149\n",
      "training Loss: 0.0000 Acc: 70.6076\n",
      "validation Loss: 0.0001 Acc: 65.7651\n",
      "Epoch 8/149\n",
      "training Loss: 0.0000 Acc: 70.5757\n",
      "validation Loss: 0.0001 Acc: 74.2616\n",
      "Epoch 9/149\n",
      "training Loss: 0.0000 Acc: 71.1723\n",
      "validation Loss: 0.0001 Acc: 73.6824\n",
      "Epoch 10/149\n",
      "training Loss: 0.0000 Acc: 70.7451\n",
      "validation Loss: 0.0001 Acc: 69.7382\n",
      "Epoch 11/149\n",
      "training Loss: 0.0000 Acc: 70.8740\n",
      "validation Loss: 0.0001 Acc: 69.9699\n",
      "Epoch 12/149\n",
      "training Loss: 0.0000 Acc: 71.9108\n",
      "validation Loss: 0.0001 Acc: 67.9138\n",
      "Epoch 13/149\n",
      "training Loss: 0.0000 Acc: 71.4488\n",
      "validation Loss: 0.0001 Acc: 69.6340\n",
      "Epoch 14/149\n",
      "training Loss: 0.0000 Acc: 71.8340\n",
      "validation Loss: 0.0000 Acc: 72.1360\n",
      "Epoch 15/149\n",
      "training Loss: 0.0000 Acc: 72.9837\n",
      "validation Loss: 0.0001 Acc: 70.2826\n",
      "Epoch 16/149\n",
      "training Loss: 0.0000 Acc: 72.7752\n",
      "validation Loss: 0.0000 Acc: 72.5125\n",
      "Epoch 17/149\n",
      "training Loss: 0.0000 Acc: 72.6072\n",
      "validation Loss: 0.0001 Acc: 73.8272\n",
      "Epoch 18/149\n",
      "training Loss: 0.0000 Acc: 73.1285\n",
      "validation Loss: 0.0000 Acc: 73.2538\n",
      "Epoch 19/149\n",
      "training Loss: 0.0000 Acc: 72.2814\n",
      "validation Loss: 0.0000 Acc: 71.8985\n",
      "Epoch 20/149\n",
      "training Loss: 0.0000 Acc: 72.9779\n",
      "validation Loss: 0.0000 Acc: 71.3483\n",
      "Epoch 21/149\n",
      "training Loss: 0.0000 Acc: 73.1213\n",
      "validation Loss: 0.0000 Acc: 71.8869\n",
      "Epoch 22/149\n",
      "training Loss: 0.0000 Acc: 72.8027\n",
      "validation Loss: 0.0000 Acc: 74.6264\n",
      "Saving..\n",
      "Epoch 23/149\n",
      "training Loss: 0.0000 Acc: 73.5484\n",
      "validation Loss: 0.0000 Acc: 72.1707\n",
      "Epoch 24/149\n",
      "training Loss: 0.0000 Acc: 73.1386\n",
      "validation Loss: 0.0000 Acc: 73.0048\n",
      "Epoch 25/149\n",
      "training Loss: 0.0000 Acc: 73.1980\n",
      "validation Loss: 0.0000 Acc: 72.3213\n",
      "Epoch 26/149\n",
      "training Loss: 0.0000 Acc: 73.3515\n",
      "validation Loss: 0.0000 Acc: 72.0665\n",
      "Epoch 27/149\n",
      "training Loss: 0.0000 Acc: 72.9518\n",
      "validation Loss: 0.0000 Acc: 73.5086\n",
      "Epoch 28/149\n",
      "training Loss: 0.0000 Acc: 73.2052\n",
      "validation Loss: 0.0000 Acc: 74.7133\n",
      "Saving..\n",
      "Epoch 29/149\n",
      "training Loss: 0.0000 Acc: 73.4948\n",
      "validation Loss: 0.0000 Acc: 72.7731\n",
      "Epoch 30/149\n",
      "training Loss: 0.0000 Acc: 73.8684\n",
      "validation Loss: 0.0000 Acc: 70.6823\n",
      "Epoch 31/149\n",
      "training Loss: 0.0000 Acc: 73.0460\n",
      "validation Loss: 0.0001 Acc: 72.9063\n",
      "Epoch 32/149\n",
      "training Loss: 0.0000 Acc: 73.1415\n",
      "validation Loss: 0.0000 Acc: 72.6225\n",
      "Epoch 33/149\n",
      "training Loss: 0.0000 Acc: 73.2950\n",
      "validation Loss: 0.0000 Acc: 71.4757\n",
      "Epoch 34/149\n",
      "training Loss: 0.0000 Acc: 72.9070\n",
      "validation Loss: 0.0000 Acc: 71.7248\n",
      "Epoch 35/149\n",
      "training Loss: 0.0000 Acc: 73.0923\n",
      "validation Loss: 0.0000 Acc: 73.3523\n",
      "Epoch 36/149\n",
      "training Loss: 0.0000 Acc: 73.6367\n",
      "validation Loss: 0.0000 Acc: 72.2924\n",
      "Epoch 37/149\n",
      "training Loss: 0.0000 Acc: 73.0503\n",
      "validation Loss: 0.0000 Acc: 73.4623\n",
      "Epoch 38/149\n",
      "training Loss: 0.0000 Acc: 73.3674\n",
      "validation Loss: 0.0000 Acc: 72.8484\n",
      "Epoch 39/149\n",
      "training Loss: 0.0000 Acc: 73.0764\n",
      "validation Loss: 0.0000 Acc: 73.0916\n",
      "Epoch 40/149\n",
      "training Loss: 0.0000 Acc: 73.7004\n",
      "validation Loss: 0.0000 Acc: 72.3040\n",
      "Epoch 41/149\n",
      "training Loss: 0.0000 Acc: 73.3660\n",
      "validation Loss: 0.0000 Acc: 72.6804\n",
      "Epoch 42/149\n",
      "training Loss: 0.0000 Acc: 73.1676\n",
      "validation Loss: 0.0000 Acc: 73.7519\n",
      "Early stopped.\n",
      "Best val acc: 74.713310\n",
      "----------\n",
      "Epoch 0/149\n",
      "training Loss: 0.0001 Acc: 49.3868\n",
      "validation Loss: 0.0001 Acc: 64.3730\n",
      "Saving..\n",
      "Epoch 1/149\n",
      "training Loss: 0.0001 Acc: 67.3530\n",
      "validation Loss: 0.0001 Acc: 62.6180\n",
      "Epoch 2/149\n",
      "training Loss: 0.0001 Acc: 68.5649\n",
      "validation Loss: 0.0001 Acc: 72.4414\n",
      "Saving..\n",
      "Epoch 3/149\n",
      "training Loss: 0.0000 Acc: 70.2663\n",
      "validation Loss: 0.0001 Acc: 78.4535\n",
      "Saving..\n",
      "Epoch 4/149\n",
      "training Loss: 0.0000 Acc: 70.3242\n",
      "validation Loss: 0.0001 Acc: 76.6174\n",
      "Epoch 5/149\n",
      "training Loss: 0.0000 Acc: 71.2277\n",
      "validation Loss: 0.0001 Acc: 72.9800\n",
      "Epoch 6/149\n",
      "training Loss: 0.0000 Acc: 70.9830\n",
      "validation Loss: 0.0001 Acc: 73.6809\n",
      "Epoch 7/149\n",
      "training Loss: 0.0000 Acc: 71.5694\n",
      "validation Loss: 0.0001 Acc: 69.6901\n",
      "Epoch 8/149\n",
      "training Loss: 0.0000 Acc: 71.6259\n",
      "validation Loss: 0.0001 Acc: 76.8549\n",
      "Epoch 9/149\n",
      "training Loss: 0.0000 Acc: 72.0690\n",
      "validation Loss: 0.0001 Acc: 69.7596\n",
      "Epoch 10/149\n",
      "training Loss: 0.0000 Acc: 70.8744\n",
      "validation Loss: 0.0001 Acc: 70.3041\n",
      "Epoch 11/149\n",
      "training Loss: 0.0000 Acc: 71.1336\n",
      "validation Loss: 0.0001 Acc: 67.8309\n",
      "Epoch 12/149\n",
      "training Loss: 0.0000 Acc: 71.5361\n",
      "validation Loss: 0.0001 Acc: 75.7892\n",
      "Epoch 13/149\n",
      "training Loss: 0.0000 Acc: 72.3716\n",
      "validation Loss: 0.0001 Acc: 72.1518\n",
      "Epoch 14/149\n",
      "training Loss: 0.0000 Acc: 72.6540\n",
      "validation Loss: 0.0001 Acc: 71.2192\n",
      "Epoch 15/149\n",
      "training Loss: 0.0000 Acc: 72.0255\n",
      "validation Loss: 0.0000 Acc: 71.8795\n",
      "Epoch 16/149\n",
      "training Loss: 0.0000 Acc: 72.5034\n",
      "validation Loss: 0.0001 Acc: 71.3293\n",
      "Epoch 17/149\n",
      "training Loss: 0.0000 Acc: 72.2065\n",
      "validation Loss: 0.0001 Acc: 73.7793\n",
      "Epoch 18/149\n",
      "training Loss: 0.0000 Acc: 72.6626\n",
      "validation Loss: 0.0000 Acc: 73.9010\n",
      "Epoch 19/149\n",
      "training Loss: 0.0000 Acc: 72.6467\n",
      "validation Loss: 0.0000 Acc: 72.7657\n",
      "Epoch 20/149\n",
      "training Loss: 0.0000 Acc: 72.3948\n",
      "validation Loss: 0.0000 Acc: 75.0999\n",
      "Epoch 21/149\n",
      "training Loss: 0.0000 Acc: 72.8292\n",
      "validation Loss: 0.0001 Acc: 71.4683\n",
      "Epoch 22/149\n",
      "training Loss: 0.0000 Acc: 72.2630\n",
      "validation Loss: 0.0001 Acc: 78.2218\n",
      "Epoch 23/149\n",
      "training Loss: 0.0000 Acc: 73.3070\n",
      "validation Loss: 0.0000 Acc: 74.9551\n",
      "Epoch 24/149\n",
      "training Loss: 0.0000 Acc: 73.4344\n",
      "validation Loss: 0.0000 Acc: 73.0206\n",
      "Epoch 25/149\n",
      "training Loss: 0.0000 Acc: 72.8798\n",
      "validation Loss: 0.0000 Acc: 73.0206\n",
      "Epoch 26/149\n",
      "training Loss: 0.0000 Acc: 72.9218\n",
      "validation Loss: 0.0000 Acc: 73.5708\n",
      "Epoch 27/149\n",
      "training Loss: 0.0000 Acc: 72.9841\n",
      "validation Loss: 0.0000 Acc: 74.1790\n",
      "Epoch 28/149\n",
      "training Loss: 0.0000 Acc: 73.3562\n",
      "validation Loss: 0.0000 Acc: 72.4066\n",
      "Epoch 29/149\n",
      "training Loss: 0.0000 Acc: 72.7423\n",
      "validation Loss: 0.0001 Acc: 72.9974\n",
      "Epoch 30/149\n",
      "training Loss: 0.0000 Acc: 73.8239\n",
      "validation Loss: 0.0000 Acc: 72.2966\n",
      "Epoch 31/149\n",
      "training Loss: 0.0000 Acc: 73.2563\n",
      "validation Loss: 0.0000 Acc: 73.8083\n",
      "Epoch 32/149\n",
      "training Loss: 0.0000 Acc: 73.3794\n",
      "validation Loss: 0.0000 Acc: 73.6751\n",
      "Epoch 33/149\n",
      "training Loss: 0.0000 Acc: 73.3591\n",
      "validation Loss: 0.0000 Acc: 74.2369\n",
      "Epoch 34/149\n",
      "training Loss: 0.0000 Acc: 73.4445\n",
      "validation Loss: 0.0000 Acc: 73.8778\n",
      "Epoch 35/149\n",
      "training Loss: 0.0000 Acc: 73.2042\n",
      "validation Loss: 0.0000 Acc: 72.6151\n",
      "Epoch 36/149\n",
      "training Loss: 0.0000 Acc: 73.9195\n",
      "validation Loss: 0.0000 Acc: 72.9047\n",
      "Epoch 37/149\n",
      "training Loss: 0.0000 Acc: 73.1694\n",
      "validation Loss: 0.0000 Acc: 74.0052\n",
      "Epoch 38/149\n",
      "training Loss: 0.0000 Acc: 73.3866\n",
      "validation Loss: 0.0000 Acc: 74.3643\n",
      "Early stopped.\n",
      "Best val acc: 78.453522\n",
      "----------\n",
      "Epoch 0/149\n",
      "training Loss: 0.0001 Acc: 44.1003\n",
      "validation Loss: 0.0001 Acc: 75.8355\n",
      "Saving..\n",
      "Epoch 1/149\n",
      "training Loss: 0.0001 Acc: 66.2337\n",
      "validation Loss: 0.0001 Acc: 64.0544\n",
      "Epoch 2/149\n",
      "training Loss: 0.0001 Acc: 66.5088\n",
      "validation Loss: 0.0001 Acc: 68.9256\n",
      "Epoch 3/149\n",
      "training Loss: 0.0000 Acc: 68.0104\n",
      "validation Loss: 0.0001 Acc: 74.2543\n",
      "Epoch 4/149\n",
      "training Loss: 0.0000 Acc: 69.3135\n",
      "validation Loss: 0.0001 Acc: 73.2870\n",
      "Epoch 5/149\n",
      "training Loss: 0.0000 Acc: 69.7262\n",
      "validation Loss: 0.0001 Acc: 71.4741\n",
      "Epoch 6/149\n",
      "training Loss: 0.0000 Acc: 70.5399\n",
      "validation Loss: 0.0001 Acc: 68.9777\n",
      "Epoch 7/149\n",
      "training Loss: 0.0000 Acc: 70.2851\n",
      "validation Loss: 0.0001 Acc: 72.5630\n",
      "Epoch 8/149\n",
      "training Loss: 0.0000 Acc: 70.7832\n",
      "validation Loss: 0.0001 Acc: 68.4970\n",
      "Epoch 9/149\n",
      "training Loss: 0.0000 Acc: 70.2706\n",
      "validation Loss: 0.0001 Acc: 72.8873\n",
      "Epoch 10/149\n",
      "training Loss: 0.0000 Acc: 70.7065\n",
      "validation Loss: 0.0001 Acc: 76.2120\n",
      "Saving..\n",
      "Epoch 11/149\n",
      "training Loss: 0.0000 Acc: 70.7817\n",
      "validation Loss: 0.0000 Acc: 73.4839\n",
      "Epoch 12/149\n",
      "training Loss: 0.0000 Acc: 71.3725\n",
      "validation Loss: 0.0001 Acc: 68.7113\n",
      "Epoch 13/149\n",
      "training Loss: 0.0000 Acc: 71.4898\n",
      "validation Loss: 0.0001 Acc: 79.2876\n",
      "Saving..\n",
      "Epoch 14/149\n",
      "training Loss: 0.0000 Acc: 71.6302\n",
      "validation Loss: 0.0000 Acc: 72.9974\n",
      "Epoch 15/149\n",
      "training Loss: 0.0000 Acc: 71.5665\n",
      "validation Loss: 0.0000 Acc: 70.2520\n",
      "Epoch 16/149\n",
      "training Loss: 0.0000 Acc: 71.3537\n",
      "validation Loss: 0.0000 Acc: 74.4280\n",
      "Epoch 17/149\n",
      "training Loss: 0.0000 Acc: 71.6201\n",
      "validation Loss: 0.0001 Acc: 74.2253\n",
      "Epoch 18/149\n",
      "training Loss: 0.0000 Acc: 71.5854\n",
      "validation Loss: 0.0000 Acc: 74.4744\n",
      "Epoch 19/149\n",
      "training Loss: 0.0000 Acc: 71.9951\n",
      "validation Loss: 0.0000 Acc: 73.6577\n",
      "Epoch 20/149\n",
      "training Loss: 0.0000 Acc: 72.2891\n",
      "validation Loss: 0.0000 Acc: 72.9221\n",
      "Epoch 21/149\n",
      "training Loss: 0.0000 Acc: 72.1443\n",
      "validation Loss: 0.0000 Acc: 71.8390\n",
      "Epoch 22/149\n",
      "training Loss: 0.0000 Acc: 72.1139\n",
      "validation Loss: 0.0001 Acc: 72.0649\n",
      "Epoch 23/149\n",
      "training Loss: 0.0000 Acc: 72.0226\n",
      "validation Loss: 0.0000 Acc: 73.7735\n",
      "Epoch 24/149\n",
      "training Loss: 0.0000 Acc: 72.3817\n",
      "validation Loss: 0.0000 Acc: 70.8775\n",
      "Epoch 25/149\n",
      "training Loss: 0.0000 Acc: 72.4498\n",
      "validation Loss: 0.0000 Acc: 75.4532\n",
      "Epoch 26/149\n",
      "training Loss: 0.0000 Acc: 72.7365\n",
      "validation Loss: 0.0000 Acc: 68.7981\n",
      "Epoch 27/149\n",
      "training Loss: 0.0000 Acc: 72.0588\n",
      "validation Loss: 0.0000 Acc: 74.9262\n",
      "Epoch 28/149\n",
      "training Loss: 0.0000 Acc: 72.5714\n",
      "validation Loss: 0.0000 Acc: 71.8506\n",
      "Epoch 29/149\n",
      "training Loss: 0.0000 Acc: 72.6120\n",
      "validation Loss: 0.0000 Acc: 73.4376\n",
      "Epoch 30/149\n",
      "training Loss: 0.0000 Acc: 72.7857\n",
      "validation Loss: 0.0000 Acc: 70.9296\n",
      "Epoch 31/149\n",
      "training Loss: 0.0000 Acc: 71.8706\n",
      "validation Loss: 0.0000 Acc: 72.6093\n",
      "Epoch 32/149\n",
      "training Loss: 0.0000 Acc: 73.0130\n",
      "validation Loss: 0.0000 Acc: 74.6366\n",
      "Epoch 33/149\n",
      "training Loss: 0.0000 Acc: 72.6569\n",
      "validation Loss: 0.0000 Acc: 73.6171\n",
      "Epoch 34/149\n",
      "training Loss: 0.0000 Acc: 73.0739\n",
      "validation Loss: 0.0000 Acc: 72.7078\n",
      "Epoch 35/149\n",
      "training Loss: 0.0000 Acc: 72.3151\n",
      "validation Loss: 0.0000 Acc: 73.2001\n",
      "Epoch 36/149\n",
      "training Loss: 0.0000 Acc: 73.0333\n",
      "validation Loss: 0.0000 Acc: 72.3661\n",
      "Epoch 37/149\n",
      "training Loss: 0.0000 Acc: 72.8306\n",
      "validation Loss: 0.0000 Acc: 71.8795\n",
      "Epoch 38/149\n",
      "training Loss: 0.0000 Acc: 72.4614\n",
      "validation Loss: 0.0000 Acc: 74.0516\n",
      "Epoch 39/149\n",
      "training Loss: 0.0000 Acc: 72.8103\n",
      "validation Loss: 0.0000 Acc: 72.1923\n",
      "Epoch 40/149\n",
      "training Loss: 0.0000 Acc: 72.9117\n",
      "validation Loss: 0.0000 Acc: 72.7947\n",
      "Epoch 41/149\n",
      "training Loss: 0.0000 Acc: 73.0565\n",
      "validation Loss: 0.0000 Acc: 71.3814\n",
      "Epoch 42/149\n",
      "training Loss: 0.0000 Acc: 72.5193\n",
      "validation Loss: 0.0000 Acc: 73.2001\n",
      "Early stopped.\n",
      "Best val acc: 79.287575\n",
      "----------\n",
      "Average best_acc across k-fold: 76.8638687133789\n"
     ]
    }
   ],
   "source": [
    "CURRENT_TIME = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "\n",
    "if CRITERION == \"NLLLoss\":\n",
    "    train_weights = torch.FloatTensor(\n",
    "        [1.0, np.sum(data_aux.loc[label==0,'eventWeight']) / np.sum(data_aux.loc[label==1,'eventWeight'])]\n",
    "    ).cuda()\n",
    "    criterion = nn.NLLLoss(weight=train_weights)\n",
    "elif CRITERION == \"BCELoss\":\n",
    "    train_weights = torch.FloatTensor(data_aux.loc[:, \"eventWeight\"]).cuda()\n",
    "    criterion = nn.BCELoss(weight=train_weights)\n",
    "else:\n",
    "    raise Exception(f\"CRITERION must be either 'NLLLoss' or 'BCELoss'. You provided {CRITERION}.\")\n",
    "\n",
    "if OPTIMIZE_SPACE:\n",
    "    config_file = OUTPUT_DIRPATH + CURRENT_TIME + '_BestConfigReallyTopclass.json'\n",
    "    best_conf = optimize_hyperparams(\n",
    "        skf, data_list, data_hlf, label, \n",
    "        config_file, epochs=10,\n",
    "        criterion=criterion\n",
    "    )\n",
    "    print(best_conf)\n",
    "else:\n",
    "    # with open(OUTPUT_DIRPATH + CURRENT_TIME + '_BestConfigReallyTopclass.json') as f:\n",
    "    # with open('model_outputs/v0/BestConfigReallyTopclass.json', 'r') as f:\n",
    "    with open('/uscms/home/tsievert/nobackup/XHYbbgg/HHtobbyy/model_outputs/v4/extra_vars/2024-08-20_23-02-48_BestConfigReallyTopclass.json') as f:\n",
    "        best_conf = json.load(f)\n",
    "        print(best_conf)\n",
    "\n",
    "fom = []\n",
    "train_losses_arr, val_losses_arr = [], []\n",
    "for fold_idx, (train_index, val_index) in enumerate(skf.split(data_hlf, label)):\n",
    "    model_file = OUTPUT_DIRPATH + CURRENT_TIME +'_ReallyTopclassStyle_'+ f'{fold_idx}.torch'\n",
    "    state_file = OUTPUT_DIRPATH + CURRENT_TIME +'_BestPerfReallyTopclass_'+ f'{fold_idx}.torch'\n",
    "\n",
    "    if CRITERION == \"NLLLoss\":\n",
    "        rectified_train_index = np.ones(len(label), dtype=bool)\n",
    "        rectified_train_index[val_index] = False\n",
    "        sig_train_mask = rectified_train_index & (label == 1)\n",
    "        bkg_train_mask = rectified_train_index & (label == 0)\n",
    "        train_weights = torch.FloatTensor(\n",
    "            [1.0, np.sum(data_aux.loc[bkg_train_mask,'eventWeight']) / np.sum(data_aux.loc[sig_train_mask,'eventWeight'])]\n",
    "        ).cuda()\n",
    "        criterion = nn.NLLLoss(weight=train_weights)\n",
    "    elif CRITERION == \"BCELoss\":\n",
    "        train_weights = torch.FloatTensor((data_aux.iloc[train_index]).loc[:, \"eventWeight\"]).cuda()\n",
    "        criterion = nn.BCELoss(weight=train_weights)\n",
    "        \n",
    "    model = InclusiveNetwork(\n",
    "        best_conf['hidden_layers'], best_conf['initial_nodes'], best_conf['dropout'], \n",
    "        best_conf['gru_layers'], best_conf['gru_size'], best_conf['dropout_g'], \n",
    "        dnn_input=np.shape(data_hlf)[-1], rnn_input=np.shape(data_list)[-1]\n",
    "    ).cuda()\n",
    "    optimizer = AMSGrad(model.parameters(), lr=best_conf['learning_rate'], weight_decay=best_conf['L2_reg'])\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        ParticleHLF(data_list[train_index], data_hlf[train_index], label[train_index]), \n",
    "        batch_size=best_conf['batch_size'], shuffle=True\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        ParticleHLF(data_list[val_index], data_hlf[val_index], label[val_index]), \n",
    "        batch_size=best_conf['batch_size'], shuffle=True\n",
    "    )\n",
    "    data_loader = {\"training\": train_loader, \"validation\": val_loader} \n",
    "\n",
    "    best_acc, train_losses, val_losses = train(\n",
    "        NUM_EPOCHS, model, criterion, optimizer, scheduler, \n",
    "        state_file, model_file, data_loader=data_loader\n",
    "    )\n",
    "    train_losses_arr.append(train_losses)\n",
    "    val_losses_arr.append(val_losses)\n",
    "\n",
    "    fom.append(best_acc)\n",
    "\n",
    "Y = np.mean(np.asarray([acc.cpu() for acc in fom]))\n",
    "print(\"Average best_acc across k-fold: {}\".format(Y))\n",
    "model = InclusiveNetwork(\n",
    "    best_conf['hidden_layers'], best_conf['initial_nodes'], best_conf['dropout'], \n",
    "    best_conf['gru_layers'], best_conf['gru_size'], best_conf['dropout_g']\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ROC.\n"
     ]
    }
   ],
   "source": [
    "# with open('model_outputs/v0/BestConfigReallyTopclass.json', 'r') as f:\n",
    "# with open(OUTPUT_DIRPATH + CURRENT_TIME + '_BestConfigReallyTopclass.json') as f:\n",
    "with open('/uscms/home/tsievert/nobackup/XHYbbgg/HHtobbyy/model_outputs/v4/extra_vars/2024-08-20_23-02-48_BestConfigReallyTopclass.json') as f:\n",
    "    best_conf = json.load(f)\n",
    "try:\n",
    "    IN_perf = evaluate(\n",
    "        data_list_test, data_hlf_test, label_test, \n",
    "        OUTPUT_DIRPATH, CURRENT_TIME, skf, best_conf, \n",
    "        train_losses_arr=train_losses_arr, val_losses_arr=val_losses_arr, \n",
    "        save=True\n",
    "    )\n",
    "except:\n",
    "    IN_perf = evaluate(\n",
    "        data_list_test, data_hlf_test, label_test, \n",
    "        OUTPUT_DIRPATH, CURRENT_TIME, skf, best_conf, \n",
    "        save=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train/Val Loss curves, ROC curves, and Output Score Dist for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network performance\n",
      "+-----------+-------------------+--------------------------+\n",
      "| Threshold | Signal Efficiency | Background Contamination |\n",
      "+-----------+-------------------+--------------------------+\n",
      "|   0.4400  |       0.9706      |    0.3668 +/- 0.0211     |\n",
      "|   0.5705  |       0.9500      |    0.2706 +/- 0.0199     |\n",
      "|   0.6935  |       0.9198      |    0.1908 +/- 0.0157     |\n",
      "|   0.9349  |       0.7538      |    0.0491 +/- 0.0049     |\n",
      "|   0.9799  |       0.5777      |    0.0151 +/- 0.0019     |\n",
      "|   0.9931  |       0.3839      |    0.0041 +/- 0.0007     |\n",
      "+-----------+-------------------+--------------------------+\n"
     ]
    }
   ],
   "source": [
    "with open(OUTPUT_DIRPATH + f'{CURRENT_TIME}_IN_perf.json', 'r') as f:\n",
    "    IN_perf = json.load(f)\n",
    "\n",
    "TPR_thresholds = [0.9704, 0.9498, 0.9196, 0.7536, 0.5777, 0.3837]\n",
    "print(\"Neural network performance\")\n",
    "NNtable = PrettyTable(['Threshold','Signal Efficiency','Background Contamination'])\n",
    "NNtable.float_format = \".4\"\n",
    "for TPR_threshold in TPR_thresholds:\n",
    "    thres_idx = np.argmax(np.array(IN_perf['base_tpr'])>TPR_threshold)\n",
    "    NNtable.add_row(\n",
    "        [\n",
    "            IN_perf['mean_thresholds'][thres_idx], IN_perf['base_tpr'][thres_idx], \n",
    "            \"{:.4f} +/- {:.4f}\".format(IN_perf['mean_fprs'][thres_idx], IN_perf['std_fprs'][thres_idx])\n",
    "        ]\n",
    "    )\n",
    "print(NNtable)\n",
    "\n",
    "plot_destdir = OUTPUT_DIRPATH + 'plots'\n",
    "if not os.path.exists(plot_destdir):\n",
    "    os.makedirs(plot_destdir)\n",
    "\n",
    "plot_train_val_losses(\n",
    "    IN_perf, plot_destdir+'/'+CURRENT_TIME, plot_postfix='_test_data',\n",
    "    labels=[str(i) for i in range(len(IN_perf['all_preds']))]\n",
    ")\n",
    "plot_roc(\n",
    "    IN_perf, plot_destdir+'/'+CURRENT_TIME, plot_postfix='_test_data', method='arr',\n",
    "    labels=[str(i) for i in range(len(IN_perf['all_preds']))]\n",
    ")\n",
    "plot_output_score(\n",
    "    IN_perf, plot_destdir+'/'+CURRENT_TIME, plot_postfix='_test_data_weighted', \n",
    "    labels=[str(i) for i in range(len(IN_perf['all_preds']))], weights={\n",
    "        'bkg': data_test_aux.loc[label_test==0, \"eventWeight\"], 'sig': data_test_aux.loc[label_test==1, \"eventWeight\"]\n",
    "    }, n_bins=25\n",
    ")\n",
    "plot_output_score(\n",
    "    IN_perf, plot_destdir+'/'+CURRENT_TIME, plot_postfix='_test_data_density', \n",
    "    labels=[str(i) for i in range(len(IN_perf['all_preds']))], n_bins=25\n",
    ")\n",
    "s_over_root_b(\n",
    "    IN_perf, plot_destdir+'/'+CURRENT_TIME, plot_postfix='_test_data', \n",
    "    labels=[str(i) for i in range(len(IN_perf['all_preds']))], weights={\n",
    "        'bkg': data_test_aux.loc[label_test==0, \"eventWeight\"], 'sig': data_test_aux.loc[label_test==1, \"eventWeight\"]\n",
    "    }, n_bins=25\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Optimized cut-boundaries for ttH score output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_cut_boundaries(IN_perf, weights, bins=50):\n",
    "    hist_list_fold = []\n",
    "    cut_boundaries_fold = []\n",
    "    cut_s_over_root_bs_fold = []\n",
    "    sig_weights_fold = []\n",
    "    bkg_weights_fold = []\n",
    "    for fold_idx in range(skf.get_n_splits()):\n",
    "        sig_np = np.exp(\n",
    "            IN_perf['all_preds'][fold_idx]\n",
    "        )[\n",
    "            np.array(IN_perf['all_labels'][fold_idx]) == 1,1\n",
    "        ]\n",
    "        bkg_np = np.exp(\n",
    "            IN_perf['all_preds'][fold_idx]\n",
    "        )[\n",
    "            np.array(IN_perf['all_labels'][fold_idx]) == 0,1\n",
    "        ]\n",
    "        hist_axis = hist.axis.Regular(bins, 0., 1., name='var', growth=False, underflow=False, overflow=False)\n",
    "        sig_hist = hist.Hist(hist_axis, storage='weight').fill(var=sig_np, weight=weights['sig'])\n",
    "        bkg_hist = hist.Hist(hist_axis, storage='weight').fill(var=bkg_np, weight=weights['bkg'])\n",
    "        hist_list_fold.append({'sig': copy.deepcopy(sig_hist), 'bkg': copy.deepcopy(bkg_hist)})\n",
    "\n",
    "        fold_idx_cuts_bins_inclusive = []\n",
    "        fold_idx_sig_weights = []\n",
    "        fold_idx_bkg_weights = []\n",
    "        fold_idx_prev_s_over_root_b = []\n",
    "        prev_s_over_root_b = 0\n",
    "        for i in range(bins):\n",
    "            s = np.sum(sig_hist.values().flatten()[\n",
    "                (bins-1) - i : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "            ])\n",
    "            sqrt_b = np.sqrt(np.sum(bkg_hist.values().flatten()[\n",
    "                (bins-1) - i : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "            ]))\n",
    "            if prev_s_over_root_b < (s / sqrt_b):\n",
    "                prev_s_over_root_b = s / sqrt_b\n",
    "                continue\n",
    "            else:\n",
    "                fold_idx_sig_weights.append(\n",
    "                    {\n",
    "                        'value': np.sum(sig_hist.values().flatten()[\n",
    "                            (bins) - i : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                        ]),\n",
    "                        'w2': np.sqrt(np.sum(sig_hist.variances().flatten()[\n",
    "                            (bins) - i : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                        ])),\n",
    "                    }\n",
    "                )\n",
    "                fold_idx_bkg_weights.append(\n",
    "                    {\n",
    "                        'value': np.sum(bkg_hist.values().flatten()[\n",
    "                            (bins) - i : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                        ]),\n",
    "                        'w2': np.sqrt(np.sum(bkg_hist.variances().flatten()[\n",
    "                            (bins) - i : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                        ])),\n",
    "                    }\n",
    "                )\n",
    "                fold_idx_cuts_bins_inclusive.append(bins - i)\n",
    "                fold_idx_prev_s_over_root_b.append(prev_s_over_root_b)\n",
    "                prev_s_over_root_b = 0\n",
    "        fold_idx_sig_weights.append(\n",
    "            {\n",
    "                'value': np.sum(sig_hist.values().flatten()[\n",
    "                    0 : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                ]),\n",
    "                'w2': np.sqrt(np.sum(sig_hist.variances().flatten()[\n",
    "                    0 : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                ])),\n",
    "            }\n",
    "        )\n",
    "        fold_idx_bkg_weights.append(\n",
    "            {\n",
    "                'value': np.sum(bkg_hist.values().flatten()[\n",
    "                    0 : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                ]),\n",
    "                'w2': np.sqrt(np.sum(bkg_hist.variances().flatten()[\n",
    "                    0 : bins if len(fold_idx_cuts_bins_inclusive) == 0 else fold_idx_cuts_bins_inclusive[-1]\n",
    "                ])),\n",
    "            }\n",
    "        )\n",
    "        fold_idx_cuts_bins_inclusive.append(0)\n",
    "        fold_idx_prev_s_over_root_b.append(prev_s_over_root_b)\n",
    "        fold_idx_score_cuts = [bin_i / bins for bin_i in fold_idx_cuts_bins_inclusive]\n",
    "        cut_boundaries_fold.append(fold_idx_score_cuts)\n",
    "        cut_s_over_root_bs_fold.append(fold_idx_prev_s_over_root_b)\n",
    "        sig_weights_fold.append(fold_idx_sig_weights)\n",
    "        bkg_weights_fold.append(fold_idx_bkg_weights)\n",
    "                \n",
    "    sig_np = np.exp(\n",
    "        IN_perf['mean_pred']\n",
    "    )[\n",
    "        np.array(IN_perf['mean_label']) == 1,1\n",
    "    ]\n",
    "    bkg_np = np.exp(\n",
    "        IN_perf['mean_pred']\n",
    "    )[\n",
    "        np.array(IN_perf['mean_label']) == 0,1\n",
    "    ]\n",
    "    hist_axis = hist.axis.Regular(bins, 0., 1., name='var', growth=False, underflow=False, overflow=False)\n",
    "    sig_hist = hist.Hist(hist_axis, storage='weight').fill(var=sig_np, weight=weights['sig'])\n",
    "    bkg_hist = hist.Hist(hist_axis, storage='weight').fill(var=bkg_np, weight=weights['bkg'])\n",
    "\n",
    "    cut_boundaries = []\n",
    "    cut_s_over_root_bs = []\n",
    "    prev_s_over_root_b = 0\n",
    "    sig_weights = []\n",
    "    bkg_weights = []\n",
    "    for i in range(bins):\n",
    "        s = np.sum(sig_hist.values().flatten()[\n",
    "            (bins-1) - i : bins if len(cut_boundaries) == 0 else cut_boundaries[-1]\n",
    "        ])\n",
    "        sqrt_b = np.sqrt(np.sum(bkg_hist.values().flatten()[\n",
    "            (bins-1) - i : bins if len(cut_boundaries) == 0 else cut_boundaries[-1]\n",
    "        ]))\n",
    "        if prev_s_over_root_b < (s / sqrt_b):\n",
    "            prev_s_over_root_b = s / sqrt_b\n",
    "            continue\n",
    "        else:\n",
    "            sig_weights.append(\n",
    "                {\n",
    "                    'value': np.sqrt(np.sum(sig_hist.values().flatten()[\n",
    "                        (bins) - i : bins if len(cut_boundaries) == 0 else cut_boundaries[-1]\n",
    "                    ])),\n",
    "                    'w2': np.sqrt(np.sum(sig_hist.variances().flatten()[\n",
    "                        (bins) - i : bins if len(cut_boundaries) == 0 else cut_boundaries[-1]\n",
    "                    ])),\n",
    "                }\n",
    "            )\n",
    "            bkg_weights.append(\n",
    "                {\n",
    "                    'value': np.sqrt(np.sum(bkg_hist.values().flatten()[\n",
    "                        (bins) - i : bins if len(cut_boundaries) == 0 else cut_boundaries[-1]\n",
    "                    ])),\n",
    "                    'w2': np.sqrt(np.sum(bkg_hist.variances().flatten()[\n",
    "                        (bins) - i : bins if len(cut_boundaries) == 0 else cut_boundaries[-1]\n",
    "                    ])),\n",
    "                }\n",
    "            )\n",
    "            cut_boundaries.append(bins - i)\n",
    "            cut_s_over_root_bs.append(prev_s_over_root_b)\n",
    "            prev_s_over_root_b = 0\n",
    "    sig_weights.append(\n",
    "        {\n",
    "            'value': np.sum(sig_hist.values().flatten()[\n",
    "                0 : bins if len(cut_boundaries) == 0 else cut_boundaries[-1]\n",
    "            ]),\n",
    "            'w2': np.sqrt(np.sum(sig_hist.variances().flatten()[\n",
    "                0 : bins if len(cut_boundaries) == 0 else cut_boundaries[-1]\n",
    "            ])),\n",
    "        }\n",
    "    )\n",
    "    bkg_weights.append(\n",
    "        {\n",
    "            'value': np.sum(bkg_hist.values().flatten()[\n",
    "                0 : bins if len(cut_boundaries) == 0 else cut_boundaries[-1]\n",
    "            ]),\n",
    "            'w2': np.sqrt(np.sum(bkg_hist.variances().flatten()[\n",
    "                0 : bins if len(cut_boundaries) == 0 else cut_boundaries[-1]\n",
    "            ])),\n",
    "        }\n",
    "    )\n",
    "    cut_boundaries.append(0)\n",
    "    cut_s_over_root_bs.append(prev_s_over_root_b)\n",
    "    cut_boundaries = [bin_i / bins for bin_i in cut_boundaries]\n",
    "    return cut_boundaries_fold, cut_s_over_root_bs_fold, sig_weights_fold, bkg_weights_fold, cut_boundaries, cut_s_over_root_bs, sig_weights, bkg_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(OUTPUT_DIRPATH + f'{CURRENT_TIME}_IN_perf.json', 'r') as f:\n",
    "    IN_perf = json.load(f)\n",
    "\n",
    "(\n",
    "    cut_boundaries_fold, cut_s_over_root_bs_fold, \n",
    "    sig_weights_fold, bkg_weights_fold, \n",
    "    cut_boundaries, cut_s_over_root_bs, \n",
    "    sig_weights, bkg_weights \n",
    ") = optimize_cut_boundaries(\n",
    "    IN_perf, {\n",
    "        'bkg': data_test_aux.loc[label_test==0, \"eventWeight\"], 'sig': data_test_aux.loc[label_test==1, \"eventWeight\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "fold_labels = [\n",
    "    [\n",
    "        f\"s/âb={cut_s_over_root_bs_fold[fold_idx][cut_idx]:.04f}, s={sig_weights_fold[fold_idx][cut_idx]['value']:.04f}Â±{sig_weights_fold[fold_idx][cut_idx]['w2']:.04f}, b={bkg_weights_fold[fold_idx][cut_idx]['value']:.04f}Â±{bkg_weights_fold[fold_idx][cut_idx]['w2']:.04f}\" for cut_idx in range(len(cut_s_over_root_bs_fold[fold_idx]))\n",
    "    ] for fold_idx in range(skf.get_n_splits())\n",
    "]\n",
    "fold_colors = [copy.deepcopy(cmap_petroff10 * ((len(cut_boundaries_fold[i]) // len(cmap_petroff10)) + 1)) for i in range(skf.get_n_splits())]\n",
    "for fold_idx in range(skf.get_n_splits()):\n",
    "    s_over_root_b(\n",
    "        IN_perf, plot_destdir+'/'+CURRENT_TIME, plot_postfix=f'_test_data_fold{fold_idx}', \n",
    "        labels=[str(i) for i in range(len(IN_perf['all_preds']))], weights={\n",
    "            'bkg': data_test_aux.loc[label_test==0, \"eventWeight\"], 'sig': data_test_aux.loc[label_test==1, \"eventWeight\"]\n",
    "        }, lines_fold=cut_boundaries_fold, lines_labels=fold_labels, only_fold=fold_idx, lines_colors=fold_colors\n",
    "    )\n",
    "labels = [\n",
    "    f\"s/âb={cut_s_over_root_bs[cut_idx]:.04f}, s={sig_weights[cut_idx]['value']:.04f}Â±{sig_weights[cut_idx]['w2']:.04f}, b={bkg_weights[cut_idx]['value']:.04f}Â±{bkg_weights[cut_idx]['w2']:.04f}\" for cut_idx in range(len(cut_s_over_root_bs))\n",
    "]\n",
    "colors = copy.deepcopy(cmap_petroff10 * ((len(cut_boundaries) // len(cmap_petroff10)) + 1))\n",
    "s_over_root_b(\n",
    "    IN_perf, plot_destdir+'/'+CURRENT_TIME, plot_postfix=f'_test_data_foldAvg', \n",
    "    labels=[str(i) for i in range(len(IN_perf['all_preds']))], weights={\n",
    "        'bkg': data_test_aux.loc[label_test==0, \"eventWeight\"], 'sig': data_test_aux.loc[label_test==1, \"eventWeight\"]\n",
    "    }, lines=cut_boundaries, lines_labels=labels, no_fold=True, lines_colors=colors\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Val Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_perf_dict = {'train': [], 'val': []}\n",
    "# with open('model_outputs/v0/BestConfigReallyTopclass.json', 'r') as f:\n",
    "# with open(OUTPUT_DIRPATH + CURRENT_TIME + '_BestConfigReallyTopclass.json') as f:\n",
    "with open('/uscms/home/tsievert/nobackup/XHYbbgg/HHtobbyy/model_outputs/v4/extra_vars/2024-08-20_23-02-48_BestConfigReallyTopclass.json') as f:\n",
    "    best_conf = json.load(f)\n",
    "for fold_idx, (train_index, val_index) in enumerate(skf.split(data_hlf, label)):\n",
    "    IN_perf_dict['train'].append(\n",
    "        evaluate(\n",
    "            data_list[train_index], data_hlf[train_index], label[train_index], \n",
    "            OUTPUT_DIRPATH, CURRENT_TIME, skf, best_conf, only_fold_idx=fold_idx,\n",
    "        )\n",
    "    )\n",
    "    IN_perf_dict['val'].append(\n",
    "        evaluate(\n",
    "            data_list[val_index], data_hlf[val_index], label[val_index], \n",
    "            OUTPUT_DIRPATH, CURRENT_TIME, skf, best_conf, only_fold_idx=fold_idx,\n",
    "        )\n",
    "    )\n",
    "\n",
    "with open(OUTPUT_DIRPATH + f'{CURRENT_TIME}_IN_perf_train_val.json', 'w') as f:\n",
    "    json.dump(IN_perf_dict, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ROC and Output Score Dist for train/val data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/uscms/home/tsievert/nobackup/miniconda3/envs/higgs-dna-hhbbgg/lib/python3.10/site-packages/mplhep/utils.py:194: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return values - np.sqrt(values), values + np.sqrt(values)\n"
     ]
    }
   ],
   "source": [
    "plot_destdir = OUTPUT_DIRPATH + 'plots'\n",
    "if not os.path.exists(plot_destdir):\n",
    "    os.makedirs(plot_destdir)\n",
    "with open(OUTPUT_DIRPATH + f'{CURRENT_TIME}_IN_perf_train_val.json', 'r') as f:\n",
    "    IN_perf_dict = json.load(f)\n",
    "\n",
    "labels_arr = ['train - fold ', 'val - fold ']\n",
    "val_weights_arr = []\n",
    "for fold_idx, (train_IN_dict, val_IN_dict, (train_index, val_index)) in enumerate(zip(IN_perf_dict['train'], IN_perf_dict['val'], skf.split(data_hlf, label))):\n",
    "    plot_roc(\n",
    "        [train_IN_dict, val_IN_dict], plot_destdir+'/'+CURRENT_TIME, plot_postfix=f'_train_val_comparison_fold{fold_idx}', \n",
    "        method='IN_arr', labels=[labels_arr[0]+str(fold_idx), labels_arr[1]+str(fold_idx)]\n",
    "    )\n",
    "    rectified_train_index = np.ones(len(label), dtype=bool)\n",
    "    rectified_train_index[val_index] = False\n",
    "    sig_train_mask = rectified_train_index & (label == 1)\n",
    "    sig_val_mask = np.logical_not(rectified_train_index) & (label == 1)\n",
    "    bkg_train_mask = rectified_train_index & (label == 0)\n",
    "    bkg_val_mask = np.logical_not(rectified_train_index) & (label == 0)\n",
    "    weights = [\n",
    "        {'sig': data_aux.loc[sig_train_mask, \"eventWeight\"], 'bkg': data_aux.loc[bkg_train_mask, \"eventWeight\"]},\n",
    "        {'sig': data_aux.loc[sig_val_mask, \"eventWeight\"], 'bkg': data_aux.loc[bkg_val_mask, \"eventWeight\"]}\n",
    "    ]\n",
    "    val_weights_arr.append(copy.deepcopy(weights[1]))\n",
    "    plot_output_score(\n",
    "        [train_IN_dict, val_IN_dict], plot_destdir+'/'+CURRENT_TIME, plot_postfix=f'_train_val_weighted_comparison{fold_idx}', \n",
    "        method='IN_arr', labels=[labels_arr[0]+str(fold_idx), labels_arr[1]+str(fold_idx)], weights=weights\n",
    "    )\n",
    "    plot_output_score(\n",
    "        [train_IN_dict, val_IN_dict], plot_destdir+'/'+CURRENT_TIME, plot_postfix=f'_train_val_density_comparison{fold_idx}', \n",
    "        method='IN_arr', labels=[labels_arr[0]+str(fold_idx), labels_arr[1]+str(fold_idx)], weights=[{'sig': None, 'bkg': None}]*len(labels_arr)\n",
    "    )\n",
    "    s_over_root_b(\n",
    "        [train_IN_dict, val_IN_dict], plot_destdir+'/'+CURRENT_TIME, plot_postfix=f'_train_val_comparison{fold_idx}', \n",
    "        method='IN_arr', labels=[labels_arr[0]+str(fold_idx), labels_arr[1]+str(fold_idx)], weights=weights\n",
    "    )\n",
    "labels_arr = ['val - fold 0', 'val - fold 1', 'val - fold 2', 'val - fold 3', 'val - fold 4']\n",
    "s_over_root_b(\n",
    "    IN_perf_dict['val'], plot_destdir+'/'+CURRENT_TIME, plot_postfix=f'_val_comparison', \n",
    "    method='IN_arr', labels=labels_arr, weights=val_weights_arr\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Vars Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### pre-standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir_pre_std = CURRENT_DIRPATH + f\"/input_comparison{'_v2' if V2_MERGED else ''}/{VERSION}/pre_std/\"\n",
    "if not os.path.exists(output_dir_pre_std):\n",
    "    os.makedirs(output_dir_pre_std)\n",
    "\n",
    "pre_std_hists = {}\n",
    "label_arr = [\n",
    "    MC_NAMES_PRETTY[\"GluGluToHH\"]+\" train\", MC_NAMES_PRETTY[\"GluGluToHH\"]+\" test\",\n",
    "    MC_NAMES_PRETTY[\"ttHToGG\"]+\" train\", MC_NAMES_PRETTY[\"ttHToGG\"]+\" test\"\n",
    "]\n",
    "label_arr_fold = [\n",
    "    MC_NAMES_PRETTY[\"GluGluToHH\"]+\" train\", MC_NAMES_PRETTY[\"GluGluToHH\"]+\" val\", MC_NAMES_PRETTY[\"GluGluToHH\"]+\" test\",\n",
    "    MC_NAMES_PRETTY[\"ttHToGG\"]+\" train\", MC_NAMES_PRETTY[\"ttHToGG\"]+\" val\", MC_NAMES_PRETTY[\"ttHToGG\"]+\" test\"\n",
    "]\n",
    "for var_name in high_level_fields:\n",
    "    if var_name in {'event', 'puppiMET_eta'}:\n",
    "        continue\n",
    "    sig_mask = (label == 1)\n",
    "    sig_test_mask = (label_test == 1)\n",
    "    bkg_mask = (label == 0)\n",
    "    bkg_test_mask = (label_test == 0)\n",
    "    for fold_idx, (train_index, val_index) in enumerate(skf.split(data_hlf, label)):\n",
    "        rectified_train_index = np.ones(len(label), dtype=bool)\n",
    "        rectified_train_index[val_index] = False\n",
    "        \n",
    "        sig_train_mask = rectified_train_index & sig_mask\n",
    "        sig_val_mask = np.logical_not(rectified_train_index) & sig_mask\n",
    "        bkg_train_mask = rectified_train_index & bkg_mask\n",
    "        bkg_val_mask = np.logical_not(rectified_train_index) & bkg_mask\n",
    "\n",
    "        sig_train_np = data_df.loc[sig_train_mask, var_name].to_numpy()\n",
    "        sig_val_np = data_df.loc[sig_val_mask, var_name].to_numpy()\n",
    "        sig_test_np = data_test_df.loc[sig_test_mask, var_name].to_numpy()\n",
    "        bkg_train_np = data_df.loc[bkg_train_mask, var_name].to_numpy()\n",
    "        bkg_val_np = data_df.loc[bkg_val_mask, var_name].to_numpy()\n",
    "        bkg_test_np = data_test_df.loc[bkg_test_mask, var_name].to_numpy()\n",
    "\n",
    "        sig_train_hist = hist.Hist(VARIABLES[var_name]).fill(var=sig_train_np[sig_train_np != 0])\n",
    "        sig_val_hist = hist.Hist(VARIABLES[var_name]).fill(var=sig_val_np[sig_val_np != 0])\n",
    "        sig_test_hist = hist.Hist(VARIABLES[var_name]).fill(var=sig_test_np[sig_test_np != 0])\n",
    "        bkg_train_hist = hist.Hist(VARIABLES[var_name]).fill(var=bkg_train_np[bkg_train_np != 0])\n",
    "        bkg_val_hist = hist.Hist(VARIABLES[var_name]).fill(var=bkg_val_np[bkg_val_np != 0])\n",
    "        bkg_test_hist = hist.Hist(VARIABLES[var_name]).fill(var=bkg_test_np[bkg_test_np != 0])\n",
    "\n",
    "        make_input_plot(\n",
    "            output_dir_pre_std, var_name, \n",
    "            [sig_train_hist, sig_val_hist, sig_test_hist, bkg_train_hist, bkg_val_hist, bkg_test_hist], \n",
    "            fold_idx=fold_idx, labels=label_arr_fold\n",
    "        )\n",
    "    sig_train_np = data_df.loc[sig_mask, var_name].to_numpy()\n",
    "    sig_test_np = data_test_df.loc[sig_test_mask, var_name].to_numpy()\n",
    "    bkg_train_np = data_df.loc[bkg_mask, var_name].to_numpy()\n",
    "    bkg_test_np = data_test_df.loc[bkg_test_mask, var_name].to_numpy()\n",
    "    sig_train_hist = hist.Hist(VARIABLES[var_name]).fill(var=sig_train_np[sig_train_np != 0])\n",
    "    sig_test_hist = hist.Hist(VARIABLES[var_name]).fill(var=sig_test_np[sig_test_np != 0])\n",
    "    bkg_train_hist = hist.Hist(VARIABLES[var_name]).fill(var=bkg_train_np[bkg_train_np != 0])\n",
    "    bkg_test_hist = hist.Hist(VARIABLES[var_name]).fill(var=bkg_test_np[bkg_test_np != 0])\n",
    "    pre_std_hists[var_name] = [\n",
    "        copy.deepcopy(sig_train_hist), copy.deepcopy(sig_test_hist), \n",
    "        copy.deepcopy(bkg_train_hist), copy.deepcopy(bkg_test_hist)\n",
    "    ]\n",
    "    make_input_plot(output_dir_pre_std, var_name, pre_std_hists[var_name], labels=label_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### post-standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir_post_std = CURRENT_DIRPATH + f\"/input_comparison{'_v2' if V2_MERGED else ''}/{VERSION}/post_std/\"\n",
    "if not os.path.exists(output_dir_post_std):\n",
    "    os.makedirs(output_dir_post_std)\n",
    "\n",
    "post_std_hists = {}\n",
    "label_arr = [\n",
    "    MC_NAMES_PRETTY[\"GluGluToHH\"]+\" train\", MC_NAMES_PRETTY[\"GluGluToHH\"]+\" test\",\n",
    "    MC_NAMES_PRETTY[\"ttHToGG\"]+\" train\", MC_NAMES_PRETTY[\"ttHToGG\"]+\" test\"\n",
    "]\n",
    "label_arr_fold = [\n",
    "    MC_NAMES_PRETTY[\"GluGluToHH\"]+\" train\", MC_NAMES_PRETTY[\"GluGluToHH\"]+\" val\", MC_NAMES_PRETTY[\"GluGluToHH\"]+\" test\",\n",
    "    MC_NAMES_PRETTY[\"ttHToGG\"]+\" train\", MC_NAMES_PRETTY[\"ttHToGG\"]+\" val\", MC_NAMES_PRETTY[\"ttHToGG\"]+\" test\"\n",
    "]\n",
    "for var_name in high_level_fields:\n",
    "    if var_name in {'event', 'puppiMET_eta'}:\n",
    "        continue\n",
    "    data, data_test = None, None\n",
    "    if var_name in (high_level_fields - set(input_hlf_vars)):\n",
    "        data, data_test = data_list, data_list_test\n",
    "    else:\n",
    "        data, data_test = data_hlf, data_hlf_test\n",
    "    for fold_idx, (train_index, val_index) in enumerate(skf.split(data_hlf, label)):\n",
    "        rectified_train_index = np.ones(len(label), dtype=bool)\n",
    "        rectified_train_index[val_index] = False\n",
    "        (\n",
    "            sig_train_np, sig_val_np, sig_test_np, \n",
    "            bkg_train_np, bkg_val_np, bkg_test_np \n",
    "        ) = post_std_np_arrays(\n",
    "            data, data_test, var_name,\n",
    "            train_index=rectified_train_index, val_index=np.logical_not(rectified_train_index)\n",
    "        )\n",
    "        sig_train_hist = hist.Hist(VARIABLES_STD[var_name]).fill(var=sig_train_np[sig_train_np != 0])\n",
    "        sig_val_hist = hist.Hist(VARIABLES_STD[var_name]).fill(var=sig_val_np[sig_val_np != 0])\n",
    "        sig_test_hist = hist.Hist(VARIABLES_STD[var_name]).fill(var=sig_test_np[sig_test_np != 0])\n",
    "        bkg_train_hist = hist.Hist(VARIABLES_STD[var_name]).fill(var=bkg_train_np[bkg_train_np != 0])\n",
    "        bkg_val_hist = hist.Hist(VARIABLES_STD[var_name]).fill(var=bkg_val_np[bkg_val_np != 0])\n",
    "        bkg_test_hist = hist.Hist(VARIABLES_STD[var_name]).fill(var=bkg_test_np[bkg_test_np != 0])\n",
    "\n",
    "        make_input_plot(\n",
    "            output_dir_post_std, var_name, \n",
    "            [sig_train_hist, sig_val_hist, sig_test_hist, bkg_train_hist, bkg_val_hist, bkg_test_hist], \n",
    "            fold_idx=fold_idx, labels=label_arr_fold\n",
    "        )\n",
    "    sig_train_np, sig_test_np, bkg_train_np, bkg_test_np = post_std_np_arrays(data, data_test, var_name)\n",
    "\n",
    "    sig_train_hist = hist.Hist(VARIABLES_STD[var_name]).fill(var=sig_train_np[sig_train_np != 0])\n",
    "    sig_test_hist = hist.Hist(VARIABLES_STD[var_name]).fill(var=sig_test_np[sig_test_np != 0])\n",
    "    bkg_train_hist = hist.Hist(VARIABLES_STD[var_name]).fill(var=bkg_train_np[bkg_train_np != 0])\n",
    "    bkg_test_hist = hist.Hist(VARIABLES_STD[var_name]).fill(var=bkg_test_np[bkg_test_np != 0])\n",
    "    post_std_hists[var_name] = [\n",
    "        copy.deepcopy(sig_train_hist), copy.deepcopy(sig_test_hist), \n",
    "        copy.deepcopy(bkg_train_hist), copy.deepcopy(bkg_test_hist)\n",
    "    ]\n",
    "    make_input_plot(output_dir_post_std, var_name, post_std_hists[var_name], labels=label_arr)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian smearing on test set (for feature importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Functions to smear variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smear_particle_list(var_name, particle_list_to_smear, method='multiply', seed=SEED):\n",
    "    index2, index3 = data_list_index_map(var_name)\n",
    "\n",
    "    # Performs the smearing and returns the result\n",
    "    rng = np.random.default_rng(seed=seed)\n",
    "    if method == 'multiply':\n",
    "        particle_list_to_smear[:, index2, index3] *= rng.normal(size=len(particle_list_to_smear))\n",
    "    elif method == 'add':\n",
    "        particle_list_to_smear[:, index2, index3] += rng.normal(size=len(particle_list_to_smear))\n",
    "    else:\n",
    "        raise Exception(f\"Only 'multiply' and 'add' are allowed as methods. You passed {method}.\")\n",
    "\n",
    "    return particle_list_to_smear\n",
    "\n",
    "\n",
    "def smear_particle_hlf(var_name, particle_hlf_to_smear, method='multiply', seed=SEED):\n",
    "    index2 = hlf_vars_columns[var_name]\n",
    "    rng = np.random.default_rng(seed=seed)\n",
    "    if method == 'multiply':\n",
    "        particle_hlf_to_smear[:, index2] *= rng.normal(size=len(particle_hlf_to_smear))\n",
    "    elif method == 'add':\n",
    "        particle_hlf_to_smear[:, index2] += rng.normal(size=len(particle_hlf_to_smear))\n",
    "    else:\n",
    "        raise Exception(f\"Only 'multiply' and 'add' are allowed as methods. You passed {method}.\")\n",
    "    \n",
    "    return particle_hlf_to_smear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluate smeared variable test-data on the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_perf_smear_dict = {}\n",
    "# with open('model_outputs/v0/BestConfigReallyTopclass.json', 'r') as f:\n",
    "# with open(OUTPUT_DIRPATH + CURRENT_TIME + '_BestConfigReallyTopclass.json') as f:\n",
    "with open('/uscms/home/tsievert/nobackup/XHYbbgg/HHtobbyy/model_outputs/v4/extra_vars/2024-08-20_23-02-48_BestConfigReallyTopclass.json') as f:\n",
    "    best_conf = json.load(f)\n",
    "for var_name in high_level_fields:\n",
    "    if var_name in {'event', 'eventWeight'}:\n",
    "        continue\n",
    "    gauss_data_list, gauss_data_hlf = None, None\n",
    "    if var_name in (high_level_fields - set(input_hlf_vars)):\n",
    "        gauss_data_list = smear_particle_list(var_name, copy.deepcopy(data_list_test))\n",
    "        gauss_data_hlf = data_hlf_test\n",
    "    else:\n",
    "        gauss_data_list = data_list_test\n",
    "        gauss_data_hlf = smear_particle_hlf(var_name, copy.deepcopy(data_hlf_test))\n",
    "\n",
    "    IN_perf_smear_dict[var_name] = evaluate(\n",
    "        gauss_data_list, gauss_data_hlf, label_test, OUTPUT_DIRPATH, CURRENT_TIME, skf, best_conf,\n",
    "    )\n",
    "\n",
    "with open(OUTPUT_DIRPATH + f'{CURRENT_TIME}_IN_perf_gauss_smear.json', 'w') as f:\n",
    "    json.dump(IN_perf_smear_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ROC for gaussian smear variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_destdir = OUTPUT_DIRPATH + 'plots'\n",
    "if not os.path.exists(plot_destdir):\n",
    "    os.makedirs(plot_destdir)\n",
    "with open(OUTPUT_DIRPATH + f'{CURRENT_TIME}_IN_perf_gauss_smear.json', 'r') as f:\n",
    "    IN_perf_smear_dict = json.load(f)\n",
    "IN_perf_smear_list = []\n",
    "label_arr = []\n",
    "for var_name, IN_perf_smear in IN_perf_smear_dict.items():\n",
    "    IN_perf_smear_list.append(IN_perf_smear)\n",
    "    label_arr.append(var_name)\n",
    "sort = np.argsort([IN_perf_smear['mean_area'] for IN_perf_smear in IN_perf_smear_list])\n",
    "plot_roc(\n",
    "    list(IN_perf_smear_dict.values()), plot_destdir+'/'+CURRENT_TIME, plot_postfix='_gauss_smear', \n",
    "    method='IN_arr', labels=label_arr, yscale='log', run2=False, sort=sort\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gaussian Smeared input Vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir_gauss_smear = CURRENT_DIRPATH + f\"/input_comparison{'_v2' if V2_MERGED else ''}/{VERSION}/gauss_smear/\"\n",
    "if not os.path.exists(output_dir_gauss_smear):\n",
    "    os.makedirs(output_dir_gauss_smear)\n",
    "\n",
    "gauss_hists = {}\n",
    "label_arr = [\n",
    "    MC_NAMES_PRETTY[\"GluGluToHH\"]+\" train\", MC_NAMES_PRETTY[\"GluGluToHH\"]+\" test\",\n",
    "    MC_NAMES_PRETTY[\"ttHToGG\"]+\" train\", MC_NAMES_PRETTY[\"ttHToGG\"]+\" test\"\n",
    "]\n",
    "label_arr_fold = [\n",
    "    MC_NAMES_PRETTY[\"GluGluToHH\"]+\" train\", MC_NAMES_PRETTY[\"GluGluToHH\"]+\" val\", MC_NAMES_PRETTY[\"GluGluToHH\"]+\" test\",\n",
    "    MC_NAMES_PRETTY[\"ttHToGG\"]+\" train\", MC_NAMES_PRETTY[\"ttHToGG\"]+\" val\", MC_NAMES_PRETTY[\"ttHToGG\"]+\" test\"\n",
    "]\n",
    "for var_name in high_level_fields:\n",
    "    if var_name in {'event', 'puppiMET_eta'}:\n",
    "        continue\n",
    "    data, data_test = None, None\n",
    "    if var_name in (high_level_fields - set(input_hlf_vars)):\n",
    "        data, data_test = smear_particle_list(var_name, data_list), smear_particle_list(var_name, data_list_test)\n",
    "    else:\n",
    "        data, data_test = smear_particle_hlf(var_name, data_hlf), smear_particle_hlf(var_name, data_hlf_test)\n",
    "    for fold_idx, (train_index, val_index) in enumerate(skf.split(data_hlf, label)):\n",
    "        rectified_train_index = np.ones(len(label), dtype=bool)\n",
    "        rectified_train_index[val_index] = False\n",
    "        (\n",
    "            sig_train_np, sig_val_np, sig_test_np, \n",
    "            bkg_train_np, bkg_val_np, bkg_test_np \n",
    "        ) = post_std_np_arrays(\n",
    "            data, data_test, var_name, \n",
    "            train_index=rectified_train_index, val_index=np.logical_not(rectified_train_index)\n",
    "        )\n",
    "        sig_train_hist = hist.Hist(VARIABLES_STD[var_name]).fill(var=sig_train_np[sig_train_np != 0])\n",
    "        sig_val_hist = hist.Hist(VARIABLES_STD[var_name]).fill(var=sig_val_np[sig_val_np != 0])\n",
    "        sig_test_hist = hist.Hist(VARIABLES_STD[var_name]).fill(var=sig_test_np[sig_test_np != 0])\n",
    "        bkg_train_hist = hist.Hist(VARIABLES_STD[var_name]).fill(var=bkg_train_np[bkg_train_np != 0])\n",
    "        bkg_val_hist = hist.Hist(VARIABLES_STD[var_name]).fill(var=bkg_val_np[bkg_val_np != 0])\n",
    "        bkg_test_hist = hist.Hist(VARIABLES_STD[var_name]).fill(var=bkg_test_np[bkg_test_np != 0])\n",
    "\n",
    "        make_input_plot(\n",
    "            output_dir_gauss_smear, var_name, \n",
    "            [sig_train_hist, sig_val_hist, sig_test_hist, bkg_train_hist, bkg_val_hist, bkg_test_hist], \n",
    "            fold_idx=fold_idx, labels=label_arr_fold\n",
    "        )\n",
    "    sig_train_np, sig_test_np, bkg_train_np, bkg_test_np = post_std_np_arrays(data, data_test, var_name, index_map)\n",
    "\n",
    "    sig_train_hist = hist.Hist(VARIABLES_STD[var_name]).fill(var=sig_train_np[sig_train_np != 0])\n",
    "    sig_test_hist = hist.Hist(VARIABLES_STD[var_name]).fill(var=sig_test_np[sig_test_np != 0])\n",
    "    bkg_train_hist = hist.Hist(VARIABLES_STD[var_name]).fill(var=bkg_train_np[bkg_train_np != 0])\n",
    "    bkg_test_hist = hist.Hist(VARIABLES_STD[var_name]).fill(var=bkg_test_np[bkg_test_np != 0])\n",
    "    gauss_hists[var_name] = [\n",
    "        copy.deepcopy(sig_train_hist), copy.deepcopy(sig_test_hist), \n",
    "        copy.deepcopy(bkg_train_hist), copy.deepcopy(bkg_test_hist)\n",
    "    ]\n",
    "    make_input_plot(output_dir_gauss_smear, var_name, gauss_hists[var_name], labels=label_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mass sculpting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('model_outputs/v0/BestConfigReallyTopclass.json', 'r') as f:\n",
    "# with open(OUTPUT_DIRPATH + CURRENT_TIME + '_BestConfigReallyTopclass.json') as f:\n",
    "with open('/uscms/home/tsievert/nobackup/XHYbbgg/HHtobbyy/model_outputs/v4/extra_vars/2024-08-20_23-02-48_BestConfigReallyTopclass.json') as f:\n",
    "    best_conf = json.load(f)\n",
    "IN_full_eval_dict = {}\n",
    "for data_type, p_list, hlf, y in [('train', data_list, data_hlf, label), ('test', data_list_test, data_hlf_test, label_test)]:\n",
    "    IN_full_eval_dict[data_type] = evaluate(\n",
    "        p_list, hlf, y, \n",
    "        OUTPUT_DIRPATH, CURRENT_TIME, skf, best_conf,\n",
    "    )\n",
    "\n",
    "with open(OUTPUT_DIRPATH + f'{CURRENT_TIME}_IN_perf_full_eval.json', 'w') as f:\n",
    "    json.dump(IN_full_eval_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mass dists with successive score cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_destdir = OUTPUT_DIRPATH + 'plots'\n",
    "if not os.path.exists(plot_destdir):\n",
    "    os.makedirs(plot_destdir)\n",
    "with open(OUTPUT_DIRPATH + f'{CURRENT_TIME}_IN_perf_full_eval.json', 'r') as f:\n",
    "    IN_full_eval_dict = json.load(f)\n",
    "\n",
    "score_cuts = [0, 0.2, 0.4, 0.6, 0.8, 0.9, 0.95, 0.99]\n",
    "label_arr = [\n",
    "    MC_NAMES_PRETTY[\"GluGluToHH\"]+\" train, score cut = \", MC_NAMES_PRETTY[\"GluGluToHH\"]+\" test, score cut = \",\n",
    "    MC_NAMES_PRETTY[\"ttHToGG\"]+\" train, score cut = \", MC_NAMES_PRETTY[\"ttHToGG\"]+\" test, score cut = \"\n",
    "] * len(score_cuts)\n",
    "label_arr = [label_arr[label_idx]+str(score_cuts[score_idx // (len(label_arr)//len(score_cuts))]) for score_idx, label_idx in enumerate(range(len(label_arr)))]\n",
    "hist_dict = {'mass': [], 'dijet_mass': []}\n",
    "for var_name in hist_dict.keys():\n",
    "    for i, score_cut in enumerate(score_cuts):\n",
    "        sig_train_np, sig_test_np, bkg_train_np, bkg_test_np = aux_np_arrays(var_name, score_cut, IN_full_eval_dict)\n",
    "        sig_train_hist = hist.Hist(VARIABLES[var_name]).fill(var=sig_train_np)\n",
    "        sig_test_hist = hist.Hist(VARIABLES[var_name]).fill(var=sig_test_np)\n",
    "        bkg_train_hist = hist.Hist(VARIABLES[var_name]).fill(var=bkg_train_np)\n",
    "        bkg_test_hist = hist.Hist(VARIABLES[var_name]).fill(var=bkg_test_np)\n",
    "        hist_dict[var_name].extend(\n",
    "            [\n",
    "                copy.deepcopy(sig_train_hist), copy.deepcopy(sig_test_hist), \n",
    "                copy.deepcopy(bkg_train_hist), copy.deepcopy(bkg_test_hist)\n",
    "            ]\n",
    "        )\n",
    "    for mod_factor, label_mod in enumerate(['sig_train', 'sig_test', 'bkg_train', 'bkg_test']):\n",
    "        plot_list = []\n",
    "        label_list = []\n",
    "        for i in range(len(hist_dict[var_name])):\n",
    "            if (i - mod_factor) % 4 == 0:\n",
    "                plot_list.append(hist_dict[var_name][i])\n",
    "                label_list.append(label_arr[i])\n",
    "        make_input_plot(\n",
    "            plot_destdir, var_name, plot_list, labels=label_list, density=True, \n",
    "            plot_prefix=CURRENT_TIME+'_', plot_postfix='_'+label_mod, alpha=0.5,\n",
    "            linestyle=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train dataset size plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/uscms_data/d3/tsievert/XHYbbgg/HHtobbyy/model_outputs/v4/extra_vars_mod50-2\n",
      "[50, 2]\n",
      "/uscms_data/d3/tsievert/XHYbbgg/HHtobbyy/model_outputs/v4/extra_vars_mod26-2\n",
      "[26, 2]\n",
      "/uscms_data/d3/tsievert/XHYbbgg/HHtobbyy/model_outputs/v4/extra_vars_mod14-2\n",
      "[14, 2]\n",
      "/uscms_data/d3/tsievert/XHYbbgg/HHtobbyy/model_outputs/v4/extra_vars_mod8-2\n",
      "[8, 2]\n",
      "/uscms_data/d3/tsievert/XHYbbgg/HHtobbyy/model_outputs/v4/extra_vars_mod4-2\n",
      "[4, 2]\n",
      "/uscms_data/d3/tsievert/XHYbbgg/HHtobbyy/model_outputs/v4/extra_vars_mod6-2\n",
      "[6, 2]\n",
      "/uscms_data/d3/tsievert/XHYbbgg/HHtobbyy/model_outputs/v4/extra_vars\n",
      "[2, 2]\n",
      "train: \n",
      "[[7.195953138017946e-05, 6.741706268935877e-05, 6.751426481531196e-05, 6.404649604845882e-05, 6.411698601473027e-05], [4.294481878235299e-05, 4.312132976701256e-05, 4.178913667349354e-05, 4.272730244698502e-05, 4.209808884358551e-05], [4.563960092465889e-05, 4.499538816093512e-05, 4.5406824434988396e-05, 4.577255373955418e-05, 4.380262879361326e-05], [4.336559396575142e-05, 4.330293038846631e-05, 4.29853471203223e-05, 4.484011844598775e-05, 4.260041346753578e-05], [4.143545233423473e-05, 4.0452116522672965e-05, 4.0961248191056604e-05, 4.029649117723129e-05, 4.129518480116741e-05], [4.356724382506676e-05, 4.493353889417332e-05, 4.394844315495369e-05, 4.337981586864486e-05, 4.360969459340976e-05], [3.9703060617766e-05, 3.9846517560766574e-05, 3.9773387180549056e-05, 3.98990823896707e-05, 3.9882870619053815e-05]]\n",
      "train: \n",
      "[[8.459132515079915e-05, 8.947640342813078e-05, 9.643985740965624e-05, 8.373927509218126e-05, 9.386795132536758e-05], [4.428855953908112e-05, 4.338021588494763e-05, 4.270635771944847e-05, 4.490028167593068e-05, 4.294434160319132e-05], [5.0902588291696954e-05, 4.6449305239039714e-05, 4.515932410693475e-05, 4.46054925783169e-05, 4.3463066190058026e-05], [5.061357606908333e-05, 5.362531717814483e-05, 5.321877710979567e-05, 5.325082631289009e-05, 5.162952300878967e-05], [4.549035413832716e-05, 4.329299214146155e-05, 4.376507375693505e-05, 4.335061545404991e-05, 4.436100619603651e-05], [4.7016436195064225e-05, 4.837648345630663e-05, 4.877997731659844e-05, 4.922543233489769e-05, 4.8300189762021575e-05], [3.91276145356545e-05, 3.905206296332591e-05, 4.0075384400260346e-05, 3.942285047860131e-05, 3.92876054099622e-05]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_size_dirs = glob.glob(OUTPUT_DIRPATH[:-1]+'_mod*') + [OUTPUT_DIRPATH[:-1]]\n",
    "final_train_losses_arr, final_val_losses_arr = [], []\n",
    "mod_values_arr = []\n",
    "\n",
    "for train_size_dir in train_size_dirs:\n",
    "    print(train_size_dir)\n",
    "    try:\n",
    "        mod_values_arr.append([\n",
    "            int(\n",
    "                train_size_dir[\n",
    "                    train_size_dir.find('_mod')+4 : train_size_dir.find('-')\n",
    "                ]\n",
    "            ),\n",
    "            int(\n",
    "                train_size_dir[train_size_dir.find('-')+1:]\n",
    "            )\n",
    "        ])\n",
    "    except:\n",
    "         mod_values_arr.append([2, 2])\n",
    "    print(mod_values_arr[-1])\n",
    "    IN_perf_path = glob.glob(f'{train_size_dir}/*IN_perf.json')[0]\n",
    "    with open(IN_perf_path, 'r') as f:\n",
    "        IN_perf = json.load(f)\n",
    "    final_train_losses_arr.append([train_losses[-7 if len(train_losses) < NUM_EPOCHS else -1] for train_losses in IN_perf['train_losses_arr']])\n",
    "    final_val_losses_arr.append([val_losses[-7 if len(val_losses) < NUM_EPOCHS else -1] for val_losses in IN_perf['val_losses_arr']])\n",
    "\n",
    "print(f\"train: \\n{final_train_losses_arr}\")\n",
    "print(f\"train: \\n{final_val_losses_arr}\")\n",
    "\n",
    "final_train_losses_arr = np.array(final_train_losses_arr)\n",
    "final_val_losses_arr = np.array(final_val_losses_arr)\n",
    "mod_values_arr = np.array(mod_values_arr)\n",
    "dataset_sizes = (len(label) + len(label_test)) / mod_values_arr\n",
    "sorted_indices = np.argsort(dataset_sizes[:, 0])\n",
    "\n",
    "plot_destdir = OUTPUT_DIRPATH + 'plots'\n",
    "if not os.path.exists(plot_destdir):\n",
    "    os.makedirs(plot_destdir)\n",
    "\n",
    "plt.plot(\n",
    "    dataset_sizes[:, 0][sorted_indices], np.mean(final_train_losses_arr, axis=1)[sorted_indices], color='k'\n",
    ")\n",
    "plt.fill_between(\n",
    "    dataset_sizes[:, 0][sorted_indices], (np.mean(final_train_losses_arr, axis=1)-np.std(final_train_losses_arr, axis=1))[sorted_indices], \n",
    "    (np.mean(final_train_losses_arr, axis=1)+np.std(final_train_losses_arr, axis=1))[sorted_indices], \n",
    "    color=cmap_petroff10[0], alpha=0.5, label='Train data'\n",
    ")\n",
    "plt.plot(\n",
    "    dataset_sizes[:, 0][sorted_indices], np.mean(final_val_losses_arr, axis=1)[sorted_indices], color='k'\n",
    ")\n",
    "plt.fill_between(\n",
    "    dataset_sizes[:, 0][sorted_indices], (np.mean(final_val_losses_arr, axis=1)-np.std(final_val_losses_arr, axis=1))[sorted_indices], \n",
    "    (np.mean(final_val_losses_arr, axis=1)+np.std(final_val_losses_arr, axis=1))[sorted_indices], \n",
    "    color=cmap_petroff10[1], alpha=0.5, label='Val data'\n",
    ")\n",
    "plt.xlabel('Size of train dataset')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig(plot_destdir + '/train_val_comparison_varying_trainset_size.pdf')\n",
    "plt.savefig(plot_destdir + '/train_val_comparison_varying_trainset_size.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "higgs-dna-hhbbgg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
