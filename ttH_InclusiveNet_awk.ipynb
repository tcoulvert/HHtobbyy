{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/uscms/home/tsievert/nobackup/miniconda3/envs/higgsDNA_test/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# import ROOT as rt\n",
    "# from root_numpy import root2array, tree2array\n",
    "\n",
    "import awkward as ak\n",
    "import h5py\n",
    "import numpy as np\n",
    "import numpy.lib.recfunctions as nlr\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "import json\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.optim as optim\n",
    "import torch.utils.data.distributed\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Integer\n",
    "from skopt.utils import use_named_args\n",
    "\n",
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lpc_fileprefix = \"/eos/uscms/store/group/lpcdihiggsboost/tsievert/HiggsDNA_parquet/v1\"\n",
    "\n",
    "SIGNAL_FILEPATHS = [lpc_fileprefix+\"/Run3_2022preEE_merged/GluGluToHH/nominal/*\", lpc_fileprefix+\"/Run3_2022postEE_merged/GluGluToHH/nominal/*\"]\n",
    "BKG_FILEPATHS = [lpc_fileprefix+\"/Run3_2022preEE_merged/ttHToGG/nominal/*\", lpc_fileprefix+\"/Run3_2022postEE_merged/ttHToGG/nominal/*\"]\n",
    "\n",
    "\n",
    "# SIGNAL_FILEPATHS = [\"/uscms/home/tsievert/nobackup/XHYbbgg/HiggsDNA_parquet/v1/GluGluToHH/nominal/*\", \"/uscms/home/tsievert/nobackup/XHYbbgg/HiggsDNA_parquet/v1_preEE/GluGluToHH/nominal/*\"]\n",
    "# BKG_FILEPATHS = [\"/uscms/home/tsievert/nobackup/XHYbbgg/HiggsDNA_parquet/v1/ttHToGG/nominal/*\", \"/uscms/home/tsievert/nobackup/XHYbbgg/HiggsDNA_parquet/v1_preEE/ttHToGG/nominal/*\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AMSGrad(optim.Optimizer):\n",
    "    \"\"\"Implements AMSGrad algorithm.\n",
    "    Arguments:\n",
    "        params (iterable): iterable of parameters to optimize or dicts defining\n",
    "            parameter groups\n",
    "        lr (float, optional): learning rate (default: 1e-3)\n",
    "        betas (Tuple[float, float], optional): coefficients used for computing\n",
    "            running averages of gradient and its square (default: (0.9, 0.999))\n",
    "        eps (float, optional): term added to the denominator to improve\n",
    "            numerical stability (default: 1e-8)\n",
    "        weight_decay (float, optional): weight decay (L2 penalty) (default: 0)\n",
    "        amsgrad (boolean, optional): whether to use the AMSGrad variant of this\n",
    "            algorithm from the paper `On the Convergence of Adam and Beyond`_\n",
    "            (default: False)\n",
    "    .. _Adam\\: A Method for Stochastic Optimization:\n",
    "        https://arxiv.org/abs/1412.6980\n",
    "    .. _On the Convergence of Adam and Beyond:\n",
    "        https://openreview.net/forum?id=ryQu7f-RZ\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8,\n",
    "                 weight_decay=0, amsgrad=True):\n",
    "        if not 0.0 <= lr:\n",
    "            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n",
    "        if not 0.0 <= eps:\n",
    "            raise ValueError(\"Invalid epsilon value: {}\".format(eps))\n",
    "        if not 0.0 <= betas[0] < 1.0:\n",
    "            raise ValueError(\"Invalid beta parameter at index 0: {}\".format(betas[0]))\n",
    "        if not 0.0 <= betas[1] < 1.0:\n",
    "            raise ValueError(\"Invalid beta parameter at index 1: {}\".format(betas[1]))\n",
    "        defaults = dict(lr=lr, betas=betas, eps=eps,\n",
    "                        weight_decay=weight_decay, amsgrad=amsgrad)\n",
    "        super(AMSGrad, self).__init__(params, defaults)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        super(AMSGrad, self).__setstate__(state)\n",
    "        for group in self.param_groups:\n",
    "            group.setdefault('amsgrad', True)\n",
    "\n",
    "    def step(self, closure=None):\n",
    "        \"\"\"Performs a single optimization step.\n",
    "        Arguments:\n",
    "            closure (callable, optional): A closure that reevaluates the model\n",
    "                and returns the loss.\n",
    "        \"\"\"\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                grad = p.grad.data\n",
    "                if grad.is_sparse:\n",
    "                    raise RuntimeError('Adam does not support sparse gradients, please consider SparseAdam instead')\n",
    "                amsgrad = group['amsgrad']\n",
    "\n",
    "                state = self.state[p]\n",
    "\n",
    "                # State initialization\n",
    "                if len(state) == 0:\n",
    "                    state['step'] = 0\n",
    "                    # Exponential moving average of gradient values\n",
    "                    state['exp_avg'] = torch.zeros_like(p.data)\n",
    "                    # Exponential moving average of squared gradient values\n",
    "                    state['exp_avg_sq'] = torch.zeros_like(p.data)\n",
    "                    if amsgrad:\n",
    "                        # Maintains max of all exp. moving avg. of sq. grad. values\n",
    "                        state['max_exp_avg_sq'] = torch.zeros_like(p.data)\n",
    "\n",
    "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
    "                if amsgrad:\n",
    "                    max_exp_avg_sq = state['max_exp_avg_sq']\n",
    "                beta1, beta2 = group['betas']\n",
    "\n",
    "                state['step'] += 1\n",
    "\n",
    "                if group['weight_decay'] != 0:\n",
    "                    grad = grad.add(group['weight_decay'], p.data)\n",
    "\n",
    "                # Decay the first and second moment running average coefficient\n",
    "                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
    "                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
    "                if amsgrad:\n",
    "                    # Maintains the maximum of all 2nd moment running avg. till now\n",
    "                    torch.max(max_exp_avg_sq, exp_avg_sq, out=max_exp_avg_sq)\n",
    "                    # Use the max. for normalizing running avg. of gradient\n",
    "                    denom = max_exp_avg_sq.sqrt().add_(group['eps'])\n",
    "                else:\n",
    "                    denom = exp_avg_sq.sqrt().add_(group['eps'])\n",
    "\n",
    "                bias_correction1 = 1 - beta1 ** state['step']\n",
    "                bias_correction2 = 1 - beta2 ** state['step']\n",
    "                step_size = group['lr'] * math.sqrt(bias_correction2) / bias_correction1\n",
    "\n",
    "                p.data.addcdiv_(-step_size, exp_avg, denom)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "destdir = 'v1_merged_plots'\n",
    "sig_samples_list = [ak.from_parquet(glob.glob(dir_path)) for dir_path in SIGNAL_FILEPATHS]\n",
    "sig_samples_pq = ak.concatenate(sig_samples_list)\n",
    "bkg_samples_list = [ak.from_parquet(glob.glob(dir_path)) for dir_path in BKG_FILEPATHS]\n",
    "bkg_samples_pq = ak.concatenate(bkg_samples_list)\n",
    "samples = {\n",
    "    'sig': sig_samples_pq,\n",
    "    'bkg': bkg_samples_pq,\n",
    "}\n",
    "\n",
    "# print(sig_samples_pq.fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Adding ttH vars ##\n",
    "# import math\n",
    "# import re\n",
    "# import vector as vec\n",
    "# vec.register_awkward()\n",
    "\n",
    "\n",
    "# # Funcs for Abs of cos and DeltaPhi #\n",
    "# def ak_sign(ak_array, inverse=False):\n",
    "#     if not inverse:\n",
    "#         return ak.where(ak_array < 0, -1, 1)\n",
    "#     else:\n",
    "#         return ak.where(ak_array < 0, 1, -1)\n",
    "        \n",
    "# def ak_abs(ak_array):\n",
    "#     valid_entry_mask = ak.where(ak_array != -999, True, False)\n",
    "#     abs_ak_array = ak.where(ak_array > 0, ak_array, -ak_array)\n",
    "#     return ak.where(valid_entry_mask, abs_ak_array, -999)\n",
    "    \n",
    "# def deltaPhi(phi1, phi2):\n",
    "#     # angle1 and angle2 are (-pi, pi]\n",
    "#     # Convention: clockwise is (+), anti-clockwise is (-)\n",
    "#     subtract_angles = phi1 - phi2\n",
    "#     return ak.where(ak_abs(subtract_angles) <= math.pi, subtract_angles, subtract_angles + 2*math.pi*ak_sign(subtract_angles, inverse=True))\n",
    "\n",
    "\n",
    "# # Funcs for chi^2 #\n",
    "# def jets_mask(sample, jet_size, i, j, t_mask, i_mask=None, j_mask=None):\n",
    "#     jet_i_mask = t_mask & ak.where(\n",
    "#             sample[f'jet{i}_4mom'].deltaR(sample[f'lead_bjet_4mom']) > jet_size, True, False\n",
    "#         ) & ak.where(\n",
    "#             sample[f'jet{i}_4mom'].deltaR(sample[f'sublead_bjet_4mom']) > jet_size, True, False\n",
    "#         ) & ak.where(sample[f'jet{i}_pt'] != -999, True, False)\n",
    "#     if i_mask is not None:\n",
    "#         jet_i_mask = jet_i_mask & i_mask\n",
    "    \n",
    "#     jet_j_mask = t_mask & ak.where(\n",
    "#             sample[f'jet{j}_4mom'].deltaR(sample[f'lead_bjet_4mom']) > jet_size, True, False\n",
    "#         ) & ak.where(\n",
    "#             sample[f'jet{j}_4mom'].deltaR(sample[f'sublead_bjet_4mom']) > jet_size, True, False\n",
    "#         ) & ak.where(sample[f'jet{j}_pt'] != -999, True, False)\n",
    "#     if j_mask is not None:\n",
    "#         jet_j_mask = jet_j_mask & j_mask\n",
    "\n",
    "#     return jet_i_mask, jet_j_mask\n",
    "\n",
    "# def find_wjet_topjet(sample, num_jets, jet_size, w_mass, top_mass, t_mask, chi_form='t0'):\n",
    "#     jet_combos = []\n",
    "#     for i in range(1, num_jets+1):\n",
    "#         jet_combos.extend(\n",
    "#             [(i, j) for j in range(i+1, num_jets+1)]\n",
    "#         )\n",
    "\n",
    "#     chosen_w1jets = ak.Array(\n",
    "#         [\n",
    "#             {'i': -999, 'j': -999} for _ in range(ak.num(sample['event'], axis=0))\n",
    "#         ]\n",
    "#     )\n",
    "#     chosen_w1jets_deltaR = ak.Array(\n",
    "#         [0 for _ in range(ak.num(sample['event'], axis=0))]\n",
    "#     )\n",
    "\n",
    "    \n",
    "#     for i, j in jet_combos:\n",
    "#         # Masks for non bjets and jet exists (jet_pt != -999)\n",
    "#         jet_i_mask, jet_j_mask = jets_mask(sample, jet_size, i, j, t_mask)\n",
    "\n",
    "#         # Select w-jets by minimizing deltaR between two not b-jets\n",
    "#         w1_decision_mask = (\n",
    "#             ak.where(\n",
    "#                 sample[f'jet{i}_4mom'].deltaR(sample[f'jet{j}_4mom']) < \n",
    "#                 chosen_w1jets_deltaR, \n",
    "#                 True, False\n",
    "#             ) | ak.where(\n",
    "#                 sample['w1jet_4mom'].mass == 0, True, False\n",
    "#             )\n",
    "#         ) & jet_i_mask & jet_j_mask\n",
    "        \n",
    "#         sample['w1jet_4mom'] = ak.where(\n",
    "#             w1_decision_mask,\n",
    "#             sample[f'jet{i}_4mom'] + sample[f'jet{j}_4mom'], sample['w1jet_4mom']\n",
    "#         )\n",
    "\n",
    "        \n",
    "#         chosen_w1jets['i'] = ak.where(\n",
    "#             w1_decision_mask,\n",
    "#             i, chosen_w1jets['i']\n",
    "#         )\n",
    "#         chosen_w1jets['j'] = ak.where(\n",
    "#             w1_decision_mask,\n",
    "#             j, chosen_w1jets['j']\n",
    "#         )\n",
    "#         chosen_w1jets_deltaR = ak.where(\n",
    "#             w1_decision_mask,\n",
    "#             sample[f'jet{i}_4mom'].deltaR(sample[f'jet{j}_4mom']), chosen_w1jets_deltaR\n",
    "#         )\n",
    "\n",
    "#     # Select bjet by minimizing deltaR between W-jet and b-jet\n",
    "#     bjet_mass_comparison_mask = ak.where(\n",
    "#         sample['w1jet_4mom'].deltaR(sample[f'lead_bjet_4mom']) <\n",
    "#         sample['w1jet_4mom'].deltaR(sample[f'sublead_bjet_4mom']),\n",
    "#         True, False\n",
    "#     )\n",
    "#     sample['top1jet_4mom'] = ak.where(\n",
    "#         bjet_mass_comparison_mask,\n",
    "#         sample['w1jet_4mom'] + sample[f'lead_bjet_4mom'], \n",
    "#         sample['w1jet_4mom'] + sample[f'sublead_bjet_4mom']\n",
    "#     )\n",
    "\n",
    "#     if chi_form == 't1':\n",
    "#         # Select other wjet by dijet of reminaing two jets \n",
    "#         for k, l in jet_combos:\n",
    "#             # Masks for non-bjets, not choosing same jets as w1, and jet exists (jet_pt != -999)\n",
    "#             jet_k_mask, jet_l_mask = jets_mask(\n",
    "#                 sample, jet_size, k, l, t_mask, \n",
    "#                 i_mask=ak.where(chosen_w1jets['i'] != k, True, False),\n",
    "#                 j_mask=ak.where(chosen_w1jets['j'] != l, True, False)\n",
    "#             )\n",
    "            \n",
    "#             w2_decision_mask = jet_k_mask & jet_l_mask\n",
    "#             sample['w2jet_4mom'] = ak.where(\n",
    "#                 w2_decision_mask,\n",
    "#                 sample[f'jet{k}_4mom'] + sample[f'jet{l}_4mom'], sample['w2jet_4mom']\n",
    "#             )\n",
    "#         # Select other bjet \n",
    "#         sample['top2jet_4mom'] = ak.where(\n",
    "#             ~bjet_mass_comparison_mask,\n",
    "#             sample['w1jet_4mom'] + sample[f'lead_bjet_4mom'], \n",
    "#             sample['w1jet_4mom'] + sample[f'sublead_bjet_4mom']\n",
    "#         )\n",
    "\n",
    "# def chi_t0(sample, num_jets, jet_size):\n",
    "#     w_mass = 80.377\n",
    "#     top_mass = 172.76\n",
    "\n",
    "#     # To not include events with 4 extra jets, as its covered by chi_t1\n",
    "#     t_mask = ak.where(\n",
    "#         sample['jet4_pt'] != -999, True, False\n",
    "#     ) & ak.where(\n",
    "#         sample['jet6_pt'] == -999, True, False\n",
    "#     )\n",
    "    \n",
    "#     find_wjet_topjet(\n",
    "#         sample, num_jets, jet_size, w_mass, top_mass, t_mask, chi_form='t0'\n",
    "#     )\n",
    "    \n",
    "#     term1 = ((w_mass - ak.where(sample['w1jet_4mom'].mass == 0, -999, sample['w1jet_4mom'].mass)) / (0.1 * w_mass))**2\n",
    "#     term2 = ((top_mass - ak.where(sample['w1jet_4mom'].mass == 0, -999, sample['top1jet_4mom'].mass)) / (0.1 * top_mass))**2\n",
    "\n",
    "#     return ak.where(t_mask, term1+term2, -999)\n",
    "        \n",
    "# def chi_t1(sample, num_jets, jet_size):\n",
    "#     w_mass = 80.377\n",
    "#     top_mass = 172.76\n",
    "\n",
    "#     t_mask = ak.where(\n",
    "#         sample['jet6_pt'] != -999, True, False\n",
    "#     )\n",
    "    \n",
    "#     find_wjet_topjet(\n",
    "#         sample, num_jets, jet_size, w_mass, top_mass, t_mask, chi_form='t1'\n",
    "#     )\n",
    "\n",
    "#     term1_1 = ((w_mass - ak.where(sample['w1jet_4mom'].mass == 0, -999, sample['w1jet_4mom'].mass)) / (0.1 * w_mass))**2\n",
    "#     term1_2 = ((top_mass - ak.where(sample['w1jet_4mom'].mass == 0, -999, sample['top1jet_4mom'].mass)) / (0.1 * top_mass))**2\n",
    "\n",
    "#     term2_1 = ((w_mass - ak.where(sample['w1jet_4mom'].mass == 0, -999, sample['w2jet_4mom'].mass)) / (0.1 * w_mass))**2\n",
    "#     term2_2 = ((top_mass - ak.where(sample['w1jet_4mom'].mass == 0, -999, sample['top2jet_4mom'].mass)) / (0.1 * top_mass))**2\n",
    "\n",
    "#     return ak.where(t_mask, term1_1+term1_2+term2_1+term2_2, -999)\n",
    "    \n",
    "\n",
    "# for sample in samples.values():\n",
    "#     # Abs of cos #\n",
    "#     sample['abs_CosThetaStar_CS'] = ak.where(sample['CosThetaStar_CS'] >= 0, sample['CosThetaStar_CS'], -1*sample['CosThetaStar_CS'])\n",
    "#     sample['abs_CosThetaStar_jj'] = ak.where(sample['CosThetaStar_jj'] >= 0, sample['CosThetaStar_jj'], -1*sample['CosThetaStar_jj'])\n",
    "\n",
    "#     # DeltaPhi of (j, MET) #\n",
    "#     sample['DeltaPhi_j1MET'] = deltaPhi(sample['lead_bjet_phi'], sample['puppiMET_phi'])\n",
    "#     sample['DeltaPhi_j2MET'] = deltaPhi(sample['sublead_bjet_phi'], sample['puppiMET_phi'])\n",
    "\n",
    "#     # chi^2 #\n",
    "#     for field in ['lead', 'sublead']:\n",
    "#         sample[f'{field}_bjet_4mom'] = ak.zip(\n",
    "#             {\n",
    "#                 'rho': sample[f'{field}_bjet_pt'], # rho is synonym for pt\n",
    "#                 'phi': sample[f'{field}_bjet_phi'],\n",
    "#                 'eta': sample[f'{field}_bjet_eta'],\n",
    "#                 'tau': sample[f'{field}_bjet_mass'], # tau is synonym for mass\n",
    "#             }, with_name='Momentum4D'\n",
    "#         )\n",
    "\n",
    "#     for i in range(1, 7): # how to not hard-code 7 jets?\n",
    "#         sample[f'jet{i}_4mom'] = ak.zip(\n",
    "#             {\n",
    "#                 'rho': sample[f'jet{i}_pt'],\n",
    "#                 'phi': sample[f'jet{i}_phi'],\n",
    "#                 'eta': sample[f'jet{i}_eta'],\n",
    "#                 'tau': sample[f'jet{i}_mass'],\n",
    "#             }, with_name='Momentum4D'\n",
    "#         )\n",
    "            \n",
    "#     for jet_type in ['w', 'top']:\n",
    "#         for jet_num in range(1, 3):\n",
    "#             # sample[f'{jet_type}{jet_num}jet_4mom'] = ak.copy(sample['zero_vector'])\n",
    "#             sample[f'{jet_type}{jet_num}jet_4mom'] = ak.Array(\n",
    "#                 [\n",
    "#                     {'rho': 0, 'phi': 0, 'eta': 0, 'tau': 0} for _ in range(ak.num(sample['event'], axis=0))\n",
    "#                 ], with_name='Momentum4D'\n",
    "#             )\n",
    "\n",
    "#     sample['chi_t0^2'] = chi_t0(sample, 6, 0.4)\n",
    "#     sample['chi_t1^2'] = chi_t1(sample, 6, 0.4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'awkward' has no attribute 'without_field'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m field \u001b[38;5;129;01min\u001b[39;00m sample\u001b[38;5;241m.\u001b[39mfields:\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m field \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m high_level_fields:\n\u001b[0;32m---> 21\u001b[0m         pandas_samples[sample_name] \u001b[38;5;241m=\u001b[39m \u001b[43mak\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwithout_field\u001b[49m(pandas_samples[sample_name], field)\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m field \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m hgih_level_aux_fields:\n\u001b[1;32m     23\u001b[0m         pandas_aux_samples[sample_name] \u001b[38;5;241m=\u001b[39m ak\u001b[38;5;241m.\u001b[39mwithout_field(pandas_aux_samples[sample_name], field)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'awkward' has no attribute 'without_field'"
     ]
    }
   ],
   "source": [
    "pandas_samples = {}\n",
    "high_level_fields = {\n",
    "    'puppiMET_pt','puppiMET_phi','DeltaPhi_j1MET','DeltaPhi_j2MET', # MET variables\n",
    "    'DeltaR_jg_min','n_jets','chi_t0^2','chi_t1^2', # jet variables\n",
    "    'lepton1_pt','lepton2_pt','pt', # lepton and diphoton pt\n",
    "    'lepton1_eta','lepton2_eta','eta', # lepton and diphoton eta\n",
    "    'lepton1_phi','lepton2_phi','phi', # lepton and diphoton phi\n",
    "    'abs_CosThetaStar_CS','abs_CosThetaStar_jj' # angular variables\n",
    "}\n",
    "\n",
    "pandas_aux_samples = {}\n",
    "hgih_level_aux_fields = {\n",
    "    'mass', 'dijet_mass' # diphoton and bb-dijet mass\n",
    "} # https://stackoverflow.com/questions/67003141/how-to-remove-a-field-from-a-collection-of-records-created-by-awkward-zip\n",
    "\n",
    "for sample_name, sample in samples.items():\n",
    "    pandas_samples[sample_name] = sample\n",
    "    pandas_aux_samples[sample_name] = sample\n",
    "    for field in sample.fields:\n",
    "        if field not in high_level_fields:\n",
    "            pandas_samples[sample_name] = ak.without_field(pandas_samples[sample_name], field)\n",
    "        if field not in hgih_level_aux_fields:\n",
    "            pandas_aux_samples[sample_name] = ak.without_field(pandas_aux_samples[sample_name], field)\n",
    "\n",
    "# del samples\n",
    "\n",
    "sig_frame = ak.to_dataframe(pandas_samples['sig'])\n",
    "sig_aux_frame = ak.to_dataframe(pandas_aux_samples['sig'])\n",
    "bkg_frame = ak.to_dataframe(pandas_samples['bkg'])\n",
    "bkg_aux_frame = ak.to_dataframe(pandas_aux_samples['bkg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://scikit-hep.org/root_numpy/reference/generated/root_numpy.tree2array.html\n",
    "# # https://numpy.org/doc/stable/user/basics.rec.html\n",
    "# # https://awkward-array.org/doc/main/reference/generated/ak.to_dataframe.html\n",
    "# # Convert akward array to pandas dataframe (maybe going thru numpy structured array in the middle if necessary, but hopefully not)\n",
    "# #   -> goal is to minimally change thong's code, which requires these pandas DF to be created, then copy paste old code and run.\n",
    "# #   Can optimize this code later as we understand it more, but firstly get it running.\n",
    "\n",
    "# for sample_name, sample in samples.items():\n",
    "#     for field in sample.fields:\n",
    "#         sample[field] = ak.where(\n",
    "#             sample[field] != -999,\n",
    "#             (sample[field] - ak.mean(sample[field])) / ak.std(sample[field]),\n",
    "#             -999\n",
    "#         )\n",
    "#         sample[field] = ak.mask(sample[field], (sample[field] != -999))\n",
    "# print(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because of zero-padding, standardization needs special treatment\n",
    "# Masked out zero\n",
    "# zero_entries = bkg_frame == 0 \n",
    "zero_entries = (bkg_frame == -999) # now pad with -999 instead of 0\n",
    "masked_x_sample = np.ma.array(bkg_frame, mask=zero_entries)\n",
    "x_mean = masked_x_sample.mean(axis=0)\n",
    "x_std = masked_x_sample.std(axis=0)\n",
    "print(\"Mean and std calculated.\")\n",
    "\n",
    "# Standardize background\n",
    "normed_bkg = (masked_x_sample - x_mean)/x_std\n",
    "\n",
    "# Standardize signal\n",
    "# zero_entries = sig_frame == 0 \n",
    "zero_entries = (sig_frame == -999) # now pad with -999 instead of 0\n",
    "masked_x_sample = np.ma.array(sig_frame, mask=zero_entries)\n",
    "normed_sig = (masked_x_sample - x_mean)/x_std\n",
    "\n",
    "normed_bkg_frame = pd.DataFrame(normed_bkg.filled(0), columns=list(bkg_frame))\n",
    "normed_bkg_frame.head()\n",
    "\n",
    "normed_sig_frame = pd.DataFrame(normed_sig.filled(0), columns=list(sig_frame))\n",
    "normed_sig_frame.head()\n",
    "\n",
    "\n",
    "\n",
    "def to_p_list(data_frame):\n",
    "    # Inputs: Pandas data frame\n",
    "    # Outputs: Numpy array of dimension (Event, Particle, Attributes)\n",
    "    \n",
    "    particle_list_sig = np.zeros(shape=(len(data_frame),6,7))\n",
    "    sorted_particle_list = np.zeros(shape=(len(data_frame),6,7))\n",
    "    #6: max particles: e1, e2, mu1, mu2, dipho, MET.\n",
    "    #7: pt, eta, phi, isEle, isMuon, isDipho, isMET\n",
    "   \n",
    "    for i in range(len(data_frame)): # loop through the list of events\n",
    "        pte1 = data_frame['pte1'][i]\n",
    "        pte2 = data_frame['pte2'][i]\n",
    "        ptmu1 = data_frame['ptmu1'][i]\n",
    "        ptmu2 = data_frame['ptmu2'][i]\n",
    "        ptdipho = data_frame['ptdipho'][i]\n",
    "        ptMET = data_frame['MET'][i]\n",
    "\n",
    "        etae1 = data_frame['etae1'][i]\n",
    "        etae2 = data_frame['etae2'][i]\n",
    "        etamu1 = data_frame['etamu1'][i]\n",
    "        etamu2 = data_frame['etamu2'][i]\n",
    "        etadipho = data_frame['etadipho'][i]\n",
    "        etaMET = 0\n",
    "\n",
    "        phie1 = data_frame['phie1'][i]\n",
    "        phie2 = data_frame['phie2'][i]\n",
    "        phimu1 = data_frame['phimu1'][i]\n",
    "        phimu2 = data_frame['phimu2'][i]\n",
    "        phidipho = data_frame['phidipho'][i]\n",
    "        phiMET = data_frame['phiMET'][i]\n",
    "\n",
    "        # list through list of particles: e1, e2, mu1, mu2, dipho, MET\n",
    "        # 0: leading ele\n",
    "        particle_list_sig[i,0, 0] = pte1\n",
    "        particle_list_sig[i,0, 1] = etae1\n",
    "        particle_list_sig[i,0, 2] = phie1\n",
    "        particle_list_sig[i,0, 3] = 1 if pte1!=0 else 0 # isEle\n",
    "        particle_list_sig[i,0, 4] = 0 # isMuon\n",
    "        particle_list_sig[i,0, 5] = 0 # isDiPho\n",
    "        particle_list_sig[i,0, 6] = 0 # isMET\n",
    "\n",
    "        # 1: subleading ele\n",
    "        particle_list_sig[i,1, 0] = pte2\n",
    "        particle_list_sig[i,1, 1] = etae2\n",
    "        particle_list_sig[i,1, 2] = phie2\n",
    "        particle_list_sig[i,1, 3] = 1 if pte2!=0 else 0 # isEle\n",
    "        particle_list_sig[i,1, 4] = 0 # isMuon\n",
    "        particle_list_sig[i,1, 5] = 0 # isDiPho\n",
    "        particle_list_sig[i,1, 6] = 0 # isMET\n",
    "\n",
    "        # 2: leading muon\n",
    "        particle_list_sig[i,2, 0] = ptmu1\n",
    "        particle_list_sig[i,2, 1] = etamu1\n",
    "        particle_list_sig[i,2, 2] = phimu1\n",
    "        particle_list_sig[i,2, 3] = 0 # isEle\n",
    "        particle_list_sig[i,2, 4] = 1 if ptmu1!=0 else 0 # isMuon\n",
    "        particle_list_sig[i,2, 5] = 0 # isDiPho\n",
    "        particle_list_sig[i,2, 6] = 0 # isMET\n",
    "\n",
    "        # 3: subleading muon\n",
    "        particle_list_sig[i,3, 0] = ptmu2\n",
    "        particle_list_sig[i,3, 1] = etamu2\n",
    "        particle_list_sig[i,3, 2] = phimu2\n",
    "        particle_list_sig[i,3, 3] = 0 #isEle\n",
    "        particle_list_sig[i,3, 4] = 1 if ptmu2!=0 else 0 # isMuon\n",
    "        particle_list_sig[i,3, 5] = 0 # isDiPho\n",
    "        particle_list_sig[i,3, 6] = 0 # isMET\n",
    "\n",
    "        # 4: dipho\n",
    "        particle_list_sig[i,4, 0] = ptdipho\n",
    "        particle_list_sig[i,4, 1] = etadipho\n",
    "        particle_list_sig[i,4, 2] = phidipho\n",
    "        particle_list_sig[i,4, 3] = 0 # isEle\n",
    "        particle_list_sig[i,4, 4] = 0 # isMuon\n",
    "        particle_list_sig[i,4, 5] = 1 if ptdipho!=0 else 0 # isDiPho\n",
    "        particle_list_sig[i,4, 6] = 0 # isMET\n",
    "\n",
    "        # 5: MET\n",
    "        particle_list_sig[i,5, 0] = ptMET\n",
    "        particle_list_sig[i,5, 1] = etaMET\n",
    "        particle_list_sig[i,5, 2] = phiMET\n",
    "        particle_list_sig[i,5, 3] = 0 #isEle\n",
    "        particle_list_sig[i,5, 4] = 0 # isMuon\n",
    "        particle_list_sig[i,5, 5] = 0 # isDiPho\n",
    "        particle_list_sig[i,5, 6] = 1 if ptMET != 0 else 0 # isMET\n",
    "    \n",
    "        # Sort by descending pT. \n",
    "        # This was implemented when standardization was done before sorting. Thus zero entry needs to be excluded\n",
    "        # Redesigned the code with standardization done after sorting. Same code still works.\n",
    "        nonzero_indices = np.nonzero(particle_list_sig[i,:,0])[0]\n",
    "        sorted_indices = particle_list_sig[i,nonzero_indices,0].argsort()[::-1] # sort by first column, which is the pT\n",
    "        global_sorted_indices = nonzero_indices[sorted_indices]\n",
    "        sorted_particle_list[i,:len(nonzero_indices),:] = particle_list_sig[i,global_sorted_indices,:]\n",
    "        \n",
    "    return sorted_particle_list\n",
    "\n",
    "sig_list = to_p_list(sig_frame)\n",
    "bkg_list = to_p_list(bkg_frame)\n",
    "\n",
    "# Standardize the particle list\n",
    "x_sample = bkg_list[:,:,:3] # don't standardize boolean flags\n",
    "# Flatten out\n",
    "x_flat = x_sample.reshape((x_sample.shape[0]*x_sample.shape[1], x_sample.shape[2]))\n",
    "# Masked out zero\n",
    "zero_entries = x_flat == 0 \n",
    "masked_x_sample = np.ma.array(x_flat, mask=zero_entries)\n",
    "x_list_mean = masked_x_sample.mean(axis=0)\n",
    "x_list_std = masked_x_sample.std(axis=0)\n",
    "print(\"Mean and std calculated for particle list.\")\n",
    "del x_sample, x_flat, zero_entries, masked_x_sample # release the memory\n",
    "\n",
    "def standardize_p_list(inputs):\n",
    "    global x_list_mean, x_list_std\n",
    "    to_norm = inputs[:,:,:3]\n",
    "    zero_entries = to_norm == 0\n",
    "    masked_to_norm = np.ma.array(to_norm, mask=zero_entries)\n",
    "    normed_x = (masked_to_norm - x_list_mean)/x_list_std\n",
    "    return np.concatenate((normed_x.filled(0), inputs[:,:,3:]), axis=2)\n",
    "    \n",
    "normed_sig_list = standardize_p_list(sig_list)\n",
    "normed_bkg_list = standardize_p_list(bkg_list)\n",
    "\n",
    "normed_sig_hlf = normed_sig_frame[['sumEt','dPhi1','dPhi2','PhoJetMinDr','njets','Xtt0',\n",
    "                                   'Xtt1','fabs_CosThetaStar_CS','fabs_CosTheta_bb']].values\n",
    "\n",
    "normed_bkg_hlf = normed_bkg_frame[['sumEt','dPhi1','dPhi2','PhoJetMinDr','njets','Xtt0',\n",
    "                                   'Xtt1','fabs_CosThetaStar_CS','fabs_CosTheta_bb']].values\n",
    "    \n",
    "# Shuffle before splitting into train-val\n",
    "randix = np.arange(len(normed_bkg_list))\n",
    "np.random.shuffle(randix)\n",
    "\n",
    "background_list = normed_bkg_list[randix]\n",
    "background_list = background_list[:len(normed_sig_list)] # downsampling\n",
    "\n",
    "background_hlf = normed_bkg_hlf[randix]\n",
    "background_hlf = background_hlf[:len(normed_sig_hlf)]\n",
    "\n",
    "sig_label = np.ones(len(normed_sig_hlf))\n",
    "bkg_label = np.zeros(len(background_hlf))\n",
    "\n",
    "data_list = np.concatenate((normed_sig_list,background_list))\n",
    "data_hlf = np.concatenate((normed_sig_hlf,background_hlf))\n",
    "\n",
    "label = np.concatenate((sig_label,bkg_label))\n",
    "print(\"Data list: {}\".format(data_list.shape))\n",
    "print(\"Data HLF: {}\".format(data_hlf.shape))\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "skf.get_n_splits(data_hlf, label)\n",
    "print(skf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS=100\n",
    "model_file = 'ReallyTopclassStyle.torch'\n",
    "config_file = 'BestConfigReallyTopclass.json'\n",
    "retrain=True\n",
    "\n",
    "class ParticleHLF(Dataset):\n",
    "    def __init__(self, data_particles, data_hlf, data_y):\n",
    "        self.len = data_y.shape[0]\n",
    "        self.data_particles = torch.from_numpy(data_particles).float()\n",
    "        self.data_hlf = torch.from_numpy(data_hlf).float()\n",
    "        self.data_y = torch.from_numpy(data_y).long()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.data_particles[idx], self.data_hlf[idx], self.data_y[idx])\n",
    "\n",
    "class InclusiveNetwork(nn.Module):\n",
    "    def __init__(self, num_hiddens=2, initial_node=500, dropout=0.5, gru_layers=2, gru_size=50, dropout_g=0.1):\n",
    "        super(InclusiveNetwork, self).__init__()\n",
    "        self.dropout = dropout\n",
    "        self.dropout_g = dropout_g\n",
    "        self.hiddens = nn.ModuleList()\n",
    "        nodes = [initial_node]\n",
    "        for i in range(num_hiddens):\n",
    "            nodes.append(int(nodes[i]/2))\n",
    "            self.hiddens.append(nn.Linear(nodes[i],nodes[i+1]))\n",
    "        self.gru = nn.GRU(input_size=7, hidden_size=gru_size, num_layers=gru_layers, batch_first=True, dropout=self.dropout_g)\n",
    "        self.merge = nn.Linear(9+gru_size,initial_node)\n",
    "        self.out = nn.Linear(nodes[-1],2)\n",
    "\n",
    "    def forward(self, particles, hlf):\n",
    "        _, hgru = self.gru(particles)\n",
    "        hgru = hgru[-1] # Get the last hidden layer\n",
    "        x = torch.cat((hlf,hgru), dim=1)\n",
    "        x = F.dropout(self.merge(x), training=self.training, p=self.dropout)\n",
    "        for i in range(len(self.hiddens)):\n",
    "            x = F.relu(self.hiddens[i](x))\n",
    "            x = F.dropout(x, training=self.training, p=self.dropout)\n",
    "        x = self.out(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "class EarlyStopping():\n",
    "    \"\"\"\n",
    "    Early Stopping to terminate training early under certain conditions\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, \n",
    "                 monitor='val_loss',\n",
    "                 min_delta=0,\n",
    "                 patience=10):\n",
    "        self.monitor = monitor\n",
    "        self.min_delta = min_delta\n",
    "        self.patience = patience\n",
    "        self.stopped_epoch = 0\n",
    "        self.stop_training= False\n",
    "        #print(\"This is my patience {}\".format(patience))\n",
    "    \n",
    "    def on_train_begin(self):\n",
    "        self.wait = 0\n",
    "        self.best_loss = 1e15\n",
    "    \n",
    "    def on_epoch_end(self, epoch, current_loss):\n",
    "        if current_loss is None:\n",
    "            pass\n",
    "        else:\n",
    "            if (current_loss - self.best_loss) < -self.min_delta:\n",
    "                self.best_loss = current_loss\n",
    "                self.wait = 1\n",
    "            else:\n",
    "                if self.wait >= self.patience:\n",
    "                    self.stopped_epoch = epoch + 1\n",
    "                    self.stop_training = True\n",
    "                self.wait += 1\n",
    "            return  self.stop_training\n",
    "        \n",
    "    def on_train_end(self):\n",
    "        if self.stopped_epoch > 0:\n",
    "            print('\\nTerminated training for early stopping at epoch %04i' % \n",
    "                (self.stopped_epoch))\n",
    "\n",
    "def train(num_epochs, model, criterion, optimizer,scheduler,volatile=False, data_loader=None):\n",
    "    best_model = model.state_dict()\n",
    "    best_acc = 0.0\n",
    "    train_losses ,val_losses = [],[]\n",
    "    callback = EarlyStopping(patience=10)\n",
    "    callback.on_train_begin()\n",
    "    breakdown = False\n",
    "    for epoch in range(num_epochs):\n",
    "        if breakdown:\n",
    "            print(\"Early stopped.\")\n",
    "            break\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        \n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['training', 'validation']:\n",
    "            if phase == 'training':\n",
    "                model.train() # Set model to training mode\n",
    "                volatile=False\n",
    "            else:\n",
    "                model.eval() # Set model to evaluate mode\n",
    "                volatile=True\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for batch_idx, (particles_data, hlf_data, y_data) in enumerate(data_loader[phase]):\n",
    "                particles_data = particles_data.numpy()\n",
    "                arr = np.sum(particles_data!=0, axis=1)[:,0] # the number of particles in each batch\n",
    "                arr = [1 if x==0 else x for x in arr]\n",
    "                arr = np.array(arr)\n",
    "                sorted_indices_la= np.argsort(-arr)\n",
    "                particles_data = torch.from_numpy(particles_data[sorted_indices_la]).float()\n",
    "                hlf_data = hlf_data[sorted_indices_la]\n",
    "                y_data = y_data[sorted_indices_la]\n",
    "                particles_data = Variable(particles_data, volatile=volatile).cuda() \n",
    "                \n",
    "                hlf_data = Variable(hlf_data, volatile).cuda()\n",
    "                y_data = Variable(y_data, volatile=volatile, requires_grad=False).cuda()\n",
    "                t_seq_length= [arr[i] for i in sorted_indices_la]\n",
    "                particles_data = torch.nn.utils.rnn.pack_padded_sequence(particles_data, t_seq_length, batch_first=True)\n",
    "                \n",
    "                if phase == 'training':\n",
    "                    optimizer.zero_grad()\n",
    "                # forward pass\n",
    "                outputs = model(particles_data, hlf_data)\n",
    "                _, preds = torch.max(outputs.data, 1)\n",
    "                loss = criterion(outputs, y_data)\n",
    "                \n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'training':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                \n",
    "                # statistics\n",
    "                running_loss += loss.data[0]\n",
    "                running_corrects += torch.sum(preds == y_data.data)\n",
    "                #print(\"I finished %d batch\" % batch_idx)\n",
    "            \n",
    "            epoch_loss = running_loss / len(data_loader[phase].dataset)\n",
    "            epoch_acc = 100. * running_corrects / len(data_loader[phase].dataset)\n",
    "            if phase == 'training':\n",
    "                train_losses.append(epoch_loss)\n",
    "            else:\n",
    "                scheduler.step(epoch_loss)\n",
    "                val_losses.append(epoch_loss)\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'validation' and epoch_acc > best_acc:\n",
    "                print('Saving..')\n",
    "                state = {\n",
    "                        'net': model, #.module if use_cuda else net,\n",
    "                        'epoch': epoch,\n",
    "                        'best_acc':epoch_acc,\n",
    "                        'train_loss':train_losses,\n",
    "                        'val_loss':val_losses,\n",
    "                        }\n",
    "                torch.save(state, model_file)\n",
    "                best_acc = epoch_acc\n",
    "                best_model = model.state_dict()\n",
    "            if phase == 'validation':\n",
    "                breakdown = callback.on_epoch_end(epoch, -epoch_acc)\n",
    "                \n",
    "         \n",
    "    print('Best val acc: {:4f}'.format(best_acc))\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model)\n",
    "    print('-' * 10)\n",
    "    return best_acc\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Loss: 0.0011 Acc: 84.5575\n",
      "validation Loss: 0.0010 Acc: 85.0119\n",
      "Epoch 32/99\n",
      "training Loss: 0.0011 Acc: 84.6884\n",
      "validation Loss: 0.0010 Acc: 84.9524\n",
      "Epoch 33/99\n",
      "training Loss: 0.0011 Acc: 84.5247\n",
      "validation Loss: 0.0010 Acc: 85.1071\n",
      "Saving..\n",
      "Epoch 34/99\n",
      "training Loss: 0.0011 Acc: 84.7301\n",
      "validation Loss: 0.0010 Acc: 85.0833\n",
      "Epoch 35/99\n",
      "training Loss: 0.0011 Acc: 84.6110\n",
      "validation Loss: 0.0010 Acc: 85.1190\n",
      "Saving..\n",
      "Epoch 36/99\n",
      "training Loss: 0.0011 Acc: 84.5247\n",
      "validation Loss: 0.0010 Acc: 85.0357\n",
      "Epoch 37/99\n",
      "training Loss: 0.0011 Acc: 84.8640\n",
      "validation Loss: 0.0010 Acc: 85.1071\n",
      "Epoch 38/99\n",
      "training Loss: 0.0011 Acc: 84.7420\n",
      "validation Loss: 0.0010 Acc: 85.0119\n",
      "Epoch 39/99\n",
      "training Loss: 0.0011 Acc: 84.7152\n",
      "validation Loss: 0.0010 Acc: 85.1190\n",
      "Epoch 40/99\n",
      "training Loss: 0.0011 Acc: 84.8491\n",
      "validation Loss: 0.0010 Acc: 84.8690\n",
      "Epoch 41/99\n",
      "training Loss: 0.0011 Acc: 84.7717\n",
      "validation Loss: 0.0010 Acc: 85.0714\n",
      "Epoch 42/99\n",
      "training Loss: 0.0011 Acc: 84.5962\n",
      "validation Loss: 0.0010 Acc: 85.0595\n",
      "Epoch 43/99\n",
      "training Loss: 0.0011 Acc: 84.7033\n",
      "validation Loss: 0.0010 Acc: 85.0476\n",
      "Epoch 44/99\n",
      "training Loss: 0.0011 Acc: 84.7301\n",
      "validation Loss: 0.0010 Acc: 85.0595\n",
      "Epoch 45/99\n",
      "training Loss: 0.0011 Acc: 84.6765\n",
      "validation Loss: 0.0010 Acc: 85.1071\n",
      "Early stopped.\n",
      "Best val acc: 85.119048\n",
      "----------\n",
      "Average best_acc across k-fold: 85.0245259065\n",
      "New configuration: {'hidden_layers': 2, 'dropout_g': 0.7228105692618836, 'initial_nodes': 479, 'dropout': 0.1349121945672542, 'gru_layers': 3, 'batch_size': 358, 'gru_size': 242, 'learning_rate': 0.001207563335135195}\n",
      "Epoch 0/99\n",
      "training Loss: 0.0012 Acc: 80.4673\n",
      "validation Loss: 0.0011 Acc: 83.3254\n",
      "Saving..\n",
      "Epoch 1/99\n",
      "training Loss: 0.0010 Acc: 83.4048\n",
      "validation Loss: 0.0010 Acc: 84.3371\n",
      "Saving..\n",
      "Epoch 2/99\n",
      "training Loss: 0.0010 Acc: 84.4554\n",
      "validation Loss: 0.0010 Acc: 85.1583\n",
      "Saving..\n",
      "Epoch 3/99\n",
      "training Loss: 0.0010 Acc: 84.8244\n",
      "validation Loss: 0.0009 Acc: 85.4915\n",
      "Saving..\n",
      "Epoch 4/99\n",
      "training Loss: 0.0009 Acc: 85.1607\n",
      "validation Loss: 0.0010 Acc: 85.3844\n",
      "Epoch 5/99\n",
      "training Loss: 0.0009 Acc: 85.1756\n",
      "validation Loss: 0.0009 Acc: 85.4439\n",
      "Epoch 6/99\n",
      "training Loss: 0.0009 Acc: 85.4435\n",
      "validation Loss: 0.0009 Acc: 85.7534\n",
      "Saving..\n",
      "Epoch 7/99\n",
      "training Loss: 0.0009 Acc: 85.3690\n",
      "validation Loss: 0.0009 Acc: 85.3487\n",
      "Epoch 8/99\n",
      "training Loss: 0.0009 Acc: 85.2321\n",
      "validation Loss: 0.0009 Acc: 85.6225\n",
      "Epoch 9/99\n",
      "training Loss: 0.0009 Acc: 85.5417\n",
      "validation Loss: 0.0009 Acc: 85.8010\n",
      "Saving..\n",
      "Epoch 10/99\n",
      "training Loss: 0.0009 Acc: 85.5863\n",
      "validation Loss: 0.0009 Acc: 85.6344\n",
      "Epoch 11/99\n",
      "training Loss: 0.0009 Acc: 85.5714\n",
      "validation Loss: 0.0009 Acc: 85.7653\n",
      "Epoch 12/99\n",
      "training Loss: 0.0009 Acc: 85.6369\n",
      "validation Loss: 0.0009 Acc: 85.6582\n",
      "Epoch 13/99\n",
      "training Loss: 0.0009 Acc: 85.6071\n",
      "validation Loss: 0.0009 Acc: 85.7177\n",
      "Epoch 14/99\n",
      "training Loss: 0.0009 Acc: 85.7411\n",
      "validation Loss: 0.0009 Acc: 85.6820\n",
      "Epoch 15/99\n",
      "training Loss: 0.0009 Acc: 85.7500\n",
      "validation Loss: 0.0009 Acc: 85.6344\n",
      "Epoch 16/99\n",
      "training Loss: 0.0009 Acc: 85.9732\n",
      "validation Loss: 0.0009 Acc: 85.6701\n",
      "Epoch 17/99\n",
      "training Loss: 0.0009 Acc: 85.8839\n",
      "validation Loss: 0.0009 Acc: 85.5868\n",
      "Epoch 18/99\n",
      "training Loss: 0.0009 Acc: 85.8958\n",
      "validation Loss: 0.0009 Acc: 85.5392\n",
      "Epoch 19/99\n",
      "training Loss: 0.0009 Acc: 85.9702\n",
      "validation Loss: 0.0009 Acc: 85.8248\n",
      "Saving..\n",
      "Epoch 20/99\n",
      "training Loss: 0.0009 Acc: 85.9673\n",
      "validation Loss: 0.0009 Acc: 86.0033\n",
      "Saving..\n",
      "Epoch 21/99\n",
      "training Loss: 0.0009 Acc: 85.9256\n",
      "validation Loss: 0.0009 Acc: 85.9676\n",
      "Epoch 22/99\n",
      "training Loss: 0.0009 Acc: 85.9821\n",
      "validation Loss: 0.0009 Acc: 85.4677\n",
      "Epoch 23/99\n",
      "training Loss: 0.0009 Acc: 85.9167\n",
      "validation Loss: 0.0009 Acc: 85.6106\n",
      "Epoch 24/99\n",
      "training Loss: 0.0009 Acc: 86.1607\n",
      "validation Loss: 0.0009 Acc: 85.7653\n",
      "Epoch 25/99\n",
      "training Loss: 0.0009 Acc: 86.2024\n",
      "validation Loss: 0.0009 Acc: 85.7534\n",
      "Epoch 26/99\n",
      "training Loss: 0.0009 Acc: 86.1726\n",
      "validation Loss: 0.0009 Acc: 85.7534\n",
      "Epoch 27/99\n",
      "training Loss: 0.0009 Acc: 86.1696\n",
      "validation Loss: 0.0009 Acc: 85.5273\n",
      "Epoch 28/99\n",
      "training Loss: 0.0009 Acc: 86.1875\n",
      "validation Loss: 0.0009 Acc: 85.7891\n",
      "Epoch 29/99\n",
      "training Loss: 0.0009 Acc: 86.2202\n",
      "validation Loss: 0.0009 Acc: 85.5630\n",
      "Epoch 30/99\n",
      "training Loss: 0.0009 Acc: 86.1220\n",
      "validation Loss: 0.0009 Acc: 85.3249\n",
      "Early stopped.\n",
      "Best val acc: 86.003333\n",
      "----------\n",
      "Epoch 0/99\n",
      "training Loss: 0.0012 Acc: 80.7511\n",
      "validation Loss: 0.0010 Acc: 83.7143\n",
      "Saving..\n",
      "Epoch 1/99\n",
      "training Loss: 0.0010 Acc: 83.3194\n",
      "validation Loss: 0.0010 Acc: 84.9286\n",
      "Saving..\n",
      "Epoch 2/99\n",
      "training Loss: 0.0010 Acc: 84.3878\n",
      "validation Loss: 0.0009 Acc: 85.3571\n",
      "Saving..\n",
      "Epoch 3/99\n",
      "training Loss: 0.0010 Acc: 84.8223\n",
      "validation Loss: 0.0010 Acc: 85.3929\n",
      "Saving..\n",
      "Epoch 4/99\n",
      "training Loss: 0.0010 Acc: 84.8223\n",
      "validation Loss: 0.0009 Acc: 85.8333\n",
      "Saving..\n",
      "Epoch 5/99\n",
      "training Loss: 0.0010 Acc: 84.9503\n",
      "validation Loss: 0.0009 Acc: 85.7619\n",
      "Epoch 6/99\n",
      "training Loss: 0.0009 Acc: 85.1586\n",
      "validation Loss: 0.0009 Acc: 86.1190\n",
      "Saving..\n",
      "Epoch 7/99\n",
      "training Loss: 0.0009 Acc: 85.1289\n",
      "validation Loss: 0.0009 Acc: 85.7619\n",
      "Epoch 8/99\n",
      "training Loss: 0.0009 Acc: 85.4354\n",
      "validation Loss: 0.0009 Acc: 85.8214\n",
      "Epoch 9/99\n",
      "training Loss: 0.0009 Acc: 85.5157\n",
      "validation Loss: 0.0009 Acc: 85.5952\n",
      "Epoch 10/99\n",
      "training Loss: 0.0009 Acc: 85.1497\n",
      "validation Loss: 0.0009 Acc: 85.9881\n",
      "Epoch 11/99\n",
      "training Loss: 0.0009 Acc: 85.5187\n",
      "validation Loss: 0.0009 Acc: 85.9286\n",
      "Epoch 12/99\n",
      "training Loss: 0.0009 Acc: 85.6943\n",
      "validation Loss: 0.0009 Acc: 86.0595\n",
      "Epoch 13/99\n",
      "training Loss: 0.0009 Acc: 85.6050\n",
      "validation Loss: 0.0009 Acc: 86.0476\n",
      "Epoch 14/99\n",
      "training Loss: 0.0009 Acc: 85.6645\n",
      "validation Loss: 0.0009 Acc: 86.1667\n",
      "Saving..\n",
      "Epoch 15/99\n",
      "training Loss: 0.0009 Acc: 85.6288\n",
      "validation Loss: 0.0009 Acc: 86.0476\n",
      "Epoch 16/99\n",
      "training Loss: 0.0009 Acc: 85.7508\n",
      "validation Loss: 0.0009 Acc: 85.9762\n",
      "Epoch 17/99\n",
      "training Loss: 0.0009 Acc: 85.5098\n",
      "validation Loss: 0.0009 Acc: 85.8810\n",
      "Epoch 18/99\n",
      "training Loss: 0.0009 Acc: 85.8044\n",
      "validation Loss: 0.0009 Acc: 86.0238\n",
      "Epoch 19/99\n",
      "training Loss: 0.0009 Acc: 85.8639\n",
      "validation Loss: 0.0009 Acc: 85.9167\n",
      "Epoch 20/99\n",
      "training Loss: 0.0009 Acc: 86.0574\n",
      "validation Loss: 0.0009 Acc: 86.0238\n",
      "Epoch 21/99\n",
      "training Loss: 0.0009 Acc: 85.8848\n",
      "validation Loss: 0.0009 Acc: 86.0952\n",
      "Epoch 22/99\n",
      "training Loss: 0.0009 Acc: 86.0157\n",
      "validation Loss: 0.0009 Acc: 86.0952\n",
      "Epoch 23/99\n",
      "training Loss: 0.0009 Acc: 85.9800\n",
      "validation Loss: 0.0009 Acc: 85.9048\n",
      "Epoch 24/99\n",
      "training Loss: 0.0009 Acc: 85.8996\n",
      "validation Loss: 0.0009 Acc: 85.9524\n",
      "Early stopped.\n",
      "Best val acc: 86.166667\n",
      "----------\n",
      "Epoch 0/99\n",
      "training Loss: 0.0012 Acc: 80.6648\n",
      "validation Loss: 0.0011 Acc: 83.9048\n",
      "Saving..\n",
      "Epoch 1/99\n",
      "training Loss: 0.0011 Acc: 83.1974\n",
      "validation Loss: 0.0010 Acc: 84.3810\n",
      "Saving..\n",
      "Epoch 2/99\n",
      "training Loss: 0.0010 Acc: 84.0575\n",
      "validation Loss: 0.0010 Acc: 85.5238\n",
      "Saving..\n",
      "Epoch 3/99\n",
      "training Loss: 0.0010 Acc: 84.6973\n",
      "validation Loss: 0.0009 Acc: 85.6429\n",
      "Saving..\n",
      "Epoch 4/99\n",
      "training Loss: 0.0010 Acc: 84.9682\n",
      "validation Loss: 0.0010 Acc: 85.8333\n",
      "Saving..\n",
      "Epoch 5/99\n",
      "training Loss: 0.0009 Acc: 85.1408\n",
      "validation Loss: 0.0009 Acc: 86.0000\n",
      "Saving..\n",
      "Epoch 6/99\n",
      "training Loss: 0.0009 Acc: 85.2033\n",
      "validation Loss: 0.0009 Acc: 86.0476\n",
      "Saving..\n",
      "Epoch 7/99\n",
      "training Loss: 0.0009 Acc: 85.3461\n",
      "validation Loss: 0.0009 Acc: 86.0119\n",
      "Epoch 8/99\n",
      "training Loss: 0.0009 Acc: 85.3610\n",
      "validation Loss: 0.0009 Acc: 86.1548\n",
      "Saving..\n",
      "Epoch 9/99\n",
      "training Loss: 0.0009 Acc: 85.4205\n",
      "validation Loss: 0.0009 Acc: 85.9881\n",
      "Epoch 10/99\n",
      "training Loss: 0.0009 Acc: 85.4473\n",
      "validation Loss: 0.0009 Acc: 85.8571\n",
      "Epoch 11/99\n",
      "training Loss: 0.0009 Acc: 85.4622\n",
      "validation Loss: 0.0009 Acc: 86.1905\n",
      "Saving..\n",
      "Epoch 12/99\n",
      "training Loss: 0.0009 Acc: 85.6229\n",
      "validation Loss: 0.0009 Acc: 85.9048\n",
      "Epoch 13/99\n",
      "training Loss: 0.0009 Acc: 85.5693\n",
      "validation Loss: 0.0009 Acc: 85.9167\n",
      "Epoch 14/99\n",
      "training Loss: 0.0009 Acc: 85.5306\n",
      "validation Loss: 0.0009 Acc: 86.0238\n",
      "Epoch 15/99\n",
      "training Loss: 0.0009 Acc: 85.8014\n",
      "validation Loss: 0.0009 Acc: 86.0595\n",
      "Epoch 16/99\n",
      "training Loss: 0.0009 Acc: 85.6705\n",
      "validation Loss: 0.0009 Acc: 85.9524\n",
      "Epoch 17/99\n",
      "training Loss: 0.0009 Acc: 85.7122\n",
      "validation Loss: 0.0009 Acc: 86.2976\n",
      "Saving..\n",
      "Epoch 18/99\n",
      "training Loss: 0.0009 Acc: 85.7806\n",
      "validation Loss: 0.0009 Acc: 86.0833\n",
      "Epoch 19/99\n",
      "training Loss: 0.0009 Acc: 85.6586\n",
      "validation Loss: 0.0009 Acc: 86.1786\n",
      "Epoch 20/99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Loss: 0.0009 Acc: 85.8282\n",
      "validation Loss: 0.0009 Acc: 86.0119\n",
      "Epoch 21/99\n",
      "training Loss: 0.0009 Acc: 85.6794\n",
      "validation Loss: 0.0009 Acc: 86.2024\n",
      "Epoch 22/99\n",
      "training Loss: 0.0009 Acc: 85.9056\n",
      "validation Loss: 0.0009 Acc: 86.1310\n",
      "Epoch 23/99\n",
      "training Loss: 0.0009 Acc: 85.9413\n",
      "validation Loss: 0.0009 Acc: 86.2500\n",
      "Epoch 24/99\n",
      "training Loss: 0.0009 Acc: 85.8729\n",
      "validation Loss: 0.0009 Acc: 86.1548\n",
      "Epoch 25/99\n",
      "training Loss: 0.0009 Acc: 86.1705\n",
      "validation Loss: 0.0009 Acc: 86.5357\n",
      "Saving..\n",
      "Epoch 26/99\n",
      "training Loss: 0.0009 Acc: 86.1169\n",
      "validation Loss: 0.0009 Acc: 86.5357\n",
      "Epoch 27/99\n",
      "training Loss: 0.0009 Acc: 86.2955\n",
      "validation Loss: 0.0009 Acc: 86.4167\n",
      "Epoch 28/99\n",
      "training Loss: 0.0009 Acc: 86.2121\n",
      "validation Loss: 0.0009 Acc: 86.4286\n",
      "Epoch 29/99\n",
      "training Loss: 0.0009 Acc: 86.2657\n",
      "validation Loss: 0.0009 Acc: 86.2262\n",
      "Epoch 30/99\n",
      "training Loss: 0.0009 Acc: 86.2092\n",
      "validation Loss: 0.0009 Acc: 86.5714\n",
      "Saving..\n",
      "Epoch 31/99\n",
      "training Loss: 0.0009 Acc: 86.3550\n",
      "validation Loss: 0.0009 Acc: 86.5714\n",
      "Epoch 32/99\n",
      "training Loss: 0.0009 Acc: 86.3103\n",
      "validation Loss: 0.0009 Acc: 86.3810\n",
      "Epoch 33/99\n",
      "training Loss: 0.0009 Acc: 86.4472\n",
      "validation Loss: 0.0009 Acc: 86.6429\n",
      "Saving..\n",
      "Epoch 34/99\n",
      "training Loss: 0.0009 Acc: 86.4026\n",
      "validation Loss: 0.0009 Acc: 86.7143\n",
      "Saving..\n",
      "Epoch 35/99\n",
      "training Loss: 0.0009 Acc: 86.4949\n",
      "validation Loss: 0.0009 Acc: 86.6310\n",
      "Epoch 36/99\n",
      "training Loss: 0.0008 Acc: 86.6556\n",
      "validation Loss: 0.0009 Acc: 86.4881\n",
      "Epoch 37/99\n",
      "training Loss: 0.0009 Acc: 86.6942\n",
      "validation Loss: 0.0009 Acc: 86.5833\n",
      "Epoch 38/99\n",
      "training Loss: 0.0008 Acc: 86.7240\n",
      "validation Loss: 0.0009 Acc: 86.7500\n",
      "Saving..\n",
      "Epoch 39/99\n",
      "training Loss: 0.0008 Acc: 86.6288\n",
      "validation Loss: 0.0009 Acc: 86.5714\n",
      "Epoch 40/99\n",
      "training Loss: 0.0008 Acc: 86.5663\n",
      "validation Loss: 0.0009 Acc: 86.5714\n",
      "Epoch 41/99\n",
      "training Loss: 0.0008 Acc: 86.5960\n",
      "validation Loss: 0.0009 Acc: 86.5833\n",
      "Epoch 42/99\n",
      "training Loss: 0.0008 Acc: 86.6823\n",
      "validation Loss: 0.0009 Acc: 86.6310\n",
      "Epoch 43/99\n",
      "training Loss: 0.0008 Acc: 86.6704\n",
      "validation Loss: 0.0009 Acc: 86.7381\n",
      "Epoch 44/99\n",
      "training Loss: 0.0008 Acc: 86.7240\n",
      "validation Loss: 0.0009 Acc: 86.7619\n",
      "Saving..\n",
      "Epoch 45/99\n",
      "training Loss: 0.0008 Acc: 86.7984\n",
      "validation Loss: 0.0009 Acc: 86.7857\n",
      "Saving..\n",
      "Epoch 46/99\n",
      "training Loss: 0.0008 Acc: 86.7567\n",
      "validation Loss: 0.0009 Acc: 86.7143\n",
      "Epoch 47/99\n",
      "training Loss: 0.0008 Acc: 86.8549\n",
      "validation Loss: 0.0009 Acc: 86.6071\n",
      "Epoch 48/99\n",
      "training Loss: 0.0008 Acc: 86.7300\n",
      "validation Loss: 0.0009 Acc: 86.6667\n",
      "Epoch 49/99\n",
      "training Loss: 0.0008 Acc: 86.9621\n",
      "validation Loss: 0.0009 Acc: 86.6310\n",
      "Epoch 50/99\n",
      "training Loss: 0.0008 Acc: 86.8758\n",
      "validation Loss: 0.0009 Acc: 86.6310\n",
      "Epoch 51/99\n",
      "training Loss: 0.0008 Acc: 86.8877\n",
      "validation Loss: 0.0009 Acc: 86.6071\n",
      "Epoch 52/99\n",
      "training Loss: 0.0008 Acc: 86.8996\n",
      "validation Loss: 0.0009 Acc: 86.8095\n",
      "Saving..\n",
      "Epoch 53/99\n",
      "training Loss: 0.0008 Acc: 86.8490\n",
      "validation Loss: 0.0009 Acc: 86.7500\n",
      "Epoch 54/99\n",
      "training Loss: 0.0008 Acc: 86.9234\n",
      "validation Loss: 0.0009 Acc: 86.7619\n",
      "Epoch 55/99\n",
      "training Loss: 0.0008 Acc: 87.0395\n",
      "validation Loss: 0.0009 Acc: 86.8810\n",
      "Saving..\n",
      "Epoch 56/99\n",
      "training Loss: 0.0008 Acc: 86.9026\n",
      "validation Loss: 0.0009 Acc: 86.7381\n",
      "Epoch 57/99\n",
      "training Loss: 0.0008 Acc: 86.9413\n",
      "validation Loss: 0.0009 Acc: 86.7619\n",
      "Epoch 58/99\n",
      "training Loss: 0.0008 Acc: 86.8669\n",
      "validation Loss: 0.0009 Acc: 86.7619\n",
      "Epoch 59/99\n",
      "training Loss: 0.0008 Acc: 86.8639\n",
      "validation Loss: 0.0009 Acc: 86.7857\n",
      "Epoch 60/99\n",
      "training Loss: 0.0008 Acc: 86.9413\n",
      "validation Loss: 0.0009 Acc: 86.7262\n",
      "Epoch 61/99\n",
      "training Loss: 0.0008 Acc: 87.0067\n",
      "validation Loss: 0.0009 Acc: 86.7857\n",
      "Epoch 62/99\n",
      "training Loss: 0.0008 Acc: 86.8877\n",
      "validation Loss: 0.0009 Acc: 86.7619\n",
      "Epoch 63/99\n",
      "training Loss: 0.0008 Acc: 86.9710\n",
      "validation Loss: 0.0009 Acc: 86.8095\n",
      "Epoch 64/99\n",
      "training Loss: 0.0008 Acc: 86.8163\n",
      "validation Loss: 0.0009 Acc: 86.7738\n",
      "Epoch 65/99\n",
      "training Loss: 0.0008 Acc: 86.9651\n",
      "validation Loss: 0.0009 Acc: 86.7738\n",
      "Early stopped.\n",
      "Best val acc: 86.880952\n",
      "----------\n",
      "Epoch 0/99\n",
      "training Loss: 0.0012 Acc: 81.3523\n",
      "validation Loss: 0.0011 Acc: 83.5833\n",
      "Saving..\n",
      "Epoch 1/99\n",
      "training Loss: 0.0010 Acc: 83.5337\n",
      "validation Loss: 0.0010 Acc: 84.3095\n",
      "Saving..\n",
      "Epoch 2/99\n",
      "training Loss: 0.0010 Acc: 84.4474\n",
      "validation Loss: 0.0010 Acc: 85.1548\n",
      "Saving..\n",
      "Epoch 3/99\n",
      "training Loss: 0.0010 Acc: 84.8461\n",
      "validation Loss: 0.0010 Acc: 85.2619\n",
      "Saving..\n",
      "Epoch 4/99\n",
      "training Loss: 0.0010 Acc: 85.2419\n",
      "validation Loss: 0.0010 Acc: 84.9643\n",
      "Epoch 5/99\n",
      "training Loss: 0.0009 Acc: 85.4652\n",
      "validation Loss: 0.0010 Acc: 85.4881\n",
      "Saving..\n",
      "Epoch 6/99\n",
      "training Loss: 0.0009 Acc: 85.4622\n",
      "validation Loss: 0.0009 Acc: 85.6786\n",
      "Saving..\n",
      "Epoch 7/99\n",
      "training Loss: 0.0009 Acc: 85.4324\n",
      "validation Loss: 0.0009 Acc: 85.3810\n",
      "Epoch 8/99\n",
      "training Loss: 0.0009 Acc: 85.4741\n",
      "validation Loss: 0.0009 Acc: 85.5238\n",
      "Epoch 9/99\n",
      "training Loss: 0.0009 Acc: 85.5663\n",
      "validation Loss: 0.0010 Acc: 85.5714\n",
      "Epoch 10/99\n",
      "training Loss: 0.0009 Acc: 85.6288\n",
      "validation Loss: 0.0009 Acc: 85.5714\n",
      "Epoch 11/99\n",
      "training Loss: 0.0009 Acc: 85.6140\n",
      "validation Loss: 0.0010 Acc: 85.1071\n",
      "Epoch 12/99\n",
      "training Loss: 0.0009 Acc: 85.8907\n",
      "validation Loss: 0.0009 Acc: 85.4643\n",
      "Epoch 13/99\n",
      "training Loss: 0.0009 Acc: 85.6794\n",
      "validation Loss: 0.0009 Acc: 85.4762\n",
      "Epoch 14/99\n",
      "training Loss: 0.0009 Acc: 85.8163\n",
      "validation Loss: 0.0009 Acc: 85.8095\n",
      "Saving..\n",
      "Epoch 15/99\n",
      "training Loss: 0.0009 Acc: 85.9800\n",
      "validation Loss: 0.0009 Acc: 85.5238\n",
      "Epoch 16/99\n",
      "training Loss: 0.0009 Acc: 85.9681\n",
      "validation Loss: 0.0009 Acc: 85.5238\n",
      "Epoch 17/99\n",
      "training Loss: 0.0009 Acc: 85.7538\n",
      "validation Loss: 0.0010 Acc: 85.1310\n",
      "Epoch 18/99\n",
      "training Loss: 0.0009 Acc: 85.9562\n",
      "validation Loss: 0.0009 Acc: 85.5833\n",
      "Epoch 19/99\n",
      "training Loss: 0.0009 Acc: 86.0931\n",
      "validation Loss: 0.0009 Acc: 85.4643\n",
      "Epoch 20/99\n",
      "training Loss: 0.0009 Acc: 85.9919\n",
      "validation Loss: 0.0009 Acc: 85.5833\n",
      "Epoch 21/99\n",
      "training Loss: 0.0009 Acc: 85.9532\n",
      "validation Loss: 0.0009 Acc: 85.5357\n",
      "Epoch 22/99\n",
      "training Loss: 0.0009 Acc: 85.9354\n",
      "validation Loss: 0.0009 Acc: 85.8095\n",
      "Epoch 23/99\n",
      "training Loss: 0.0009 Acc: 86.1556\n",
      "validation Loss: 0.0009 Acc: 85.0000\n",
      "Epoch 24/99\n",
      "training Loss: 0.0009 Acc: 86.1318\n",
      "validation Loss: 0.0009 Acc: 85.2381\n",
      "Early stopped.\n",
      "Best val acc: 85.809524\n",
      "----------\n",
      "Epoch 0/99\n",
      "training Loss: 0.0012 Acc: 81.3315\n",
      "validation Loss: 0.0011 Acc: 83.4881\n",
      "Saving..\n",
      "Epoch 1/99\n",
      "training Loss: 0.0010 Acc: 83.6409\n",
      "validation Loss: 0.0011 Acc: 83.3929\n",
      "Epoch 2/99\n",
      "training Loss: 0.0010 Acc: 84.3164\n",
      "validation Loss: 0.0010 Acc: 84.9762\n",
      "Saving..\n",
      "Epoch 3/99\n",
      "training Loss: 0.0010 Acc: 84.9682\n",
      "validation Loss: 0.0010 Acc: 84.7262\n",
      "Epoch 4/99\n",
      "training Loss: 0.0010 Acc: 85.0961\n",
      "validation Loss: 0.0010 Acc: 85.1667\n",
      "Saving..\n",
      "Epoch 5/99\n",
      "training Loss: 0.0009 Acc: 85.2628\n",
      "validation Loss: 0.0010 Acc: 85.2500\n",
      "Saving..\n",
      "Epoch 6/99\n",
      "training Loss: 0.0009 Acc: 85.4711\n",
      "validation Loss: 0.0010 Acc: 84.9167\n",
      "Epoch 7/99\n",
      "training Loss: 0.0009 Acc: 85.5068\n",
      "validation Loss: 0.0010 Acc: 84.9762\n",
      "Epoch 8/99\n",
      "training Loss: 0.0009 Acc: 85.5247\n",
      "validation Loss: 0.0010 Acc: 85.3452\n",
      "Saving..\n",
      "Epoch 9/99\n",
      "training Loss: 0.0009 Acc: 85.6080\n",
      "validation Loss: 0.0010 Acc: 85.4048\n",
      "Saving..\n",
      "Epoch 10/99\n",
      "training Loss: 0.0009 Acc: 85.5366\n",
      "validation Loss: 0.0009 Acc: 85.4048\n",
      "Epoch 11/99\n",
      "training Loss: 0.0009 Acc: 85.6794\n",
      "validation Loss: 0.0010 Acc: 85.2738\n",
      "Epoch 12/99\n",
      "training Loss: 0.0009 Acc: 85.5574\n",
      "validation Loss: 0.0010 Acc: 85.5119\n",
      "Saving..\n",
      "Epoch 13/99\n",
      "training Loss: 0.0009 Acc: 85.7806\n",
      "validation Loss: 0.0009 Acc: 85.6548\n",
      "Saving..\n",
      "Epoch 14/99\n",
      "training Loss: 0.0009 Acc: 85.7925\n",
      "validation Loss: 0.0009 Acc: 85.4762\n",
      "Epoch 15/99\n",
      "training Loss: 0.0009 Acc: 85.8907\n",
      "validation Loss: 0.0009 Acc: 85.5357\n",
      "Epoch 16/99\n",
      "training Loss: 0.0009 Acc: 86.0723\n",
      "validation Loss: 0.0009 Acc: 85.8333\n",
      "Saving..\n",
      "Epoch 17/99\n",
      "training Loss: 0.0009 Acc: 85.7866\n",
      "validation Loss: 0.0009 Acc: 85.6429\n",
      "Epoch 18/99\n",
      "training Loss: 0.0009 Acc: 86.0842\n",
      "validation Loss: 0.0009 Acc: 85.5476\n",
      "Epoch 19/99\n",
      "training Loss: 0.0009 Acc: 85.9592\n",
      "validation Loss: 0.0009 Acc: 85.5833\n",
      "Epoch 20/99\n",
      "training Loss: 0.0009 Acc: 86.1318\n",
      "validation Loss: 0.0009 Acc: 85.5833\n",
      "Epoch 21/99\n",
      "training Loss: 0.0009 Acc: 86.0455\n",
      "validation Loss: 0.0009 Acc: 85.7500\n",
      "Epoch 22/99\n",
      "training Loss: 0.0009 Acc: 86.0276\n",
      "validation Loss: 0.0009 Acc: 85.8095\n",
      "Epoch 23/99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Loss: 0.0009 Acc: 86.1258\n",
      "validation Loss: 0.0009 Acc: 85.5595\n",
      "Epoch 24/99\n",
      "training Loss: 0.0009 Acc: 86.2121\n",
      "validation Loss: 0.0009 Acc: 85.7857\n",
      "Epoch 25/99\n",
      "training Loss: 0.0009 Acc: 86.0931\n",
      "validation Loss: 0.0009 Acc: 85.5476\n",
      "Epoch 26/99\n",
      "training Loss: 0.0009 Acc: 86.1973\n",
      "validation Loss: 0.0009 Acc: 85.7143\n",
      "Early stopped.\n",
      "Best val acc: 85.833333\n",
      "----------\n",
      "Average best_acc across k-fold: 86.1387617461\n",
      "New configuration: {'hidden_layers': 2, 'dropout_g': 0.4315043732185252, 'initial_nodes': 295, 'dropout': 0.4882621742096196, 'gru_layers': 3, 'batch_size': 386, 'gru_size': 62, 'learning_rate': 5.5632602056985624e-05}\n",
      "Epoch 0/99\n",
      "training Loss: 0.0017 Acc: 60.9315\n",
      "validation Loss: 0.0016 Acc: 75.1012\n",
      "Saving..\n",
      "Epoch 1/99\n",
      "training Loss: 0.0015 Acc: 74.1220\n",
      "validation Loss: 0.0013 Acc: 78.0528\n",
      "Saving..\n",
      "Epoch 2/99\n",
      "training Loss: 0.0013 Acc: 77.2173\n",
      "validation Loss: 0.0012 Acc: 79.8143\n",
      "Saving..\n",
      "Epoch 3/99\n",
      "training Loss: 0.0012 Acc: 78.6815\n",
      "validation Loss: 0.0011 Acc: 81.2188\n",
      "Saving..\n",
      "Epoch 4/99\n",
      "training Loss: 0.0012 Acc: 79.9405\n",
      "validation Loss: 0.0010 Acc: 82.3137\n",
      "Saving..\n",
      "Epoch 5/99\n",
      "training Loss: 0.0011 Acc: 80.6905\n",
      "validation Loss: 0.0010 Acc: 82.6708\n",
      "Saving..\n",
      "Epoch 6/99\n",
      "training Loss: 0.0011 Acc: 81.4881\n",
      "validation Loss: 0.0010 Acc: 83.2183\n",
      "Saving..\n",
      "Epoch 7/99\n",
      "training Loss: 0.0011 Acc: 81.9435\n",
      "validation Loss: 0.0010 Acc: 83.5515\n",
      "Saving..\n",
      "Epoch 8/99\n",
      "training Loss: 0.0011 Acc: 82.1339\n",
      "validation Loss: 0.0010 Acc: 83.8610\n",
      "Saving..\n",
      "Epoch 9/99\n",
      "training Loss: 0.0010 Acc: 82.2619\n",
      "validation Loss: 0.0009 Acc: 83.9562\n",
      "Saving..\n",
      "Epoch 10/99\n",
      "training Loss: 0.0010 Acc: 82.4673\n",
      "validation Loss: 0.0009 Acc: 84.0276\n",
      "Saving..\n",
      "Epoch 11/99\n",
      "training Loss: 0.0010 Acc: 82.4911\n",
      "validation Loss: 0.0009 Acc: 84.1466\n",
      "Saving..\n",
      "Epoch 12/99\n",
      "training Loss: 0.0010 Acc: 82.6161\n",
      "validation Loss: 0.0009 Acc: 84.1466\n",
      "Epoch 13/99\n",
      "training Loss: 0.0010 Acc: 82.7024\n",
      "validation Loss: 0.0009 Acc: 84.2061\n",
      "Saving..\n",
      "Epoch 14/99\n",
      "training Loss: 0.0010 Acc: 82.7946\n",
      "validation Loss: 0.0009 Acc: 84.1585\n",
      "Epoch 15/99\n",
      "training Loss: 0.0010 Acc: 82.8542\n",
      "validation Loss: 0.0009 Acc: 84.2895\n",
      "Saving..\n",
      "Epoch 16/99\n",
      "training Loss: 0.0010 Acc: 82.9405\n",
      "validation Loss: 0.0009 Acc: 84.2061\n",
      "Epoch 17/99\n",
      "training Loss: 0.0010 Acc: 82.6845\n",
      "validation Loss: 0.0009 Acc: 84.2657\n",
      "Epoch 18/99\n",
      "training Loss: 0.0010 Acc: 82.8571\n",
      "validation Loss: 0.0009 Acc: 84.3133\n",
      "Saving..\n",
      "Epoch 19/99\n",
      "training Loss: 0.0010 Acc: 82.8601\n",
      "validation Loss: 0.0009 Acc: 84.2299\n",
      "Epoch 20/99\n",
      "training Loss: 0.0010 Acc: 82.9613\n",
      "validation Loss: 0.0009 Acc: 84.3133\n",
      "Epoch 21/99\n",
      "training Loss: 0.0010 Acc: 82.9762\n",
      "validation Loss: 0.0009 Acc: 84.3490\n",
      "Saving..\n",
      "Epoch 22/99\n",
      "training Loss: 0.0010 Acc: 83.0685\n",
      "validation Loss: 0.0009 Acc: 84.3966\n",
      "Saving..\n",
      "Epoch 23/99\n",
      "training Loss: 0.0010 Acc: 83.0595\n",
      "validation Loss: 0.0009 Acc: 84.4561\n",
      "Saving..\n",
      "Epoch 24/99\n",
      "training Loss: 0.0010 Acc: 83.0179\n",
      "validation Loss: 0.0009 Acc: 84.3014\n",
      "Epoch 25/99\n",
      "training Loss: 0.0010 Acc: 83.0595\n",
      "validation Loss: 0.0009 Acc: 84.4561\n",
      "Epoch 26/99\n",
      "training Loss: 0.0010 Acc: 83.0714\n",
      "validation Loss: 0.0009 Acc: 84.3966\n",
      "Epoch 27/99\n",
      "training Loss: 0.0010 Acc: 83.3244\n",
      "validation Loss: 0.0009 Acc: 84.4680\n",
      "Saving..\n",
      "Epoch 28/99\n",
      "training Loss: 0.0010 Acc: 83.1190\n",
      "validation Loss: 0.0009 Acc: 84.4799\n",
      "Saving..\n",
      "Epoch 29/99\n",
      "training Loss: 0.0010 Acc: 83.4018\n",
      "validation Loss: 0.0009 Acc: 84.4442\n",
      "Epoch 30/99\n",
      "training Loss: 0.0010 Acc: 83.1875\n",
      "validation Loss: 0.0009 Acc: 84.4204\n",
      "Epoch 31/99\n",
      "training Loss: 0.0010 Acc: 83.2917\n",
      "validation Loss: 0.0009 Acc: 84.5394\n",
      "Saving..\n",
      "Epoch 32/99\n",
      "training Loss: 0.0010 Acc: 83.2708\n",
      "validation Loss: 0.0009 Acc: 84.6108\n",
      "Saving..\n",
      "Epoch 33/99\n",
      "training Loss: 0.0010 Acc: 83.4107\n",
      "validation Loss: 0.0009 Acc: 84.6346\n",
      "Saving..\n",
      "Epoch 34/99\n",
      "training Loss: 0.0010 Acc: 83.1935\n",
      "validation Loss: 0.0009 Acc: 84.6465\n",
      "Saving..\n",
      "Epoch 35/99\n",
      "training Loss: 0.0010 Acc: 83.5179\n",
      "validation Loss: 0.0009 Acc: 84.6941\n",
      "Saving..\n",
      "Epoch 36/99\n",
      "training Loss: 0.0010 Acc: 83.4315\n",
      "validation Loss: 0.0009 Acc: 84.6822\n",
      "Epoch 37/99\n",
      "training Loss: 0.0010 Acc: 83.4881\n",
      "validation Loss: 0.0009 Acc: 84.5394\n",
      "Epoch 38/99\n",
      "training Loss: 0.0010 Acc: 83.5060\n",
      "validation Loss: 0.0009 Acc: 84.7417\n",
      "Saving..\n",
      "Epoch 39/99\n",
      "training Loss: 0.0010 Acc: 83.5119\n",
      "validation Loss: 0.0009 Acc: 84.8726\n",
      "Saving..\n",
      "Epoch 40/99\n",
      "training Loss: 0.0010 Acc: 83.4077\n",
      "validation Loss: 0.0009 Acc: 84.8607\n",
      "Epoch 41/99\n",
      "training Loss: 0.0010 Acc: 83.5446\n",
      "validation Loss: 0.0009 Acc: 84.8607\n",
      "Epoch 42/99\n",
      "training Loss: 0.0010 Acc: 83.6786\n",
      "validation Loss: 0.0009 Acc: 84.8250\n",
      "Epoch 43/99\n",
      "training Loss: 0.0010 Acc: 83.7143\n",
      "validation Loss: 0.0009 Acc: 84.9084\n",
      "Saving..\n",
      "Epoch 44/99\n",
      "training Loss: 0.0010 Acc: 83.7530\n",
      "validation Loss: 0.0009 Acc: 84.9322\n",
      "Saving..\n",
      "Epoch 45/99\n",
      "training Loss: 0.0010 Acc: 83.7887\n",
      "validation Loss: 0.0009 Acc: 84.9917\n",
      "Saving..\n",
      "Epoch 46/99\n",
      "training Loss: 0.0010 Acc: 83.8244\n",
      "validation Loss: 0.0009 Acc: 85.0512\n",
      "Saving..\n",
      "Epoch 47/99\n",
      "training Loss: 0.0010 Acc: 83.7798\n",
      "validation Loss: 0.0009 Acc: 84.9798\n",
      "Epoch 48/99\n",
      "training Loss: 0.0010 Acc: 83.8988\n",
      "validation Loss: 0.0009 Acc: 85.0631\n",
      "Saving..\n",
      "Epoch 49/99\n",
      "training Loss: 0.0010 Acc: 84.0208\n",
      "validation Loss: 0.0009 Acc: 85.0869\n",
      "Saving..\n",
      "Epoch 50/99\n",
      "training Loss: 0.0010 Acc: 83.8988\n",
      "validation Loss: 0.0009 Acc: 85.1583\n",
      "Saving..\n",
      "Epoch 51/99\n",
      "training Loss: 0.0010 Acc: 84.0714\n",
      "validation Loss: 0.0009 Acc: 85.2059\n",
      "Saving..\n",
      "Epoch 52/99\n",
      "training Loss: 0.0010 Acc: 83.9732\n",
      "validation Loss: 0.0009 Acc: 85.2297\n",
      "Saving..\n",
      "Epoch 53/99\n",
      "training Loss: 0.0010 Acc: 84.0744\n",
      "validation Loss: 0.0009 Acc: 85.2654\n",
      "Saving..\n",
      "Epoch 54/99\n",
      "training Loss: 0.0010 Acc: 83.9792\n",
      "validation Loss: 0.0009 Acc: 85.3130\n",
      "Saving..\n",
      "Epoch 55/99\n",
      "training Loss: 0.0010 Acc: 84.2113\n",
      "validation Loss: 0.0009 Acc: 85.3011\n",
      "Epoch 56/99\n",
      "training Loss: 0.0010 Acc: 84.2113\n",
      "validation Loss: 0.0009 Acc: 85.3844\n",
      "Saving..\n",
      "Epoch 57/99\n",
      "training Loss: 0.0010 Acc: 84.2292\n",
      "validation Loss: 0.0009 Acc: 85.5273\n",
      "Saving..\n",
      "Epoch 58/99\n",
      "training Loss: 0.0010 Acc: 84.2024\n",
      "validation Loss: 0.0009 Acc: 85.5273\n",
      "Epoch 59/99\n",
      "training Loss: 0.0009 Acc: 84.4405\n",
      "validation Loss: 0.0009 Acc: 85.5868\n",
      "Saving..\n",
      "Epoch 60/99\n",
      "training Loss: 0.0010 Acc: 84.3244\n",
      "validation Loss: 0.0009 Acc: 85.6225\n",
      "Saving..\n",
      "Epoch 61/99\n",
      "training Loss: 0.0009 Acc: 84.3839\n",
      "validation Loss: 0.0009 Acc: 85.6582\n",
      "Saving..\n",
      "Epoch 62/99\n",
      "training Loss: 0.0009 Acc: 84.3393\n",
      "validation Loss: 0.0009 Acc: 85.7534\n",
      "Saving..\n",
      "Epoch 63/99\n",
      "training Loss: 0.0010 Acc: 84.4643\n",
      "validation Loss: 0.0009 Acc: 85.7534\n",
      "Epoch 64/99\n",
      "training Loss: 0.0009 Acc: 84.2530\n",
      "validation Loss: 0.0009 Acc: 85.6939\n",
      "Epoch 65/99\n",
      "training Loss: 0.0010 Acc: 84.2679\n",
      "validation Loss: 0.0009 Acc: 85.7415\n",
      "Epoch 66/99\n",
      "training Loss: 0.0009 Acc: 84.4494\n",
      "validation Loss: 0.0009 Acc: 85.8129\n",
      "Saving..\n",
      "Epoch 67/99\n",
      "training Loss: 0.0009 Acc: 84.3452\n",
      "validation Loss: 0.0008 Acc: 85.8129\n",
      "Epoch 68/99\n",
      "training Loss: 0.0009 Acc: 84.4613\n",
      "validation Loss: 0.0008 Acc: 85.8486\n",
      "Saving..\n",
      "Epoch 69/99\n",
      "training Loss: 0.0009 Acc: 84.4375\n",
      "validation Loss: 0.0008 Acc: 85.8724\n",
      "Saving..\n",
      "Epoch 70/99\n",
      "training Loss: 0.0009 Acc: 84.4911\n",
      "validation Loss: 0.0008 Acc: 85.9319\n",
      "Saving..\n",
      "Epoch 71/99\n",
      "training Loss: 0.0009 Acc: 84.3720\n",
      "validation Loss: 0.0008 Acc: 85.8605\n",
      "Epoch 72/99\n",
      "training Loss: 0.0009 Acc: 84.5863\n",
      "validation Loss: 0.0008 Acc: 85.9557\n",
      "Saving..\n",
      "Epoch 73/99\n",
      "training Loss: 0.0009 Acc: 84.5863\n",
      "validation Loss: 0.0008 Acc: 85.9200\n",
      "Epoch 74/99\n",
      "training Loss: 0.0009 Acc: 84.6518\n",
      "validation Loss: 0.0008 Acc: 85.9081\n",
      "Epoch 75/99\n",
      "training Loss: 0.0009 Acc: 84.5833\n",
      "validation Loss: 0.0008 Acc: 85.9081\n",
      "Epoch 76/99\n",
      "training Loss: 0.0009 Acc: 84.5744\n",
      "validation Loss: 0.0008 Acc: 85.9795\n",
      "Saving..\n",
      "Epoch 77/99\n",
      "training Loss: 0.0009 Acc: 84.6250\n",
      "validation Loss: 0.0008 Acc: 86.0152\n",
      "Saving..\n",
      "Epoch 78/99\n",
      "training Loss: 0.0009 Acc: 84.6935\n",
      "validation Loss: 0.0008 Acc: 86.0152\n",
      "Epoch 79/99\n",
      "training Loss: 0.0009 Acc: 84.5417\n",
      "validation Loss: 0.0008 Acc: 85.9676\n",
      "Epoch 80/99\n",
      "training Loss: 0.0009 Acc: 84.5030\n",
      "validation Loss: 0.0008 Acc: 85.9914\n",
      "Epoch 81/99\n",
      "training Loss: 0.0009 Acc: 84.4702\n",
      "validation Loss: 0.0008 Acc: 86.0033\n",
      "Epoch 82/99\n",
      "training Loss: 0.0009 Acc: 84.6012\n",
      "validation Loss: 0.0008 Acc: 85.9557\n",
      "Epoch 83/99\n",
      "training Loss: 0.0009 Acc: 84.6637\n",
      "validation Loss: 0.0008 Acc: 86.0866\n",
      "Saving..\n",
      "Epoch 84/99\n",
      "training Loss: 0.0009 Acc: 84.6042\n",
      "validation Loss: 0.0008 Acc: 85.9557\n",
      "Epoch 85/99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Loss: 0.0009 Acc: 84.4792\n",
      "validation Loss: 0.0008 Acc: 86.0628\n",
      "Epoch 86/99\n",
      "training Loss: 0.0009 Acc: 84.5952\n",
      "validation Loss: 0.0008 Acc: 86.0033\n",
      "Epoch 87/99\n",
      "training Loss: 0.0009 Acc: 84.5744\n",
      "validation Loss: 0.0008 Acc: 86.0271\n",
      "Epoch 88/99\n",
      "training Loss: 0.0009 Acc: 84.7321\n",
      "validation Loss: 0.0008 Acc: 86.0271\n",
      "Epoch 89/99\n",
      "training Loss: 0.0009 Acc: 84.7827\n",
      "validation Loss: 0.0008 Acc: 86.0985\n",
      "Saving..\n",
      "Epoch 90/99\n",
      "training Loss: 0.0009 Acc: 84.6518\n",
      "validation Loss: 0.0008 Acc: 86.0866\n",
      "Epoch 91/99\n",
      "training Loss: 0.0009 Acc: 84.7798\n",
      "validation Loss: 0.0008 Acc: 86.1462\n",
      "Saving..\n",
      "Epoch 92/99\n",
      "training Loss: 0.0009 Acc: 84.7500\n",
      "validation Loss: 0.0008 Acc: 86.0866\n",
      "Epoch 93/99\n",
      "training Loss: 0.0009 Acc: 84.6369\n",
      "validation Loss: 0.0008 Acc: 86.0866\n",
      "Epoch 94/99\n",
      "training Loss: 0.0009 Acc: 84.7173\n",
      "validation Loss: 0.0008 Acc: 86.1104\n",
      "Epoch 95/99\n",
      "training Loss: 0.0009 Acc: 84.6696\n",
      "validation Loss: 0.0008 Acc: 86.1224\n",
      "Epoch 96/99\n",
      "training Loss: 0.0009 Acc: 84.8512\n",
      "validation Loss: 0.0008 Acc: 86.1224\n",
      "Epoch 97/99\n",
      "training Loss: 0.0009 Acc: 84.7202\n",
      "validation Loss: 0.0008 Acc: 86.0390\n",
      "Epoch 98/99\n",
      "training Loss: 0.0009 Acc: 84.6964\n",
      "validation Loss: 0.0008 Acc: 86.1224\n",
      "Epoch 99/99\n",
      "training Loss: 0.0009 Acc: 84.6964\n",
      "validation Loss: 0.0008 Acc: 86.1343\n",
      "Best val acc: 86.146156\n",
      "----------\n",
      "Epoch 0/99\n",
      "training Loss: 0.0017 Acc: 62.6094\n",
      "validation Loss: 0.0016 Acc: 74.7381\n",
      "Saving..\n",
      "Epoch 1/99\n",
      "training Loss: 0.0015 Acc: 74.5759\n",
      "validation Loss: 0.0013 Acc: 76.2024\n",
      "Saving..\n",
      "Epoch 2/99\n",
      "training Loss: 0.0013 Acc: 77.0252\n",
      "validation Loss: 0.0012 Acc: 77.9881\n",
      "Saving..\n",
      "Epoch 3/99\n",
      "training Loss: 0.0012 Acc: 78.5548\n",
      "validation Loss: 0.0012 Acc: 79.2857\n",
      "Saving..\n",
      "Epoch 4/99\n",
      "training Loss: 0.0012 Acc: 79.8286\n",
      "validation Loss: 0.0011 Acc: 80.1905\n",
      "Saving..\n",
      "Epoch 5/99\n",
      "training Loss: 0.0011 Acc: 80.5547\n",
      "validation Loss: 0.0011 Acc: 81.0714\n",
      "Saving..\n",
      "Epoch 6/99\n",
      "training Loss: 0.0011 Acc: 81.0815\n",
      "validation Loss: 0.0010 Acc: 81.6429\n",
      "Saving..\n",
      "Epoch 7/99\n",
      "training Loss: 0.0011 Acc: 81.6142\n",
      "validation Loss: 0.0010 Acc: 82.0476\n",
      "Saving..\n",
      "Epoch 8/99\n",
      "training Loss: 0.0011 Acc: 82.0487\n",
      "validation Loss: 0.0010 Acc: 82.5357\n",
      "Saving..\n",
      "Epoch 9/99\n",
      "training Loss: 0.0010 Acc: 82.3046\n",
      "validation Loss: 0.0010 Acc: 82.9524\n",
      "Saving..\n",
      "Epoch 10/99\n",
      "training Loss: 0.0010 Acc: 82.3909\n",
      "validation Loss: 0.0010 Acc: 83.1310\n",
      "Saving..\n",
      "Epoch 11/99\n",
      "training Loss: 0.0010 Acc: 82.7600\n",
      "validation Loss: 0.0010 Acc: 83.1429\n",
      "Saving..\n",
      "Epoch 12/99\n",
      "training Loss: 0.0010 Acc: 82.7778\n",
      "validation Loss: 0.0010 Acc: 83.1786\n",
      "Saving..\n",
      "Epoch 13/99\n",
      "training Loss: 0.0010 Acc: 82.7064\n",
      "validation Loss: 0.0010 Acc: 83.2738\n",
      "Saving..\n",
      "Epoch 14/99\n",
      "training Loss: 0.0010 Acc: 82.8760\n",
      "validation Loss: 0.0010 Acc: 83.3214\n",
      "Saving..\n",
      "Epoch 15/99\n",
      "training Loss: 0.0010 Acc: 82.8671\n",
      "validation Loss: 0.0010 Acc: 83.2619\n",
      "Epoch 16/99\n",
      "training Loss: 0.0010 Acc: 83.0576\n",
      "validation Loss: 0.0010 Acc: 83.4167\n",
      "Saving..\n",
      "Epoch 17/99\n",
      "training Loss: 0.0010 Acc: 82.9772\n",
      "validation Loss: 0.0010 Acc: 83.3333\n",
      "Epoch 18/99\n",
      "training Loss: 0.0010 Acc: 83.3016\n",
      "validation Loss: 0.0010 Acc: 83.5357\n",
      "Saving..\n",
      "Epoch 19/99\n",
      "training Loss: 0.0010 Acc: 83.0695\n",
      "validation Loss: 0.0010 Acc: 83.4643\n",
      "Epoch 20/99\n",
      "training Loss: 0.0010 Acc: 83.0992\n",
      "validation Loss: 0.0010 Acc: 83.5476\n",
      "Saving..\n",
      "Epoch 21/99\n",
      "training Loss: 0.0010 Acc: 83.1974\n",
      "validation Loss: 0.0010 Acc: 83.5952\n",
      "Saving..\n",
      "Epoch 22/99\n",
      "training Loss: 0.0010 Acc: 83.2272\n",
      "validation Loss: 0.0010 Acc: 83.6310\n",
      "Saving..\n",
      "Epoch 23/99\n",
      "training Loss: 0.0010 Acc: 83.2718\n",
      "validation Loss: 0.0010 Acc: 83.6310\n",
      "Epoch 24/99\n",
      "training Loss: 0.0010 Acc: 83.3016\n",
      "validation Loss: 0.0010 Acc: 83.7024\n",
      "Saving..\n",
      "Epoch 25/99\n",
      "training Loss: 0.0010 Acc: 83.2986\n",
      "validation Loss: 0.0010 Acc: 83.4762\n",
      "Epoch 26/99\n",
      "training Loss: 0.0010 Acc: 83.4415\n",
      "validation Loss: 0.0010 Acc: 83.6310\n",
      "Epoch 27/99\n",
      "training Loss: 0.0010 Acc: 83.3403\n",
      "validation Loss: 0.0010 Acc: 83.7381\n",
      "Saving..\n",
      "Epoch 28/99\n",
      "training Loss: 0.0010 Acc: 83.3165\n",
      "validation Loss: 0.0010 Acc: 83.7143\n",
      "Epoch 29/99\n",
      "training Loss: 0.0010 Acc: 83.3522\n",
      "validation Loss: 0.0010 Acc: 83.7857\n",
      "Saving..\n",
      "Epoch 30/99\n",
      "training Loss: 0.0010 Acc: 83.2659\n",
      "validation Loss: 0.0010 Acc: 83.8333\n",
      "Saving..\n",
      "Epoch 31/99\n",
      "training Loss: 0.0010 Acc: 83.4712\n",
      "validation Loss: 0.0010 Acc: 83.8214\n",
      "Epoch 32/99\n",
      "training Loss: 0.0010 Acc: 83.3462\n",
      "validation Loss: 0.0010 Acc: 83.7857\n",
      "Epoch 33/99\n",
      "training Loss: 0.0010 Acc: 83.6647\n",
      "validation Loss: 0.0010 Acc: 83.8571\n",
      "Saving..\n",
      "Epoch 34/99\n",
      "training Loss: 0.0010 Acc: 83.5278\n",
      "validation Loss: 0.0010 Acc: 83.9167\n",
      "Saving..\n",
      "Epoch 35/99\n",
      "training Loss: 0.0010 Acc: 83.6200\n",
      "validation Loss: 0.0010 Acc: 83.9881\n",
      "Saving..\n",
      "Epoch 36/99\n",
      "training Loss: 0.0010 Acc: 83.5635\n",
      "validation Loss: 0.0010 Acc: 83.9881\n",
      "Epoch 37/99\n",
      "training Loss: 0.0010 Acc: 83.6111\n",
      "validation Loss: 0.0010 Acc: 84.0000\n",
      "Saving..\n",
      "Epoch 38/99\n",
      "training Loss: 0.0010 Acc: 83.6528\n",
      "validation Loss: 0.0010 Acc: 84.0119\n",
      "Saving..\n",
      "Epoch 39/99\n",
      "training Loss: 0.0010 Acc: 83.7956\n",
      "validation Loss: 0.0010 Acc: 84.0000\n",
      "Epoch 40/99\n",
      "training Loss: 0.0010 Acc: 83.6766\n",
      "validation Loss: 0.0009 Acc: 84.1310\n",
      "Saving..\n",
      "Epoch 41/99\n",
      "training Loss: 0.0010 Acc: 83.8075\n",
      "validation Loss: 0.0009 Acc: 84.0357\n",
      "Epoch 42/99\n",
      "training Loss: 0.0010 Acc: 83.7986\n",
      "validation Loss: 0.0009 Acc: 84.0714\n",
      "Epoch 43/99\n",
      "training Loss: 0.0010 Acc: 83.7182\n",
      "validation Loss: 0.0009 Acc: 84.1071\n",
      "Epoch 44/99\n",
      "training Loss: 0.0010 Acc: 83.8432\n",
      "validation Loss: 0.0009 Acc: 84.2262\n",
      "Saving..\n",
      "Epoch 45/99\n",
      "training Loss: 0.0010 Acc: 83.8492\n",
      "validation Loss: 0.0009 Acc: 84.1786\n",
      "Epoch 46/99\n",
      "training Loss: 0.0010 Acc: 83.8670\n",
      "validation Loss: 0.0009 Acc: 84.2619\n",
      "Saving..\n",
      "Epoch 47/99\n",
      "training Loss: 0.0010 Acc: 83.8254\n",
      "validation Loss: 0.0009 Acc: 84.1667\n",
      "Epoch 48/99\n",
      "training Loss: 0.0010 Acc: 84.0010\n",
      "validation Loss: 0.0009 Acc: 84.2381\n",
      "Epoch 49/99\n",
      "training Loss: 0.0010 Acc: 84.0069\n",
      "validation Loss: 0.0009 Acc: 84.2857\n",
      "Saving..\n",
      "Epoch 50/99\n",
      "training Loss: 0.0010 Acc: 84.0634\n",
      "validation Loss: 0.0009 Acc: 84.3095\n",
      "Saving..\n",
      "Epoch 51/99\n",
      "training Loss: 0.0010 Acc: 84.0962\n",
      "validation Loss: 0.0009 Acc: 84.2857\n",
      "Epoch 52/99\n",
      "training Loss: 0.0010 Acc: 84.0932\n",
      "validation Loss: 0.0009 Acc: 84.2738\n",
      "Epoch 53/99\n",
      "training Loss: 0.0010 Acc: 84.0902\n",
      "validation Loss: 0.0009 Acc: 84.3571\n",
      "Saving..\n",
      "Epoch 54/99\n",
      "training Loss: 0.0010 Acc: 84.2569\n",
      "validation Loss: 0.0009 Acc: 84.4405\n",
      "Saving..\n",
      "Epoch 55/99\n",
      "training Loss: 0.0010 Acc: 84.0724\n",
      "validation Loss: 0.0009 Acc: 84.4643\n",
      "Saving..\n",
      "Epoch 56/99\n",
      "training Loss: 0.0010 Acc: 84.2866\n",
      "validation Loss: 0.0009 Acc: 84.4643\n",
      "Epoch 57/99\n",
      "training Loss: 0.0010 Acc: 84.1587\n",
      "validation Loss: 0.0009 Acc: 84.5476\n",
      "Saving..\n",
      "Epoch 58/99\n",
      "training Loss: 0.0009 Acc: 84.2718\n",
      "validation Loss: 0.0009 Acc: 84.6310\n",
      "Saving..\n",
      "Epoch 59/99\n",
      "training Loss: 0.0009 Acc: 84.2718\n",
      "validation Loss: 0.0009 Acc: 84.6429\n",
      "Saving..\n",
      "Epoch 60/99\n",
      "training Loss: 0.0009 Acc: 84.2599\n",
      "validation Loss: 0.0009 Acc: 84.6786\n",
      "Saving..\n",
      "Epoch 61/99\n",
      "training Loss: 0.0009 Acc: 84.3849\n",
      "validation Loss: 0.0009 Acc: 84.5595\n",
      "Epoch 62/99\n",
      "training Loss: 0.0009 Acc: 84.5188\n",
      "validation Loss: 0.0009 Acc: 84.7619\n",
      "Saving..\n",
      "Epoch 63/99\n",
      "training Loss: 0.0009 Acc: 84.5783\n",
      "validation Loss: 0.0009 Acc: 84.8095\n",
      "Saving..\n",
      "Epoch 64/99\n",
      "training Loss: 0.0009 Acc: 84.4712\n",
      "validation Loss: 0.0009 Acc: 84.8810\n",
      "Saving..\n",
      "Epoch 65/99\n",
      "training Loss: 0.0009 Acc: 84.7152\n",
      "validation Loss: 0.0009 Acc: 84.9405\n",
      "Saving..\n",
      "Epoch 66/99\n",
      "training Loss: 0.0009 Acc: 84.4831\n",
      "validation Loss: 0.0009 Acc: 85.0714\n",
      "Saving..\n",
      "Epoch 67/99\n",
      "training Loss: 0.0009 Acc: 84.6110\n",
      "validation Loss: 0.0009 Acc: 84.9167\n",
      "Epoch 68/99\n",
      "training Loss: 0.0009 Acc: 84.5962\n",
      "validation Loss: 0.0009 Acc: 84.9167\n",
      "Epoch 69/99\n",
      "training Loss: 0.0009 Acc: 84.6408\n",
      "validation Loss: 0.0009 Acc: 85.0238\n",
      "Epoch 70/99\n",
      "training Loss: 0.0009 Acc: 84.5485\n",
      "validation Loss: 0.0009 Acc: 85.0952\n",
      "Saving..\n",
      "Epoch 71/99\n",
      "training Loss: 0.0009 Acc: 84.6706\n",
      "validation Loss: 0.0009 Acc: 85.0714\n",
      "Epoch 72/99\n",
      "training Loss: 0.0009 Acc: 84.8164\n",
      "validation Loss: 0.0009 Acc: 85.1667\n",
      "Saving..\n",
      "Epoch 73/99\n",
      "training Loss: 0.0009 Acc: 84.8223\n",
      "validation Loss: 0.0009 Acc: 85.1548\n",
      "Epoch 74/99\n",
      "training Loss: 0.0009 Acc: 84.9443\n",
      "validation Loss: 0.0009 Acc: 85.1667\n",
      "Epoch 75/99\n",
      "training Loss: 0.0009 Acc: 84.7658\n",
      "validation Loss: 0.0009 Acc: 85.1786\n",
      "Saving..\n",
      "Epoch 76/99\n",
      "training Loss: 0.0009 Acc: 84.8521\n",
      "validation Loss: 0.0009 Acc: 85.2381\n",
      "Saving..\n",
      "Epoch 77/99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Loss: 0.0009 Acc: 85.0039\n",
      "validation Loss: 0.0009 Acc: 85.2976\n",
      "Saving..\n",
      "Epoch 78/99\n",
      "training Loss: 0.0009 Acc: 84.8759\n",
      "validation Loss: 0.0009 Acc: 85.3214\n",
      "Saving..\n",
      "Epoch 79/99\n",
      "training Loss: 0.0009 Acc: 84.9324\n",
      "validation Loss: 0.0009 Acc: 85.3214\n",
      "Epoch 80/99\n",
      "training Loss: 0.0009 Acc: 84.9890\n",
      "validation Loss: 0.0009 Acc: 85.3214\n",
      "Epoch 81/99\n",
      "training Loss: 0.0009 Acc: 84.9146\n",
      "validation Loss: 0.0009 Acc: 85.3214\n",
      "Epoch 82/99\n",
      "training Loss: 0.0009 Acc: 84.9592\n",
      "validation Loss: 0.0009 Acc: 85.3095\n",
      "Epoch 83/99\n",
      "training Loss: 0.0009 Acc: 84.8372\n",
      "validation Loss: 0.0009 Acc: 85.2619\n",
      "Epoch 84/99\n",
      "training Loss: 0.0009 Acc: 84.9414\n",
      "validation Loss: 0.0009 Acc: 85.3095\n",
      "Epoch 85/99\n",
      "training Loss: 0.0009 Acc: 85.0753\n",
      "validation Loss: 0.0009 Acc: 85.2619\n",
      "Epoch 86/99\n",
      "training Loss: 0.0009 Acc: 84.7836\n",
      "validation Loss: 0.0009 Acc: 85.2619\n",
      "Epoch 87/99\n",
      "training Loss: 0.0009 Acc: 84.9176\n",
      "validation Loss: 0.0009 Acc: 85.3810\n",
      "Saving..\n",
      "Epoch 88/99\n",
      "training Loss: 0.0009 Acc: 84.9949\n",
      "validation Loss: 0.0009 Acc: 85.4167\n",
      "Saving..\n",
      "Epoch 89/99\n",
      "training Loss: 0.0009 Acc: 85.0455\n",
      "validation Loss: 0.0009 Acc: 85.3810\n",
      "Epoch 90/99\n",
      "training Loss: 0.0009 Acc: 84.9979\n",
      "validation Loss: 0.0009 Acc: 85.3452\n",
      "Epoch 91/99\n",
      "training Loss: 0.0009 Acc: 85.1467\n",
      "validation Loss: 0.0009 Acc: 85.2500\n",
      "Epoch 92/99\n",
      "training Loss: 0.0009 Acc: 84.8491\n",
      "validation Loss: 0.0009 Acc: 85.3810\n",
      "Epoch 93/99\n",
      "training Loss: 0.0009 Acc: 85.0812\n",
      "validation Loss: 0.0009 Acc: 85.3690\n",
      "Epoch 94/99\n",
      "training Loss: 0.0009 Acc: 84.9086\n",
      "validation Loss: 0.0009 Acc: 85.4286\n",
      "Saving..\n",
      "Epoch 95/99\n",
      "training Loss: 0.0009 Acc: 85.1021\n",
      "validation Loss: 0.0009 Acc: 85.4405\n",
      "Saving..\n",
      "Epoch 96/99\n",
      "training Loss: 0.0009 Acc: 84.9354\n",
      "validation Loss: 0.0009 Acc: 85.4881\n",
      "Saving..\n",
      "Epoch 97/99\n",
      "training Loss: 0.0009 Acc: 85.0604\n",
      "validation Loss: 0.0009 Acc: 85.4286\n",
      "Epoch 98/99\n",
      "training Loss: 0.0009 Acc: 85.2033\n",
      "validation Loss: 0.0009 Acc: 85.4286\n",
      "Epoch 99/99\n",
      "training Loss: 0.0009 Acc: 85.0723\n",
      "validation Loss: 0.0009 Acc: 85.4762\n",
      "Best val acc: 85.488095\n",
      "----------\n",
      "Epoch 0/99\n",
      "training Loss: 0.0017 Acc: 64.3980\n",
      "validation Loss: 0.0016 Acc: 76.6429\n",
      "Saving..\n",
      "Epoch 1/99\n",
      "training Loss: 0.0015 Acc: 75.7901\n",
      "validation Loss: 0.0013 Acc: 76.9405\n",
      "Saving..\n",
      "Epoch 2/99\n",
      "training Loss: 0.0013 Acc: 77.2305\n",
      "validation Loss: 0.0012 Acc: 78.8095\n",
      "Saving..\n",
      "Epoch 3/99\n",
      "training Loss: 0.0012 Acc: 79.1203\n",
      "validation Loss: 0.0011 Acc: 80.2262\n",
      "Saving..\n",
      "Epoch 4/99\n",
      "training Loss: 0.0012 Acc: 80.2155\n",
      "validation Loss: 0.0011 Acc: 81.2024\n",
      "Saving..\n",
      "Epoch 5/99\n",
      "training Loss: 0.0011 Acc: 80.9595\n",
      "validation Loss: 0.0011 Acc: 81.8214\n",
      "Saving..\n",
      "Epoch 6/99\n",
      "training Loss: 0.0011 Acc: 81.5785\n",
      "validation Loss: 0.0010 Acc: 82.5476\n",
      "Saving..\n",
      "Epoch 7/99\n",
      "training Loss: 0.0011 Acc: 81.9237\n",
      "validation Loss: 0.0010 Acc: 82.9881\n",
      "Saving..\n",
      "Epoch 8/99\n",
      "training Loss: 0.0010 Acc: 82.1290\n",
      "validation Loss: 0.0010 Acc: 83.5238\n",
      "Saving..\n",
      "Epoch 9/99\n",
      "training Loss: 0.0010 Acc: 82.5070\n",
      "validation Loss: 0.0010 Acc: 83.6429\n",
      "Saving..\n",
      "Epoch 10/99\n",
      "training Loss: 0.0010 Acc: 82.6022\n",
      "validation Loss: 0.0010 Acc: 83.7857\n",
      "Saving..\n",
      "Epoch 11/99\n",
      "training Loss: 0.0010 Acc: 82.6856\n",
      "validation Loss: 0.0010 Acc: 83.7143\n",
      "Epoch 12/99\n",
      "training Loss: 0.0010 Acc: 82.7391\n",
      "validation Loss: 0.0010 Acc: 83.8214\n",
      "Saving..\n",
      "Epoch 13/99\n",
      "training Loss: 0.0010 Acc: 82.8463\n",
      "validation Loss: 0.0010 Acc: 83.8571\n",
      "Saving..\n",
      "Epoch 14/99\n",
      "training Loss: 0.0010 Acc: 82.8135\n",
      "validation Loss: 0.0010 Acc: 83.9762\n",
      "Saving..\n",
      "Epoch 15/99\n",
      "training Loss: 0.0010 Acc: 82.8582\n",
      "validation Loss: 0.0010 Acc: 84.0000\n",
      "Saving..\n",
      "Epoch 16/99\n",
      "training Loss: 0.0010 Acc: 82.8820\n",
      "validation Loss: 0.0010 Acc: 83.9286\n",
      "Epoch 17/99\n",
      "training Loss: 0.0010 Acc: 83.1111\n",
      "validation Loss: 0.0010 Acc: 84.0833\n",
      "Saving..\n",
      "Epoch 18/99\n",
      "training Loss: 0.0010 Acc: 83.0040\n",
      "validation Loss: 0.0010 Acc: 83.9286\n",
      "Epoch 19/99\n",
      "training Loss: 0.0010 Acc: 83.0873\n",
      "validation Loss: 0.0010 Acc: 84.0000\n",
      "Epoch 20/99\n",
      "training Loss: 0.0010 Acc: 83.1171\n",
      "validation Loss: 0.0010 Acc: 84.0595\n",
      "Epoch 21/99\n",
      "training Loss: 0.0010 Acc: 82.9564\n",
      "validation Loss: 0.0010 Acc: 84.1667\n",
      "Saving..\n",
      "Epoch 22/99\n",
      "training Loss: 0.0010 Acc: 83.1558\n",
      "validation Loss: 0.0010 Acc: 84.3929\n",
      "Saving..\n",
      "Epoch 23/99\n",
      "training Loss: 0.0010 Acc: 83.1260\n",
      "validation Loss: 0.0010 Acc: 84.3095\n",
      "Epoch 24/99\n",
      "training Loss: 0.0010 Acc: 83.1439\n",
      "validation Loss: 0.0010 Acc: 84.3452\n",
      "Epoch 25/99\n",
      "training Loss: 0.0010 Acc: 83.2718\n",
      "validation Loss: 0.0010 Acc: 84.5000\n",
      "Saving..\n",
      "Epoch 26/99\n",
      "training Loss: 0.0010 Acc: 83.4504\n",
      "validation Loss: 0.0010 Acc: 84.4643\n",
      "Epoch 27/99\n",
      "training Loss: 0.0010 Acc: 83.2748\n",
      "validation Loss: 0.0010 Acc: 84.3929\n",
      "Epoch 28/99\n",
      "training Loss: 0.0010 Acc: 83.3611\n",
      "validation Loss: 0.0010 Acc: 84.4643\n",
      "Epoch 29/99\n",
      "training Loss: 0.0010 Acc: 83.2450\n",
      "validation Loss: 0.0010 Acc: 84.5595\n",
      "Saving..\n",
      "Epoch 30/99\n",
      "training Loss: 0.0010 Acc: 83.3254\n",
      "validation Loss: 0.0010 Acc: 84.5833\n",
      "Saving..\n",
      "Epoch 31/99\n",
      "training Loss: 0.0010 Acc: 83.3909\n",
      "validation Loss: 0.0010 Acc: 84.6429\n",
      "Saving..\n",
      "Epoch 32/99\n",
      "training Loss: 0.0010 Acc: 83.3998\n",
      "validation Loss: 0.0010 Acc: 84.6071\n",
      "Epoch 33/99\n",
      "training Loss: 0.0010 Acc: 83.4772\n",
      "validation Loss: 0.0010 Acc: 84.6548\n",
      "Saving..\n",
      "Epoch 34/99\n",
      "training Loss: 0.0010 Acc: 83.4296\n",
      "validation Loss: 0.0010 Acc: 84.6548\n",
      "Epoch 35/99\n",
      "training Loss: 0.0010 Acc: 83.5367\n",
      "validation Loss: 0.0010 Acc: 84.6667\n",
      "Saving..\n",
      "Epoch 36/99\n",
      "training Loss: 0.0010 Acc: 83.5813\n",
      "validation Loss: 0.0010 Acc: 84.7143\n",
      "Saving..\n",
      "Epoch 37/99\n",
      "training Loss: 0.0010 Acc: 83.4355\n",
      "validation Loss: 0.0010 Acc: 84.5952\n",
      "Epoch 38/99\n",
      "training Loss: 0.0010 Acc: 83.6498\n",
      "validation Loss: 0.0010 Acc: 84.6905\n",
      "Epoch 39/99\n",
      "training Loss: 0.0010 Acc: 83.5724\n",
      "validation Loss: 0.0010 Acc: 84.7381\n",
      "Saving..\n",
      "Epoch 40/99\n",
      "training Loss: 0.0010 Acc: 83.6230\n",
      "validation Loss: 0.0009 Acc: 84.8095\n",
      "Saving..\n",
      "Epoch 41/99\n",
      "training Loss: 0.0010 Acc: 83.7242\n",
      "validation Loss: 0.0009 Acc: 84.6429\n",
      "Epoch 42/99\n",
      "training Loss: 0.0010 Acc: 83.5754\n",
      "validation Loss: 0.0009 Acc: 84.7500\n",
      "Epoch 43/99\n",
      "training Loss: 0.0010 Acc: 83.7004\n",
      "validation Loss: 0.0009 Acc: 84.8214\n",
      "Saving..\n",
      "Epoch 44/99\n",
      "training Loss: 0.0010 Acc: 83.8343\n",
      "validation Loss: 0.0009 Acc: 84.8810\n",
      "Saving..\n",
      "Epoch 45/99\n",
      "training Loss: 0.0010 Acc: 83.6706\n",
      "validation Loss: 0.0009 Acc: 84.7619\n",
      "Epoch 46/99\n",
      "training Loss: 0.0010 Acc: 83.7837\n",
      "validation Loss: 0.0009 Acc: 84.7262\n",
      "Epoch 47/99\n",
      "training Loss: 0.0010 Acc: 83.9117\n",
      "validation Loss: 0.0009 Acc: 84.9405\n",
      "Saving..\n",
      "Epoch 48/99\n",
      "training Loss: 0.0010 Acc: 83.9742\n",
      "validation Loss: 0.0009 Acc: 84.8452\n",
      "Epoch 49/99\n",
      "training Loss: 0.0010 Acc: 83.9385\n",
      "validation Loss: 0.0009 Acc: 84.7738\n",
      "Epoch 50/99\n",
      "training Loss: 0.0010 Acc: 83.9533\n",
      "validation Loss: 0.0009 Acc: 84.8690\n",
      "Epoch 51/99\n",
      "training Loss: 0.0010 Acc: 84.0099\n",
      "validation Loss: 0.0009 Acc: 84.9048\n",
      "Epoch 52/99\n",
      "training Loss: 0.0010 Acc: 84.1378\n",
      "validation Loss: 0.0009 Acc: 84.9524\n",
      "Saving..\n",
      "Epoch 53/99\n",
      "training Loss: 0.0010 Acc: 84.1527\n",
      "validation Loss: 0.0009 Acc: 85.0000\n",
      "Saving..\n",
      "Epoch 54/99\n",
      "training Loss: 0.0010 Acc: 84.1855\n",
      "validation Loss: 0.0009 Acc: 85.0714\n",
      "Saving..\n",
      "Epoch 55/99\n",
      "training Loss: 0.0009 Acc: 84.2866\n",
      "validation Loss: 0.0009 Acc: 85.0833\n",
      "Saving..\n",
      "Epoch 56/99\n",
      "training Loss: 0.0009 Acc: 84.3164\n",
      "validation Loss: 0.0009 Acc: 85.1548\n",
      "Saving..\n",
      "Epoch 57/99\n",
      "training Loss: 0.0009 Acc: 84.2093\n",
      "validation Loss: 0.0009 Acc: 85.1786\n",
      "Saving..\n",
      "Epoch 58/99\n",
      "training Loss: 0.0009 Acc: 84.2539\n",
      "validation Loss: 0.0009 Acc: 85.0952\n",
      "Epoch 59/99\n",
      "training Loss: 0.0009 Acc: 84.5188\n",
      "validation Loss: 0.0009 Acc: 85.2381\n",
      "Saving..\n",
      "Epoch 60/99\n",
      "training Loss: 0.0009 Acc: 84.4563\n",
      "validation Loss: 0.0009 Acc: 85.1905\n",
      "Epoch 61/99\n",
      "training Loss: 0.0009 Acc: 84.5247\n",
      "validation Loss: 0.0009 Acc: 85.2381\n",
      "Epoch 62/99\n",
      "training Loss: 0.0009 Acc: 84.6051\n",
      "validation Loss: 0.0009 Acc: 85.2143\n",
      "Epoch 63/99\n",
      "training Loss: 0.0009 Acc: 84.3730\n",
      "validation Loss: 0.0009 Acc: 85.3214\n",
      "Saving..\n",
      "Epoch 64/99\n",
      "training Loss: 0.0009 Acc: 84.3343\n",
      "validation Loss: 0.0009 Acc: 85.3214\n",
      "Epoch 65/99\n",
      "training Loss: 0.0009 Acc: 84.5456\n",
      "validation Loss: 0.0009 Acc: 85.4167\n",
      "Saving..\n",
      "Epoch 66/99\n",
      "training Loss: 0.0009 Acc: 84.6676\n",
      "validation Loss: 0.0009 Acc: 85.4167\n",
      "Epoch 67/99\n",
      "training Loss: 0.0009 Acc: 84.4206\n",
      "validation Loss: 0.0009 Acc: 85.2500\n",
      "Epoch 68/99\n",
      "training Loss: 0.0009 Acc: 84.7717\n",
      "validation Loss: 0.0009 Acc: 85.2976\n",
      "Epoch 69/99\n",
      "training Loss: 0.0009 Acc: 84.7896\n",
      "validation Loss: 0.0009 Acc: 85.3571\n",
      "Epoch 70/99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Loss: 0.0009 Acc: 84.6289\n",
      "validation Loss: 0.0009 Acc: 85.3214\n",
      "Epoch 71/99\n",
      "training Loss: 0.0009 Acc: 84.6438\n",
      "validation Loss: 0.0009 Acc: 85.3095\n",
      "Epoch 72/99\n",
      "training Loss: 0.0009 Acc: 84.6467\n",
      "validation Loss: 0.0009 Acc: 85.3095\n",
      "Epoch 73/99\n",
      "training Loss: 0.0009 Acc: 84.6259\n",
      "validation Loss: 0.0009 Acc: 85.2976\n",
      "Epoch 74/99\n",
      "training Loss: 0.0009 Acc: 84.7509\n",
      "validation Loss: 0.0009 Acc: 85.4167\n",
      "Epoch 75/99\n",
      "training Loss: 0.0009 Acc: 84.8075\n",
      "validation Loss: 0.0009 Acc: 85.4048\n",
      "Early stopped.\n",
      "Best val acc: 85.416667\n",
      "----------\n",
      "Epoch 0/99\n",
      "training Loss: 0.0018 Acc: 57.5234\n",
      "validation Loss: 0.0016 Acc: 70.9167\n",
      "Saving..\n",
      "Epoch 1/99\n",
      "training Loss: 0.0015 Acc: 74.0611\n",
      "validation Loss: 0.0013 Acc: 76.7619\n",
      "Saving..\n",
      "Epoch 2/99\n",
      "training Loss: 0.0013 Acc: 77.4656\n",
      "validation Loss: 0.0012 Acc: 78.2500\n",
      "Saving..\n",
      "Epoch 3/99\n",
      "training Loss: 0.0012 Acc: 78.7572\n",
      "validation Loss: 0.0011 Acc: 79.7738\n",
      "Saving..\n",
      "Epoch 4/99\n",
      "training Loss: 0.0012 Acc: 79.8256\n",
      "validation Loss: 0.0011 Acc: 80.6071\n",
      "Saving..\n",
      "Epoch 5/99\n",
      "training Loss: 0.0011 Acc: 80.7482\n",
      "validation Loss: 0.0011 Acc: 81.1548\n",
      "Saving..\n",
      "Epoch 6/99\n",
      "training Loss: 0.0011 Acc: 81.4803\n",
      "validation Loss: 0.0010 Acc: 81.7381\n",
      "Saving..\n",
      "Epoch 7/99\n",
      "training Loss: 0.0011 Acc: 81.8642\n",
      "validation Loss: 0.0010 Acc: 82.3095\n",
      "Saving..\n",
      "Epoch 8/99\n",
      "training Loss: 0.0011 Acc: 82.1618\n",
      "validation Loss: 0.0010 Acc: 82.7857\n",
      "Saving..\n",
      "Epoch 9/99\n",
      "training Loss: 0.0010 Acc: 82.4445\n",
      "validation Loss: 0.0010 Acc: 83.0714\n",
      "Saving..\n",
      "Epoch 10/99\n",
      "training Loss: 0.0010 Acc: 82.5814\n",
      "validation Loss: 0.0010 Acc: 83.1310\n",
      "Saving..\n",
      "Epoch 11/99\n",
      "training Loss: 0.0010 Acc: 82.6826\n",
      "validation Loss: 0.0010 Acc: 83.2262\n",
      "Saving..\n",
      "Epoch 12/99\n",
      "training Loss: 0.0010 Acc: 82.6975\n",
      "validation Loss: 0.0010 Acc: 83.2738\n",
      "Saving..\n",
      "Epoch 13/99\n",
      "training Loss: 0.0010 Acc: 82.9742\n",
      "validation Loss: 0.0010 Acc: 83.5119\n",
      "Saving..\n",
      "Epoch 14/99\n",
      "training Loss: 0.0010 Acc: 82.9713\n",
      "validation Loss: 0.0010 Acc: 83.5119\n",
      "Epoch 15/99\n",
      "training Loss: 0.0010 Acc: 82.8373\n",
      "validation Loss: 0.0010 Acc: 83.4881\n",
      "Epoch 16/99\n",
      "training Loss: 0.0010 Acc: 83.0218\n",
      "validation Loss: 0.0010 Acc: 83.6310\n",
      "Saving..\n",
      "Epoch 17/99\n",
      "training Loss: 0.0010 Acc: 82.9088\n",
      "validation Loss: 0.0010 Acc: 83.6429\n",
      "Saving..\n",
      "Epoch 18/99\n",
      "training Loss: 0.0010 Acc: 83.1647\n",
      "validation Loss: 0.0010 Acc: 83.6905\n",
      "Saving..\n",
      "Epoch 19/99\n",
      "training Loss: 0.0010 Acc: 83.2867\n",
      "validation Loss: 0.0010 Acc: 83.6190\n",
      "Epoch 20/99\n",
      "training Loss: 0.0010 Acc: 83.1468\n",
      "validation Loss: 0.0010 Acc: 83.6667\n",
      "Epoch 21/99\n",
      "training Loss: 0.0010 Acc: 83.0754\n",
      "validation Loss: 0.0010 Acc: 83.6667\n",
      "Epoch 22/99\n",
      "training Loss: 0.0010 Acc: 83.3433\n",
      "validation Loss: 0.0010 Acc: 83.7262\n",
      "Saving..\n",
      "Epoch 23/99\n",
      "training Loss: 0.0010 Acc: 83.3760\n",
      "validation Loss: 0.0010 Acc: 83.6667\n",
      "Epoch 24/99\n",
      "training Loss: 0.0010 Acc: 83.3790\n",
      "validation Loss: 0.0010 Acc: 83.6667\n",
      "Epoch 25/99\n",
      "training Loss: 0.0010 Acc: 83.4236\n",
      "validation Loss: 0.0010 Acc: 83.7262\n",
      "Epoch 26/99\n",
      "training Loss: 0.0010 Acc: 83.4534\n",
      "validation Loss: 0.0010 Acc: 83.6310\n",
      "Epoch 27/99\n",
      "training Loss: 0.0010 Acc: 83.3671\n",
      "validation Loss: 0.0010 Acc: 83.7024\n",
      "Epoch 28/99\n",
      "training Loss: 0.0010 Acc: 83.3819\n",
      "validation Loss: 0.0010 Acc: 83.6905\n",
      "Epoch 29/99\n",
      "training Loss: 0.0010 Acc: 83.3194\n",
      "validation Loss: 0.0010 Acc: 83.6786\n",
      "Epoch 30/99\n",
      "training Loss: 0.0010 Acc: 83.3224\n",
      "validation Loss: 0.0010 Acc: 83.6548\n",
      "Epoch 31/99\n",
      "training Loss: 0.0010 Acc: 83.4801\n",
      "validation Loss: 0.0010 Acc: 83.6786\n",
      "Epoch 32/99\n",
      "training Loss: 0.0010 Acc: 83.6200\n",
      "validation Loss: 0.0010 Acc: 83.7024\n",
      "Early stopped.\n",
      "Best val acc: 83.726190\n",
      "----------\n",
      "Epoch 0/99\n",
      "training Loss: 0.0017 Acc: 68.1448\n",
      "validation Loss: 0.0016 Acc: 75.7738\n",
      "Saving..\n",
      "Epoch 1/99\n",
      "training Loss: 0.0015 Acc: 75.8139\n",
      "validation Loss: 0.0013 Acc: 76.3571\n",
      "Saving..\n",
      "Epoch 2/99\n",
      "training Loss: 0.0013 Acc: 77.9269\n",
      "validation Loss: 0.0012 Acc: 78.9524\n",
      "Saving..\n",
      "Epoch 3/99\n",
      "training Loss: 0.0012 Acc: 79.5012\n",
      "validation Loss: 0.0011 Acc: 79.9881\n",
      "Saving..\n",
      "Epoch 4/99\n",
      "training Loss: 0.0011 Acc: 80.5994\n",
      "validation Loss: 0.0011 Acc: 80.8690\n",
      "Saving..\n",
      "Epoch 5/99\n",
      "training Loss: 0.0011 Acc: 81.5725\n",
      "validation Loss: 0.0010 Acc: 81.5476\n",
      "Saving..\n",
      "Epoch 6/99\n",
      "training Loss: 0.0011 Acc: 81.9475\n",
      "validation Loss: 0.0010 Acc: 82.1905\n",
      "Saving..\n",
      "Epoch 7/99\n",
      "training Loss: 0.0011 Acc: 82.4326\n",
      "validation Loss: 0.0010 Acc: 82.7143\n",
      "Saving..\n",
      "Epoch 8/99\n",
      "training Loss: 0.0010 Acc: 82.5368\n",
      "validation Loss: 0.0010 Acc: 82.8333\n",
      "Saving..\n",
      "Epoch 9/99\n",
      "training Loss: 0.0010 Acc: 82.5635\n",
      "validation Loss: 0.0010 Acc: 82.9286\n",
      "Saving..\n",
      "Epoch 10/99\n",
      "training Loss: 0.0010 Acc: 82.9058\n",
      "validation Loss: 0.0010 Acc: 82.9405\n",
      "Saving..\n",
      "Epoch 11/99\n",
      "training Loss: 0.0010 Acc: 82.8939\n",
      "validation Loss: 0.0010 Acc: 83.1429\n",
      "Saving..\n",
      "Epoch 12/99\n",
      "training Loss: 0.0010 Acc: 82.9534\n",
      "validation Loss: 0.0010 Acc: 83.1905\n",
      "Saving..\n",
      "Epoch 13/99\n",
      "training Loss: 0.0010 Acc: 83.0159\n",
      "validation Loss: 0.0010 Acc: 83.0595\n",
      "Epoch 14/99\n",
      "training Loss: 0.0010 Acc: 83.0665\n",
      "validation Loss: 0.0010 Acc: 83.1667\n",
      "Epoch 15/99\n",
      "training Loss: 0.0010 Acc: 83.0218\n",
      "validation Loss: 0.0010 Acc: 83.2857\n",
      "Saving..\n",
      "Epoch 16/99\n",
      "training Loss: 0.0010 Acc: 83.0486\n",
      "validation Loss: 0.0010 Acc: 83.4048\n",
      "Saving..\n",
      "Epoch 17/99\n",
      "training Loss: 0.0010 Acc: 83.2212\n",
      "validation Loss: 0.0010 Acc: 83.2024\n",
      "Epoch 18/99\n",
      "training Loss: 0.0010 Acc: 83.2153\n",
      "validation Loss: 0.0010 Acc: 83.2738\n",
      "Epoch 19/99\n",
      "training Loss: 0.0010 Acc: 83.3522\n",
      "validation Loss: 0.0010 Acc: 83.3214\n",
      "Epoch 20/99\n",
      "training Loss: 0.0010 Acc: 83.2302\n",
      "validation Loss: 0.0010 Acc: 83.3452\n",
      "Epoch 21/99\n",
      "training Loss: 0.0010 Acc: 83.3998\n",
      "validation Loss: 0.0010 Acc: 83.2619\n",
      "Epoch 22/99\n",
      "training Loss: 0.0010 Acc: 83.2034\n",
      "validation Loss: 0.0010 Acc: 83.5119\n",
      "Saving..\n",
      "Epoch 23/99\n",
      "training Loss: 0.0010 Acc: 83.2778\n",
      "validation Loss: 0.0010 Acc: 83.3452\n",
      "Epoch 24/99\n",
      "training Loss: 0.0010 Acc: 83.3522\n",
      "validation Loss: 0.0010 Acc: 83.4405\n",
      "Epoch 25/99\n",
      "training Loss: 0.0010 Acc: 83.3909\n",
      "validation Loss: 0.0010 Acc: 83.4881\n",
      "Epoch 26/99\n",
      "training Loss: 0.0010 Acc: 83.5962\n",
      "validation Loss: 0.0010 Acc: 83.5357\n",
      "Saving..\n",
      "Epoch 27/99\n",
      "training Loss: 0.0010 Acc: 83.4504\n",
      "validation Loss: 0.0010 Acc: 83.4286\n",
      "Epoch 28/99\n",
      "training Loss: 0.0010 Acc: 83.5337\n",
      "validation Loss: 0.0010 Acc: 83.4524\n",
      "Epoch 29/99\n",
      "training Loss: 0.0010 Acc: 83.6230\n",
      "validation Loss: 0.0010 Acc: 83.4762\n",
      "Epoch 30/99\n",
      "training Loss: 0.0010 Acc: 83.6141\n",
      "validation Loss: 0.0010 Acc: 83.5714\n",
      "Saving..\n",
      "Epoch 31/99\n",
      "training Loss: 0.0010 Acc: 83.7301\n",
      "validation Loss: 0.0010 Acc: 83.5714\n",
      "Epoch 32/99\n",
      "training Loss: 0.0010 Acc: 83.6141\n",
      "validation Loss: 0.0010 Acc: 83.5833\n",
      "Saving..\n",
      "Epoch 33/99\n",
      "training Loss: 0.0010 Acc: 83.6260\n",
      "validation Loss: 0.0010 Acc: 83.5952\n",
      "Saving..\n",
      "Epoch 34/99\n",
      "training Loss: 0.0010 Acc: 83.5635\n",
      "validation Loss: 0.0010 Acc: 83.5952\n",
      "Epoch 35/99\n",
      "training Loss: 0.0010 Acc: 83.6587\n",
      "validation Loss: 0.0010 Acc: 83.6667\n",
      "Saving..\n",
      "Epoch 36/99\n",
      "training Loss: 0.0010 Acc: 83.6141\n",
      "validation Loss: 0.0010 Acc: 83.5833\n",
      "Epoch 37/99\n",
      "training Loss: 0.0010 Acc: 83.7450\n",
      "validation Loss: 0.0010 Acc: 83.6786\n",
      "Saving..\n",
      "Epoch 38/99\n",
      "training Loss: 0.0010 Acc: 83.8105\n",
      "validation Loss: 0.0010 Acc: 83.7024\n",
      "Saving..\n",
      "Epoch 39/99\n",
      "training Loss: 0.0010 Acc: 83.8819\n",
      "validation Loss: 0.0010 Acc: 83.7143\n",
      "Saving..\n",
      "Epoch 40/99\n",
      "training Loss: 0.0010 Acc: 83.7063\n",
      "validation Loss: 0.0010 Acc: 83.7857\n",
      "Saving..\n",
      "Epoch 41/99\n",
      "training Loss: 0.0010 Acc: 83.8641\n",
      "validation Loss: 0.0010 Acc: 83.8095\n",
      "Saving..\n",
      "Epoch 42/99\n",
      "training Loss: 0.0010 Acc: 83.9146\n",
      "validation Loss: 0.0010 Acc: 83.8333\n",
      "Saving..\n",
      "Epoch 43/99\n",
      "training Loss: 0.0010 Acc: 83.9355\n",
      "validation Loss: 0.0010 Acc: 83.8333\n",
      "Epoch 44/99\n",
      "training Loss: 0.0010 Acc: 83.9325\n",
      "validation Loss: 0.0010 Acc: 83.9167\n",
      "Saving..\n",
      "Epoch 45/99\n",
      "training Loss: 0.0010 Acc: 84.0605\n",
      "validation Loss: 0.0009 Acc: 83.9048\n",
      "Epoch 46/99\n",
      "training Loss: 0.0010 Acc: 84.1021\n",
      "validation Loss: 0.0009 Acc: 83.9405\n",
      "Saving..\n",
      "Epoch 47/99\n",
      "training Loss: 0.0010 Acc: 83.9206\n",
      "validation Loss: 0.0009 Acc: 83.8810\n",
      "Epoch 48/99\n",
      "training Loss: 0.0010 Acc: 84.0575\n",
      "validation Loss: 0.0009 Acc: 83.8810\n",
      "Epoch 49/99\n",
      "training Loss: 0.0010 Acc: 84.1378\n",
      "validation Loss: 0.0009 Acc: 84.0595\n",
      "Saving..\n",
      "Epoch 50/99\n",
      "training Loss: 0.0010 Acc: 84.2301\n",
      "validation Loss: 0.0009 Acc: 84.0714\n",
      "Saving..\n",
      "Epoch 51/99\n",
      "training Loss: 0.0009 Acc: 84.3164\n",
      "validation Loss: 0.0009 Acc: 83.9881\n",
      "Epoch 52/99\n",
      "training Loss: 0.0009 Acc: 84.2331\n",
      "validation Loss: 0.0009 Acc: 84.0476\n",
      "Epoch 53/99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Loss: 0.0010 Acc: 84.4979\n",
      "validation Loss: 0.0009 Acc: 84.1429\n",
      "Saving..\n",
      "Epoch 54/99\n",
      "training Loss: 0.0010 Acc: 84.3045\n",
      "validation Loss: 0.0009 Acc: 84.2500\n",
      "Saving..\n",
      "Epoch 55/99\n",
      "training Loss: 0.0009 Acc: 84.3075\n",
      "validation Loss: 0.0009 Acc: 84.1905\n",
      "Epoch 56/99\n",
      "training Loss: 0.0009 Acc: 84.4712\n",
      "validation Loss: 0.0009 Acc: 84.2143\n",
      "Epoch 57/99\n",
      "training Loss: 0.0009 Acc: 84.4176\n",
      "validation Loss: 0.0009 Acc: 84.2024\n",
      "Epoch 58/99\n",
      "training Loss: 0.0009 Acc: 84.4950\n",
      "validation Loss: 0.0009 Acc: 84.2738\n",
      "Saving..\n",
      "Epoch 59/99\n",
      "training Loss: 0.0009 Acc: 84.4890\n",
      "validation Loss: 0.0009 Acc: 84.2976\n",
      "Saving..\n",
      "Epoch 60/99\n",
      "training Loss: 0.0009 Acc: 84.5485\n",
      "validation Loss: 0.0009 Acc: 84.2619\n",
      "Epoch 61/99\n",
      "training Loss: 0.0009 Acc: 84.6557\n",
      "validation Loss: 0.0009 Acc: 84.3095\n",
      "Saving..\n",
      "Epoch 62/99\n",
      "training Loss: 0.0009 Acc: 84.6795\n",
      "validation Loss: 0.0009 Acc: 84.5000\n",
      "Saving..\n",
      "Epoch 63/99\n",
      "training Loss: 0.0009 Acc: 84.5575\n",
      "validation Loss: 0.0009 Acc: 84.4643\n",
      "Epoch 64/99\n",
      "training Loss: 0.0009 Acc: 84.6646\n",
      "validation Loss: 0.0009 Acc: 84.4762\n",
      "Epoch 65/99\n",
      "training Loss: 0.0009 Acc: 84.8253\n",
      "validation Loss: 0.0009 Acc: 84.6310\n",
      "Saving..\n",
      "Epoch 66/99\n",
      "training Loss: 0.0009 Acc: 84.8551\n",
      "validation Loss: 0.0009 Acc: 84.6667\n",
      "Saving..\n",
      "Epoch 67/99\n",
      "training Loss: 0.0009 Acc: 84.6527\n",
      "validation Loss: 0.0009 Acc: 84.6190\n",
      "Epoch 68/99\n",
      "training Loss: 0.0009 Acc: 84.8967\n",
      "validation Loss: 0.0009 Acc: 84.5238\n",
      "Epoch 69/99\n",
      "training Loss: 0.0009 Acc: 84.8461\n",
      "validation Loss: 0.0009 Acc: 84.7619\n",
      "Saving..\n",
      "Epoch 70/99\n",
      "training Loss: 0.0009 Acc: 84.7955\n",
      "validation Loss: 0.0009 Acc: 84.7143\n",
      "Epoch 71/99\n",
      "training Loss: 0.0009 Acc: 84.7896\n",
      "validation Loss: 0.0009 Acc: 84.7143\n",
      "Epoch 72/99\n",
      "training Loss: 0.0009 Acc: 85.0455\n",
      "validation Loss: 0.0009 Acc: 84.8095\n",
      "Saving..\n",
      "Epoch 73/99\n",
      "training Loss: 0.0009 Acc: 84.8461\n",
      "validation Loss: 0.0009 Acc: 84.8095\n",
      "Epoch 74/99\n",
      "training Loss: 0.0009 Acc: 84.8640\n",
      "validation Loss: 0.0009 Acc: 84.9286\n",
      "Saving..\n",
      "Epoch 75/99\n",
      "training Loss: 0.0009 Acc: 84.9176\n",
      "validation Loss: 0.0009 Acc: 84.7738\n",
      "Epoch 76/99\n",
      "training Loss: 0.0009 Acc: 85.0098\n",
      "validation Loss: 0.0009 Acc: 84.8333\n",
      "Epoch 77/99\n",
      "training Loss: 0.0009 Acc: 84.9533\n",
      "validation Loss: 0.0009 Acc: 84.7262\n",
      "Epoch 78/99\n",
      "training Loss: 0.0009 Acc: 84.9384\n",
      "validation Loss: 0.0009 Acc: 84.7500\n",
      "Epoch 79/99\n",
      "training Loss: 0.0009 Acc: 84.8283\n",
      "validation Loss: 0.0009 Acc: 84.9048\n",
      "Epoch 80/99\n",
      "training Loss: 0.0009 Acc: 85.0009\n",
      "validation Loss: 0.0009 Acc: 84.8214\n",
      "Epoch 81/99\n",
      "training Loss: 0.0009 Acc: 84.9890\n",
      "validation Loss: 0.0009 Acc: 84.7143\n",
      "Epoch 82/99\n",
      "training Loss: 0.0009 Acc: 84.9563\n",
      "validation Loss: 0.0009 Acc: 84.9167\n",
      "Epoch 83/99\n",
      "training Loss: 0.0009 Acc: 85.0217\n",
      "validation Loss: 0.0009 Acc: 84.8571\n",
      "Epoch 84/99\n",
      "training Loss: 0.0009 Acc: 84.9295\n",
      "validation Loss: 0.0009 Acc: 84.8214\n",
      "Early stopped.\n",
      "Best val acc: 84.928571\n",
      "----------\n",
      "Average best_acc across k-fold: 85.1411358973\n",
      "New configuration: {'hidden_layers': 1, 'dropout_g': 0.35397519320201726, 'initial_nodes': 76, 'dropout': 0.2984854969359606, 'gru_layers': 1, 'batch_size': 248, 'gru_size': 119, 'learning_rate': 0.04077499365367614}\n",
      "Epoch 0/99\n",
      "training Loss: 0.0017 Acc: 81.5774\n",
      "validation Loss: 0.0014 Acc: 84.3371\n",
      "Saving..\n",
      "Epoch 1/99\n",
      "training Loss: 0.0016 Acc: 83.8125\n",
      "validation Loss: 0.0014 Acc: 84.0157\n",
      "Epoch 2/99\n",
      "training Loss: 0.0016 Acc: 82.9345\n",
      "validation Loss: 0.0015 Acc: 84.4323\n",
      "Saving..\n",
      "Epoch 3/99\n",
      "training Loss: 0.0016 Acc: 83.1667\n",
      "validation Loss: 0.0015 Acc: 84.5989\n",
      "Saving..\n",
      "Epoch 4/99\n",
      "training Loss: 0.0016 Acc: 83.0833\n",
      "validation Loss: 0.0015 Acc: 84.0871\n",
      "Epoch 5/99\n",
      "training Loss: 0.0016 Acc: 82.8661\n",
      "validation Loss: 0.0015 Acc: 84.6822\n",
      "Saving..\n",
      "Epoch 6/99\n",
      "training Loss: 0.0017 Acc: 81.8065\n",
      "validation Loss: 0.0016 Acc: 84.1704\n",
      "Epoch 7/99\n",
      "training Loss: 0.0016 Acc: 82.9226\n",
      "validation Loss: 0.0014 Acc: 84.9203\n",
      "Saving..\n",
      "Epoch 8/99\n",
      "training Loss: 0.0015 Acc: 83.9643\n",
      "validation Loss: 0.0014 Acc: 84.9917\n",
      "Saving..\n",
      "Epoch 9/99\n",
      "training Loss: 0.0015 Acc: 83.9911\n",
      "validation Loss: 0.0014 Acc: 84.9560\n",
      "Epoch 10/99\n",
      "training Loss: 0.0015 Acc: 84.2381\n",
      "validation Loss: 0.0014 Acc: 85.0274\n",
      "Saving..\n",
      "Epoch 11/99\n",
      "training Loss: 0.0015 Acc: 84.1756\n",
      "validation Loss: 0.0014 Acc: 85.4439\n",
      "Saving..\n",
      "Epoch 12/99\n",
      "training Loss: 0.0015 Acc: 83.9583\n",
      "validation Loss: 0.0014 Acc: 84.5632\n",
      "Epoch 13/99\n",
      "training Loss: 0.0015 Acc: 84.3155\n",
      "validation Loss: 0.0014 Acc: 84.0157\n",
      "Epoch 14/99\n",
      "training Loss: 0.0015 Acc: 84.2887\n",
      "validation Loss: 0.0014 Acc: 84.9203\n",
      "Epoch 15/99\n",
      "training Loss: 0.0015 Acc: 84.1458\n",
      "validation Loss: 0.0014 Acc: 85.2059\n",
      "Epoch 16/99\n",
      "training Loss: 0.0015 Acc: 84.5268\n",
      "validation Loss: 0.0014 Acc: 85.0512\n",
      "Epoch 17/99\n",
      "training Loss: 0.0015 Acc: 84.3750\n",
      "validation Loss: 0.0014 Acc: 85.0631\n",
      "Epoch 18/99\n",
      "training Loss: 0.0015 Acc: 84.6964\n",
      "validation Loss: 0.0014 Acc: 85.1702\n",
      "Epoch 19/99\n",
      "training Loss: 0.0015 Acc: 84.5179\n",
      "validation Loss: 0.0014 Acc: 85.3130\n",
      "Epoch 20/99\n",
      "training Loss: 0.0015 Acc: 84.6667\n",
      "validation Loss: 0.0014 Acc: 85.0869\n",
      "Epoch 21/99\n",
      "training Loss: 0.0015 Acc: 84.5238\n",
      "validation Loss: 0.0014 Acc: 85.0988\n",
      "Early stopped.\n",
      "Best val acc: 85.443942\n",
      "----------\n",
      "Epoch 0/99\n",
      "training Loss: 0.0017 Acc: 81.8820\n",
      "validation Loss: 0.0014 Acc: 85.0238\n",
      "Saving..\n",
      "Epoch 1/99\n",
      "training Loss: 0.0016 Acc: 83.4980\n",
      "validation Loss: 0.0015 Acc: 85.0238\n",
      "Epoch 2/99\n",
      "training Loss: 0.0016 Acc: 83.6676\n",
      "validation Loss: 0.0015 Acc: 84.6548\n",
      "Epoch 3/99\n",
      "training Loss: 0.0016 Acc: 83.5069\n",
      "validation Loss: 0.0016 Acc: 84.6905\n",
      "Epoch 4/99\n",
      "training Loss: 0.0016 Acc: 83.1796\n",
      "validation Loss: 0.0014 Acc: 84.8571\n",
      "Epoch 5/99\n",
      "training Loss: 0.0016 Acc: 83.0308\n",
      "validation Loss: 0.0014 Acc: 84.5238\n",
      "Epoch 6/99\n",
      "training Loss: 0.0016 Acc: 82.8611\n",
      "validation Loss: 0.0014 Acc: 84.5952\n",
      "Epoch 7/99\n",
      "training Loss: 0.0017 Acc: 81.8166\n",
      "validation Loss: 0.0016 Acc: 84.3810\n",
      "Epoch 8/99\n",
      "training Loss: 0.0017 Acc: 81.4922\n",
      "validation Loss: 0.0016 Acc: 85.2024\n",
      "Saving..\n",
      "Epoch 9/99\n",
      "training Loss: 0.0017 Acc: 80.8910\n",
      "validation Loss: 0.0016 Acc: 79.8571\n",
      "Epoch 10/99\n",
      "training Loss: 0.0017 Acc: 81.0428\n",
      "validation Loss: 0.0015 Acc: 83.8333\n",
      "Epoch 11/99\n",
      "training Loss: 0.0016 Acc: 82.4118\n",
      "validation Loss: 0.0014 Acc: 84.5238\n",
      "Epoch 12/99\n",
      "training Loss: 0.0016 Acc: 82.4951\n",
      "validation Loss: 0.0014 Acc: 85.2143\n",
      "Saving..\n",
      "Epoch 13/99\n",
      "training Loss: 0.0015 Acc: 83.2183\n",
      "validation Loss: 0.0015 Acc: 84.8690\n",
      "Epoch 14/99\n",
      "training Loss: 0.0016 Acc: 83.1736\n",
      "validation Loss: 0.0014 Acc: 85.2857\n",
      "Saving..\n",
      "Epoch 15/99\n",
      "training Loss: 0.0015 Acc: 83.5843\n",
      "validation Loss: 0.0014 Acc: 84.7500\n",
      "Epoch 16/99\n",
      "training Loss: 0.0015 Acc: 83.5040\n",
      "validation Loss: 0.0014 Acc: 84.9286\n",
      "Epoch 17/99\n",
      "training Loss: 0.0015 Acc: 83.8105\n",
      "validation Loss: 0.0014 Acc: 85.2024\n",
      "Epoch 18/99\n",
      "training Loss: 0.0015 Acc: 83.7629\n",
      "validation Loss: 0.0015 Acc: 85.5119\n",
      "Saving..\n",
      "Epoch 19/99\n",
      "training Loss: 0.0015 Acc: 83.9742\n",
      "validation Loss: 0.0014 Acc: 85.3333\n",
      "Epoch 20/99\n",
      "training Loss: 0.0015 Acc: 83.9920\n",
      "validation Loss: 0.0014 Acc: 85.1905\n",
      "Epoch 21/99\n",
      "training Loss: 0.0015 Acc: 83.6349\n",
      "validation Loss: 0.0014 Acc: 85.0833\n",
      "Epoch 22/99\n",
      "training Loss: 0.0015 Acc: 83.8581\n",
      "validation Loss: 0.0014 Acc: 85.2381\n",
      "Epoch 23/99\n",
      "training Loss: 0.0015 Acc: 83.7807\n",
      "validation Loss: 0.0014 Acc: 85.2738\n",
      "Epoch 24/99\n",
      "training Loss: 0.0015 Acc: 84.0605\n",
      "validation Loss: 0.0014 Acc: 85.7381\n",
      "Saving..\n",
      "Epoch 25/99\n",
      "training Loss: 0.0015 Acc: 84.2658\n",
      "validation Loss: 0.0014 Acc: 85.3929\n",
      "Epoch 26/99\n",
      "training Loss: 0.0015 Acc: 84.4563\n",
      "validation Loss: 0.0014 Acc: 85.5476\n",
      "Epoch 27/99\n",
      "training Loss: 0.0014 Acc: 84.5366\n",
      "validation Loss: 0.0014 Acc: 85.2857\n",
      "Epoch 28/99\n",
      "training Loss: 0.0014 Acc: 84.3640\n",
      "validation Loss: 0.0014 Acc: 85.5119\n",
      "Epoch 29/99\n",
      "training Loss: 0.0014 Acc: 84.3759\n",
      "validation Loss: 0.0014 Acc: 85.5000\n",
      "Epoch 30/99\n",
      "training Loss: 0.0014 Acc: 84.4771\n",
      "validation Loss: 0.0014 Acc: 85.4048\n",
      "Epoch 31/99\n",
      "training Loss: 0.0014 Acc: 84.9027\n",
      "validation Loss: 0.0014 Acc: 85.5238\n",
      "Epoch 32/99\n",
      "training Loss: 0.0014 Acc: 84.8313\n",
      "validation Loss: 0.0014 Acc: 85.6190\n",
      "Epoch 33/99\n",
      "training Loss: 0.0014 Acc: 84.8015\n",
      "validation Loss: 0.0014 Acc: 85.6429\n",
      "Epoch 34/99\n",
      "training Loss: 0.0014 Acc: 84.8491\n",
      "validation Loss: 0.0014 Acc: 85.5952\n",
      "Early stopped.\n",
      "Best val acc: 85.738095\n",
      "----------\n",
      "Epoch 0/99\n",
      "training Loss: 0.0016 Acc: 82.1201\n",
      "validation Loss: 0.0015 Acc: 84.3214\n",
      "Saving..\n",
      "Epoch 1/99\n",
      "training Loss: 0.0015 Acc: 83.6974\n",
      "validation Loss: 0.0016 Acc: 84.4643\n",
      "Saving..\n",
      "Epoch 2/99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Loss: 0.0016 Acc: 83.5575\n",
      "validation Loss: 0.0016 Acc: 83.4524\n",
      "Epoch 3/99\n",
      "training Loss: 0.0016 Acc: 83.3581\n",
      "validation Loss: 0.0014 Acc: 83.4524\n",
      "Epoch 4/99\n",
      "training Loss: 0.0016 Acc: 82.8790\n",
      "validation Loss: 0.0015 Acc: 84.2738\n",
      "Epoch 5/99\n",
      "training Loss: 0.0017 Acc: 81.2243\n",
      "validation Loss: 0.0016 Acc: 82.7024\n",
      "Epoch 6/99\n",
      "training Loss: 0.0018 Acc: 77.6888\n",
      "validation Loss: 0.0016 Acc: 81.7738\n",
      "Epoch 7/99\n",
      "training Loss: 0.0017 Acc: 81.6707\n",
      "validation Loss: 0.0015 Acc: 84.2738\n",
      "Epoch 8/99\n",
      "training Loss: 0.0017 Acc: 81.1886\n",
      "validation Loss: 0.0017 Acc: 83.0595\n",
      "Epoch 9/99\n",
      "training Loss: 0.0021 Acc: 76.4954\n",
      "validation Loss: 0.0016 Acc: 83.2738\n",
      "Epoch 10/99\n",
      "training Loss: 0.0019 Acc: 75.7931\n",
      "validation Loss: 0.0015 Acc: 84.2024\n",
      "Epoch 11/99\n",
      "training Loss: 0.0018 Acc: 75.7068\n",
      "validation Loss: 0.0016 Acc: 84.0000\n",
      "Early stopped.\n",
      "Best val acc: 84.464286\n",
      "----------\n",
      "Epoch 0/99\n",
      "training Loss: 0.0017 Acc: 81.6053\n",
      "validation Loss: 0.0015 Acc: 83.7381\n",
      "Saving..\n",
      "Epoch 1/99\n",
      "training Loss: 0.0016 Acc: 83.5932\n",
      "validation Loss: 0.0015 Acc: 84.0952\n",
      "Saving..\n",
      "Epoch 2/99\n",
      "training Loss: 0.0016 Acc: 82.9683\n",
      "validation Loss: 0.0014 Acc: 84.3810\n",
      "Saving..\n",
      "Epoch 3/99\n",
      "training Loss: 0.0016 Acc: 83.4206\n",
      "validation Loss: 0.0014 Acc: 84.5000\n",
      "Saving..\n",
      "Epoch 4/99\n",
      "training Loss: 0.0016 Acc: 83.2153\n",
      "validation Loss: 0.0015 Acc: 84.4643\n",
      "Epoch 5/99\n",
      "training Loss: 0.0016 Acc: 82.6112\n",
      "validation Loss: 0.0015 Acc: 83.1667\n",
      "Epoch 6/99\n",
      "training Loss: 0.0016 Acc: 82.8105\n",
      "validation Loss: 0.0015 Acc: 84.5000\n",
      "Epoch 7/99\n",
      "training Loss: 0.0016 Acc: 83.3641\n",
      "validation Loss: 0.0014 Acc: 84.3929\n",
      "Epoch 8/99\n",
      "training Loss: 0.0016 Acc: 83.2897\n",
      "validation Loss: 0.0014 Acc: 84.2500\n",
      "Epoch 9/99\n",
      "training Loss: 0.0016 Acc: 82.8433\n",
      "validation Loss: 0.0014 Acc: 84.7381\n",
      "Saving..\n",
      "Epoch 10/99\n",
      "training Loss: 0.0019 Acc: 79.9893\n",
      "validation Loss: 0.0016 Acc: 84.4405\n",
      "Epoch 11/99\n",
      "training Loss: 0.0024 Acc: 66.4812\n",
      "validation Loss: 0.0024 Acc: 65.3095\n",
      "Epoch 12/99\n",
      "training Loss: 0.0028 Acc: 55.9133\n",
      "validation Loss: 0.0027 Acc: 57.6190\n",
      "Epoch 13/99\n",
      "training Loss: 0.0029 Acc: 52.9641\n",
      "validation Loss: 0.0028 Acc: 50.0000\n",
      "Epoch 14/99\n",
      "training Loss: 0.0028 Acc: 50.2797\n",
      "validation Loss: 0.0028 Acc: 50.0000\n",
      "Epoch 15/99\n",
      "training Loss: 0.0028 Acc: 49.4346\n",
      "validation Loss: 0.0028 Acc: 50.0000\n",
      "Epoch 16/99\n",
      "training Loss: 0.0028 Acc: 49.3512\n",
      "validation Loss: 0.0028 Acc: 50.0000\n",
      "Epoch 17/99\n",
      "training Loss: 0.0028 Acc: 50.2797\n",
      "validation Loss: 0.0028 Acc: 50.0000\n",
      "Epoch 18/99\n",
      "training Loss: 0.0028 Acc: 50.0476\n",
      "validation Loss: 0.0028 Acc: 50.0000\n",
      "Epoch 19/99\n",
      "training Loss: 0.0028 Acc: 50.0179\n",
      "validation Loss: 0.0028 Acc: 50.0000\n",
      "Early stopped.\n",
      "Best val acc: 84.738095\n",
      "----------\n",
      "Epoch 0/99\n",
      "training Loss: 0.0017 Acc: 82.1677\n",
      "validation Loss: 0.0016 Acc: 82.4167\n",
      "Saving..\n",
      "Epoch 1/99\n",
      "training Loss: 0.0016 Acc: 83.3760\n",
      "validation Loss: 0.0016 Acc: 83.4167\n",
      "Saving..\n",
      "Epoch 2/99\n",
      "training Loss: 0.0016 Acc: 83.1974\n",
      "validation Loss: 0.0015 Acc: 84.1905\n",
      "Saving..\n",
      "Epoch 3/99\n",
      "training Loss: 0.0016 Acc: 83.0397\n",
      "validation Loss: 0.0015 Acc: 83.7262\n",
      "Epoch 4/99\n",
      "training Loss: 0.0015 Acc: 83.6022\n",
      "validation Loss: 0.0015 Acc: 84.1905\n",
      "Epoch 5/99\n",
      "training Loss: 0.0016 Acc: 83.2242\n",
      "validation Loss: 0.0016 Acc: 84.3810\n",
      "Saving..\n",
      "Epoch 6/99\n",
      "training Loss: 0.0016 Acc: 82.7302\n",
      "validation Loss: 0.0016 Acc: 83.9524\n",
      "Epoch 7/99\n",
      "training Loss: 0.0016 Acc: 82.1975\n",
      "validation Loss: 0.0016 Acc: 84.5119\n",
      "Saving..\n",
      "Epoch 8/99\n",
      "training Loss: 0.0016 Acc: 82.2183\n",
      "validation Loss: 0.0016 Acc: 83.8929\n",
      "Epoch 9/99\n",
      "training Loss: 0.0016 Acc: 83.4712\n",
      "validation Loss: 0.0014 Acc: 84.2381\n",
      "Epoch 10/99\n",
      "training Loss: 0.0015 Acc: 83.6051\n",
      "validation Loss: 0.0015 Acc: 82.7976\n",
      "Epoch 11/99\n",
      "training Loss: 0.0015 Acc: 84.1527\n",
      "validation Loss: 0.0014 Acc: 84.3095\n",
      "Epoch 12/99\n",
      "training Loss: 0.0015 Acc: 84.2271\n",
      "validation Loss: 0.0014 Acc: 84.4048\n",
      "Epoch 13/99\n",
      "training Loss: 0.0015 Acc: 84.2271\n",
      "validation Loss: 0.0014 Acc: 84.4762\n",
      "Epoch 14/99\n",
      "training Loss: 0.0015 Acc: 84.4384\n",
      "validation Loss: 0.0014 Acc: 84.7857\n",
      "Saving..\n",
      "Epoch 15/99\n",
      "training Loss: 0.0015 Acc: 84.4503\n",
      "validation Loss: 0.0014 Acc: 84.7738\n",
      "Epoch 16/99\n",
      "training Loss: 0.0015 Acc: 84.4503\n",
      "validation Loss: 0.0014 Acc: 83.5000\n",
      "Epoch 17/99\n",
      "training Loss: 0.0015 Acc: 84.4979\n",
      "validation Loss: 0.0015 Acc: 84.8690\n",
      "Saving..\n",
      "Epoch 18/99\n",
      "training Loss: 0.0015 Acc: 84.5575\n",
      "validation Loss: 0.0014 Acc: 84.5714\n",
      "Epoch 19/99\n",
      "training Loss: 0.0014 Acc: 84.7479\n",
      "validation Loss: 0.0014 Acc: 84.8095\n",
      "Epoch 20/99\n",
      "training Loss: 0.0014 Acc: 84.8253\n",
      "validation Loss: 0.0014 Acc: 84.5833\n",
      "Epoch 21/99\n",
      "training Loss: 0.0014 Acc: 84.5902\n",
      "validation Loss: 0.0014 Acc: 84.9524\n",
      "Saving..\n",
      "Epoch 22/99\n",
      "training Loss: 0.0014 Acc: 84.9473\n",
      "validation Loss: 0.0014 Acc: 84.9048\n",
      "Epoch 23/99\n",
      "training Loss: 0.0014 Acc: 84.9563\n",
      "validation Loss: 0.0014 Acc: 84.9524\n",
      "Epoch 24/99\n",
      "training Loss: 0.0014 Acc: 85.0574\n",
      "validation Loss: 0.0014 Acc: 85.0238\n",
      "Saving..\n",
      "Epoch 25/99\n",
      "training Loss: 0.0014 Acc: 84.9563\n",
      "validation Loss: 0.0015 Acc: 84.6190\n",
      "Epoch 26/99\n",
      "training Loss: 0.0014 Acc: 85.2181\n",
      "validation Loss: 0.0014 Acc: 85.0952\n",
      "Saving..\n",
      "Epoch 27/99\n",
      "training Loss: 0.0014 Acc: 85.2092\n",
      "validation Loss: 0.0014 Acc: 84.9762\n",
      "Epoch 28/99\n",
      "training Loss: 0.0014 Acc: 85.2300\n",
      "validation Loss: 0.0014 Acc: 84.8571\n",
      "Epoch 29/99\n",
      "training Loss: 0.0014 Acc: 85.2479\n",
      "validation Loss: 0.0014 Acc: 85.0000\n",
      "Epoch 30/99\n",
      "training Loss: 0.0014 Acc: 85.2717\n",
      "validation Loss: 0.0014 Acc: 85.1190\n",
      "Saving..\n",
      "Epoch 31/99\n",
      "training Loss: 0.0014 Acc: 85.0545\n",
      "validation Loss: 0.0014 Acc: 85.1071\n",
      "Epoch 32/99\n",
      "training Loss: 0.0014 Acc: 85.2122\n",
      "validation Loss: 0.0014 Acc: 85.0714\n",
      "Epoch 33/99\n",
      "training Loss: 0.0014 Acc: 85.3312\n",
      "validation Loss: 0.0014 Acc: 85.0595\n",
      "Epoch 34/99\n",
      "training Loss: 0.0014 Acc: 85.2806\n",
      "validation Loss: 0.0014 Acc: 85.0357\n",
      "Epoch 35/99\n",
      "training Loss: 0.0014 Acc: 85.2925\n",
      "validation Loss: 0.0014 Acc: 85.1071\n",
      "Epoch 36/99\n",
      "training Loss: 0.0014 Acc: 85.3074\n",
      "validation Loss: 0.0014 Acc: 85.0476\n",
      "Epoch 37/99\n",
      "training Loss: 0.0014 Acc: 85.2896\n",
      "validation Loss: 0.0014 Acc: 85.0238\n",
      "Epoch 38/99\n",
      "training Loss: 0.0013 Acc: 85.4027\n",
      "validation Loss: 0.0014 Acc: 85.0119\n",
      "Epoch 39/99\n",
      "training Loss: 0.0014 Acc: 85.5396\n",
      "validation Loss: 0.0014 Acc: 84.9881\n",
      "Epoch 40/99\n",
      "training Loss: 0.0014 Acc: 85.3431\n",
      "validation Loss: 0.0014 Acc: 85.1310\n",
      "Saving..\n",
      "Epoch 41/99\n",
      "training Loss: 0.0013 Acc: 85.4741\n",
      "validation Loss: 0.0014 Acc: 85.0476\n",
      "Epoch 42/99\n",
      "training Loss: 0.0013 Acc: 85.2985\n",
      "validation Loss: 0.0014 Acc: 85.2024\n",
      "Saving..\n",
      "Epoch 43/99\n",
      "training Loss: 0.0013 Acc: 85.5485\n",
      "validation Loss: 0.0014 Acc: 85.1310\n",
      "Epoch 44/99\n",
      "training Loss: 0.0013 Acc: 85.4741\n",
      "validation Loss: 0.0014 Acc: 85.0000\n",
      "Epoch 45/99\n",
      "training Loss: 0.0013 Acc: 85.4800\n",
      "validation Loss: 0.0014 Acc: 85.0238\n",
      "Epoch 46/99\n",
      "training Loss: 0.0013 Acc: 85.5009\n",
      "validation Loss: 0.0014 Acc: 85.0238\n",
      "Epoch 47/99\n",
      "training Loss: 0.0013 Acc: 85.6437\n",
      "validation Loss: 0.0014 Acc: 85.0357\n",
      "Epoch 48/99\n",
      "training Loss: 0.0013 Acc: 85.4592\n",
      "validation Loss: 0.0014 Acc: 84.9643\n",
      "Epoch 49/99\n",
      "training Loss: 0.0013 Acc: 85.7300\n",
      "validation Loss: 0.0014 Acc: 85.0357\n",
      "Epoch 50/99\n",
      "training Loss: 0.0013 Acc: 85.6378\n",
      "validation Loss: 0.0014 Acc: 85.0119\n",
      "Epoch 51/99\n",
      "training Loss: 0.0013 Acc: 85.5455\n",
      "validation Loss: 0.0014 Acc: 85.0833\n",
      "Epoch 52/99\n",
      "training Loss: 0.0013 Acc: 85.7419\n",
      "validation Loss: 0.0014 Acc: 85.0476\n",
      "Early stopped.\n",
      "Best val acc: 85.202381\n",
      "----------\n",
      "Average best_acc across k-fold: 85.1173598123\n",
      "New configuration: {'hidden_layers': 2, 'dropout_g': 0.16210953077108023, 'initial_nodes': 452, 'dropout': 0.09835951181948677, 'gru_layers': 3, 'batch_size': 392, 'gru_size': 330, 'learning_rate': 0.00027077506445052755}\n",
      "Epoch 0/99\n",
      "training Loss: 0.0012 Acc: 79.5923\n",
      "validation Loss: 0.0010 Acc: 83.1707\n",
      "Saving..\n",
      "Epoch 1/99\n",
      "training Loss: 0.0010 Acc: 83.3185\n",
      "validation Loss: 0.0010 Acc: 83.3016\n",
      "Saving..\n",
      "Epoch 2/99\n",
      "training Loss: 0.0009 Acc: 83.7917\n",
      "validation Loss: 0.0009 Acc: 84.6346\n",
      "Saving..\n",
      "Epoch 3/99\n",
      "training Loss: 0.0009 Acc: 84.5685\n",
      "validation Loss: 0.0009 Acc: 84.3728\n",
      "Epoch 4/99\n",
      "training Loss: 0.0009 Acc: 84.8363\n",
      "validation Loss: 0.0009 Acc: 85.2297\n",
      "Saving..\n",
      "Epoch 5/99\n",
      "training Loss: 0.0009 Acc: 84.9792\n",
      "validation Loss: 0.0009 Acc: 85.5035\n",
      "Saving..\n",
      "Epoch 6/99\n",
      "training Loss: 0.0009 Acc: 85.2470\n",
      "validation Loss: 0.0009 Acc: 85.6106\n",
      "Saving..\n",
      "Epoch 7/99\n",
      "training Loss: 0.0009 Acc: 85.3185\n",
      "validation Loss: 0.0009 Acc: 85.8605\n",
      "Saving..\n",
      "Epoch 8/99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Loss: 0.0008 Acc: 85.3631\n",
      "validation Loss: 0.0009 Acc: 85.7534\n",
      "Epoch 9/99\n",
      "training Loss: 0.0008 Acc: 85.4464\n",
      "validation Loss: 0.0009 Acc: 85.7653\n",
      "Epoch 10/99\n",
      "training Loss: 0.0008 Acc: 85.3512\n",
      "validation Loss: 0.0009 Acc: 85.6939\n",
      "Epoch 11/99\n",
      "training Loss: 0.0008 Acc: 85.5952\n",
      "validation Loss: 0.0008 Acc: 85.7058\n",
      "Epoch 12/99\n",
      "training Loss: 0.0008 Acc: 85.6875\n",
      "validation Loss: 0.0009 Acc: 85.7653\n",
      "Epoch 13/99\n",
      "training Loss: 0.0008 Acc: 85.5327\n",
      "validation Loss: 0.0008 Acc: 85.7772\n",
      "Epoch 14/99\n",
      "training Loss: 0.0008 Acc: 85.7530\n",
      "validation Loss: 0.0009 Acc: 85.7058\n",
      "Epoch 15/99\n",
      "training Loss: 0.0008 Acc: 85.6994\n",
      "validation Loss: 0.0009 Acc: 85.6463\n",
      "Epoch 16/99\n",
      "training Loss: 0.0008 Acc: 85.7500\n",
      "validation Loss: 0.0008 Acc: 85.9081\n",
      "Saving..\n",
      "Epoch 17/99\n",
      "training Loss: 0.0008 Acc: 85.8363\n",
      "validation Loss: 0.0009 Acc: 85.7415\n",
      "Epoch 18/99\n",
      "training Loss: 0.0008 Acc: 85.8601\n",
      "validation Loss: 0.0009 Acc: 85.9319\n",
      "Saving..\n",
      "Epoch 19/99\n",
      "training Loss: 0.0008 Acc: 85.9940\n",
      "validation Loss: 0.0008 Acc: 86.0628\n",
      "Saving..\n",
      "Epoch 20/99\n",
      "training Loss: 0.0008 Acc: 85.8393\n",
      "validation Loss: 0.0008 Acc: 86.0628\n",
      "Epoch 21/99\n",
      "training Loss: 0.0008 Acc: 85.9970\n",
      "validation Loss: 0.0008 Acc: 85.9438\n",
      "Epoch 22/99\n",
      "training Loss: 0.0008 Acc: 85.9732\n",
      "validation Loss: 0.0008 Acc: 85.9557\n",
      "Epoch 23/99\n",
      "training Loss: 0.0008 Acc: 86.0387\n",
      "validation Loss: 0.0008 Acc: 85.5749\n",
      "Epoch 24/99\n",
      "training Loss: 0.0008 Acc: 86.0208\n",
      "validation Loss: 0.0008 Acc: 85.9795\n",
      "Epoch 25/99\n",
      "training Loss: 0.0008 Acc: 86.0714\n",
      "validation Loss: 0.0008 Acc: 85.6939\n",
      "Epoch 26/99\n",
      "training Loss: 0.0008 Acc: 86.0060\n",
      "validation Loss: 0.0008 Acc: 86.0509\n",
      "Epoch 27/99\n",
      "training Loss: 0.0008 Acc: 85.9911\n",
      "validation Loss: 0.0008 Acc: 85.9914\n",
      "Epoch 28/99\n",
      "training Loss: 0.0008 Acc: 86.1607\n",
      "validation Loss: 0.0008 Acc: 85.8724\n",
      "Epoch 29/99\n",
      "training Loss: 0.0008 Acc: 86.0804\n",
      "validation Loss: 0.0008 Acc: 85.8605\n",
      "Early stopped.\n",
      "Best val acc: 86.062842\n",
      "----------\n",
      "Epoch 0/99\n",
      "training Loss: 0.0012 Acc: 79.8256\n",
      "validation Loss: 0.0010 Acc: 83.3452\n",
      "Saving..\n",
      "Epoch 1/99\n",
      "training Loss: 0.0010 Acc: 83.1617\n",
      "validation Loss: 0.0010 Acc: 83.5357\n",
      "Saving..\n",
      "Epoch 2/99\n",
      "training Loss: 0.0009 Acc: 83.8402\n",
      "validation Loss: 0.0009 Acc: 84.4048\n",
      "Saving..\n",
      "Epoch 3/99\n",
      "training Loss: 0.0009 Acc: 84.6378\n",
      "validation Loss: 0.0009 Acc: 84.6667\n",
      "Saving..\n",
      "Epoch 4/99\n",
      "training Loss: 0.0009 Acc: 84.9414\n",
      "validation Loss: 0.0009 Acc: 84.5476\n",
      "Epoch 5/99\n",
      "training Loss: 0.0009 Acc: 85.0961\n",
      "validation Loss: 0.0009 Acc: 85.4048\n",
      "Saving..\n",
      "Epoch 6/99\n",
      "training Loss: 0.0009 Acc: 85.2806\n",
      "validation Loss: 0.0009 Acc: 85.5357\n",
      "Saving..\n",
      "Epoch 7/99\n",
      "training Loss: 0.0009 Acc: 85.2479\n",
      "validation Loss: 0.0009 Acc: 85.7976\n",
      "Saving..\n",
      "Epoch 8/99\n",
      "training Loss: 0.0009 Acc: 85.4354\n",
      "validation Loss: 0.0008 Acc: 85.7381\n",
      "Epoch 9/99\n",
      "training Loss: 0.0008 Acc: 85.3729\n",
      "validation Loss: 0.0008 Acc: 85.7738\n",
      "Epoch 10/99\n",
      "training Loss: 0.0008 Acc: 85.5931\n",
      "validation Loss: 0.0009 Acc: 86.0476\n",
      "Saving..\n",
      "Epoch 11/99\n",
      "training Loss: 0.0008 Acc: 85.5663\n",
      "validation Loss: 0.0009 Acc: 86.1548\n",
      "Saving..\n",
      "Epoch 12/99\n",
      "training Loss: 0.0008 Acc: 85.6497\n",
      "validation Loss: 0.0008 Acc: 85.9405\n",
      "Epoch 13/99\n",
      "training Loss: 0.0008 Acc: 85.7151\n",
      "validation Loss: 0.0008 Acc: 86.1190\n",
      "Epoch 14/99\n",
      "training Loss: 0.0008 Acc: 85.6110\n",
      "validation Loss: 0.0008 Acc: 86.2500\n",
      "Saving..\n",
      "Epoch 15/99\n",
      "training Loss: 0.0008 Acc: 85.6407\n",
      "validation Loss: 0.0008 Acc: 86.1905\n",
      "Epoch 16/99\n",
      "training Loss: 0.0008 Acc: 85.6080\n",
      "validation Loss: 0.0008 Acc: 86.1310\n",
      "Epoch 17/99\n",
      "training Loss: 0.0008 Acc: 85.7211\n",
      "validation Loss: 0.0008 Acc: 86.1429\n",
      "Epoch 18/99\n",
      "training Loss: 0.0008 Acc: 85.7717\n",
      "validation Loss: 0.0008 Acc: 86.1071\n",
      "Epoch 19/99\n",
      "training Loss: 0.0008 Acc: 85.7389\n",
      "validation Loss: 0.0008 Acc: 86.2024\n",
      "Epoch 20/99\n",
      "training Loss: 0.0008 Acc: 85.7508\n",
      "validation Loss: 0.0008 Acc: 86.3452\n",
      "Saving..\n",
      "Epoch 21/99\n",
      "training Loss: 0.0008 Acc: 85.8491\n",
      "validation Loss: 0.0008 Acc: 86.1310\n",
      "Epoch 22/99\n",
      "training Loss: 0.0008 Acc: 85.9294\n",
      "validation Loss: 0.0008 Acc: 86.2857\n",
      "Epoch 23/99\n",
      "training Loss: 0.0008 Acc: 85.9532\n",
      "validation Loss: 0.0008 Acc: 86.2024\n",
      "Epoch 24/99\n",
      "training Loss: 0.0008 Acc: 85.8491\n",
      "validation Loss: 0.0008 Acc: 86.3333\n",
      "Epoch 25/99\n",
      "training Loss: 0.0008 Acc: 85.9830\n",
      "validation Loss: 0.0008 Acc: 86.2738\n",
      "Epoch 26/99\n",
      "training Loss: 0.0008 Acc: 85.9502\n",
      "validation Loss: 0.0008 Acc: 86.2976\n",
      "Epoch 27/99\n",
      "training Loss: 0.0008 Acc: 85.8372\n",
      "validation Loss: 0.0008 Acc: 86.4881\n",
      "Saving..\n",
      "Epoch 28/99\n",
      "training Loss: 0.0008 Acc: 85.8937\n",
      "validation Loss: 0.0008 Acc: 86.1548\n",
      "Epoch 29/99\n",
      "training Loss: 0.0008 Acc: 86.0842\n",
      "validation Loss: 0.0008 Acc: 86.3690\n",
      "Epoch 30/99\n",
      "training Loss: 0.0008 Acc: 85.9383\n",
      "validation Loss: 0.0008 Acc: 86.3571\n",
      "Epoch 31/99\n",
      "training Loss: 0.0008 Acc: 86.1883\n",
      "validation Loss: 0.0008 Acc: 86.3095\n",
      "Epoch 32/99\n",
      "training Loss: 0.0008 Acc: 86.0782\n",
      "validation Loss: 0.0008 Acc: 86.2619\n",
      "Epoch 33/99\n",
      "training Loss: 0.0008 Acc: 86.1586\n",
      "validation Loss: 0.0008 Acc: 86.3333\n",
      "Epoch 34/99\n",
      "training Loss: 0.0008 Acc: 86.0990\n",
      "validation Loss: 0.0008 Acc: 86.2976\n",
      "Epoch 35/99\n",
      "training Loss: 0.0008 Acc: 86.1080\n",
      "validation Loss: 0.0008 Acc: 86.1786\n",
      "Epoch 36/99\n",
      "training Loss: 0.0008 Acc: 86.0752\n",
      "validation Loss: 0.0008 Acc: 86.3095\n",
      "Epoch 37/99\n",
      "training Loss: 0.0008 Acc: 86.0842\n",
      "validation Loss: 0.0008 Acc: 86.4286\n",
      "Early stopped.\n",
      "Best val acc: 86.488095\n",
      "----------\n",
      "Epoch 0/99\n",
      "training Loss: 0.0012 Acc: 79.8673\n",
      "validation Loss: 0.0010 Acc: 83.0238\n",
      "Saving..\n",
      "Epoch 1/99\n",
      "training Loss: 0.0010 Acc: 83.2153\n",
      "validation Loss: 0.0010 Acc: 83.7381\n",
      "Saving..\n",
      "Epoch 2/99\n",
      "training Loss: 0.0009 Acc: 83.8670\n",
      "validation Loss: 0.0009 Acc: 84.3214\n",
      "Saving..\n",
      "Epoch 3/99\n",
      "training Loss: 0.0009 Acc: 84.4831\n",
      "validation Loss: 0.0009 Acc: 84.6905\n",
      "Saving..\n",
      "Epoch 4/99\n",
      "training Loss: 0.0009 Acc: 84.9116\n",
      "validation Loss: 0.0009 Acc: 85.0714\n",
      "Saving..\n",
      "Epoch 5/99\n",
      "training Loss: 0.0009 Acc: 85.1854\n",
      "validation Loss: 0.0009 Acc: 85.3452\n",
      "Saving..\n",
      "Epoch 6/99\n",
      "training Loss: 0.0009 Acc: 85.1854\n",
      "validation Loss: 0.0009 Acc: 85.5833\n",
      "Saving..\n",
      "Epoch 7/99\n",
      "training Loss: 0.0009 Acc: 85.3997\n",
      "validation Loss: 0.0009 Acc: 85.3571\n",
      "Epoch 8/99\n",
      "training Loss: 0.0008 Acc: 85.4830\n",
      "validation Loss: 0.0009 Acc: 85.6310\n",
      "Saving..\n",
      "Epoch 9/99\n",
      "training Loss: 0.0008 Acc: 85.5901\n",
      "validation Loss: 0.0009 Acc: 85.5476\n",
      "Epoch 10/99\n",
      "training Loss: 0.0008 Acc: 85.7211\n",
      "validation Loss: 0.0009 Acc: 85.7143\n",
      "Saving..\n",
      "Epoch 11/99\n",
      "training Loss: 0.0008 Acc: 85.6407\n",
      "validation Loss: 0.0009 Acc: 85.3571\n",
      "Epoch 12/99\n",
      "training Loss: 0.0008 Acc: 85.6705\n",
      "validation Loss: 0.0009 Acc: 85.7738\n",
      "Saving..\n",
      "Epoch 13/99\n",
      "training Loss: 0.0008 Acc: 85.7122\n",
      "validation Loss: 0.0009 Acc: 85.2262\n",
      "Epoch 14/99\n",
      "training Loss: 0.0008 Acc: 85.8937\n",
      "validation Loss: 0.0009 Acc: 85.6786\n",
      "Epoch 15/99\n",
      "training Loss: 0.0008 Acc: 85.6854\n",
      "validation Loss: 0.0009 Acc: 85.6905\n",
      "Epoch 16/99\n",
      "training Loss: 0.0008 Acc: 85.8848\n",
      "validation Loss: 0.0009 Acc: 85.8810\n",
      "Saving..\n",
      "Epoch 17/99\n",
      "training Loss: 0.0008 Acc: 85.9770\n",
      "validation Loss: 0.0009 Acc: 85.8690\n",
      "Epoch 18/99\n",
      "training Loss: 0.0008 Acc: 85.8996\n",
      "validation Loss: 0.0009 Acc: 85.8690\n",
      "Epoch 19/99\n",
      "training Loss: 0.0008 Acc: 85.9175\n",
      "validation Loss: 0.0009 Acc: 85.9405\n",
      "Saving..\n",
      "Epoch 20/99\n",
      "training Loss: 0.0008 Acc: 85.8699\n",
      "validation Loss: 0.0009 Acc: 85.8333\n",
      "Epoch 21/99\n",
      "training Loss: 0.0008 Acc: 86.0068\n",
      "validation Loss: 0.0009 Acc: 85.6548\n",
      "Epoch 22/99\n",
      "training Loss: 0.0008 Acc: 86.0663\n",
      "validation Loss: 0.0009 Acc: 85.9643\n",
      "Saving..\n",
      "Epoch 23/99\n",
      "training Loss: 0.0008 Acc: 86.0276\n",
      "validation Loss: 0.0009 Acc: 85.7500\n",
      "Epoch 24/99\n",
      "training Loss: 0.0008 Acc: 85.9324\n",
      "validation Loss: 0.0009 Acc: 85.9286\n",
      "Epoch 25/99\n",
      "training Loss: 0.0008 Acc: 85.9681\n",
      "validation Loss: 0.0009 Acc: 85.8571\n",
      "Epoch 26/99\n",
      "training Loss: 0.0008 Acc: 85.9889\n",
      "validation Loss: 0.0008 Acc: 85.9643\n",
      "Epoch 27/99\n",
      "training Loss: 0.0008 Acc: 86.1883\n",
      "validation Loss: 0.0009 Acc: 85.8214\n",
      "Epoch 28/99\n",
      "training Loss: 0.0008 Acc: 86.0157\n",
      "validation Loss: 0.0009 Acc: 85.6429\n",
      "Epoch 29/99\n",
      "training Loss: 0.0008 Acc: 86.0455\n",
      "validation Loss: 0.0009 Acc: 85.7143\n",
      "Epoch 30/99\n",
      "training Loss: 0.0008 Acc: 86.1407\n",
      "validation Loss: 0.0009 Acc: 85.6905\n",
      "Epoch 31/99\n",
      "training Loss: 0.0008 Acc: 85.9919\n",
      "validation Loss: 0.0009 Acc: 85.8095\n",
      "Epoch 32/99\n",
      "training Loss: 0.0008 Acc: 86.1288\n",
      "validation Loss: 0.0008 Acc: 85.8095\n",
      "Early stopped.\n",
      "Best val acc: 85.964286\n",
      "----------\n",
      "Epoch 0/99\n",
      "training Loss: 0.0012 Acc: 79.9744\n",
      "validation Loss: 0.0010 Acc: 83.3571\n",
      "Saving..\n",
      "Epoch 1/99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Loss: 0.0010 Acc: 83.2064\n",
      "validation Loss: 0.0010 Acc: 83.5833\n",
      "Saving..\n",
      "Epoch 2/99\n",
      "training Loss: 0.0009 Acc: 83.7450\n",
      "validation Loss: 0.0009 Acc: 84.3095\n",
      "Saving..\n",
      "Epoch 3/99\n",
      "training Loss: 0.0009 Acc: 84.3521\n",
      "validation Loss: 0.0009 Acc: 84.8929\n",
      "Saving..\n",
      "Epoch 4/99\n",
      "training Loss: 0.0009 Acc: 84.7985\n",
      "validation Loss: 0.0009 Acc: 85.2143\n",
      "Saving..\n",
      "Epoch 5/99\n",
      "training Loss: 0.0009 Acc: 84.9979\n",
      "validation Loss: 0.0009 Acc: 85.2619\n",
      "Saving..\n",
      "Epoch 6/99\n",
      "training Loss: 0.0009 Acc: 85.1646\n",
      "validation Loss: 0.0009 Acc: 85.3571\n",
      "Saving..\n",
      "Epoch 7/99\n",
      "training Loss: 0.0009 Acc: 85.2211\n",
      "validation Loss: 0.0009 Acc: 85.5952\n",
      "Saving..\n",
      "Epoch 8/99\n",
      "training Loss: 0.0009 Acc: 85.1556\n",
      "validation Loss: 0.0009 Acc: 85.8214\n",
      "Saving..\n",
      "Epoch 9/99\n",
      "training Loss: 0.0008 Acc: 85.3967\n",
      "validation Loss: 0.0009 Acc: 85.9762\n",
      "Saving..\n",
      "Epoch 10/99\n",
      "training Loss: 0.0008 Acc: 85.4592\n",
      "validation Loss: 0.0008 Acc: 85.7976\n",
      "Epoch 11/99\n",
      "training Loss: 0.0008 Acc: 85.5544\n",
      "validation Loss: 0.0008 Acc: 86.2024\n",
      "Saving..\n",
      "Epoch 12/99\n",
      "training Loss: 0.0008 Acc: 85.4860\n",
      "validation Loss: 0.0008 Acc: 85.8333\n",
      "Epoch 13/99\n",
      "training Loss: 0.0008 Acc: 85.8342\n",
      "validation Loss: 0.0008 Acc: 86.1310\n",
      "Epoch 14/99\n",
      "training Loss: 0.0008 Acc: 85.6854\n",
      "validation Loss: 0.0008 Acc: 85.9405\n",
      "Epoch 15/99\n",
      "training Loss: 0.0008 Acc: 85.5723\n",
      "validation Loss: 0.0008 Acc: 85.9405\n",
      "Epoch 16/99\n",
      "training Loss: 0.0008 Acc: 85.6764\n",
      "validation Loss: 0.0008 Acc: 85.8333\n",
      "Epoch 17/99\n",
      "training Loss: 0.0008 Acc: 85.7032\n",
      "validation Loss: 0.0008 Acc: 85.9405\n",
      "Epoch 18/99\n",
      "training Loss: 0.0008 Acc: 85.7449\n",
      "validation Loss: 0.0008 Acc: 85.8690\n",
      "Epoch 19/99\n",
      "training Loss: 0.0008 Acc: 85.7241\n",
      "validation Loss: 0.0008 Acc: 86.0119\n",
      "Epoch 20/99\n",
      "training Loss: 0.0008 Acc: 85.8610\n",
      "validation Loss: 0.0008 Acc: 86.2857\n",
      "Saving..\n",
      "Epoch 21/99\n",
      "training Loss: 0.0008 Acc: 85.8193\n",
      "validation Loss: 0.0008 Acc: 86.0357\n",
      "Epoch 22/99\n",
      "training Loss: 0.0008 Acc: 86.0008\n",
      "validation Loss: 0.0008 Acc: 86.0119\n",
      "Epoch 23/99\n",
      "training Loss: 0.0008 Acc: 86.0008\n",
      "validation Loss: 0.0008 Acc: 86.1667\n",
      "Epoch 24/99\n",
      "training Loss: 0.0008 Acc: 85.9621\n",
      "validation Loss: 0.0008 Acc: 86.2976\n",
      "Saving..\n",
      "Epoch 25/99\n",
      "training Loss: 0.0008 Acc: 86.0157\n",
      "validation Loss: 0.0008 Acc: 86.2619\n",
      "Epoch 26/99\n",
      "training Loss: 0.0008 Acc: 86.1258\n",
      "validation Loss: 0.0008 Acc: 86.2143\n",
      "Epoch 27/99\n",
      "training Loss: 0.0008 Acc: 86.0306\n",
      "validation Loss: 0.0008 Acc: 86.1905\n",
      "Epoch 28/99\n",
      "training Loss: 0.0008 Acc: 86.1288\n",
      "validation Loss: 0.0008 Acc: 86.0833\n",
      "Epoch 29/99\n",
      "training Loss: 0.0008 Acc: 86.0782\n",
      "validation Loss: 0.0008 Acc: 86.1667\n",
      "Epoch 30/99\n",
      "training Loss: 0.0008 Acc: 86.1318\n",
      "validation Loss: 0.0008 Acc: 86.0714\n",
      "Epoch 31/99\n",
      "training Loss: 0.0008 Acc: 86.2062\n",
      "validation Loss: 0.0008 Acc: 85.8810\n",
      "Epoch 32/99\n",
      "training Loss: 0.0008 Acc: 86.0604\n",
      "validation Loss: 0.0008 Acc: 86.2024\n",
      "Epoch 33/99\n",
      "training Loss: 0.0008 Acc: 86.1973\n",
      "validation Loss: 0.0008 Acc: 86.1905\n",
      "Epoch 34/99\n",
      "training Loss: 0.0008 Acc: 86.3044\n",
      "validation Loss: 0.0008 Acc: 86.1786\n",
      "Early stopped.\n",
      "Best val acc: 86.297619\n",
      "----------\n",
      "Epoch 0/99\n",
      "training Loss: 0.0012 Acc: 79.1709\n",
      "validation Loss: 0.0010 Acc: 83.2738\n",
      "Saving..\n",
      "Epoch 1/99\n",
      "training Loss: 0.0010 Acc: 83.3135\n",
      "validation Loss: 0.0010 Acc: 82.6190\n",
      "Epoch 2/99\n",
      "training Loss: 0.0009 Acc: 83.9623\n",
      "validation Loss: 0.0009 Acc: 83.9762\n",
      "Saving..\n",
      "Epoch 3/99\n",
      "training Loss: 0.0009 Acc: 84.8164\n",
      "validation Loss: 0.0009 Acc: 84.3571\n",
      "Saving..\n",
      "Epoch 4/99\n",
      "training Loss: 0.0009 Acc: 85.0307\n",
      "validation Loss: 0.0009 Acc: 84.7143\n",
      "Saving..\n",
      "Epoch 5/99\n",
      "training Loss: 0.0009 Acc: 85.1616\n",
      "validation Loss: 0.0009 Acc: 84.8333\n",
      "Saving..\n",
      "Epoch 6/99\n",
      "training Loss: 0.0009 Acc: 85.2360\n",
      "validation Loss: 0.0009 Acc: 84.7976\n",
      "Epoch 7/99\n",
      "training Loss: 0.0009 Acc: 85.6199\n",
      "validation Loss: 0.0009 Acc: 84.8333\n",
      "Epoch 8/99\n",
      "training Loss: 0.0008 Acc: 85.6675\n",
      "validation Loss: 0.0009 Acc: 84.9524\n",
      "Saving..\n",
      "Epoch 9/99\n",
      "training Loss: 0.0008 Acc: 85.7241\n",
      "validation Loss: 0.0009 Acc: 84.8095\n",
      "Epoch 10/99\n",
      "training Loss: 0.0008 Acc: 85.8639\n",
      "validation Loss: 0.0009 Acc: 84.9524\n",
      "Epoch 11/99\n",
      "training Loss: 0.0008 Acc: 85.8729\n",
      "validation Loss: 0.0009 Acc: 85.1667\n",
      "Saving..\n",
      "Epoch 12/99\n",
      "training Loss: 0.0008 Acc: 85.7866\n",
      "validation Loss: 0.0009 Acc: 85.2619\n",
      "Saving..\n",
      "Epoch 13/99\n",
      "training Loss: 0.0008 Acc: 85.8937\n",
      "validation Loss: 0.0009 Acc: 85.1905\n",
      "Epoch 14/99\n",
      "training Loss: 0.0008 Acc: 85.9681\n",
      "validation Loss: 0.0009 Acc: 85.0952\n",
      "Epoch 15/99\n",
      "training Loss: 0.0008 Acc: 85.9145\n",
      "validation Loss: 0.0009 Acc: 85.0476\n",
      "Epoch 16/99\n",
      "training Loss: 0.0008 Acc: 85.9621\n",
      "validation Loss: 0.0009 Acc: 85.0357\n",
      "Epoch 17/99\n",
      "training Loss: 0.0008 Acc: 86.0098\n",
      "validation Loss: 0.0009 Acc: 85.1905\n",
      "Epoch 18/99\n",
      "training Loss: 0.0008 Acc: 86.1377\n",
      "validation Loss: 0.0009 Acc: 85.0595\n",
      "Epoch 19/99\n",
      "training Loss: 0.0008 Acc: 86.1080\n",
      "validation Loss: 0.0009 Acc: 85.1429\n",
      "Epoch 20/99\n",
      "training Loss: 0.0008 Acc: 86.1794\n",
      "validation Loss: 0.0009 Acc: 85.4524\n",
      "Saving..\n",
      "Epoch 21/99\n",
      "training Loss: 0.0008 Acc: 86.2181\n",
      "validation Loss: 0.0009 Acc: 85.1667\n",
      "Epoch 22/99\n",
      "training Loss: 0.0008 Acc: 86.3014\n",
      "validation Loss: 0.0009 Acc: 85.1786\n",
      "Epoch 23/99\n",
      "training Loss: 0.0008 Acc: 86.1288\n",
      "validation Loss: 0.0009 Acc: 85.1071\n",
      "Epoch 24/99\n",
      "training Loss: 0.0008 Acc: 86.2657\n",
      "validation Loss: 0.0009 Acc: 85.1429\n",
      "Epoch 25/99\n",
      "training Loss: 0.0008 Acc: 86.2032\n",
      "validation Loss: 0.0009 Acc: 85.1786\n",
      "Epoch 26/99\n",
      "training Loss: 0.0008 Acc: 86.2597\n",
      "validation Loss: 0.0009 Acc: 85.3571\n",
      "Epoch 27/99\n",
      "training Loss: 0.0008 Acc: 86.1973\n",
      "validation Loss: 0.0008 Acc: 85.3810\n",
      "Epoch 28/99\n",
      "training Loss: 0.0008 Acc: 86.1853\n",
      "validation Loss: 0.0009 Acc: 85.2619\n",
      "Epoch 29/99\n",
      "training Loss: 0.0008 Acc: 86.2062\n",
      "validation Loss: 0.0009 Acc: 84.9405\n",
      "Epoch 30/99\n",
      "training Loss: 0.0008 Acc: 86.2836\n",
      "validation Loss: 0.0009 Acc: 85.1905\n",
      "Early stopped.\n",
      "Best val acc: 85.452381\n",
      "----------\n",
      "Average best_acc across k-fold: 86.0530446266\n",
      "New configuration: {'hidden_layers': 2, 'dropout_g': 0.590983382134887, 'initial_nodes': 169, 'dropout': 0.044198629560733914, 'gru_layers': 2, 'batch_size': 510, 'gru_size': 480, 'learning_rate': 0.0034692491808253506}\n",
      "Epoch 0/99\n",
      "training Loss: 0.0008 Acc: 80.8452\n",
      "validation Loss: 0.0007 Acc: 83.6825\n",
      "Saving..\n",
      "Epoch 1/99\n",
      "training Loss: 0.0007 Acc: 84.3214\n",
      "validation Loss: 0.0007 Acc: 84.4918\n",
      "Saving..\n",
      "Epoch 2/99\n",
      "training Loss: 0.0007 Acc: 84.8006\n",
      "validation Loss: 0.0007 Acc: 84.6346\n",
      "Saving..\n",
      "Epoch 3/99\n",
      "training Loss: 0.0007 Acc: 84.8542\n",
      "validation Loss: 0.0007 Acc: 85.2892\n",
      "Saving..\n",
      "Epoch 4/99\n",
      "training Loss: 0.0007 Acc: 85.3304\n",
      "validation Loss: 0.0007 Acc: 85.2892\n",
      "Epoch 5/99\n",
      "training Loss: 0.0007 Acc: 85.2143\n",
      "validation Loss: 0.0007 Acc: 85.2535\n",
      "Epoch 6/99\n",
      "training Loss: 0.0007 Acc: 85.3929\n",
      "validation Loss: 0.0007 Acc: 85.4320\n",
      "Saving..\n",
      "Epoch 7/99\n",
      "training Loss: 0.0007 Acc: 85.3631\n",
      "validation Loss: 0.0007 Acc: 85.5511\n",
      "Saving..\n",
      "Epoch 8/99\n",
      "training Loss: 0.0007 Acc: 85.4137\n",
      "validation Loss: 0.0007 Acc: 85.4201\n",
      "Epoch 9/99\n",
      "training Loss: 0.0007 Acc: 85.3423\n",
      "validation Loss: 0.0007 Acc: 85.4201\n",
      "Epoch 10/99\n",
      "training Loss: 0.0006 Acc: 85.6161\n",
      "validation Loss: 0.0007 Acc: 85.3844\n",
      "Epoch 11/99\n",
      "training Loss: 0.0006 Acc: 85.5387\n",
      "validation Loss: 0.0007 Acc: 85.7296\n",
      "Saving..\n",
      "Epoch 12/99\n",
      "training Loss: 0.0006 Acc: 85.4702\n",
      "validation Loss: 0.0007 Acc: 85.4439\n",
      "Epoch 13/99\n",
      "training Loss: 0.0006 Acc: 85.6964\n",
      "validation Loss: 0.0007 Acc: 85.5154\n",
      "Epoch 14/99\n",
      "training Loss: 0.0006 Acc: 85.6696\n",
      "validation Loss: 0.0007 Acc: 85.5511\n",
      "Epoch 15/99\n",
      "training Loss: 0.0006 Acc: 85.6577\n",
      "validation Loss: 0.0007 Acc: 85.7772\n",
      "Saving..\n",
      "Epoch 16/99\n",
      "training Loss: 0.0006 Acc: 85.8363\n",
      "validation Loss: 0.0007 Acc: 85.8724\n",
      "Saving..\n",
      "Epoch 17/99\n",
      "training Loss: 0.0006 Acc: 85.8393\n",
      "validation Loss: 0.0007 Acc: 85.7891\n",
      "Epoch 18/99\n",
      "training Loss: 0.0006 Acc: 85.8214\n",
      "validation Loss: 0.0007 Acc: 85.4439\n",
      "Epoch 19/99\n",
      "training Loss: 0.0006 Acc: 85.9167\n",
      "validation Loss: 0.0007 Acc: 85.9319\n",
      "Saving..\n",
      "Epoch 20/99\n",
      "training Loss: 0.0006 Acc: 85.9315\n",
      "validation Loss: 0.0007 Acc: 85.8010\n",
      "Epoch 21/99\n",
      "training Loss: 0.0006 Acc: 85.9226\n",
      "validation Loss: 0.0007 Acc: 85.9795\n",
      "Saving..\n",
      "Epoch 22/99\n",
      "training Loss: 0.0006 Acc: 85.8839\n",
      "validation Loss: 0.0007 Acc: 85.4677\n",
      "Epoch 23/99\n",
      "training Loss: 0.0006 Acc: 85.9435\n",
      "validation Loss: 0.0007 Acc: 85.6701\n",
      "Epoch 24/99\n",
      "training Loss: 0.0006 Acc: 85.9554\n",
      "validation Loss: 0.0007 Acc: 85.4558\n",
      "Epoch 25/99\n",
      "training Loss: 0.0006 Acc: 86.0417\n",
      "validation Loss: 0.0007 Acc: 85.6820\n",
      "Epoch 26/99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Loss: 0.0006 Acc: 85.9107\n",
      "validation Loss: 0.0007 Acc: 85.7891\n",
      "Epoch 27/99\n",
      "training Loss: 0.0006 Acc: 86.0625\n",
      "validation Loss: 0.0007 Acc: 85.6344\n",
      "Epoch 28/99\n",
      "training Loss: 0.0006 Acc: 86.2768\n",
      "validation Loss: 0.0007 Acc: 85.7772\n",
      "Epoch 29/99\n",
      "training Loss: 0.0006 Acc: 86.2351\n",
      "validation Loss: 0.0007 Acc: 85.9200\n",
      "Epoch 30/99\n",
      "training Loss: 0.0006 Acc: 86.1875\n",
      "validation Loss: 0.0006 Acc: 85.6820\n",
      "Epoch 31/99\n",
      "training Loss: 0.0006 Acc: 86.2798\n",
      "validation Loss: 0.0007 Acc: 85.5868\n",
      "Early stopped.\n",
      "Best val acc: 85.979529\n",
      "----------\n",
      "Epoch 0/99\n",
      "training Loss: 0.0008 Acc: 81.7005\n",
      "validation Loss: 0.0007 Acc: 83.4167\n",
      "Saving..\n",
      "Epoch 1/99\n",
      "training Loss: 0.0007 Acc: 84.6616\n",
      "validation Loss: 0.0007 Acc: 84.0595\n",
      "Saving..\n",
      "Epoch 2/99\n",
      "training Loss: 0.0007 Acc: 85.0068\n",
      "validation Loss: 0.0007 Acc: 84.6190\n",
      "Saving..\n",
      "Epoch 3/99\n",
      "training Loss: 0.0007 Acc: 85.0961\n",
      "validation Loss: 0.0007 Acc: 84.1786\n",
      "Epoch 4/99\n",
      "training Loss: 0.0007 Acc: 85.4860\n",
      "validation Loss: 0.0007 Acc: 84.7857\n",
      "Saving..\n",
      "Epoch 5/99\n",
      "training Loss: 0.0007 Acc: 85.2568\n",
      "validation Loss: 0.0007 Acc: 84.9286\n",
      "Saving..\n",
      "Epoch 6/99\n",
      "training Loss: 0.0007 Acc: 85.5574\n",
      "validation Loss: 0.0007 Acc: 84.9167\n",
      "Epoch 7/99\n",
      "training Loss: 0.0006 Acc: 85.5663\n",
      "validation Loss: 0.0007 Acc: 84.7976\n",
      "Epoch 8/99\n",
      "training Loss: 0.0006 Acc: 85.7092\n",
      "validation Loss: 0.0007 Acc: 84.8810\n",
      "Epoch 9/99\n",
      "training Loss: 0.0006 Acc: 85.5812\n",
      "validation Loss: 0.0007 Acc: 84.9643\n",
      "Saving..\n",
      "Epoch 10/99\n",
      "training Loss: 0.0006 Acc: 85.6318\n",
      "validation Loss: 0.0007 Acc: 85.2619\n",
      "Saving..\n",
      "Epoch 11/99\n",
      "training Loss: 0.0006 Acc: 85.8401\n",
      "validation Loss: 0.0007 Acc: 85.0714\n",
      "Epoch 12/99\n",
      "training Loss: 0.0006 Acc: 85.7747\n",
      "validation Loss: 0.0007 Acc: 85.0952\n",
      "Epoch 13/99\n",
      "training Loss: 0.0006 Acc: 85.9116\n",
      "validation Loss: 0.0007 Acc: 85.1905\n",
      "Epoch 14/99\n",
      "training Loss: 0.0006 Acc: 85.9413\n",
      "validation Loss: 0.0007 Acc: 85.2976\n",
      "Saving..\n",
      "Epoch 15/99\n",
      "training Loss: 0.0006 Acc: 85.8550\n",
      "validation Loss: 0.0007 Acc: 85.4286\n",
      "Saving..\n",
      "Epoch 16/99\n",
      "training Loss: 0.0006 Acc: 85.9294\n",
      "validation Loss: 0.0007 Acc: 85.1071\n",
      "Epoch 17/99\n",
      "training Loss: 0.0006 Acc: 86.1318\n",
      "validation Loss: 0.0007 Acc: 85.0952\n",
      "Epoch 18/99\n",
      "training Loss: 0.0006 Acc: 86.1348\n",
      "validation Loss: 0.0007 Acc: 85.2262\n",
      "Epoch 19/99\n",
      "training Loss: 0.0006 Acc: 86.0633\n",
      "validation Loss: 0.0007 Acc: 85.3095\n",
      "Epoch 20/99\n",
      "training Loss: 0.0006 Acc: 86.1943\n",
      "validation Loss: 0.0007 Acc: 85.2500\n",
      "Epoch 21/99\n",
      "training Loss: 0.0006 Acc: 86.1407\n",
      "validation Loss: 0.0007 Acc: 85.5238\n",
      "Saving..\n",
      "Epoch 22/99\n",
      "training Loss: 0.0006 Acc: 86.0842\n",
      "validation Loss: 0.0007 Acc: 85.3810\n",
      "Epoch 23/99\n",
      "training Loss: 0.0006 Acc: 86.2657\n",
      "validation Loss: 0.0007 Acc: 85.4881\n",
      "Epoch 24/99\n",
      "training Loss: 0.0006 Acc: 86.2955\n",
      "validation Loss: 0.0007 Acc: 85.5238\n",
      "Epoch 25/99\n",
      "training Loss: 0.0006 Acc: 86.4919\n",
      "validation Loss: 0.0007 Acc: 85.5238\n",
      "Epoch 26/99\n",
      "training Loss: 0.0006 Acc: 86.4264\n",
      "validation Loss: 0.0007 Acc: 85.6429\n",
      "Saving..\n",
      "Epoch 27/99\n",
      "training Loss: 0.0006 Acc: 86.4026\n",
      "validation Loss: 0.0007 Acc: 85.2976\n",
      "Epoch 28/99\n",
      "training Loss: 0.0006 Acc: 86.4472\n",
      "validation Loss: 0.0007 Acc: 85.4405\n",
      "Epoch 29/99\n",
      "training Loss: 0.0006 Acc: 86.5335\n",
      "validation Loss: 0.0007 Acc: 85.4167\n",
      "Epoch 30/99\n",
      "training Loss: 0.0006 Acc: 86.5008\n",
      "validation Loss: 0.0007 Acc: 85.5595\n",
      "Epoch 31/99\n",
      "training Loss: 0.0006 Acc: 86.5484\n",
      "validation Loss: 0.0007 Acc: 85.5476\n",
      "Epoch 32/99\n",
      "training Loss: 0.0006 Acc: 86.7091\n",
      "validation Loss: 0.0007 Acc: 85.3571\n",
      "Epoch 33/99\n",
      "training Loss: 0.0006 Acc: 86.6794\n",
      "validation Loss: 0.0007 Acc: 85.4881\n",
      "Epoch 34/99\n",
      "training Loss: 0.0006 Acc: 86.7895\n",
      "validation Loss: 0.0007 Acc: 85.5476\n",
      "Epoch 35/99\n",
      "training Loss: 0.0006 Acc: 86.6823\n",
      "validation Loss: 0.0007 Acc: 85.4643\n",
      "Epoch 36/99\n",
      "training Loss: 0.0006 Acc: 86.7657\n",
      "validation Loss: 0.0007 Acc: 85.4762\n",
      "Early stopped.\n",
      "Best val acc: 85.642857\n",
      "----------\n",
      "Epoch 0/99\n",
      "training Loss: 0.0008 Acc: 80.9267\n",
      "validation Loss: 0.0007 Acc: 84.7381\n",
      "Saving..\n",
      "Epoch 1/99\n",
      "training Loss: 0.0007 Acc: 84.2628\n",
      "validation Loss: 0.0007 Acc: 85.2143\n",
      "Saving..\n",
      "Epoch 2/99\n",
      "training Loss: 0.0007 Acc: 84.8134\n",
      "validation Loss: 0.0007 Acc: 85.0952\n",
      "Epoch 3/99\n",
      "training Loss: 0.0007 Acc: 84.9086\n",
      "validation Loss: 0.0007 Acc: 85.2381\n",
      "Saving..\n",
      "Epoch 4/99\n",
      "training Loss: 0.0007 Acc: 85.0515\n",
      "validation Loss: 0.0007 Acc: 85.4286\n",
      "Saving..\n",
      "Epoch 5/99\n",
      "training Loss: 0.0007 Acc: 85.0455\n",
      "validation Loss: 0.0007 Acc: 85.5119\n",
      "Saving..\n",
      "Epoch 6/99\n",
      "training Loss: 0.0007 Acc: 85.2836\n",
      "validation Loss: 0.0007 Acc: 85.6786\n",
      "Saving..\n",
      "Epoch 7/99\n",
      "training Loss: 0.0007 Acc: 85.1527\n",
      "validation Loss: 0.0007 Acc: 85.8690\n",
      "Saving..\n",
      "Epoch 8/99\n",
      "training Loss: 0.0007 Acc: 85.1348\n",
      "validation Loss: 0.0007 Acc: 85.7500\n",
      "Epoch 9/99\n",
      "training Loss: 0.0006 Acc: 85.5544\n",
      "validation Loss: 0.0007 Acc: 85.9167\n",
      "Saving..\n",
      "Epoch 10/99\n",
      "training Loss: 0.0007 Acc: 85.3610\n",
      "validation Loss: 0.0007 Acc: 85.9048\n",
      "Epoch 11/99\n",
      "training Loss: 0.0006 Acc: 85.4175\n",
      "validation Loss: 0.0007 Acc: 85.9762\n",
      "Saving..\n",
      "Epoch 12/99\n",
      "training Loss: 0.0006 Acc: 85.3015\n",
      "validation Loss: 0.0007 Acc: 86.1786\n",
      "Saving..\n",
      "Epoch 13/99\n",
      "training Loss: 0.0006 Acc: 85.3908\n",
      "validation Loss: 0.0007 Acc: 85.9643\n",
      "Epoch 14/99\n",
      "training Loss: 0.0006 Acc: 85.5306\n",
      "validation Loss: 0.0007 Acc: 85.6548\n",
      "Epoch 15/99\n",
      "training Loss: 0.0006 Acc: 85.6348\n",
      "validation Loss: 0.0007 Acc: 86.0476\n",
      "Epoch 16/99\n",
      "training Loss: 0.0006 Acc: 85.6050\n",
      "validation Loss: 0.0007 Acc: 85.9881\n",
      "Epoch 17/99\n",
      "training Loss: 0.0006 Acc: 85.7389\n",
      "validation Loss: 0.0007 Acc: 85.7976\n",
      "Epoch 18/99\n",
      "training Loss: 0.0006 Acc: 85.6735\n",
      "validation Loss: 0.0007 Acc: 85.9048\n",
      "Epoch 19/99\n",
      "training Loss: 0.0006 Acc: 85.6973\n",
      "validation Loss: 0.0007 Acc: 85.9762\n",
      "Epoch 20/99\n",
      "training Loss: 0.0006 Acc: 85.5515\n",
      "validation Loss: 0.0007 Acc: 86.0357\n",
      "Epoch 21/99\n",
      "training Loss: 0.0006 Acc: 85.8372\n",
      "validation Loss: 0.0007 Acc: 85.6310\n",
      "Epoch 22/99\n",
      "training Loss: 0.0006 Acc: 85.8401\n",
      "validation Loss: 0.0007 Acc: 86.0357\n",
      "Early stopped.\n",
      "Best val acc: 86.178571\n",
      "----------\n",
      "Epoch 0/99\n",
      "training Loss: 0.0008 Acc: 81.1916\n",
      "validation Loss: 0.0007 Acc: 84.5238\n",
      "Saving..\n",
      "Epoch 1/99\n",
      "training Loss: 0.0007 Acc: 84.2986\n",
      "validation Loss: 0.0007 Acc: 84.7857\n",
      "Saving..\n",
      "Epoch 2/99\n",
      "training Loss: 0.0007 Acc: 84.8640\n",
      "validation Loss: 0.0007 Acc: 84.7738\n",
      "Epoch 3/99\n",
      "training Loss: 0.0007 Acc: 84.9473\n",
      "validation Loss: 0.0007 Acc: 85.2738\n",
      "Saving..\n",
      "Epoch 4/99\n",
      "training Loss: 0.0007 Acc: 85.0574\n",
      "validation Loss: 0.0007 Acc: 85.5357\n",
      "Saving..\n",
      "Epoch 5/99\n",
      "training Loss: 0.0007 Acc: 85.0485\n",
      "validation Loss: 0.0007 Acc: 85.4167\n",
      "Epoch 6/99\n",
      "training Loss: 0.0007 Acc: 85.2330\n",
      "validation Loss: 0.0007 Acc: 85.8571\n",
      "Saving..\n",
      "Epoch 7/99\n",
      "training Loss: 0.0007 Acc: 85.2687\n",
      "validation Loss: 0.0007 Acc: 85.2024\n",
      "Epoch 8/99\n",
      "training Loss: 0.0007 Acc: 85.2925\n",
      "validation Loss: 0.0007 Acc: 85.8214\n",
      "Epoch 9/99\n",
      "training Loss: 0.0007 Acc: 85.4384\n",
      "validation Loss: 0.0007 Acc: 85.6548\n",
      "Epoch 10/99\n",
      "training Loss: 0.0007 Acc: 85.2658\n",
      "validation Loss: 0.0007 Acc: 86.0595\n",
      "Saving..\n",
      "Epoch 11/99\n",
      "training Loss: 0.0007 Acc: 85.2836\n",
      "validation Loss: 0.0007 Acc: 85.7976\n",
      "Epoch 12/99\n",
      "training Loss: 0.0006 Acc: 85.3550\n",
      "validation Loss: 0.0006 Acc: 86.1190\n",
      "Saving..\n",
      "Epoch 13/99\n",
      "training Loss: 0.0006 Acc: 85.4503\n",
      "validation Loss: 0.0007 Acc: 85.8929\n",
      "Epoch 14/99\n",
      "training Loss: 0.0006 Acc: 85.4086\n",
      "validation Loss: 0.0007 Acc: 85.5952\n",
      "Epoch 15/99\n",
      "training Loss: 0.0006 Acc: 85.5247\n",
      "validation Loss: 0.0006 Acc: 86.0595\n",
      "Epoch 16/99\n",
      "training Loss: 0.0006 Acc: 85.7003\n",
      "validation Loss: 0.0006 Acc: 86.0000\n",
      "Epoch 17/99\n",
      "training Loss: 0.0006 Acc: 85.7062\n",
      "validation Loss: 0.0007 Acc: 85.7976\n",
      "Epoch 18/99\n",
      "training Loss: 0.0006 Acc: 85.8729\n",
      "validation Loss: 0.0007 Acc: 86.0357\n",
      "Epoch 19/99\n",
      "training Loss: 0.0006 Acc: 85.6824\n",
      "validation Loss: 0.0006 Acc: 86.0238\n",
      "Epoch 20/99\n",
      "training Loss: 0.0006 Acc: 85.8074\n",
      "validation Loss: 0.0006 Acc: 86.0119\n",
      "Epoch 21/99\n",
      "training Loss: 0.0006 Acc: 85.7211\n",
      "validation Loss: 0.0006 Acc: 85.9881\n",
      "Epoch 22/99\n",
      "training Loss: 0.0006 Acc: 85.7866\n",
      "validation Loss: 0.0006 Acc: 86.0000\n",
      "Early stopped.\n",
      "Best val acc: 86.119048\n",
      "----------\n",
      "Epoch 0/99\n",
      "training Loss: 0.0008 Acc: 81.6767\n",
      "validation Loss: 0.0007 Acc: 84.7976\n",
      "Saving..\n",
      "Epoch 1/99\n",
      "training Loss: 0.0007 Acc: 84.4890\n",
      "validation Loss: 0.0007 Acc: 84.8095\n",
      "Saving..\n",
      "Epoch 2/99\n",
      "training Loss: 0.0007 Acc: 84.9205\n",
      "validation Loss: 0.0007 Acc: 84.7976\n",
      "Epoch 3/99\n",
      "training Loss: 0.0007 Acc: 85.0455\n",
      "validation Loss: 0.0007 Acc: 84.9643\n",
      "Saving..\n",
      "Epoch 4/99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Loss: 0.0007 Acc: 85.0515\n",
      "validation Loss: 0.0007 Acc: 84.7738\n",
      "Epoch 5/99\n",
      "training Loss: 0.0007 Acc: 85.3431\n",
      "validation Loss: 0.0007 Acc: 85.2857\n",
      "Saving..\n",
      "Epoch 6/99\n",
      "training Loss: 0.0007 Acc: 85.2390\n",
      "validation Loss: 0.0007 Acc: 85.0119\n",
      "Epoch 7/99\n",
      "training Loss: 0.0007 Acc: 85.2181\n",
      "validation Loss: 0.0007 Acc: 84.9643\n",
      "Epoch 8/99\n",
      "training Loss: 0.0006 Acc: 85.4235\n",
      "validation Loss: 0.0007 Acc: 85.5833\n",
      "Saving..\n",
      "Epoch 9/99\n",
      "training Loss: 0.0006 Acc: 85.4443\n",
      "validation Loss: 0.0007 Acc: 85.5595\n",
      "Epoch 10/99\n",
      "training Loss: 0.0006 Acc: 85.7538\n",
      "validation Loss: 0.0007 Acc: 85.3810\n",
      "Epoch 11/99\n",
      "training Loss: 0.0006 Acc: 85.5009\n",
      "validation Loss: 0.0007 Acc: 85.6786\n",
      "Saving..\n",
      "Epoch 12/99\n",
      "training Loss: 0.0006 Acc: 85.5366\n",
      "validation Loss: 0.0007 Acc: 85.6310\n",
      "Epoch 13/99\n",
      "training Loss: 0.0006 Acc: 85.6824\n",
      "validation Loss: 0.0007 Acc: 85.4524\n",
      "Epoch 14/99\n",
      "training Loss: 0.0006 Acc: 85.7657\n",
      "validation Loss: 0.0007 Acc: 85.3333\n",
      "Epoch 15/99\n",
      "training Loss: 0.0006 Acc: 85.7568\n",
      "validation Loss: 0.0006 Acc: 85.7619\n",
      "Saving..\n",
      "Epoch 16/99\n",
      "training Loss: 0.0006 Acc: 85.7955\n",
      "validation Loss: 0.0007 Acc: 85.6548\n",
      "Epoch 17/99\n",
      "training Loss: 0.0006 Acc: 85.9740\n",
      "validation Loss: 0.0006 Acc: 85.5119\n",
      "Epoch 18/99\n",
      "training Loss: 0.0006 Acc: 85.7508\n",
      "validation Loss: 0.0006 Acc: 85.6786\n",
      "Epoch 19/99\n",
      "training Loss: 0.0006 Acc: 85.8580\n",
      "validation Loss: 0.0006 Acc: 85.7024\n",
      "Epoch 20/99\n",
      "training Loss: 0.0006 Acc: 85.9294\n",
      "validation Loss: 0.0006 Acc: 85.5119\n",
      "Epoch 21/99\n",
      "training Loss: 0.0006 Acc: 85.8848\n",
      "validation Loss: 0.0006 Acc: 85.4048\n",
      "Epoch 22/99\n",
      "training Loss: 0.0006 Acc: 86.1675\n",
      "validation Loss: 0.0006 Acc: 85.5119\n",
      "Epoch 23/99\n",
      "training Loss: 0.0006 Acc: 86.2508\n",
      "validation Loss: 0.0006 Acc: 85.7143\n",
      "Epoch 24/99\n",
      "training Loss: 0.0006 Acc: 86.2955\n",
      "validation Loss: 0.0006 Acc: 85.9048\n",
      "Saving..\n",
      "Epoch 25/99\n",
      "training Loss: 0.0006 Acc: 86.2597\n",
      "validation Loss: 0.0006 Acc: 85.8333\n",
      "Epoch 26/99\n",
      "training Loss: 0.0006 Acc: 86.3133\n",
      "validation Loss: 0.0006 Acc: 85.8333\n",
      "Epoch 27/99\n",
      "training Loss: 0.0006 Acc: 86.4145\n",
      "validation Loss: 0.0006 Acc: 85.7619\n",
      "Epoch 28/99\n",
      "training Loss: 0.0006 Acc: 86.3401\n",
      "validation Loss: 0.0006 Acc: 85.5714\n",
      "Epoch 29/99\n",
      "training Loss: 0.0006 Acc: 86.3133\n",
      "validation Loss: 0.0007 Acc: 85.7619\n",
      "Epoch 30/99\n",
      "training Loss: 0.0006 Acc: 86.2836\n",
      "validation Loss: 0.0006 Acc: 85.7262\n",
      "Epoch 31/99\n",
      "training Loss: 0.0006 Acc: 86.3877\n",
      "validation Loss: 0.0006 Acc: 85.7500\n",
      "Epoch 32/99\n",
      "training Loss: 0.0006 Acc: 86.5395\n",
      "validation Loss: 0.0006 Acc: 85.8452\n",
      "Epoch 33/99\n",
      "training Loss: 0.0006 Acc: 86.5931\n",
      "validation Loss: 0.0006 Acc: 85.8571\n",
      "Epoch 34/99\n",
      "training Loss: 0.0006 Acc: 86.5901\n",
      "validation Loss: 0.0006 Acc: 85.7976\n",
      "Early stopped.\n",
      "Best val acc: 85.904762\n",
      "----------\n",
      "Average best_acc across k-fold: 85.9649533558\n",
      "New configuration: {'hidden_layers': 2, 'dropout_g': 0.6105295668105285, 'initial_nodes': 213, 'dropout': 0.4324807770366876, 'gru_layers': 2, 'batch_size': 406, 'gru_size': 176, 'learning_rate': 0.00018569788965728436}\n",
      "Epoch 0/99\n",
      "training Loss: 0.0015 Acc: 70.6518\n",
      "validation Loss: 0.0011 Acc: 80.2190\n",
      "Saving..\n",
      "Epoch 1/99\n",
      "training Loss: 0.0010 Acc: 81.7857\n",
      "validation Loss: 0.0010 Acc: 82.7422\n",
      "Saving..\n",
      "Epoch 2/99\n",
      "training Loss: 0.0010 Acc: 83.0149\n",
      "validation Loss: 0.0009 Acc: 83.1707\n",
      "Saving..\n",
      "Epoch 3/99\n",
      "training Loss: 0.0010 Acc: 83.1845\n",
      "validation Loss: 0.0009 Acc: 83.4087\n",
      "Saving..\n",
      "Epoch 4/99\n",
      "training Loss: 0.0009 Acc: 83.6429\n",
      "validation Loss: 0.0009 Acc: 83.6110\n",
      "Saving..\n",
      "Epoch 5/99\n",
      "training Loss: 0.0009 Acc: 83.7857\n",
      "validation Loss: 0.0009 Acc: 83.9681\n",
      "Saving..\n",
      "Epoch 6/99\n",
      "training Loss: 0.0009 Acc: 84.0536\n",
      "validation Loss: 0.0009 Acc: 84.0633\n",
      "Saving..\n",
      "Epoch 7/99\n",
      "training Loss: 0.0009 Acc: 84.1667\n",
      "validation Loss: 0.0009 Acc: 84.0990\n",
      "Saving..\n",
      "Epoch 8/99\n",
      "training Loss: 0.0009 Acc: 84.2798\n",
      "validation Loss: 0.0009 Acc: 84.1823\n",
      "Saving..\n",
      "Epoch 9/99\n",
      "training Loss: 0.0009 Acc: 84.5417\n",
      "validation Loss: 0.0009 Acc: 84.3847\n",
      "Saving..\n",
      "Epoch 10/99\n",
      "training Loss: 0.0009 Acc: 84.6190\n",
      "validation Loss: 0.0009 Acc: 84.3014\n",
      "Epoch 11/99\n",
      "training Loss: 0.0009 Acc: 84.7202\n",
      "validation Loss: 0.0009 Acc: 84.3847\n",
      "Epoch 12/99\n",
      "training Loss: 0.0009 Acc: 84.6607\n",
      "validation Loss: 0.0009 Acc: 84.5751\n",
      "Saving..\n",
      "Epoch 13/99\n",
      "training Loss: 0.0009 Acc: 84.8304\n",
      "validation Loss: 0.0009 Acc: 84.5394\n",
      "Epoch 14/99\n",
      "training Loss: 0.0009 Acc: 84.7054\n",
      "validation Loss: 0.0009 Acc: 84.5870\n",
      "Saving..\n",
      "Epoch 15/99\n",
      "training Loss: 0.0009 Acc: 84.8542\n",
      "validation Loss: 0.0008 Acc: 84.6108\n",
      "Saving..\n",
      "Epoch 16/99\n",
      "training Loss: 0.0009 Acc: 84.8452\n",
      "validation Loss: 0.0008 Acc: 84.6465\n",
      "Saving..\n",
      "Epoch 17/99\n",
      "training Loss: 0.0009 Acc: 84.7976\n",
      "validation Loss: 0.0008 Acc: 84.6227\n",
      "Epoch 18/99\n",
      "training Loss: 0.0009 Acc: 84.9940\n",
      "validation Loss: 0.0008 Acc: 84.7417\n",
      "Saving..\n",
      "Epoch 19/99\n",
      "training Loss: 0.0009 Acc: 84.8839\n",
      "validation Loss: 0.0008 Acc: 84.7179\n",
      "Epoch 20/99\n",
      "training Loss: 0.0009 Acc: 85.0387\n",
      "validation Loss: 0.0008 Acc: 84.7655\n",
      "Saving..\n",
      "Epoch 21/99\n",
      "training Loss: 0.0009 Acc: 84.9435\n",
      "validation Loss: 0.0008 Acc: 84.6941\n",
      "Epoch 22/99\n",
      "training Loss: 0.0009 Acc: 85.0238\n",
      "validation Loss: 0.0008 Acc: 84.8369\n",
      "Saving..\n",
      "Epoch 23/99\n",
      "training Loss: 0.0009 Acc: 84.9524\n",
      "validation Loss: 0.0008 Acc: 84.8488\n",
      "Saving..\n",
      "Epoch 24/99\n",
      "training Loss: 0.0009 Acc: 85.0893\n",
      "validation Loss: 0.0008 Acc: 84.9203\n",
      "Saving..\n",
      "Epoch 25/99\n",
      "training Loss: 0.0009 Acc: 85.0446\n",
      "validation Loss: 0.0008 Acc: 84.8488\n",
      "Epoch 26/99\n",
      "training Loss: 0.0008 Acc: 85.1310\n",
      "validation Loss: 0.0008 Acc: 84.9560\n",
      "Saving..\n",
      "Epoch 27/99\n",
      "training Loss: 0.0009 Acc: 85.0565\n",
      "validation Loss: 0.0008 Acc: 84.9917\n",
      "Saving..\n",
      "Epoch 28/99\n",
      "training Loss: 0.0009 Acc: 85.1518\n",
      "validation Loss: 0.0008 Acc: 84.9084\n",
      "Epoch 29/99\n",
      "training Loss: 0.0008 Acc: 85.1339\n",
      "validation Loss: 0.0008 Acc: 84.9679\n",
      "Epoch 30/99\n",
      "training Loss: 0.0009 Acc: 85.0625\n",
      "validation Loss: 0.0008 Acc: 84.9679\n",
      "Epoch 31/99\n",
      "training Loss: 0.0008 Acc: 85.3661\n",
      "validation Loss: 0.0008 Acc: 85.0988\n",
      "Saving..\n",
      "Epoch 32/99\n",
      "training Loss: 0.0008 Acc: 85.3274\n",
      "validation Loss: 0.0008 Acc: 85.1702\n",
      "Saving..\n",
      "Epoch 33/99\n",
      "training Loss: 0.0008 Acc: 85.3125\n",
      "validation Loss: 0.0008 Acc: 84.9917\n",
      "Epoch 34/99\n",
      "training Loss: 0.0008 Acc: 85.2827\n",
      "validation Loss: 0.0008 Acc: 85.1107\n",
      "Epoch 35/99\n",
      "training Loss: 0.0008 Acc: 85.2113\n",
      "validation Loss: 0.0008 Acc: 85.0750\n",
      "Epoch 36/99\n",
      "training Loss: 0.0008 Acc: 85.3482\n",
      "validation Loss: 0.0008 Acc: 85.0750\n",
      "Epoch 37/99\n",
      "training Loss: 0.0008 Acc: 85.3512\n",
      "validation Loss: 0.0008 Acc: 85.1226\n",
      "Epoch 38/99\n",
      "training Loss: 0.0008 Acc: 85.2917\n",
      "validation Loss: 0.0008 Acc: 85.3249\n",
      "Saving..\n",
      "Epoch 39/99\n",
      "training Loss: 0.0008 Acc: 85.2440\n",
      "validation Loss: 0.0008 Acc: 85.1940\n",
      "Epoch 40/99\n",
      "training Loss: 0.0008 Acc: 85.3899\n",
      "validation Loss: 0.0008 Acc: 85.2892\n",
      "Epoch 41/99\n",
      "training Loss: 0.0008 Acc: 85.2530\n",
      "validation Loss: 0.0008 Acc: 85.0750\n",
      "Epoch 42/99\n",
      "training Loss: 0.0008 Acc: 85.3185\n",
      "validation Loss: 0.0008 Acc: 85.2297\n",
      "Epoch 43/99\n",
      "training Loss: 0.0008 Acc: 85.2798\n",
      "validation Loss: 0.0008 Acc: 85.2773\n",
      "Epoch 44/99\n",
      "training Loss: 0.0008 Acc: 85.4911\n",
      "validation Loss: 0.0008 Acc: 85.1940\n",
      "Epoch 45/99\n",
      "training Loss: 0.0008 Acc: 85.4702\n",
      "validation Loss: 0.0008 Acc: 85.3487\n",
      "Saving..\n",
      "Epoch 46/99\n",
      "training Loss: 0.0008 Acc: 85.5119\n",
      "validation Loss: 0.0008 Acc: 85.2416\n",
      "Epoch 47/99\n",
      "training Loss: 0.0008 Acc: 85.4048\n",
      "validation Loss: 0.0008 Acc: 85.3844\n",
      "Saving..\n",
      "Epoch 48/99\n",
      "training Loss: 0.0008 Acc: 85.5000\n",
      "validation Loss: 0.0008 Acc: 85.1821\n",
      "Epoch 49/99\n",
      "training Loss: 0.0008 Acc: 85.3780\n",
      "validation Loss: 0.0008 Acc: 85.2297\n",
      "Epoch 50/99\n",
      "training Loss: 0.0008 Acc: 85.4286\n",
      "validation Loss: 0.0008 Acc: 85.3606\n",
      "Epoch 51/99\n",
      "training Loss: 0.0008 Acc: 85.3363\n",
      "validation Loss: 0.0008 Acc: 85.2654\n",
      "Epoch 52/99\n",
      "training Loss: 0.0008 Acc: 85.4137\n",
      "validation Loss: 0.0008 Acc: 85.3844\n",
      "Epoch 53/99\n",
      "training Loss: 0.0008 Acc: 85.4405\n",
      "validation Loss: 0.0008 Acc: 85.2416\n",
      "Epoch 54/99\n",
      "training Loss: 0.0008 Acc: 85.5536\n",
      "validation Loss: 0.0008 Acc: 85.4558\n",
      "Saving..\n",
      "Epoch 55/99\n",
      "training Loss: 0.0008 Acc: 85.4137\n",
      "validation Loss: 0.0008 Acc: 85.3368\n",
      "Epoch 56/99\n",
      "training Loss: 0.0008 Acc: 85.4940\n",
      "validation Loss: 0.0008 Acc: 85.3725\n",
      "Epoch 57/99\n",
      "training Loss: 0.0008 Acc: 85.4018\n",
      "validation Loss: 0.0008 Acc: 85.3249\n",
      "Epoch 58/99\n",
      "training Loss: 0.0008 Acc: 85.4702\n",
      "validation Loss: 0.0008 Acc: 85.3844\n",
      "Epoch 59/99\n",
      "training Loss: 0.0008 Acc: 85.5119\n",
      "validation Loss: 0.0008 Acc: 85.4320\n",
      "Epoch 60/99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Loss: 0.0008 Acc: 85.3661\n",
      "validation Loss: 0.0008 Acc: 85.1940\n",
      "Epoch 61/99\n",
      "training Loss: 0.0008 Acc: 85.4702\n",
      "validation Loss: 0.0008 Acc: 85.4558\n",
      "Epoch 62/99\n",
      "training Loss: 0.0008 Acc: 85.4643\n",
      "validation Loss: 0.0008 Acc: 85.4796\n",
      "Saving..\n",
      "Epoch 63/99\n",
      "training Loss: 0.0008 Acc: 85.4911\n",
      "validation Loss: 0.0008 Acc: 85.4439\n",
      "Epoch 64/99\n",
      "training Loss: 0.0008 Acc: 85.6577\n",
      "validation Loss: 0.0008 Acc: 85.4558\n",
      "Epoch 65/99\n",
      "training Loss: 0.0008 Acc: 85.6071\n",
      "validation Loss: 0.0008 Acc: 85.3606\n",
      "Epoch 66/99\n",
      "training Loss: 0.0008 Acc: 85.5327\n",
      "validation Loss: 0.0008 Acc: 85.3963\n",
      "Epoch 67/99\n",
      "training Loss: 0.0008 Acc: 85.3929\n",
      "validation Loss: 0.0008 Acc: 85.5154\n",
      "Saving..\n",
      "Epoch 68/99\n",
      "training Loss: 0.0008 Acc: 85.5536\n",
      "validation Loss: 0.0008 Acc: 85.4201\n",
      "Epoch 69/99\n",
      "training Loss: 0.0008 Acc: 85.5833\n",
      "validation Loss: 0.0008 Acc: 85.3725\n",
      "Epoch 70/99\n",
      "training Loss: 0.0008 Acc: 85.5000\n",
      "validation Loss: 0.0008 Acc: 85.4082\n",
      "Epoch 71/99\n",
      "training Loss: 0.0008 Acc: 85.5476\n",
      "validation Loss: 0.0008 Acc: 85.4558\n",
      "Epoch 72/99\n",
      "training Loss: 0.0008 Acc: 85.4524\n",
      "validation Loss: 0.0008 Acc: 85.4558\n",
      "Epoch 73/99\n",
      "training Loss: 0.0008 Acc: 85.5149\n",
      "validation Loss: 0.0008 Acc: 85.5749\n",
      "Saving..\n",
      "Epoch 74/99\n",
      "training Loss: 0.0008 Acc: 85.6190\n",
      "validation Loss: 0.0008 Acc: 85.5392\n",
      "Epoch 75/99\n",
      "training Loss: 0.0008 Acc: 85.6696\n",
      "validation Loss: 0.0008 Acc: 85.4558\n",
      "Epoch 76/99\n",
      "training Loss: 0.0008 Acc: 85.6905\n",
      "validation Loss: 0.0008 Acc: 85.2892\n",
      "Epoch 77/99\n",
      "training Loss: 0.0008 Acc: 85.6161\n",
      "validation Loss: 0.0008 Acc: 85.5273\n",
      "Epoch 78/99\n",
      "training Loss: 0.0008 Acc: 85.5000\n",
      "validation Loss: 0.0008 Acc: 85.3963\n",
      "Epoch 79/99\n",
      "training Loss: 0.0008 Acc: 85.7202\n",
      "validation Loss: 0.0008 Acc: 85.4796\n",
      "Epoch 80/99\n",
      "training Loss: 0.0008 Acc: 85.6250\n",
      "validation Loss: 0.0008 Acc: 85.5392\n",
      "Epoch 81/99\n",
      "training Loss: 0.0008 Acc: 85.5774\n",
      "validation Loss: 0.0008 Acc: 85.4915\n",
      "Epoch 82/99\n",
      "training Loss: 0.0008 Acc: 85.6131\n",
      "validation Loss: 0.0008 Acc: 85.5749\n",
      "Epoch 83/99\n",
      "training Loss: 0.0008 Acc: 85.5714\n",
      "validation Loss: 0.0008 Acc: 85.4796\n",
      "Early stopped.\n",
      "Best val acc: 85.574863\n",
      "----------\n",
      "Epoch 0/99\n",
      "training Loss: 0.0015 Acc: 68.2965\n",
      "validation Loss: 0.0010 Acc: 80.9405\n",
      "Saving..\n",
      "Epoch 1/99\n",
      "training Loss: 0.0010 Acc: 81.7779\n",
      "validation Loss: 0.0009 Acc: 83.3690\n",
      "Saving..\n",
      "Epoch 2/99\n",
      "training Loss: 0.0010 Acc: 82.8254\n",
      "validation Loss: 0.0009 Acc: 83.8571\n",
      "Saving..\n",
      "Epoch 3/99\n",
      "training Loss: 0.0010 Acc: 83.3284\n",
      "validation Loss: 0.0009 Acc: 83.8095\n",
      "Epoch 4/99\n",
      "training Loss: 0.0009 Acc: 83.4653\n",
      "validation Loss: 0.0009 Acc: 83.6786\n",
      "Epoch 5/99\n",
      "training Loss: 0.0009 Acc: 83.7034\n",
      "validation Loss: 0.0009 Acc: 84.5476\n",
      "Saving..\n",
      "Epoch 6/99\n",
      "training Loss: 0.0009 Acc: 83.7837\n",
      "validation Loss: 0.0009 Acc: 84.6429\n",
      "Saving..\n",
      "Epoch 7/99\n",
      "training Loss: 0.0009 Acc: 84.0902\n",
      "validation Loss: 0.0009 Acc: 84.8095\n",
      "Saving..\n",
      "Epoch 8/99\n",
      "training Loss: 0.0009 Acc: 84.2331\n",
      "validation Loss: 0.0009 Acc: 84.9762\n",
      "Saving..\n",
      "Epoch 9/99\n",
      "training Loss: 0.0009 Acc: 84.2777\n",
      "validation Loss: 0.0008 Acc: 85.0119\n",
      "Saving..\n",
      "Epoch 10/99\n",
      "training Loss: 0.0009 Acc: 84.3134\n",
      "validation Loss: 0.0008 Acc: 85.1667\n",
      "Saving..\n",
      "Epoch 11/99\n",
      "training Loss: 0.0009 Acc: 84.4712\n",
      "validation Loss: 0.0008 Acc: 85.1429\n",
      "Epoch 12/99\n",
      "training Loss: 0.0009 Acc: 84.4741\n",
      "validation Loss: 0.0008 Acc: 85.2381\n",
      "Saving..\n",
      "Epoch 13/99\n",
      "training Loss: 0.0009 Acc: 84.5366\n",
      "validation Loss: 0.0008 Acc: 85.2381\n",
      "Epoch 14/99\n",
      "training Loss: 0.0009 Acc: 84.5366\n",
      "validation Loss: 0.0008 Acc: 85.2857\n",
      "Saving..\n",
      "Epoch 15/99\n",
      "training Loss: 0.0009 Acc: 84.6795\n",
      "validation Loss: 0.0008 Acc: 85.3571\n",
      "Saving..\n",
      "Epoch 16/99\n",
      "training Loss: 0.0009 Acc: 84.8372\n",
      "validation Loss: 0.0008 Acc: 85.2976\n",
      "Epoch 17/99\n",
      "training Loss: 0.0009 Acc: 84.6438\n",
      "validation Loss: 0.0008 Acc: 85.4643\n",
      "Saving..\n",
      "Epoch 18/99\n",
      "training Loss: 0.0009 Acc: 84.6557\n",
      "validation Loss: 0.0008 Acc: 85.2738\n",
      "Epoch 19/99\n",
      "training Loss: 0.0009 Acc: 84.7807\n",
      "validation Loss: 0.0008 Acc: 85.2381\n",
      "Epoch 20/99\n",
      "training Loss: 0.0009 Acc: 84.8699\n",
      "validation Loss: 0.0008 Acc: 85.2976\n",
      "Epoch 21/99\n",
      "training Loss: 0.0009 Acc: 84.8521\n",
      "validation Loss: 0.0008 Acc: 85.3452\n",
      "Epoch 22/99\n",
      "training Loss: 0.0009 Acc: 84.9265\n",
      "validation Loss: 0.0008 Acc: 85.3571\n",
      "Epoch 23/99\n",
      "training Loss: 0.0009 Acc: 84.8521\n",
      "validation Loss: 0.0008 Acc: 85.5119\n",
      "Saving..\n",
      "Epoch 24/99\n",
      "training Loss: 0.0009 Acc: 84.9235\n",
      "validation Loss: 0.0008 Acc: 85.4048\n",
      "Epoch 25/99\n",
      "training Loss: 0.0009 Acc: 85.0693\n",
      "validation Loss: 0.0008 Acc: 85.5238\n",
      "Saving..\n",
      "Epoch 26/99\n",
      "training Loss: 0.0009 Acc: 84.8819\n",
      "validation Loss: 0.0008 Acc: 85.5357\n",
      "Saving..\n",
      "Epoch 27/99\n",
      "training Loss: 0.0009 Acc: 85.1437\n",
      "validation Loss: 0.0008 Acc: 85.5238\n",
      "Epoch 28/99\n",
      "training Loss: 0.0009 Acc: 85.0128\n",
      "validation Loss: 0.0008 Acc: 85.6667\n",
      "Saving..\n",
      "Epoch 29/99\n",
      "training Loss: 0.0009 Acc: 85.0098\n",
      "validation Loss: 0.0008 Acc: 85.5476\n",
      "Epoch 30/99\n",
      "training Loss: 0.0009 Acc: 85.0664\n",
      "validation Loss: 0.0008 Acc: 85.5595\n",
      "Epoch 31/99\n",
      "training Loss: 0.0009 Acc: 85.1348\n",
      "validation Loss: 0.0008 Acc: 85.6429\n",
      "Epoch 32/99\n",
      "training Loss: 0.0009 Acc: 85.2717\n",
      "validation Loss: 0.0008 Acc: 85.7857\n",
      "Saving..\n",
      "Epoch 33/99\n",
      "training Loss: 0.0008 Acc: 85.0753\n",
      "validation Loss: 0.0008 Acc: 85.5714\n",
      "Epoch 34/99\n",
      "training Loss: 0.0008 Acc: 85.1735\n",
      "validation Loss: 0.0008 Acc: 85.6071\n",
      "Epoch 35/99\n",
      "training Loss: 0.0008 Acc: 85.2390\n",
      "validation Loss: 0.0008 Acc: 85.4286\n",
      "Epoch 36/99\n",
      "training Loss: 0.0008 Acc: 85.3044\n",
      "validation Loss: 0.0008 Acc: 85.5952\n",
      "Epoch 37/99\n",
      "training Loss: 0.0009 Acc: 85.3312\n",
      "validation Loss: 0.0008 Acc: 85.5833\n",
      "Epoch 38/99\n",
      "training Loss: 0.0008 Acc: 85.0396\n",
      "validation Loss: 0.0008 Acc: 85.6071\n",
      "Epoch 39/99\n",
      "training Loss: 0.0008 Acc: 85.3164\n",
      "validation Loss: 0.0008 Acc: 85.5952\n",
      "Epoch 40/99\n",
      "training Loss: 0.0008 Acc: 85.0574\n",
      "validation Loss: 0.0008 Acc: 85.6071\n",
      "Epoch 41/99\n",
      "training Loss: 0.0008 Acc: 85.3699\n",
      "validation Loss: 0.0008 Acc: 85.5595\n",
      "Epoch 42/99\n",
      "training Loss: 0.0008 Acc: 85.1705\n",
      "validation Loss: 0.0008 Acc: 85.4881\n",
      "Early stopped.\n",
      "Best val acc: 85.785714\n",
      "----------\n",
      "Epoch 0/99\n",
      "training Loss: 0.0015 Acc: 71.1237\n",
      "validation Loss: 0.0011 Acc: 80.5595\n",
      "Saving..\n",
      "Epoch 1/99\n",
      "training Loss: 0.0010 Acc: 81.8910\n",
      "validation Loss: 0.0010 Acc: 82.9881\n",
      "Saving..\n",
      "Epoch 2/99\n",
      "training Loss: 0.0010 Acc: 83.1409\n",
      "validation Loss: 0.0009 Acc: 83.2619\n",
      "Saving..\n",
      "Epoch 3/99\n",
      "training Loss: 0.0010 Acc: 83.3849\n",
      "validation Loss: 0.0009 Acc: 83.5119\n",
      "Saving..\n",
      "Epoch 4/99\n",
      "training Loss: 0.0009 Acc: 83.6319\n",
      "validation Loss: 0.0009 Acc: 83.7262\n",
      "Saving..\n",
      "Epoch 5/99\n",
      "training Loss: 0.0009 Acc: 83.9861\n",
      "validation Loss: 0.0009 Acc: 84.0952\n",
      "Saving..\n",
      "Epoch 6/99\n",
      "training Loss: 0.0009 Acc: 84.0575\n",
      "validation Loss: 0.0009 Acc: 84.2619\n",
      "Saving..\n",
      "Epoch 7/99\n",
      "training Loss: 0.0009 Acc: 84.3372\n",
      "validation Loss: 0.0009 Acc: 84.5357\n",
      "Saving..\n",
      "Epoch 8/99\n",
      "training Loss: 0.0009 Acc: 84.3253\n",
      "validation Loss: 0.0009 Acc: 84.5714\n",
      "Saving..\n",
      "Epoch 9/99\n",
      "training Loss: 0.0009 Acc: 84.4771\n",
      "validation Loss: 0.0009 Acc: 84.5595\n",
      "Epoch 10/99\n",
      "training Loss: 0.0009 Acc: 84.7866\n",
      "validation Loss: 0.0009 Acc: 84.6667\n",
      "Saving..\n",
      "Epoch 11/99\n",
      "training Loss: 0.0009 Acc: 84.6587\n",
      "validation Loss: 0.0009 Acc: 84.7738\n",
      "Saving..\n",
      "Epoch 12/99\n",
      "training Loss: 0.0009 Acc: 84.6200\n",
      "validation Loss: 0.0009 Acc: 84.7738\n",
      "Epoch 13/99\n",
      "training Loss: 0.0009 Acc: 84.6765\n",
      "validation Loss: 0.0009 Acc: 84.7976\n",
      "Saving..\n",
      "Epoch 14/99\n",
      "training Loss: 0.0009 Acc: 84.7747\n",
      "validation Loss: 0.0009 Acc: 84.9643\n",
      "Saving..\n",
      "Epoch 15/99\n",
      "training Loss: 0.0009 Acc: 84.8729\n",
      "validation Loss: 0.0009 Acc: 84.9881\n",
      "Saving..\n",
      "Epoch 16/99\n",
      "training Loss: 0.0009 Acc: 85.0068\n",
      "validation Loss: 0.0009 Acc: 85.0238\n",
      "Saving..\n",
      "Epoch 17/99\n",
      "training Loss: 0.0009 Acc: 84.7390\n",
      "validation Loss: 0.0009 Acc: 84.9881\n",
      "Epoch 18/99\n",
      "training Loss: 0.0009 Acc: 85.0187\n",
      "validation Loss: 0.0009 Acc: 84.9405\n",
      "Epoch 19/99\n",
      "training Loss: 0.0009 Acc: 84.9622\n",
      "validation Loss: 0.0009 Acc: 85.1190\n",
      "Saving..\n",
      "Epoch 20/99\n",
      "training Loss: 0.0009 Acc: 85.0455\n",
      "validation Loss: 0.0009 Acc: 85.0476\n",
      "Epoch 21/99\n",
      "training Loss: 0.0009 Acc: 84.9652\n",
      "validation Loss: 0.0009 Acc: 85.1667\n",
      "Saving..\n",
      "Epoch 22/99\n",
      "training Loss: 0.0008 Acc: 85.0366\n",
      "validation Loss: 0.0009 Acc: 85.3571\n",
      "Saving..\n",
      "Epoch 23/99\n",
      "training Loss: 0.0009 Acc: 85.1348\n",
      "validation Loss: 0.0009 Acc: 85.1786\n",
      "Epoch 24/99\n",
      "training Loss: 0.0008 Acc: 85.0783\n",
      "validation Loss: 0.0009 Acc: 85.2857\n",
      "Epoch 25/99\n",
      "training Loss: 0.0008 Acc: 85.2122\n",
      "validation Loss: 0.0009 Acc: 85.1667\n",
      "Epoch 26/99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Loss: 0.0008 Acc: 85.0723\n",
      "validation Loss: 0.0009 Acc: 85.2500\n",
      "Epoch 27/99\n",
      "training Loss: 0.0008 Acc: 84.9949\n",
      "validation Loss: 0.0009 Acc: 85.1667\n",
      "Epoch 28/99\n",
      "training Loss: 0.0008 Acc: 85.1943\n",
      "validation Loss: 0.0009 Acc: 85.1071\n",
      "Epoch 29/99\n",
      "training Loss: 0.0008 Acc: 85.2360\n",
      "validation Loss: 0.0009 Acc: 85.3333\n",
      "Epoch 30/99\n",
      "training Loss: 0.0008 Acc: 85.2062\n",
      "validation Loss: 0.0009 Acc: 85.3095\n",
      "Epoch 31/99\n",
      "training Loss: 0.0008 Acc: 85.2360\n",
      "validation Loss: 0.0009 Acc: 85.2262\n",
      "Epoch 32/99\n",
      "training Loss: 0.0008 Acc: 85.2598\n",
      "validation Loss: 0.0009 Acc: 85.3333\n",
      "Early stopped.\n",
      "Best val acc: 85.357143\n",
      "----------\n",
      "Epoch 0/99\n",
      "training Loss: 0.0015 Acc: 73.1415\n",
      "validation Loss: 0.0011 Acc: 80.5714\n",
      "Saving..\n",
      "Epoch 1/99\n",
      "training Loss: 0.0010 Acc: 81.9594\n",
      "validation Loss: 0.0010 Acc: 83.3452\n",
      "Saving..\n",
      "Epoch 2/99\n",
      "training Loss: 0.0010 Acc: 83.2331\n",
      "validation Loss: 0.0009 Acc: 83.3333\n",
      "Epoch 3/99\n",
      "training Loss: 0.0010 Acc: 83.4087\n",
      "validation Loss: 0.0009 Acc: 83.7500\n",
      "Saving..\n",
      "Epoch 4/99\n",
      "training Loss: 0.0009 Acc: 83.5159\n",
      "validation Loss: 0.0009 Acc: 83.8214\n",
      "Saving..\n",
      "Epoch 5/99\n",
      "training Loss: 0.0009 Acc: 83.8194\n",
      "validation Loss: 0.0009 Acc: 84.1667\n",
      "Saving..\n",
      "Epoch 6/99\n",
      "training Loss: 0.0009 Acc: 84.1974\n",
      "validation Loss: 0.0009 Acc: 84.3095\n",
      "Saving..\n",
      "Epoch 7/99\n",
      "training Loss: 0.0009 Acc: 84.3164\n",
      "validation Loss: 0.0009 Acc: 84.2143\n",
      "Epoch 8/99\n",
      "training Loss: 0.0009 Acc: 84.3789\n",
      "validation Loss: 0.0009 Acc: 84.2500\n",
      "Epoch 9/99\n",
      "training Loss: 0.0009 Acc: 84.5872\n",
      "validation Loss: 0.0009 Acc: 84.3214\n",
      "Saving..\n",
      "Epoch 10/99\n",
      "training Loss: 0.0009 Acc: 84.5337\n",
      "validation Loss: 0.0009 Acc: 84.3810\n",
      "Saving..\n",
      "Epoch 11/99\n",
      "training Loss: 0.0009 Acc: 84.5218\n",
      "validation Loss: 0.0009 Acc: 84.6667\n",
      "Saving..\n",
      "Epoch 12/99\n",
      "training Loss: 0.0009 Acc: 84.7003\n",
      "validation Loss: 0.0009 Acc: 84.6190\n",
      "Epoch 13/99\n",
      "training Loss: 0.0009 Acc: 84.7182\n",
      "validation Loss: 0.0009 Acc: 84.4048\n",
      "Epoch 14/99\n",
      "training Loss: 0.0009 Acc: 84.9354\n",
      "validation Loss: 0.0009 Acc: 84.5595\n",
      "Epoch 15/99\n",
      "training Loss: 0.0009 Acc: 84.8015\n",
      "validation Loss: 0.0008 Acc: 84.7262\n",
      "Saving..\n",
      "Epoch 16/99\n",
      "training Loss: 0.0009 Acc: 84.8580\n",
      "validation Loss: 0.0009 Acc: 84.7024\n",
      "Epoch 17/99\n",
      "training Loss: 0.0009 Acc: 84.8491\n",
      "validation Loss: 0.0008 Acc: 84.7738\n",
      "Saving..\n",
      "Epoch 18/99\n",
      "training Loss: 0.0009 Acc: 84.9503\n",
      "validation Loss: 0.0008 Acc: 84.8571\n",
      "Saving..\n",
      "Epoch 19/99\n",
      "training Loss: 0.0009 Acc: 85.0009\n",
      "validation Loss: 0.0008 Acc: 84.8452\n",
      "Epoch 20/99\n",
      "training Loss: 0.0009 Acc: 84.9592\n",
      "validation Loss: 0.0008 Acc: 84.7381\n",
      "Epoch 21/99\n",
      "training Loss: 0.0009 Acc: 84.9592\n",
      "validation Loss: 0.0008 Acc: 84.9524\n",
      "Saving..\n",
      "Epoch 22/99\n",
      "training Loss: 0.0009 Acc: 84.8580\n",
      "validation Loss: 0.0008 Acc: 85.0357\n",
      "Saving..\n",
      "Epoch 23/99\n",
      "training Loss: 0.0009 Acc: 85.1646\n",
      "validation Loss: 0.0008 Acc: 84.9524\n",
      "Epoch 24/99\n",
      "training Loss: 0.0009 Acc: 85.0812\n",
      "validation Loss: 0.0008 Acc: 85.0952\n",
      "Saving..\n",
      "Epoch 25/99\n",
      "training Loss: 0.0009 Acc: 85.0812\n",
      "validation Loss: 0.0008 Acc: 85.1310\n",
      "Saving..\n",
      "Epoch 26/99\n",
      "training Loss: 0.0009 Acc: 85.0664\n",
      "validation Loss: 0.0008 Acc: 85.1667\n",
      "Saving..\n",
      "Epoch 27/99\n",
      "training Loss: 0.0008 Acc: 85.3997\n",
      "validation Loss: 0.0008 Acc: 85.0833\n",
      "Epoch 28/99\n",
      "training Loss: 0.0009 Acc: 85.1884\n",
      "validation Loss: 0.0008 Acc: 85.2024\n",
      "Saving..\n",
      "Epoch 29/99\n",
      "training Loss: 0.0008 Acc: 85.1527\n",
      "validation Loss: 0.0008 Acc: 85.0714\n",
      "Epoch 30/99\n",
      "training Loss: 0.0009 Acc: 85.2241\n",
      "validation Loss: 0.0008 Acc: 85.2619\n",
      "Saving..\n",
      "Epoch 31/99\n",
      "training Loss: 0.0008 Acc: 85.1616\n",
      "validation Loss: 0.0008 Acc: 85.3214\n",
      "Saving..\n",
      "Epoch 32/99\n",
      "training Loss: 0.0008 Acc: 85.2390\n",
      "validation Loss: 0.0008 Acc: 85.0714\n",
      "Epoch 33/99\n",
      "training Loss: 0.0008 Acc: 85.1556\n",
      "validation Loss: 0.0008 Acc: 85.2857\n",
      "Epoch 34/99\n",
      "training Loss: 0.0008 Acc: 85.1884\n",
      "validation Loss: 0.0008 Acc: 85.4524\n",
      "Saving..\n",
      "Epoch 35/99\n",
      "training Loss: 0.0008 Acc: 85.3640\n",
      "validation Loss: 0.0008 Acc: 85.4643\n",
      "Saving..\n",
      "Epoch 36/99\n",
      "training Loss: 0.0008 Acc: 85.3550\n",
      "validation Loss: 0.0008 Acc: 85.4524\n",
      "Epoch 37/99\n",
      "training Loss: 0.0008 Acc: 85.2211\n",
      "validation Loss: 0.0008 Acc: 85.2500\n",
      "Epoch 38/99\n",
      "training Loss: 0.0008 Acc: 85.2360\n",
      "validation Loss: 0.0008 Acc: 85.2381\n",
      "Epoch 39/99\n",
      "training Loss: 0.0008 Acc: 85.3342\n",
      "validation Loss: 0.0008 Acc: 85.4762\n",
      "Saving..\n",
      "Epoch 40/99\n",
      "training Loss: 0.0008 Acc: 85.4205\n",
      "validation Loss: 0.0008 Acc: 85.1905\n",
      "Epoch 41/99\n",
      "training Loss: 0.0008 Acc: 85.3640\n",
      "validation Loss: 0.0008 Acc: 85.0357\n",
      "Epoch 42/99\n",
      "training Loss: 0.0008 Acc: 85.3074\n",
      "validation Loss: 0.0008 Acc: 85.2381\n",
      "Epoch 43/99\n",
      "training Loss: 0.0008 Acc: 85.4294\n",
      "validation Loss: 0.0008 Acc: 85.4881\n",
      "Saving..\n",
      "Epoch 44/99\n",
      "training Loss: 0.0008 Acc: 85.2747\n",
      "validation Loss: 0.0008 Acc: 85.3214\n",
      "Epoch 45/99\n",
      "training Loss: 0.0008 Acc: 85.4622\n",
      "validation Loss: 0.0008 Acc: 85.3095\n",
      "Epoch 46/99\n",
      "training Loss: 0.0008 Acc: 85.4919\n",
      "validation Loss: 0.0008 Acc: 85.3571\n",
      "Epoch 47/99\n",
      "training Loss: 0.0008 Acc: 85.4473\n",
      "validation Loss: 0.0008 Acc: 85.2976\n",
      "Epoch 48/99\n",
      "training Loss: 0.0008 Acc: 85.4116\n",
      "validation Loss: 0.0008 Acc: 85.2619\n",
      "Epoch 49/99\n",
      "training Loss: 0.0008 Acc: 85.5872\n",
      "validation Loss: 0.0008 Acc: 85.3929\n",
      "Epoch 50/99\n",
      "training Loss: 0.0008 Acc: 85.5157\n",
      "validation Loss: 0.0008 Acc: 85.5833\n",
      "Saving..\n",
      "Epoch 51/99\n",
      "training Loss: 0.0008 Acc: 85.5009\n",
      "validation Loss: 0.0008 Acc: 85.3333\n",
      "Epoch 52/99\n",
      "training Loss: 0.0008 Acc: 85.3431\n",
      "validation Loss: 0.0008 Acc: 85.4286\n",
      "Epoch 53/99\n",
      "training Loss: 0.0008 Acc: 85.6556\n",
      "validation Loss: 0.0008 Acc: 85.4762\n",
      "Epoch 54/99\n",
      "training Loss: 0.0008 Acc: 85.5276\n",
      "validation Loss: 0.0008 Acc: 85.4762\n",
      "Epoch 55/99\n",
      "training Loss: 0.0008 Acc: 85.5574\n",
      "validation Loss: 0.0008 Acc: 85.4286\n",
      "Epoch 56/99\n",
      "training Loss: 0.0008 Acc: 85.5455\n",
      "validation Loss: 0.0008 Acc: 85.4286\n",
      "Epoch 57/99\n",
      "training Loss: 0.0008 Acc: 85.4800\n",
      "validation Loss: 0.0008 Acc: 85.4762\n",
      "Epoch 58/99\n",
      "training Loss: 0.0008 Acc: 85.5663\n",
      "validation Loss: 0.0008 Acc: 85.4286\n",
      "Epoch 59/99\n",
      "training Loss: 0.0008 Acc: 85.5396\n",
      "validation Loss: 0.0008 Acc: 85.4762\n",
      "Epoch 60/99\n",
      "training Loss: 0.0008 Acc: 85.5336\n",
      "validation Loss: 0.0008 Acc: 85.5595\n",
      "Early stopped.\n",
      "Best val acc: 85.583333\n",
      "----------\n",
      "Epoch 0/99\n",
      "training Loss: 0.0015 Acc: 72.6237\n",
      "validation Loss: 0.0010 Acc: 81.0476\n",
      "Saving..\n",
      "Epoch 1/99\n",
      "training Loss: 0.0010 Acc: 81.6797\n",
      "validation Loss: 0.0009 Acc: 83.9286\n",
      "Saving..\n",
      "Epoch 2/99\n",
      "training Loss: 0.0010 Acc: 83.0159\n",
      "validation Loss: 0.0009 Acc: 84.2500\n",
      "Saving..\n",
      "Epoch 3/99\n",
      "training Loss: 0.0010 Acc: 83.3075\n",
      "validation Loss: 0.0009 Acc: 84.5238\n",
      "Saving..\n",
      "Epoch 4/99\n",
      "training Loss: 0.0009 Acc: 83.5248\n",
      "validation Loss: 0.0009 Acc: 84.7024\n",
      "Saving..\n",
      "Epoch 5/99\n",
      "training Loss: 0.0009 Acc: 83.7123\n",
      "validation Loss: 0.0009 Acc: 84.8690\n",
      "Saving..\n",
      "Epoch 6/99\n",
      "training Loss: 0.0009 Acc: 84.1140\n",
      "validation Loss: 0.0009 Acc: 85.0476\n",
      "Saving..\n",
      "Epoch 7/99\n",
      "training Loss: 0.0009 Acc: 84.2926\n",
      "validation Loss: 0.0008 Acc: 85.2143\n",
      "Saving..\n",
      "Epoch 8/99\n",
      "training Loss: 0.0009 Acc: 84.2837\n",
      "validation Loss: 0.0008 Acc: 85.1548\n",
      "Epoch 9/99\n",
      "training Loss: 0.0009 Acc: 84.4414\n",
      "validation Loss: 0.0008 Acc: 85.1905\n",
      "Epoch 10/99\n",
      "training Loss: 0.0009 Acc: 84.3730\n",
      "validation Loss: 0.0008 Acc: 85.4048\n",
      "Saving..\n",
      "Epoch 11/99\n",
      "training Loss: 0.0009 Acc: 84.6438\n",
      "validation Loss: 0.0008 Acc: 85.4405\n",
      "Saving..\n",
      "Epoch 12/99\n",
      "training Loss: 0.0009 Acc: 84.4533\n",
      "validation Loss: 0.0008 Acc: 85.4881\n",
      "Saving..\n",
      "Epoch 13/99\n",
      "training Loss: 0.0009 Acc: 84.5337\n",
      "validation Loss: 0.0008 Acc: 85.5952\n",
      "Saving..\n",
      "Epoch 14/99\n",
      "training Loss: 0.0009 Acc: 84.5456\n",
      "validation Loss: 0.0008 Acc: 85.5119\n",
      "Epoch 15/99\n",
      "training Loss: 0.0009 Acc: 84.7807\n",
      "validation Loss: 0.0008 Acc: 85.5952\n",
      "Epoch 16/99\n",
      "training Loss: 0.0009 Acc: 84.7122\n",
      "validation Loss: 0.0008 Acc: 85.5833\n",
      "Epoch 17/99\n",
      "training Loss: 0.0009 Acc: 84.6438\n",
      "validation Loss: 0.0008 Acc: 85.6190\n",
      "Saving..\n",
      "Epoch 18/99\n",
      "training Loss: 0.0009 Acc: 84.9473\n",
      "validation Loss: 0.0008 Acc: 85.5833\n",
      "Epoch 19/99\n",
      "training Loss: 0.0009 Acc: 84.8848\n",
      "validation Loss: 0.0008 Acc: 85.6429\n",
      "Saving..\n",
      "Epoch 20/99\n",
      "training Loss: 0.0009 Acc: 84.7331\n",
      "validation Loss: 0.0008 Acc: 85.6905\n",
      "Saving..\n",
      "Epoch 21/99\n",
      "training Loss: 0.0009 Acc: 84.8313\n",
      "validation Loss: 0.0008 Acc: 85.7500\n",
      "Saving..\n",
      "Epoch 22/99\n",
      "training Loss: 0.0009 Acc: 84.9711\n",
      "validation Loss: 0.0008 Acc: 85.6429\n",
      "Epoch 23/99\n",
      "training Loss: 0.0009 Acc: 84.9384\n",
      "validation Loss: 0.0008 Acc: 85.7500\n",
      "Epoch 24/99\n",
      "training Loss: 0.0009 Acc: 84.9652\n",
      "validation Loss: 0.0008 Acc: 85.5238\n",
      "Epoch 25/99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Loss: 0.0009 Acc: 85.1616\n",
      "validation Loss: 0.0008 Acc: 85.7857\n",
      "Saving..\n",
      "Epoch 26/99\n",
      "training Loss: 0.0009 Acc: 84.9324\n",
      "validation Loss: 0.0008 Acc: 85.8810\n",
      "Saving..\n",
      "Epoch 27/99\n",
      "training Loss: 0.0009 Acc: 85.0842\n",
      "validation Loss: 0.0008 Acc: 85.7738\n",
      "Epoch 28/99\n",
      "training Loss: 0.0009 Acc: 85.1556\n",
      "validation Loss: 0.0008 Acc: 85.8929\n",
      "Saving..\n",
      "Epoch 29/99\n",
      "training Loss: 0.0009 Acc: 85.0187\n",
      "validation Loss: 0.0008 Acc: 85.8690\n",
      "Epoch 30/99\n",
      "training Loss: 0.0009 Acc: 85.0812\n",
      "validation Loss: 0.0008 Acc: 85.8452\n",
      "Epoch 31/99\n",
      "training Loss: 0.0009 Acc: 85.0664\n",
      "validation Loss: 0.0008 Acc: 85.8929\n",
      "Epoch 32/99\n",
      "training Loss: 0.0009 Acc: 85.1556\n",
      "validation Loss: 0.0008 Acc: 85.8214\n",
      "Epoch 33/99\n",
      "training Loss: 0.0008 Acc: 85.0664\n",
      "validation Loss: 0.0008 Acc: 86.0714\n",
      "Saving..\n",
      "Epoch 34/99\n",
      "training Loss: 0.0008 Acc: 85.2033\n",
      "validation Loss: 0.0008 Acc: 85.7738\n",
      "Epoch 35/99\n",
      "training Loss: 0.0008 Acc: 85.2271\n",
      "validation Loss: 0.0008 Acc: 85.9167\n",
      "Epoch 36/99\n",
      "training Loss: 0.0008 Acc: 85.1497\n",
      "validation Loss: 0.0008 Acc: 86.0000\n",
      "Epoch 37/99\n",
      "training Loss: 0.0008 Acc: 85.1914\n",
      "validation Loss: 0.0008 Acc: 85.9167\n",
      "Epoch 38/99\n",
      "training Loss: 0.0009 Acc: 85.1556\n",
      "validation Loss: 0.0008 Acc: 85.8571\n",
      "Epoch 39/99\n",
      "training Loss: 0.0008 Acc: 85.2598\n",
      "validation Loss: 0.0008 Acc: 85.9405\n",
      "Epoch 40/99\n",
      "training Loss: 0.0008 Acc: 85.2062\n",
      "validation Loss: 0.0008 Acc: 85.9405\n",
      "Epoch 41/99\n",
      "training Loss: 0.0008 Acc: 85.2925\n",
      "validation Loss: 0.0008 Acc: 85.8810\n",
      "Epoch 42/99\n",
      "training Loss: 0.0008 Acc: 85.0902\n",
      "validation Loss: 0.0008 Acc: 86.0000\n",
      "Epoch 43/99\n",
      "training Loss: 0.0008 Acc: 85.1318\n",
      "validation Loss: 0.0008 Acc: 86.0119\n",
      "Early stopped.\n",
      "Best val acc: 86.071429\n",
      "----------\n",
      "Average best_acc across k-fold: 85.6744964351\n",
      "New configuration: {'hidden_layers': 3, 'dropout_g': 0.8750310522247028, 'initial_nodes': 335, 'dropout': 0.022078755694777755, 'gru_layers': 2, 'batch_size': 277, 'gru_size': 340, 'learning_rate': 0.03256670988872255}\n",
      "Epoch 0/99\n",
      "training Loss: 0.0034 Acc: 72.8006\n",
      "validation Loss: 0.0015 Acc: 83.2421\n",
      "Saving..\n",
      "Epoch 1/99\n",
      "training Loss: 0.0016 Acc: 81.3155\n",
      "validation Loss: 0.0015 Acc: 82.5161\n",
      "Epoch 2/99\n",
      "training Loss: 0.0016 Acc: 81.1756\n",
      "validation Loss: 0.0015 Acc: 83.1231\n",
      "Epoch 3/99\n",
      "training Loss: 0.0016 Acc: 81.1280\n",
      "validation Loss: 0.0016 Acc: 82.7541\n",
      "Epoch 4/99\n",
      "training Loss: 0.0016 Acc: 81.4762\n",
      "validation Loss: 0.0015 Acc: 83.0398\n",
      "Epoch 5/99\n",
      "training Loss: 0.0018 Acc: 79.5655\n",
      "validation Loss: 0.0016 Acc: 82.9921\n",
      "Epoch 6/99\n",
      "training Loss: 0.0016 Acc: 81.5060\n",
      "validation Loss: 0.0014 Acc: 83.5277\n",
      "Saving..\n",
      "Epoch 7/99\n",
      "training Loss: 0.0016 Acc: 81.6875\n",
      "validation Loss: 0.0014 Acc: 83.8491\n",
      "Saving..\n",
      "Epoch 8/99\n",
      "training Loss: 0.0016 Acc: 81.4405\n",
      "validation Loss: 0.0017 Acc: 81.1711\n",
      "Epoch 9/99\n",
      "training Loss: 0.0017 Acc: 80.7292\n",
      "validation Loss: 0.0016 Acc: 81.9686\n",
      "Epoch 10/99\n",
      "training Loss: 0.0016 Acc: 81.1071\n",
      "validation Loss: 0.0015 Acc: 83.7301\n",
      "Epoch 11/99\n",
      "training Loss: 0.0016 Acc: 81.4048\n",
      "validation Loss: 0.0015 Acc: 83.6110\n",
      "Epoch 12/99\n",
      "training Loss: 0.0016 Acc: 81.5625\n",
      "validation Loss: 0.0015 Acc: 82.7184\n",
      "Epoch 13/99\n",
      "training Loss: 0.0016 Acc: 81.5565\n",
      "validation Loss: 0.0016 Acc: 81.1235\n",
      "Epoch 14/99\n",
      "training Loss: 0.0015 Acc: 81.8929\n",
      "validation Loss: 0.0014 Acc: 83.9086\n",
      "Saving..\n",
      "Epoch 15/99\n",
      "training Loss: 0.0016 Acc: 81.7768\n",
      "validation Loss: 0.0015 Acc: 82.9088\n",
      "Epoch 16/99\n",
      "training Loss: 0.0015 Acc: 82.1607\n",
      "validation Loss: 0.0014 Acc: 83.9205\n",
      "Saving..\n",
      "Epoch 17/99\n",
      "training Loss: 0.0015 Acc: 82.2738\n",
      "validation Loss: 0.0014 Acc: 83.7896\n",
      "Epoch 18/99\n",
      "training Loss: 0.0015 Acc: 82.2738\n",
      "validation Loss: 0.0014 Acc: 83.8967\n",
      "Epoch 19/99\n",
      "training Loss: 0.0015 Acc: 82.1101\n",
      "validation Loss: 0.0015 Acc: 83.4325\n",
      "Epoch 20/99\n",
      "training Loss: 0.0015 Acc: 82.4107\n",
      "validation Loss: 0.0014 Acc: 83.8967\n",
      "Epoch 21/99\n",
      "training Loss: 0.0015 Acc: 82.2946\n",
      "validation Loss: 0.0014 Acc: 83.9443\n",
      "Saving..\n",
      "Epoch 22/99\n",
      "training Loss: 0.0015 Acc: 82.6429\n",
      "validation Loss: 0.0014 Acc: 83.5634\n",
      "Epoch 23/99\n",
      "training Loss: 0.0015 Acc: 82.3512\n",
      "validation Loss: 0.0014 Acc: 84.1704\n",
      "Saving..\n",
      "Epoch 24/99\n",
      "training Loss: 0.0015 Acc: 82.4970\n",
      "validation Loss: 0.0014 Acc: 83.3016\n",
      "Epoch 25/99\n",
      "training Loss: 0.0015 Acc: 82.5179\n",
      "validation Loss: 0.0014 Acc: 84.0395\n",
      "Epoch 26/99\n",
      "training Loss: 0.0015 Acc: 82.4137\n",
      "validation Loss: 0.0014 Acc: 83.5158\n",
      "Epoch 27/99\n",
      "training Loss: 0.0015 Acc: 82.5685\n",
      "validation Loss: 0.0014 Acc: 83.3849\n",
      "Epoch 28/99\n",
      "training Loss: 0.0015 Acc: 82.5655\n",
      "validation Loss: 0.0014 Acc: 84.3133\n",
      "Saving..\n",
      "Epoch 29/99\n",
      "training Loss: 0.0015 Acc: 82.8571\n",
      "validation Loss: 0.0014 Acc: 83.5991\n",
      "Epoch 30/99\n",
      "training Loss: 0.0015 Acc: 82.8839\n",
      "validation Loss: 0.0014 Acc: 84.0276\n",
      "Epoch 31/99\n",
      "training Loss: 0.0014 Acc: 82.6577\n",
      "validation Loss: 0.0014 Acc: 84.0871\n",
      "Epoch 32/99\n",
      "training Loss: 0.0015 Acc: 82.9167\n",
      "validation Loss: 0.0014 Acc: 84.0038\n",
      "Epoch 33/99\n",
      "training Loss: 0.0015 Acc: 82.8065\n",
      "validation Loss: 0.0014 Acc: 84.3371\n",
      "Saving..\n",
      "Epoch 34/99\n",
      "training Loss: 0.0014 Acc: 83.1101\n",
      "validation Loss: 0.0014 Acc: 84.4918\n",
      "Saving..\n",
      "Epoch 35/99\n",
      "training Loss: 0.0015 Acc: 82.5417\n",
      "validation Loss: 0.0014 Acc: 84.3609\n",
      "Epoch 36/99\n",
      "training Loss: 0.0014 Acc: 82.9375\n",
      "validation Loss: 0.0014 Acc: 83.9562\n",
      "Epoch 37/99\n",
      "training Loss: 0.0014 Acc: 83.1518\n",
      "validation Loss: 0.0013 Acc: 84.5037\n",
      "Saving..\n",
      "Epoch 38/99\n",
      "training Loss: 0.0014 Acc: 83.2232\n",
      "validation Loss: 0.0013 Acc: 84.5513\n",
      "Saving..\n",
      "Epoch 39/99\n",
      "training Loss: 0.0014 Acc: 83.2679\n",
      "validation Loss: 0.0014 Acc: 84.2776\n",
      "Epoch 40/99\n",
      "training Loss: 0.0014 Acc: 83.2351\n",
      "validation Loss: 0.0013 Acc: 84.5275\n",
      "Epoch 41/99\n",
      "training Loss: 0.0014 Acc: 83.3750\n",
      "validation Loss: 0.0013 Acc: 84.5156\n",
      "Epoch 42/99\n",
      "training Loss: 0.0014 Acc: 83.5268\n",
      "validation Loss: 0.0013 Acc: 84.6822\n",
      "Saving..\n",
      "Epoch 43/99\n",
      "training Loss: 0.0014 Acc: 83.1935\n",
      "validation Loss: 0.0013 Acc: 84.7060\n",
      "Saving..\n",
      "Epoch 44/99\n",
      "training Loss: 0.0014 Acc: 83.1101\n",
      "validation Loss: 0.0013 Acc: 84.3490\n",
      "Epoch 45/99\n",
      "training Loss: 0.0014 Acc: 83.4256\n",
      "validation Loss: 0.0014 Acc: 83.9205\n",
      "Epoch 46/99\n",
      "training Loss: 0.0014 Acc: 83.4256\n",
      "validation Loss: 0.0013 Acc: 84.4442\n",
      "Epoch 47/99\n",
      "training Loss: 0.0014 Acc: 83.4167\n",
      "validation Loss: 0.0013 Acc: 84.6822\n",
      "Epoch 48/99\n",
      "training Loss: 0.0014 Acc: 83.3244\n",
      "validation Loss: 0.0013 Acc: 84.8965\n",
      "Saving..\n",
      "Epoch 49/99\n",
      "training Loss: 0.0014 Acc: 83.3810\n",
      "validation Loss: 0.0013 Acc: 84.5989\n",
      "Epoch 50/99\n",
      "training Loss: 0.0014 Acc: 83.5625\n",
      "validation Loss: 0.0013 Acc: 84.1347\n",
      "Epoch 51/99\n",
      "training Loss: 0.0014 Acc: 83.4077\n",
      "validation Loss: 0.0013 Acc: 84.5275\n",
      "Epoch 52/99\n",
      "training Loss: 0.0014 Acc: 83.1756\n",
      "validation Loss: 0.0013 Acc: 84.7774\n",
      "Epoch 53/99\n",
      "training Loss: 0.0014 Acc: 83.4821\n",
      "validation Loss: 0.0013 Acc: 84.0752\n",
      "Epoch 54/99\n",
      "training Loss: 0.0014 Acc: 83.4732\n",
      "validation Loss: 0.0013 Acc: 84.1585\n",
      "Epoch 55/99\n",
      "training Loss: 0.0014 Acc: 83.6726\n",
      "validation Loss: 0.0013 Acc: 84.6584\n",
      "Epoch 56/99\n",
      "training Loss: 0.0014 Acc: 83.4286\n",
      "validation Loss: 0.0013 Acc: 84.1109\n",
      "Epoch 57/99\n",
      "training Loss: 0.0014 Acc: 83.5893\n",
      "validation Loss: 0.0013 Acc: 84.9917\n",
      "Saving..\n",
      "Epoch 58/99\n",
      "training Loss: 0.0014 Acc: 83.4107\n",
      "validation Loss: 0.0013 Acc: 84.7060\n",
      "Epoch 59/99\n",
      "training Loss: 0.0014 Acc: 83.5744\n",
      "validation Loss: 0.0013 Acc: 85.1226\n",
      "Saving..\n",
      "Epoch 60/99\n",
      "training Loss: 0.0014 Acc: 83.6964\n",
      "validation Loss: 0.0013 Acc: 84.9322\n",
      "Epoch 61/99\n",
      "training Loss: 0.0014 Acc: 83.7292\n",
      "validation Loss: 0.0013 Acc: 84.5989\n",
      "Epoch 62/99\n",
      "training Loss: 0.0014 Acc: 83.6369\n",
      "validation Loss: 0.0013 Acc: 84.7893\n",
      "Epoch 63/99\n",
      "training Loss: 0.0014 Acc: 83.6280\n",
      "validation Loss: 0.0013 Acc: 84.5513\n",
      "Epoch 64/99\n",
      "training Loss: 0.0014 Acc: 83.9286\n",
      "validation Loss: 0.0013 Acc: 85.2535\n",
      "Saving..\n",
      "Epoch 65/99\n",
      "training Loss: 0.0014 Acc: 83.8185\n",
      "validation Loss: 0.0013 Acc: 85.1107\n",
      "Epoch 66/99\n",
      "training Loss: 0.0014 Acc: 83.7381\n",
      "validation Loss: 0.0013 Acc: 84.9322\n",
      "Epoch 67/99\n",
      "training Loss: 0.0014 Acc: 83.7857\n",
      "validation Loss: 0.0013 Acc: 84.9322\n",
      "Epoch 68/99\n",
      "training Loss: 0.0014 Acc: 83.6250\n",
      "validation Loss: 0.0013 Acc: 85.1821\n",
      "Epoch 69/99\n",
      "training Loss: 0.0014 Acc: 83.6637\n",
      "validation Loss: 0.0013 Acc: 85.0512\n",
      "Epoch 70/99\n",
      "training Loss: 0.0014 Acc: 83.8661\n",
      "validation Loss: 0.0013 Acc: 84.8965\n",
      "Epoch 71/99\n",
      "training Loss: 0.0014 Acc: 84.0238\n",
      "validation Loss: 0.0013 Acc: 85.0750\n",
      "Epoch 72/99\n",
      "training Loss: 0.0014 Acc: 83.8661\n",
      "validation Loss: 0.0013 Acc: 85.3011\n",
      "Saving..\n",
      "Epoch 73/99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Loss: 0.0014 Acc: 83.7560\n",
      "validation Loss: 0.0013 Acc: 85.0869\n",
      "Epoch 74/99\n",
      "training Loss: 0.0014 Acc: 83.8423\n",
      "validation Loss: 0.0013 Acc: 85.1345\n",
      "Epoch 75/99\n",
      "training Loss: 0.0014 Acc: 83.8542\n",
      "validation Loss: 0.0013 Acc: 85.0274\n",
      "Epoch 76/99\n",
      "training Loss: 0.0014 Acc: 83.9494\n",
      "validation Loss: 0.0013 Acc: 85.1702\n",
      "Epoch 77/99\n",
      "training Loss: 0.0014 Acc: 83.8333\n",
      "validation Loss: 0.0013 Acc: 85.1821\n",
      "Epoch 78/99\n",
      "training Loss: 0.0014 Acc: 83.8929\n",
      "validation Loss: 0.0013 Acc: 85.2535\n",
      "Epoch 79/99\n",
      "training Loss: 0.0014 Acc: 83.8542\n",
      "validation Loss: 0.0013 Acc: 85.1583\n",
      "Epoch 80/99\n",
      "training Loss: 0.0014 Acc: 83.8929\n",
      "validation Loss: 0.0013 Acc: 84.9917\n",
      "Epoch 81/99\n",
      "training Loss: 0.0014 Acc: 83.9167\n",
      "validation Loss: 0.0013 Acc: 85.0393\n",
      "Epoch 82/99\n",
      "training Loss: 0.0014 Acc: 83.8869\n",
      "validation Loss: 0.0013 Acc: 85.0155\n",
      "Early stopped.\n",
      "Best val acc: 85.301119\n",
      "----------\n",
      "Epoch 0/99\n",
      "training Loss: 0.0042 Acc: 60.0054\n",
      "validation Loss: 0.0022 Acc: 66.7024\n",
      "Saving..\n",
      "Epoch 1/99\n",
      "training Loss: 0.0021 Acc: 68.4215\n",
      "validation Loss: 0.0020 Acc: 76.8690\n",
      "Saving..\n",
      "Epoch 2/99\n",
      "training Loss: 0.0023 Acc: 59.9756\n",
      "validation Loss: 0.0026 Acc: 50.0000\n",
      "Epoch 3/99\n",
      "training Loss: 0.0025 Acc: 49.8095\n",
      "validation Loss: 0.0026 Acc: 50.0000\n",
      "Epoch 4/99\n",
      "training Loss: 0.0025 Acc: 49.9226\n",
      "validation Loss: 0.0026 Acc: 50.0000\n",
      "Epoch 5/99\n",
      "training Loss: 0.0025 Acc: 50.2351\n",
      "validation Loss: 0.0026 Acc: 50.0000\n",
      "Epoch 6/99\n",
      "training Loss: 0.0025 Acc: 49.4703\n",
      "validation Loss: 0.0026 Acc: 50.0000\n",
      "Epoch 7/99\n",
      "training Loss: 0.0025 Acc: 50.0655\n",
      "validation Loss: 0.0026 Acc: 50.0000\n",
      "Epoch 8/99\n",
      "training Loss: 0.0025 Acc: 50.4643\n",
      "validation Loss: 0.0026 Acc: 50.0000\n",
      "Epoch 9/99\n",
      "training Loss: 0.0025 Acc: 49.4167\n",
      "validation Loss: 0.0026 Acc: 50.0000\n",
      "Epoch 10/99\n",
      "training Loss: 0.0025 Acc: 49.7143\n",
      "validation Loss: 0.0026 Acc: 50.0000\n",
      "Epoch 11/99\n",
      "training Loss: 0.0025 Acc: 49.8304\n",
      "validation Loss: 0.0026 Acc: 50.0000\n",
      "Early stopped.\n",
      "Best val acc: 76.869048\n",
      "----------\n",
      "Epoch 0/99\n",
      "training Loss: 0.0043 Acc: 49.8839\n",
      "validation Loss: 0.0026 Acc: 50.0000\n",
      "Saving..\n",
      "Epoch 1/99\n",
      "training Loss: 0.0025 Acc: 50.3303\n",
      "validation Loss: 0.0026 Acc: 50.0000\n",
      "Epoch 2/99\n",
      "training Loss: 0.0025 Acc: 50.1101\n",
      "validation Loss: 0.0026 Acc: 50.0000\n",
      "Epoch 3/99\n",
      "training Loss: 0.0025 Acc: 50.2946\n",
      "validation Loss: 0.0026 Acc: 50.0000\n",
      "Epoch 4/99\n",
      "training Loss: 0.0025 Acc: 50.2559\n",
      "validation Loss: 0.0026 Acc: 50.0000\n",
      "Epoch 5/99\n",
      "training Loss: 0.0025 Acc: 49.9911\n",
      "validation Loss: 0.0026 Acc: 50.0000\n",
      "Epoch 6/99\n",
      "training Loss: 0.0025 Acc: 50.0655\n",
      "validation Loss: 0.0026 Acc: 50.0000\n",
      "Epoch 7/99\n",
      "training Loss: 0.0025 Acc: 50.3393\n",
      "validation Loss: 0.0026 Acc: 50.0000\n",
      "Epoch 8/99\n",
      "training Loss: 0.0025 Acc: 49.6131\n",
      "validation Loss: 0.0026 Acc: 50.0000\n",
      "Epoch 9/99\n",
      "training Loss: 0.0025 Acc: 50.1756\n",
      "validation Loss: 0.0026 Acc: 50.0000\n",
      "Epoch 10/99\n",
      "training Loss: 0.0025 Acc: 49.8869\n",
      "validation Loss: 0.0026 Acc: 50.0000\n",
      "Early stopped.\n",
      "Best val acc: 50.000000\n",
      "----------\n",
      "Epoch 0/99\n",
      "training Loss: 0.0039 Acc: 50.1309\n",
      "validation Loss: 0.0026 Acc: 50.0000\n",
      "Saving..\n",
      "Epoch 1/99\n",
      "training Loss: 0.0025 Acc: 50.3155\n",
      "validation Loss: 0.0026 Acc: 50.0000\n",
      "Epoch 2/99\n",
      "training Loss: 0.0025 Acc: 49.9524\n",
      "validation Loss: 0.0026 Acc: 50.0000\n",
      "Epoch 3/99\n",
      "training Loss: 0.0025 Acc: 49.9792\n",
      "validation Loss: 0.0026 Acc: 50.0000\n",
      "Epoch 4/99\n",
      "training Loss: 0.0025 Acc: 49.8363\n",
      "validation Loss: 0.0026 Acc: 50.0000\n",
      "Epoch 5/99\n",
      "training Loss: 0.0025 Acc: 49.2828\n",
      "validation Loss: 0.0026 Acc: 50.0000\n",
      "Epoch 6/99\n",
      "training Loss: 0.0025 Acc: 49.7351\n",
      "validation Loss: 0.0026 Acc: 50.0000\n",
      "Epoch 7/99\n",
      "training Loss: 0.0025 Acc: 49.8631\n",
      "validation Loss: 0.0026 Acc: 50.0000\n",
      "Epoch 8/99\n",
      "training Loss: 0.0025 Acc: 49.9554\n",
      "validation Loss: 0.0026 Acc: 50.0000\n",
      "Epoch 9/99\n",
      "training Loss: 0.0025 Acc: 49.7679\n",
      "validation Loss: 0.0026 Acc: 50.0000\n",
      "Epoch 10/99\n",
      "training Loss: 0.0025 Acc: 49.6756\n",
      "validation Loss: 0.0026 Acc: 50.0000\n",
      "Early stopped.\n",
      "Best val acc: 50.000000\n",
      "----------\n",
      "Epoch 0/99\n",
      "training Loss: 0.0025 Acc: 70.0167\n",
      "validation Loss: 0.0015 Acc: 83.0714\n",
      "Saving..\n",
      "Epoch 1/99\n",
      "training Loss: 0.0016 Acc: 80.9476\n",
      "validation Loss: 0.0015 Acc: 82.5952\n",
      "Epoch 2/99\n",
      "training Loss: 0.0015 Acc: 81.3463\n",
      "validation Loss: 0.0014 Acc: 84.2024\n",
      "Saving..\n",
      "Epoch 3/99\n",
      "training Loss: 0.0015 Acc: 81.5457\n",
      "validation Loss: 0.0014 Acc: 84.3095\n",
      "Saving..\n",
      "Epoch 4/99\n",
      "training Loss: 0.0016 Acc: 81.5071\n",
      "validation Loss: 0.0016 Acc: 79.2857\n",
      "Epoch 5/99\n",
      "training Loss: 0.0015 Acc: 81.7779\n",
      "validation Loss: 0.0014 Acc: 84.3452\n",
      "Saving..\n",
      "Epoch 6/99\n",
      "training Loss: 0.0015 Acc: 81.8076\n",
      "validation Loss: 0.0014 Acc: 84.1190\n",
      "Epoch 7/99\n",
      "training Loss: 0.0015 Acc: 81.6559\n",
      "validation Loss: 0.0016 Acc: 79.9643\n",
      "Epoch 8/99\n",
      "training Loss: 0.0018 Acc: 76.2455\n",
      "validation Loss: 0.0026 Acc: 50.0000\n",
      "Epoch 9/99\n",
      "training Loss: 0.0025 Acc: 49.8363\n",
      "validation Loss: 0.0026 Acc: 50.0000\n",
      "Epoch 10/99\n",
      "training Loss: 0.0025 Acc: 49.5447\n",
      "validation Loss: 0.0026 Acc: 50.0000\n",
      "Epoch 11/99\n",
      "training Loss: 0.0025 Acc: 50.2172\n",
      "validation Loss: 0.0026 Acc: 50.0000\n",
      "Epoch 12/99\n",
      "training Loss: 0.0025 Acc: 49.7113\n",
      "validation Loss: 0.0026 Acc: 50.0000\n",
      "Epoch 13/99\n",
      "training Loss: 0.0025 Acc: 49.9435\n",
      "validation Loss: 0.0026 Acc: 50.0000\n",
      "Epoch 14/99\n",
      "training Loss: 0.0025 Acc: 49.6012\n",
      "validation Loss: 0.0026 Acc: 50.0000\n",
      "Epoch 15/99\n",
      "training Loss: 0.0025 Acc: 49.8572\n",
      "validation Loss: 0.0026 Acc: 50.0000\n",
      "Early stopped.\n",
      "Best val acc: 84.345238\n",
      "----------\n",
      "Average best_acc across k-fold: 69.3030808991\n",
      "New configuration: {'hidden_layers': 1, 'dropout_g': 0.3299055729326962, 'initial_nodes': 231, 'dropout': 0.027789022213795277, 'gru_layers': 2, 'batch_size': 363, 'gru_size': 490, 'learning_rate': 0.000838637201070686}\n",
      "Epoch 0/99\n",
      "training Loss: 0.0011 Acc: 81.4286\n",
      "validation Loss: 0.0010 Acc: 84.3609\n",
      "Saving..\n",
      "Epoch 1/99\n",
      "training Loss: 0.0010 Acc: 84.0357\n",
      "validation Loss: 0.0010 Acc: 84.0157\n",
      "Epoch 2/99\n",
      "training Loss: 0.0010 Acc: 84.5298\n",
      "validation Loss: 0.0010 Acc: 84.8131\n",
      "Saving..\n",
      "Epoch 3/99\n",
      "training Loss: 0.0010 Acc: 84.7113\n",
      "validation Loss: 0.0009 Acc: 84.9679\n",
      "Saving..\n",
      "Epoch 4/99\n",
      "training Loss: 0.0009 Acc: 85.0238\n",
      "validation Loss: 0.0010 Acc: 85.2059\n",
      "Saving..\n",
      "Epoch 5/99\n",
      "training Loss: 0.0009 Acc: 85.0893\n",
      "validation Loss: 0.0010 Acc: 85.3011\n",
      "Saving..\n",
      "Epoch 6/99\n",
      "training Loss: 0.0009 Acc: 85.2232\n",
      "validation Loss: 0.0010 Acc: 85.5392\n",
      "Saving..\n",
      "Epoch 7/99\n",
      "training Loss: 0.0009 Acc: 85.3988\n",
      "validation Loss: 0.0009 Acc: 85.5511\n",
      "Saving..\n",
      "Epoch 8/99\n",
      "training Loss: 0.0009 Acc: 85.4226\n",
      "validation Loss: 0.0009 Acc: 85.5749\n",
      "Saving..\n",
      "Epoch 9/99\n",
      "training Loss: 0.0009 Acc: 85.5387\n",
      "validation Loss: 0.0009 Acc: 85.4915\n",
      "Epoch 10/99\n",
      "training Loss: 0.0009 Acc: 85.5089\n",
      "validation Loss: 0.0009 Acc: 85.5035\n",
      "Epoch 11/99\n",
      "training Loss: 0.0009 Acc: 85.6310\n",
      "validation Loss: 0.0009 Acc: 85.5630\n",
      "Epoch 12/99\n",
      "training Loss: 0.0009 Acc: 85.6905\n",
      "validation Loss: 0.0009 Acc: 85.4201\n",
      "Epoch 13/99\n",
      "training Loss: 0.0009 Acc: 85.7321\n",
      "validation Loss: 0.0009 Acc: 85.4082\n",
      "Epoch 14/99\n",
      "training Loss: 0.0009 Acc: 85.6012\n",
      "validation Loss: 0.0009 Acc: 85.6820\n",
      "Saving..\n",
      "Epoch 15/99\n",
      "training Loss: 0.0009 Acc: 85.7649\n",
      "validation Loss: 0.0009 Acc: 85.7534\n",
      "Saving..\n",
      "Epoch 16/99\n",
      "training Loss: 0.0009 Acc: 85.6101\n",
      "validation Loss: 0.0009 Acc: 85.3249\n",
      "Epoch 17/99\n",
      "training Loss: 0.0009 Acc: 85.7589\n",
      "validation Loss: 0.0009 Acc: 85.5630\n",
      "Epoch 18/99\n",
      "training Loss: 0.0009 Acc: 85.8036\n",
      "validation Loss: 0.0009 Acc: 85.6344\n",
      "Epoch 19/99\n",
      "training Loss: 0.0009 Acc: 85.6429\n",
      "validation Loss: 0.0009 Acc: 85.7891\n",
      "Saving..\n",
      "Epoch 20/99\n",
      "training Loss: 0.0009 Acc: 85.7500\n",
      "validation Loss: 0.0009 Acc: 85.6463\n",
      "Epoch 21/99\n",
      "training Loss: 0.0009 Acc: 85.9315\n",
      "validation Loss: 0.0009 Acc: 85.8605\n",
      "Saving..\n",
      "Epoch 22/99\n",
      "training Loss: 0.0009 Acc: 85.7946\n",
      "validation Loss: 0.0009 Acc: 85.7177\n",
      "Epoch 23/99\n",
      "training Loss: 0.0009 Acc: 85.8125\n",
      "validation Loss: 0.0009 Acc: 85.8724\n",
      "Saving..\n",
      "Epoch 24/99\n",
      "training Loss: 0.0009 Acc: 85.8601\n",
      "validation Loss: 0.0009 Acc: 85.7296\n",
      "Epoch 25/99\n",
      "training Loss: 0.0009 Acc: 85.7976\n",
      "validation Loss: 0.0009 Acc: 85.9081\n",
      "Saving..\n",
      "Epoch 26/99\n",
      "training Loss: 0.0009 Acc: 85.9435\n",
      "validation Loss: 0.0009 Acc: 85.7772\n",
      "Epoch 27/99\n",
      "training Loss: 0.0009 Acc: 85.8363\n",
      "validation Loss: 0.0009 Acc: 85.6820\n",
      "Epoch 28/99\n",
      "training Loss: 0.0009 Acc: 85.9018\n",
      "validation Loss: 0.0009 Acc: 85.8724\n",
      "Epoch 29/99\n",
      "training Loss: 0.0009 Acc: 85.9762\n",
      "validation Loss: 0.0009 Acc: 85.7653\n",
      "Epoch 30/99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Loss: 0.0009 Acc: 86.0476\n",
      "validation Loss: 0.0009 Acc: 85.8010\n",
      "Epoch 31/99\n",
      "training Loss: 0.0009 Acc: 86.1667\n",
      "validation Loss: 0.0009 Acc: 85.9557\n",
      "Saving..\n",
      "Epoch 32/99\n",
      "training Loss: 0.0009 Acc: 86.0982\n",
      "validation Loss: 0.0009 Acc: 85.7891\n",
      "Epoch 33/99\n",
      "training Loss: 0.0009 Acc: 86.2470\n",
      "validation Loss: 0.0009 Acc: 85.9081\n",
      "Epoch 34/99\n",
      "training Loss: 0.0009 Acc: 86.1429\n",
      "validation Loss: 0.0009 Acc: 85.8724\n",
      "Epoch 35/99\n",
      "training Loss: 0.0009 Acc: 86.1786\n",
      "validation Loss: 0.0009 Acc: 85.8486\n",
      "Epoch 36/99\n",
      "training Loss: 0.0009 Acc: 86.0744\n",
      "validation Loss: 0.0009 Acc: 85.8724\n",
      "Epoch 37/99\n",
      "training Loss: 0.0009 Acc: 86.0923\n",
      "validation Loss: 0.0009 Acc: 85.9557\n",
      "Epoch 38/99\n",
      "training Loss: 0.0009 Acc: 86.2798\n",
      "validation Loss: 0.0009 Acc: 86.1819\n",
      "Saving..\n",
      "Epoch 39/99\n",
      "training Loss: 0.0009 Acc: 86.2976\n",
      "validation Loss: 0.0009 Acc: 85.8605\n",
      "Epoch 40/99\n",
      "training Loss: 0.0009 Acc: 86.2917\n",
      "validation Loss: 0.0009 Acc: 85.9557\n",
      "Epoch 41/99\n",
      "training Loss: 0.0009 Acc: 86.2530\n",
      "validation Loss: 0.0009 Acc: 85.8248\n",
      "Epoch 42/99\n",
      "training Loss: 0.0009 Acc: 86.2619\n",
      "validation Loss: 0.0009 Acc: 85.8843\n",
      "Epoch 43/99\n",
      "training Loss: 0.0009 Acc: 86.2411\n",
      "validation Loss: 0.0009 Acc: 85.9676\n",
      "Epoch 44/99\n",
      "training Loss: 0.0009 Acc: 86.3601\n",
      "validation Loss: 0.0009 Acc: 86.1224\n",
      "Epoch 45/99\n",
      "training Loss: 0.0009 Acc: 86.3214\n",
      "validation Loss: 0.0009 Acc: 86.0985\n",
      "Epoch 46/99\n",
      "training Loss: 0.0009 Acc: 86.5089\n",
      "validation Loss: 0.0009 Acc: 86.0152\n",
      "Epoch 47/99\n",
      "training Loss: 0.0009 Acc: 86.4286\n",
      "validation Loss: 0.0009 Acc: 85.9081\n",
      "Epoch 48/99\n",
      "training Loss: 0.0008 Acc: 86.4613\n",
      "validation Loss: 0.0009 Acc: 86.1104\n",
      "Early stopped.\n",
      "Best val acc: 86.181861\n",
      "----------\n",
      "Epoch 0/99\n",
      "training Loss: 0.0011 Acc: 81.8791\n",
      "validation Loss: 0.0010 Acc: 84.2143\n",
      "Saving..\n",
      "Epoch 1/99\n",
      "training Loss: 0.0010 Acc: 84.2628\n",
      "validation Loss: 0.0010 Acc: 84.3690\n",
      "Saving..\n",
      "Epoch 2/99\n",
      "training Loss: 0.0010 Acc: 84.7122\n",
      "validation Loss: 0.0010 Acc: 84.9643\n",
      "Saving..\n",
      "Epoch 3/99\n",
      "training Loss: 0.0009 Acc: 84.7628\n",
      "validation Loss: 0.0010 Acc: 85.2381\n",
      "Saving..\n",
      "Epoch 4/99\n",
      "training Loss: 0.0009 Acc: 85.1051\n",
      "validation Loss: 0.0010 Acc: 85.2024\n",
      "Epoch 5/99\n",
      "training Loss: 0.0009 Acc: 85.2122\n",
      "validation Loss: 0.0010 Acc: 85.4048\n",
      "Saving..\n",
      "Epoch 6/99\n",
      "training Loss: 0.0009 Acc: 85.1586\n",
      "validation Loss: 0.0010 Acc: 85.1071\n",
      "Epoch 7/99\n",
      "training Loss: 0.0009 Acc: 85.2390\n",
      "validation Loss: 0.0009 Acc: 85.8810\n",
      "Saving..\n",
      "Epoch 8/99\n",
      "training Loss: 0.0009 Acc: 85.2866\n",
      "validation Loss: 0.0009 Acc: 85.7738\n",
      "Epoch 9/99\n",
      "training Loss: 0.0009 Acc: 85.5217\n",
      "validation Loss: 0.0009 Acc: 85.7262\n",
      "Epoch 10/99\n",
      "training Loss: 0.0009 Acc: 85.4503\n",
      "validation Loss: 0.0009 Acc: 85.6548\n",
      "Epoch 11/99\n",
      "training Loss: 0.0009 Acc: 85.5366\n",
      "validation Loss: 0.0009 Acc: 85.6190\n",
      "Epoch 12/99\n",
      "training Loss: 0.0009 Acc: 85.5157\n",
      "validation Loss: 0.0010 Acc: 85.4524\n",
      "Epoch 13/99\n",
      "training Loss: 0.0009 Acc: 85.5098\n",
      "validation Loss: 0.0009 Acc: 85.5357\n",
      "Epoch 14/99\n",
      "training Loss: 0.0009 Acc: 85.5098\n",
      "validation Loss: 0.0009 Acc: 85.8214\n",
      "Epoch 15/99\n",
      "training Loss: 0.0009 Acc: 85.6675\n",
      "validation Loss: 0.0009 Acc: 85.9524\n",
      "Saving..\n",
      "Epoch 16/99\n",
      "training Loss: 0.0009 Acc: 85.6259\n",
      "validation Loss: 0.0009 Acc: 85.9405\n",
      "Epoch 17/99\n",
      "training Loss: 0.0009 Acc: 85.7032\n",
      "validation Loss: 0.0009 Acc: 86.0476\n",
      "Saving..\n",
      "Epoch 18/99\n",
      "training Loss: 0.0009 Acc: 85.9264\n",
      "validation Loss: 0.0009 Acc: 85.9643\n",
      "Epoch 19/99\n",
      "training Loss: 0.0009 Acc: 85.8610\n",
      "validation Loss: 0.0009 Acc: 85.6190\n",
      "Epoch 20/99\n",
      "training Loss: 0.0009 Acc: 85.8580\n",
      "validation Loss: 0.0009 Acc: 85.8690\n",
      "Epoch 21/99\n",
      "training Loss: 0.0009 Acc: 85.7211\n",
      "validation Loss: 0.0009 Acc: 85.8214\n",
      "Epoch 22/99\n",
      "training Loss: 0.0009 Acc: 85.8491\n",
      "validation Loss: 0.0009 Acc: 85.9762\n",
      "Epoch 23/99\n",
      "training Loss: 0.0009 Acc: 85.9264\n",
      "validation Loss: 0.0009 Acc: 86.1310\n",
      "Saving..\n",
      "Epoch 24/99\n",
      "training Loss: 0.0009 Acc: 85.8818\n",
      "validation Loss: 0.0009 Acc: 86.1190\n",
      "Epoch 25/99\n",
      "training Loss: 0.0009 Acc: 86.0306\n",
      "validation Loss: 0.0009 Acc: 86.1667\n",
      "Saving..\n",
      "Epoch 26/99\n",
      "training Loss: 0.0009 Acc: 86.0336\n",
      "validation Loss: 0.0009 Acc: 86.0714\n",
      "Epoch 27/99\n",
      "training Loss: 0.0009 Acc: 86.0961\n",
      "validation Loss: 0.0009 Acc: 86.1310\n",
      "Epoch 28/99\n",
      "training Loss: 0.0009 Acc: 86.0276\n",
      "validation Loss: 0.0009 Acc: 86.0833\n",
      "Epoch 29/99\n",
      "training Loss: 0.0009 Acc: 86.2270\n",
      "validation Loss: 0.0009 Acc: 86.0952\n",
      "Epoch 30/99\n",
      "training Loss: 0.0009 Acc: 86.1169\n",
      "validation Loss: 0.0009 Acc: 85.5952\n",
      "Epoch 31/99\n",
      "training Loss: 0.0009 Acc: 86.1526\n",
      "validation Loss: 0.0009 Acc: 86.0595\n",
      "Epoch 32/99\n",
      "training Loss: 0.0009 Acc: 86.2359\n",
      "validation Loss: 0.0009 Acc: 86.1905\n",
      "Saving..\n",
      "Epoch 33/99\n",
      "training Loss: 0.0009 Acc: 86.1913\n",
      "validation Loss: 0.0009 Acc: 86.1905\n",
      "Epoch 34/99\n",
      "training Loss: 0.0009 Acc: 86.1645\n",
      "validation Loss: 0.0009 Acc: 86.2738\n",
      "Saving..\n",
      "Epoch 35/99\n",
      "training Loss: 0.0009 Acc: 86.2300\n",
      "validation Loss: 0.0009 Acc: 86.1905\n",
      "Epoch 36/99\n",
      "training Loss: 0.0009 Acc: 86.1318\n",
      "validation Loss: 0.0009 Acc: 86.0714\n",
      "Epoch 37/99\n",
      "training Loss: 0.0009 Acc: 86.2597\n",
      "validation Loss: 0.0009 Acc: 86.1190\n",
      "Epoch 38/99\n",
      "training Loss: 0.0009 Acc: 86.3788\n",
      "validation Loss: 0.0009 Acc: 86.0714\n",
      "Epoch 39/99\n",
      "training Loss: 0.0009 Acc: 86.2151\n",
      "validation Loss: 0.0009 Acc: 86.2024\n",
      "Epoch 40/99\n",
      "training Loss: 0.0009 Acc: 86.3818\n",
      "validation Loss: 0.0009 Acc: 86.1786\n",
      "Epoch 41/99\n",
      "training Loss: 0.0009 Acc: 86.2865\n",
      "validation Loss: 0.0009 Acc: 86.1548\n",
      "Epoch 42/99\n",
      "training Loss: 0.0009 Acc: 86.3074\n",
      "validation Loss: 0.0009 Acc: 86.1667\n",
      "Epoch 43/99\n",
      "training Loss: 0.0009 Acc: 86.2865\n",
      "validation Loss: 0.0009 Acc: 86.1786\n",
      "Epoch 44/99\n",
      "training Loss: 0.0009 Acc: 86.2806\n",
      "validation Loss: 0.0009 Acc: 86.1667\n",
      "Early stopped.\n",
      "Best val acc: 86.273810\n",
      "----------\n",
      "Epoch 0/99\n",
      "training Loss: 0.0011 Acc: 81.8701\n",
      "validation Loss: 0.0010 Acc: 84.0119\n",
      "Saving..\n",
      "Epoch 1/99\n",
      "training Loss: 0.0010 Acc: 84.2688\n",
      "validation Loss: 0.0010 Acc: 84.6667\n",
      "Saving..\n",
      "Epoch 2/99\n",
      "training Loss: 0.0010 Acc: 84.5277\n",
      "validation Loss: 0.0010 Acc: 85.0952\n",
      "Saving..\n",
      "Epoch 3/99\n",
      "training Loss: 0.0009 Acc: 84.9592\n",
      "validation Loss: 0.0010 Acc: 85.4524\n",
      "Saving..\n",
      "Epoch 4/99\n",
      "training Loss: 0.0009 Acc: 85.1973\n",
      "validation Loss: 0.0010 Acc: 85.6429\n",
      "Saving..\n",
      "Epoch 5/99\n",
      "training Loss: 0.0009 Acc: 85.0485\n",
      "validation Loss: 0.0009 Acc: 85.4286\n",
      "Epoch 6/99\n",
      "training Loss: 0.0009 Acc: 85.2925\n",
      "validation Loss: 0.0010 Acc: 85.1071\n",
      "Epoch 7/99\n",
      "training Loss: 0.0009 Acc: 85.3550\n",
      "validation Loss: 0.0010 Acc: 85.3452\n",
      "Epoch 8/99\n",
      "training Loss: 0.0009 Acc: 85.3402\n",
      "validation Loss: 0.0010 Acc: 85.5476\n",
      "Epoch 9/99\n",
      "training Loss: 0.0009 Acc: 85.3997\n",
      "validation Loss: 0.0009 Acc: 85.7738\n",
      "Saving..\n",
      "Epoch 10/99\n",
      "training Loss: 0.0009 Acc: 85.3967\n",
      "validation Loss: 0.0009 Acc: 85.8333\n",
      "Saving..\n",
      "Epoch 11/99\n",
      "training Loss: 0.0009 Acc: 85.5247\n",
      "validation Loss: 0.0010 Acc: 85.4881\n",
      "Epoch 12/99\n",
      "training Loss: 0.0009 Acc: 85.6705\n",
      "validation Loss: 0.0010 Acc: 85.5357\n",
      "Epoch 13/99\n",
      "training Loss: 0.0009 Acc: 85.5931\n",
      "validation Loss: 0.0009 Acc: 85.7500\n",
      "Epoch 14/99\n",
      "training Loss: 0.0009 Acc: 85.6645\n",
      "validation Loss: 0.0009 Acc: 85.7619\n",
      "Epoch 15/99\n",
      "training Loss: 0.0009 Acc: 85.6020\n",
      "validation Loss: 0.0009 Acc: 85.7976\n",
      "Epoch 16/99\n",
      "training Loss: 0.0009 Acc: 85.6586\n",
      "validation Loss: 0.0009 Acc: 85.8214\n",
      "Epoch 17/99\n",
      "training Loss: 0.0009 Acc: 85.4413\n",
      "validation Loss: 0.0009 Acc: 85.7143\n",
      "Epoch 18/99\n",
      "training Loss: 0.0009 Acc: 85.8014\n",
      "validation Loss: 0.0009 Acc: 86.0714\n",
      "Saving..\n",
      "Epoch 19/99\n",
      "training Loss: 0.0009 Acc: 85.8877\n",
      "validation Loss: 0.0009 Acc: 85.7024\n",
      "Epoch 20/99\n",
      "training Loss: 0.0009 Acc: 85.7568\n",
      "validation Loss: 0.0009 Acc: 85.8333\n",
      "Epoch 21/99\n",
      "training Loss: 0.0009 Acc: 85.9145\n",
      "validation Loss: 0.0009 Acc: 85.8333\n",
      "Epoch 22/99\n",
      "training Loss: 0.0009 Acc: 85.7538\n",
      "validation Loss: 0.0009 Acc: 85.8214\n",
      "Epoch 23/99\n",
      "training Loss: 0.0009 Acc: 85.9354\n",
      "validation Loss: 0.0009 Acc: 85.7381\n",
      "Epoch 24/99\n",
      "training Loss: 0.0009 Acc: 85.7895\n",
      "validation Loss: 0.0009 Acc: 85.8571\n",
      "Epoch 25/99\n",
      "training Loss: 0.0009 Acc: 85.9324\n",
      "validation Loss: 0.0009 Acc: 85.7619\n",
      "Epoch 26/99\n",
      "training Loss: 0.0009 Acc: 86.0574\n",
      "validation Loss: 0.0009 Acc: 85.7262\n",
      "Epoch 27/99\n",
      "training Loss: 0.0009 Acc: 86.0157\n",
      "validation Loss: 0.0009 Acc: 86.0238\n",
      "Epoch 28/99\n",
      "training Loss: 0.0009 Acc: 86.1407\n",
      "validation Loss: 0.0009 Acc: 85.9881\n",
      "Early stopped.\n",
      "Best val acc: 86.071429\n",
      "----------\n",
      "Epoch 0/99\n",
      "training Loss: 0.0011 Acc: 81.7957\n",
      "validation Loss: 0.0010 Acc: 83.6905\n",
      "Saving..\n",
      "Epoch 1/99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Loss: 0.0010 Acc: 84.3759\n",
      "validation Loss: 0.0010 Acc: 84.4405\n",
      "Saving..\n",
      "Epoch 2/99\n",
      "training Loss: 0.0010 Acc: 84.7063\n",
      "validation Loss: 0.0010 Acc: 84.8810\n",
      "Saving..\n",
      "Epoch 3/99\n",
      "training Loss: 0.0009 Acc: 84.9503\n",
      "validation Loss: 0.0010 Acc: 85.0714\n",
      "Saving..\n",
      "Epoch 4/99\n",
      "training Loss: 0.0009 Acc: 85.2658\n",
      "validation Loss: 0.0010 Acc: 84.8333\n",
      "Epoch 5/99\n",
      "training Loss: 0.0009 Acc: 85.1765\n",
      "validation Loss: 0.0010 Acc: 84.7857\n",
      "Epoch 6/99\n",
      "training Loss: 0.0009 Acc: 85.2925\n",
      "validation Loss: 0.0010 Acc: 85.1429\n",
      "Saving..\n",
      "Epoch 7/99\n",
      "training Loss: 0.0009 Acc: 85.4354\n",
      "validation Loss: 0.0010 Acc: 85.0119\n",
      "Epoch 8/99\n",
      "training Loss: 0.0009 Acc: 85.4592\n",
      "validation Loss: 0.0009 Acc: 85.1548\n",
      "Saving..\n",
      "Epoch 9/99\n",
      "training Loss: 0.0009 Acc: 85.5128\n",
      "validation Loss: 0.0009 Acc: 85.1190\n",
      "Epoch 10/99\n",
      "training Loss: 0.0009 Acc: 85.5455\n",
      "validation Loss: 0.0009 Acc: 85.4048\n",
      "Saving..\n",
      "Epoch 11/99\n",
      "training Loss: 0.0009 Acc: 85.5634\n",
      "validation Loss: 0.0009 Acc: 85.3452\n",
      "Epoch 12/99\n",
      "training Loss: 0.0009 Acc: 85.5931\n",
      "validation Loss: 0.0010 Acc: 85.0476\n",
      "Epoch 13/99\n",
      "training Loss: 0.0009 Acc: 85.6824\n",
      "validation Loss: 0.0009 Acc: 85.3810\n",
      "Epoch 14/99\n",
      "training Loss: 0.0009 Acc: 85.7836\n",
      "validation Loss: 0.0009 Acc: 85.4405\n",
      "Saving..\n",
      "Epoch 15/99\n",
      "training Loss: 0.0009 Acc: 85.8193\n",
      "validation Loss: 0.0009 Acc: 85.3452\n",
      "Epoch 16/99\n",
      "training Loss: 0.0009 Acc: 85.8610\n",
      "validation Loss: 0.0009 Acc: 85.2500\n",
      "Epoch 17/99\n",
      "training Loss: 0.0009 Acc: 85.8014\n",
      "validation Loss: 0.0009 Acc: 85.3571\n",
      "Epoch 18/99\n",
      "training Loss: 0.0009 Acc: 85.7330\n",
      "validation Loss: 0.0009 Acc: 85.3452\n",
      "Epoch 19/99\n",
      "training Loss: 0.0009 Acc: 86.0038\n",
      "validation Loss: 0.0009 Acc: 85.3571\n",
      "Epoch 20/99\n",
      "training Loss: 0.0009 Acc: 85.8223\n",
      "validation Loss: 0.0009 Acc: 85.5238\n",
      "Saving..\n",
      "Epoch 21/99\n",
      "training Loss: 0.0009 Acc: 85.9740\n",
      "validation Loss: 0.0009 Acc: 85.3929\n",
      "Epoch 22/99\n",
      "training Loss: 0.0009 Acc: 85.9473\n",
      "validation Loss: 0.0009 Acc: 85.4643\n",
      "Epoch 23/99\n",
      "training Loss: 0.0009 Acc: 85.8729\n",
      "validation Loss: 0.0009 Acc: 85.1548\n",
      "Epoch 24/99\n",
      "training Loss: 0.0009 Acc: 85.8550\n",
      "validation Loss: 0.0009 Acc: 85.3214\n",
      "Epoch 25/99\n",
      "training Loss: 0.0009 Acc: 86.0157\n",
      "validation Loss: 0.0009 Acc: 85.6429\n",
      "Saving..\n",
      "Epoch 26/99\n",
      "training Loss: 0.0009 Acc: 86.0484\n",
      "validation Loss: 0.0009 Acc: 85.5238\n",
      "Epoch 27/99\n",
      "training Loss: 0.0009 Acc: 86.2032\n",
      "validation Loss: 0.0009 Acc: 85.5833\n",
      "Epoch 28/99\n",
      "training Loss: 0.0009 Acc: 86.1377\n",
      "validation Loss: 0.0009 Acc: 85.6190\n",
      "Epoch 29/99\n",
      "training Loss: 0.0009 Acc: 86.2032\n",
      "validation Loss: 0.0009 Acc: 85.7143\n",
      "Saving..\n",
      "Epoch 30/99\n",
      "training Loss: 0.0009 Acc: 86.2925\n",
      "validation Loss: 0.0009 Acc: 85.4405\n",
      "Epoch 31/99\n",
      "training Loss: 0.0009 Acc: 86.0663\n",
      "validation Loss: 0.0009 Acc: 85.7024\n",
      "Epoch 32/99\n",
      "training Loss: 0.0009 Acc: 86.1645\n",
      "validation Loss: 0.0009 Acc: 85.8095\n",
      "Saving..\n",
      "Epoch 33/99\n",
      "training Loss: 0.0009 Acc: 86.1943\n",
      "validation Loss: 0.0009 Acc: 85.7024\n",
      "Epoch 34/99\n",
      "training Loss: 0.0009 Acc: 86.2836\n",
      "validation Loss: 0.0009 Acc: 85.7143\n",
      "Epoch 35/99\n",
      "training Loss: 0.0009 Acc: 86.2121\n",
      "validation Loss: 0.0009 Acc: 85.5357\n",
      "Epoch 36/99\n",
      "training Loss: 0.0009 Acc: 86.0901\n",
      "validation Loss: 0.0009 Acc: 85.5595\n",
      "Epoch 37/99\n",
      "training Loss: 0.0009 Acc: 86.3580\n",
      "validation Loss: 0.0009 Acc: 85.7500\n",
      "Epoch 38/99\n",
      "training Loss: 0.0009 Acc: 86.1943\n",
      "validation Loss: 0.0009 Acc: 85.5952\n",
      "Epoch 39/99\n",
      "training Loss: 0.0009 Acc: 86.2895\n",
      "validation Loss: 0.0009 Acc: 85.8095\n",
      "Epoch 40/99\n",
      "training Loss: 0.0009 Acc: 86.4115\n",
      "validation Loss: 0.0009 Acc: 85.6667\n",
      "Epoch 41/99\n",
      "training Loss: 0.0009 Acc: 86.4324\n",
      "validation Loss: 0.0009 Acc: 85.6786\n",
      "Epoch 42/99\n",
      "training Loss: 0.0009 Acc: 86.3788\n",
      "validation Loss: 0.0009 Acc: 85.7857\n",
      "Early stopped.\n",
      "Best val acc: 85.809524\n",
      "----------\n",
      "Epoch 0/99\n",
      "training Loss: 0.0011 Acc: 81.7332\n",
      "validation Loss: 0.0011 Acc: 83.5595\n",
      "Saving..\n",
      "Epoch 1/99\n",
      "training Loss: 0.0010 Acc: 84.3462\n",
      "validation Loss: 0.0010 Acc: 84.2619\n",
      "Saving..\n",
      "Epoch 2/99\n",
      "training Loss: 0.0010 Acc: 84.8075\n",
      "validation Loss: 0.0010 Acc: 84.9048\n",
      "Saving..\n",
      "Epoch 3/99\n",
      "training Loss: 0.0009 Acc: 85.0455\n",
      "validation Loss: 0.0010 Acc: 85.0000\n",
      "Saving..\n",
      "Epoch 4/99\n",
      "training Loss: 0.0009 Acc: 85.3580\n",
      "validation Loss: 0.0010 Acc: 84.9524\n",
      "Epoch 5/99\n",
      "training Loss: 0.0009 Acc: 85.3788\n",
      "validation Loss: 0.0010 Acc: 84.6667\n",
      "Epoch 6/99\n",
      "training Loss: 0.0009 Acc: 85.3610\n",
      "validation Loss: 0.0010 Acc: 84.8095\n",
      "Epoch 7/99\n",
      "training Loss: 0.0009 Acc: 85.4354\n",
      "validation Loss: 0.0009 Acc: 84.9643\n",
      "Epoch 8/99\n",
      "training Loss: 0.0009 Acc: 85.3550\n",
      "validation Loss: 0.0010 Acc: 84.9762\n",
      "Epoch 9/99\n",
      "training Loss: 0.0009 Acc: 85.5425\n",
      "validation Loss: 0.0009 Acc: 85.4286\n",
      "Saving..\n",
      "Epoch 10/99\n",
      "training Loss: 0.0009 Acc: 85.4027\n",
      "validation Loss: 0.0010 Acc: 85.1190\n",
      "Epoch 11/99\n",
      "training Loss: 0.0009 Acc: 85.6735\n",
      "validation Loss: 0.0010 Acc: 85.2143\n",
      "Epoch 12/99\n",
      "training Loss: 0.0009 Acc: 85.7092\n",
      "validation Loss: 0.0010 Acc: 85.0714\n",
      "Epoch 13/99\n",
      "training Loss: 0.0009 Acc: 85.5872\n",
      "validation Loss: 0.0009 Acc: 85.3929\n",
      "Epoch 14/99\n",
      "training Loss: 0.0009 Acc: 85.6854\n",
      "validation Loss: 0.0009 Acc: 85.1071\n",
      "Epoch 15/99\n",
      "training Loss: 0.0009 Acc: 85.7300\n",
      "validation Loss: 0.0009 Acc: 85.2143\n",
      "Epoch 16/99\n",
      "training Loss: 0.0009 Acc: 85.7151\n",
      "validation Loss: 0.0009 Acc: 85.5833\n",
      "Saving..\n",
      "Epoch 17/99\n",
      "training Loss: 0.0009 Acc: 85.7717\n",
      "validation Loss: 0.0009 Acc: 85.3095\n",
      "Epoch 18/99\n",
      "training Loss: 0.0009 Acc: 85.8163\n",
      "validation Loss: 0.0010 Acc: 85.3214\n",
      "Epoch 19/99\n",
      "training Loss: 0.0009 Acc: 85.9830\n",
      "validation Loss: 0.0009 Acc: 85.4643\n",
      "Epoch 20/99\n",
      "training Loss: 0.0009 Acc: 85.9086\n",
      "validation Loss: 0.0009 Acc: 85.4405\n",
      "Epoch 21/99\n",
      "training Loss: 0.0009 Acc: 86.1258\n",
      "validation Loss: 0.0009 Acc: 85.4881\n",
      "Epoch 22/99\n",
      "training Loss: 0.0009 Acc: 86.1764\n",
      "validation Loss: 0.0009 Acc: 85.5833\n",
      "Epoch 23/99\n",
      "training Loss: 0.0009 Acc: 86.2032\n",
      "validation Loss: 0.0009 Acc: 85.4405\n",
      "Epoch 24/99\n",
      "training Loss: 0.0009 Acc: 86.1496\n",
      "validation Loss: 0.0009 Acc: 85.5357\n",
      "Epoch 25/99\n",
      "training Loss: 0.0009 Acc: 86.2092\n",
      "validation Loss: 0.0009 Acc: 85.6786\n",
      "Saving..\n",
      "Epoch 26/99\n",
      "training Loss: 0.0009 Acc: 86.1496\n",
      "validation Loss: 0.0009 Acc: 85.5595\n",
      "Epoch 27/99\n",
      "training Loss: 0.0009 Acc: 86.2330\n",
      "validation Loss: 0.0009 Acc: 85.4286\n",
      "Epoch 28/99\n",
      "training Loss: 0.0009 Acc: 86.2746\n",
      "validation Loss: 0.0009 Acc: 85.3095\n",
      "Epoch 29/99\n",
      "training Loss: 0.0009 Acc: 86.2538\n",
      "validation Loss: 0.0009 Acc: 85.5833\n",
      "Epoch 30/99\n",
      "training Loss: 0.0009 Acc: 86.3461\n",
      "validation Loss: 0.0009 Acc: 85.6071\n",
      "Epoch 31/99\n",
      "training Loss: 0.0009 Acc: 86.3014\n",
      "validation Loss: 0.0009 Acc: 85.4881\n",
      "Epoch 32/99\n",
      "training Loss: 0.0009 Acc: 86.3103\n",
      "validation Loss: 0.0009 Acc: 85.3214\n",
      "Epoch 33/99\n",
      "training Loss: 0.0009 Acc: 86.2955\n",
      "validation Loss: 0.0009 Acc: 85.5000\n",
      "Epoch 34/99\n",
      "training Loss: 0.0009 Acc: 86.2865\n",
      "validation Loss: 0.0009 Acc: 85.5119\n",
      "Epoch 35/99\n",
      "training Loss: 0.0009 Acc: 86.3282\n",
      "validation Loss: 0.0009 Acc: 85.5476\n",
      "Early stopped.\n",
      "Best val acc: 85.678571\n",
      "----------\n",
      "Average best_acc across k-fold: 86.003038959\n",
      "New configuration: {'hidden_layers': 2, 'dropout_g': 0.7769987508551582, 'initial_nodes': 328, 'dropout': 0.01, 'gru_layers': 1, 'batch_size': 32, 'gru_size': 199, 'learning_rate': 3.079162391975715e-05}\n",
      "Epoch 0/99\n",
      "training Loss: 0.0144 Acc: 77.9643\n",
      "validation Loss: 0.0118 Acc: 83.1588\n",
      "Saving..\n",
      "Epoch 1/99\n",
      "training Loss: 0.0113 Acc: 84.1994\n",
      "validation Loss: 0.0113 Acc: 83.7063\n",
      "Saving..\n",
      "Epoch 2/99\n",
      "training Loss: 0.0110 Acc: 84.5387\n",
      "validation Loss: 0.0111 Acc: 84.2537\n",
      "Saving..\n",
      "Epoch 3/99\n",
      "training Loss: 0.0109 Acc: 84.5893\n",
      "validation Loss: 0.0110 Acc: 84.3966\n",
      "Saving..\n",
      "Epoch 4/99\n",
      "training Loss: 0.0108 Acc: 84.7917\n",
      "validation Loss: 0.0110 Acc: 84.2299\n",
      "Epoch 5/99\n",
      "training Loss: 0.0107 Acc: 84.8631\n",
      "validation Loss: 0.0108 Acc: 84.7655\n",
      "Saving..\n",
      "Epoch 6/99\n",
      "training Loss: 0.0107 Acc: 84.9821\n",
      "validation Loss: 0.0108 Acc: 84.4799\n",
      "Epoch 7/99\n",
      "training Loss: 0.0106 Acc: 84.9732\n",
      "validation Loss: 0.0107 Acc: 84.8131\n",
      "Saving..\n",
      "Epoch 8/99\n",
      "training Loss: 0.0106 Acc: 85.1786\n",
      "validation Loss: 0.0107 Acc: 84.7179\n",
      "Epoch 9/99\n",
      "training Loss: 0.0105 Acc: 85.2083\n",
      "validation Loss: 0.0107 Acc: 85.0036\n",
      "Saving..\n",
      "Epoch 10/99\n",
      "training Loss: 0.0105 Acc: 85.2768\n",
      "validation Loss: 0.0106 Acc: 84.8965\n",
      "Epoch 11/99\n",
      "training Loss: 0.0105 Acc: 85.2470\n",
      "validation Loss: 0.0106 Acc: 85.0869\n",
      "Saving..\n",
      "Epoch 12/99\n",
      "training Loss: 0.0105 Acc: 85.2321\n",
      "validation Loss: 0.0107 Acc: 85.1226\n",
      "Saving..\n",
      "Epoch 13/99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Loss: 0.0104 Acc: 85.4315\n",
      "validation Loss: 0.0105 Acc: 84.9917\n",
      "Epoch 14/99\n",
      "training Loss: 0.0104 Acc: 85.4345\n",
      "validation Loss: 0.0105 Acc: 85.0036\n",
      "Epoch 15/99\n",
      "training Loss: 0.0104 Acc: 85.4286\n",
      "validation Loss: 0.0105 Acc: 85.1940\n",
      "Saving..\n",
      "Epoch 16/99\n",
      "training Loss: 0.0103 Acc: 85.5298\n",
      "validation Loss: 0.0105 Acc: 85.0155\n",
      "Epoch 17/99\n",
      "training Loss: 0.0103 Acc: 85.5268\n",
      "validation Loss: 0.0105 Acc: 85.2297\n",
      "Saving..\n",
      "Epoch 18/99\n",
      "training Loss: 0.0103 Acc: 85.6101\n",
      "validation Loss: 0.0104 Acc: 85.3130\n",
      "Saving..\n",
      "Epoch 19/99\n",
      "training Loss: 0.0103 Acc: 85.4940\n",
      "validation Loss: 0.0104 Acc: 85.1583\n",
      "Epoch 20/99\n",
      "training Loss: 0.0102 Acc: 85.5863\n",
      "validation Loss: 0.0104 Acc: 85.3606\n",
      "Saving..\n",
      "Epoch 21/99\n",
      "training Loss: 0.0102 Acc: 85.6339\n",
      "validation Loss: 0.0104 Acc: 85.3963\n",
      "Saving..\n",
      "Epoch 22/99\n",
      "training Loss: 0.0102 Acc: 85.8125\n",
      "validation Loss: 0.0103 Acc: 85.4082\n",
      "Saving..\n",
      "Epoch 23/99\n",
      "training Loss: 0.0102 Acc: 85.6905\n",
      "validation Loss: 0.0103 Acc: 85.3725\n",
      "Epoch 24/99\n",
      "training Loss: 0.0102 Acc: 85.7679\n",
      "validation Loss: 0.0103 Acc: 85.3368\n",
      "Epoch 25/99\n",
      "training Loss: 0.0101 Acc: 85.8214\n",
      "validation Loss: 0.0103 Acc: 85.5868\n",
      "Saving..\n",
      "Epoch 26/99\n",
      "training Loss: 0.0101 Acc: 85.7649\n",
      "validation Loss: 0.0103 Acc: 85.4677\n",
      "Epoch 27/99\n",
      "training Loss: 0.0101 Acc: 85.8125\n",
      "validation Loss: 0.0102 Acc: 85.4439\n",
      "Epoch 28/99\n",
      "training Loss: 0.0101 Acc: 85.8839\n",
      "validation Loss: 0.0103 Acc: 85.5273\n",
      "Epoch 29/99\n",
      "training Loss: 0.0101 Acc: 85.9196\n",
      "validation Loss: 0.0102 Acc: 85.5868\n",
      "Epoch 30/99\n",
      "training Loss: 0.0100 Acc: 85.9405\n",
      "validation Loss: 0.0103 Acc: 85.4915\n",
      "Epoch 31/99\n",
      "training Loss: 0.0100 Acc: 85.8929\n",
      "validation Loss: 0.0102 Acc: 85.3487\n",
      "Epoch 32/99\n",
      "training Loss: 0.0100 Acc: 85.8988\n",
      "validation Loss: 0.0102 Acc: 85.4439\n",
      "Epoch 33/99\n",
      "training Loss: 0.0100 Acc: 85.9494\n",
      "validation Loss: 0.0102 Acc: 85.5749\n",
      "Epoch 34/99\n",
      "training Loss: 0.0100 Acc: 86.0536\n",
      "validation Loss: 0.0102 Acc: 85.5868\n",
      "Epoch 35/99\n",
      "training Loss: 0.0100 Acc: 85.9881\n",
      "validation Loss: 0.0102 Acc: 85.4558\n",
      "Early stopped.\n",
      "Best val acc: 85.586765\n",
      "----------\n",
      "Epoch 0/99\n",
      "training Loss: 0.0144 Acc: 77.9924\n",
      "validation Loss: 0.0114 Acc: 84.0714\n",
      "Saving..\n",
      "Epoch 1/99\n",
      "training Loss: 0.0114 Acc: 84.1021\n",
      "validation Loss: 0.0110 Acc: 84.2857\n",
      "Saving..\n",
      "Epoch 2/99\n",
      "training Loss: 0.0111 Acc: 84.2837\n",
      "validation Loss: 0.0108 Acc: 84.7619\n",
      "Saving..\n",
      "Epoch 3/99\n",
      "training Loss: 0.0109 Acc: 84.5069\n",
      "validation Loss: 0.0107 Acc: 84.9167\n",
      "Saving..\n",
      "Epoch 4/99\n",
      "training Loss: 0.0108 Acc: 84.7390\n",
      "validation Loss: 0.0107 Acc: 84.8214\n",
      "Epoch 5/99\n",
      "training Loss: 0.0108 Acc: 84.7688\n",
      "validation Loss: 0.0106 Acc: 85.0833\n",
      "Saving..\n",
      "Epoch 6/99\n",
      "training Loss: 0.0107 Acc: 84.8848\n",
      "validation Loss: 0.0106 Acc: 84.8929\n",
      "Epoch 7/99\n",
      "training Loss: 0.0107 Acc: 85.0366\n",
      "validation Loss: 0.0105 Acc: 85.1548\n",
      "Saving..\n",
      "Epoch 8/99\n",
      "training Loss: 0.0106 Acc: 84.9949\n",
      "validation Loss: 0.0105 Acc: 85.1786\n",
      "Saving..\n",
      "Epoch 9/99\n",
      "training Loss: 0.0106 Acc: 85.1140\n",
      "validation Loss: 0.0105 Acc: 85.0357\n",
      "Epoch 10/99\n",
      "training Loss: 0.0106 Acc: 85.0842\n",
      "validation Loss: 0.0104 Acc: 85.2143\n",
      "Saving..\n",
      "Epoch 11/99\n",
      "training Loss: 0.0105 Acc: 85.2598\n",
      "validation Loss: 0.0104 Acc: 85.1905\n",
      "Epoch 12/99\n",
      "training Loss: 0.0105 Acc: 85.2152\n",
      "validation Loss: 0.0104 Acc: 85.3571\n",
      "Saving..\n",
      "Epoch 13/99\n",
      "training Loss: 0.0105 Acc: 85.2419\n",
      "validation Loss: 0.0104 Acc: 85.3333\n",
      "Epoch 14/99\n",
      "training Loss: 0.0105 Acc: 85.3967\n",
      "validation Loss: 0.0104 Acc: 85.2619\n",
      "Epoch 15/99\n",
      "training Loss: 0.0104 Acc: 85.3937\n",
      "validation Loss: 0.0103 Acc: 85.5833\n",
      "Saving..\n",
      "Epoch 16/99\n",
      "training Loss: 0.0104 Acc: 85.4235\n",
      "validation Loss: 0.0103 Acc: 85.4405\n",
      "Epoch 17/99\n",
      "training Loss: 0.0104 Acc: 85.4027\n",
      "validation Loss: 0.0103 Acc: 85.5119\n",
      "Epoch 18/99\n",
      "training Loss: 0.0103 Acc: 85.5247\n",
      "validation Loss: 0.0103 Acc: 85.4881\n",
      "Epoch 19/99\n",
      "training Loss: 0.0103 Acc: 85.6259\n",
      "validation Loss: 0.0103 Acc: 85.5119\n",
      "Epoch 20/99\n",
      "training Loss: 0.0103 Acc: 85.4592\n",
      "validation Loss: 0.0102 Acc: 85.6429\n",
      "Saving..\n",
      "Epoch 21/99\n",
      "training Loss: 0.0103 Acc: 85.6140\n",
      "validation Loss: 0.0102 Acc: 85.6667\n",
      "Saving..\n",
      "Epoch 22/99\n",
      "training Loss: 0.0102 Acc: 85.5961\n",
      "validation Loss: 0.0102 Acc: 85.6548\n",
      "Epoch 23/99\n",
      "training Loss: 0.0102 Acc: 85.7122\n",
      "validation Loss: 0.0102 Acc: 85.8571\n",
      "Saving..\n",
      "Epoch 24/99\n",
      "training Loss: 0.0102 Acc: 85.6169\n",
      "validation Loss: 0.0102 Acc: 85.8095\n",
      "Epoch 25/99\n",
      "training Loss: 0.0102 Acc: 85.6140\n",
      "validation Loss: 0.0101 Acc: 85.7976\n",
      "Epoch 26/99\n",
      "training Loss: 0.0102 Acc: 85.8282\n",
      "validation Loss: 0.0101 Acc: 85.9405\n",
      "Saving..\n",
      "Epoch 27/99\n",
      "training Loss: 0.0102 Acc: 85.7151\n",
      "validation Loss: 0.0101 Acc: 85.9881\n",
      "Saving..\n",
      "Epoch 28/99\n",
      "training Loss: 0.0101 Acc: 85.7866\n",
      "validation Loss: 0.0101 Acc: 85.9881\n",
      "Epoch 29/99\n",
      "training Loss: 0.0101 Acc: 85.7628\n",
      "validation Loss: 0.0101 Acc: 85.9167\n",
      "Epoch 30/99\n",
      "training Loss: 0.0101 Acc: 85.8669\n",
      "validation Loss: 0.0101 Acc: 86.0952\n",
      "Saving..\n",
      "Epoch 31/99\n",
      "training Loss: 0.0101 Acc: 85.8431\n",
      "validation Loss: 0.0101 Acc: 86.0595\n",
      "Epoch 32/99\n",
      "training Loss: 0.0101 Acc: 85.7806\n",
      "validation Loss: 0.0102 Acc: 85.9167\n",
      "Epoch 33/99\n",
      "training Loss: 0.0100 Acc: 85.8967\n",
      "validation Loss: 0.0101 Acc: 86.1310\n",
      "Saving..\n",
      "Epoch 34/99\n",
      "training Loss: 0.0100 Acc: 85.9294\n",
      "validation Loss: 0.0101 Acc: 86.1905\n",
      "Saving..\n",
      "Epoch 35/99\n",
      "training Loss: 0.0100 Acc: 85.8758\n",
      "validation Loss: 0.0100 Acc: 86.2619\n",
      "Saving..\n",
      "Epoch 36/99\n",
      "training Loss: 0.0100 Acc: 85.9026\n",
      "validation Loss: 0.0101 Acc: 85.9048\n",
      "Epoch 37/99\n",
      "training Loss: 0.0100 Acc: 85.8580\n",
      "validation Loss: 0.0100 Acc: 85.9643\n",
      "Epoch 38/99\n",
      "training Loss: 0.0101 Acc: 85.9413\n",
      "validation Loss: 0.0100 Acc: 86.0595\n",
      "Epoch 39/99\n",
      "training Loss: 0.0100 Acc: 85.9711\n",
      "validation Loss: 0.0100 Acc: 86.0238\n",
      "Epoch 40/99\n",
      "training Loss: 0.0100 Acc: 85.9740\n",
      "validation Loss: 0.0100 Acc: 86.3452\n",
      "Saving..\n",
      "Epoch 41/99\n",
      "training Loss: 0.0100 Acc: 85.9949\n",
      "validation Loss: 0.0101 Acc: 86.1190\n",
      "Epoch 42/99\n",
      "training Loss: 0.0100 Acc: 85.9324\n",
      "validation Loss: 0.0100 Acc: 86.2738\n",
      "Epoch 43/99\n",
      "training Loss: 0.0100 Acc: 85.9175\n",
      "validation Loss: 0.0100 Acc: 86.3690\n",
      "Saving..\n",
      "Epoch 44/99\n",
      "training Loss: 0.0100 Acc: 86.0484\n",
      "validation Loss: 0.0100 Acc: 86.3095\n",
      "Epoch 45/99\n",
      "training Loss: 0.0100 Acc: 86.1109\n",
      "validation Loss: 0.0100 Acc: 86.4286\n",
      "Saving..\n",
      "Epoch 46/99\n",
      "training Loss: 0.0099 Acc: 86.1109\n",
      "validation Loss: 0.0100 Acc: 86.2738\n",
      "Epoch 47/99\n",
      "training Loss: 0.0099 Acc: 86.0127\n",
      "validation Loss: 0.0100 Acc: 86.2500\n",
      "Epoch 48/99\n",
      "training Loss: 0.0099 Acc: 86.0842\n",
      "validation Loss: 0.0100 Acc: 86.4048\n",
      "Epoch 49/99\n",
      "training Loss: 0.0099 Acc: 86.0425\n",
      "validation Loss: 0.0100 Acc: 86.3929\n",
      "Epoch 50/99\n",
      "training Loss: 0.0099 Acc: 86.0365\n",
      "validation Loss: 0.0100 Acc: 86.3571\n",
      "Epoch 51/99\n",
      "training Loss: 0.0099 Acc: 86.0782\n",
      "validation Loss: 0.0100 Acc: 86.3333\n",
      "Epoch 52/99\n",
      "training Loss: 0.0099 Acc: 86.1228\n",
      "validation Loss: 0.0100 Acc: 86.2500\n",
      "Epoch 53/99\n",
      "training Loss: 0.0099 Acc: 86.1705\n",
      "validation Loss: 0.0100 Acc: 86.3690\n",
      "Epoch 54/99\n",
      "training Loss: 0.0099 Acc: 86.1496\n",
      "validation Loss: 0.0100 Acc: 86.2738\n",
      "Epoch 55/99\n",
      "training Loss: 0.0098 Acc: 86.1228\n",
      "validation Loss: 0.0100 Acc: 86.3929\n",
      "Early stopped.\n",
      "Best val acc: 86.428571\n",
      "----------\n",
      "Epoch 0/99\n",
      "training Loss: 0.0148 Acc: 79.7839\n",
      "validation Loss: 0.0117 Acc: 83.6667\n",
      "Saving..\n",
      "Epoch 1/99\n",
      "training Loss: 0.0115 Acc: 83.8105\n",
      "validation Loss: 0.0111 Acc: 84.8571\n",
      "Saving..\n",
      "Epoch 2/99\n",
      "training Loss: 0.0111 Acc: 84.1646\n",
      "validation Loss: 0.0109 Acc: 85.0595\n",
      "Saving..\n",
      "Epoch 3/99\n",
      "training Loss: 0.0110 Acc: 84.4384\n",
      "validation Loss: 0.0109 Acc: 85.1667\n",
      "Saving..\n",
      "Epoch 4/99\n",
      "training Loss: 0.0109 Acc: 84.5247\n",
      "validation Loss: 0.0107 Acc: 85.2024\n",
      "Saving..\n",
      "Epoch 5/99\n",
      "training Loss: 0.0108 Acc: 84.6110\n",
      "validation Loss: 0.0107 Acc: 85.4048\n",
      "Saving..\n",
      "Epoch 6/99\n",
      "training Loss: 0.0108 Acc: 84.7211\n",
      "validation Loss: 0.0108 Acc: 85.5714\n",
      "Saving..\n",
      "Epoch 7/99\n",
      "training Loss: 0.0107 Acc: 84.7450\n",
      "validation Loss: 0.0106 Acc: 85.4405\n",
      "Epoch 8/99\n",
      "training Loss: 0.0107 Acc: 84.7926\n",
      "validation Loss: 0.0106 Acc: 85.4405\n",
      "Epoch 9/99\n",
      "training Loss: 0.0106 Acc: 84.9027\n",
      "validation Loss: 0.0105 Acc: 85.7262\n",
      "Saving..\n",
      "Epoch 10/99\n",
      "training Loss: 0.0106 Acc: 84.8997\n",
      "validation Loss: 0.0105 Acc: 85.7619\n",
      "Saving..\n",
      "Epoch 11/99\n",
      "training Loss: 0.0106 Acc: 85.1110\n",
      "validation Loss: 0.0105 Acc: 85.4762\n",
      "Epoch 12/99\n",
      "training Loss: 0.0106 Acc: 85.0515\n",
      "validation Loss: 0.0106 Acc: 85.6310\n",
      "Epoch 13/99\n",
      "training Loss: 0.0105 Acc: 85.1051\n",
      "validation Loss: 0.0105 Acc: 85.5595\n",
      "Epoch 14/99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Loss: 0.0105 Acc: 85.1824\n",
      "validation Loss: 0.0104 Acc: 85.6905\n",
      "Epoch 15/99\n",
      "training Loss: 0.0105 Acc: 85.3253\n",
      "validation Loss: 0.0104 Acc: 85.8690\n",
      "Saving..\n",
      "Epoch 16/99\n",
      "training Loss: 0.0104 Acc: 85.2271\n",
      "validation Loss: 0.0104 Acc: 85.7381\n",
      "Epoch 17/99\n",
      "training Loss: 0.0104 Acc: 85.1884\n",
      "validation Loss: 0.0104 Acc: 85.7619\n",
      "Epoch 18/99\n",
      "training Loss: 0.0104 Acc: 85.3669\n",
      "validation Loss: 0.0103 Acc: 85.9048\n",
      "Saving..\n",
      "Epoch 19/99\n",
      "training Loss: 0.0104 Acc: 85.3074\n",
      "validation Loss: 0.0103 Acc: 85.9524\n",
      "Saving..\n",
      "Epoch 20/99\n",
      "training Loss: 0.0103 Acc: 85.4979\n",
      "validation Loss: 0.0102 Acc: 86.0833\n",
      "Saving..\n",
      "Epoch 21/99\n",
      "training Loss: 0.0103 Acc: 85.4324\n",
      "validation Loss: 0.0103 Acc: 85.7738\n",
      "Epoch 22/99\n",
      "training Loss: 0.0103 Acc: 85.5276\n",
      "validation Loss: 0.0102 Acc: 86.0714\n",
      "Epoch 23/99\n",
      "training Loss: 0.0102 Acc: 85.5515\n",
      "validation Loss: 0.0103 Acc: 85.8929\n",
      "Epoch 24/99\n",
      "training Loss: 0.0103 Acc: 85.5663\n",
      "validation Loss: 0.0103 Acc: 86.0476\n",
      "Epoch 25/99\n",
      "training Loss: 0.0102 Acc: 85.6020\n",
      "validation Loss: 0.0102 Acc: 86.0000\n",
      "Epoch 26/99\n",
      "training Loss: 0.0102 Acc: 85.5574\n",
      "validation Loss: 0.0102 Acc: 86.1429\n",
      "Saving..\n",
      "Epoch 27/99\n",
      "training Loss: 0.0102 Acc: 85.6794\n",
      "validation Loss: 0.0102 Acc: 86.1190\n",
      "Epoch 28/99\n",
      "training Loss: 0.0102 Acc: 85.6318\n",
      "validation Loss: 0.0102 Acc: 86.1905\n",
      "Saving..\n",
      "Epoch 29/99\n",
      "training Loss: 0.0101 Acc: 85.7717\n",
      "validation Loss: 0.0102 Acc: 86.0357\n",
      "Epoch 30/99\n",
      "training Loss: 0.0101 Acc: 85.7895\n",
      "validation Loss: 0.0101 Acc: 86.2381\n",
      "Saving..\n",
      "Epoch 31/99\n",
      "training Loss: 0.0101 Acc: 85.8372\n",
      "validation Loss: 0.0101 Acc: 86.2619\n",
      "Saving..\n",
      "Epoch 32/99\n",
      "training Loss: 0.0101 Acc: 85.8074\n",
      "validation Loss: 0.0101 Acc: 85.9762\n",
      "Epoch 33/99\n",
      "training Loss: 0.0101 Acc: 85.8252\n",
      "validation Loss: 0.0102 Acc: 86.1667\n",
      "Epoch 34/99\n",
      "training Loss: 0.0101 Acc: 85.8967\n",
      "validation Loss: 0.0101 Acc: 86.1905\n",
      "Epoch 35/99\n",
      "training Loss: 0.0101 Acc: 85.8372\n",
      "validation Loss: 0.0101 Acc: 86.1548\n",
      "Epoch 36/99\n",
      "training Loss: 0.0101 Acc: 85.8461\n",
      "validation Loss: 0.0100 Acc: 86.2857\n",
      "Saving..\n",
      "Epoch 37/99\n",
      "training Loss: 0.0100 Acc: 85.9116\n",
      "validation Loss: 0.0102 Acc: 86.0952\n",
      "Epoch 38/99\n",
      "training Loss: 0.0100 Acc: 85.8491\n",
      "validation Loss: 0.0100 Acc: 86.3214\n",
      "Saving..\n",
      "Epoch 39/99\n",
      "training Loss: 0.0100 Acc: 85.8877\n",
      "validation Loss: 0.0100 Acc: 86.2143\n",
      "Epoch 40/99\n",
      "training Loss: 0.0100 Acc: 85.8907\n",
      "validation Loss: 0.0100 Acc: 86.1190\n",
      "Epoch 41/99\n",
      "training Loss: 0.0100 Acc: 85.7866\n",
      "validation Loss: 0.0101 Acc: 86.0952\n",
      "Epoch 42/99\n",
      "training Loss: 0.0100 Acc: 85.9770\n",
      "validation Loss: 0.0100 Acc: 86.3810\n",
      "Saving..\n",
      "Epoch 43/99\n",
      "training Loss: 0.0100 Acc: 85.9264\n",
      "validation Loss: 0.0100 Acc: 86.0714\n",
      "Epoch 44/99\n",
      "training Loss: 0.0100 Acc: 86.0008\n",
      "validation Loss: 0.0100 Acc: 86.1071\n",
      "Epoch 45/99\n",
      "training Loss: 0.0100 Acc: 85.8996\n",
      "validation Loss: 0.0101 Acc: 86.0595\n",
      "Epoch 46/99\n",
      "training Loss: 0.0100 Acc: 85.9473\n",
      "validation Loss: 0.0100 Acc: 86.1429\n",
      "Epoch 47/99\n",
      "training Loss: 0.0099 Acc: 86.0246\n",
      "validation Loss: 0.0100 Acc: 86.3333\n",
      "Epoch 48/99\n",
      "training Loss: 0.0099 Acc: 85.8758\n",
      "validation Loss: 0.0100 Acc: 86.3571\n",
      "Epoch 49/99\n",
      "training Loss: 0.0099 Acc: 85.9919\n",
      "validation Loss: 0.0101 Acc: 86.1548\n",
      "Epoch 50/99\n",
      "training Loss: 0.0099 Acc: 85.9294\n",
      "validation Loss: 0.0100 Acc: 86.2262\n",
      "Epoch 51/99\n",
      "training Loss: 0.0099 Acc: 86.1348\n",
      "validation Loss: 0.0100 Acc: 86.2500\n",
      "Epoch 52/99\n",
      "training Loss: 0.0099 Acc: 85.9979\n",
      "validation Loss: 0.0100 Acc: 86.2143\n",
      "Early stopped.\n",
      "Best val acc: 86.380952\n",
      "----------\n",
      "Epoch 0/99\n",
      "training Loss: 0.0144 Acc: 79.5697\n",
      "validation Loss: 0.0118 Acc: 83.2976\n",
      "Saving..\n",
      "Epoch 1/99\n",
      "training Loss: 0.0112 Acc: 84.1587\n",
      "validation Loss: 0.0114 Acc: 84.0238\n",
      "Saving..\n",
      "Epoch 2/99\n",
      "training Loss: 0.0109 Acc: 84.4979\n",
      "validation Loss: 0.0112 Acc: 84.3452\n",
      "Saving..\n",
      "Epoch 3/99\n",
      "training Loss: 0.0108 Acc: 84.7152\n",
      "validation Loss: 0.0111 Acc: 84.4405\n",
      "Saving..\n",
      "Epoch 4/99\n",
      "training Loss: 0.0107 Acc: 84.7985\n",
      "validation Loss: 0.0111 Acc: 84.2976\n",
      "Epoch 5/99\n",
      "training Loss: 0.0107 Acc: 84.9473\n",
      "validation Loss: 0.0110 Acc: 84.4048\n",
      "Epoch 6/99\n",
      "training Loss: 0.0106 Acc: 84.9860\n",
      "validation Loss: 0.0110 Acc: 84.5595\n",
      "Saving..\n",
      "Epoch 7/99\n",
      "training Loss: 0.0106 Acc: 85.1259\n",
      "validation Loss: 0.0110 Acc: 84.5476\n",
      "Epoch 8/99\n",
      "training Loss: 0.0105 Acc: 85.2925\n",
      "validation Loss: 0.0109 Acc: 84.5000\n",
      "Epoch 9/99\n",
      "training Loss: 0.0105 Acc: 85.3253\n",
      "validation Loss: 0.0109 Acc: 84.5476\n",
      "Epoch 10/99\n",
      "training Loss: 0.0105 Acc: 85.4027\n",
      "validation Loss: 0.0109 Acc: 84.7024\n",
      "Saving..\n",
      "Epoch 11/99\n",
      "training Loss: 0.0104 Acc: 85.3788\n",
      "validation Loss: 0.0109 Acc: 84.6071\n",
      "Epoch 12/99\n",
      "training Loss: 0.0104 Acc: 85.4592\n",
      "validation Loss: 0.0108 Acc: 84.7381\n",
      "Saving..\n",
      "Epoch 13/99\n",
      "training Loss: 0.0104 Acc: 85.4919\n",
      "validation Loss: 0.0107 Acc: 84.8452\n",
      "Saving..\n",
      "Epoch 14/99\n",
      "training Loss: 0.0103 Acc: 85.5961\n",
      "validation Loss: 0.0107 Acc: 84.6429\n",
      "Epoch 15/99\n",
      "training Loss: 0.0103 Acc: 85.6913\n",
      "validation Loss: 0.0107 Acc: 84.9167\n",
      "Saving..\n",
      "Epoch 16/99\n",
      "training Loss: 0.0103 Acc: 85.6140\n",
      "validation Loss: 0.0107 Acc: 84.8810\n",
      "Epoch 17/99\n",
      "training Loss: 0.0103 Acc: 85.7895\n",
      "validation Loss: 0.0107 Acc: 85.0476\n",
      "Saving..\n",
      "Epoch 18/99\n",
      "training Loss: 0.0102 Acc: 85.7568\n",
      "validation Loss: 0.0107 Acc: 84.9524\n",
      "Epoch 19/99\n",
      "training Loss: 0.0102 Acc: 85.7419\n",
      "validation Loss: 0.0107 Acc: 84.8095\n",
      "Epoch 20/99\n",
      "training Loss: 0.0102 Acc: 85.8223\n",
      "validation Loss: 0.0106 Acc: 85.0952\n",
      "Saving..\n",
      "Epoch 21/99\n",
      "training Loss: 0.0101 Acc: 85.8342\n",
      "validation Loss: 0.0106 Acc: 85.1429\n",
      "Saving..\n",
      "Epoch 22/99\n",
      "training Loss: 0.0101 Acc: 85.8996\n",
      "validation Loss: 0.0106 Acc: 85.1905\n",
      "Saving..\n",
      "Epoch 23/99\n",
      "training Loss: 0.0101 Acc: 85.9830\n",
      "validation Loss: 0.0106 Acc: 84.8810\n",
      "Epoch 24/99\n",
      "training Loss: 0.0101 Acc: 85.9592\n",
      "validation Loss: 0.0105 Acc: 85.2143\n",
      "Saving..\n",
      "Epoch 25/99\n",
      "training Loss: 0.0100 Acc: 86.0008\n",
      "validation Loss: 0.0105 Acc: 85.1548\n",
      "Epoch 26/99\n",
      "training Loss: 0.0100 Acc: 85.9532\n",
      "validation Loss: 0.0105 Acc: 85.1786\n",
      "Epoch 27/99\n",
      "training Loss: 0.0100 Acc: 86.0842\n",
      "validation Loss: 0.0106 Acc: 85.0714\n",
      "Epoch 28/99\n",
      "training Loss: 0.0100 Acc: 86.0842\n",
      "validation Loss: 0.0105 Acc: 85.0833\n",
      "Epoch 29/99\n",
      "training Loss: 0.0100 Acc: 86.1764\n",
      "validation Loss: 0.0105 Acc: 85.2143\n",
      "Epoch 30/99\n",
      "training Loss: 0.0100 Acc: 86.1675\n",
      "validation Loss: 0.0105 Acc: 85.0357\n",
      "Epoch 31/99\n",
      "training Loss: 0.0100 Acc: 86.1050\n",
      "validation Loss: 0.0105 Acc: 85.4405\n",
      "Saving..\n",
      "Epoch 32/99\n",
      "training Loss: 0.0099 Acc: 86.1526\n",
      "validation Loss: 0.0105 Acc: 85.1548\n",
      "Epoch 33/99\n",
      "training Loss: 0.0099 Acc: 86.1199\n",
      "validation Loss: 0.0104 Acc: 85.2500\n",
      "Epoch 34/99\n",
      "training Loss: 0.0099 Acc: 86.1853\n",
      "validation Loss: 0.0104 Acc: 85.3095\n",
      "Epoch 35/99\n",
      "training Loss: 0.0099 Acc: 86.2300\n",
      "validation Loss: 0.0104 Acc: 85.1429\n",
      "Epoch 36/99\n",
      "training Loss: 0.0099 Acc: 86.2478\n",
      "validation Loss: 0.0104 Acc: 85.3810\n",
      "Epoch 37/99\n",
      "training Loss: 0.0099 Acc: 86.1526\n",
      "validation Loss: 0.0104 Acc: 85.0833\n",
      "Epoch 38/99\n",
      "training Loss: 0.0099 Acc: 86.2895\n",
      "validation Loss: 0.0104 Acc: 85.0119\n",
      "Epoch 39/99\n",
      "training Loss: 0.0098 Acc: 86.2657\n",
      "validation Loss: 0.0104 Acc: 85.2381\n",
      "Epoch 40/99\n",
      "training Loss: 0.0099 Acc: 86.2955\n",
      "validation Loss: 0.0104 Acc: 85.3452\n",
      "Epoch 41/99\n",
      "training Loss: 0.0099 Acc: 86.2151\n",
      "validation Loss: 0.0104 Acc: 85.3929\n",
      "Early stopped.\n",
      "Best val acc: 85.440476\n",
      "----------\n",
      "Epoch 0/99\n",
      "training Loss: 0.0145 Acc: 77.8466\n",
      "validation Loss: 0.0115 Acc: 83.8571\n",
      "Saving..\n",
      "Epoch 1/99\n",
      "training Loss: 0.0113 Acc: 84.0754\n",
      "validation Loss: 0.0111 Acc: 84.0833\n",
      "Saving..\n",
      "Epoch 2/99\n",
      "training Loss: 0.0111 Acc: 84.3819\n",
      "validation Loss: 0.0109 Acc: 84.4643\n",
      "Saving..\n",
      "Epoch 3/99\n",
      "training Loss: 0.0109 Acc: 84.6200\n",
      "validation Loss: 0.0107 Acc: 84.8095\n",
      "Saving..\n",
      "Epoch 4/99\n",
      "training Loss: 0.0109 Acc: 84.6557\n",
      "validation Loss: 0.0106 Acc: 84.9405\n",
      "Saving..\n",
      "Epoch 5/99\n",
      "training Loss: 0.0108 Acc: 84.8104\n",
      "validation Loss: 0.0106 Acc: 84.9881\n",
      "Saving..\n",
      "Epoch 6/99\n",
      "training Loss: 0.0107 Acc: 84.8908\n",
      "validation Loss: 0.0106 Acc: 85.0238\n",
      "Saving..\n",
      "Epoch 7/99\n",
      "training Loss: 0.0107 Acc: 84.9057\n",
      "validation Loss: 0.0105 Acc: 85.1310\n",
      "Saving..\n",
      "Epoch 8/99\n",
      "training Loss: 0.0107 Acc: 85.0128\n",
      "validation Loss: 0.0105 Acc: 85.0595\n",
      "Epoch 9/99\n",
      "training Loss: 0.0106 Acc: 85.0931\n",
      "validation Loss: 0.0104 Acc: 85.2500\n",
      "Saving..\n",
      "Epoch 10/99\n",
      "training Loss: 0.0106 Acc: 85.1140\n",
      "validation Loss: 0.0104 Acc: 85.2976\n",
      "Saving..\n",
      "Epoch 11/99\n",
      "training Loss: 0.0106 Acc: 85.1467\n",
      "validation Loss: 0.0104 Acc: 85.2619\n",
      "Epoch 12/99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Loss: 0.0105 Acc: 85.2122\n",
      "validation Loss: 0.0103 Acc: 85.4048\n",
      "Saving..\n",
      "Epoch 13/99\n",
      "training Loss: 0.0105 Acc: 85.2985\n",
      "validation Loss: 0.0104 Acc: 85.0595\n",
      "Epoch 14/99\n",
      "training Loss: 0.0105 Acc: 85.3521\n",
      "validation Loss: 0.0103 Acc: 85.6190\n",
      "Saving..\n",
      "Epoch 15/99\n",
      "training Loss: 0.0104 Acc: 85.4592\n",
      "validation Loss: 0.0103 Acc: 85.5000\n",
      "Epoch 16/99\n",
      "training Loss: 0.0104 Acc: 85.4205\n",
      "validation Loss: 0.0102 Acc: 85.5714\n",
      "Epoch 17/99\n",
      "training Loss: 0.0104 Acc: 85.4622\n",
      "validation Loss: 0.0102 Acc: 85.6548\n",
      "Saving..\n",
      "Epoch 18/99\n",
      "training Loss: 0.0103 Acc: 85.5187\n",
      "validation Loss: 0.0102 Acc: 85.5595\n",
      "Epoch 19/99\n",
      "training Loss: 0.0103 Acc: 85.6467\n",
      "validation Loss: 0.0102 Acc: 85.5714\n",
      "Epoch 20/99\n",
      "training Loss: 0.0103 Acc: 85.6735\n",
      "validation Loss: 0.0102 Acc: 85.4286\n",
      "Epoch 21/99\n",
      "training Loss: 0.0103 Acc: 85.6259\n",
      "validation Loss: 0.0101 Acc: 85.7500\n",
      "Saving..\n",
      "Epoch 22/99\n",
      "training Loss: 0.0103 Acc: 85.6764\n",
      "validation Loss: 0.0102 Acc: 85.5952\n",
      "Epoch 23/99\n",
      "training Loss: 0.0102 Acc: 85.6973\n",
      "validation Loss: 0.0101 Acc: 85.5952\n",
      "Epoch 24/99\n",
      "training Loss: 0.0102 Acc: 85.8461\n",
      "validation Loss: 0.0101 Acc: 85.7024\n",
      "Epoch 25/99\n",
      "training Loss: 0.0102 Acc: 85.8639\n",
      "validation Loss: 0.0101 Acc: 85.6786\n",
      "Epoch 26/99\n",
      "training Loss: 0.0102 Acc: 85.7776\n",
      "validation Loss: 0.0101 Acc: 85.8095\n",
      "Saving..\n",
      "Epoch 27/99\n",
      "training Loss: 0.0101 Acc: 85.8580\n",
      "validation Loss: 0.0101 Acc: 85.7262\n",
      "Epoch 28/99\n",
      "training Loss: 0.0101 Acc: 85.8729\n",
      "validation Loss: 0.0101 Acc: 85.7857\n",
      "Epoch 29/99\n",
      "training Loss: 0.0101 Acc: 85.8996\n",
      "validation Loss: 0.0101 Acc: 85.8929\n",
      "Saving..\n",
      "Epoch 30/99\n",
      "training Loss: 0.0101 Acc: 85.9770\n",
      "validation Loss: 0.0100 Acc: 85.7500\n",
      "Epoch 31/99\n",
      "training Loss: 0.0101 Acc: 85.9592\n",
      "validation Loss: 0.0100 Acc: 85.9881\n",
      "Saving..\n",
      "Epoch 32/99\n",
      "training Loss: 0.0101 Acc: 86.0038\n",
      "validation Loss: 0.0100 Acc: 85.8095\n",
      "Epoch 33/99\n",
      "training Loss: 0.0100 Acc: 85.9443\n",
      "validation Loss: 0.0100 Acc: 85.9405\n",
      "Epoch 34/99\n",
      "training Loss: 0.0100 Acc: 85.9413\n",
      "validation Loss: 0.0100 Acc: 85.8214\n",
      "Epoch 35/99\n",
      "training Loss: 0.0100 Acc: 85.9651\n",
      "validation Loss: 0.0100 Acc: 85.7381\n",
      "Epoch 36/99\n",
      "training Loss: 0.0100 Acc: 86.0604\n",
      "validation Loss: 0.0100 Acc: 85.8095\n",
      "Epoch 37/99\n",
      "training Loss: 0.0100 Acc: 86.0752\n",
      "validation Loss: 0.0100 Acc: 85.9286\n",
      "Epoch 38/99\n",
      "training Loss: 0.0100 Acc: 86.0663\n",
      "validation Loss: 0.0100 Acc: 85.9762\n",
      "Epoch 39/99\n",
      "training Loss: 0.0100 Acc: 86.0187\n",
      "validation Loss: 0.0100 Acc: 85.7738\n",
      "Epoch 40/99\n",
      "training Loss: 0.0100 Acc: 86.1496\n",
      "validation Loss: 0.0100 Acc: 85.8810\n",
      "Epoch 41/99\n",
      "training Loss: 0.0100 Acc: 86.0693\n",
      "validation Loss: 0.0100 Acc: 85.9405\n",
      "Early stopped.\n",
      "Best val acc: 85.988095\n",
      "----------\n",
      "Average best_acc across k-fold: 85.9649720588\n",
      "New configuration: {'hidden_layers': 2, 'dropout_g': 0.4950783201946942, 'initial_nodes': 500, 'dropout': 0.01, 'gru_layers': 3, 'batch_size': 160, 'gru_size': 500, 'learning_rate': 0.005242167592045912}\n",
      "Epoch 0/99\n",
      "training Loss: 0.0025 Acc: 82.0417\n",
      "validation Loss: 0.0023 Acc: 84.4680\n",
      "Saving..\n",
      "Epoch 1/99\n",
      "training Loss: 0.0022 Acc: 84.4226\n",
      "validation Loss: 0.0022 Acc: 84.7536\n",
      "Saving..\n",
      "Epoch 2/99\n",
      "training Loss: 0.0022 Acc: 84.3690\n",
      "validation Loss: 0.0022 Acc: 84.8726\n",
      "Saving..\n",
      "Epoch 3/99\n",
      "training Loss: 0.0022 Acc: 84.7798\n",
      "validation Loss: 0.0021 Acc: 85.8129\n",
      "Saving..\n",
      "Epoch 4/99\n",
      "training Loss: 0.0022 Acc: 84.7798\n",
      "validation Loss: 0.0021 Acc: 85.9319\n",
      "Saving..\n",
      "Epoch 5/99\n",
      "training Loss: 0.0022 Acc: 84.8869\n",
      "validation Loss: 0.0021 Acc: 85.7534\n",
      "Epoch 6/99\n",
      "training Loss: 0.0021 Acc: 85.0536\n",
      "validation Loss: 0.0021 Acc: 85.7891\n",
      "Epoch 7/99\n",
      "training Loss: 0.0021 Acc: 85.1548\n",
      "validation Loss: 0.0021 Acc: 85.7415\n",
      "Epoch 8/99\n",
      "training Loss: 0.0021 Acc: 85.1101\n",
      "validation Loss: 0.0021 Acc: 85.4558\n",
      "Epoch 9/99\n",
      "training Loss: 0.0021 Acc: 85.2560\n",
      "validation Loss: 0.0021 Acc: 85.9200\n",
      "Epoch 10/99\n",
      "training Loss: 0.0021 Acc: 85.3214\n",
      "validation Loss: 0.0021 Acc: 86.2414\n",
      "Saving..\n",
      "Epoch 11/99\n",
      "training Loss: 0.0021 Acc: 85.2768\n",
      "validation Loss: 0.0020 Acc: 86.0033\n",
      "Epoch 12/99\n",
      "training Loss: 0.0021 Acc: 85.2530\n",
      "validation Loss: 0.0021 Acc: 86.2057\n",
      "Epoch 13/99\n",
      "training Loss: 0.0021 Acc: 85.2798\n",
      "validation Loss: 0.0021 Acc: 86.2414\n",
      "Epoch 14/99\n",
      "training Loss: 0.0021 Acc: 85.3988\n",
      "validation Loss: 0.0021 Acc: 86.2414\n",
      "Epoch 15/99\n",
      "training Loss: 0.0021 Acc: 85.4821\n",
      "validation Loss: 0.0021 Acc: 85.8248\n",
      "Epoch 16/99\n",
      "training Loss: 0.0021 Acc: 85.2768\n",
      "validation Loss: 0.0021 Acc: 85.9557\n",
      "Epoch 17/99\n",
      "training Loss: 0.0021 Acc: 85.1429\n",
      "validation Loss: 0.0020 Acc: 85.9795\n",
      "Epoch 18/99\n",
      "training Loss: 0.0021 Acc: 85.2351\n",
      "validation Loss: 0.0021 Acc: 85.9676\n",
      "Epoch 19/99\n",
      "training Loss: 0.0021 Acc: 85.3899\n",
      "validation Loss: 0.0020 Acc: 86.1104\n",
      "Epoch 20/99\n",
      "training Loss: 0.0021 Acc: 85.5506\n",
      "validation Loss: 0.0020 Acc: 86.1224\n",
      "Early stopped.\n",
      "Best val acc: 86.241371\n",
      "----------\n",
      "Epoch 0/99\n",
      "training Loss: 0.0026 Acc: 82.5159\n",
      "validation Loss: 0.0024 Acc: 83.2857\n",
      "Saving..\n",
      "Epoch 1/99\n",
      "training Loss: 0.0022 Acc: 84.5218\n",
      "validation Loss: 0.0026 Acc: 83.6786\n",
      "Saving..\n",
      "Epoch 2/99\n",
      "training Loss: 0.0022 Acc: 84.8342\n",
      "validation Loss: 0.0022 Acc: 83.9405\n",
      "Saving..\n",
      "Epoch 3/99\n",
      "training Loss: 0.0021 Acc: 85.0664\n",
      "validation Loss: 0.0024 Acc: 83.4762\n",
      "Epoch 4/99\n",
      "training Loss: 0.0021 Acc: 85.3253\n",
      "validation Loss: 0.0022 Acc: 84.1786\n",
      "Saving..\n",
      "Epoch 5/99\n",
      "training Loss: 0.0021 Acc: 85.2568\n",
      "validation Loss: 0.0022 Acc: 84.4405\n",
      "Saving..\n",
      "Epoch 6/99\n",
      "training Loss: 0.0021 Acc: 85.0961\n",
      "validation Loss: 0.0022 Acc: 83.9881\n",
      "Epoch 7/99\n",
      "training Loss: 0.0021 Acc: 85.2241\n",
      "validation Loss: 0.0023 Acc: 83.7857\n",
      "Epoch 8/99\n",
      "training Loss: 0.0021 Acc: 85.0187\n",
      "validation Loss: 0.0023 Acc: 84.1905\n",
      "Epoch 9/99\n",
      "training Loss: 0.0021 Acc: 85.1795\n",
      "validation Loss: 0.0021 Acc: 84.7500\n",
      "Saving..\n",
      "Epoch 10/99\n",
      "training Loss: 0.0021 Acc: 85.4146\n",
      "validation Loss: 0.0024 Acc: 84.3929\n",
      "Epoch 11/99\n",
      "training Loss: 0.0022 Acc: 85.0187\n",
      "validation Loss: 0.0022 Acc: 84.0000\n",
      "Epoch 12/99\n",
      "training Loss: 0.0021 Acc: 85.2330\n",
      "validation Loss: 0.0022 Acc: 84.3452\n",
      "Epoch 13/99\n",
      "training Loss: 0.0021 Acc: 85.4800\n",
      "validation Loss: 0.0022 Acc: 84.3690\n",
      "Epoch 14/99\n",
      "training Loss: 0.0021 Acc: 85.2985\n",
      "validation Loss: 0.0022 Acc: 84.3571\n",
      "Epoch 15/99\n",
      "training Loss: 0.0021 Acc: 85.2003\n",
      "validation Loss: 0.0022 Acc: 84.0476\n",
      "Epoch 16/99\n",
      "training Loss: 0.0020 Acc: 85.7360\n",
      "validation Loss: 0.0021 Acc: 85.0119\n",
      "Saving..\n",
      "Epoch 17/99\n",
      "training Loss: 0.0020 Acc: 85.7479\n",
      "validation Loss: 0.0021 Acc: 84.8214\n",
      "Epoch 18/99\n",
      "training Loss: 0.0020 Acc: 85.9145\n",
      "validation Loss: 0.0021 Acc: 84.6190\n",
      "Epoch 19/99\n",
      "training Loss: 0.0020 Acc: 85.8282\n",
      "validation Loss: 0.0022 Acc: 84.8333\n",
      "Epoch 20/99\n",
      "training Loss: 0.0020 Acc: 85.6080\n",
      "validation Loss: 0.0021 Acc: 84.8810\n",
      "Epoch 21/99\n",
      "training Loss: 0.0020 Acc: 85.8699\n",
      "validation Loss: 0.0021 Acc: 84.8095\n",
      "Epoch 22/99\n",
      "training Loss: 0.0020 Acc: 85.8461\n",
      "validation Loss: 0.0021 Acc: 84.8452\n",
      "Epoch 23/99\n",
      "training Loss: 0.0020 Acc: 85.9919\n",
      "validation Loss: 0.0021 Acc: 84.9167\n",
      "Epoch 24/99\n",
      "training Loss: 0.0020 Acc: 85.9592\n",
      "validation Loss: 0.0021 Acc: 84.6905\n",
      "Epoch 25/99\n",
      "training Loss: 0.0020 Acc: 86.0157\n",
      "validation Loss: 0.0021 Acc: 84.9048\n",
      "Epoch 26/99\n",
      "training Loss: 0.0020 Acc: 86.0068\n",
      "validation Loss: 0.0022 Acc: 84.7024\n",
      "Early stopped.\n",
      "Best val acc: 85.011905\n",
      "----------\n",
      "Epoch 0/99\n",
      "training Loss: 0.0025 Acc: 82.4147\n",
      "validation Loss: 0.0023 Acc: 84.9881\n",
      "Saving..\n",
      "Epoch 1/99\n",
      "training Loss: 0.0022 Acc: 84.2658\n",
      "validation Loss: 0.0024 Acc: 84.0714\n",
      "Epoch 2/99\n",
      "training Loss: 0.0023 Acc: 84.3402\n",
      "validation Loss: 0.0023 Acc: 83.8929\n",
      "Epoch 3/99\n",
      "training Loss: 0.0022 Acc: 84.3581\n",
      "validation Loss: 0.0022 Acc: 85.0000\n",
      "Saving..\n",
      "Epoch 4/99\n",
      "training Loss: 0.0022 Acc: 84.7003\n",
      "validation Loss: 0.0022 Acc: 85.1071\n",
      "Saving..\n",
      "Epoch 5/99\n",
      "training Loss: 0.0022 Acc: 84.8670\n",
      "validation Loss: 0.0022 Acc: 85.1786\n",
      "Saving..\n",
      "Epoch 6/99\n",
      "training Loss: 0.0022 Acc: 84.6765\n",
      "validation Loss: 0.0021 Acc: 85.3333\n",
      "Saving..\n",
      "Epoch 7/99\n",
      "training Loss: 0.0022 Acc: 84.9146\n",
      "validation Loss: 0.0021 Acc: 85.4048\n",
      "Saving..\n",
      "Epoch 8/99\n",
      "training Loss: 0.0022 Acc: 84.9086\n",
      "validation Loss: 0.0021 Acc: 85.2381\n",
      "Epoch 9/99\n",
      "training Loss: 0.0021 Acc: 85.2390\n",
      "validation Loss: 0.0021 Acc: 85.1548\n",
      "Epoch 10/99\n",
      "training Loss: 0.0021 Acc: 85.1408\n",
      "validation Loss: 0.0022 Acc: 85.4524\n",
      "Saving..\n",
      "Epoch 11/99\n",
      "training Loss: 0.0022 Acc: 85.0485\n",
      "validation Loss: 0.0023 Acc: 84.2262\n",
      "Epoch 12/99\n",
      "training Loss: 0.0022 Acc: 84.3759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation Loss: 0.0022 Acc: 84.9286\n",
      "Epoch 13/99\n",
      "training Loss: 0.0021 Acc: 85.1348\n",
      "validation Loss: 0.0022 Acc: 85.4762\n",
      "Saving..\n",
      "Epoch 14/99\n",
      "training Loss: 0.0021 Acc: 85.2598\n",
      "validation Loss: 0.0021 Acc: 85.8690\n",
      "Saving..\n",
      "Epoch 15/99\n",
      "training Loss: 0.0021 Acc: 85.2955\n",
      "validation Loss: 0.0021 Acc: 85.8810\n",
      "Saving..\n",
      "Epoch 16/99\n",
      "training Loss: 0.0020 Acc: 85.5515\n",
      "validation Loss: 0.0021 Acc: 85.3214\n",
      "Epoch 17/99\n",
      "training Loss: 0.0020 Acc: 85.5306\n",
      "validation Loss: 0.0021 Acc: 85.6786\n",
      "Epoch 18/99\n",
      "training Loss: 0.0020 Acc: 85.5604\n",
      "validation Loss: 0.0021 Acc: 85.7857\n",
      "Epoch 19/99\n",
      "training Loss: 0.0020 Acc: 85.6467\n",
      "validation Loss: 0.0021 Acc: 85.9286\n",
      "Saving..\n",
      "Epoch 20/99\n",
      "training Loss: 0.0020 Acc: 85.5842\n",
      "validation Loss: 0.0021 Acc: 85.8333\n",
      "Epoch 21/99\n",
      "training Loss: 0.0020 Acc: 85.7032\n",
      "validation Loss: 0.0021 Acc: 86.1190\n",
      "Saving..\n",
      "Epoch 22/99\n",
      "training Loss: 0.0021 Acc: 85.8074\n",
      "validation Loss: 0.0021 Acc: 86.0476\n",
      "Epoch 23/99\n",
      "training Loss: 0.0020 Acc: 85.7806\n",
      "validation Loss: 0.0021 Acc: 85.9524\n",
      "Epoch 24/99\n",
      "training Loss: 0.0020 Acc: 85.7181\n",
      "validation Loss: 0.0021 Acc: 85.9762\n",
      "Epoch 25/99\n",
      "training Loss: 0.0020 Acc: 85.7360\n",
      "validation Loss: 0.0021 Acc: 85.8810\n",
      "Epoch 26/99\n",
      "training Loss: 0.0020 Acc: 85.7330\n",
      "validation Loss: 0.0020 Acc: 85.8929\n",
      "Epoch 27/99\n",
      "training Loss: 0.0020 Acc: 85.8044\n",
      "validation Loss: 0.0021 Acc: 86.1310\n",
      "Saving..\n",
      "Epoch 28/99\n",
      "training Loss: 0.0020 Acc: 86.0008\n",
      "validation Loss: 0.0021 Acc: 85.8810\n",
      "Epoch 29/99\n",
      "training Loss: 0.0020 Acc: 85.6913\n",
      "validation Loss: 0.0021 Acc: 85.9405\n",
      "Epoch 30/99\n",
      "training Loss: 0.0020 Acc: 85.7717\n",
      "validation Loss: 0.0021 Acc: 85.7500\n",
      "Epoch 31/99\n",
      "training Loss: 0.0020 Acc: 85.6199\n",
      "validation Loss: 0.0020 Acc: 86.0952\n",
      "Epoch 32/99\n",
      "training Loss: 0.0020 Acc: 85.6794\n",
      "validation Loss: 0.0021 Acc: 85.7857\n",
      "Epoch 33/99\n",
      "training Loss: 0.0020 Acc: 85.8520\n",
      "validation Loss: 0.0021 Acc: 85.8690\n",
      "Epoch 34/99\n",
      "training Loss: 0.0020 Acc: 85.8967\n",
      "validation Loss: 0.0021 Acc: 86.1667\n",
      "Saving..\n",
      "Epoch 35/99\n",
      "training Loss: 0.0020 Acc: 85.8014\n",
      "validation Loss: 0.0021 Acc: 85.8929\n",
      "Epoch 36/99\n",
      "training Loss: 0.0020 Acc: 85.8758\n",
      "validation Loss: 0.0020 Acc: 86.2262\n",
      "Saving..\n",
      "Epoch 37/99\n",
      "training Loss: 0.0020 Acc: 85.9264\n",
      "validation Loss: 0.0021 Acc: 86.0476\n",
      "Epoch 38/99\n",
      "training Loss: 0.0019 Acc: 86.0901\n",
      "validation Loss: 0.0020 Acc: 86.1786\n",
      "Epoch 39/99\n",
      "training Loss: 0.0019 Acc: 86.1734\n",
      "validation Loss: 0.0021 Acc: 86.0238\n",
      "Epoch 40/99\n",
      "training Loss: 0.0020 Acc: 86.1853\n",
      "validation Loss: 0.0021 Acc: 86.0119\n",
      "Epoch 41/99\n",
      "training Loss: 0.0020 Acc: 86.2211\n",
      "validation Loss: 0.0021 Acc: 86.1429\n",
      "Epoch 42/99\n",
      "training Loss: 0.0019 Acc: 86.3163\n",
      "validation Loss: 0.0021 Acc: 86.0476\n",
      "Epoch 43/99\n",
      "training Loss: 0.0019 Acc: 86.2627\n",
      "validation Loss: 0.0021 Acc: 85.8929\n",
      "Epoch 44/99\n",
      "training Loss: 0.0019 Acc: 86.3133\n",
      "validation Loss: 0.0021 Acc: 86.0119\n",
      "Epoch 45/99\n",
      "training Loss: 0.0019 Acc: 86.4026\n",
      "validation Loss: 0.0021 Acc: 86.2500\n",
      "Saving..\n",
      "Epoch 46/99\n",
      "training Loss: 0.0019 Acc: 86.5246\n",
      "validation Loss: 0.0021 Acc: 86.2143\n",
      "Epoch 47/99\n",
      "training Loss: 0.0019 Acc: 86.6020\n",
      "validation Loss: 0.0021 Acc: 86.2381\n",
      "Epoch 48/99\n",
      "training Loss: 0.0019 Acc: 86.5246\n",
      "validation Loss: 0.0021 Acc: 86.2381\n",
      "Epoch 49/99\n",
      "training Loss: 0.0019 Acc: 86.6079\n",
      "validation Loss: 0.0021 Acc: 86.2381\n",
      "Epoch 50/99\n",
      "training Loss: 0.0019 Acc: 86.4919\n",
      "validation Loss: 0.0021 Acc: 86.1190\n",
      "Epoch 51/99\n",
      "training Loss: 0.0019 Acc: 86.6585\n",
      "validation Loss: 0.0021 Acc: 86.2619\n",
      "Saving..\n",
      "Epoch 52/99\n",
      "training Loss: 0.0019 Acc: 86.7567\n",
      "validation Loss: 0.0021 Acc: 86.1310\n",
      "Epoch 53/99\n",
      "training Loss: 0.0019 Acc: 86.7925\n",
      "validation Loss: 0.0021 Acc: 86.2857\n",
      "Saving..\n",
      "Epoch 54/99\n",
      "training Loss: 0.0019 Acc: 86.7835\n",
      "validation Loss: 0.0021 Acc: 86.2024\n",
      "Epoch 55/99\n",
      "training Loss: 0.0018 Acc: 86.8192\n",
      "validation Loss: 0.0021 Acc: 86.2143\n",
      "Epoch 56/99\n",
      "training Loss: 0.0019 Acc: 86.8669\n",
      "validation Loss: 0.0021 Acc: 86.0238\n",
      "Epoch 57/99\n",
      "training Loss: 0.0018 Acc: 86.9085\n",
      "validation Loss: 0.0021 Acc: 86.1548\n",
      "Epoch 58/99\n",
      "training Loss: 0.0018 Acc: 87.0097\n",
      "validation Loss: 0.0021 Acc: 86.0595\n",
      "Epoch 59/99\n",
      "training Loss: 0.0019 Acc: 86.8609\n",
      "validation Loss: 0.0021 Acc: 86.1190\n",
      "Epoch 60/99\n",
      "training Loss: 0.0019 Acc: 87.0365\n",
      "validation Loss: 0.0022 Acc: 85.9881\n",
      "Epoch 61/99\n",
      "training Loss: 0.0018 Acc: 86.8698\n",
      "validation Loss: 0.0022 Acc: 86.1905\n",
      "Epoch 62/99\n",
      "training Loss: 0.0018 Acc: 86.9085\n",
      "validation Loss: 0.0022 Acc: 86.1548\n",
      "Epoch 63/99\n",
      "training Loss: 0.0018 Acc: 86.9859\n",
      "validation Loss: 0.0021 Acc: 86.0952\n",
      "Early stopped.\n",
      "Best val acc: 86.285714\n",
      "----------\n",
      "Epoch 0/99\n",
      "training Loss: 0.0026 Acc: 82.1707\n",
      "validation Loss: 0.0023 Acc: 83.6548\n",
      "Saving..\n",
      "Epoch 1/99\n",
      "training Loss: 0.0023 Acc: 84.3670\n",
      "validation Loss: 0.0030 Acc: 77.3452\n",
      "Epoch 2/99\n",
      "training Loss: 0.0023 Acc: 83.7004\n",
      "validation Loss: 0.0022 Acc: 83.5357\n",
      "Epoch 3/99\n",
      "training Loss: 0.0022 Acc: 84.4444\n",
      "validation Loss: 0.0022 Acc: 84.7262\n",
      "Saving..\n",
      "Epoch 4/99\n",
      "training Loss: 0.0022 Acc: 85.1497\n",
      "validation Loss: 0.0022 Acc: 84.9762\n",
      "Saving..\n",
      "Epoch 5/99\n",
      "training Loss: 0.0022 Acc: 85.0426\n",
      "validation Loss: 0.0024 Acc: 84.8333\n",
      "Epoch 6/99\n",
      "training Loss: 0.0021 Acc: 84.8372\n",
      "validation Loss: 0.0023 Acc: 84.8929\n",
      "Epoch 7/99\n",
      "training Loss: 0.0021 Acc: 84.8878\n",
      "validation Loss: 0.0022 Acc: 84.8095\n",
      "Epoch 8/99\n",
      "training Loss: 0.0021 Acc: 85.2985\n",
      "validation Loss: 0.0022 Acc: 85.1071\n",
      "Saving..\n",
      "Epoch 9/99\n",
      "training Loss: 0.0021 Acc: 85.3164\n",
      "validation Loss: 0.0024 Acc: 82.8690\n",
      "Epoch 10/99\n",
      "training Loss: 0.0022 Acc: 84.6854\n",
      "validation Loss: 0.0022 Acc: 85.0238\n",
      "Epoch 11/99\n",
      "training Loss: 0.0021 Acc: 84.8164\n",
      "validation Loss: 0.0022 Acc: 85.1071\n",
      "Epoch 12/99\n",
      "training Loss: 0.0021 Acc: 85.2241\n",
      "validation Loss: 0.0022 Acc: 84.9762\n",
      "Epoch 13/99\n",
      "training Loss: 0.0021 Acc: 85.4175\n",
      "validation Loss: 0.0021 Acc: 85.1548\n",
      "Saving..\n",
      "Epoch 14/99\n",
      "training Loss: 0.0021 Acc: 85.3134\n",
      "validation Loss: 0.0022 Acc: 85.1190\n",
      "Epoch 15/99\n",
      "training Loss: 0.0021 Acc: 85.4532\n",
      "validation Loss: 0.0021 Acc: 85.2619\n",
      "Saving..\n",
      "Epoch 16/99\n",
      "training Loss: 0.0021 Acc: 85.6526\n",
      "validation Loss: 0.0022 Acc: 84.6429\n",
      "Epoch 17/99\n",
      "training Loss: 0.0021 Acc: 85.3491\n",
      "validation Loss: 0.0022 Acc: 84.9524\n",
      "Epoch 18/99\n",
      "training Loss: 0.0021 Acc: 85.6556\n",
      "validation Loss: 0.0021 Acc: 85.0119\n",
      "Epoch 19/99\n",
      "training Loss: 0.0021 Acc: 85.4503\n",
      "validation Loss: 0.0021 Acc: 85.3452\n",
      "Saving..\n",
      "Epoch 20/99\n",
      "training Loss: 0.0021 Acc: 85.7568\n",
      "validation Loss: 0.0022 Acc: 84.8810\n",
      "Epoch 21/99\n",
      "training Loss: 0.0021 Acc: 85.7300\n",
      "validation Loss: 0.0022 Acc: 85.1667\n",
      "Epoch 22/99\n",
      "training Loss: 0.0021 Acc: 85.5009\n",
      "validation Loss: 0.0023 Acc: 84.7024\n",
      "Epoch 23/99\n",
      "training Loss: 0.0021 Acc: 85.6884\n",
      "validation Loss: 0.0021 Acc: 85.2143\n",
      "Epoch 24/99\n",
      "training Loss: 0.0021 Acc: 85.6884\n",
      "validation Loss: 0.0022 Acc: 84.6190\n",
      "Epoch 25/99\n",
      "training Loss: 0.0020 Acc: 85.8877\n",
      "validation Loss: 0.0021 Acc: 85.0000\n",
      "Epoch 26/99\n",
      "training Loss: 0.0020 Acc: 85.9383\n",
      "validation Loss: 0.0022 Acc: 85.2262\n",
      "Epoch 27/99\n",
      "training Loss: 0.0020 Acc: 85.8520\n",
      "validation Loss: 0.0021 Acc: 85.1310\n",
      "Epoch 28/99\n",
      "training Loss: 0.0020 Acc: 86.0187\n",
      "validation Loss: 0.0021 Acc: 85.3690\n",
      "Saving..\n",
      "Epoch 29/99\n",
      "training Loss: 0.0020 Acc: 86.0961\n",
      "validation Loss: 0.0021 Acc: 85.2262\n",
      "Epoch 30/99\n",
      "training Loss: 0.0020 Acc: 85.4235\n",
      "validation Loss: 0.0021 Acc: 84.9524\n",
      "Epoch 31/99\n",
      "training Loss: 0.0020 Acc: 86.2330\n",
      "validation Loss: 0.0021 Acc: 85.2619\n",
      "Epoch 32/99\n",
      "training Loss: 0.0020 Acc: 86.2181\n",
      "validation Loss: 0.0021 Acc: 85.1071\n",
      "Epoch 33/99\n",
      "training Loss: 0.0020 Acc: 86.1169\n",
      "validation Loss: 0.0021 Acc: 84.9286\n",
      "Epoch 34/99\n",
      "training Loss: 0.0020 Acc: 86.1824\n",
      "validation Loss: 0.0021 Acc: 85.1905\n",
      "Epoch 35/99\n",
      "training Loss: 0.0020 Acc: 86.2181\n",
      "validation Loss: 0.0021 Acc: 85.2500\n",
      "Epoch 36/99\n",
      "training Loss: 0.0020 Acc: 86.1675\n",
      "validation Loss: 0.0021 Acc: 85.3333\n",
      "Epoch 37/99\n",
      "training Loss: 0.0020 Acc: 86.2300\n",
      "validation Loss: 0.0021 Acc: 85.4762\n",
      "Saving..\n",
      "Epoch 38/99\n",
      "training Loss: 0.0020 Acc: 86.3520\n",
      "validation Loss: 0.0022 Acc: 85.2262\n",
      "Epoch 39/99\n",
      "training Loss: 0.0021 Acc: 85.8818\n",
      "validation Loss: 0.0021 Acc: 85.1071\n",
      "Epoch 40/99\n",
      "training Loss: 0.0020 Acc: 86.1526\n",
      "validation Loss: 0.0021 Acc: 85.0833\n",
      "Epoch 41/99\n",
      "training Loss: 0.0021 Acc: 85.4919\n",
      "validation Loss: 0.0021 Acc: 84.8452\n",
      "Epoch 42/99\n",
      "training Loss: 0.0020 Acc: 86.3014\n",
      "validation Loss: 0.0021 Acc: 85.4643\n",
      "Epoch 43/99\n",
      "training Loss: 0.0019 Acc: 86.3907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation Loss: 0.0021 Acc: 85.3214\n",
      "Epoch 44/99\n",
      "training Loss: 0.0019 Acc: 86.4205\n",
      "validation Loss: 0.0021 Acc: 85.2976\n",
      "Epoch 45/99\n",
      "training Loss: 0.0019 Acc: 86.4829\n",
      "validation Loss: 0.0021 Acc: 85.2262\n",
      "Epoch 46/99\n",
      "training Loss: 0.0019 Acc: 86.6079\n",
      "validation Loss: 0.0021 Acc: 85.5357\n",
      "Saving..\n",
      "Epoch 47/99\n",
      "training Loss: 0.0019 Acc: 86.6407\n",
      "validation Loss: 0.0021 Acc: 85.5000\n",
      "Epoch 48/99\n",
      "training Loss: 0.0019 Acc: 86.8669\n",
      "validation Loss: 0.0021 Acc: 85.3810\n",
      "Epoch 49/99\n",
      "training Loss: 0.0019 Acc: 86.8609\n",
      "validation Loss: 0.0021 Acc: 85.4762\n",
      "Epoch 50/99\n",
      "training Loss: 0.0019 Acc: 86.8698\n",
      "validation Loss: 0.0021 Acc: 85.3690\n",
      "Epoch 51/99\n",
      "training Loss: 0.0019 Acc: 86.8996\n",
      "validation Loss: 0.0021 Acc: 85.4286\n",
      "Epoch 52/99\n",
      "training Loss: 0.0019 Acc: 86.9264\n",
      "validation Loss: 0.0021 Acc: 85.3095\n",
      "Epoch 53/99\n",
      "training Loss: 0.0018 Acc: 87.1020\n",
      "validation Loss: 0.0021 Acc: 85.2857\n",
      "Epoch 54/99\n",
      "training Loss: 0.0018 Acc: 87.1079\n",
      "validation Loss: 0.0021 Acc: 85.3571\n",
      "Epoch 55/99\n",
      "training Loss: 0.0018 Acc: 87.2597\n",
      "validation Loss: 0.0021 Acc: 85.4643\n",
      "Epoch 56/99\n",
      "training Loss: 0.0019 Acc: 87.1615\n",
      "validation Loss: 0.0021 Acc: 85.2619\n",
      "Early stopped.\n",
      "Best val acc: 85.535714\n",
      "----------\n",
      "Epoch 0/99\n",
      "training Loss: 0.0025 Acc: 82.4385\n",
      "validation Loss: 0.0024 Acc: 84.2619\n",
      "Saving..\n",
      "Epoch 1/99\n",
      "training Loss: 0.0022 Acc: 84.3105\n",
      "validation Loss: 0.0022 Acc: 84.1548\n",
      "Epoch 2/99\n",
      "training Loss: 0.0022 Acc: 84.7211\n",
      "validation Loss: 0.0024 Acc: 82.9762\n",
      "Epoch 3/99\n",
      "training Loss: 0.0023 Acc: 84.1170\n",
      "validation Loss: 0.0022 Acc: 84.9405\n",
      "Saving..\n",
      "Epoch 4/99\n",
      "training Loss: 0.0022 Acc: 84.9086\n",
      "validation Loss: 0.0021 Acc: 85.0476\n",
      "Saving..\n",
      "Epoch 5/99\n",
      "training Loss: 0.0022 Acc: 84.8342\n",
      "validation Loss: 0.0022 Acc: 84.3810\n",
      "Epoch 6/99\n",
      "training Loss: 0.0022 Acc: 84.9741\n",
      "validation Loss: 0.0021 Acc: 85.1786\n",
      "Saving..\n",
      "Epoch 7/99\n",
      "training Loss: 0.0022 Acc: 84.8938\n",
      "validation Loss: 0.0021 Acc: 85.3452\n",
      "Saving..\n",
      "Epoch 8/99\n",
      "training Loss: 0.0022 Acc: 85.0426\n",
      "validation Loss: 0.0021 Acc: 85.0833\n",
      "Epoch 9/99\n",
      "training Loss: 0.0022 Acc: 84.6229\n",
      "validation Loss: 0.0021 Acc: 85.4881\n",
      "Saving..\n",
      "Epoch 10/99\n",
      "training Loss: 0.0022 Acc: 84.9592\n",
      "validation Loss: 0.0021 Acc: 84.7143\n",
      "Epoch 11/99\n",
      "training Loss: 0.0021 Acc: 85.0068\n",
      "validation Loss: 0.0021 Acc: 85.2857\n",
      "Epoch 12/99\n",
      "training Loss: 0.0021 Acc: 85.1318\n",
      "validation Loss: 0.0021 Acc: 85.1786\n",
      "Epoch 13/99\n",
      "training Loss: 0.0021 Acc: 84.9384\n",
      "validation Loss: 0.0022 Acc: 85.2143\n",
      "Epoch 14/99\n",
      "training Loss: 0.0021 Acc: 85.2390\n",
      "validation Loss: 0.0021 Acc: 85.5238\n",
      "Saving..\n",
      "Epoch 15/99\n",
      "training Loss: 0.0021 Acc: 85.0931\n",
      "validation Loss: 0.0021 Acc: 85.6310\n",
      "Saving..\n",
      "Epoch 16/99\n",
      "training Loss: 0.0021 Acc: 85.1527\n",
      "validation Loss: 0.0021 Acc: 85.3095\n",
      "Epoch 17/99\n",
      "training Loss: 0.0021 Acc: 85.1735\n",
      "validation Loss: 0.0020 Acc: 85.7976\n",
      "Saving..\n",
      "Epoch 18/99\n",
      "training Loss: 0.0021 Acc: 85.3967\n",
      "validation Loss: 0.0021 Acc: 85.1429\n",
      "Epoch 19/99\n",
      "training Loss: 0.0021 Acc: 85.2181\n",
      "validation Loss: 0.0020 Acc: 85.4524\n",
      "Epoch 20/99\n",
      "training Loss: 0.0021 Acc: 85.2628\n",
      "validation Loss: 0.0021 Acc: 84.7976\n",
      "Epoch 21/99\n",
      "training Loss: 0.0021 Acc: 85.1497\n",
      "validation Loss: 0.0021 Acc: 85.3571\n",
      "Epoch 22/99\n",
      "training Loss: 0.0021 Acc: 85.1497\n",
      "validation Loss: 0.0021 Acc: 85.7262\n",
      "Epoch 23/99\n",
      "training Loss: 0.0021 Acc: 85.1497\n",
      "validation Loss: 0.0021 Acc: 85.4881\n",
      "Epoch 24/99\n",
      "training Loss: 0.0021 Acc: 85.2896\n",
      "validation Loss: 0.0020 Acc: 85.6429\n",
      "Epoch 25/99\n",
      "training Loss: 0.0021 Acc: 85.3997\n",
      "validation Loss: 0.0021 Acc: 85.5238\n",
      "Epoch 26/99\n",
      "training Loss: 0.0021 Acc: 85.4592\n",
      "validation Loss: 0.0020 Acc: 85.6071\n",
      "Epoch 27/99\n",
      "training Loss: 0.0021 Acc: 85.6586\n",
      "validation Loss: 0.0020 Acc: 85.7262\n",
      "Early stopped.\n",
      "Best val acc: 85.797619\n",
      "----------\n",
      "Average best_acc across k-fold: 85.7744646966\n",
      "New configuration: {'hidden_layers': 2, 'dropout_g': 0.9, 'initial_nodes': 198, 'dropout': 0.1806783439081628, 'gru_layers': 2, 'batch_size': 512, 'gru_size': 298, 'learning_rate': 0.027853133690742892}\n",
      "Epoch 0/99\n",
      "training Loss: 0.0013 Acc: 70.6101\n",
      "validation Loss: 0.0008 Acc: 81.2902\n",
      "Saving..\n",
      "Epoch 1/99\n",
      "training Loss: 0.0009 Acc: 80.3185\n",
      "validation Loss: 0.0008 Acc: 82.6351\n",
      "Saving..\n",
      "Epoch 2/99\n",
      "training Loss: 0.0009 Acc: 81.7202\n",
      "validation Loss: 0.0008 Acc: 83.2183\n",
      "Saving..\n",
      "Epoch 3/99\n",
      "training Loss: 0.0008 Acc: 82.4018\n",
      "validation Loss: 0.0008 Acc: 83.1945\n",
      "Epoch 4/99\n",
      "training Loss: 0.0008 Acc: 82.1429\n",
      "validation Loss: 0.0008 Acc: 83.1707\n",
      "Epoch 5/99\n",
      "training Loss: 0.0008 Acc: 81.7649\n",
      "validation Loss: 0.0008 Acc: 82.8969\n",
      "Epoch 6/99\n",
      "training Loss: 0.0008 Acc: 82.2589\n",
      "validation Loss: 0.0008 Acc: 82.3494\n",
      "Epoch 7/99\n",
      "training Loss: 0.0008 Acc: 82.3095\n",
      "validation Loss: 0.0008 Acc: 81.9924\n",
      "Epoch 8/99\n",
      "training Loss: 0.0008 Acc: 82.0923\n",
      "validation Loss: 0.0008 Acc: 83.0993\n",
      "Epoch 9/99\n",
      "training Loss: 0.0008 Acc: 81.5565\n",
      "validation Loss: 0.0008 Acc: 82.3494\n",
      "Epoch 10/99\n",
      "training Loss: 0.0008 Acc: 81.4851\n",
      "validation Loss: 0.0008 Acc: 82.7065\n",
      "Epoch 11/99\n",
      "training Loss: 0.0008 Acc: 81.3899\n",
      "validation Loss: 0.0008 Acc: 82.9564\n",
      "Epoch 12/99\n",
      "training Loss: 0.0008 Acc: 81.3006\n",
      "validation Loss: 0.0009 Acc: 81.7781\n",
      "Early stopped.\n",
      "Best val acc: 83.218281\n",
      "----------\n",
      "Epoch 0/99\n",
      "training Loss: 0.0032 Acc: 63.0707\n",
      "validation Loss: 0.0009 Acc: 82.7738\n",
      "Saving..\n",
      "Epoch 1/99\n",
      "training Loss: 0.0009 Acc: 79.9714\n",
      "validation Loss: 0.0008 Acc: 83.0595\n",
      "Saving..\n",
      "Epoch 2/99\n",
      "training Loss: 0.0009 Acc: 80.6381\n",
      "validation Loss: 0.0008 Acc: 83.1905\n",
      "Saving..\n",
      "Epoch 3/99\n",
      "training Loss: 0.0008 Acc: 81.3315\n",
      "validation Loss: 0.0008 Acc: 83.0238\n",
      "Epoch 4/99\n",
      "training Loss: 0.0008 Acc: 81.5130\n",
      "validation Loss: 0.0007 Acc: 83.8810\n",
      "Saving..\n",
      "Epoch 5/99\n",
      "training Loss: 0.0008 Acc: 81.7749\n",
      "validation Loss: 0.0007 Acc: 83.2381\n",
      "Epoch 6/99\n",
      "training Loss: 0.0008 Acc: 81.8344\n",
      "validation Loss: 0.0008 Acc: 83.5238\n",
      "Epoch 7/99\n",
      "training Loss: 0.0008 Acc: 82.2034\n",
      "validation Loss: 0.0007 Acc: 84.8333\n",
      "Saving..\n",
      "Epoch 8/99\n",
      "training Loss: 0.0008 Acc: 82.0130\n",
      "validation Loss: 0.0008 Acc: 81.5714\n",
      "Epoch 9/99\n",
      "training Loss: 0.0008 Acc: 82.0546\n",
      "validation Loss: 0.0008 Acc: 81.4762\n",
      "Epoch 10/99\n",
      "training Loss: 0.0008 Acc: 81.9832\n",
      "validation Loss: 0.0007 Acc: 82.9405\n",
      "Epoch 11/99\n",
      "training Loss: 0.0008 Acc: 82.2838\n",
      "validation Loss: 0.0007 Acc: 84.2619\n",
      "Epoch 12/99\n",
      "training Loss: 0.0008 Acc: 82.8492\n",
      "validation Loss: 0.0007 Acc: 85.1905\n",
      "Saving..\n",
      "Epoch 13/99\n",
      "training Loss: 0.0008 Acc: 82.9028\n",
      "validation Loss: 0.0007 Acc: 84.2024\n",
      "Epoch 14/99\n",
      "training Loss: 0.0008 Acc: 82.8135\n",
      "validation Loss: 0.0007 Acc: 84.7381\n",
      "Epoch 15/99\n",
      "training Loss: 0.0008 Acc: 82.4862\n",
      "validation Loss: 0.0007 Acc: 85.1548\n",
      "Epoch 16/99\n",
      "training Loss: 0.0008 Acc: 83.1141\n",
      "validation Loss: 0.0007 Acc: 83.9167\n",
      "Epoch 17/99\n",
      "training Loss: 0.0007 Acc: 83.2867\n",
      "validation Loss: 0.0007 Acc: 85.6429\n",
      "Saving..\n",
      "Epoch 18/99\n",
      "training Loss: 0.0008 Acc: 83.1706\n",
      "validation Loss: 0.0007 Acc: 85.5357\n",
      "Epoch 19/99\n",
      "training Loss: 0.0007 Acc: 83.3433\n",
      "validation Loss: 0.0007 Acc: 84.4881\n",
      "Epoch 20/99\n",
      "training Loss: 0.0007 Acc: 83.0933\n",
      "validation Loss: 0.0007 Acc: 85.7500\n",
      "Saving..\n",
      "Epoch 21/99\n",
      "training Loss: 0.0007 Acc: 83.4980\n",
      "validation Loss: 0.0007 Acc: 85.9881\n",
      "Saving..\n",
      "Epoch 22/99\n",
      "training Loss: 0.0007 Acc: 83.3075\n",
      "validation Loss: 0.0007 Acc: 85.9524\n",
      "Epoch 23/99\n",
      "training Loss: 0.0007 Acc: 83.3968\n",
      "validation Loss: 0.0007 Acc: 85.7262\n",
      "Epoch 24/99\n",
      "training Loss: 0.0007 Acc: 83.3581\n",
      "validation Loss: 0.0007 Acc: 85.0119\n",
      "Epoch 25/99\n",
      "training Loss: 0.0007 Acc: 83.7093\n",
      "validation Loss: 0.0007 Acc: 84.7024\n",
      "Epoch 26/99\n",
      "training Loss: 0.0007 Acc: 83.0962\n",
      "validation Loss: 0.0007 Acc: 84.8571\n",
      "Epoch 27/99\n",
      "training Loss: 0.0007 Acc: 83.6260\n",
      "validation Loss: 0.0007 Acc: 84.5357\n",
      "Epoch 28/99\n",
      "training Loss: 0.0007 Acc: 83.8760\n",
      "validation Loss: 0.0007 Acc: 85.8095\n",
      "Epoch 29/99\n",
      "training Loss: 0.0007 Acc: 83.9712\n",
      "validation Loss: 0.0007 Acc: 85.9405\n",
      "Epoch 30/99\n",
      "training Loss: 0.0007 Acc: 84.0010\n",
      "validation Loss: 0.0007 Acc: 85.7857\n",
      "Epoch 31/99\n",
      "training Loss: 0.0007 Acc: 84.0545\n",
      "validation Loss: 0.0007 Acc: 86.1071\n",
      "Saving..\n",
      "Epoch 32/99\n",
      "training Loss: 0.0007 Acc: 84.0813\n",
      "validation Loss: 0.0007 Acc: 85.9881\n",
      "Epoch 33/99\n",
      "training Loss: 0.0007 Acc: 84.0099\n",
      "validation Loss: 0.0006 Acc: 86.2262\n",
      "Saving..\n",
      "Epoch 34/99\n",
      "training Loss: 0.0007 Acc: 84.2390\n",
      "validation Loss: 0.0007 Acc: 85.8571\n",
      "Epoch 35/99\n",
      "training Loss: 0.0007 Acc: 84.1646\n",
      "validation Loss: 0.0007 Acc: 86.2381\n",
      "Saving..\n",
      "Epoch 36/99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Loss: 0.0007 Acc: 84.2509\n",
      "validation Loss: 0.0007 Acc: 86.0952\n",
      "Epoch 37/99\n",
      "training Loss: 0.0007 Acc: 84.2152\n",
      "validation Loss: 0.0007 Acc: 86.0238\n",
      "Epoch 38/99\n",
      "training Loss: 0.0007 Acc: 84.4235\n",
      "validation Loss: 0.0007 Acc: 85.4405\n",
      "Epoch 39/99\n",
      "training Loss: 0.0007 Acc: 84.2361\n",
      "validation Loss: 0.0007 Acc: 85.9048\n",
      "Epoch 40/99\n",
      "training Loss: 0.0007 Acc: 84.3253\n",
      "validation Loss: 0.0007 Acc: 86.1190\n",
      "Epoch 41/99\n",
      "training Loss: 0.0007 Acc: 84.3610\n",
      "validation Loss: 0.0007 Acc: 85.7262\n",
      "Epoch 42/99\n",
      "training Loss: 0.0007 Acc: 84.5575\n",
      "validation Loss: 0.0007 Acc: 86.1310\n",
      "Epoch 43/99\n",
      "training Loss: 0.0007 Acc: 84.4146\n",
      "validation Loss: 0.0007 Acc: 86.3095\n",
      "Saving..\n",
      "Epoch 44/99\n",
      "training Loss: 0.0007 Acc: 84.5218\n",
      "validation Loss: 0.0006 Acc: 86.1071\n",
      "Epoch 45/99\n",
      "training Loss: 0.0007 Acc: 84.5128\n",
      "validation Loss: 0.0007 Acc: 86.1786\n",
      "Epoch 46/99\n",
      "training Loss: 0.0007 Acc: 84.5218\n",
      "validation Loss: 0.0007 Acc: 85.9524\n",
      "Epoch 47/99\n",
      "training Loss: 0.0007 Acc: 84.5723\n",
      "validation Loss: 0.0006 Acc: 86.1667\n",
      "Epoch 48/99\n",
      "training Loss: 0.0007 Acc: 84.5396\n",
      "validation Loss: 0.0007 Acc: 86.2381\n",
      "Epoch 49/99\n",
      "training Loss: 0.0007 Acc: 84.7539\n",
      "validation Loss: 0.0006 Acc: 86.2857\n",
      "Epoch 50/99\n",
      "training Loss: 0.0007 Acc: 84.6973\n",
      "validation Loss: 0.0006 Acc: 86.2738\n",
      "Epoch 51/99\n",
      "training Loss: 0.0007 Acc: 84.5783\n",
      "validation Loss: 0.0006 Acc: 86.2024\n",
      "Epoch 52/99\n",
      "training Loss: 0.0007 Acc: 84.7450\n",
      "validation Loss: 0.0006 Acc: 86.1429\n",
      "Epoch 53/99\n",
      "training Loss: 0.0007 Acc: 84.8194\n",
      "validation Loss: 0.0006 Acc: 86.2619\n",
      "Early stopped.\n",
      "Best val acc: 86.309524\n",
      "----------\n",
      "Epoch 0/99\n",
      "training Loss: 0.0012 Acc: 73.8379\n",
      "validation Loss: 0.0009 Acc: 83.2143\n",
      "Saving..\n",
      "Epoch 1/99\n",
      "training Loss: 0.0008 Acc: 81.5725\n",
      "validation Loss: 0.0007 Acc: 84.2738\n",
      "Saving..\n",
      "Epoch 2/99\n",
      "training Loss: 0.0008 Acc: 82.4743\n",
      "validation Loss: 0.0008 Acc: 84.4643\n",
      "Saving..\n",
      "Epoch 3/99\n",
      "training Loss: 0.0008 Acc: 83.3403\n",
      "validation Loss: 0.0008 Acc: 84.6905\n",
      "Saving..\n",
      "Epoch 4/99\n",
      "training Loss: 0.0007 Acc: 83.9146\n",
      "validation Loss: 0.0008 Acc: 84.5833\n",
      "Epoch 5/99\n",
      "training Loss: 0.0007 Acc: 83.8789\n",
      "validation Loss: 0.0007 Acc: 84.6905\n",
      "Epoch 6/99\n",
      "training Loss: 0.0007 Acc: 83.7480\n",
      "validation Loss: 0.0007 Acc: 84.5238\n",
      "Epoch 7/99\n",
      "training Loss: 0.0008 Acc: 83.3224\n",
      "validation Loss: 0.0007 Acc: 84.8095\n",
      "Saving..\n",
      "Epoch 8/99\n",
      "training Loss: 0.0008 Acc: 83.7450\n",
      "validation Loss: 0.0007 Acc: 84.6905\n",
      "Epoch 9/99\n",
      "training Loss: 0.0007 Acc: 83.6051\n",
      "validation Loss: 0.0008 Acc: 83.9643\n",
      "Epoch 10/99\n",
      "training Loss: 0.0008 Acc: 83.2689\n",
      "validation Loss: 0.0007 Acc: 84.7143\n",
      "Epoch 11/99\n",
      "training Loss: 0.0008 Acc: 83.3016\n",
      "validation Loss: 0.0007 Acc: 84.5000\n",
      "Epoch 12/99\n",
      "training Loss: 0.0008 Acc: 83.5873\n",
      "validation Loss: 0.0007 Acc: 85.2619\n",
      "Saving..\n",
      "Epoch 13/99\n",
      "training Loss: 0.0007 Acc: 83.7391\n",
      "validation Loss: 0.0008 Acc: 84.9881\n",
      "Epoch 14/99\n",
      "training Loss: 0.0007 Acc: 83.8760\n",
      "validation Loss: 0.0007 Acc: 84.6190\n",
      "Epoch 15/99\n",
      "training Loss: 0.0007 Acc: 84.0515\n",
      "validation Loss: 0.0007 Acc: 84.5357\n",
      "Epoch 16/99\n",
      "training Loss: 0.0007 Acc: 84.1140\n",
      "validation Loss: 0.0007 Acc: 85.2024\n",
      "Epoch 17/99\n",
      "training Loss: 0.0007 Acc: 84.0129\n",
      "validation Loss: 0.0007 Acc: 84.8452\n",
      "Epoch 18/99\n",
      "training Loss: 0.0007 Acc: 84.2926\n",
      "validation Loss: 0.0007 Acc: 85.1429\n",
      "Epoch 19/99\n",
      "training Loss: 0.0007 Acc: 84.3670\n",
      "validation Loss: 0.0007 Acc: 85.1548\n",
      "Epoch 20/99\n",
      "training Loss: 0.0007 Acc: 84.2896\n",
      "validation Loss: 0.0007 Acc: 85.2976\n",
      "Saving..\n",
      "Epoch 21/99\n",
      "training Loss: 0.0007 Acc: 84.5456\n",
      "validation Loss: 0.0007 Acc: 85.1190\n",
      "Epoch 22/99\n",
      "training Loss: 0.0007 Acc: 84.5515\n",
      "validation Loss: 0.0007 Acc: 85.2262\n",
      "Epoch 23/99\n",
      "training Loss: 0.0007 Acc: 84.7241\n",
      "validation Loss: 0.0007 Acc: 85.1071\n",
      "Epoch 24/99\n",
      "training Loss: 0.0007 Acc: 84.5843\n",
      "validation Loss: 0.0007 Acc: 85.0595\n",
      "Epoch 25/99\n",
      "training Loss: 0.0007 Acc: 84.7271\n",
      "validation Loss: 0.0007 Acc: 85.1905\n",
      "Epoch 26/99\n",
      "training Loss: 0.0007 Acc: 84.7003\n",
      "validation Loss: 0.0007 Acc: 85.2381\n",
      "Epoch 27/99\n",
      "training Loss: 0.0007 Acc: 84.9741\n",
      "validation Loss: 0.0007 Acc: 85.0714\n",
      "Epoch 28/99\n",
      "training Loss: 0.0007 Acc: 84.5604\n",
      "validation Loss: 0.0007 Acc: 85.1667\n",
      "Epoch 29/99\n",
      "training Loss: 0.0007 Acc: 84.7331\n",
      "validation Loss: 0.0007 Acc: 85.2143\n",
      "Epoch 30/99\n",
      "training Loss: 0.0007 Acc: 84.6348\n",
      "validation Loss: 0.0007 Acc: 85.1786\n",
      "Early stopped.\n",
      "Best val acc: 85.297619\n",
      "----------\n",
      "Epoch 0/99\n",
      "training Loss: 0.0014 Acc: 63.4337\n",
      "validation Loss: 0.0009 Acc: 80.7381\n",
      "Saving..\n",
      "Epoch 1/99\n",
      "training Loss: 0.0009 Acc: 79.0132\n",
      "validation Loss: 0.0008 Acc: 83.3095\n",
      "Saving..\n",
      "Epoch 2/99\n",
      "training Loss: 0.0009 Acc: 80.0905\n",
      "validation Loss: 0.0008 Acc: 83.3214\n",
      "Saving..\n",
      "Epoch 3/99\n",
      "training Loss: 0.0008 Acc: 81.1559\n",
      "validation Loss: 0.0008 Acc: 83.4048\n",
      "Saving..\n",
      "Epoch 4/99\n",
      "training Loss: 0.0008 Acc: 81.4803\n",
      "validation Loss: 0.0007 Acc: 84.0238\n",
      "Saving..\n",
      "Epoch 5/99\n",
      "training Loss: 0.0008 Acc: 81.2749\n",
      "validation Loss: 0.0008 Acc: 84.1429\n",
      "Saving..\n",
      "Epoch 6/99\n",
      "training Loss: 0.0008 Acc: 81.7868\n",
      "validation Loss: 0.0008 Acc: 84.0000\n",
      "Epoch 7/99\n",
      "training Loss: 0.0008 Acc: 82.1052\n",
      "validation Loss: 0.0008 Acc: 84.6905\n",
      "Saving..\n",
      "Epoch 8/99\n",
      "training Loss: 0.0008 Acc: 81.9862\n",
      "validation Loss: 0.0008 Acc: 80.6905\n",
      "Epoch 9/99\n",
      "training Loss: 0.0008 Acc: 82.2451\n",
      "validation Loss: 0.0008 Acc: 81.8214\n",
      "Epoch 10/99\n",
      "training Loss: 0.0008 Acc: 81.3196\n",
      "validation Loss: 0.0007 Acc: 84.9048\n",
      "Saving..\n",
      "Epoch 11/99\n",
      "training Loss: 0.0008 Acc: 81.4803\n",
      "validation Loss: 0.0007 Acc: 84.5952\n",
      "Epoch 12/99\n",
      "training Loss: 0.0008 Acc: 81.6886\n",
      "validation Loss: 0.0007 Acc: 85.5000\n",
      "Saving..\n",
      "Epoch 13/99\n",
      "training Loss: 0.0008 Acc: 82.1231\n",
      "validation Loss: 0.0007 Acc: 84.4524\n",
      "Epoch 14/99\n",
      "training Loss: 0.0008 Acc: 81.5071\n",
      "validation Loss: 0.0008 Acc: 81.1786\n",
      "Epoch 15/99\n",
      "training Loss: 0.0008 Acc: 81.8106\n",
      "validation Loss: 0.0007 Acc: 84.5000\n",
      "Epoch 16/99\n",
      "training Loss: 0.0008 Acc: 81.6826\n",
      "validation Loss: 0.0007 Acc: 84.5833\n",
      "Epoch 17/99\n",
      "training Loss: 0.0008 Acc: 81.5993\n",
      "validation Loss: 0.0007 Acc: 84.6548\n",
      "Epoch 18/99\n",
      "training Loss: 0.0008 Acc: 81.9802\n",
      "validation Loss: 0.0007 Acc: 84.1310\n",
      "Epoch 19/99\n",
      "training Loss: 0.0008 Acc: 82.5219\n",
      "validation Loss: 0.0007 Acc: 85.1905\n",
      "Epoch 20/99\n",
      "training Loss: 0.0008 Acc: 82.5576\n",
      "validation Loss: 0.0007 Acc: 84.9167\n",
      "Epoch 21/99\n",
      "training Loss: 0.0008 Acc: 82.9028\n",
      "validation Loss: 0.0007 Acc: 85.0833\n",
      "Epoch 22/99\n",
      "training Loss: 0.0008 Acc: 82.6320\n",
      "validation Loss: 0.0007 Acc: 84.1667\n",
      "Early stopped.\n",
      "Best val acc: 85.500000\n",
      "----------\n",
      "Epoch 0/99\n",
      "training Loss: 0.0013 Acc: 67.1418\n",
      "validation Loss: 0.0008 Acc: 80.9643\n",
      "Saving..\n",
      "Epoch 1/99\n",
      "training Loss: 0.0009 Acc: 76.0312\n",
      "validation Loss: 0.0008 Acc: 83.5119\n",
      "Saving..\n",
      "Epoch 2/99\n",
      "training Loss: 0.0009 Acc: 80.7244\n",
      "validation Loss: 0.0008 Acc: 83.4524\n",
      "Epoch 3/99\n",
      "training Loss: 0.0008 Acc: 81.2541\n",
      "validation Loss: 0.0008 Acc: 83.4643\n",
      "Epoch 4/99\n",
      "training Loss: 0.0008 Acc: 81.5100\n",
      "validation Loss: 0.0008 Acc: 83.5000\n",
      "Epoch 5/99\n",
      "training Loss: 0.0008 Acc: 81.4475\n",
      "validation Loss: 0.0008 Acc: 83.8452\n",
      "Saving..\n",
      "Epoch 6/99\n",
      "training Loss: 0.0008 Acc: 81.6886\n",
      "validation Loss: 0.0008 Acc: 83.6548\n",
      "Epoch 7/99\n",
      "training Loss: 0.0008 Acc: 81.4713\n",
      "validation Loss: 0.0008 Acc: 83.7738\n",
      "Epoch 8/99\n",
      "training Loss: 0.0008 Acc: 81.5011\n",
      "validation Loss: 0.0008 Acc: 84.0000\n",
      "Saving..\n",
      "Epoch 9/99\n",
      "training Loss: 0.0008 Acc: 81.7749\n",
      "validation Loss: 0.0007 Acc: 83.2262\n",
      "Epoch 10/99\n",
      "training Loss: 0.0008 Acc: 81.7779\n",
      "validation Loss: 0.0008 Acc: 83.0000\n",
      "Epoch 11/99\n",
      "training Loss: 0.0008 Acc: 81.1916\n",
      "validation Loss: 0.0008 Acc: 83.0000\n",
      "Epoch 12/99\n",
      "training Loss: 0.0008 Acc: 81.3166\n",
      "validation Loss: 0.0008 Acc: 83.2262\n",
      "Epoch 13/99\n",
      "training Loss: 0.0008 Acc: 80.8940\n",
      "validation Loss: 0.0008 Acc: 83.1190\n",
      "Epoch 14/99\n",
      "training Loss: 0.0008 Acc: 81.4475\n",
      "validation Loss: 0.0007 Acc: 83.2143\n",
      "Epoch 15/99\n",
      "training Loss: 0.0008 Acc: 81.4565\n",
      "validation Loss: 0.0008 Acc: 83.6190\n",
      "Epoch 16/99\n",
      "training Loss: 0.0008 Acc: 81.2243\n",
      "validation Loss: 0.0008 Acc: 82.9762\n",
      "Epoch 17/99\n",
      "training Loss: 0.0008 Acc: 80.6410\n",
      "validation Loss: 0.0008 Acc: 81.4167\n",
      "Epoch 18/99\n",
      "training Loss: 0.0008 Acc: 81.0249\n",
      "validation Loss: 0.0008 Acc: 83.8333\n",
      "Early stopped.\n",
      "Best val acc: 84.000000\n",
      "----------\n",
      "Average best_acc across k-fold: 84.8650848437\n",
      "New configuration: {'hidden_layers': 2, 'dropout_g': 0.01, 'initial_nodes': 500, 'dropout': 0.01, 'gru_layers': 3, 'batch_size': 32, 'gru_size': 500, 'learning_rate': 1e-05}\n",
      "Epoch 0/99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Loss: 0.0152 Acc: 79.7679\n",
      "validation Loss: 0.0119 Acc: 83.0040\n",
      "Saving..\n",
      "Epoch 1/99\n",
      "training Loss: 0.0121 Acc: 82.6071\n",
      "validation Loss: 0.0117 Acc: 83.1826\n",
      "Saving..\n",
      "Epoch 2/99\n",
      "training Loss: 0.0119 Acc: 83.0298\n",
      "validation Loss: 0.0116 Acc: 83.7063\n",
      "Saving..\n",
      "Epoch 3/99\n",
      "training Loss: 0.0119 Acc: 83.2619\n",
      "validation Loss: 0.0115 Acc: 83.4563\n",
      "Epoch 4/99\n",
      "training Loss: 0.0118 Acc: 83.3542\n",
      "validation Loss: 0.0114 Acc: 83.7777\n",
      "Saving..\n",
      "Epoch 5/99\n",
      "training Loss: 0.0117 Acc: 83.4762\n",
      "validation Loss: 0.0114 Acc: 84.1109\n",
      "Saving..\n",
      "Epoch 6/99\n",
      "training Loss: 0.0117 Acc: 83.6548\n",
      "validation Loss: 0.0113 Acc: 83.9800\n",
      "Epoch 7/99\n",
      "training Loss: 0.0116 Acc: 83.7470\n",
      "validation Loss: 0.0112 Acc: 83.9800\n",
      "Epoch 8/99\n",
      "training Loss: 0.0114 Acc: 83.8780\n",
      "validation Loss: 0.0111 Acc: 84.5394\n",
      "Saving..\n",
      "Epoch 9/99\n",
      "training Loss: 0.0113 Acc: 84.0744\n",
      "validation Loss: 0.0109 Acc: 84.9084\n",
      "Saving..\n",
      "Epoch 10/99\n",
      "training Loss: 0.0112 Acc: 84.2351\n",
      "validation Loss: 0.0107 Acc: 84.8965\n",
      "Epoch 11/99\n",
      "training Loss: 0.0111 Acc: 84.3363\n",
      "validation Loss: 0.0106 Acc: 84.9679\n",
      "Saving..\n",
      "Epoch 12/99\n",
      "training Loss: 0.0110 Acc: 84.5327\n",
      "validation Loss: 0.0106 Acc: 85.1107\n",
      "Saving..\n",
      "Epoch 13/99\n",
      "training Loss: 0.0109 Acc: 84.4792\n",
      "validation Loss: 0.0106 Acc: 85.0869\n",
      "Epoch 14/99\n",
      "training Loss: 0.0109 Acc: 84.5268\n",
      "validation Loss: 0.0104 Acc: 85.2297\n",
      "Saving..\n",
      "Epoch 15/99\n",
      "training Loss: 0.0109 Acc: 84.6101\n",
      "validation Loss: 0.0106 Acc: 85.1464\n",
      "Epoch 16/99\n",
      "training Loss: 0.0108 Acc: 84.6071\n",
      "validation Loss: 0.0104 Acc: 85.2773\n",
      "Saving..\n",
      "Epoch 17/99\n",
      "training Loss: 0.0108 Acc: 84.7589\n",
      "validation Loss: 0.0104 Acc: 85.2892\n",
      "Saving..\n",
      "Epoch 18/99\n",
      "training Loss: 0.0108 Acc: 84.8006\n",
      "validation Loss: 0.0103 Acc: 85.4082\n",
      "Saving..\n",
      "Epoch 19/99\n",
      "training Loss: 0.0107 Acc: 84.7351\n",
      "validation Loss: 0.0103 Acc: 85.4558\n",
      "Saving..\n",
      "Epoch 20/99\n",
      "training Loss: 0.0107 Acc: 84.8006\n",
      "validation Loss: 0.0104 Acc: 85.3844\n",
      "Epoch 21/99\n",
      "training Loss: 0.0107 Acc: 84.8661\n",
      "validation Loss: 0.0103 Acc: 85.3368\n",
      "Epoch 22/99\n",
      "training Loss: 0.0107 Acc: 84.8482\n",
      "validation Loss: 0.0102 Acc: 85.6106\n",
      "Saving..\n",
      "Epoch 23/99\n",
      "training Loss: 0.0107 Acc: 84.8750\n",
      "validation Loss: 0.0102 Acc: 85.4677\n",
      "Epoch 24/99\n",
      "training Loss: 0.0107 Acc: 85.0119\n",
      "validation Loss: 0.0102 Acc: 85.7891\n",
      "Saving..\n",
      "Epoch 25/99\n",
      "training Loss: 0.0106 Acc: 84.9821\n",
      "validation Loss: 0.0102 Acc: 85.8010\n",
      "Saving..\n",
      "Epoch 26/99\n",
      "training Loss: 0.0106 Acc: 85.1131\n",
      "validation Loss: 0.0102 Acc: 85.6939\n",
      "Epoch 27/99\n",
      "training Loss: 0.0106 Acc: 85.1071\n",
      "validation Loss: 0.0102 Acc: 85.6106\n",
      "Epoch 28/99\n",
      "training Loss: 0.0106 Acc: 85.1131\n",
      "validation Loss: 0.0102 Acc: 85.8486\n",
      "Saving..\n",
      "Epoch 29/99\n",
      "training Loss: 0.0106 Acc: 85.0208\n",
      "validation Loss: 0.0102 Acc: 85.6582\n",
      "Epoch 30/99\n",
      "training Loss: 0.0105 Acc: 85.1399\n",
      "validation Loss: 0.0101 Acc: 85.7296\n",
      "Epoch 31/99\n",
      "training Loss: 0.0105 Acc: 85.1696\n",
      "validation Loss: 0.0101 Acc: 85.7415\n",
      "Epoch 32/99\n",
      "training Loss: 0.0105 Acc: 85.2113\n",
      "validation Loss: 0.0101 Acc: 85.7415\n",
      "Epoch 33/99\n",
      "training Loss: 0.0105 Acc: 85.2470\n",
      "validation Loss: 0.0101 Acc: 85.8129\n",
      "Epoch 34/99\n",
      "training Loss: 0.0105 Acc: 85.1280\n",
      "validation Loss: 0.0100 Acc: 85.8129\n",
      "Epoch 35/99\n",
      "training Loss: 0.0105 Acc: 85.1935\n",
      "validation Loss: 0.0101 Acc: 85.7296\n",
      "Epoch 36/99\n",
      "training Loss: 0.0105 Acc: 85.2976\n",
      "validation Loss: 0.0101 Acc: 85.8010\n",
      "Epoch 37/99\n",
      "training Loss: 0.0105 Acc: 85.3155\n",
      "validation Loss: 0.0101 Acc: 85.9319\n",
      "Saving..\n",
      "Epoch 38/99\n",
      "training Loss: 0.0104 Acc: 85.3155\n",
      "validation Loss: 0.0100 Acc: 85.8129\n",
      "Epoch 39/99\n",
      "training Loss: 0.0104 Acc: 85.4077\n",
      "validation Loss: 0.0101 Acc: 85.9795\n",
      "Saving..\n",
      "Epoch 40/99\n",
      "training Loss: 0.0104 Acc: 85.4792\n",
      "validation Loss: 0.0100 Acc: 85.8605\n",
      "Epoch 41/99\n",
      "training Loss: 0.0104 Acc: 85.5030\n",
      "validation Loss: 0.0100 Acc: 86.0152\n",
      "Saving..\n",
      "Epoch 42/99\n",
      "training Loss: 0.0104 Acc: 85.4940\n",
      "validation Loss: 0.0100 Acc: 85.9795\n",
      "Epoch 43/99\n",
      "training Loss: 0.0104 Acc: 85.5506\n",
      "validation Loss: 0.0100 Acc: 85.9676\n",
      "Epoch 44/99\n",
      "training Loss: 0.0104 Acc: 85.4345\n",
      "validation Loss: 0.0100 Acc: 85.9438\n",
      "Epoch 45/99\n",
      "training Loss: 0.0104 Acc: 85.6012\n",
      "validation Loss: 0.0100 Acc: 85.7534\n",
      "Epoch 46/99\n",
      "training Loss: 0.0104 Acc: 85.5387\n",
      "validation Loss: 0.0100 Acc: 85.8843\n",
      "Epoch 47/99\n",
      "training Loss: 0.0103 Acc: 85.5298\n",
      "validation Loss: 0.0100 Acc: 86.1343\n",
      "Saving..\n",
      "Epoch 48/99\n",
      "training Loss: 0.0103 Acc: 85.6161\n",
      "validation Loss: 0.0099 Acc: 85.9557\n",
      "Epoch 49/99\n",
      "training Loss: 0.0103 Acc: 85.5714\n",
      "validation Loss: 0.0099 Acc: 85.9676\n",
      "Epoch 50/99\n",
      "training Loss: 0.0103 Acc: 85.6369\n",
      "validation Loss: 0.0099 Acc: 86.0390\n",
      "Epoch 51/99\n",
      "training Loss: 0.0103 Acc: 85.7054\n",
      "validation Loss: 0.0099 Acc: 85.9676\n",
      "Epoch 52/99\n",
      "training Loss: 0.0103 Acc: 85.6161\n",
      "validation Loss: 0.0099 Acc: 86.0152\n",
      "Epoch 53/99\n",
      "training Loss: 0.0103 Acc: 85.6667\n",
      "validation Loss: 0.0099 Acc: 86.0509\n",
      "Epoch 54/99\n",
      "training Loss: 0.0103 Acc: 85.6994\n",
      "validation Loss: 0.0099 Acc: 86.0509\n",
      "Epoch 55/99\n",
      "training Loss: 0.0103 Acc: 85.7202\n",
      "validation Loss: 0.0099 Acc: 86.1343\n",
      "Epoch 56/99\n",
      "training Loss: 0.0103 Acc: 85.7232\n",
      "validation Loss: 0.0100 Acc: 85.7296\n",
      "Epoch 57/99\n",
      "training Loss: 0.0103 Acc: 85.7679\n",
      "validation Loss: 0.0099 Acc: 86.0390\n",
      "Early stopped.\n",
      "Best val acc: 86.134254\n",
      "----------\n",
      "Epoch 0/99\n",
      "training Loss: 0.0152 Acc: 77.9835\n",
      "validation Loss: 0.0125 Acc: 81.9048\n",
      "Saving..\n",
      "Epoch 1/99\n",
      "training Loss: 0.0120 Acc: 82.8969\n",
      "validation Loss: 0.0122 Acc: 82.5119\n",
      "Saving..\n",
      "Epoch 2/99\n",
      "training Loss: 0.0118 Acc: 83.2123\n",
      "validation Loss: 0.0122 Acc: 83.1071\n",
      "Saving..\n",
      "Epoch 3/99\n",
      "training Loss: 0.0118 Acc: 83.2927\n",
      "validation Loss: 0.0120 Acc: 83.3571\n",
      "Saving..\n",
      "Epoch 4/99\n",
      "training Loss: 0.0117 Acc: 83.3909\n",
      "validation Loss: 0.0119 Acc: 83.4286\n",
      "Saving..\n",
      "Epoch 5/99\n",
      "training Loss: 0.0116 Acc: 83.6170\n",
      "validation Loss: 0.0119 Acc: 83.5476\n",
      "Saving..\n",
      "Epoch 6/99\n",
      "training Loss: 0.0116 Acc: 83.6944\n",
      "validation Loss: 0.0118 Acc: 83.6429\n",
      "Saving..\n",
      "Epoch 7/99\n",
      "training Loss: 0.0115 Acc: 83.7956\n",
      "validation Loss: 0.0118 Acc: 83.8214\n",
      "Saving..\n",
      "Epoch 8/99\n",
      "training Loss: 0.0114 Acc: 83.8492\n",
      "validation Loss: 0.0115 Acc: 83.9762\n",
      "Saving..\n",
      "Epoch 9/99\n",
      "training Loss: 0.0113 Acc: 84.1438\n",
      "validation Loss: 0.0114 Acc: 83.9286\n",
      "Epoch 10/99\n",
      "training Loss: 0.0111 Acc: 84.3908\n",
      "validation Loss: 0.0113 Acc: 83.9762\n",
      "Epoch 11/99\n",
      "training Loss: 0.0109 Acc: 84.6765\n",
      "validation Loss: 0.0112 Acc: 84.1429\n",
      "Saving..\n",
      "Epoch 12/99\n",
      "training Loss: 0.0109 Acc: 84.7836\n",
      "validation Loss: 0.0110 Acc: 84.2619\n",
      "Saving..\n",
      "Epoch 13/99\n",
      "training Loss: 0.0108 Acc: 84.8075\n",
      "validation Loss: 0.0109 Acc: 84.3571\n",
      "Saving..\n",
      "Epoch 14/99\n",
      "training Loss: 0.0107 Acc: 84.8997\n",
      "validation Loss: 0.0109 Acc: 84.5119\n",
      "Saving..\n",
      "Epoch 15/99\n",
      "training Loss: 0.0107 Acc: 84.9265\n",
      "validation Loss: 0.0109 Acc: 84.3333\n",
      "Epoch 16/99\n",
      "training Loss: 0.0107 Acc: 84.8580\n",
      "validation Loss: 0.0108 Acc: 84.4524\n",
      "Epoch 17/99\n",
      "training Loss: 0.0107 Acc: 84.9830\n",
      "validation Loss: 0.0108 Acc: 84.5476\n",
      "Saving..\n",
      "Epoch 18/99\n",
      "training Loss: 0.0106 Acc: 85.0128\n",
      "validation Loss: 0.0108 Acc: 84.5238\n",
      "Epoch 19/99\n",
      "training Loss: 0.0106 Acc: 85.0723\n",
      "validation Loss: 0.0108 Acc: 84.4762\n",
      "Epoch 20/99\n",
      "training Loss: 0.0106 Acc: 85.1824\n",
      "validation Loss: 0.0108 Acc: 84.5714\n",
      "Saving..\n",
      "Epoch 21/99\n",
      "training Loss: 0.0106 Acc: 85.0693\n",
      "validation Loss: 0.0108 Acc: 84.6667\n",
      "Saving..\n",
      "Epoch 22/99\n",
      "training Loss: 0.0106 Acc: 85.0664\n",
      "validation Loss: 0.0108 Acc: 84.5714\n",
      "Epoch 23/99\n",
      "training Loss: 0.0105 Acc: 85.0783\n",
      "validation Loss: 0.0108 Acc: 84.7738\n",
      "Saving..\n",
      "Epoch 24/99\n",
      "training Loss: 0.0105 Acc: 85.2598\n",
      "validation Loss: 0.0107 Acc: 84.8690\n",
      "Saving..\n",
      "Epoch 25/99\n",
      "training Loss: 0.0105 Acc: 85.1795\n",
      "validation Loss: 0.0108 Acc: 84.7857\n",
      "Epoch 26/99\n",
      "training Loss: 0.0105 Acc: 85.1884\n",
      "validation Loss: 0.0107 Acc: 84.8452\n",
      "Epoch 27/99\n",
      "training Loss: 0.0105 Acc: 85.3134\n",
      "validation Loss: 0.0107 Acc: 84.9643\n",
      "Saving..\n",
      "Epoch 28/99\n",
      "training Loss: 0.0105 Acc: 85.3104\n",
      "validation Loss: 0.0107 Acc: 84.9762\n",
      "Saving..\n",
      "Epoch 29/99\n",
      "training Loss: 0.0105 Acc: 85.3997\n",
      "validation Loss: 0.0106 Acc: 85.0833\n",
      "Saving..\n",
      "Epoch 30/99\n",
      "training Loss: 0.0105 Acc: 85.2925\n",
      "validation Loss: 0.0107 Acc: 84.9881\n",
      "Epoch 31/99\n",
      "training Loss: 0.0105 Acc: 85.3104\n",
      "validation Loss: 0.0106 Acc: 85.1429\n",
      "Saving..\n",
      "Epoch 32/99\n",
      "training Loss: 0.0104 Acc: 85.2925\n",
      "validation Loss: 0.0106 Acc: 84.9643\n",
      "Epoch 33/99\n",
      "training Loss: 0.0104 Acc: 85.4949\n",
      "validation Loss: 0.0106 Acc: 84.9405\n",
      "Epoch 34/99\n",
      "training Loss: 0.0104 Acc: 85.4860\n",
      "validation Loss: 0.0106 Acc: 85.0595\n",
      "Epoch 35/99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Loss: 0.0104 Acc: 85.3848\n",
      "validation Loss: 0.0106 Acc: 84.8095\n",
      "Epoch 36/99\n",
      "training Loss: 0.0104 Acc: 85.3908\n",
      "validation Loss: 0.0106 Acc: 85.1786\n",
      "Saving..\n",
      "Epoch 37/99\n",
      "training Loss: 0.0104 Acc: 85.4503\n",
      "validation Loss: 0.0106 Acc: 85.1310\n",
      "Epoch 38/99\n",
      "training Loss: 0.0104 Acc: 85.3908\n",
      "validation Loss: 0.0105 Acc: 85.2381\n",
      "Saving..\n",
      "Epoch 39/99\n",
      "training Loss: 0.0104 Acc: 85.5396\n",
      "validation Loss: 0.0105 Acc: 85.0357\n",
      "Epoch 40/99\n",
      "training Loss: 0.0103 Acc: 85.5306\n",
      "validation Loss: 0.0105 Acc: 85.0833\n",
      "Epoch 41/99\n",
      "training Loss: 0.0104 Acc: 85.5038\n",
      "validation Loss: 0.0106 Acc: 85.0952\n",
      "Epoch 42/99\n",
      "training Loss: 0.0104 Acc: 85.6199\n",
      "validation Loss: 0.0105 Acc: 85.0833\n",
      "Epoch 43/99\n",
      "training Loss: 0.0103 Acc: 85.4622\n",
      "validation Loss: 0.0106 Acc: 85.0119\n",
      "Epoch 44/99\n",
      "training Loss: 0.0103 Acc: 85.5396\n",
      "validation Loss: 0.0105 Acc: 85.2024\n",
      "Epoch 45/99\n",
      "training Loss: 0.0103 Acc: 85.6140\n",
      "validation Loss: 0.0106 Acc: 84.8690\n",
      "Epoch 46/99\n",
      "training Loss: 0.0103 Acc: 85.6050\n",
      "validation Loss: 0.0105 Acc: 85.1667\n",
      "Epoch 47/99\n",
      "training Loss: 0.0103 Acc: 85.6199\n",
      "validation Loss: 0.0105 Acc: 85.2024\n",
      "Epoch 48/99\n",
      "training Loss: 0.0103 Acc: 85.6407\n",
      "validation Loss: 0.0105 Acc: 85.1310\n",
      "Early stopped.\n",
      "Best val acc: 85.238095\n",
      "----------\n",
      "Epoch 0/99\n",
      "training Loss: 0.0153 Acc: 79.5965\n",
      "validation Loss: 0.0127 Acc: 81.5119\n",
      "Saving..\n",
      "Epoch 1/99\n",
      "training Loss: 0.0120 Acc: 82.9504\n",
      "validation Loss: 0.0125 Acc: 81.9881\n",
      "Saving..\n",
      "Epoch 2/99\n",
      "training Loss: 0.0118 Acc: 83.4206\n",
      "validation Loss: 0.0123 Acc: 82.7500\n",
      "Saving..\n",
      "Epoch 3/99\n",
      "training Loss: 0.0117 Acc: 83.6022\n",
      "validation Loss: 0.0123 Acc: 82.5238\n",
      "Epoch 4/99\n",
      "training Loss: 0.0117 Acc: 83.6379\n",
      "validation Loss: 0.0125 Acc: 82.0833\n",
      "Epoch 5/99\n",
      "training Loss: 0.0116 Acc: 83.7539\n",
      "validation Loss: 0.0121 Acc: 82.9405\n",
      "Saving..\n",
      "Epoch 6/99\n",
      "training Loss: 0.0115 Acc: 83.7658\n",
      "validation Loss: 0.0120 Acc: 83.0714\n",
      "Saving..\n",
      "Epoch 7/99\n",
      "training Loss: 0.0114 Acc: 83.9980\n",
      "validation Loss: 0.0119 Acc: 83.1667\n",
      "Saving..\n",
      "Epoch 8/99\n",
      "training Loss: 0.0113 Acc: 84.1140\n",
      "validation Loss: 0.0118 Acc: 83.3571\n",
      "Saving..\n",
      "Epoch 9/99\n",
      "training Loss: 0.0112 Acc: 84.2628\n",
      "validation Loss: 0.0116 Acc: 83.4643\n",
      "Saving..\n",
      "Epoch 10/99\n",
      "training Loss: 0.0111 Acc: 84.3819\n",
      "validation Loss: 0.0115 Acc: 83.6905\n",
      "Saving..\n",
      "Epoch 11/99\n",
      "training Loss: 0.0109 Acc: 84.4384\n",
      "validation Loss: 0.0114 Acc: 83.9405\n",
      "Saving..\n",
      "Epoch 12/99\n",
      "training Loss: 0.0109 Acc: 84.5277\n",
      "validation Loss: 0.0115 Acc: 83.7976\n",
      "Epoch 13/99\n",
      "training Loss: 0.0108 Acc: 84.7271\n",
      "validation Loss: 0.0113 Acc: 84.1429\n",
      "Saving..\n",
      "Epoch 14/99\n",
      "training Loss: 0.0108 Acc: 84.7390\n",
      "validation Loss: 0.0112 Acc: 84.2143\n",
      "Saving..\n",
      "Epoch 15/99\n",
      "training Loss: 0.0107 Acc: 84.8997\n",
      "validation Loss: 0.0112 Acc: 84.2381\n",
      "Saving..\n",
      "Epoch 16/99\n",
      "training Loss: 0.0107 Acc: 84.8640\n",
      "validation Loss: 0.0112 Acc: 84.1429\n",
      "Epoch 17/99\n",
      "training Loss: 0.0107 Acc: 84.9592\n",
      "validation Loss: 0.0111 Acc: 84.3214\n",
      "Saving..\n",
      "Epoch 18/99\n",
      "training Loss: 0.0107 Acc: 84.9682\n",
      "validation Loss: 0.0111 Acc: 84.2262\n",
      "Epoch 19/99\n",
      "training Loss: 0.0106 Acc: 85.0277\n",
      "validation Loss: 0.0111 Acc: 84.3452\n",
      "Saving..\n",
      "Epoch 20/99\n",
      "training Loss: 0.0106 Acc: 85.0128\n",
      "validation Loss: 0.0110 Acc: 84.4167\n",
      "Saving..\n",
      "Epoch 21/99\n",
      "training Loss: 0.0106 Acc: 84.9949\n",
      "validation Loss: 0.0110 Acc: 84.4405\n",
      "Saving..\n",
      "Epoch 22/99\n",
      "training Loss: 0.0106 Acc: 85.0931\n",
      "validation Loss: 0.0110 Acc: 84.5833\n",
      "Saving..\n",
      "Epoch 23/99\n",
      "training Loss: 0.0105 Acc: 84.9682\n",
      "validation Loss: 0.0110 Acc: 84.5714\n",
      "Epoch 24/99\n",
      "training Loss: 0.0106 Acc: 85.0664\n",
      "validation Loss: 0.0109 Acc: 84.5357\n",
      "Epoch 25/99\n",
      "training Loss: 0.0105 Acc: 85.0574\n",
      "validation Loss: 0.0109 Acc: 84.7143\n",
      "Saving..\n",
      "Epoch 26/99\n",
      "training Loss: 0.0105 Acc: 85.1021\n",
      "validation Loss: 0.0109 Acc: 84.7143\n",
      "Epoch 27/99\n",
      "training Loss: 0.0105 Acc: 85.0426\n",
      "validation Loss: 0.0109 Acc: 84.6071\n",
      "Epoch 28/99\n",
      "training Loss: 0.0105 Acc: 85.1795\n",
      "validation Loss: 0.0109 Acc: 84.7500\n",
      "Saving..\n",
      "Epoch 29/99\n",
      "training Loss: 0.0104 Acc: 85.1795\n",
      "validation Loss: 0.0109 Acc: 84.7024\n",
      "Epoch 30/99\n",
      "training Loss: 0.0104 Acc: 85.3104\n",
      "validation Loss: 0.0109 Acc: 84.8571\n",
      "Saving..\n",
      "Epoch 31/99\n",
      "training Loss: 0.0104 Acc: 85.3044\n",
      "validation Loss: 0.0108 Acc: 84.8929\n",
      "Saving..\n",
      "Epoch 32/99\n",
      "training Loss: 0.0104 Acc: 85.3759\n",
      "validation Loss: 0.0108 Acc: 84.8214\n",
      "Epoch 33/99\n",
      "training Loss: 0.0104 Acc: 85.2658\n",
      "validation Loss: 0.0108 Acc: 84.7024\n",
      "Epoch 34/99\n",
      "training Loss: 0.0104 Acc: 85.4175\n",
      "validation Loss: 0.0108 Acc: 84.8690\n",
      "Epoch 35/99\n",
      "training Loss: 0.0104 Acc: 85.4443\n",
      "validation Loss: 0.0108 Acc: 84.8810\n",
      "Epoch 36/99\n",
      "training Loss: 0.0104 Acc: 85.3699\n",
      "validation Loss: 0.0108 Acc: 84.9048\n",
      "Saving..\n",
      "Epoch 37/99\n",
      "training Loss: 0.0104 Acc: 85.4056\n",
      "validation Loss: 0.0108 Acc: 84.9524\n",
      "Saving..\n",
      "Epoch 38/99\n",
      "training Loss: 0.0103 Acc: 85.4771\n",
      "validation Loss: 0.0108 Acc: 84.9881\n",
      "Saving..\n",
      "Epoch 39/99\n",
      "training Loss: 0.0103 Acc: 85.4890\n",
      "validation Loss: 0.0107 Acc: 84.9762\n",
      "Epoch 40/99\n",
      "training Loss: 0.0103 Acc: 85.5931\n",
      "validation Loss: 0.0107 Acc: 84.9286\n",
      "Epoch 41/99\n",
      "training Loss: 0.0103 Acc: 85.5396\n",
      "validation Loss: 0.0107 Acc: 84.9881\n",
      "Epoch 42/99\n",
      "training Loss: 0.0103 Acc: 85.5306\n",
      "validation Loss: 0.0107 Acc: 84.9405\n",
      "Epoch 43/99\n",
      "training Loss: 0.0103 Acc: 85.5872\n",
      "validation Loss: 0.0107 Acc: 85.0714\n",
      "Saving..\n",
      "Epoch 44/99\n",
      "training Loss: 0.0103 Acc: 85.6735\n",
      "validation Loss: 0.0107 Acc: 85.0952\n",
      "Saving..\n",
      "Epoch 45/99\n",
      "training Loss: 0.0103 Acc: 85.6050\n",
      "validation Loss: 0.0106 Acc: 85.1905\n",
      "Saving..\n",
      "Epoch 46/99\n",
      "training Loss: 0.0102 Acc: 85.5663\n",
      "validation Loss: 0.0107 Acc: 85.2024\n",
      "Saving..\n",
      "Epoch 47/99\n",
      "training Loss: 0.0102 Acc: 85.6586\n",
      "validation Loss: 0.0107 Acc: 85.1429\n",
      "Epoch 48/99\n",
      "training Loss: 0.0102 Acc: 85.5991\n",
      "validation Loss: 0.0106 Acc: 85.3095\n",
      "Saving..\n",
      "Epoch 49/99\n",
      "training Loss: 0.0102 Acc: 85.6467\n",
      "validation Loss: 0.0106 Acc: 85.1548\n",
      "Epoch 50/99\n",
      "training Loss: 0.0102 Acc: 85.6110\n",
      "validation Loss: 0.0107 Acc: 84.9167\n",
      "Epoch 51/99\n",
      "training Loss: 0.0102 Acc: 85.6467\n",
      "validation Loss: 0.0106 Acc: 85.3929\n",
      "Saving..\n",
      "Epoch 52/99\n",
      "training Loss: 0.0102 Acc: 85.7270\n",
      "validation Loss: 0.0106 Acc: 85.3571\n",
      "Epoch 53/99\n",
      "training Loss: 0.0102 Acc: 85.7598\n",
      "validation Loss: 0.0107 Acc: 85.1429\n",
      "Epoch 54/99\n",
      "training Loss: 0.0102 Acc: 85.6437\n",
      "validation Loss: 0.0106 Acc: 85.2738\n",
      "Epoch 55/99\n",
      "training Loss: 0.0101 Acc: 85.6794\n",
      "validation Loss: 0.0106 Acc: 85.2262\n",
      "Epoch 56/99\n",
      "training Loss: 0.0101 Acc: 85.7151\n",
      "validation Loss: 0.0106 Acc: 85.1786\n",
      "Epoch 57/99\n",
      "training Loss: 0.0102 Acc: 85.7479\n",
      "validation Loss: 0.0106 Acc: 85.2024\n",
      "Epoch 58/99\n",
      "training Loss: 0.0101 Acc: 85.7955\n",
      "validation Loss: 0.0106 Acc: 85.0357\n",
      "Epoch 59/99\n",
      "training Loss: 0.0101 Acc: 85.7925\n",
      "validation Loss: 0.0106 Acc: 85.3690\n",
      "Epoch 60/99\n",
      "training Loss: 0.0101 Acc: 85.8193\n",
      "validation Loss: 0.0106 Acc: 85.1310\n",
      "Epoch 61/99\n",
      "training Loss: 0.0101 Acc: 85.7479\n",
      "validation Loss: 0.0105 Acc: 85.4286\n",
      "Saving..\n",
      "Epoch 62/99\n",
      "training Loss: 0.0101 Acc: 85.8461\n",
      "validation Loss: 0.0105 Acc: 85.4405\n",
      "Saving..\n",
      "Epoch 63/99\n",
      "training Loss: 0.0101 Acc: 85.7687\n",
      "validation Loss: 0.0105 Acc: 85.4524\n",
      "Saving..\n",
      "Epoch 64/99\n",
      "training Loss: 0.0101 Acc: 85.8312\n",
      "validation Loss: 0.0106 Acc: 85.4405\n",
      "Epoch 65/99\n",
      "training Loss: 0.0101 Acc: 85.7866\n",
      "validation Loss: 0.0105 Acc: 85.5119\n",
      "Saving..\n",
      "Epoch 66/99\n",
      "training Loss: 0.0101 Acc: 85.7985\n",
      "validation Loss: 0.0106 Acc: 85.2024\n",
      "Epoch 67/99\n",
      "training Loss: 0.0101 Acc: 85.8342\n",
      "validation Loss: 0.0105 Acc: 85.5000\n",
      "Epoch 68/99\n",
      "training Loss: 0.0101 Acc: 85.8550\n",
      "validation Loss: 0.0105 Acc: 85.4762\n",
      "Epoch 69/99\n",
      "training Loss: 0.0101 Acc: 85.9235\n",
      "validation Loss: 0.0105 Acc: 85.4643\n",
      "Epoch 70/99\n",
      "training Loss: 0.0101 Acc: 85.8788\n",
      "validation Loss: 0.0106 Acc: 85.2262\n",
      "Epoch 71/99\n",
      "training Loss: 0.0100 Acc: 85.9026\n",
      "validation Loss: 0.0105 Acc: 85.2976\n",
      "Epoch 72/99\n",
      "training Loss: 0.0100 Acc: 85.9116\n",
      "validation Loss: 0.0105 Acc: 85.5000\n",
      "Epoch 73/99\n",
      "training Loss: 0.0100 Acc: 85.8550\n",
      "validation Loss: 0.0105 Acc: 85.3810\n",
      "Epoch 74/99\n",
      "training Loss: 0.0100 Acc: 85.9473\n",
      "validation Loss: 0.0105 Acc: 85.5119\n",
      "Epoch 75/99\n",
      "training Loss: 0.0100 Acc: 85.9711\n",
      "validation Loss: 0.0105 Acc: 85.4167\n",
      "Early stopped.\n",
      "Best val acc: 85.511905\n",
      "----------\n",
      "Epoch 0/99\n",
      "training Loss: 0.0155 Acc: 78.1293\n",
      "validation Loss: 0.0120 Acc: 82.9524\n",
      "Saving..\n",
      "Epoch 1/99\n",
      "training Loss: 0.0121 Acc: 82.6290\n",
      "validation Loss: 0.0117 Acc: 83.3333\n",
      "Saving..\n",
      "Epoch 2/99\n",
      "training Loss: 0.0119 Acc: 83.1528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation Loss: 0.0117 Acc: 83.5000\n",
      "Saving..\n",
      "Epoch 3/99\n",
      "training Loss: 0.0118 Acc: 83.3581\n",
      "validation Loss: 0.0117 Acc: 83.4524\n",
      "Epoch 4/99\n",
      "training Loss: 0.0117 Acc: 83.4534\n",
      "validation Loss: 0.0116 Acc: 84.0000\n",
      "Saving..\n",
      "Epoch 5/99\n",
      "training Loss: 0.0117 Acc: 83.6200\n",
      "validation Loss: 0.0115 Acc: 83.9524\n",
      "Epoch 6/99\n",
      "training Loss: 0.0116 Acc: 83.6409\n",
      "validation Loss: 0.0114 Acc: 84.0357\n",
      "Saving..\n",
      "Epoch 7/99\n",
      "training Loss: 0.0115 Acc: 83.7926\n",
      "validation Loss: 0.0113 Acc: 84.2738\n",
      "Saving..\n",
      "Epoch 8/99\n",
      "training Loss: 0.0113 Acc: 84.0010\n",
      "validation Loss: 0.0111 Acc: 84.4048\n",
      "Saving..\n",
      "Epoch 9/99\n",
      "training Loss: 0.0112 Acc: 84.3075\n",
      "validation Loss: 0.0111 Acc: 84.4048\n",
      "Epoch 10/99\n",
      "training Loss: 0.0110 Acc: 84.3343\n",
      "validation Loss: 0.0109 Acc: 84.6429\n",
      "Saving..\n",
      "Epoch 11/99\n",
      "training Loss: 0.0110 Acc: 84.5604\n",
      "validation Loss: 0.0108 Acc: 84.6786\n",
      "Saving..\n",
      "Epoch 12/99\n",
      "training Loss: 0.0109 Acc: 84.5753\n",
      "validation Loss: 0.0108 Acc: 84.6786\n",
      "Epoch 13/99\n",
      "training Loss: 0.0109 Acc: 84.5575\n",
      "validation Loss: 0.0108 Acc: 84.6786\n",
      "Epoch 14/99\n",
      "training Loss: 0.0108 Acc: 84.6200\n",
      "validation Loss: 0.0108 Acc: 84.6310\n",
      "Epoch 15/99\n",
      "training Loss: 0.0108 Acc: 84.6735\n",
      "validation Loss: 0.0107 Acc: 84.7857\n",
      "Saving..\n",
      "Epoch 16/99\n",
      "training Loss: 0.0108 Acc: 84.7747\n",
      "validation Loss: 0.0107 Acc: 85.0238\n",
      "Saving..\n",
      "Epoch 17/99\n",
      "training Loss: 0.0107 Acc: 84.7777\n",
      "validation Loss: 0.0108 Acc: 84.7976\n",
      "Epoch 18/99\n",
      "training Loss: 0.0107 Acc: 84.9533\n",
      "validation Loss: 0.0107 Acc: 84.8571\n",
      "Epoch 19/99\n",
      "training Loss: 0.0106 Acc: 84.8729\n",
      "validation Loss: 0.0107 Acc: 84.9643\n",
      "Epoch 20/99\n",
      "training Loss: 0.0106 Acc: 84.8908\n",
      "validation Loss: 0.0107 Acc: 84.7500\n",
      "Epoch 21/99\n",
      "training Loss: 0.0106 Acc: 84.9830\n",
      "validation Loss: 0.0107 Acc: 84.9286\n",
      "Epoch 22/99\n",
      "training Loss: 0.0106 Acc: 85.0723\n",
      "validation Loss: 0.0106 Acc: 84.9881\n",
      "Epoch 23/99\n",
      "training Loss: 0.0106 Acc: 85.1854\n",
      "validation Loss: 0.0106 Acc: 85.0119\n",
      "Epoch 24/99\n",
      "training Loss: 0.0105 Acc: 85.2062\n",
      "validation Loss: 0.0106 Acc: 84.9048\n",
      "Epoch 25/99\n",
      "training Loss: 0.0105 Acc: 85.2747\n",
      "validation Loss: 0.0106 Acc: 84.9405\n",
      "Epoch 26/99\n",
      "training Loss: 0.0105 Acc: 85.3342\n",
      "validation Loss: 0.0106 Acc: 84.9524\n",
      "Early stopped.\n",
      "Best val acc: 85.023810\n",
      "----------\n",
      "Epoch 0/99\n",
      "training Loss: 0.0154 Acc: 79.5637\n",
      "validation Loss: 0.0120 Acc: 82.7381\n",
      "Saving..\n",
      "Epoch 1/99\n",
      "training Loss: 0.0122 Acc: 82.5873\n",
      "validation Loss: 0.0117 Acc: 83.3095\n",
      "Saving..\n",
      "Epoch 2/99\n",
      "training Loss: 0.0120 Acc: 83.0546\n",
      "validation Loss: 0.0116 Acc: 83.7738\n",
      "Saving..\n",
      "Epoch 3/99\n",
      "training Loss: 0.0119 Acc: 83.1945\n",
      "validation Loss: 0.0116 Acc: 83.6786\n",
      "Epoch 4/99\n",
      "training Loss: 0.0118 Acc: 83.2837\n",
      "validation Loss: 0.0116 Acc: 84.0357\n",
      "Saving..\n",
      "Epoch 5/99\n",
      "training Loss: 0.0117 Acc: 83.3968\n",
      "validation Loss: 0.0114 Acc: 83.8929\n",
      "Epoch 6/99\n",
      "training Loss: 0.0117 Acc: 83.5099\n",
      "validation Loss: 0.0113 Acc: 84.1905\n",
      "Saving..\n",
      "Epoch 7/99\n",
      "training Loss: 0.0116 Acc: 83.5843\n",
      "validation Loss: 0.0113 Acc: 83.7619\n",
      "Epoch 8/99\n",
      "training Loss: 0.0115 Acc: 83.8045\n",
      "validation Loss: 0.0112 Acc: 83.9643\n",
      "Epoch 9/99\n",
      "training Loss: 0.0113 Acc: 84.1289\n",
      "validation Loss: 0.0111 Acc: 84.2143\n",
      "Saving..\n",
      "Epoch 10/99\n",
      "training Loss: 0.0111 Acc: 84.2331\n",
      "validation Loss: 0.0110 Acc: 84.9881\n",
      "Saving..\n",
      "Epoch 11/99\n",
      "training Loss: 0.0110 Acc: 84.4235\n",
      "validation Loss: 0.0108 Acc: 84.7619\n",
      "Epoch 12/99\n",
      "training Loss: 0.0109 Acc: 84.4831\n",
      "validation Loss: 0.0108 Acc: 84.7500\n",
      "Epoch 13/99\n",
      "training Loss: 0.0108 Acc: 84.5783\n",
      "validation Loss: 0.0108 Acc: 85.0238\n",
      "Saving..\n",
      "Epoch 14/99\n",
      "training Loss: 0.0108 Acc: 84.7360\n",
      "validation Loss: 0.0108 Acc: 84.7500\n",
      "Epoch 15/99\n",
      "training Loss: 0.0108 Acc: 84.7271\n",
      "validation Loss: 0.0108 Acc: 85.0476\n",
      "Saving..\n",
      "Epoch 16/99\n",
      "training Loss: 0.0107 Acc: 84.9027\n",
      "validation Loss: 0.0106 Acc: 84.9643\n",
      "Epoch 17/99\n",
      "training Loss: 0.0107 Acc: 84.8253\n",
      "validation Loss: 0.0106 Acc: 85.1548\n",
      "Saving..\n",
      "Epoch 18/99\n",
      "training Loss: 0.0107 Acc: 84.8610\n",
      "validation Loss: 0.0106 Acc: 85.1667\n",
      "Saving..\n",
      "Epoch 19/99\n",
      "training Loss: 0.0107 Acc: 84.9563\n",
      "validation Loss: 0.0106 Acc: 85.2143\n",
      "Saving..\n",
      "Epoch 20/99\n",
      "training Loss: 0.0107 Acc: 84.9265\n",
      "validation Loss: 0.0105 Acc: 85.2381\n",
      "Saving..\n",
      "Epoch 21/99\n",
      "training Loss: 0.0106 Acc: 84.8729\n",
      "validation Loss: 0.0105 Acc: 85.1190\n",
      "Epoch 22/99\n",
      "training Loss: 0.0106 Acc: 85.1170\n",
      "validation Loss: 0.0105 Acc: 85.2738\n",
      "Saving..\n",
      "Epoch 23/99\n",
      "training Loss: 0.0106 Acc: 85.0366\n",
      "validation Loss: 0.0105 Acc: 85.3333\n",
      "Saving..\n",
      "Epoch 24/99\n",
      "training Loss: 0.0106 Acc: 85.2033\n",
      "validation Loss: 0.0105 Acc: 85.2500\n",
      "Epoch 25/99\n",
      "training Loss: 0.0106 Acc: 85.0961\n",
      "validation Loss: 0.0105 Acc: 85.2143\n",
      "Epoch 26/99\n",
      "training Loss: 0.0106 Acc: 84.9771\n",
      "validation Loss: 0.0105 Acc: 85.3452\n",
      "Saving..\n",
      "Epoch 27/99\n",
      "training Loss: 0.0105 Acc: 85.0396\n",
      "validation Loss: 0.0105 Acc: 85.2976\n",
      "Epoch 28/99\n",
      "training Loss: 0.0105 Acc: 85.1914\n",
      "validation Loss: 0.0104 Acc: 85.3810\n",
      "Saving..\n",
      "Epoch 29/99\n",
      "training Loss: 0.0105 Acc: 85.1348\n",
      "validation Loss: 0.0104 Acc: 85.3929\n",
      "Saving..\n",
      "Epoch 30/99\n",
      "training Loss: 0.0105 Acc: 85.2241\n",
      "validation Loss: 0.0105 Acc: 85.3214\n",
      "Epoch 31/99\n",
      "training Loss: 0.0105 Acc: 85.2211\n",
      "validation Loss: 0.0104 Acc: 85.5238\n",
      "Saving..\n",
      "Epoch 32/99\n",
      "training Loss: 0.0105 Acc: 85.2330\n",
      "validation Loss: 0.0104 Acc: 85.5357\n",
      "Saving..\n",
      "Epoch 33/99\n",
      "training Loss: 0.0105 Acc: 85.3223\n",
      "validation Loss: 0.0104 Acc: 85.5595\n",
      "Saving..\n",
      "Epoch 34/99\n",
      "training Loss: 0.0105 Acc: 85.4265\n",
      "validation Loss: 0.0104 Acc: 85.4881\n",
      "Epoch 35/99\n",
      "training Loss: 0.0105 Acc: 85.3431\n",
      "validation Loss: 0.0103 Acc: 85.5357\n",
      "Epoch 36/99\n",
      "training Loss: 0.0104 Acc: 85.3312\n",
      "validation Loss: 0.0104 Acc: 85.4405\n",
      "Epoch 37/99\n",
      "training Loss: 0.0104 Acc: 85.3431\n",
      "validation Loss: 0.0103 Acc: 85.6667\n",
      "Saving..\n",
      "Epoch 38/99\n",
      "training Loss: 0.0104 Acc: 85.3640\n",
      "validation Loss: 0.0104 Acc: 85.5357\n",
      "Epoch 39/99\n",
      "training Loss: 0.0104 Acc: 85.3491\n",
      "validation Loss: 0.0103 Acc: 85.6667\n",
      "Epoch 40/99\n",
      "training Loss: 0.0104 Acc: 85.4622\n",
      "validation Loss: 0.0103 Acc: 85.6429\n",
      "Epoch 41/99\n",
      "training Loss: 0.0104 Acc: 85.4205\n",
      "validation Loss: 0.0103 Acc: 85.5595\n",
      "Epoch 42/99\n",
      "training Loss: 0.0104 Acc: 85.5247\n",
      "validation Loss: 0.0103 Acc: 85.7738\n",
      "Saving..\n",
      "Epoch 43/99\n",
      "training Loss: 0.0103 Acc: 85.4473\n",
      "validation Loss: 0.0104 Acc: 85.6548\n",
      "Epoch 44/99\n",
      "training Loss: 0.0103 Acc: 85.4919\n",
      "validation Loss: 0.0103 Acc: 85.7500\n",
      "Epoch 45/99\n",
      "training Loss: 0.0104 Acc: 85.5187\n",
      "validation Loss: 0.0103 Acc: 85.7143\n",
      "Epoch 46/99\n",
      "training Loss: 0.0103 Acc: 85.5901\n",
      "validation Loss: 0.0102 Acc: 85.7857\n",
      "Saving..\n",
      "Epoch 47/99\n",
      "training Loss: 0.0103 Acc: 85.5485\n",
      "validation Loss: 0.0102 Acc: 85.8690\n",
      "Saving..\n",
      "Epoch 48/99\n",
      "training Loss: 0.0103 Acc: 85.6645\n",
      "validation Loss: 0.0102 Acc: 85.8690\n",
      "Epoch 49/99\n",
      "training Loss: 0.0103 Acc: 85.6318\n",
      "validation Loss: 0.0102 Acc: 85.8452\n",
      "Epoch 50/99\n",
      "training Loss: 0.0103 Acc: 85.6943\n",
      "validation Loss: 0.0102 Acc: 85.8333\n",
      "Epoch 51/99\n",
      "training Loss: 0.0103 Acc: 85.6050\n",
      "validation Loss: 0.0102 Acc: 85.9405\n",
      "Saving..\n",
      "Epoch 52/99\n",
      "training Loss: 0.0103 Acc: 85.7032\n",
      "validation Loss: 0.0102 Acc: 85.9167\n",
      "Epoch 53/99\n",
      "training Loss: 0.0103 Acc: 85.5396\n",
      "validation Loss: 0.0102 Acc: 85.8929\n",
      "Epoch 54/99\n",
      "training Loss: 0.0102 Acc: 85.6378\n",
      "validation Loss: 0.0102 Acc: 86.0119\n",
      "Saving..\n",
      "Epoch 55/99\n",
      "training Loss: 0.0103 Acc: 85.6437\n",
      "validation Loss: 0.0101 Acc: 86.0238\n",
      "Saving..\n",
      "Epoch 56/99\n",
      "training Loss: 0.0102 Acc: 85.6467\n",
      "validation Loss: 0.0102 Acc: 86.0238\n",
      "Epoch 57/99\n",
      "training Loss: 0.0102 Acc: 85.7211\n",
      "validation Loss: 0.0101 Acc: 86.0595\n",
      "Saving..\n",
      "Epoch 58/99\n",
      "training Loss: 0.0102 Acc: 85.7181\n",
      "validation Loss: 0.0102 Acc: 86.0119\n",
      "Epoch 59/99\n",
      "training Loss: 0.0102 Acc: 85.8996\n",
      "validation Loss: 0.0102 Acc: 86.1667\n",
      "Saving..\n",
      "Epoch 60/99\n",
      "training Loss: 0.0102 Acc: 85.7241\n",
      "validation Loss: 0.0102 Acc: 86.2262\n",
      "Saving..\n",
      "Epoch 61/99\n",
      "training Loss: 0.0102 Acc: 85.8282\n",
      "validation Loss: 0.0101 Acc: 86.0119\n",
      "Epoch 62/99\n",
      "training Loss: 0.0102 Acc: 85.7895\n",
      "validation Loss: 0.0101 Acc: 86.0952\n",
      "Epoch 63/99\n",
      "training Loss: 0.0102 Acc: 85.7330\n",
      "validation Loss: 0.0101 Acc: 85.9048\n",
      "Epoch 64/99\n",
      "training Loss: 0.0102 Acc: 85.8014\n",
      "validation Loss: 0.0101 Acc: 85.9643\n",
      "Epoch 65/99\n",
      "training Loss: 0.0101 Acc: 85.8907\n",
      "validation Loss: 0.0101 Acc: 86.2143\n",
      "Epoch 66/99\n",
      "training Loss: 0.0101 Acc: 85.8342\n",
      "validation Loss: 0.0101 Acc: 85.9881\n",
      "Epoch 67/99\n",
      "training Loss: 0.0101 Acc: 85.7419\n",
      "validation Loss: 0.0101 Acc: 85.9643\n",
      "Epoch 68/99\n",
      "training Loss: 0.0101 Acc: 85.7776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation Loss: 0.0101 Acc: 86.0833\n",
      "Epoch 69/99\n",
      "training Loss: 0.0101 Acc: 85.8788\n",
      "validation Loss: 0.0101 Acc: 86.0595\n",
      "Epoch 70/99\n",
      "training Loss: 0.0101 Acc: 85.8252\n",
      "validation Loss: 0.0101 Acc: 86.2024\n",
      "Early stopped.\n",
      "Best val acc: 86.226190\n",
      "----------\n",
      "Average best_acc across k-fold: 85.6268507498\n",
      "New configuration: {'hidden_layers': 2, 'dropout_g': 0.3612177236562843, 'initial_nodes': 500, 'dropout': 0.01, 'gru_layers': 3, 'batch_size': 32, 'gru_size': 500, 'learning_rate': 0.0004688074614206375}\n",
      "Epoch 0/99\n",
      "training Loss: 0.0118 Acc: 83.2827\n",
      "validation Loss: 0.0114 Acc: 83.8967\n",
      "Saving..\n",
      "Epoch 1/99\n",
      "training Loss: 0.0107 Acc: 84.8988\n",
      "validation Loss: 0.0108 Acc: 84.5394\n",
      "Saving..\n",
      "Epoch 2/99\n",
      "training Loss: 0.0105 Acc: 85.2827\n",
      "validation Loss: 0.0108 Acc: 84.7893\n",
      "Saving..\n",
      "Epoch 3/99\n",
      "training Loss: 0.0104 Acc: 85.4345\n",
      "validation Loss: 0.0106 Acc: 85.1821\n",
      "Saving..\n",
      "Epoch 4/99\n",
      "training Loss: 0.0102 Acc: 85.7857\n",
      "validation Loss: 0.0107 Acc: 85.1226\n",
      "Epoch 5/99\n",
      "training Loss: 0.0102 Acc: 85.7173\n",
      "validation Loss: 0.0106 Acc: 85.0869\n",
      "Epoch 6/99\n",
      "training Loss: 0.0101 Acc: 85.7411\n",
      "validation Loss: 0.0106 Acc: 85.0393\n",
      "Epoch 7/99\n",
      "training Loss: 0.0101 Acc: 85.7798\n",
      "validation Loss: 0.0105 Acc: 84.9798\n",
      "Epoch 8/99\n",
      "training Loss: 0.0101 Acc: 85.7440\n",
      "validation Loss: 0.0106 Acc: 84.9679\n",
      "Epoch 9/99\n",
      "training Loss: 0.0100 Acc: 85.8661\n",
      "validation Loss: 0.0106 Acc: 85.0274\n",
      "Epoch 10/99\n",
      "training Loss: 0.0100 Acc: 86.0298\n",
      "validation Loss: 0.0106 Acc: 84.9441\n",
      "Epoch 11/99\n",
      "training Loss: 0.0099 Acc: 86.1696\n",
      "validation Loss: 0.0106 Acc: 85.0155\n",
      "Epoch 12/99\n",
      "training Loss: 0.0099 Acc: 86.1935\n",
      "validation Loss: 0.0105 Acc: 85.4439\n",
      "Saving..\n",
      "Epoch 13/99\n",
      "training Loss: 0.0099 Acc: 86.3006\n",
      "validation Loss: 0.0106 Acc: 85.0512\n",
      "Epoch 14/99\n",
      "training Loss: 0.0098 Acc: 86.1667\n",
      "validation Loss: 0.0105 Acc: 85.1226\n",
      "Epoch 15/99\n",
      "training Loss: 0.0097 Acc: 86.3423\n",
      "validation Loss: 0.0104 Acc: 85.2297\n",
      "Epoch 16/99\n",
      "training Loss: 0.0097 Acc: 86.3036\n",
      "validation Loss: 0.0104 Acc: 85.2416\n",
      "Epoch 17/99\n",
      "training Loss: 0.0097 Acc: 86.3720\n",
      "validation Loss: 0.0104 Acc: 85.1464\n",
      "Epoch 18/99\n",
      "training Loss: 0.0096 Acc: 86.4405\n",
      "validation Loss: 0.0104 Acc: 85.5987\n",
      "Saving..\n",
      "Epoch 19/99\n",
      "training Loss: 0.0096 Acc: 86.5565\n",
      "validation Loss: 0.0103 Acc: 85.7415\n",
      "Saving..\n",
      "Epoch 20/99\n",
      "training Loss: 0.0096 Acc: 86.4911\n",
      "validation Loss: 0.0104 Acc: 85.4677\n",
      "Epoch 21/99\n",
      "training Loss: 0.0095 Acc: 86.5893\n",
      "validation Loss: 0.0104 Acc: 85.5154\n",
      "Epoch 22/99\n",
      "training Loss: 0.0095 Acc: 86.7173\n",
      "validation Loss: 0.0105 Acc: 85.3487\n",
      "Epoch 23/99\n",
      "training Loss: 0.0094 Acc: 86.7411\n",
      "validation Loss: 0.0104 Acc: 85.5035\n",
      "Epoch 24/99\n",
      "training Loss: 0.0094 Acc: 86.8065\n",
      "validation Loss: 0.0107 Acc: 85.2892\n",
      "Epoch 25/99\n",
      "training Loss: 0.0093 Acc: 86.8185\n",
      "validation Loss: 0.0106 Acc: 85.2773\n",
      "Epoch 26/99\n",
      "training Loss: 0.0091 Acc: 87.2024\n",
      "validation Loss: 0.0104 Acc: 85.5749\n",
      "Epoch 27/99\n",
      "training Loss: 0.0090 Acc: 87.4405\n",
      "validation Loss: 0.0104 Acc: 85.5035\n",
      "Epoch 28/99\n",
      "training Loss: 0.0090 Acc: 87.4345\n",
      "validation Loss: 0.0105 Acc: 85.4915\n",
      "Epoch 29/99\n",
      "training Loss: 0.0089 Acc: 87.5149\n",
      "validation Loss: 0.0104 Acc: 85.5392\n",
      "Early stopped.\n",
      "Best val acc: 85.741490\n",
      "----------\n",
      "Epoch 0/99\n",
      "training Loss: 0.0117 Acc: 83.4891\n",
      "validation Loss: 0.0108 Acc: 84.8571\n",
      "Saving..\n",
      "Epoch 1/99\n",
      "training Loss: 0.0108 Acc: 84.6795\n",
      "validation Loss: 0.0108 Acc: 85.1548\n",
      "Saving..\n",
      "Epoch 2/99\n",
      "training Loss: 0.0106 Acc: 85.1854\n",
      "validation Loss: 0.0105 Acc: 85.3095\n",
      "Saving..\n",
      "Epoch 3/99\n",
      "training Loss: 0.0105 Acc: 85.3312\n",
      "validation Loss: 0.0106 Acc: 85.4405\n",
      "Saving..\n",
      "Epoch 4/99\n",
      "training Loss: 0.0104 Acc: 85.4354\n",
      "validation Loss: 0.0104 Acc: 85.5952\n",
      "Saving..\n",
      "Epoch 5/99\n",
      "training Loss: 0.0103 Acc: 85.3640\n",
      "validation Loss: 0.0106 Acc: 85.1429\n",
      "Epoch 6/99\n",
      "training Loss: 0.0102 Acc: 85.7181\n",
      "validation Loss: 0.0103 Acc: 85.3095\n",
      "Epoch 7/99\n",
      "training Loss: 0.0101 Acc: 85.6645\n",
      "validation Loss: 0.0103 Acc: 85.5119\n",
      "Epoch 8/99\n",
      "training Loss: 0.0101 Acc: 85.7776\n",
      "validation Loss: 0.0104 Acc: 85.4167\n",
      "Epoch 9/99\n",
      "training Loss: 0.0101 Acc: 85.7300\n",
      "validation Loss: 0.0104 Acc: 85.7143\n",
      "Saving..\n",
      "Epoch 10/99\n",
      "training Loss: 0.0101 Acc: 85.7389\n",
      "validation Loss: 0.0104 Acc: 85.5833\n",
      "Epoch 11/99\n",
      "training Loss: 0.0100 Acc: 85.8996\n",
      "validation Loss: 0.0102 Acc: 85.5238\n",
      "Epoch 12/99\n",
      "training Loss: 0.0100 Acc: 85.8342\n",
      "validation Loss: 0.0102 Acc: 85.4643\n",
      "Epoch 13/99\n",
      "training Loss: 0.0100 Acc: 86.0752\n",
      "validation Loss: 0.0103 Acc: 85.5595\n",
      "Epoch 14/99\n",
      "training Loss: 0.0099 Acc: 86.1853\n",
      "validation Loss: 0.0101 Acc: 85.9048\n",
      "Saving..\n",
      "Epoch 15/99\n",
      "training Loss: 0.0099 Acc: 86.0455\n",
      "validation Loss: 0.0102 Acc: 85.8095\n",
      "Epoch 16/99\n",
      "training Loss: 0.0098 Acc: 85.9294\n",
      "validation Loss: 0.0101 Acc: 86.0238\n",
      "Saving..\n",
      "Epoch 17/99\n",
      "training Loss: 0.0098 Acc: 86.2211\n",
      "validation Loss: 0.0102 Acc: 85.6310\n",
      "Epoch 18/99\n",
      "training Loss: 0.0098 Acc: 86.2330\n",
      "validation Loss: 0.0102 Acc: 85.7381\n",
      "Epoch 19/99\n",
      "training Loss: 0.0097 Acc: 86.4532\n",
      "validation Loss: 0.0103 Acc: 85.8452\n",
      "Epoch 20/99\n",
      "training Loss: 0.0096 Acc: 86.4949\n",
      "validation Loss: 0.0103 Acc: 85.6310\n",
      "Epoch 21/99\n",
      "training Loss: 0.0096 Acc: 86.4919\n",
      "validation Loss: 0.0103 Acc: 85.5000\n",
      "Epoch 22/99\n",
      "training Loss: 0.0096 Acc: 86.3996\n",
      "validation Loss: 0.0102 Acc: 85.8571\n",
      "Epoch 23/99\n",
      "training Loss: 0.0093 Acc: 86.8936\n",
      "validation Loss: 0.0100 Acc: 86.1786\n",
      "Saving..\n",
      "Epoch 24/99\n",
      "training Loss: 0.0093 Acc: 86.8579\n",
      "validation Loss: 0.0100 Acc: 86.2857\n",
      "Saving..\n",
      "Epoch 25/99\n",
      "training Loss: 0.0093 Acc: 86.9472\n",
      "validation Loss: 0.0101 Acc: 85.9405\n",
      "Epoch 26/99\n",
      "training Loss: 0.0092 Acc: 87.1317\n",
      "validation Loss: 0.0101 Acc: 85.8690\n",
      "Epoch 27/99\n",
      "training Loss: 0.0091 Acc: 87.1109\n",
      "validation Loss: 0.0101 Acc: 86.0595\n",
      "Epoch 28/99\n",
      "training Loss: 0.0091 Acc: 87.1168\n",
      "validation Loss: 0.0102 Acc: 86.0952\n",
      "Epoch 29/99\n",
      "training Loss: 0.0090 Acc: 87.1823\n",
      "validation Loss: 0.0103 Acc: 85.9286\n",
      "Epoch 30/99\n",
      "training Loss: 0.0090 Acc: 87.3103\n",
      "validation Loss: 0.0103 Acc: 85.8571\n",
      "Epoch 31/99\n",
      "training Loss: 0.0088 Acc: 87.6704\n",
      "validation Loss: 0.0103 Acc: 86.0238\n",
      "Epoch 32/99\n",
      "training Loss: 0.0087 Acc: 87.5543\n",
      "validation Loss: 0.0103 Acc: 85.5833\n",
      "Epoch 33/99\n",
      "training Loss: 0.0087 Acc: 87.8013\n",
      "validation Loss: 0.0103 Acc: 85.7738\n",
      "Epoch 34/99\n",
      "training Loss: 0.0086 Acc: 87.8668\n",
      "validation Loss: 0.0104 Acc: 85.7738\n",
      "Early stopped.\n",
      "Best val acc: 86.285714\n",
      "----------\n",
      "Epoch 0/99\n",
      "training Loss: 0.0119 Acc: 83.4385\n",
      "validation Loss: 0.0106 Acc: 84.9286\n",
      "Saving..\n",
      "Epoch 1/99\n",
      "training Loss: 0.0109 Acc: 84.8223\n",
      "validation Loss: 0.0106 Acc: 85.2024\n",
      "Saving..\n",
      "Epoch 2/99\n",
      "training Loss: 0.0107 Acc: 85.1259\n",
      "validation Loss: 0.0101 Acc: 85.6190\n",
      "Saving..\n",
      "Epoch 3/99\n",
      "training Loss: 0.0105 Acc: 85.1259\n",
      "validation Loss: 0.0101 Acc: 85.9405\n",
      "Saving..\n",
      "Epoch 4/99\n",
      "training Loss: 0.0104 Acc: 85.5068\n",
      "validation Loss: 0.0103 Acc: 85.3929\n",
      "Epoch 5/99\n",
      "training Loss: 0.0103 Acc: 85.5068\n",
      "validation Loss: 0.0104 Acc: 85.7262\n",
      "Epoch 6/99\n",
      "training Loss: 0.0103 Acc: 85.6437\n",
      "validation Loss: 0.0101 Acc: 85.5952\n",
      "Epoch 7/99\n",
      "training Loss: 0.0103 Acc: 85.6259\n",
      "validation Loss: 0.0100 Acc: 85.8571\n",
      "Epoch 8/99\n",
      "training Loss: 0.0102 Acc: 85.6616\n",
      "validation Loss: 0.0100 Acc: 85.9405\n",
      "Epoch 9/99\n",
      "training Loss: 0.0101 Acc: 85.6705\n",
      "validation Loss: 0.0099 Acc: 85.7738\n",
      "Epoch 10/99\n",
      "training Loss: 0.0101 Acc: 85.7866\n",
      "validation Loss: 0.0099 Acc: 85.9524\n",
      "Saving..\n",
      "Epoch 11/99\n",
      "training Loss: 0.0101 Acc: 85.7985\n",
      "validation Loss: 0.0100 Acc: 85.4524\n",
      "Epoch 12/99\n",
      "training Loss: 0.0100 Acc: 85.8848\n",
      "validation Loss: 0.0100 Acc: 85.9643\n",
      "Saving..\n",
      "Epoch 13/99\n",
      "training Loss: 0.0100 Acc: 85.9264\n",
      "validation Loss: 0.0098 Acc: 85.8810\n",
      "Epoch 14/99\n",
      "training Loss: 0.0099 Acc: 85.9056\n",
      "validation Loss: 0.0099 Acc: 85.6905\n",
      "Epoch 15/99\n",
      "training Loss: 0.0099 Acc: 86.1199\n",
      "validation Loss: 0.0099 Acc: 85.7500\n",
      "Epoch 16/99\n",
      "training Loss: 0.0099 Acc: 85.9770\n",
      "validation Loss: 0.0102 Acc: 85.7262\n",
      "Epoch 17/99\n",
      "training Loss: 0.0098 Acc: 86.2181\n",
      "validation Loss: 0.0098 Acc: 86.0000\n",
      "Saving..\n",
      "Epoch 18/99\n",
      "training Loss: 0.0098 Acc: 86.2478\n",
      "validation Loss: 0.0099 Acc: 85.6667\n",
      "Epoch 19/99\n",
      "training Loss: 0.0098 Acc: 86.0068\n",
      "validation Loss: 0.0099 Acc: 85.8690\n",
      "Epoch 20/99\n",
      "training Loss: 0.0097 Acc: 86.3163\n",
      "validation Loss: 0.0101 Acc: 86.0833\n",
      "Saving..\n",
      "Epoch 21/99\n",
      "training Loss: 0.0096 Acc: 86.4264\n",
      "validation Loss: 0.0099 Acc: 86.1905\n",
      "Saving..\n",
      "Epoch 22/99\n",
      "training Loss: 0.0096 Acc: 86.2806\n",
      "validation Loss: 0.0099 Acc: 86.0357\n",
      "Epoch 23/99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Loss: 0.0096 Acc: 86.5365\n",
      "validation Loss: 0.0100 Acc: 85.9881\n",
      "Epoch 24/99\n",
      "training Loss: 0.0093 Acc: 86.9710\n",
      "validation Loss: 0.0098 Acc: 86.1905\n",
      "Epoch 25/99\n",
      "training Loss: 0.0092 Acc: 86.9651\n",
      "validation Loss: 0.0099 Acc: 85.9405\n",
      "Epoch 26/99\n",
      "training Loss: 0.0092 Acc: 87.1139\n",
      "validation Loss: 0.0100 Acc: 86.1429\n",
      "Epoch 27/99\n",
      "training Loss: 0.0091 Acc: 87.2746\n",
      "validation Loss: 0.0099 Acc: 85.9405\n",
      "Epoch 28/99\n",
      "training Loss: 0.0091 Acc: 87.2210\n",
      "validation Loss: 0.0101 Acc: 86.0000\n",
      "Epoch 29/99\n",
      "training Loss: 0.0090 Acc: 87.3638\n",
      "validation Loss: 0.0101 Acc: 85.6071\n",
      "Epoch 30/99\n",
      "training Loss: 0.0088 Acc: 87.5930\n",
      "validation Loss: 0.0101 Acc: 85.6667\n",
      "Epoch 31/99\n",
      "training Loss: 0.0087 Acc: 87.6912\n",
      "validation Loss: 0.0101 Acc: 85.6310\n",
      "Early stopped.\n",
      "Best val acc: 86.190476\n",
      "----------\n",
      "Epoch 0/99\n",
      "training Loss: 0.0118 Acc: 83.3492\n",
      "validation Loss: 0.0107 Acc: 85.0357\n",
      "Saving..\n",
      "Epoch 1/99\n",
      "training Loss: 0.0108 Acc: 84.9830\n",
      "validation Loss: 0.0105 Acc: 85.1190\n",
      "Saving..\n",
      "Epoch 2/99\n",
      "training Loss: 0.0106 Acc: 85.2628\n",
      "validation Loss: 0.0107 Acc: 84.7738\n",
      "Epoch 3/99\n",
      "training Loss: 0.0105 Acc: 85.2211\n",
      "validation Loss: 0.0105 Acc: 84.8690\n",
      "Epoch 4/99\n",
      "training Loss: 0.0104 Acc: 85.3193\n",
      "validation Loss: 0.0105 Acc: 85.2381\n",
      "Saving..\n",
      "Epoch 5/99\n",
      "training Loss: 0.0104 Acc: 85.3937\n",
      "validation Loss: 0.0104 Acc: 85.2857\n",
      "Saving..\n",
      "Epoch 6/99\n",
      "training Loss: 0.0103 Acc: 85.4086\n",
      "validation Loss: 0.0101 Acc: 85.8810\n",
      "Saving..\n",
      "Epoch 7/99\n",
      "training Loss: 0.0102 Acc: 85.5336\n",
      "validation Loss: 0.0106 Acc: 84.9286\n",
      "Epoch 8/99\n",
      "training Loss: 0.0102 Acc: 85.6288\n",
      "validation Loss: 0.0101 Acc: 85.8095\n",
      "Epoch 9/99\n",
      "training Loss: 0.0102 Acc: 85.6854\n",
      "validation Loss: 0.0100 Acc: 85.7024\n",
      "Epoch 10/99\n",
      "training Loss: 0.0101 Acc: 85.7806\n",
      "validation Loss: 0.0102 Acc: 85.3690\n",
      "Epoch 11/99\n",
      "training Loss: 0.0101 Acc: 85.8342\n",
      "validation Loss: 0.0102 Acc: 85.8333\n",
      "Epoch 12/99\n",
      "training Loss: 0.0101 Acc: 85.6794\n",
      "validation Loss: 0.0101 Acc: 85.9762\n",
      "Saving..\n",
      "Epoch 13/99\n",
      "training Loss: 0.0100 Acc: 85.8252\n",
      "validation Loss: 0.0101 Acc: 85.5119\n",
      "Epoch 14/99\n",
      "training Loss: 0.0099 Acc: 85.9830\n",
      "validation Loss: 0.0100 Acc: 85.7976\n",
      "Epoch 15/99\n",
      "training Loss: 0.0099 Acc: 86.0395\n",
      "validation Loss: 0.0101 Acc: 85.7500\n",
      "Epoch 16/99\n",
      "training Loss: 0.0097 Acc: 86.2062\n",
      "validation Loss: 0.0099 Acc: 86.1786\n",
      "Saving..\n",
      "Epoch 17/99\n",
      "training Loss: 0.0097 Acc: 86.2508\n",
      "validation Loss: 0.0099 Acc: 85.9048\n",
      "Epoch 18/99\n",
      "training Loss: 0.0096 Acc: 86.3818\n",
      "validation Loss: 0.0100 Acc: 85.8810\n",
      "Epoch 19/99\n",
      "training Loss: 0.0096 Acc: 86.4651\n",
      "validation Loss: 0.0100 Acc: 85.8095\n",
      "Epoch 20/99\n",
      "training Loss: 0.0095 Acc: 86.4949\n",
      "validation Loss: 0.0100 Acc: 85.8810\n",
      "Epoch 21/99\n",
      "training Loss: 0.0095 Acc: 86.5633\n",
      "validation Loss: 0.0099 Acc: 86.1071\n",
      "Epoch 22/99\n",
      "training Loss: 0.0095 Acc: 86.6050\n",
      "validation Loss: 0.0101 Acc: 85.8452\n",
      "Epoch 23/99\n",
      "training Loss: 0.0095 Acc: 86.6913\n",
      "validation Loss: 0.0100 Acc: 86.0595\n",
      "Epoch 24/99\n",
      "training Loss: 0.0094 Acc: 86.7091\n",
      "validation Loss: 0.0101 Acc: 85.8690\n",
      "Epoch 25/99\n",
      "training Loss: 0.0094 Acc: 86.6883\n",
      "validation Loss: 0.0100 Acc: 86.2143\n",
      "Saving..\n",
      "Epoch 26/99\n",
      "training Loss: 0.0093 Acc: 86.8073\n",
      "validation Loss: 0.0100 Acc: 85.9643\n",
      "Epoch 27/99\n",
      "training Loss: 0.0093 Acc: 86.8877\n",
      "validation Loss: 0.0101 Acc: 86.1071\n",
      "Epoch 28/99\n",
      "training Loss: 0.0091 Acc: 87.0484\n",
      "validation Loss: 0.0101 Acc: 85.9405\n",
      "Epoch 29/99\n",
      "training Loss: 0.0090 Acc: 87.1942\n",
      "validation Loss: 0.0101 Acc: 85.9048\n",
      "Epoch 30/99\n",
      "training Loss: 0.0090 Acc: 87.1853\n",
      "validation Loss: 0.0101 Acc: 85.8690\n",
      "Epoch 31/99\n",
      "training Loss: 0.0090 Acc: 87.1972\n",
      "validation Loss: 0.0101 Acc: 85.8571\n",
      "Epoch 32/99\n",
      "training Loss: 0.0089 Acc: 87.3668\n",
      "validation Loss: 0.0101 Acc: 85.7143\n",
      "Epoch 33/99\n",
      "training Loss: 0.0089 Acc: 87.5632\n",
      "validation Loss: 0.0102 Acc: 85.7738\n",
      "Epoch 34/99\n",
      "training Loss: 0.0087 Acc: 87.6525\n",
      "validation Loss: 0.0101 Acc: 85.5714\n",
      "Epoch 35/99\n",
      "training Loss: 0.0087 Acc: 87.7239\n",
      "validation Loss: 0.0103 Acc: 85.3571\n",
      "Early stopped.\n",
      "Best val acc: 86.214286\n",
      "----------\n",
      "Epoch 0/99\n",
      "training Loss: 0.0118 Acc: 83.5069\n",
      "validation Loss: 0.0108 Acc: 85.4524\n",
      "Saving..\n",
      "Epoch 1/99\n",
      "training Loss: 0.0109 Acc: 84.9205\n",
      "validation Loss: 0.0106 Acc: 85.0833\n",
      "Epoch 2/99\n",
      "training Loss: 0.0107 Acc: 85.0991\n",
      "validation Loss: 0.0102 Acc: 85.8095\n",
      "Saving..\n",
      "Epoch 3/99\n",
      "training Loss: 0.0105 Acc: 85.2658\n",
      "validation Loss: 0.0103 Acc: 85.8452\n",
      "Saving..\n",
      "Epoch 4/99\n",
      "training Loss: 0.0104 Acc: 85.2419\n",
      "validation Loss: 0.0104 Acc: 85.5595\n",
      "Epoch 5/99\n",
      "training Loss: 0.0104 Acc: 85.4443\n",
      "validation Loss: 0.0102 Acc: 85.9048\n",
      "Saving..\n",
      "Epoch 6/99\n",
      "training Loss: 0.0103 Acc: 85.5187\n",
      "validation Loss: 0.0102 Acc: 85.7857\n",
      "Epoch 7/99\n",
      "training Loss: 0.0102 Acc: 85.7330\n",
      "validation Loss: 0.0102 Acc: 86.0119\n",
      "Saving..\n",
      "Epoch 8/99\n",
      "training Loss: 0.0102 Acc: 85.7598\n",
      "validation Loss: 0.0101 Acc: 85.8095\n",
      "Epoch 9/99\n",
      "training Loss: 0.0102 Acc: 85.9473\n",
      "validation Loss: 0.0100 Acc: 85.7143\n",
      "Epoch 10/99\n",
      "training Loss: 0.0101 Acc: 85.8014\n",
      "validation Loss: 0.0102 Acc: 85.4881\n",
      "Epoch 11/99\n",
      "training Loss: 0.0101 Acc: 85.7985\n",
      "validation Loss: 0.0100 Acc: 85.8929\n",
      "Epoch 12/99\n",
      "training Loss: 0.0100 Acc: 85.9919\n",
      "validation Loss: 0.0101 Acc: 86.0952\n",
      "Saving..\n",
      "Epoch 13/99\n",
      "training Loss: 0.0100 Acc: 86.0842\n",
      "validation Loss: 0.0102 Acc: 85.9524\n",
      "Epoch 14/99\n",
      "training Loss: 0.0099 Acc: 85.9473\n",
      "validation Loss: 0.0101 Acc: 85.8810\n",
      "Epoch 15/99\n",
      "training Loss: 0.0099 Acc: 86.2419\n",
      "validation Loss: 0.0100 Acc: 86.0357\n",
      "Epoch 16/99\n",
      "training Loss: 0.0098 Acc: 86.1258\n",
      "validation Loss: 0.0100 Acc: 85.5833\n",
      "Epoch 17/99\n",
      "training Loss: 0.0098 Acc: 86.2478\n",
      "validation Loss: 0.0100 Acc: 86.0833\n",
      "Epoch 18/99\n",
      "training Loss: 0.0096 Acc: 86.5722\n",
      "validation Loss: 0.0099 Acc: 86.0000\n",
      "Epoch 19/99\n",
      "training Loss: 0.0095 Acc: 86.6734\n",
      "validation Loss: 0.0099 Acc: 86.0714\n",
      "Epoch 20/99\n",
      "training Loss: 0.0095 Acc: 86.8133\n",
      "validation Loss: 0.0099 Acc: 86.0476\n",
      "Epoch 21/99\n",
      "training Loss: 0.0095 Acc: 86.7419\n",
      "validation Loss: 0.0099 Acc: 85.9286\n",
      "Epoch 22/99\n",
      "training Loss: 0.0094 Acc: 86.9234\n",
      "validation Loss: 0.0100 Acc: 85.6310\n",
      "Early stopped.\n",
      "Best val acc: 86.095238\n",
      "----------\n",
      "Average best_acc across k-fold: 86.1054408814\n",
      "New configuration: {'hidden_layers': 1, 'dropout_g': 0.6935906574298658, 'initial_nodes': 500, 'dropout': 0.01, 'gru_layers': 3, 'batch_size': 32, 'gru_size': 500, 'learning_rate': 1e-05}\n",
      "Epoch 0/99\n",
      "training Loss: 0.0158 Acc: 76.5476\n",
      "validation Loss: 0.0123 Acc: 81.9686\n",
      "Saving..\n",
      "Epoch 1/99\n",
      "training Loss: 0.0124 Acc: 81.8304\n",
      "validation Loss: 0.0120 Acc: 82.7422\n",
      "Saving..\n",
      "Epoch 2/99\n",
      "training Loss: 0.0122 Acc: 82.3333\n",
      "validation Loss: 0.0118 Acc: 83.0279\n",
      "Saving..\n",
      "Epoch 3/99\n",
      "training Loss: 0.0120 Acc: 82.8244\n",
      "validation Loss: 0.0116 Acc: 83.2659\n",
      "Saving..\n",
      "Epoch 4/99\n",
      "training Loss: 0.0120 Acc: 82.8899\n",
      "validation Loss: 0.0116 Acc: 83.6468\n",
      "Saving..\n",
      "Epoch 5/99\n",
      "training Loss: 0.0119 Acc: 82.9464\n",
      "validation Loss: 0.0116 Acc: 83.5515\n",
      "Epoch 6/99\n",
      "training Loss: 0.0119 Acc: 83.1280\n",
      "validation Loss: 0.0115 Acc: 83.5991\n",
      "Epoch 7/99\n",
      "training Loss: 0.0118 Acc: 83.1875\n",
      "validation Loss: 0.0115 Acc: 83.7539\n",
      "Saving..\n",
      "Epoch 8/99\n",
      "training Loss: 0.0118 Acc: 83.2411\n",
      "validation Loss: 0.0115 Acc: 83.6110\n",
      "Epoch 9/99\n",
      "training Loss: 0.0118 Acc: 83.2649\n",
      "validation Loss: 0.0114 Acc: 83.7301\n",
      "Epoch 10/99\n",
      "training Loss: 0.0118 Acc: 83.3839\n",
      "validation Loss: 0.0114 Acc: 83.8610\n",
      "Saving..\n",
      "Epoch 11/99\n",
      "training Loss: 0.0117 Acc: 83.3185\n",
      "validation Loss: 0.0114 Acc: 83.9800\n",
      "Saving..\n",
      "Epoch 12/99\n",
      "training Loss: 0.0117 Acc: 83.3929\n",
      "validation Loss: 0.0114 Acc: 83.9205\n",
      "Epoch 13/99\n",
      "training Loss: 0.0117 Acc: 83.4345\n",
      "validation Loss: 0.0113 Acc: 84.0038\n",
      "Saving..\n",
      "Epoch 14/99\n",
      "training Loss: 0.0116 Acc: 83.4464\n",
      "validation Loss: 0.0113 Acc: 84.1466\n",
      "Saving..\n",
      "Epoch 15/99\n",
      "training Loss: 0.0116 Acc: 83.5744\n",
      "validation Loss: 0.0113 Acc: 84.1585\n",
      "Saving..\n",
      "Epoch 16/99\n",
      "training Loss: 0.0115 Acc: 83.6161\n",
      "validation Loss: 0.0112 Acc: 84.3490\n",
      "Saving..\n",
      "Epoch 17/99\n",
      "training Loss: 0.0115 Acc: 83.6845\n",
      "validation Loss: 0.0111 Acc: 84.4680\n",
      "Saving..\n",
      "Epoch 18/99\n",
      "training Loss: 0.0114 Acc: 83.8601\n",
      "validation Loss: 0.0111 Acc: 84.5513\n",
      "Saving..\n",
      "Epoch 19/99\n",
      "training Loss: 0.0114 Acc: 83.8839\n",
      "validation Loss: 0.0110 Acc: 84.5513\n",
      "Epoch 20/99\n",
      "training Loss: 0.0113 Acc: 84.0655\n",
      "validation Loss: 0.0110 Acc: 84.6584\n",
      "Saving..\n",
      "Epoch 21/99\n",
      "training Loss: 0.0112 Acc: 84.1905\n",
      "validation Loss: 0.0109 Acc: 84.8131\n",
      "Saving..\n",
      "Epoch 22/99\n",
      "training Loss: 0.0112 Acc: 84.2708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation Loss: 0.0108 Acc: 84.6465\n",
      "Epoch 23/99\n",
      "training Loss: 0.0111 Acc: 84.2440\n",
      "validation Loss: 0.0108 Acc: 85.0988\n",
      "Saving..\n",
      "Epoch 24/99\n",
      "training Loss: 0.0111 Acc: 84.3036\n",
      "validation Loss: 0.0108 Acc: 84.9798\n",
      "Epoch 25/99\n",
      "training Loss: 0.0111 Acc: 84.4345\n",
      "validation Loss: 0.0107 Acc: 85.2178\n",
      "Saving..\n",
      "Epoch 26/99\n",
      "training Loss: 0.0110 Acc: 84.4077\n",
      "validation Loss: 0.0107 Acc: 85.2773\n",
      "Saving..\n",
      "Epoch 27/99\n",
      "training Loss: 0.0110 Acc: 84.5595\n",
      "validation Loss: 0.0107 Acc: 85.2773\n",
      "Epoch 28/99\n",
      "training Loss: 0.0110 Acc: 84.5536\n",
      "validation Loss: 0.0106 Acc: 85.3725\n",
      "Saving..\n",
      "Epoch 29/99\n",
      "training Loss: 0.0110 Acc: 84.3661\n",
      "validation Loss: 0.0106 Acc: 85.3725\n",
      "Epoch 30/99\n",
      "training Loss: 0.0109 Acc: 84.7708\n",
      "validation Loss: 0.0105 Acc: 85.3487\n",
      "Epoch 31/99\n",
      "training Loss: 0.0109 Acc: 84.6369\n",
      "validation Loss: 0.0105 Acc: 85.5154\n",
      "Saving..\n",
      "Epoch 32/99\n",
      "training Loss: 0.0109 Acc: 84.7887\n",
      "validation Loss: 0.0105 Acc: 85.5273\n",
      "Saving..\n",
      "Epoch 33/99\n",
      "training Loss: 0.0109 Acc: 84.7024\n",
      "validation Loss: 0.0105 Acc: 85.4677\n",
      "Epoch 34/99\n",
      "training Loss: 0.0108 Acc: 84.6042\n",
      "validation Loss: 0.0105 Acc: 85.6106\n",
      "Saving..\n",
      "Epoch 35/99\n",
      "training Loss: 0.0108 Acc: 84.7232\n",
      "validation Loss: 0.0105 Acc: 85.5273\n",
      "Epoch 36/99\n",
      "training Loss: 0.0108 Acc: 84.8542\n",
      "validation Loss: 0.0105 Acc: 85.4796\n",
      "Epoch 37/99\n",
      "training Loss: 0.0108 Acc: 84.8363\n",
      "validation Loss: 0.0104 Acc: 85.4677\n",
      "Epoch 38/99\n",
      "training Loss: 0.0107 Acc: 84.9048\n",
      "validation Loss: 0.0104 Acc: 85.6225\n",
      "Saving..\n",
      "Epoch 39/99\n",
      "training Loss: 0.0108 Acc: 84.7262\n",
      "validation Loss: 0.0104 Acc: 85.5987\n",
      "Epoch 40/99\n",
      "training Loss: 0.0108 Acc: 84.7173\n",
      "validation Loss: 0.0105 Acc: 85.5154\n",
      "Epoch 41/99\n",
      "training Loss: 0.0107 Acc: 84.9018\n",
      "validation Loss: 0.0104 Acc: 85.8248\n",
      "Saving..\n",
      "Epoch 42/99\n",
      "training Loss: 0.0107 Acc: 85.0149\n",
      "validation Loss: 0.0104 Acc: 85.7296\n",
      "Epoch 43/99\n",
      "training Loss: 0.0107 Acc: 84.9226\n",
      "validation Loss: 0.0104 Acc: 85.7415\n",
      "Epoch 44/99\n",
      "training Loss: 0.0107 Acc: 84.8780\n",
      "validation Loss: 0.0104 Acc: 85.6582\n",
      "Epoch 45/99\n",
      "training Loss: 0.0107 Acc: 85.0417\n",
      "validation Loss: 0.0104 Acc: 85.5273\n",
      "Epoch 46/99\n",
      "training Loss: 0.0106 Acc: 84.9345\n",
      "validation Loss: 0.0104 Acc: 85.6939\n",
      "Epoch 47/99\n",
      "training Loss: 0.0106 Acc: 84.9881\n",
      "validation Loss: 0.0103 Acc: 85.5511\n",
      "Epoch 48/99\n",
      "training Loss: 0.0106 Acc: 85.0000\n",
      "validation Loss: 0.0104 Acc: 85.7415\n",
      "Epoch 49/99\n",
      "training Loss: 0.0106 Acc: 85.0179\n",
      "validation Loss: 0.0103 Acc: 85.5868\n",
      "Epoch 50/99\n",
      "training Loss: 0.0106 Acc: 85.1607\n",
      "validation Loss: 0.0104 Acc: 85.7534\n",
      "Epoch 51/99\n",
      "training Loss: 0.0106 Acc: 85.0714\n",
      "validation Loss: 0.0104 Acc: 85.5035\n",
      "Early stopped.\n",
      "Best val acc: 85.824804\n",
      "----------\n",
      "Epoch 0/99\n",
      "training Loss: 0.0158 Acc: 78.6441\n",
      "validation Loss: 0.0126 Acc: 81.4167\n",
      "Saving..\n",
      "Epoch 1/99\n",
      "training Loss: 0.0124 Acc: 81.8582\n",
      "validation Loss: 0.0122 Acc: 82.0238\n",
      "Saving..\n",
      "Epoch 2/99\n",
      "training Loss: 0.0121 Acc: 82.3909\n",
      "validation Loss: 0.0121 Acc: 82.6429\n",
      "Saving..\n",
      "Epoch 3/99\n",
      "training Loss: 0.0120 Acc: 82.7332\n",
      "validation Loss: 0.0119 Acc: 82.7738\n",
      "Saving..\n",
      "Epoch 4/99\n",
      "training Loss: 0.0120 Acc: 83.0278\n",
      "validation Loss: 0.0119 Acc: 83.0833\n",
      "Saving..\n",
      "Epoch 5/99\n",
      "training Loss: 0.0119 Acc: 83.1171\n",
      "validation Loss: 0.0118 Acc: 83.2738\n",
      "Saving..\n",
      "Epoch 6/99\n",
      "training Loss: 0.0119 Acc: 83.0843\n",
      "validation Loss: 0.0118 Acc: 83.2857\n",
      "Saving..\n",
      "Epoch 7/99\n",
      "training Loss: 0.0118 Acc: 83.2093\n",
      "validation Loss: 0.0117 Acc: 83.5119\n",
      "Saving..\n",
      "Epoch 8/99\n",
      "training Loss: 0.0118 Acc: 83.1915\n",
      "validation Loss: 0.0117 Acc: 83.6667\n",
      "Saving..\n",
      "Epoch 9/99\n",
      "training Loss: 0.0118 Acc: 83.2004\n",
      "validation Loss: 0.0117 Acc: 83.5119\n",
      "Epoch 10/99\n",
      "training Loss: 0.0118 Acc: 83.2778\n",
      "validation Loss: 0.0117 Acc: 83.4643\n",
      "Epoch 11/99\n",
      "training Loss: 0.0117 Acc: 83.4236\n",
      "validation Loss: 0.0117 Acc: 83.2381\n",
      "Epoch 12/99\n",
      "training Loss: 0.0117 Acc: 83.4861\n",
      "validation Loss: 0.0116 Acc: 83.8452\n",
      "Saving..\n",
      "Epoch 13/99\n",
      "training Loss: 0.0116 Acc: 83.3433\n",
      "validation Loss: 0.0116 Acc: 84.0238\n",
      "Saving..\n",
      "Epoch 14/99\n",
      "training Loss: 0.0116 Acc: 83.3909\n",
      "validation Loss: 0.0115 Acc: 83.8095\n",
      "Epoch 15/99\n",
      "training Loss: 0.0116 Acc: 83.5813\n",
      "validation Loss: 0.0115 Acc: 83.9643\n",
      "Epoch 16/99\n",
      "training Loss: 0.0115 Acc: 83.6647\n",
      "validation Loss: 0.0114 Acc: 83.8333\n",
      "Epoch 17/99\n",
      "training Loss: 0.0115 Acc: 83.6766\n",
      "validation Loss: 0.0114 Acc: 84.1667\n",
      "Saving..\n",
      "Epoch 18/99\n",
      "training Loss: 0.0114 Acc: 83.8164\n",
      "validation Loss: 0.0113 Acc: 84.0119\n",
      "Epoch 19/99\n",
      "training Loss: 0.0114 Acc: 83.7599\n",
      "validation Loss: 0.0113 Acc: 84.0952\n",
      "Epoch 20/99\n",
      "training Loss: 0.0113 Acc: 84.0099\n",
      "validation Loss: 0.0112 Acc: 84.2619\n",
      "Saving..\n",
      "Epoch 21/99\n",
      "training Loss: 0.0113 Acc: 83.9593\n",
      "validation Loss: 0.0111 Acc: 84.4405\n",
      "Saving..\n",
      "Epoch 22/99\n",
      "training Loss: 0.0112 Acc: 84.0099\n",
      "validation Loss: 0.0110 Acc: 84.6071\n",
      "Saving..\n",
      "Epoch 23/99\n",
      "training Loss: 0.0111 Acc: 84.2837\n",
      "validation Loss: 0.0110 Acc: 84.7024\n",
      "Saving..\n",
      "Epoch 24/99\n",
      "training Loss: 0.0111 Acc: 84.2777\n",
      "validation Loss: 0.0109 Acc: 84.5357\n",
      "Epoch 25/99\n",
      "training Loss: 0.0111 Acc: 84.1855\n",
      "validation Loss: 0.0109 Acc: 84.6071\n",
      "Epoch 26/99\n",
      "training Loss: 0.0110 Acc: 84.3491\n",
      "validation Loss: 0.0108 Acc: 84.7381\n",
      "Saving..\n",
      "Epoch 27/99\n",
      "training Loss: 0.0110 Acc: 84.5307\n",
      "validation Loss: 0.0108 Acc: 84.6786\n",
      "Epoch 28/99\n",
      "training Loss: 0.0110 Acc: 84.3819\n",
      "validation Loss: 0.0108 Acc: 84.8452\n",
      "Saving..\n",
      "Epoch 29/99\n",
      "training Loss: 0.0109 Acc: 84.4533\n",
      "validation Loss: 0.0107 Acc: 84.8452\n",
      "Epoch 30/99\n",
      "training Loss: 0.0109 Acc: 84.4771\n",
      "validation Loss: 0.0107 Acc: 84.8929\n",
      "Saving..\n",
      "Epoch 31/99\n",
      "training Loss: 0.0109 Acc: 84.6200\n",
      "validation Loss: 0.0107 Acc: 84.9286\n",
      "Saving..\n",
      "Epoch 32/99\n",
      "training Loss: 0.0109 Acc: 84.4801\n",
      "validation Loss: 0.0106 Acc: 84.9881\n",
      "Saving..\n",
      "Epoch 33/99\n",
      "training Loss: 0.0108 Acc: 84.6229\n",
      "validation Loss: 0.0106 Acc: 85.0357\n",
      "Saving..\n",
      "Epoch 34/99\n",
      "training Loss: 0.0109 Acc: 84.6289\n",
      "validation Loss: 0.0106 Acc: 85.1548\n",
      "Saving..\n",
      "Epoch 35/99\n",
      "training Loss: 0.0109 Acc: 84.5694\n",
      "validation Loss: 0.0106 Acc: 85.0714\n",
      "Epoch 36/99\n",
      "training Loss: 0.0108 Acc: 84.5128\n",
      "validation Loss: 0.0106 Acc: 85.1310\n",
      "Epoch 37/99\n",
      "training Loss: 0.0108 Acc: 84.8045\n",
      "validation Loss: 0.0106 Acc: 85.0714\n",
      "Epoch 38/99\n",
      "training Loss: 0.0108 Acc: 84.7509\n",
      "validation Loss: 0.0106 Acc: 85.1310\n",
      "Epoch 39/99\n",
      "training Loss: 0.0108 Acc: 84.7301\n",
      "validation Loss: 0.0106 Acc: 85.0833\n",
      "Epoch 40/99\n",
      "training Loss: 0.0107 Acc: 84.7003\n",
      "validation Loss: 0.0106 Acc: 85.1667\n",
      "Saving..\n",
      "Epoch 41/99\n",
      "training Loss: 0.0107 Acc: 84.7777\n",
      "validation Loss: 0.0106 Acc: 85.2738\n",
      "Saving..\n",
      "Epoch 42/99\n",
      "training Loss: 0.0107 Acc: 84.7926\n",
      "validation Loss: 0.0106 Acc: 85.2857\n",
      "Saving..\n",
      "Epoch 43/99\n",
      "training Loss: 0.0107 Acc: 84.8938\n",
      "validation Loss: 0.0105 Acc: 85.1667\n",
      "Epoch 44/99\n",
      "training Loss: 0.0107 Acc: 84.9384\n",
      "validation Loss: 0.0105 Acc: 85.1190\n",
      "Epoch 45/99\n",
      "training Loss: 0.0107 Acc: 84.8938\n",
      "validation Loss: 0.0105 Acc: 85.3214\n",
      "Saving..\n",
      "Epoch 46/99\n"
     ]
    }
   ],
   "source": [
    "space  = [Integer(1, 3, name='hidden_layers'),\n",
    "          Integer(10, 500, name='initial_nodes'),\n",
    "          Real(0.01,0.9,name='dropout'),\n",
    "          Integer(1, 3, name='gru_layers'),\n",
    "          Integer(10, 500, name='gru_size'),\n",
    "          Real(0.01,0.9,name='dropout_g'),\n",
    "          Real(10**-5, 10**-1, \"log-uniform\", name='learning_rate'),\n",
    "          Integer(32,512,name='batch_size')\n",
    "          ]\n",
    "\n",
    "@use_named_args(space)\n",
    "def objective(**X):\n",
    "    print(\"New configuration: {}\".format(X))\n",
    "    fom = []\n",
    "    for train_index, test_index in skf.split(data_hlf, label):\n",
    "        train_loader = DataLoader(ParticleHLF(data_list[train_index], data_hlf[train_index], label[train_index]), batch_size = X['batch_size'], shuffle=True)\n",
    "        val_loader = DataLoader(ParticleHLF(data_list[test_index], data_hlf[test_index], label[test_index]), batch_size = X['batch_size'], shuffle=True)\n",
    "        data_loader = {\"training\": train_loader, \"validation\": val_loader} \n",
    "\n",
    "        model = InclusiveNetwork(X['hidden_layers'], X['initial_nodes'], X['dropout'], X['gru_layers'], X['gru_size'], X['dropout_g']).cuda()\n",
    "        optimizer = AMSGrad(model.parameters(), lr=X['learning_rate'])\n",
    "        criterion= nn.NLLLoss()\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,mode ='min',factor=0.5,patience=4)\n",
    "        best_acc = train(EPOCHS, model, criterion, optimizer, scheduler, data_loader=data_loader)\n",
    "        fom.append(best_acc)\n",
    "    Y = np.mean(np.asarray(fom))\n",
    "    print(\"Average best_acc across k-fold: {}\".format(Y))\n",
    "    return -Y\n",
    "\n",
    "res_gp = gp_minimize(objective, space, n_calls=30, random_state=0)\n",
    "\n",
    "print(\"Best parameters: {}\".format(res_gp.x))\n",
    "best_hidden_layers = res_gp.x[0]\n",
    "best_initial_nodes = res_gp.x[1]\n",
    "best_dropout = res_gp.x[2]\n",
    "best_gru_layers = res_gp.x[3]\n",
    "best_gru_size = res_gp.x[4]\n",
    "best_dropout_g = res_gp.x[5]\n",
    "best_learning_rate = res_gp.x[6]\n",
    "best_batch_size = res_gp.x[7]\n",
    "\n",
    "bestconf = {\"hidden_layers\": best_hidden_layers,\n",
    "          \"initial_nodes\": best_initial_nodes,\n",
    "          \"dropout\": best_dropout,\n",
    "          \"gru_layers\": best_gru_layers,\n",
    "          \"gru_size\": best_gru_size,\n",
    "          \"dropout_g\": best_dropout_g,\n",
    "          \"learning_rate\": best_learning_rate,\n",
    "          \"batch_size\": best_batch_size}\n",
    "with open(config_file, 'w') as config:\n",
    "    json.dump(bestconf, config)\n",
    "    print(\"Save best configuration to {}\".format(config_file))\n",
    "\n",
    "train_index, test_index = skf.split(data_hlf, label).next()\n",
    "model = InclusiveNetwork(best_hidden_layers, best_initial_nodes, best_dropout, best_gru_layers, best_gru_size, best_dropout_g).cuda()\n",
    "train_loader = DataLoader(ParticleHLF(data_list[train_index], data_hlf[train_index], label[train_index]), batch_size = best_batch_size, shuffle=True)\n",
    "val_loader = DataLoader(ParticleHLF(data_list[test_index], data_hlf[test_index], label[test_index]), batch_size = best_batch_size, shuffle=True)\n",
    "data_loader = {\"training\": train_loader, \"validation\": val_loader}\n",
    "optimizer = AMSGrad(model.parameters(), lr=best_learning_rate)\n",
    "criterion= nn.NLLLoss()\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,mode ='min',factor=0.5,patience=3)\n",
    "best_acc = train(EPOCHS, model, criterion, optimizer, scheduler, data_loader=data_loader)\n",
    "torch.save(model.state_dict(), model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the optimized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(config_file) as f:\n",
    "    bestconf = json.load(f)\n",
    "    print(bestconf)\n",
    "print(\"Loaded best configuration from {}\".format(config_file))\n",
    "model = InclusiveNetwork(bestconf['hidden_layers'], bestconf['initial_nodes'], bestconf['dropout'], bestconf['gru_layers'], bestconf['gru_size'], bestconf['dropout_g']).cuda()\n",
    "model.load_state_dict(torch.load(model_file))\n",
    "print(\"Loaded best model parameter from {}\".format(model_file))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_array(array_to_fill, value, index, batch_size):\n",
    "    array_to_fill[index*batch_size:min((index+1)*batch_size, array_to_fill.shape[0]),...] = value  \n",
    "\n",
    "TPR_thresholds = [0.96, 0.935, 0.9, 0.7, 0.5, 0.3]\n",
    "\n",
    "fprs = []\n",
    "base_tpr = np.linspace(0, 1, 5000)\n",
    "thresholds = []\n",
    "volatile=True\n",
    "best_batch_size = bestconf['batch_size']\n",
    "for train_index, test_index in skf.split(data_hlf, label):\n",
    "    val_loader = DataLoader(ParticleHLF(data_list[test_index], data_hlf[test_index], label[test_index]), batch_size = best_batch_size, shuffle=False)\n",
    "    model.eval()\n",
    "    all_pred = np.zeros(shape=(len(data_hlf[test_index]),2))\n",
    "    all_label = np.zeros(shape=(len(data_hlf[test_index])))\n",
    "    criterion= nn.NLLLoss()\n",
    "\n",
    "    for batch_idx, (particles_data, hlf_data, y_data) in enumerate(val_loader):\n",
    "        particles_data = particles_data.numpy()\n",
    "        arr = np.sum(particles_data!=0, axis=1)[:,0] # the number of particles in the whole batch\n",
    "        arr = [1 if x==0 else x for x in arr]\n",
    "        arr = np.array(arr)\n",
    "        sorted_indices_la= np.argsort(-arr)\n",
    "        particles_data = torch.from_numpy(particles_data[sorted_indices_la]).float()\n",
    "        hlf_data = hlf_data[sorted_indices_la]\n",
    "        particles_data = Variable(particles_data, volatile=volatile).cuda()\n",
    "        hlf_data = Variable(hlf_data, volatile).cuda()\n",
    "        t_seq_length= [arr[i] for i in sorted_indices_la]\n",
    "        particles_data = torch.nn.utils.rnn.pack_padded_sequence(particles_data, t_seq_length, batch_first=True)\n",
    "\n",
    "        outputs = model(particles_data, hlf_data)\n",
    "\n",
    "        # Unsort the predictions (to match the original data order)\n",
    "        # https://stackoverflow.com/questions/34159608/how-to-unsort-a-np-array-given-the-argsort\n",
    "        b = np.argsort(sorted_indices_la)\n",
    "        unsorted_pred = outputs[b].data.cpu().numpy()\n",
    "\n",
    "        fill_array(all_pred, unsorted_pred, batch_idx, best_batch_size)\n",
    "        fill_array(all_label, y_data.numpy(), batch_idx, best_batch_size)\n",
    "\n",
    "    fpr, tpr, threshold = roc_curve(all_label, np.exp(all_pred)[:,1])\n",
    "    \n",
    "    fpr = np.interp(base_tpr, tpr, fpr)\n",
    "    threshold = np.interp(base_tpr, tpr, threshold)\n",
    "    fpr[0] = 0.0\n",
    "    fprs.append(fpr)\n",
    "    thresholds.append(threshold)\n",
    "\n",
    "thresholds = np.array(thresholds)\n",
    "mean_thresholds = thresholds.mean(axis=0)\n",
    "\n",
    "fprs = np.array(fprs)\n",
    "mean_fprs = fprs.mean(axis=0)\n",
    "std_fprs = fprs.std(axis=0)\n",
    "fprs_right = np.minimum(mean_fprs + std_fprs, 1)\n",
    "fprs_left = np.maximum(mean_fprs - std_fprs,0)\n",
    "\n",
    "mean_area = auc(mean_fprs, base_tpr)\n",
    "\n",
    "print(\"Neural network performance\")\n",
    "NNtable = PrettyTable(['Threshold','Signal Efficiency','Background Contamination'])\n",
    "NNtable.float_format = \".4\"\n",
    "for TPR_threshold in TPR_thresholds:\n",
    "    thres_idx = np.argmax(base_tpr>TPR_threshold)\n",
    "    NNtable.add_row([mean_thresholds[thres_idx], base_tpr[thres_idx], \"{:.4f} +/- {:.4f}\".format(mean_fprs[thres_idx], std_fprs[thres_idx])])\n",
    "print(NNtable)\n",
    "\n",
    "plt.figure(figsize=(9,7))\n",
    "plt.plot(mean_fprs, base_tpr,label=\"NN AUC = {}\".format(mean_area))\n",
    "plt.fill_betweenx(base_tpr, fprs_left, fprs_right, color='grey', alpha=0.4)\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Background contamination')\n",
    "plt.ylabel('Signal efficiency')\n",
    "#plt.axhline(tpr[thres_idx],ls='--',color='tab:gray')\n",
    "#plt.axvline(fpr[thres_idx],ls='--',color='tab:gray')\n",
    "\n",
    "plt.figure(figsize=(9,7))\n",
    "plt.hist(np.exp(all_pred)[all_label==0,1], bins=60, label='ttH background',alpha=0.5, normed=True)\n",
    "plt.hist(np.exp(all_pred)[all_label==1,1], bins=60, label='HH signal', alpha=0.5, normed=True)\n",
    "#plt.axvline(thresholds[thres_idx], ls='--',color='tab:gray')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel(\"Threshold\", fontsize=18)\n",
    "\n",
    "with h5py.File(\"ReallyInclusive_ROC.h5\",\"w\") as out:\n",
    "    out['FPR'] = mean_fprs\n",
    "    out['dFPR'] = std_fprs\n",
    "    out['TPR'] = base_tpr\n",
    "    out['Thresholds'] = mean_thresholds\n",
    "    print(\"Saved ROC.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_array(array_to_fill, value, index, batch_size):\n",
    "    array_to_fill[index*batch_size:min((index+1)*batch_size, array_to_fill.shape[0]),...] = value\n",
    "\n",
    "particles_val = np.concatenate((normed_sig_list, normed_bkg_list))\n",
    "hlf_val = np.concatenate((normed_sig_hlf, normed_bkg_hlf))\n",
    "y_val = np.concatenate((np.ones(len(normed_sig_hlf)),np.zeros(len(normed_bkg_hlf))))\n",
    "print(particles_val.shape)\n",
    "print(hlf_val.shape)\n",
    "print(y_val.shape)\n",
    "\n",
    "test_batch_size = 300\n",
    "\n",
    "all_pred = np.zeros(shape=(len(y_val),2))\n",
    "test_loader = DataLoader(ParticleHLF(particles_val, hlf_val, y_val), batch_size = test_batch_size, shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "volatile=True\n",
    "\n",
    "for batch_idx, (particles_data, hlf_data, y_data) in enumerate(test_loader):\n",
    "    particles_data = particles_data.numpy()\n",
    "    arr = np.sum(particles_data!=0, axis=1)[:,0] # the number of particles in the whole batch\n",
    "    arr = [1 if x==0 else x for x in arr]\n",
    "    arr = np.array(arr)\n",
    "    sorted_indices_la= np.argsort(-arr)\n",
    "    particles_data = torch.from_numpy(particles_data[sorted_indices_la]).float()\n",
    "    hlf_data = hlf_data[sorted_indices_la]\n",
    "    particles_data = Variable(particles_data, volatile=volatile).cuda()\n",
    "    hlf_data = Variable(hlf_data, volatile).cuda()\n",
    "    t_seq_length= [arr[i] for i in sorted_indices_la]\n",
    "    particles_data = torch.nn.utils.rnn.pack_padded_sequence(particles_data, t_seq_length, batch_first=True)\n",
    "\n",
    "    outputs = model(particles_data, hlf_data)\n",
    "\n",
    "    # Unsort the predictions (to match the original data order)\n",
    "    # https://stackoverflow.com/questions/34159608/how-to-unsort-a-np-array-given-the-argsort\n",
    "    b = np.argsort(sorted_indices_la)\n",
    "    unsorted_pred = outputs[b].data.cpu().numpy()\n",
    "    fill_array(all_pred, unsorted_pred, batch_idx, test_batch_size)\n",
    "    \n",
    "fpr, tpr, thresholds = roc_curve(y_val, np.exp(all_pred)[:,1])\n",
    "area = auc(fpr, tpr)\n",
    "\n",
    "TPR_thresholds = [0.96, 0.935, 0.9, 0.7, 0.5, 0.3]\n",
    "print(\"Neural network performance\")\n",
    "NNtable = PrettyTable(['Threshold','Signal Efficiency','Background Contamination'])\n",
    "NNtable.float_format = \".4\"\n",
    "for TPR_threshold in TPR_thresholds:\n",
    "    thres_idx = np.argmax(tpr>TPR_threshold)\n",
    "    #print(\"NN Signal efficiency = {} @ {} ttH background contamination\".format(tpr[thres_idx], fpr[thres_idx]))\n",
    "    NNtable.add_row([thresholds[thres_idx], tpr[thres_idx],  fpr[thres_idx]])\n",
    "print(NNtable)\n",
    "plt.figure(figsize=(9,7))\n",
    "plt.plot(fpr,tpr,label=\"NN AUC = {}\".format(area))\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Background contamination')\n",
    "plt.ylabel('Signal efficiency')\n",
    "#plt.axhline(tpr[thres_idx],ls='--',color='tab:gray')\n",
    "#plt.axvline(fpr[thres_idx],ls='--',color='tab:gray')\n",
    "\n",
    "plt.figure(figsize=(9,7))\n",
    "plt.hist(np.exp(all_pred)[y_val==0,1], bins=60, label='ttH background',alpha=0.5, normed=True)\n",
    "plt.hist(np.exp(all_pred)[y_val==1,1], bins=60, label='HH signal', alpha=0.5, normed=True)\n",
    "#plt.axvline(thresholds[thres_idx], ls='--',color='tab:gray')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel(\"Threshold\", fontsize=18)\n",
    "\n",
    "sig_frame = pd.DataFrame.from_records(signp)\n",
    "bkg_frame = pd.DataFrame.from_records(bkgnp)\n",
    "\n",
    "sig_frame['NN_score'] = pd.Series(np.exp(all_pred[:len(normed_sig_hlf),1]), index=sig_frame.index)\n",
    "bkg_frame['NN_score'] = pd.Series(np.exp(all_pred[len(normed_sig_hlf):,1]), index=bkg_frame.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check mistagged samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_check = {\n",
    "    'sumEt': [40, 0, 2500],\n",
    "    'MET': [40,0,500],\n",
    "    'phiMET': [40, -3.15, 3.15],\n",
    "    'dPhi1': [40, -3.15, 3,15],\n",
    "    'dPhi2': [40, -3.15, 3,15],\n",
    "    'PhoJetMinDr': [40, 0, 5],\n",
    "    'njets': [12, 0, 12],\n",
    "    'Xtt0': [40, 0, 1000],\n",
    "    'Xtt1': [40, 0, 1000],\n",
    "    'pte1': [40, 0, 500],\n",
    "    'pte2': [40, 0, 500],\n",
    "    'ptmu1': [40, 0, 500],\n",
    "    'ptmu2': [40, 0, 500],\n",
    "    'ptdipho': [40, 0, 1500],\n",
    "    'etae1': [40, -3.15, 3.15],\n",
    "    'etae2': [40, -3.15, 3.15],\n",
    "    'etamu1': [40, -3.15, 3.15],\n",
    "    'etamu2': [40, -3.15, 3.15],\n",
    "    'etadipho': [40, -5, 5],\n",
    "    'phie1': [40, -3.15, 3.15],\n",
    "    'phie2': [40, -3.15, 3.15],\n",
    "    'phimu1': [40, -3.15, 3.15],\n",
    "    'phimu2': [40, -3.15, 3.15],\n",
    "    'phidipho': [40, -3.15, 3.15],\n",
    "    'fabs_CosThetaStar_CS': [40, 0, 1],\n",
    "    'fabs_CosTheta_bb': [40, 0, 1]\n",
    "}\n",
    "\n",
    "background_mistag_thres = thresholds[np.argmax(fpr>0.005)]\n",
    "signal_mistag_thres = thresholds[np.argmax(tpr>0.97)]\n",
    "print(\"Threshold for bkg mistag: {}\".format(background_mistag_thres))\n",
    "print(\"Threshold for signal mistag: {}\".format(signal_mistag_thres))\n",
    "\n",
    "plt.figure(figsize=(9,7))\n",
    "plt.hist(np.exp(all_pred)[y_val==0,1], bins=60, label='ttH background',alpha=0.5, normed=True)\n",
    "plt.hist(np.exp(all_pred)[y_val==1,1], bins=60, label='HH signal', alpha=0.5, normed=True)\n",
    "plt.axvline(background_mistag_thres, ls='--',color='tab:gray')\n",
    "plt.axvline(signal_mistag_thres, ls='--',color='tab:gray')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel(\"Threshold\", fontsize=18)\n",
    "\n",
    "\n",
    "for feat in features_to_check:\n",
    "\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.hist(bkg_frame[feat], bins=features_to_check[feat][0], \n",
    "             range=(features_to_check[feat][1], features_to_check[feat][2]),\n",
    "             label='Full background',\n",
    "             histtype='stepfilled',\n",
    "             alpha=0.4,\n",
    "             normed=True\n",
    "             )\n",
    "    plt.hist(sig_frame[feat], bins=features_to_check[feat][0], \n",
    "             range=(features_to_check[feat][1], features_to_check[feat][2]),\n",
    "              label='Full signal',\n",
    "              histtype='stepfilled',\n",
    "             alpha=0.4,\n",
    "             normed=True,\n",
    "            )\n",
    "    plt.hist(sig_frame[feat][sig_frame['NN_score']<signal_mistag_thres], bins=features_to_check[feat][0], \n",
    "             range=(features_to_check[feat][1], features_to_check[feat][2]),\n",
    "             label='Signal predicted as bkg',\n",
    "            histtype='step',\n",
    "            linewidth=3,\n",
    "             normed=True,\n",
    "            )\n",
    "    plt.hist(bkg_frame[feat][bkg_frame['NN_score']>background_mistag_thres], bins=features_to_check[feat][0], \n",
    "             range=(features_to_check[feat][1], features_to_check[feat][2]),\n",
    "             histtype='step',\n",
    "             linewidth=3,\n",
    "             label='Bkg predicted as signal',\n",
    "             normed=True\n",
    "            )\n",
    "    plt.xlabel(feat, fontsize=15)\n",
    "    plt.yscale('log')\n",
    "    plt.legend(loc='upper center', bbox_to_anchor=(0.5, 1.2),\n",
    "          ncol=2, fancybox=True, fontsize=14)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check mass sculpting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fontsize=25\n",
    "\n",
    "plt.figure(figsize=(9,6))\n",
    "plt.hist(bkg_aux_frame['mass_jj'], bins=100, histtype='step', label='No cut',normed=True)\n",
    "for TPR_threshold in TPR_thresholds:\n",
    "    thres_idx = np.argmax(tpr>TPR_threshold)\n",
    "    #print(\"NN Signal efficiency = {} @ {} ttH background contamination\".format(tpr[thres_idx], fpr[thres_idx]))\n",
    "    plt.hist(bkg_aux_frame['mass_jj'][bkg_frame['NN_score']>thresholds[thres_idx]], \n",
    "             bins=100, histtype='step', \n",
    "             label= \"{:.0f}% signal eff\".format(100*tpr[thres_idx]),\n",
    "             normed=True)\n",
    "plt.legend(loc='best')\n",
    "plt.ylabel('Background events',fontsize=fontsize)\n",
    "plt.xlabel(r'$m_{bb}$',fontsize=fontsize)\n",
    "\n",
    "plt.figure(figsize=(9,6))\n",
    "plt.hist(sig_aux_frame['mass_jj'], bins=100, histtype='step', label='No cut', normed=True)\n",
    "for TPR_threshold in TPR_thresholds:\n",
    "    thres_idx = np.argmax(tpr>TPR_threshold)\n",
    "    #print(\"NN Signal efficiency = {} @ {} ttH background contamination\".format(tpr[thres_idx], fpr[thres_idx]))\n",
    "    plt.hist(sig_aux_frame['mass_jj'][sig_frame['NN_score']>thresholds[thres_idx]], \n",
    "             bins=100, histtype='step', label= \"{:.0f}% signal eff\".format(100*tpr[thres_idx]),\n",
    "             normed=True)\n",
    "plt.legend(loc='best')\n",
    "plt.ylabel('Signal events',fontsize=fontsize)\n",
    "plt.xlabel(r'$m_{bb}$',fontsize=fontsize)\n",
    "\n",
    "plt.figure(figsize=(9,6))\n",
    "plt.hist(bkg_aux_frame['mass_gg'], bins=100, range=(115,135), histtype='step', label='No cut', normed=True)\n",
    "for TPR_threshold in TPR_thresholds:\n",
    "    thres_idx = np.argmax(tpr>TPR_threshold)\n",
    "    #print(\"NN Signal efficiency = {} @ {} ttH background contamination\".format(tpr[thres_idx], fpr[thres_idx]))\n",
    "    plt.hist(bkg_aux_frame['mass_gg'][bkg_frame['NN_score']>thresholds[thres_idx]], \n",
    "             bins=100, histtype='step', \n",
    "             range=(115,135),\n",
    "             label= \"{:.0f}% signal eff\".format(100*tpr[thres_idx]),\n",
    "             normed=True)\n",
    "plt.legend(loc='best')\n",
    "plt.ylabel('Background events',fontsize=fontsize)\n",
    "plt.xlabel(r'$m_{\\gamma \\gamma}$',fontsize=fontsize)\n",
    "\n",
    "plt.figure(figsize=(9,6))\n",
    "plt.hist(sig_aux_frame['mass_gg'], bins=100, range=(115,135), histtype='step', label='No cut', normed=True)\n",
    "for TPR_threshold in TPR_thresholds:\n",
    "    thres_idx = np.argmax(tpr>TPR_threshold)\n",
    "    #print(\"NN Signal efficiency = {} @ {} ttH background contamination\".format(tpr[thres_idx], fpr[thres_idx]))\n",
    "    plt.hist(sig_aux_frame['mass_gg'][sig_frame['NN_score']>thresholds[thres_idx]], \n",
    "             bins=100, \n",
    "             histtype='step', \n",
    "             range=(115,135),\n",
    "             label= \"{:.0f}% signal eff\".format(100*tpr[thres_idx]),\n",
    "             normed=True)\n",
    "plt.legend(loc='best')\n",
    "plt.ylabel('Signal events',fontsize=fontsize)\n",
    "plt.xlabel(r'$m_{\\gamma \\gamma}$',fontsize=fontsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(\"DNN_ROC.h5\",\"r\") as rocfile:\n",
    "    fpr_dnn = rocfile['FPR'][:]\n",
    "    dfpr_dnn = rocfile['dFPR'][:]\n",
    "    tpr_dnn = rocfile['TPR'][:]\n",
    "    thres_dnn = rocfile['Thresholds'][:]\n",
    "    area_dnn = auc(fpr_dnn, tpr_dnn)\n",
    "    fprs_dnn_right = np.minimum(fpr_dnn + dfpr_dnn, 1)\n",
    "    fprs_dnn_left = np.maximum(fpr_dnn - dfpr_dnn,0)\n",
    "    darea_dnn = (1-auc(tpr_dnn,fprs_dnn_left))-area_dnn\n",
    "    \n",
    "with h5py.File(\"BDT_ROC.h5\",\"r\") as rocfile:\n",
    "    fpr_bdt = rocfile['FPR'][:]\n",
    "    tpr_bdt = rocfile['TPR'][:]\n",
    "    thres_bdt = rocfile['Thresholds'][:]\n",
    "    area_bdt = auc(fpr_bdt, tpr_bdt)\n",
    "\n",
    "with h5py.File(\"ReallyInclusive_ROC.h5\",\"r\") as rocfile:\n",
    "    fpr_inc = rocfile['FPR'][:]\n",
    "    dfpr_inc = rocfile['dFPR'][:]\n",
    "    tpr_inc = rocfile['TPR'][:]\n",
    "    thres_inc = rocfile['Thresholds'][:]\n",
    "    area_inc = auc(fpr_inc, tpr_inc)\n",
    "    fprs_inc_right = np.minimum(fpr_inc + dfpr_dnn, 1)\n",
    "    fprs_inc_left = np.maximum(fpr_inc - dfpr_dnn,0)\n",
    "    darea_inc = (1-auc(tpr_inc,fprs_inc_left))-area_inc\n",
    "\n",
    "### Compare\n",
    "plt.figure(figsize=(9,7))\n",
    "\n",
    "plt.plot(fpr_bdt,tpr_bdt,color='blue',label=\"BDT AUC = {:.4f}\".format(area_bdt))\n",
    "\n",
    "\n",
    "plt.plot(fpr_dnn,tpr_dnn,color='green',label=r\"VanillaDNN AUC = {:.4f}$\\pm${:.4f}\".format(area_dnn, darea_dnn))\n",
    "plt.fill_betweenx(tpr_dnn, fprs_dnn_left, fprs_dnn_right, color='green', alpha=0.3)\n",
    "\n",
    "\n",
    "plt.plot(fpr_inc,tpr_inc,color='orange',label=r\"InclusiveNet AUC = {:.4f}$\\pm${:.4f}\".format(area_inc, darea_inc))\n",
    "plt.fill_betweenx(tpr_inc, fprs_inc_left, fprs_inc_right, color='orange', alpha=0.3)\n",
    "\n",
    "plt.xlabel('Background contamination',fontsize=18)\n",
    "plt.ylabel('Signal efficiency',fontsize=18)\n",
    "# # plt.xlim(0.01,0.6)\n",
    "# # plt.ylim(0.2,1)\n",
    "# plt.axhline(tpr[thres_idx],ls='--',color='tab:gray')\n",
    "# plt.axvline(fpr[thres_idx],ls='--',color='tab:gray')\n",
    "plt.legend(loc='best',fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TPR_thresholds = [0.96, 0.935, 0.9, 0.7, 0.5]\n",
    "\n",
    "table = PrettyTable(['Signal Efficiency','BDT','VanillaDNN','InclusiveNet'])\n",
    "table.get_string(title=\"Background contamination at different signal efficiencies\")\n",
    "table.float_format = \".2\"\n",
    "for TPR_threshold in TPR_thresholds:\n",
    "    thres_dnn = np.argmax(tpr_dnn>TPR_threshold)\n",
    "    thres_bdt = np.argmax(tpr_bdt>TPR_threshold)\n",
    "    thres_inc = np.argmax(tpr_inc>TPR_threshold)\n",
    "\n",
    "    table.add_row([\"{:.2f}%\".format(100*(tpr_dnn[thres_dnn])),  \"{:.2f}%\".format(100*fpr_bdt[thres_bdt]), \"({:.2f} +/- {:.2f})%\".format(100*fpr_dnn[thres_dnn], 100*dfpr_dnn[thres_dnn]), \"({:.2f} +/- {:.2f})%\".format(100*fpr_inc[thres_inc], 100*dfpr_inc[thres_inc])])\n",
    "print(table.get_string(title=\"Background contamination at different signal efficiencies\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['pte1','pte2','ptmu1','ptmu2','ptdipho',\n",
    "            'etae1','etae2','etamu1','etamu2','etadipho',\n",
    "            'phie1','phie2','phimu1','phimu2','phidipho',\n",
    "            'MET','phiMET']\n",
    "\n",
    "for fea in features:\n",
    "    plt.figure()\n",
    "    plt.hist(sig_frame[fea][sig_frame[fea]!=0], bins=40, normed=True, \n",
    "             histtype='stepfilled', alpha=0.3, label='GluGluToHHTo2B2G Signal')\n",
    "    plt.hist(bkg_frame[fea][bkg_frame[fea]!=0], bins=40, normed=True, \n",
    "             histtype='stepfilled', alpha=0.45, label='ttHToGG Background')\n",
    "    plt.xlabel(fea,fontsize=15)\n",
    "    plt.legend(loc='best',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (higgsDNA_test)",
   "language": "python",
   "name": "higgsdna_test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
